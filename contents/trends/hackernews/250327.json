[
  {
    "id": "a42fcf6f48d18fb3",
    "title": {
      "en": "Coordinating the Superbowl's visual fidelity with Elixir",
      "ko": "엘릭서로 슈퍼볼 비주얼 조율하기",
      "ja": "スーパーボウルの映像美をエリクサーで"
    },
    "type": "story",
    "url": "https://elixir-lang.org/blog/2025/03/25/cyanview-elixir-case/",
    "score": 423,
    "by": "lawik",
    "time": 1742966362,
    "content": "Cyanview: Coordinating Super Bowl's visual fidelity with Elixir\n\n        March 25, 2025 · by Lars Wikman, José Valim · in\n\n            Elixir in Production\n\n        How do you coordinate visual fidelity across two hundred cameras for a live event like the Super Bowl?\n\nThe answer is: by using the craft of camera shading, which involves adjusting each camera to ensure they match up in color, exposure and various other visual aspects. The goal is to turn the live event broadcast into a cohesive and consistent experience. For every angle used, you want the same green grass and the same skin tones. Everything needs to be very closely tuned across a diverse set of products and brands. From large broadcast cameras, drone cameras, and PTZ cameras to gimbal-held mirrorless cameras and more. This is what Cyanview does. Cyanview is a small Belgian company that sells products for the live video broadcast industry, and its primary focus is shading.\n\nBroadcast is a business where you only get one chance to prove that your tool is up to the task. Reliability is king. There can be no hard failures.\n\nA small team of three built a product so powerful and effective that it spread across the industry purely on the strength of its functionality. Without any marketing, it earned a reputation among seasoned professionals and became a staple at the world’s top live events. Cyanview’s Remote Control Panel (RCP) is now used by specialist video operators on the Olympics, Super Bowl, NFL, NBA, ESPN, Amazon and many more. Even most fashion shows in Paris use Cyanview’s devices.\n\nThese devices put Elixir right in the critical path for serious broadcast operations. By choosing Elixir, Cyanview gained best-in-class networking features, state-of-the-art resilience and an ecosystem that allowed fast iteration on product features.\n\nWhy Elixir?\n\nThe founding team of Cyanview primarily had experience with embedded development, and the devices they produce involve a lot of low-level C code and plenty of FPGA. This is due to the low-level details of color science and the really tight timing requirements.\n\nIf you’ve ever worked with camera software, you know it can be a mixed bag. Even after going fully digital, much of it remained tied to analog systems or relied on proprietary connectivity solutions. Cyanview has been targeting IP (as in Internet Protocol) from early on. This means Cyanview’s software can operate on commodity networks that work in well-known and well-understood ways. This has aligned well with an increase in remote production, partially due to the pandemic, where production crews operate from a central location with minimal crew on location. Custom radio frequency or serial wire protocols have a hard time scaling to cross-continent distances.\n\nThis also paved the way for Elixir, as the Erlang VM was designed to communicate and coordinate millions of devices, reliably, over the network.\n\nElixir was brought in by the developer Ghislain, who needed to build integrations with cameras and interact with the other bits of required video gear, with many different protocols over the network. The language comes with a lot of practical features for encoding and decoding binary data down to the individual bits. Elixir gave them a strong foundation and the tools to iterate fast.\n\nGhislain has been building the core intellectual property of Cyanview ever since. While the physical device naturally has to be solid, reliable, and of high quality, a lot of the secret sauce ultimately lies in the massive number of integrations and huge amounts of reverse engineering. Thus, the product is able to work with as many professional camera systems and related equipment as possible. It is designed to be compatible with everything and anything a customer is using. Plus, it offers an API to ensure smooth integration with other devices.\n\nDavid Bourgeois, the founder of Cyanview, told us a story how these technical decisions alongside Elixir helped them tackle real-world challenges:\n\n“During the Olympics in China, a studio in Beijing relied on a large number of Panasonic PTZ cameras. Most of their team, however, was based in Paris and needed to control the cameras remotely to run various shows throughout the day. The problem? Panasonic’s camera protocols were never designed for internet use — they require precise timing and multiple messages for every adjustment. With network latency, that leads to timeouts, disconnects, and system failures… So they ended up placing our devices next to the cameras in Beijing and controlled them over IP from Paris — just as designed.”\n\nThe devices in a given location communicate and coordinate on the network over a custom MQTT protocol. Over a hundred cameras without issue on a single Remote Control Panel (RCP), implemented on top of Elixir’s network stack.\n\nTechnical composition\n\nThe system as a whole consists of RCP devices running a Yocto Linux system, with most of the logic built in Elixir and C. While Python is still used for scripting and tooling, its role has gradually diminished. The setup also includes multiple microcontrollers and the on-camera device, all communicating over MQTT. Additionally, cloud relays facilitate connectivity, while dashboards and controller UIs provide oversight and control. The two critical devices are the RCP offering control on the production end and the RIO handling low-latency manipulation of the camera. Both run Elixir.\n\nThe configuration UI is currently built in Elm, but - depending on priorities - it might be converted to Phoenix LiveView over time to reduce the number of languages in use. The controller web UI is already in LiveView, and it is performing quite well on a very low-spec embedded Linux machine.\n\nThe cloud part of the system is very limited today, which is unusual in a world of SaaS. There are cloud relays for distributing and sharing camera control as well as forwarding network ports between locations and some related features, also built in Elixir, but cloud is not at the core of the business. The devices running Elixir on location form a cluster over IP using a custom MQTT-based protocol suited to the task and are talking to hundreds of cameras and other video devices.\n\nIt goes without saying that integration with so much proprietary equipment comes with challenges. Some integrations are more reliable than others. Some devices are more common, and their quirks are well-known through hard-won experience. A few even have good documentation that you can reference while others offer mystery and constant surprises. In this context, David emphasizes the importance of Elixir’s mechanisms for recovering from failures:\n\n“If one camera connection has a blip, a buggy protocol or the physical connection to a device breaks it is incredibly important that everything else keeps working. And this is where Elixir’s supervision trees provide a critical advantage.”\n\nGrowth & team composition\n\nThe team has grown over the 9 years that the company has been operating, but it did so at a slow and steady pace. On average, the company has added just one person per year. With nine employees at the time of writing, Cyanview supports some of the biggest broadcast events in the world.\n\nThere are two Elixir developers on board: Daniil who is focusing on revising some of the UI as well as charting a course into more cloud functionality, and Ghislain, who works on cameras and integration. Both LiveView and Elm are used to power device UIs and dashboards.\n\nWhat’s interesting is that, overall, the other embedded developers say that they don’t know much about Elixir and they don’t use it in their day-to-day work. Nonetheless, they are very comfortable implementing protocols and encodings in Elixir. The main reason they haven’t fully learned the language is simply time — they have plenty of other work to focus on, and deep Elixir expertise hasn’t been necessary. After all, there’s much more to their work beyond Elixir: designing PCBs, selecting electronic components, reverse engineering protocols, interfacing with displays, implementing FPGAs, managing production tests, real productions and releasing firmware updates.\n\nInnovation and customer focus\n\nWhether it’s providing onboard cameras in 40+ cars during the 24 hours of Le Mans, covering Ninja Warrior, the Australian Open, and the US Open, operating a studio in the Louvre, being installed in NFL pylons, or connecting over 200 cameras simultaneously – the product speaks for itself. Cyanview built a device for a world that runs on top of IP, using Elixir, a language with networking and protocols deep in its bones. This choice enabled them to do both: implement support for all the equipment and provide features no one else had.\n\nBy shifting from conventional local-area radio frequency, serial connections, and inflexible proprietary protocols to IP networking, Cyanview’s devices redefined how camera systems operate. Their feature set is unheard of in the industry: Unlimited multicam. Tally lights. Pan & Tilt control. Integration with color correctors. World-spanning remote production.\n\nThe ease and safety of shipping new functionality have allowed the company to support new features very quickly. One example is the increasing use of mirrorless cameras on gimbals to capture crowd shots. Cyanview were able to prototype gimbal control, test it with a customer and validate that it worked in a very short amount of time. This quick prototyping and validation of features is made possible by a flexible architecture that ensures that critical fundamentals don’t break.\n\nCamera companies that don’t produce broadcast shading remotes, such as Canon or RED, recommend Cyanview to their customers. Rather than competing with most broadcast hardware companies, Cyanview considers itself a partner. The power of a small team, a quality product and powerful tools can be surprising. Rather than focusing on marketing, Cyanview works very closely with its customers by supporting the success of their events and providing in-depth customer service.\n\nLooking back and forward\n\nWhen asked if he would choose Elixir again, David responded:\n\n“Yes. We’ve seen what the Erlang VM can do, and it has been very well-suited to our needs. You don’t appreciate all the things Elixir offers out of the box until you have to try to implement them yourself. It was not pure luck that we picked it, but we were still lucky. Elixir turned out to bring a lot that we did not know would be valuable to us. And we see those parts clearly now.”\n\nCyanview hopes to grow the team more, but plans to do so responsibly over time. Currently there is a lot more to do than the small team can manage.\n\nDevelopment is highly active, with complementary products already in place alongside the main RCP device, and the future holds even more in that regard. Cloud offerings are on the horizon, along with exciting hardware projects that build on the lessons learned so far. As these developments unfold, we’ll see Elixir play an increasingly critical role in some of the world’s largest live broadcasts.\n\nIn summary\n\nA high-quality product delivering the right innovation at the right time in an industry that’s been underserved in terms of good integration. Elixir provided serious leverage for developing a lot of integrations with high confidence and consistent reliability. In an era where productivity and lean, efficient teams are everything, Cyanview is a prime example of how Elixir empowers small teams to achieve an outsized impact.",
    "summary": {
      "en": "**Summary of Cyanview's Use of Elixir in Live Broadcasts**\n\nCyanview, a small Belgian company, specializes in coordinating the visual quality of live broadcasts, such as the Super Bowl, using a technique called camera shading. This process ensures that all cameras deliver consistent colors and exposures, making the broadcast experience cohesive. Their Remote Control Panel (RCP) is widely used in major events like the Olympics and NBA, primarily due to its reliability and functionality.\n\nCyanview chose Elixir for its robust networking capabilities and ability to handle multiple devices efficiently. The team, experienced in embedded development, transitioned from traditional analog systems to IP-based solutions, which improved remote control capabilities, especially during the pandemic. Elixir's features allowed for quick integration with various camera systems, essential for handling the complexities of live production.\n\nTheir system consists of devices running on a Yocto Linux platform, with most logic in Elixir and C, and uses MQTT for communication between devices. The team has grown gradually and now includes two Elixir developers who focus on user interfaces and camera integrations.\n\nCyanview's innovative approach has allowed them to redefine camera system operations, leading to features like unlimited multicam support and remote production across continents. Their focus on customer collaboration over marketing has established them as trusted partners in the industry.\n\nLooking ahead, Cyanview plans to grow responsibly and continue developing new products, with Elixir playing a crucial role in their future projects. Overall, Elixir has enabled Cyanview to make significant advancements in live broadcasting technology with a small but efficient team.",
      "ko": "벨기에의 작은 회사인 Cyanview는 슈퍼볼과 같은 라이브 방송의 시각적 품질을 조정하는 데 특화되어 있으며, 이를 위해 카메라 셰이딩이라는 기술을 사용합니다. 이 과정은 모든 카메라가 일관된 색상과 노출을 제공하도록 하여 방송 경험을 통일감 있게 만듭니다. 그들의 원격 제어 패널(RCP)은 올림픽과 NBA와 같은 주요 이벤트에서 널리 사용되며, 이는 신뢰성과 기능성 덕분입니다.\n\nCyanview는 강력한 네트워킹 기능과 여러 장치를 효율적으로 처리할 수 있는 능력 때문에 Elixir를 선택했습니다. 임베디드 개발에 경험이 있는 팀은 전통적인 아날로그 시스템에서 IP 기반 솔루션으로 전환하여 원격 제어 기능을 개선했습니다. 특히 팬데믹 동안 이러한 변화가 두드러졌습니다. Elixir의 기능 덕분에 다양한 카메라 시스템과의 빠른 통합이 가능해져 라이브 제작의 복잡성을 처리하는 데 필수적이었습니다.\n\n그들의 시스템은 Yocto Linux 플랫폼에서 작동하는 장치들로 구성되어 있으며, 대부분의 로직은 Elixir와 C로 작성되어 있습니다. 장치 간의 통신에는 MQTT를 사용합니다. 팀은 점진적으로 성장하여 현재는 사용자 인터페이스와 카메라 통합에 집중하는 두 명의 Elixir 개발자가 포함되어 있습니다.\n\nCyanview의 혁신적인 접근 방식은 카메라 시스템 운영 방식을 재정의하게 되었고, 무제한 멀티카메라 지원 및 대륙 간 원격 제작과 같은 기능을 가능하게 했습니다. 그들은 마케팅보다 고객 협업에 중점을 두어 업계에서 신뢰받는 파트너로 자리 잡았습니다.\n\n앞으로 Cyanview는 책임감 있게 성장하고 새로운 제품 개발을 지속할 계획이며, Elixir는 그들의 미래 프로젝트에서 중요한 역할을 할 것입니다. 전반적으로 Elixir는 Cyanview가 소규모이지만 효율적인 팀으로 라이브 방송 기술에서 중요한 발전을 이룰 수 있도록 도와주었습니다.",
      "ja": "ベルギーの小さな企業、Cyanviewは、スーパーボウルなどのライブ放送において、カメラシェーディングという技術を用いて視覚的な品質を調整することを専門としています。このプロセスにより、すべてのカメラが一貫した色合いや露出を提供し、放送体験が統一されます。彼らのリモートコントロールパネル（RCP）は、オリンピックやNBAなどの大規模イベントで広く使用されており、その信頼性と機能性が評価されています。\n\nCyanviewは、強力なネットワーキング機能と複数のデバイスを効率的に扱う能力を持つElixirを選びました。チームは組み込み開発の経験が豊富で、従来のアナログシステムからIPベースのソリューションに移行しました。これにより、特にパンデミック中にリモートコントロール機能が向上しました。Elixirの機能は、さまざまなカメラシステムとの迅速な統合を可能にし、ライブ制作の複雑さに対応するために不可欠でした。\n\n彼らのシステムは、Yocto Linuxプラットフォーム上で動作するデバイスで構成されており、ほとんどのロジックはElixirとCで実装されています。デバイス間の通信にはMQTTが使用されています。チームは徐々に成長し、現在はユーザーインターフェースやカメラ統合に特化した2人のElixir開発者がいます。\n\nCyanviewの革新的なアプローチにより、カメラシステムの運用が再定義され、無限のマルチカメラサポートや大陸を越えたリモート制作といった機能が実現しました。彼らはマーケティングよりも顧客との協力を重視し、業界内で信頼されるパートナーとしての地位を確立しています。\n\n今後、Cyanviewは責任を持って成長し、新製品の開発を続ける計画であり、Elixirは彼らの将来のプロジェクトにおいて重要な役割を果たすでしょう。全体として、ElixirはCyanviewが小規模ながら効率的なチームでライブ放送技術において大きな進展を遂げることを可能にしました。"
    }
  },
  {
    "id": "2cd23850efe44556",
    "title": {
      "en": "Stoop Coffee: A simple idea transformed my neighborhood",
      "ko": "스투프 커피: 동네를 바꾼 아이디어",
      "ja": "ストゥープコーヒーの奇跡"
    },
    "type": "story",
    "url": "https://supernuclear.substack.com/p/stoop-coffee-how-a-simple-idea-transformed",
    "score": 1384,
    "by": "surprisetalk",
    "time": 1742923005,
    "content": "Share this postSupernuclearStoop Coffee: How a Simple Idea Transformed My NeighborhoodCopy linkFacebookEmailNotesMoreDiscover more from SupernuclearHow to live near (and with) friendsOver 8,000 subscribersSubscribeBy subscribing,  I agree to Substack's Terms of Use, and acknowledge its Information Collection Notice and Privacy Policy.Already have an account? Sign inStoop Coffee: How a Simple Idea Transformed My NeighborhoodPatty SmithMar 26, 2025281Share this postSupernuclearStoop Coffee: How a Simple Idea Transformed My NeighborhoodCopy linkFacebookEmailNotesMore4638ShareEditor’s note: This is a guest post from Patty Smith. Patty and her husband enjoy the kind of neighborhood so many of us would like - connected, helpful, fun - but it wasn’t that way two years ago. A simple tradition changed their neighborhood and is a good reminder of how small, consistent actions can have outsize results. It also shows you don’t have to share a kitchen or a roof to live in community. 18 months ago, I wasn’t planning on spending more time hanging out with my neighbors than with friends I’d known for decades. It started with a simple goal: my husband Tyler and I wanted that sense of community that feels like it’s only possible in the suburbs, but we believed we could achieve this while living in San Francisco. We brainstormed: should we make cookies and knock on doors? Should we invite neighbors over for dinner? Ultimately, we landed on sipping coffee on our “stoop”.Tyler (left) and Patty (me! right) on one of our first stoop coffeesHanging out on a stoop is not a novel concept. Unfortunately, an increasing trend of isolation has resulted in fewer and fewer neighbors gathering to connect with one another. Stooping has provided benefits to so many communities. Why not bring this concept to my own neighborhood?Tyler and I were already having leisurely weekend morning coffees in our house, so it was an easy pivot to sit outside with our coffees and enjoy the sunshine. And thus our tradition began. Every weekend, we would bring our folding chairs out onto the street – we had to make do since our house doesn’t have a stoop – and enjoy our caffeine. As we saw people entering or exiting their homes, we'd enthusiastically wave them down, introduce ourselves, and write down their names in our shared spreadsheet. I wore a goofy tie-dyed Six Flags hat so people would remember us as “those people” and we started calling this our brand awareness campaign (but of course, we live in SF).The First ConvertWe met Luke a month or two after we’d been “stooping” on a regular basis. He came by to introduce himself and asked to exchange numbers so we could let him know if we’d be out there in the future, he’d love to join. At the time we didn’t realize how important this moment was for us. We’d been meeting many neighbors in passing but Luke was the first person to offer to sit with us and he wanted to know how to coordinate. In retrospect we should have been trying to get peoples’ numbers all along but hey, we were new to this!The WhatsApp CommunityAs soon as Luke started coming to stoop we actually started to resemble a group. It was validating to see a few neighbors getting together and this quickly attracted more! We learned to bring extra folding chairs for people who wanted to drop in for “just a minute” (or ninety) and Luke started bringing homebrew coffee to share. After a while, we realized it was starting to become unwieldy texting everyone when we were going to be outside. Thus, the WhatsApp group was born. At first this was just a place to announce when we’d be out having stoop coffee, but we soon realized people wanted to connect over more things than just coffee. So we ended up converting the group into a WhatsApp Community where we could have chats dedicated to certain topics or groups and plan other types of events together. Things were starting to get fun!A typical weekend stoop hangSupernuclear is a reader-supported publication. To receive new posts and support the work, consider becoming a free or paid subscriber.SubscribeLarger EventsThe first larger event that our “stoopers” wanted to host together was a block party that soon got scoped down to a pancake party. We made a spreadsheet, assigned tasks, and acquired obscene amounts of pancake mix. We decided to host the party on the sidewalk in front of our neighbor’s garage to keep things easy and so we didn’t have to apply for permits. Gathering tables, chairs and an electric griddle was quick work with so many neighbors invested in making the party a success. The most important thing we did in preparation for this party was to print out 100 door drops to deliver to the nearest set of neighbors and post party fliers up on telephone poles. It was old school but it worked! Most of the new faces we saw were people who found out about the event through our paper invitations.The Pancake Party in full swingThe event was a resounding success. 70+ people came by, and we added over 50 new numbers to our WhatsApp Community. From that point forward, each stoop coffee started seeing at least 10-15 faces and new people were volunteering to host. A few neighbor gatherings later – including an epic “Dipsgiving” sidewalk potluck where everyone brought a dip to share – the momentum has continued and we now have multiple events every week. During the span of a recent week in December, we had a neighborhood trash pickup, a cookie swap, a TV show watch party, a parent hang at a neighborhood brewery, and—of course—a stoop coffee.Where We Are TodayAs I write this post, I realize that the “we” from earlier in the post has grown from just Tyler and me to a “we” that represents many more people who are invested in our community. It feels like our neighborhood is thriving. The in-person gatherings continue even without much intervention from the original few who got the ball rolling. The daily chatter on our WhatsApp is so gosh darn wholesome. Someone even sold a car in our ‘classifieds’ chat! Tyler and I have made many new friends in the neighborhood, and our neighbors who never knew each other before are becoming friends with each other. Our neighborhood community is now a group of people that we rely on and who rely on us for emotional support, last-minute childcare, home-cooked meals, general comradery, and much more. The best part is that I can tell we are still early in our growth, there are still many people to meet, and I feel a palpable sense of awe when I learn about a new skill or talent that exists right next door.What We’ve LearnedKeeping it simple: we’ve realized that some of our best events require the smallest amount of effort. To avoid burnout, we’ve intentionally kept our community building as low-lift as possible, which has the added benefit of creating space for other people to step up.Broadening vs. deepening: we bucket our events into “broadening” events which have the purpose of meeting new neighbors and “deepening” events which allow us to get to know our existing neighbors better. Being aware of that classification has helped us be strategic depending on what feels needed for the time and season.Seasonal events: Naturally, the colder months have become a better time for deepening events that often occur in someone’s home (e.g. TV show watch parties, cookie swaps, potlucks), while warmer events are better for getting together outside and broadening our community (e.g. sidewalk chalk murals, pancake parties, bonus evening stoop beers).The street as a third space: most of our stoop coffees are held in the street in front of someone’s driveway. This has the benefit of being visible and inviting to other neighbors, while making use of a previously underutilized space. It’s also got us thinking of other unused spaces that we can turn into community-gathering spots, such as turning a nearby parking spot into a parklet or a transit stop into a community gathering space.Relying on the community: It can often feel overwhelming to take on planning a big event. We started using the phrase “the universe provides” because the real magic is found in asking and giving freely within the community. It’s a daily treat to see neighbors stepping up for one another in unexpected ways now that more of us are connected!What’s NextOur biggest goal in the coming year is to help more people organize in-person events and build towards a future where the community is sustainable even if we ever (god forbid!) move away. We’ve also been looking to connect with local businesses and influence policy matters that impact our local footprint. A few of us met recently to ideate on how we can keep vibrant commerce happening at our local businesses and how to best connect with the city decision-makers responsible for issues that impact our neighborhood community. To inform where we spend our energy, we’ve been starting with the issues that folks in the community care about and want to change (yes, we asked people at a recent block party!). We are also trying to find quick wins in collaborating with the city government to show that our voices can be heard and have a positive impact.I cherish the neighbors I’ve met and am so grateful for the many people who put time and effort into building our community (Luke and Tyler, in particular, deserve a special shoutout). As we continue to grow, I’m excited to keep learning from others – please reach out if you want to brainstorm about neighborhood community building!Thanks Patty for sharing your story! For more inspiration on how to do things like this in your neighborhood, please also see Savannah’s post on Building Neighborhood Communities.Thanks for reading Supernuclear! This post is public so feel free to share it.ShareCurious about coliving? Find more case studies, how tos, and reflections at Supernuclear: a guide to coliving. Sign up to be notified as future articles are published here:SubscribeAnd If you are interested in sharing a stoop with friends or family, check out Live Near Friends, which was started by Phil.281 Likes∙38 Restacks281Share this postSupernuclearStoop Coffee: How a Simple Idea Transformed My NeighborhoodCopy linkFacebookEmailNotesMore4638ShareA guest post byPatty SmithI love drinking coffee on my stoop and meeting my neighbors. After 12 years living in San Francisco, I've fallen in love with the city and am excited to help others find that same love for the places where they live.Subscribe to Patty",
    "summary": {
      "en": "**Summary:**\n\nPatty Smith shares how she and her husband, Tyler, transformed their San Francisco neighborhood through a simple tradition called \"stoop coffee.\" Initially seeking community connections similar to those in suburbs, they started sitting outside with coffee on weekends, inviting neighbors to join them. This led to a growing group of participants and the creation of a WhatsApp community for better coordination and connection.\n\nTheir first major event was a pancake party, which attracted over 70 people, significantly expanding their community. They learned to keep events simple and categorized them into \"broadening\" (to meet new neighbors) and \"deepening\" (to connect with existing neighbors). They utilized public spaces for gatherings and encouraged neighbors to support each other.\n\nAs their community thrived, they aimed to sustain it even if they moved away and began collaborating with local businesses and city officials to address community issues. Patty expressed gratitude for the relationships formed and the positive impact of their efforts, inviting others to engage in similar community-building.",
      "ko": "패티 스미스는 그녀와 남편 타일러가 샌프란시스코 이웃을 어떻게 변화시켰는지에 대해 이야기합니다. 그들은 \"스툽 커피\"라는 간단한 전통을 통해 이웃과의 연결을 추구했습니다. 처음에는 교외처럼 이웃과의 관계를 원했지만, 주말마다 커피를 마시며 밖에 앉아 이웃들을 초대하기 시작했습니다. 이로 인해 점점 더 많은 사람들이 모이게 되었고, 더 나은 소통을 위해 WhatsApp 커뮤니티를 만들었습니다.\n\n그들의 첫 번째 주요 이벤트는 팬케이크 파티로, 70명 이상의 사람들이 참석하여 커뮤니티가 크게 확장되었습니다. 그들은 이벤트를 간단하게 유지하는 법을 배우고, 이를 \"확장\" (새로운 이웃 만나기)과 \"심화\" (기존 이웃과의 연결)로 나누어 진행했습니다. 공공 공간을 활용하여 모임을 가졌고, 이웃들이 서로를 지원하도록 장려했습니다.\n\n커뮤니티가 성장함에 따라, 그들은 이사를 가더라도 지속할 수 있는 방법을 모색하기 시작했습니다. 지역 비즈니스와 시 관계자들과 협력하여 커뮤니티 문제를 해결하기 위해 노력했습니다. 패티는 형성된 관계와 그들의 노력의 긍정적인 영향에 감사하며, 다른 사람들도 비슷한 커뮤니티 구축에 참여하길 초대했습니다.",
      "ja": "パティ・スミスは、彼女と夫のタイラーがサンフランシスコの近所を「ストープコーヒー」というシンプルな伝統を通じてどのように変えたかを語っています。彼らは郊外のようなコミュニティのつながりを求めて、週末にコーヒーを持って外に座り、近所の人々を招待することから始めました。これがきっかけで参加者が増え、より良い連携のためにWhatsAppのコミュニティを作ることになりました。\n\n最初の大きなイベントはパンケーキパーティーで、70人以上が集まり、コミュニティが大きく広がりました。彼らはイベントをシンプルに保つことを学び、新しい近所の人と出会う「広げる」イベントと、既存の近所の人とつながる「深める」イベントに分類しました。公共の場を利用して集まりを開き、近所の人々が互いに支え合うことを促しました。\n\nコミュニティが成長する中で、彼らは引っ越してもそのつながりを維持しようと考え、地域のビジネスや市の関係者と協力して地域の問題に取り組むようになりました。パティは、形成された関係や彼らの努力がもたらしたポジティブな影響に感謝の意を表し、他の人々にも同様のコミュニティづくりに参加するよう呼びかけています。"
    }
  },
  {
    "id": "a6f381390dda99f1",
    "title": {
      "en": "Heap-overflowing Llama.cpp to RCE",
      "ko": "라마의 재앙: RCE로!",
      "ja": "ラマの脆弱性"
    },
    "type": "story",
    "url": "https://retr0.blog/blog/llama-rpc-rce",
    "score": 85,
    "by": "retr0reg",
    "time": 1742724122,
    "content": "Llama's Paradox - Delving deep into Llama.cpp and exploiting Llama.cpp's Heap Maze, from Heap-Overflow to Remote-Code Execution.By Patrick PengFebruary 6, 2025\n\nIf you are an exploitation enthusiast, this write-up will be a perfect source of entertainment. I spent ~30h on exploiting the heap-overflow to remote-code execution. At the same time, I had already spent around 2 weeks prior researching/understanding Llama.cpp source regarding its very own RPC & Memory implementations. Since Llama.cpp has such a special heap-management system, special features of this system will fail the classic ptmalloc exploitations that we are familiar with. Thus, even though this is a heap-overflow, the exploitation won't be the classic ptmalloc heap-exploitations, rather interesting vectors exploiting Llama.cpp's implementations logic. Enjoy reading:)\n\nLlama.cpp is always something I would love to work on, a sort of 'ultimate' goal for my AI/ML research; not only that but finding a stack/heap-overflow RCE in this sophisticated and well-developed ML Project always sounds so cool. (Besides, I am so hungry for a binary-exp in AI Projects to prove my binary-exploitation things are not 'outdated', but that's another thing ) Thus, I decided to research on Llama.cpp's RPC components, when I saw these security adversaries posted on its GitHub 'Security' tab - I was like: Wow, these are just simple write-what-wheres and read-what-wheres; this must be a 'money' project to work on with a little bit of efforts required.\nThen Llama.cpp proved me very wrong. I found nothing in the first two weeks, as they implemented tons of security checks on RPC Tensor deserializations, fully allocated memory 'buffer' tracing, and implementations of the RPC endpoints. These write-what-wheres were patched strictly so that when you try to exploit again, you might trigger two assert errors on the way, integer overflow was checked everywhere, you can't mess with the pointers anymore in anyways. It is very secure and not exploitable - devastating it's, I do gain a better understanding of the implementation itself and cpp (I never systematically learn cpp) - Llama.cpp have its very own memory-management system, memory security patches and mitigations, you will see what I am talking about in most parts of this write-up, we will be dealing with different paradox, mitigation, entirely new methodology and exploitation vectors that I never though up before this such unique exploitation. Finally, everything is just chained together, and you will see what a unique exploitation script and process is, as well as the satisfaction of bypassing everything and not giving up on the process.\nFor this 10k-word write-up, I spent around a month finishing up the main parts, and refining/editing it took an extra while. Writing this is indeed a painful process. I spent the entire day on the weekend and 4-5 hours during the rest of the week working on it for around two weeks. But on the other hand, it is a joyful process of exploring memory things step-by-step. Who doesn't like it? Enjoy reading!\nBefore the Storm\nThe story begins at Llama.cpp's RPC functions, for the past few months, Llama.cpp's RPC Server had been a focus of exploitation. rpc-server in llama.cpp enables the execution of the GGML backend on a remote host, allowing for distributed large language model (LLM) inference. By offloading computations to one or more rpc-server instances, users can leverage the processing power of multiple machines or specialized hardware, such as GPUs, to enhance performance.\nAt the very beginning of the development stage of the RPC server, low-level memory security vulnerabilities were reported (GHSA-wcr5-566p-9cwj, GHSA-5vm9-p64x-gqw9j, GHSA-mqp6-7pv6-fqj), mostly exploited on Llama.cpp's tensor memory-related operations. These early-stage vulnerabilities are straightforward exploits that depend less on GGML's RPC memory management logic and more on input considerations. However, we should understand a bit about its memory management process;\nLlama.cpp implements its own mechanism for memory management, based on glibc basic malloc and the classic ptmalloc management methods; meanwhile, added features to the manage-process to optimize Tensor related processing operations.\nTo begin with, all memory-related operations require a RPC allocated memory via the alloc_buffer command. The RPC endpoint for it requires only a parameter of size. However, this is a bit more complex than simply returning the malloc-ed pointer address. Instead, the address of a buffer structure, allocated additionally, with the actual malloc-ed region wrapped as buffer->data with be returned; At the meantime, Llama.cpp's RPC parse request in the format of Tensor, not only as a form of payload for these\nPrerequisites: Tensor, buffer structure\n    // ggml/src/ggml-backend-impl.h:60\n    struct ggml_backend_buffer {\n        struct ggml_backend_buffer_i  iface;\n        ggml_backend_buffer_type_t    buft;\n        void * context;\n        size_t size;\n        enum ggml_backend_buffer_usage usage;\n    };\n\nThe buffer structure consists of the buffer methods/pointers structure ggml_backend_buffer_i iface, backend management thread ggml_backend_buffer_type_t buft; the actual address of allocated memory context, the size_t size; of the allocated memory, lastly the ggml_backend_buffer_usage usage; The interesting part here is the iface structure, a part that we will embrace a lot, and take a much deeper analysis during the exploitation steps.\n    struct ggml_backend_buffer_i {\n        void         (*free_buffer)  (ggml_backend_buffer_t buffer);\n        void *       (*get_base)     (ggml_backend_buffer_t buffer);\n        void         (*init_tensor)  (ggml_backend_buffer_t buffer, struct ggml_tensor * tensor);\n        void         (*memset_tensor)(ggml_backend_buffer_t buffer,       struct ggml_tensor * tensor,     uint8_t value, size_t offset, size_t size);\n        void         (*set_tensor)   (ggml_backend_buffer_t buffer,       struct ggml_tensor * tensor, const void * data, size_t offset, size_t size);\n        void         (*get_tensor)   (ggml_backend_buffer_t buffer, const struct ggml_tensor * tensor,       void * data, size_t offset, size_t size);\n        bool         (*cpy_tensor)   (ggml_backend_buffer_t buffer, const struct ggml_tensor * src, struct ggml_tensor * dst);\n        void         (*clear)        (ggml_backend_buffer_t buffer, uint8_t value);\n        void         (*reset)        (ggml_backend_buffer_t buffer);\n    };\n\nLlama.cpp's multi-architectural made it necessary to assign different methods according to the targeted server architecture; for instance machines with only CPU support's iface.get_tensor will be set to ggml_backend_cpu_buffer_get_tensor, while CUDA supported server will enable ggml_backend_cuda_buffer_get_tensor. These methods, different in architecture have identical implementation, however, with different compatibility variations (For instance, CUDA machine uses cudaMemcpyAsync, on the other hand CPU versions use the native memcpy from the C-Standard-Library).\nstruct ggml_tensor {\n        enum ggml_type type;\n        GGML_DEPRECATED(enum ggml_backend_type backend, \"use the buffer type to find the storage location of the tensor\");\n        struct ggml_backend_buffer * buffer;\n        int64_t ne[GGML_MAX_DIMS]; // number of elements\n        size_t  nb[GGML_MAX_DIMS]; // stride in bytes:\n        // compute data\n        enum ggml_op op;\n        // op params - allocated as int32_t for alignment\n        int32_t op_params[GGML_MAX_OP_PARAMS / sizeof(int32_t)];\n        int32_t flags;\n        struct ggml_tensor * src[GGML_MAX_SRC];\n        // source tensor and offset for views\n        struct ggml_tensor * view_src;\n        size_t               view_offs;\n        void * data;\n        char name[GGML_MAX_NAME];\n        void * extra; // extra things e.g., for ggml-cuda.cu\n        char padding[8];\n    };\n\nTensor is used everywhere in llama.cpp. Here yet we won't delve in to the technical details of int64_t ne[GGML_MAX_DIMS]; / size_t nb[GGML_MAX_DIMS]; and how it stores tensors's shapes and strides. Additionally to tensor data transportations, the Tensor structure in llama.cpp provides a serialization standard for the RPC communications, combined with previous introductions to the buffer structure, lets take a looking in an instance how the memory-allocation-endpoints communicates, using buffer and Tensor.\nPast Patches, Mitigation\nThe three reported adversaries we mentioned previously (GHSA-wcr5-566p-9cwj, GHSA-5vm9-p64x-gqw9j, GHSA-mqp6-7pv6-fqj) are actually exploitations that are exploiting a fundamental, essence of flaw of design - the lack of boundary checks on the buffer / buffer->data pointer. The existence of this flaw in applied different features of RPC server - whether the get_tensoror the set_tensor allowed attackers to achieve read-what-wheres or write-what-where.\nstatic void ggml_backend_cpu_buffer_set_tensor(ggml_backend_buffer_t buffer, struct ggml_tensor * tensor, const void * data, size_t offset, size_t size) {\n    memcpy((char *)tensor->data + offset, data, size);\n    // write-what-wheres, past version of Llama.cpp's RPC had no sanitization on buffer->data validty, sadly you can just write-what-where\n    GGML_UNUSED(buffer);\n}\n\nHowever, these memory problems were solved by implementing tons of glibc level memory-checks of the buffer structure - there's time that a pointer or Tensor size will be check twice, or even more; These mitigations are implemented before deserialization of a tensor (deserialize_tensor()), RPC method call-wrappers (e.g rpc_server::set_tensor), call-wrappers's internal implementations (e.g. ggml_backend_tensor_set), and even in the buffer->iface implementations (e.g ggml_backend_cpu_buffer_cpy_tensor), these four stage of checks made you aware of the pointer validation according to every-steps of the RPC processing (Fun fact, at the very beginning of the research I spent around 3-5 hours just to figurer out how the tensor checks works so I c",
    "summary": {
      "en": "**Summary of Llama's Paradox**\n\nIn this write-up, Patrick Peng explores the exploitation of Llama.cpp, an advanced machine learning project, focusing on its heap management system and how it differs from traditional exploitation methods. The author invested about 30 hours into exploiting a heap overflow, building on two weeks of research into Llama.cpp's RPC (Remote Procedure Call) and memory management implementations.\n\nLlama.cpp has a unique security framework that makes classic heap exploitation techniques ineffective. The author initially found it challenging to identify vulnerabilities due to extensive security checks in the RPC server, which manages memory for tensor operations. Despite the initial difficulties, the author gained valuable insights into C++ and Llama.cpp's memory management.\n\nThe write-up details the RPC server's function, which enables distributed processing for large language model inference and highlights past security vulnerabilities that were successfully patched through rigorous memory checks. The author’s journey emphasizes the complexity of exploitation in modern software and showcases the satisfaction of overcoming such challenges. \n\nOverall, this 10,000-word document serves as both a technical exploration and a personal narrative of the author's experience with Llama.cpp, encouraging readers to appreciate the intricate nature of memory exploitation.",
      "ko": "패트릭 펭은 Llama.cpp라는 고급 머신러닝 프로젝트의 힙 관리 시스템을 중심으로 이 프로젝트의 취약점을 탐구했습니다. 그는 전통적인 취약점 이용 방법과의 차이점에 주목하며, 힙 오버플로우를 이용하는 데 약 30시간을 투자했습니다. 이 과정은 Llama.cpp의 원격 프로시저 호출(RPC)과 메모리 관리 구현에 대한 2주간의 연구를 바탕으로 진행되었습니다.\n\nLlama.cpp는 독특한 보안 프레임워크를 가지고 있어 전통적인 힙 취약점 이용 기법이 효과적이지 않습니다. 저자는 처음에 텐서 작업을 위한 메모리를 관리하는 RPC 서버의 광범위한 보안 검사로 인해 취약점을 찾는 데 어려움을 겪었습니다. 그러나 초기의 어려움에도 불구하고, 그는 C++와 Llama.cpp의 메모리 관리에 대한 귀중한 통찰을 얻었습니다.\n\n이 글에서는 RPC 서버의 기능을 자세히 설명하며, 대규모 언어 모델 추론을 위한 분산 처리를 가능하게 하는 방법을 강조합니다. 또한, 과거에 발견된 보안 취약점들이 철저한 메모리 검사를 통해 성공적으로 패치된 사례도 언급됩니다. 저자의 여정은 현대 소프트웨어에서의 취약점 이용의 복잡성을 강조하며, 이러한 도전을 극복하는 데서 오는 만족감을 보여줍니다.\n\n이 10,000단어 분량의 문서는 기술적인 탐구이자 저자의 Llama.cpp 경험에 대한 개인적인 서사로, 독자들이 메모리 취약점 이용의 복잡한 본질을 이해하도록 격려합니다.",
      "ja": "パトリック・ペンは、先進的な機械学習プロジェクトであるLlama.cppの利用について考察しています。特に、ヒープ管理システムに焦点を当て、従来の攻撃手法との違いを探ります。著者は、ヒープオーバーフローを利用するために約30時間を費やし、Llama.cppのRPC（リモートプロシージャコール）とメモリ管理の実装について2週間の研究を重ねました。\n\nLlama.cppは独自のセキュリティフレームワークを持っており、従来のヒープ攻撃手法が通用しません。著者は、テンソル操作のためのメモリを管理するRPCサーバーにおける厳格なセキュリティチェックのため、脆弱性を特定するのが難しいと感じました。しかし、最初の困難を乗り越え、C++やLlama.cppのメモリ管理について貴重な知見を得ることができました。\n\nこの文書では、RPCサーバーの機能が詳述されており、大規模な言語モデルの推論のための分散処理を可能にしています。また、過去に発見されたセキュリティの脆弱性が厳格なメモリチェックによって修正されたことも強調されています。著者の経験は、現代のソフトウェアにおける攻撃の複雑さを示し、こうした課題を克服することの満足感を伝えています。\n\n全体として、この1万語の文書は、技術的な探求と著者のLlama.cppに関する個人的な体験を兼ね備えた内容であり、読者にメモリ攻撃の複雑さを理解してもらうことを促しています。"
    }
  },
  {
    "id": "231895d570006adc",
    "title": {
      "en": "Pi Pico Rx – A crystal radio for the digital age?",
      "ko": "디지털 시대의 크리스탈 라디오?",
      "ja": "デジタル時代のクリスタルラジオ"
    },
    "type": "story",
    "url": "https://101-things.readthedocs.io/en/latest/radio_receiver.html",
    "score": 46,
    "by": "nolist_policy",
    "time": 1742732290,
    "content": "Pi Pico Rx - A crystal radio for the digital age?¶\nMy first step into the world of electronics was with a crystal radio, just like this one.\n\nBack then, I don’t think it has ever occurred to me that I could make a radio\nmyself, so I wasn’t expecting it to work. But when I put the earphone in, I was\namazed to hear very faint sounds coming through. I couldn’t believe that\nbuilding a radio could be so simple, and the best part was, it didn’t need any\nbatteries! That little experience sparked my interest in electronics.\nTimes have certainly changed since then, and today, we find ourselves in a\ngolden age for electronics enthusiasts. Back in the ninteen eightees, I could\nhave never imagined that my pocket money would one day buy a device with\ncomputing power that could have filled an entire room just a few decades ago.\nI often wonder how we can still capture that sense of awe and excitement from\nmy first crystal radio experience. Is it still possible to create something\nsimple yet captivating?\nThe Pi Pico Rx - may be the answer to that question. While it may not be quite\nas straightforward as the crystal radio, the Pi Pico Rx presents a remarkably\nsimple solution. Armed with just a\nRaspberry Pi Pico,\nan analogue switch, and an op-amp, we now have the power to construct a capable\nSDR receiver covering the LW, MW, and SW bands. With the ability to receive\nsignals from halfway around the globe. I can’t help but think that my younger\nself would have been truly impressed!\nIf you are interested in a simpler version that can be built on a breadboard using mostly through-hole components, checkout the breadboard version\nhere.\n\nFeatures¶\n\n0 - 30MHz coverage\n250kHz bandwidth SDR reciever\nCW/SSB/AM/FM reception\nOLED display\nsimple spectrum scope\nHeadphones/Speaker\n500 general purpose memories\nruns on 3 AAA batteries\nless than 50mA current consumption\n\nPi Pico Rx¶\n\nPi Pico Rx is a minimal SDR receiver based around the Raspberry Pi Pico.\nThe design uses a “Tayloe” Quadrature Sampling Detector (QSD) popularised by\nDan Tayloe.\nAnd used in many HF SDR radio designs. This simple, design allows a\nhigh-quality mixer to be implemented using an inexpensive analogue\nswitch.\n\nA quadrature oscillator is generated using the PIO feature of the\nRP2040. This eliminates the need to use an external programmable\noscillator. Without overclocking the device this supports frequencies up\nto about 30MHz, conveniently covering the LW, MW and SW bands.\nThe IQ output from the QSD is amplified using a high-speed, low-noise\nop-amp. The I and Q channels are sampled by the built-in ADC which\nprovides 250kHz of bandwidth. The dual-core ARM Cortex M0 processor\nimplements the Digital Signal Processing algorithms, demodulating AM,\nFM, SSB and CW to produce an audio output.\nAudio output is provided using a PWM followed by a low-pass filter. At\nfirst, I used an LM386 audio amplifier, but later found that with a\nsuitable current limiting resistor the IO pin could easily drive a pair\nof headphones or even a small speaker directly.\nA cobbled-together prototype proves that it is possible to build an HF\nSDR receiver using a Pi Pico, an analogue switch, an op-amp and a\nhandful of discrete components.\n\nOther SDR Receivers¶\nThis isn’t a new idea by any means, there are loads of SDR designs out\nthere. Some use a PC soundcard, others use a built-in CPU for the SDR.\nThe uSDX project even does the DSP processing using an 8-bit micro! I\nhave put a list of links to some of the other projects that have\ninspired me. Each of these projects introduces new ideas and\ninnovations. I hope that the Pi Pico Rx has introduced some of its own\nevolutionary developments that might inspire others with their designs.\n\nsoftrock SDR\nQRP Labs\nmcHF\nelecraft KX3\nusdx\n(tr)uSDX\nuSDR-pico\ncompact-si5351-based-sdr\nqex\nTeensy-Convolutional SDR\n\nContinuing in the spirit of knowledge sharing, I have attempted to\ndescribe the finer details of the hardware and software in this wiki,\nstarting here with an overview of the new features introduced by the Pi\nPico Rx that I haven’t seen before in other designs.\n\nSampling IQ data using a round-robin ADC¶\nOne of the challenges I faced was sampling IQ signals using an ADC that\nis only capable of sampling one channel at a time. It can be configured\nin a round-robin mode that samples I and Q alternately. I had worried\nthat this might create a phase imbalance between the I and Q channels. I\nneedn’t have worried, it turns out that there is a simple way to recover\na complex signal with 250kHz bandwidth by sampling I and Q alternately\nat 500kSample/s.\nThe trick is to low pass filter the I and Q data leaving 250kHz of\nbandwidth from -125kHz to 125kHz. The QSD detector itself forms a\nlow-pass filter, so this can easily be achieved by selecting suitable\ncapacitor values in the op-amp. The ADC is configured to sample I and Q\nalternately (starting with I). In the software, the “missing” values can\nbe replaced by zeros.\n\nThis results in a complex signal with a sampling rate of 500KS/s. The\ncentral half of the spectrum from -125kHz to 125kHz contains the\nspectrum we want. The outer half of the spectrum from -250kHz to -125kHz\nand 125kHz to 250kHz contains reflections of the central half. To\nrecover the original spectrum, we simply need to low-pass filter the\nsignal so that we retain the central section. We could then reduce the\nsample rate to 250kHz. In our application, we filter out only a very\nsmall section of the spectrum containing the signal of interest, we\ndon’t need to take any additional steps to remove the reflections.\n\nWhy does this work?¶\nTo understand why this works, it helps to think about how we could have\nconverted the signal into a real (rather than complex IQ) signal and\nsampled it using a single-channel ADC. This is one of the approaches I\nhad originally considered taking. I only realised that there was an\neasier way once I worked the problem through. This was my thought\nprocess.\n\nTo satisfy Nyquist, we need to filter the complex data so that all our\nsignals sit between -125kHz and 125kHz. We could then shift the data up\nby 125kHz so that our signals are between 0 and 250kHz. The frequency\nshift is 1/4 of the 500KSample/second sample rate. A frequency shift by\nFs/4 can be implemented by rotating the signal by 1/4 turn in each\nsample. This doesn’t need any multiplication, only negation.\nSince our signal now only contains positive frequencies, the imaginary\n(Q) part of the signal doesn’t contain any useful information and we can\nthrow it away. A signal containing only real (I) values has a\nsymmetrical spectrum, discarding the imaginary samples introduces\nnegative frequency reflections of the positive frequency signals.\nThe real signal can now be sampled with a single-channel ADC at\n500kSamples/s. The frequency shift could have been implemented in\nhardware using a simple mixer, but we only need I and Q samples\nalternately, so we could use a round-robin ADC to capture the alternate\nI and Q samples and implement the mixer in software, negating I and Q\nwhen necessary.\nOnce we have the real signal in the software, we might like to convert\nthe real signal back to a complex one. We could use a Hilbert transform,\nthis would filter out the negative frequencies leaving a complex signal\nwith an asymmetrical spectrum containing only positive frequencies from\n0 to 250kHz.\nAnother approach would be to shift the frequencies down by 125kHz\nleaving the original spectrum from -125kHz to 125kHz, now with\nreflections in the outer half of the spectrum. These could be removed\nwith a low-pass filter. We can take the same approach to the Fs/4\nfrequency shift, this time rotating 1/4 turn each sample in the opposite\ndirection.\nInspecting the resulting samples, we can see that the downwards\nfrequency shift has cancelled out the negations we performed during the\nupwards frequency shift, leaving us with the alternating I/Q samples we\noriginally captured.\nConveniently, it turns out, the alternating IQ samples captured from the\nround-robin ADC were the only samples we needed to fully capture the\ncentral half of the frequency spectrum. The “missing” samples only\ncontributed to the outer part of the spectrum that we had already\nfiltered out.\n\nCreating Quadrature Oscillator Using PIO¶\nThe pi pico is based on the\nRP2040\nmicrocontroller. The PIO is a novel feature of the RP2040. Programmable\nState Machines (like small microprocessors) can be configured to offload\nIO functions from the software. It is fairly simple to configure a PIO\nstate machine to output a quadrature oscillator on 2 IO pins. Once\nconfigured the Oscillator runs autonomously without software\nintervention, not placing any further load on the CPU.\nThe PIO program is remarkably simple:\n.program nco\nset pins, 0\nset pins, 1      ; Drive pin low\nset pins, 3      ; Drive pin high\nset pins, 2      ; Drive pin low\n\nThe frequency of the NCO can be programmed using the PIO clock divider.\nThis has a 16-bit integer and an 8-bit fractional part. With an input\nclock of 125MHz, the NCO can be programmed from a few hundred Hz to just\nover 30MHz. Perfect for an LW/MW/SW receiver.\nAt low frequencies, a good resolution can be achieved, but at high\nfrequencies, the step size can be more than 100kHz. However, with a\nbandwidth of 250kHz, that is still enough to give continuous coverage of\nthe whole frequency range. To compensate for the coarse frequency\nresolution in the oscillator, a high-resolution frequency shifter is\nimplemented in the software. (The 32-bit phase accumulator has a\ntheoretical resolution of a little over 0.0001 Hz which should be\nample.)\n\nHardware Design¶\nThe design aim for the hardware is to make the design as simple and\ncheap as possible without compromising the performance too much. I have\ndesigned a PCB that expands on the basic concept to include a\npreamplifier and a bank of low-pass filters. To check out the details\nyou can look at the full Schematics in pdf format,\nbut I will walk through some of the details here.\n\nRaspberry Pi Pico¶\nThe heart of the receiver is a Raspberry Pi Pico. The onboard ADC\nsamples at 500kSamples/s giving us 250kHz of bandwidth. The 12-bit ADC\nhas a theoretical dynamic range of 72 dB, but it won’t be that good in\nreality. An SSB signal only needs 2.5kHz of bandwidth. We can exchange\nour excess bandwidth for increased dynamic range improving the overall\nsensitivity. An oversampling ratio of 100 gives us an extra 20dB,\nequivalent to adding 3 extra bits. This gives a theoretical dynamic\nrange of 92dB in SSB mode. The ADC has an input range of 0 to 3.3V. With\nno amplification, that represents a range of -78 dBm to 14 dBm.\n\nThe Raspberry Pi Pico has an onboard switched mode regulator, which\nallows the Pico to be easily powered by batteries. This design uses\n3xAAA batteries. It is possible to add additional external components to\nthe pi pico to allow the device to be powered from batteries, or the USB\npower supply. This design is primarily intended to be a portable\nstandalone radio, with the USB connection providing the ability to\nprogram the flash. To avoid the need to add additional components, I\nopted to remove D1 from the pico instead. This prevents the possibility\nof contention between the USB supply and the batteries.\n\nUser Interface¶\nThere isn’t anything particularly unusual about the user interface. A\n128x64 OLED display uses an ssd1306-based I2C interface. These are\nfairly ubiquitous these days and have replaced the HD44780 as the go-to\ncheap/simple display. The I2C interface certainly helps reduce the pin\ncount. Cost is a key driver, I could have replaced the rotary encoder\nwith a pair of push buttons to save cost, but I think this would be a\nstep too far. It wouldn’t feel like a radio without a proper tuning\nknob. Ideally, I would have liked to use something a bit more compact, a\nthumbwheel-based rotary encoder mounted on one edge would have been\nideal. Although there do seem to be some around, they seem to be quite\nhard to find.\nThis\ndirectional navigation scroll wheel also caught my eye, but in the end,\ncost won out and I went with a standard encoder.\n\nPWM audio¶\nAt first, I considered using an LM386 (or similar) audio amplifier to\ndrive the headphones or a small speaker. It turns out that the PWM is\nperfectly capable of driving headphones or a small speaker directly. A\n100uF capacitor blocks DC, the larger the capacitance the better the DC\nresponse, but in this application 100uF is probably overkill. The RP2040\nhas a maximum drive strength of 12mA. The 100-ohm resistor serves as a\ncurrent limiting resistor and one-half of an RC low-pass filter. With a\npeak voltage of 1.65v, and assuming an internal resistance of about 40\nohms, the maximum current into a 32-ohm load is\n1.65/(100+40+32) = 9.5mA and with an 8-ohm load is\n1.65/(100+40+8) = 11.1mA.\n\nIf a better speaker were needed, the\nTPA2012\nlooks like the ideal modern replacement for the LM386, and would be\nideal for battery-powered applications. The output also works well with\nPC speakers, but watch out for the drive level being significantly\nhigher than the usual 100mV pk-pk.\n\nQSD Detector (Tayloe Detector)¶\nThe design uses a “Tayloe” Quadrature Sampling Detector (QSD)\npopularised by [Dan Tayloe](The design uses a “Tayloe” Quadrature\nSampling Detector (QSD) popularised by Dan Tayloe.\nIt is used in many SDR receivers, and for good reason. In this design,\nthe select inputs to the analogue switch are driven directly by the\nRaspberry Pi Pico, the PIO feature of the RP2040 is capable of\ngenerating a quadrature oscillator at frequencies up to 30MHz without\nsoftware intervention. The resistor values have been chosen to give a\ngain of 1000 or 60 dB. This gives a theoretical input range at the input\nto the QSD of -138 dBm to -46 dBm. The capacitor values have been chosen\nto give a cut-off frequency of about 60kHz and a bandwidth of 120kHz.\nQSD is effectively acting as the anti-aliasing filter, so a degree of\noversampling helps. The gain and bandwidth requirements require a fast\nop-amp. The LT6231 is a popular choice in this type of SDR because of\nits low noise, it is fast enough to cope with the larger bandwidth used\nin this design compared to most SDRs. The newer LTC6227 op-amp is\nrecommended for new designs and is even better.\n\nOne potential weakness of this design is the potential of aliasing in\nthe ADC. This isn’t an issue for SDRs that use sound cards or audio\nADCs, they usually include very good antialiasing filters. A potential\nimprovement would be to include an active low-pass filter. This could\nmake use of a more basic (and cheaper) op-amp. There is also a potential\nto save cost by cascading several cheaper op-amps sharing the gain\nbetween them, the gain ban",
    "summary": {
      "en": "The Pi Pico Rx is a simple and innovative software-defined radio (SDR) receiver designed around the Raspberry Pi Pico. It allows users to build a capable radio that can receive long wave (LW), medium wave (MW), and short wave (SW) signals without needing batteries, as it operates on three AAA batteries. The device has a range of features, including:\n\n- Coverage from 0 to 30 MHz with a 250 kHz bandwidth.\n- Capabilities for various reception modes: CW, SSB, AM, and FM.\n- An OLED display and a simple spectrum scope.\n- 500 general-purpose memory slots.\n\nThis project aims to capture the excitement of early radio building experiences, similar to the author's first encounter with a crystal radio. The Pi Pico Rx uses an analogue switch and an op-amp to implement a high-quality mixer and a unique quadrature sampling detector (QSD), making it a cost-effective solution for SDR.\n\nKey components include:\n- A quadrature oscillator created using the Pico's programmable input/output (PIO) feature.\n- An ADC that samples at 500kHz, providing sufficient bandwidth for effective signal processing.\n- A simple user interface with an OLED display and a rotary encoder for tuning.\n\nThe design prioritizes simplicity and affordability while maintaining performance. The author shares insights into the hardware and software design, including overcoming challenges like sampling IQ signals and implementing efficient signal processing algorithms. The Pi Pico Rx, while not the first SDR design, introduces ideas that may inspire further innovations in the field.",
      "ko": "Pi Pico Rx는 Raspberry Pi Pico를 기반으로 한 간단하고 혁신적인 소프트웨어 정의 라디오(SDR) 수신기입니다. 이 장치는 사용자가 배터리 없이도 장거리(롱 웨이브), 중거리(미디엄 웨이브), 단거리(쇼트 웨이브) 신호를 수신할 수 있는 능력 있는 라디오를 만들 수 있게 해줍니다. Pi Pico Rx는 AAA 배터리 세 개로 작동합니다. 이 장치는 다음과 같은 다양한 기능을 제공합니다.\n\n0에서 30MHz까지의 주파수를 커버하며, 250kHz의 대역폭을 지원합니다. CW, SSB, AM, FM 등 다양한 수신 모드를 지원합니다. OLED 디스플레이와 간단한 스펙트럼 스코프가 포함되어 있으며, 500개의 일반 메모리 슬롯을 제공합니다.\n\n이 프로젝트는 저자가 처음으로 크리스탈 라디오를 접했을 때의 흥미를 재현하는 것을 목표로 하고 있습니다. Pi Pico Rx는 아날로그 스위치와 연산 증폭기를 사용하여 고품질 믹서와 독특한 쿼드라처 샘플링 감지기(QSD)를 구현하여 비용 효율적인 SDR 솔루션을 제공합니다.\n\n주요 구성 요소로는 Pico의 프로그래머블 입력/출력(PIO) 기능을 사용하여 생성된 쿼드라처 발진기와 500kHz로 샘플링하는 ADC가 있습니다. 이 ADC는 효과적인 신호 처리를 위한 충분한 대역폭을 제공합니다. 사용자는 OLED 디스플레이와 튜닝을 위한 로터리 인코더를 통해 간단한 사용자 인터페이스를 이용할 수 있습니다.\n\n디자인은 성능을 유지하면서도 단순성과 경제성을 우선시합니다. 저자는 IQ 신호 샘플링과 효율적인 신호 처리 알고리즘 구현과 같은 도전 과제를 극복한 하드웨어 및 소프트웨어 설계에 대한 통찰을 공유합니다. Pi Pico Rx는 최초의 SDR 디자인은 아니지만, 이 분야에서 더 많은 혁신을 이끌어낼 수 있는 아이디어를 제시합니다.",
      "ja": "Pi Pico Rxは、Raspberry Pi Picoを基にしたシンプルで革新的なソフトウェア定義ラジオ（SDR）受信機です。このデバイスは、長波（LW）、中波（MW）、短波（SW）の信号を受信できるラジオを構築することを可能にし、3本のAAA電池で動作するため、バッテリーを必要としません。さまざまな機能が搭載されており、0から30MHzの範囲を250kHzの帯域幅でカバーします。また、CW、SSB、AM、FMなどの受信モードに対応しています。OLEDディスプレイとシンプルなスペクトラムスコープも備えており、500の汎用メモリスロットがあります。\n\nこのプロジェクトは、著者が初めてクリスタルラジオに触れたときの興奮を再現することを目指しています。Pi Pico Rxは、アナログスイッチとオペアンプを使用して高品質のミキサーと独自の直交サンプリング検出器（QSD）を実装しており、コストパフォーマンスに優れたSDRソリューションとなっています。\n\n主要なコンポーネントには、Picoのプログラム可能な入出力（PIO）機能を利用して作成された直交発振器や、500kHzでサンプリングするADCが含まれています。これにより、効果的な信号処理に十分な帯域幅が提供されます。ユーザーインターフェースはシンプルで、OLEDディスプレイとチューニング用のロータリーエンコーダーが搭載されています。\n\nデザインはシンプルさと手頃な価格を重視しつつ、性能も維持しています。著者は、IQ信号のサンプリングや効率的な信号処理アルゴリズムの実装といった課題を克服した経験を共有しています。Pi Pico Rxは、初めてのSDRデザインではありませんが、この分野でのさらなる革新を促すアイデアを提供しています。"
    }
  },
  {
    "id": "82573d218fb6fbaf",
    "title": {
      "en": "4o Image Generation",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://openai.com/index/introducing-4o-image-generation/",
    "score": 923,
    "by": "meetpateltech",
    "time": 1742925962,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "2fdf30b6073aca70",
    "title": {
      "en": "Hyperlight WASM: Fast, secure, and OS-free",
      "ko": "하이퍼라이트 WASM: 빠르고 안전하게!",
      "ja": "ハイパーライトWASM"
    },
    "type": "story",
    "url": "https://opensource.microsoft.com/blog/2025/03/26/hyperlight-wasm-fast-secure-and-os-free/",
    "score": 35,
    "by": "yoshuaw",
    "time": 1742998731,
    "content": "Mar 10\n\t\t\t\t\t•\n\n\t\t\t\t\t\t7 min read\n\n\t\t\t\t\tBuild a Hyperlight C guest to securely execute JavaScript\n\n\t\t\tThis article will show you how to create a “guest” application that…",
    "summary": {
      "en": "The article explains how to create a \"guest\" application using Hyperlight C, which allows for the secure execution of JavaScript. It provides step-by-step instructions and insights into the process.",
      "ko": "이 글에서는 Hyperlight C를 사용하여 \"게스트\" 애플리케이션을 만드는 방법을 설명합니다. 이 애플리케이션은 JavaScript를 안전하게 실행할 수 있도록 도와줍니다. 글에서는 이 과정을 단계별로 안내하며, 필요한 정보와 통찰도 제공합니다.",
      "ja": "この記事では、Hyperlight Cを使用して「ゲスト」アプリケーションを作成する方法について説明しています。このアプリケーションは、JavaScriptを安全に実行することができます。手順を追って詳しい説明があり、プロセスに関する洞察も提供されています。"
    }
  },
  {
    "id": "3df89415774c71e7",
    "title": {
      "en": "All Clothing Is Handmade (2022)",
      "ko": "모든 옷은 수제!",
      "ja": "すべて手作りの服"
    },
    "type": "story",
    "url": "https://ruthtillman.com/post/all-clothing-is-handmade/",
    "score": 97,
    "by": "panic",
    "time": 1742697834,
    "content": "All Clothing Is Handmade\n\n    2022-10-29\n\n    quilts\n\n       The idea for this quilt came to me several years ago. Besides making quilts, I make some of my own clothes and occasionally make clothes for people in my life. I made my own wedding dress and one for a college friend as well (and never doing that again).\nThere’s something special nowadays about something that was made or tailored just for you, whether it was done by a friend/family member or something you had made. When I was a kid, my father gave my mother a birthday gift of what was essentially a copy of her favorite dress, made by a local seamstress. The style was pretty basic, but not being sold in stores at that time. I’m sure it was quite expensive. It was very thoughtful, she loved and wore the dress for ages, until her cancer surgeries made its fit uncomfortable.\nBut while I love the personal connections of bespoke/self-made clothing, I want to push back a bit against some language that occurs when people (myself included) talk about store-bought clothing, especially cheaper clothing. Whether it’s the nice Lands End flannel shirt I’m wearing as I write this, or the one my husband is wearing that I made for him, or the TikTok influencer’s Shein t-shirt that rips when she tries it on… all clothing is handmade.\nI made this quilt using worn textiles from friends, family, and some folks in my church and scraps from my own projects. It’s got a piece of fabric from my wedding dress and others from one of my mom’s favorite dresses. There’s a couple of my husband’s old dress shirts, bits of my father’s ties, the lining of my little sister’s worn jacket, highlights from a friend’s tunic, bits of baby dresses, another friend’s dress shirt, and more. There’s a couple little pieces of leftover fabric from that same flannel shirt my husband is wearing right now.\nI pieced it ages ago, I can’t quite even remember… 2020? It’s a wonky quilt, dozens of fabrics that were never meant to sit side-by-side. A little leather just for fun and frustration. It took forever to figure out how I wanted to quilt it (large stitches with long strokes, colors matching as best I could in the blocks themselves) and then to get to it, but I’m very glad that it’s done and I can share it now.\nWho Controls Clothing’s Quality\n21st century textile production happens on a massive scale, one that keeps ramping up and has enormous environmental costs. The quality of mass-market textiles has dropped noticeably since the 1990s, which were also a noticeable drop from the 1970s.\nWhen people talk about this change in quality, the language often carries a set of assumptions. These assumptions are often both geographically and racially coded. “This t-shirt was made in Honduras” or “This blouse was made in Cambodia” imply things about their quality and often subtly, sometimes not-so-subtly, attached to the people actually doing the work.\nBut even if one assessed ten thousand blouses made in Cambodia for their quality, any negative findings say nothing about the talents or potential of Cambodian garment workers as a whole or relate to, say, American garment workers. What they reflect instead are:\n\nThe brand’s choice of materials:\n\nWhere did the cloth come from and how was it made?\nWhat kind of thread are they using? (Thread can make a major difference in the longevity of a garment. The recent trend of lowering thread quality to save money is why the crotch of your new pants split after a month when the last pair you got of these same pants lasted a solid 5 years.)\n\nThe cutting setup:\n\nHow many layers of fabric are being cut together?\nHow much time do the workers have to operate cutting tools?\nHow likely are things to slip and slide during the cutting process?\n\nThe actual garment design. Before a garment is made, especially in a mass-production context, decisions about construction need to be made including:\n\nHow are the seams finished?\nWhat’s the stitch length?\nHow are buttons attached?\n\nThe speed at which it is being made:\n\nIs the garment worker sewing 30 seams an hour? 60? 100?\nWhat happens when there’s an error?\nWhat kind of breaks does the worker get? Really?\n\nThese decisions are all made by the company that ordered the clothing and, quite possibly, also by one or more subcontractors. While brands may plead innocence and outsourcing, the cost per item they demand from their suppliers directly influences this…and they know it.\nMass-produced clothing is low quality when someone overseeing the project decided to make it low quality. Mass-produced clothing is high quality when someone overseeing the project decided to make it high quality. What country it came from and who made it is a reflection of how the company wanted to pay and treat the people making it, not of those people’s skills or potential.\nHow does the way we speak of textile manufacturing (especially that done in East Asia) create and reinforce perceptions of East Asian women’s (primarily in our perception) capacity to do high-quality sewing? Why do we let it reflect on them instead of on the companies which made the choice? What can we change about our how we think and talk to change that stereotype?\nWhile some clothing is bespoke, all clothing is handmade.\nSources and Further Reading/Watching\nIn thinking about this, I was inspired by many of the books I’ve read but also by Janneken Smucker’s Amish Quilts. In particular, she delves into perceptions of Hmong women in Lancaster County and, later on, in refugee camps in Thailand, who sew “Amish” quilts. Is there something about an Amish woman that actually makes her a better seamstress or is that our racial perceptions? (yes)\nAlso check out the documentary Invisible Seams by Jia Li and Jodie Chan, which interviews eight Asian seamstresses and pattern-makers in the New York garment industry. I only came across this a week ago, just before finishing the quilt, but it spoke to another element of the same thing. Check out this interview with Jia and Jodie where they go into more depth about the project and what they didn’t have space to cover.",
    "summary": {
      "en": "The author reflects on the personal significance of handmade clothing and quilts, sharing their own experiences in creating garments for themselves and others. They highlight the emotional value of bespoke clothing, recalling a special dress made for their mother. However, they argue against negative assumptions about store-bought clothing, emphasizing that all clothing is ultimately handmade, even if mass-produced.\n\nThe text discusses the decline in quality of mass-market textiles and the factors influencing this, such as material choices and production practices. The author points out that the quality of clothing often reflects the decisions made by companies rather than the skills of the workers who make them. They urge a change in how we talk about textile manufacturing, particularly regarding perceptions of East Asian garment workers, advocating for a focus on corporate responsibility rather than stereotypes.\n\nIn summary, while some clothing is custom-made, all clothing is handmade in some way, and the quality of mass-produced items is largely determined by the choices of the brands that create them.",
      "ko": "저자는 수제 의류와 퀼트의 개인적인 의미를 되새기며, 자신과 타인을 위해 옷을 만드는 경험을 공유합니다. 맞춤형 의류의 감정적 가치를 강조하며, 어머니를 위해 만든 특별한 드레스를 회상합니다. 그러나 상점에서 구입한 의류에 대한 부정적인 선입견에 반대하며, 대량 생산된 옷이라도 결국 모든 의류는 손으로 만들어진 것이라고 주장합니다.\n\n이 글에서는 대량 시장에서 판매되는 섬유의 품질 저하와 이를 유발하는 여러 요인, 예를 들어 소재 선택과 생산 방식에 대해 논의합니다. 저자는 의류의 품질이 종종 이를 만드는 노동자의 기술이 아니라 기업의 결정에 의해 좌우된다고 지적합니다. 또한, 섬유 제조에 대한 대화 방식을 변화시킬 필요성을 강조하며, 특히 동아시아 의류 노동자에 대한 인식에 대해 기업의 책임에 초점을 맞추어야 한다고 주장합니다.\n\n결론적으로, 일부 의류는 맞춤 제작되지만, 모든 의류는 어떤 방식으로든 수제로 만들어지며, 대량 생산된 제품의 품질은 주로 이를 제작하는 브랜드의 선택에 의해 결정된다고 말할 수 있습니다.",
      "ja": "著者は、手作りの衣服やキルトの個人的な意義について考え、自身が他の人や自分のために衣服を作った経験を共有しています。特に、母のために作った特別なドレスを思い出し、オーダーメイドの衣服が持つ感情的な価値を強調しています。しかし、著者は既製品に対する否定的な先入観に反対し、すべての衣服は最終的には手作りであると主張しています。たとえ大量生産されていても、手作りの要素があるということです。\n\nまた、著者は大量生産される繊維製品の品質の低下について言及し、その要因として素材の選択や生産方法を挙げています。衣服の品質は、しばしば製造する企業の決定によって反映されるものであり、作業者の技術によるものではないと指摘しています。著者は、特に東アジアの衣料品労働者に関する認識について、繊維製造に関する話し方を変える必要があると訴えています。ステレオタイプではなく、企業の責任に焦点を当てるべきだと主張しています。\n\n要するに、一部の衣服はオーダーメイドですが、すべての衣服は何らかの形で手作りであり、大量生産された商品の品質は、それを作るブランドの選択によって大きく左右されるのです。"
    }
  },
  {
    "id": "2ed996f9c9deb3ef",
    "title": {
      "en": "Sell yourself, sell your work",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://www.solipsys.co.uk/new/SellYourselfSellYourWork.html?yc25hn",
    "score": 351,
    "by": "ColinWright",
    "time": 1742938516,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "fcd27f228533181e",
    "title": {
      "en": "The role of developer skills in agentic coding",
      "ko": "개발자 기술의 힘",
      "ja": "エージェントコーディングの技術"
    },
    "type": "story",
    "url": "https://martinfowler.com/articles/exploring-gen-ai.html#memo-13",
    "score": 12,
    "by": "BerislavLopac",
    "time": 1742988252,
    "content": "content\n\nVideos\n\nContent Index\n\nBoard Games\n\nPhotography",
    "summary": {
      "en": "The text lists different types of content available, which include videos, a content index, board games, and photography.",
      "ko": "이 텍스트는 다양한 종류의 콘텐츠를 나열하고 있습니다. 여기에는 비디오, 콘텐츠 색인, 보드 게임, 그리고 사진이 포함됩니다.",
      "ja": "さまざまな種類のコンテンツが用意されています。これには、動画、コンテンツのインデックス、ボードゲーム、そして写真が含まれています。"
    }
  },
  {
    "id": "f3c2c2f20bb9efe6",
    "title": {
      "en": "In Jail Without a Lawyer: How a Texas Town Fails Poor Defendants",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://www.nytimes.com/2025/03/25/us/maverick-county-texas-court-system.html",
    "score": 265,
    "by": "ceejayoz",
    "time": 1742929162,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "5f242b139bf770c2",
    "title": {
      "en": "A (Long) Peek into Reinforcement Learning",
      "ko": "강화학습의 모든 것",
      "ja": "強化学習の深層探求"
    },
    "type": "story",
    "url": "https://lilianweng.github.io/posts/2018-02-19-rl-overview/",
    "score": 109,
    "by": "Brysonbw",
    "time": 1742715629,
    "content": "A (Long) Peek into Reinforcement Learning\n\n    Date: February 19, 2018  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n\n            Table of Contents\n\n                    What is Reinforcement Learning?\n\n                    Key Concepts\n\n                    Model: Transition and Reward\n\n                    Policy\n\n                    Value Function\n\n                    Optimal Value and Policy\n\n                    Markov Decision Processes\n\n                    Bellman Equations\n\n                    Bellman Expectation Equations\n\n                    Bellman Optimality Equations\n\n                    Common Approaches\n\n                    Dynamic Programming\n\n                    Policy Evaluation\n\n                    Policy Improvement\n\n                    Policy Iteration\n\n                    Monte-Carlo Methods\n\n                    Temporal-Difference Learning\n\n                    Bootstrapping\n\n                    Value Estimation\n\n                    SARSA: On-Policy TD control\n\n                    Q-Learning: Off-policy TD control\n\n                    Deep Q-Network\n\n                    Combining TD and MC Learning\n\n                    Policy Gradient\n\n                    Policy Gradient Theorem\n\n                    REINFORCE\n\n                    Actor-Critic\n\n                    A3C\n\n                    Evolution Strategies\n\n                    Known Problems\n\n                    Exploration-Exploitation Dilemma\n\n                    Deadly Triad Issue\n\n                    Case Study: AlphaGo Zero\n\n                    References\n\n[Updated on 2020-09-03: Updated the algorithm of SARSA and Q-learning so that the difference is more pronounced.\n\n[Updated on 2021-09-19: Thanks to 爱吃猫的鱼, we have this post in Chinese].\nA couple of exciting news in Artificial Intelligence (AI) has just happened in recent years.  AlphaGo defeated the best professional human player in the game of Go. Very soon the extended algorithm AlphaGo Zero beat AlphaGo by 100-0 without supervised learning on human knowledge. Top professional game players lost to the bot developed by OpenAI on DOTA2 1v1 competition. After knowing these, it is pretty hard not to be curious about the magic behind these algorithms — Reinforcement Learning (RL). I’m writing this post to briefly go over the field. We will first introduce several fundamental concepts and then dive into classic approaches to solving RL problems. Hopefully, this post could be a good starting point for newbies, bridging the future study on the cutting-edge research.\nWhat is Reinforcement Learning?#\nSay, we have an agent in an unknown environment and this agent can obtain some rewards by interacting with the environment. The agent ought to take actions so as to maximize cumulative rewards. In reality, the scenario could be a bot playing a game to achieve high scores, or a robot trying to complete physical tasks with physical items; and not just limited to these.\n\nFig. 1. An agent interacts with the environment, trying to take smart actions to maximize cumulative rewards.\nThe goal of Reinforcement Learning (RL) is to learn a good strategy for the agent from experimental trials and relative simple feedback received. With the optimal strategy, the agent is capable to actively adapt to the environment to maximize future rewards.\nKey Concepts#\nNow Let’s formally define a set of key concepts in RL.\nThe agent is acting in an environment. How the environment reacts to certain actions is defined by a model which we may or may not know. The agent can stay in one of many states (s∈S) of the environment, and choose to take one of many actions (a∈A) to switch from one state to another. Which state the agent will arrive in is decided by transition probabilities between states (P). Once an action is taken, the environment delivers a reward (r∈R) as feedback.\nThe model defines the reward function and transition probabilities. We may or may not know how the model works and this differentiate two circumstances:\n\nKnow the model: planning with perfect information; do model-based RL. When we fully know the environment, we can find the optimal solution by Dynamic Programming (DP). Do you still remember “longest increasing subsequence” or “traveling salesmen problem” from your Algorithms 101 class? LOL. This is not the focus of this post though.\nDoes not know the model: learning with incomplete information; do model-free RL or try to learn the model explicitly as part of the algorithm. Most of the following content serves the scenarios when the model is unknown.\n\nThe agent’s policy π(s) provides the guideline on what is the optimal action to take in a certain state with the goal to maximize the total rewards. Each state is associated with a value function V(s) predicting the expected amount of future rewards we are able to receive in this state by acting the corresponding policy. In other words, the value function quantifies how good a state is. Both policy and value functions are what we try to learn in reinforcement learning.\n\nFig. 2. Summary of approaches in RL based on whether we want to model the value, policy, or the environment. (Image source: reproduced from David Silver's RL course lecture 1.)\nThe interaction between the agent and the environment involves a sequence of actions and observed rewards in time, t=1,2,…,T. During the process, the agent accumulates the knowledge about the environment, learns the optimal policy, and makes decisions on which action to take next so as to efficiently learn the best policy. Let’s label the state, action, and reward at time step t as St, At, and Rt, respectively. Thus the interaction sequence is fully described by one episode (also known as “trial” or “trajectory”) and the sequence ends at the terminal state ST:\n\nS1,A1,R2,S2,A2,…,ST\n\nTerms you will encounter a lot when diving into different categories of RL algorithms:\n\nModel-based: Rely on the model of the environment; either the model is known or the algorithm learns it explicitly.\nModel-free: No dependency on the model during learning.\nOn-policy: Use the deterministic outcomes or samples from the target policy to train the algorithm.\nOff-policy: Training on a distribution of transitions or episodes produced by a different behavior policy rather than that produced by the target policy.\n\nModel: Transition and Reward#\nThe model is a descriptor of the environment. With the model, we can learn or infer how the environment would interact with and provide feedback to the agent. The model has two major parts, transition probability function P and reward function R.\nLet’s say when we are in state s, we decide to take action a to arrive in the next state s’ and obtain reward r. This is known as one transition step, represented by a tuple (s, a, s’, r).\nThe transition function P records the probability of transitioning from state s to s’ after taking action a while obtaining reward r. We use P as a symbol of “probability”.\n\nP(s′,r|s,a)=P[St+1=s′,Rt+1=r|St=s,At=a]\n\nThus the state-transition function can be defined as a function of P(s′,r|s,a):\n\nPss′a=P(s′|s,a)=P[St+1=s′|St=s,At=a]=∑r∈RP(s′,r|s,a)\n\nThe reward function R predicts the next reward triggered by one action:\n\nR(s,a)=E[Rt+1|St=s,At=a]=∑r∈Rr∑s′∈SP(s′,r|s,a)\n\nPolicy#\nPolicy, as the agent’s behavior function π, tells us which action to take in state s. It is a mapping from state s to action a and can be either deterministic or stochastic:\n\nDeterministic: π(s)=a.\nStochastic: π(a|s)=Pπ[A=a|S=s].\n\nValue Function#\nValue function measures the goodness of a state or how rewarding a state or an action is by a prediction of future reward. The future reward, also known as return, is a total sum of discounted rewards going forward. Let’s compute the return Gt starting from time t:\n\nGt=Rt+1+γRt+2+⋯=∑k=0∞γkRt+k+1\n\nThe discounting factor γ∈[0,1] penalize the rewards in the future, because:\n\nThe future rewards may have higher uncertainty; i.e. stock market.\nThe future rewards do not provide immediate benefits; i.e. As human beings, we might prefer to have fun today rather than 5 years later ;).\nDiscounting provides mathematical convenience; i.e., we don’t need to track future steps forever to compute return.\nWe don’t need to worry about the infinite loops in the state transition graph.\n\nThe state-value of a state s is the expected return if we are in this state at time t, St=s:\n\nVπ(s)=Eπ[Gt|St=s]\n\nSimilarly, we define the action-value (“Q-value”; Q as “Quality” I believe?) of a state-action pair as:\n\nQπ(s,a)=Eπ[Gt|St=s,At=a]\n\nAdditionally, since we follow the target policy π, we can make use of the probility distribution over possible actions and the Q-values to recover the state-value:\n\nVπ(s)=∑a∈AQπ(s,a)π(a|s)\n\nThe difference between action-value and state-value is the action advantage function (“A-value”):\n\nAπ(s,a)=Qπ(s,a)−Vπ(s)\n\nOptimal Value and Policy#\nThe optimal value function produces the maximum return:\n\nV∗(s)=maxπVπ(s),Q∗(s,a)=maxπQπ(s,a)\n\nThe optimal policy achieves optimal value functions:\n\nπ∗=arg⁡maxπVπ(s),π∗=arg⁡maxπQπ(s,a)\n\nAnd of course, we have Vπ∗(s)=V∗(s) and Qπ∗(s,a)=Q∗(s,a).\nMarkov Decision Processes#\nIn more formal terms, almost all the RL problems can be framed as Markov Decision Processes (MDPs). All states in MDP has “Markov” property, referring to the fact that the future only depends on the current state, not the history:\n\nP[St+1|St]=P[St+1|S1,…,St]\n\nOr in other words, the future and the past are conditionally independent given the present, as the current state encapsulates all the statistics we need to decide the future.\n\nFig. 3. The agent-environment interaction in a Markov decision process. (Image source: Sec. 3.1 Sutton & Barto (2017).)\nA Markov deicison process consists of five elements M=⟨S,A,P,R,γ⟩, where the symbols carry the same meanings as key concepts in the previous section, well aligned with RL problem settings:\n\nS - a set of states;\nA - a set of actions;\nP - transition probability function;\nR - reward function;\nγ - discounting factor for future rewards.\nIn an unknown environment, we do not have perfect knowledge about P and R.\n\nFig. 4. A fun example of Markov decision process: a typical work day. (Image source: randomant.net/reinforcement-learning-concepts)\nBellman Equations#\nBellman equations refer to a set of equations that decompose the value function into the immediate reward plus the discounted future values.\n\nV(s)=E[Gt|St=s]=E[Rt+1+γRt+2+γ2Rt+3+…|St=s]=E[Rt+1+γ(Rt+2+γRt+3+…)|St=s]=E[Rt+1+γGt+1|St=s]=E[Rt+1+γV(St+1)|St=s]\n\nSimilarly for Q-value,\n\nQ(s,a)=E[Rt+1+γV(St+1)∣St=s,At=a]=E[Rt+1+γEa∼πQ(St+1,a)∣St=s,At=a]\n\nBellman Expectation Equations#\nThe recursive update process can be further decomposed to be equations built on both state-value and action-value functions. As we go further in future action steps, we extend V and Q alternatively by following the policy π.\n\nFig. 5. Illustration of how Bellman expection equations update state-value and action-value functions.\n\nVπ(s)=∑a∈Aπ(a|s)Qπ(s,a)Qπ(s,a)=R(s,a)+γ∑s′∈SPss′aVπ(s′)Vπ(s)=∑a∈Aπ(a|s)(R(s,a)+γ∑s′∈SPss′aVπ(s′))Qπ(s,a)=R(s,a)+γ∑s′∈SPss′a∑a′∈Aπ(a′|s′)Qπ(s′,a′)\n\nBellman Optimality Equations#\nIf we are only interested in the optimal values, rather than computing the expectation following a policy, we could jump right into the maximum returns during the alternative updates without using a policy. RECAP: the optimal values V∗ and Q∗ are the best returns we can obtain, defined here.\n\nV∗(s)=maxa∈AQ∗(s,a)Q∗(s,a)=R(s,a)+γ∑s′∈SPss′aV∗(s′)V∗(s)=maxa∈A(R(s,a)+γ∑s′∈SPss′aV∗(s′))Q∗(s,a)=R(s,a)+γ∑s′∈SPss′amaxa′∈AQ∗(s′,a′)\n\nUnsurprisingly they look very similar to Bellman expectation equations.\nIf we have complete information of the environment, this turns into a planning problem, solvable by DP. Unfortunately, in most scenarios, we do not know Pss′a or R(s,a), so we cannot solve MDPs by directly applying Bellmen equations, but it lays the theoretical foundation for many RL algorithms.\nCommon Approaches#\nNow it is the time to go through the major approaches and classic algorithms for solving RL problems. In future posts, I plan to dive into each approach further.\nDynamic Programming#\nWhen the model is fully known, following Bellman equations, we can use Dynamic Programming (DP) to iteratively evaluate value functions and improve policy.\nPolicy Evaluation#\nPolicy Evaluation is to compute the state-value Vπ for a given policy π:\n\nVt+1(s)=Eπ[r+γVt(s′)|St=s]=∑aπ(a|s)∑s′,rP(s′,r|s,a)(r+γVt(s′))\n\nPolicy Improvement#\nBased on the value functions, Policy Improvement generates a better policy π′≥π by acting greedily.\n\nQπ(s,a)=E[Rt+1+γVπ(St+1)|St=s,At=a]=∑s′,rP(s′,r|s,a)(r+γVπ(s′))\n\nPolicy Iteration#\nThe Generalized Policy Iteration (GPI) algorithm refers to an iterative procedure to improve the policy when combining policy evaluation and improvement.\n\nπ0→evaluationVπ0→improveπ1→evaluationVπ1→improveπ2→evaluation⋯→improveπ∗→evaluationV∗\n\nIn GPI, the value function is approximated repeatedly to be closer to the true value of the current policy and in the meantime, the policy is improved repeatedly to approach optimality. This policy iteration process works and always converges to the optimality, but why this is the case?\nSay, we have a policy π and then generate an improved version π′ by greedily taking actions, π′(s)=arg⁡maxa∈AQπ(s,a). The value of this improved π′ is guaranteed to be better because:\n\nQπ(s,π′(s))=Qπ(s,arg⁡maxa∈AQπ(s,a))=maxa∈AQπ(s,a)≥Qπ(s,π(s))=Vπ(s)\n\nMonte-Carlo Methods#\nFirst, let’s recall that V(s)=E[Gt|St=s]. Monte-Carlo (MC) methods uses a simple idea: It learns from episodes of raw experience without modeling the environmental dynamics and computes the observed mean return as an approximation of the expected return. To compute the empirical return Gt, MC methods need to learn from complete episodes S1,A1,R2,…,ST to compute Gt=∑k=0T−t−1γkRt+k+1 and all the episodes must eventually terminate.\nThe empirical mean return for state s is:\n\n𝟙𝟙V(s)=∑t=1T1[St=s]Gt∑t=1T1[St=s]\n\nwhere 𝟙1[St=s] is a binary indicator function. We may count the visit of state s every time so that there could exist multiple visits of one state in one episode (“every-visit”), or only count it the first time we encounter a state in one episode (“first-visit”). This way of approximation can be easily extended to action-value functions by counting (s, a) pair.\n\n𝟙𝟙Q(s,a)=∑t=1T1[St=s,At=a]Gt∑t=1T1[St=s,At=a]\n\nTo learn the optimal policy by MC, we iterate it by following a similar idea to GPI.\n\nImprove the policy greedily with respect to the current value function: π(s)=arg⁡maxa∈AQ(s,a).\nGenerate a new episode with the new policy π (i.e. using algorithms like ε-greedy helps us balance between exploitation and exploration.)\nEstimate Q using the new episode: 𝟙𝟙qπ(s,a)=∑t=1T(1[St=s,At=a]∑k=0T−t−1γkRt+k+1)∑t=1T1[St=s,At=a]\n\nTemporal-Difference Learning#\nSimilar to Monte-Carlo methods, Temporal-Difference (TD) Learning is model-free and learns from episodes of experience. However, TD learning can learn from incomplete episodes and hence we don’t need to track the episode up to termination. TD learning is so important that Sutton & Barto (2017) in their RL book describes it as “one idea … central and novel to reinforcement learning”.\nBootstrapping#\nTD learning methods update targets with regard to existing estimates rather than exclusively relying on actual rewards and complete returns as in MC methods. This approach is known as bootstrapping.\nValue Estimation#\nThe key idea in TD learning is to update the value function V(St) towards an estimated return Rt+1+γV(St+1) (known as “TD target”). To what extent we want to update the value function is controlled by the learning rate hyperparameter α:\n\nV(St)←(1−α)V(St)+αGtV(St)←V(St)+α(Gt−V(St))V(St)←V(St)+α(Rt+1+γV(St+1)−V(St))\n\nSimilarly, for action-value estimation:\n\nQ(St,At)←Q(St,At)+α(Rt+1+γQ(St+1,At+1)−Q(St,At))\n\nNext, let’s dig into the fun part on how to learn optimal policy in TD learning (aka “TD control”). Be prepared, you are gonna see many famous names of classic algorithms in this section.\nSARSA: On-Policy TD control#\n“SARSA” refers to the procedure of updaing Q-value by following a sequence of …,St,At,Rt+1,St+1,At+1,…. The idea follows the same route of GPI. Within one episode, it works as follows:\n\nInitialize t=0.\nStart with S0 and choose action A0=arg⁡maxa∈AQ(S0,a), where ϵ-greedy is commonly applied.\nAt time t, after applying action At, we observe reward Rt+1 and get into the next state St+1.\nThen pick the next action in the same way as in step 2: At+1=arg⁡maxa∈AQ(St+1,a).\nUpdate the Q-value function: Q(St,At)←Q(St,At)+α(Rt+1+γQ(St+1,At+1)−Q(St,At)).\nSet t=t+1 and repeat from step 3.\n\nIn each step of SARSA, we need to choose the next action according to the current policy.\nQ-Learning: Off-policy TD control#\nThe development of Q-learning (Watkins & Dayan, 1992) is a big breakout in the early days of Reinforcement Learning. Within one episode, it works as follows:\n\nInitialize t=0.\nStarts with S0.\nAt time step t, we pick the action according to Q values, At=arg⁡maxa∈AQ(St,a) and ϵ-greedy is commonly applied.\nAfter applying action At, we observe reward Rt+1 and get into the next state St+1.\nUpdate the Q-value function: Q(St,At)←Q(St,At)+α(Rt+1+γmaxa∈AQ(St+1,a)−Q(St,At)).\nt=t+1 and repeat from step 3.\n\nThe key difference from SARSA is that Q-learning does not follow the current policy to pick the second action At+1. It estimates Q∗ out of the best Q values, but which action (denoted as a∗) leads to this maximal Q does not matter and in the next step Q-learning may not follow a∗.\n\nFig. 6. The backup diagrams for Q-learning and SARSA. (Image source: Replotted based on Figure 6.5 in Sutton & Barto (2017))\nDeep Q-Network#\nTheoretically, we can memorize Q∗(.) for all state-action pairs in Q-learning, like in a gigantic table. However, it quickly becomes computationally infeasible when the state and action space are large. Thus people use functions (i.e. a machine learning model) to approximate Q values and this is called function approximation. For example, if we use a function with parameter θ to calculate Q values, we can label Q value function as Q(s,a;θ).\nUnfortunately Q-learning may suffer from instability and divergence when combined with an nonlinear Q-value function approximation and bootstrapping (See Problems #2).\nDeep Q-Network (“DQN”; Mnih et al. 2015) aims to greatly improve and stabilize the training procedure of Q-learning by two innovative mechanisms:\n\nExperience Replay: All the episode steps et=(St,At,Rt,St+1) are stored in one replay memory Dt={e1,…,et}. Dt has experience tuples over many episodes. During Q-learning updates, samples are drawn at random from the replay memory and thus one sample could be used multiple times. Experience replay improves data efficiency, removes correlations in the observation sequences, and smooths over changes in the data distribution.\nPeriodically Updated Target: Q is optimized towards target values that are only periodically updated. The Q network is cloned and kept frozen as the optimization target every C steps (C is a hyperparameter). This modification makes the training more stable as it overcomes the short-term oscillations.\n\nThe loss function looks like this:\n\nL(θ)=E(s,a,r,s′)∼U(D)[(r+γmaxa′Q(s′,a′;θ−)−Q(s,a;θ))2]\n\nwhere U(D) is a uniform distribution over the replay memory D; θ− is the parameters of the frozen target Q-network.\nIn addition, it is also found to be helpful to clip the error term to be between [-1, 1]. (I always get mixed feeling with parameter clipping, as many studies have shown that it works empirically but it makes the math much less pretty. :/)\n\nFig. 7. Algorithm for DQN with experience replay and occasionally frozen optimization target. The prepossessed sequence is the output of some processes running on the input images of Atari games. Don't worry too much about it; just consider them as input feature vectors. (Image source: Mnih et al. 2015)\nThere are many extensions of DQN to improve the original design, such as DQN with dueling architecture (Wang et al. 2016) which estimates state-value function V(s) and advantage function A(s, a) with shared network parameters.\nCombining TD and MC Learning#\nIn the previous section on value estimation in TD learning, we only trace one step further down the action chain when calculating the TD target. One can easily extend it to take multiple steps to estimate the return.\nLet’s label the estimated return following n steps as Gt(n),n=1,…,∞, then:\n\n          n\n          Gt\n          Notes\n\n          n=1\n          Gt(1)=Rt+1+γV(St+1)\n          TD learning\n\n          n=2\n          Gt(2)=Rt+1+γRt+2+γ2V(St+2)\n\n          …\n\n          n=n\n          Gt(n)=Rt+1+γRt+2+⋯+γn−1Rt+n+γnV(St+n)\n\n          …\n\n          n=∞\n          Gt(∞)=Rt+1+γRt+2+⋯+γT−t−1RT+γT−tV(ST)\n          MC estimation\n\nThe generalized n-step TD learning still has the same form for updating the value function:\n\nV(St)←V(St)+α(Gt(n)−V(St))\n\nWe are free to pick any n in TD learning as we like. Now the question becomes what is the best n? Which Gt(n) gives us the best return approximation? A common yet smart solution is to apply a weighted sum of all possible n-step TD targets rather than to pick a single best n. The weights decay by a factor λ with n, λn−1; the intuition is similar to why we want to discount future rewards when computing the return: the more future we look into the less confident we would be. To make all the weight (n → ∞) sum up to 1, we multiply every weight by (1-λ), because:\n\nletS=1+λ+λ2+…S=1+λ(1+λ+λ2+…)S=1+λSS=1/(1−λ)\n\nThis weighted sum of many n-step returns is called λ-return Gtλ=(1−λ)∑n=1∞λn−1Gt(n). TD learning that adopts λ-return for value updating is labeled as TD(λ). The original version we introduced above is equivalent to TD(0).\n\nFig. 8. Comparison of the backup diagrams of Monte-Carlo, Temporal-Difference learning, and Dynamic Programming for state value functions. (Image source: David Silver's RL course lecture 4: \"Model-Free Prediction\")\nPolicy Gradient#\nAll the methods we have introduced above aim to learn the state/action value function and then to select actions accordingly. Policy Gradient methods instead learn the policy directly with a parameterized function respect to θ, π(a|s;θ). Let’s define the reward function (opposite of loss function) as the expected return and train the algorithm with the goal to maximize the reward function. My next post described why the policy gradient theorem works (proof) and introduced a number of policy gradient algorithms.\nIn discrete space:\n\nJ(θ)=Vπθ(S1)=Eπθ[V1]\n\nwhere S1 is the initial starting state.\nOr in continuous space:\n\nJ(θ)=∑s∈Sdπθ(s)Vπθ(s)=∑s∈S(dπθ(s)∑a∈Aπ(a|s,θ)Qπ(s,a))\n\nwhere dπθ(s) is stationary distribution of Markov chain for πθ. If you are unfamiliar with the definition of a “stationary distribution,” please check this reference.\nUsing gradient ascent we can find the best θ that produces the highest return. It is natural to expect policy-based methods are more useful in continuous space, because there is an infinite number of actions and/or states to estimate the values for in continuous space and hence value-based approaches are computationally much more expensive.\nPolicy Gradient Theorem#\nComputing the gradient numerically can be done by perturbing θ by a small amount ε in the k-th dimension. It works even when J(θ) is not differentiable (nice!), but unsurprisingly very slow.\n\n∂J(θ)∂θk≈J(θ+ϵuk)−J(θ)ϵ\n\nOr analytically,\n\nJ(θ)=Eπθ[r]=∑s∈Sdπθ(s)∑a∈Aπ(a|s;θ)R(s,a)\n\nActually we have nice theoretical support for (replacing d(.) with dπ(.)):\n\nJ(θ)=∑s∈Sdπθ(s)∑a∈Aπ(a|s;θ)Qπ(s,a)∝∑s∈Sd(s)∑a∈Aπ(a|s;θ)Qπ(s,a)\n\nCheck Sec 13.1 in Sutton & Barto (2017) for why this is the case.\nThen,\n\nJ(θ)=∑s∈Sd(s)∑a∈Aπ(a|s;θ)Qπ(s,a)∇J(θ)=∑s∈Sd(s)∑a∈A∇π(a|s;θ)Qπ(s,a)=∑s∈Sd(s)∑a∈Aπ(a|s;θ)∇π(a|s;θ)π(a|s;θ)Qπ(s,a)=∑s∈Sd(s)∑a∈Aπ(a|s;θ)∇ln⁡π(a|s;θ)Qπ(s,a)=Eπθ[∇ln⁡π(a|s;θ)Qπ(s,a)]\n\nThis result is named “Policy Gradient Theorem” which lays the theoretical foundation for various policy gradient algorithms:\n\n∇J(θ)=Eπθ[∇ln⁡π(a|s,θ)Qπ(s,a)]\n\nREINFORCE#\nREINFORCE, also known as Monte-Carlo policy gradient, relies on Qπ(s,a), an estimated return by MC methods using episode samples, to update the policy parameter θ.\nA commonly used variation of REINFORCE is to subtract a baseline value from the return Gt to reduce the variance of gradient estimation while keeping the bias unchanged. For example, a common baseline is state-value, and if applied, we would use A(s,a)=Q(s,a)−V(s) in the gradient ascent update.\n\nInitialize θ at random\nGenerate one episode S1,A1,R2,S2,A2,…,ST\nFor t=1, 2, … , T:\n\nEstimate the the return G_t since the time step t.\nθ←θ+αγtGt∇ln⁡π(At|St,θ).\n\nActor-Critic#\nIf the value function is learned in addition to the policy, we would get Actor-Critic algorithm.\n\nCritic: updates value function parameters w and depending on the algorithm it could be action-value Q(a|s;w) or state-value V(s;w).\nActor: updates policy parameters θ, in the direction suggested by the critic, π(a|s;θ).\n\nLet’s see how it works in an action-value actor-critic algorithm.\n\nInitialize s, θ, w at random; sample a∼π(a|s;θ).\nFor t = 1… T:\n\nSample reward rt∼R(s,a) and next state s′∼P(s′|s,a).\nThen sample the next action a′∼π(s′,a′;θ).\nUpdate policy parameters: θ←θ+αθQ(s,a;w)∇θln⁡π(a|s;θ).\nCompute the correction for action-value at time t:\nGt:t+1=rt+γQ(s′,a′;w)−Q(s,a;w)\nand use it to update value function parameters:\nw←w+αwGt:t+1∇wQ(s,a;w).\nUpdate a←a′ and s←s′.\n\nαθ and αw are two learning rates for policy and value function parameter updates, respectively.\nA3C#\nAsynchronous Advantage Actor-Critic (Mnih et al., 2016), short for A3C, is a classic policy gradient method with the special focus on parallel training.\nIn A3C, the critics learn the state-value function, V(s;w), while multiple actors are trained in parallel and get synced with global parameters from time to time. Hence, A3C is good for parallel training by default, i.e. on one machine with multi-core CPU.\nThe loss function for state-value is to minimize the mean squared error, Jv(w)=(Gt−V(s;w))2 and we use gradient descent to find the optimal w. This state-value function is used as the baseline in the policy gradient update.\nHere is the algorithm outline:\n\nWe have global parameters, θ and w; similar thread-specific parameters, θ’ and w'.\nInitialize the time step t = 1\nWhile T <= T_MAX:\n\nReset gradient: dθ = 0 and dw = 0.\nSynchronize thread-specific parameters with global ones: θ’ = θ and w’ = w.\ntstart = t and get st.\nWhile (st≠TERMINAL) and (t−tstart<=tmax):\n\nPick the action at∼π(at|st;θ′) and receive a new reward rt and a new state st+1.\nUpdate t = t + 1 and T = T + 1.\n\nInitialize the variable that holds the return estimation R={0ifstis TERMINALV(st;w′)otherwise.\nFor i=t−1,…,tstart:\n\nR←ri+γR; here R is a MC measure of Gi.\nAccumulate gradients w.r.t. θ’: dθ←dθ+∇θ′log⁡π(ai|si;θ′)(R−V(si;w′));\nAccumulate gradients w.r.t. w’: dw←dw+∇w′(R−V(si;w′))2.\n\nUpdate synchronously θ using dθ, and w using dw.\n\nA3C enables the parallelism in multiple agent training. The gradient accumulation step (6.2) can be considered as a reformation of minibatch-based stochastic gradient update: the values of w or θ get corrected by a little bit in the direction of each training thread independently.\nEvolution Strategies#\nEvolution Strategies (ES) is a type of model-agnostic optimization approach. It learns the optimal solution by imitating Darwin’s theory of the evolution of species by natural selection. Two prerequisites for applying ES: (1) our solutions can freely interact with the environment and see whether they can solve the problem; (2) we are able to compute a fitness score of how good each solution is. We don’t have to know the environment configuration to solve the problem.\nSay, we start with a population of random solutions. All of them are capable of interacting with the environment and only candidates with high fitness scores can survive (only the fittest can survive in a competition for limited resources). A new generation is then created by recombining the settings (gene mutation) of high-fitness survivors. This process is repeated until the new solutions are good enough.\nVery different from the popular MDP-based approaches as what we have introduced above, ES aims to learn the policy parameter θ without value approximation. Let’s assume the distribution over the parameter θ is an isotropic multivariate Gaussian with mean μ and fixed covariance σ2I. The gradient of F(θ) is calculated:\n\n∇θEθ∼N(μ,σ2)F(θ)=∇θ∫θF(θ)Pr(θ)Pr(.) is the Gaussian density function.=∫θF(θ)Pr(θ)∇θPr(θ)Pr(θ)=∫θF(θ)Pr(θ)∇θlog⁡Pr(θ)=Eθ∼N(μ,σ2)[F(θ)∇θlog⁡Pr(θ)]Similar to how we do policy gradient update.=Eθ∼N(μ,σ2)[F(θ)∇θlog⁡(12πσ2e−(θ−μ)22σ2)]=Eθ∼N(μ,σ2)[F(θ)∇θ(−log⁡2πσ2−(θ−μ)22σ2)]=Eθ∼N(μ,σ2)[F(θ)θ−μσ2]\n\nWe can rewrite this formula in terms of a “mean” parameter θ (different from the θ above; this θ is the base gene for further mutation), ϵ∼N(0,I) and therefore θ+ϵσ∼N(θ,σ2). ϵ controls how much Gaussian noises should be added to create mutation:\n\n∇θEϵ∼N(0,I)F(θ+σϵ)=1σEϵ∼N(0,I)[F(θ+σϵ)ϵ]\n\nFig. 9. A simple parallel evolution-strategies-based RL algorithm. Parallel workers share the random seeds so that they can reconstruct the Gaussian noises with tiny communication bandwidth. (Image source: Salimans et al. 2017.)\nES, as a black-box optimization algorithm, is another approach to RL problems (In my original writing, I used the phrase “a nice alternative”; Seita pointed me to this discussion and thus I updated my wording.). It has a couple of good characteristics (Salimans et al., 2017) keeping it fast and easy to train:\n\nES does not need value function approximation;\nES does not perform gradient back-propagation;\nES is invariant to delayed or long-term rewards;\nES is highly parallelizable with very little data communication.\n\nKnown Problems#\nExploration-Exploitation Dilemma#\nThe problem of exploration vs exploitation dilemma has been discussed in my previous post. When the RL problem faces an unknown environment, this issue is especially a key to finding a good solution: without enough exploration, we cannot learn the environment well enough; without enough exploitation, we cannot complete our reward optimization task.\nDifferent RL algorithms balance between exploration and exploitation in different ways. In MC methods, Q-learning or many on-policy algorithms, the exploration is commonly implemented by ε-greedy; In ES, the exploration is captured by the policy parameter perturbation. Please keep this into consideration when developing a new RL algorithm.\nDeadly Triad Issue#\nWe do seek the efficiency and flexibility of TD methods that involve bootstrapping. However, when off-policy, nonlinear function approximation, and bootstrapping are combined in one RL algorithm, the training could be unstable and hard to converge. This issue is known as the deadly triad (Sutton & Barto, 2017). Many architectures using deep learning models were proposed to resolve the problem, including DQN to stabilize the training with experience replay and occasionally frozen target network.\nCase Study: AlphaGo Zero#\nThe game of Go has been an extremely hard problem in the field of Artificial Intelligence for decades until recent years. AlphaGo and AlphaGo Zero are two programs developed by a team at DeepMind. Both involve deep Convolutional Neural Networks (CNN) and Monte Carlo Tree Search (MCTS) and both have been approved to achieve the level of professional human Go players. Different from AlphaGo that relied on supervised learning from expert human moves, AlphaGo Zero used only reinforcement learning and self-play without human knowledge beyond the basic rules.\n\nFig. 10. The board of Go. Two players play black and white stones alternatively on the vacant intersections of a board with 19 x 19 lines. A group of stones must have at least one open point (an intersection, called a \"liberty\") to remain on the board and must have at least two or more enclosed liberties (called \"eyes\") to stay \"alive\". No stone shall repeat a previous position.\nWith all the knowledge of RL above, let’s take a look at how AlphaGo Zero works. The main component is a deep CNN over the game board configuration (precisely, a ResNet with batch normalization and ReLU). This network outputs two values:\n\n(p,v)=fθ(s)\n\ns: the game board configuration, 19 x 19 x 17 stacked feature planes; 17 features for each position, 8 past configurations (including current) for the current player + 8 past configurations for the opponent + 1 feature indicating the color (1=black, 0=white). We need to code the color specifically because the network is playing with itself and the colors of current player and opponents are switching between steps.\np: the probability of selecting a move over 19^2 + 1 candidates (19^2 positions on the board, in addition to passing).\nv: the winning probability given the current setting.\n\nDuring self-play, MCTS further improves the action probability distribution π∼p(.) and then the action at is sampled from this improved policy. The reward zt is a binary value indicating whether the current player eventually wins the game. Each move generates an episode tuple (st,πt,zt) and it is saved into the replay memory. The details on MCTS are skipped for the sake of space in this post; please read the original paper if you are interested.\n\nFig. 11. AlphaGo Zero is trained by self-play while MCTS improves the output policy further in every step. (Image source: Figure 1a in Silver et al., 2017).\nThe network is trained with the samples in the replay memory to minimize the loss:\n\nL=(z−v)2−π⊤log⁡p+c‖θ‖2\n\nwhere c is a hyperparameter controlling the intensity of L2 penalty to avoid overfitting.\nAlphaGo Zero simplified AlphaGo by removing supervised learning and merging separated policy and value networks into one. It turns out that AlphaGo Zero achieved largely improved performance with a much shorter training time! I strongly recommend reading these two papers side by side and compare the difference, super fun.\nI know this is a long read, but hopefully worth it. If you notice mistakes and errors in this post, don’t hesitate to contact me at [lilian dot wengweng at gmail dot com]. See you in the next post! :)\n\nCited as:\n@article{weng2018bandit,\n  title   = \"A (Long) Peek into Reinforcement Learning\",\n  author  = \"Weng, Lilian\",\n  journal = \"lilianweng.github.io\",\n  year    = \"2018\",\n  url     = \"https://lilianweng.github.io/posts/2018-02-19-rl-overview/\"\n}\ncopyReferences#\n[1] Yuxi Li. Deep reinforcement learning: An overview. arXiv preprint arXiv:1701.07274. 2017.\n[2] Richard S. Sutton and Andrew G. Barto. Reinforcement Learning: An Introduction; 2nd Edition. 2017.\n[3] Volodymyr Mnih, et al. Asynchronous methods for deep reinforcement learning. ICML. 2016.\n[4] Tim Salimans, et al. Evolution strategies as a scalable alternative to reinforcement learning. arXiv preprint arXiv:1703.03864 (2017).\n[5] David Silver, et al. Mastering the game of go without human knowledge. Nature 550.7676 (2017): 354.\n[6] David Silver, et al. Mastering the game of Go with deep neural networks and tree search. Nature 529.7587 (2016): 484-489.\n[7] Volodymyr Mnih, et al. Human-level control through deep reinforcement learning. Nature 518.7540 (2015): 529.\n[8] Ziyu Wang, et al. Dueling network architectures for deep reinforcement learning. ICML. 2016.\n[9] Reinforcement Learning lectures by David Silver on YouTube.\n[10] OpenAI Blog: Evolution Strategies as a Scalable Alternative to Reinforcement Learning\n[11] Frank Sehnke, et al. Parameter-exploring policy gradients. Neural Networks 23.4 (2010): 551-559.\n[12] Csaba Szepesvári. Algorithms for reinforcement learning. 1st Edition. Synthesis lectures on artificial intelligence and machine learning 4.1 (2010): 1-103.\n\nIf you notice mistakes and errors in this post, please don’t hesitate to contact me at [lilian dot wengweng at gmail dot com] and I would be super happy to correct them right away!\n\n      Reinforcement-Learning\n      Long-Read\n      Math-Heavy\n\n    «\n\n    Policy Gradient Algorithms\n\n     »\n\n    The Multi-Armed Bandit Problem and Its Solutions",
    "summary": {
      "en": "**Summary of \"A (Long) Peek into Reinforcement Learning\"**\n\nReinforcement Learning (RL) is a branch of artificial intelligence where an agent learns to make decisions by interacting with an environment to maximize cumulative rewards. Key concepts in RL include:\n\n1. **Agent and Environment**: The agent performs actions in an environment and receives rewards as feedback.\n2. **Policy**: A strategy that defines the actions the agent should take in various states.\n3. **Value Function**: A measure of the expected future rewards from a state, helping the agent evaluate how good a state is.\n\nReinforcement Learning can be categorized into two types based on model knowledge:\n- **Model-based RL**: The model of the environment is known, allowing the use of techniques like Dynamic Programming.\n- **Model-free RL**: The agent learns without a model, using methods such as Monte-Carlo and Temporal-Difference learning.\n\n**Common Approaches in RL**:\n- **Dynamic Programming**: Used when the model is known to evaluate and improve policies iteratively.\n- **Monte-Carlo Methods**: Learn from complete episodes without needing the model.\n- **Temporal-Difference Learning**: Learns from incomplete episodes and updates estimates based on the current value function.\n- **Q-Learning**: An off-policy method that updates the value function based on the best possible future actions, regardless of the current policy.\n- **Deep Q-Networks (DQN)**: Combines Q-learning with deep learning to handle large state spaces efficiently.\n\n**Challenges in RL**:\n- **Exploration-Exploitation Dilemma**: Balancing the need to explore the environment and exploit known rewards.\n- **Deadly Triad**: Issues that arise when using off-policy learning, bootstrapping, and non-linear function approximations together.\n\n**Case Study - AlphaGo Zero**: Demonstrates the power of RL by defeating top human players in Go using self-play and deep neural networks, without relying on human knowledge.\n\nThis overview provides a foundation for understanding Reinforcement Learning, its key concepts, methods, and challenges, making it accessible for newcomers.",
      "ko": "강화 학습(Reinforcement Learning, RL)은 인공지능의 한 분야로, 에이전트가 환경과 상호작용하며 누적 보상을 극대화하기 위해 결정을 내리는 방법을 배우는 과정입니다. RL의 주요 개념은 다음과 같습니다.\n\n에이전트와 환경은 에이전트가 환경 내에서 행동을 수행하고 그에 대한 피드백으로 보상을 받는 구조입니다. 정책은 에이전트가 다양한 상태에서 어떤 행동을 취해야 하는지를 정의하는 전략입니다. 가치 함수는 특정 상태에서 예상되는 미래 보상을 측정하여 에이전트가 그 상태의 가치를 평가하는 데 도움을 줍니다.\n\n강화 학습은 모델 지식에 따라 두 가지 유형으로 나눌 수 있습니다. 모델 기반 RL은 환경의 모델이 알려져 있어 동적 프로그래밍과 같은 기법을 사용할 수 있습니다. 반면 모델 없는 RL은 모델 없이 학습하며 몬테카를로 방법이나 시간 차 학습과 같은 방법을 사용합니다.\n\n강화 학습에서 일반적으로 사용되는 접근 방식은 다음과 같습니다. 동적 프로그래밍은 모델이 알려져 있을 때 정책을 평가하고 개선하는 데 사용됩니다. 몬테카를로 방법은 모델 없이 전체 에피소드에서 학습합니다. 시간 차 학습은 불완전한 에피소드에서 학습하며 현재 가치 함수를 기반으로 추정치를 업데이트합니다. Q-학습은 현재 정책과 관계없이 최적의 미래 행동을 기반으로 가치 함수를 업데이트하는 오프 정책 방법입니다. 딥 Q-네트워크(DQN)는 Q-학습과 딥러닝을 결합하여 큰 상태 공간을 효율적으로 처리합니다.\n\n강화 학습의 도전 과제 중 하나는 탐색과 활용의 딜레마입니다. 이는 환경을 탐색할 필요성과 이미 알고 있는 보상을 활용할 필요성 사이의 균형을 맞추는 것입니다. 또한, 치명적인 삼각형 문제는 오프 정책 학습, 부트스트래핑, 비선형 함수 근사치를 함께 사용할 때 발생하는 문제를 의미합니다.\n\n사례 연구로 알파고 제로(AlphaGo Zero)는 자가 대국과 딥 뉴럴 네트워크를 사용하여 인간 최고 선수들을 이기는 강화 학습의 힘을 보여줍니다. 이 과정에서 인간의 지식에 의존하지 않았습니다.\n\n이 개요는 강화 학습의 기본 개념, 방법 및 도전 과제를 이해하는 데 도움을 주어, 초보자들이 접근할 수 있도록 합니다.",
      "ja": "強化学習（RL）は、エージェントが環境と相互作用しながら意思決定を学び、累積報酬を最大化する人工知能の一分野です。RLの重要な概念には、エージェントと環境、ポリシー、価値関数があります。\n\nエージェントは環境内で行動を行い、その結果として報酬を受け取ります。ポリシーは、エージェントがさまざまな状態でどのような行動を取るべきかを定義する戦略です。価値関数は、ある状態から得られる将来の報酬の期待値を示し、エージェントがその状態の良さを評価するのに役立ちます。\n\n強化学習は、モデルの知識に基づいて二つのタイプに分類されます。モデルベースのRLは、環境のモデルが知られている場合に、動的計画法などの手法を使用します。一方、モデルフリーのRLは、モデルなしで学習し、モンテカルロ法や時間差学習などの方法を用います。\n\n強化学習でよく使われるアプローチには、動的計画法、モンテカルロ法、時間差学習、Q学習、深層Qネットワーク（DQN）があります。動的計画法は、モデルが知られているときにポリシーを評価し改善するために使われます。モンテカルロ法は、モデルを必要とせずに完全なエピソードから学習します。時間差学習は、不完全なエピソードから学び、現在の価値関数に基づいて推定を更新します。Q学習は、オフポリシー手法で、現在のポリシーに関係なく、最良の将来の行動に基づいて価値関数を更新します。深層Qネットワークは、Q学習と深層学習を組み合わせて、大規模な状態空間を効率的に扱います。\n\n強化学習にはいくつかの課題があります。探索と活用のジレンマは、環境を探索する必要性と既知の報酬を活用することのバランスを取ることです。また、致命的な三重奏は、オフポリシー学習、ブートストラップ、非線形関数近似を同時に使用する際に発生する問題です。\n\nケーススタディとしてのAlphaGo Zeroは、自己対戦と深層ニューラルネットワークを用いて、トップの人間プレイヤーを打ち負かすことで強化学習の力を示しています。人間の知識に依存せずに学習を行いました。\n\nこの概要は、強化学習の基本的な理解を提供し、主要な概念、手法、課題を紹介することで、新しい学習者にとってアクセスしやすい内容となっています。"
    }
  },
  {
    "id": "d0e349c2b2184e97",
    "title": {
      "en": "SplitQuantV2: Enhancing Low-Bit Quantization of LLMs Without GPUs",
      "ko": "GPU 없이 LLM 저비트 양자화 개선!",
      "ja": "GPU不要！LLM低ビット量子化の進化"
    },
    "type": "story",
    "url": "https://arxiv.org/abs/2503.07657",
    "score": 8,
    "by": "PaulHoule",
    "time": 1742988977,
    "content": "The quantization of large language models (LLMs) is crucial for deploying them on devices with limited computational resources. While advanced quantization algorithms offer improved performance compared to the basic linear quantization, they typically require high-end graphics processing units (GPUs), are often restricted to specific deep neural network (DNN) frameworks, and require calibration datasets. This limitation poses challenges for using such algorithms on various neural processing units (NPUs) and edge AI devices, which have diverse model formats and frameworks. In this paper, we show SplitQuantV2, an innovative algorithm designed to enhance low-bit linear quantization of LLMs, can achieve results comparable to those of advanced algorithms. SplitQuantV2 preprocesses models by splitting linear and convolution layers into functionally equivalent, quantization-friendly structures. The algorithm's platform-agnostic, concise, and efficient nature allows for implementation without the need for GPUs. Our evaluation on the Llama 3.2 1B Instruct model using the AI2's Reasoning Challenge (ARC) dataset demonstrates that SplitQuantV2 improves the accuracy of the INT4 quantization model by 11.76%p, matching the performance of the original floating-point model. Remarkably, SplitQuantV2 took only 2 minutes 6 seconds to preprocess the 1B model and perform linear INT4 quantization using only an Apple M4 CPU. SplitQuantV2 provides a practical solution for low-bit quantization on LLMs, especially when complex, computation-intensive algorithms are inaccessible due to hardware limitations or framework incompatibilities.",
    "summary": {
      "en": "The quantization of large language models (LLMs) is important for running them on devices with limited processing power. Advanced quantization methods can improve performance but often need high-end GPUs, specific frameworks, and calibration datasets, making them hard to use on various devices. This paper introduces SplitQuantV2, a new algorithm that enhances low-bit linear quantization of LLMs and achieves results similar to advanced methods. It works by reorganizing model layers into structures that are easier to quantize. SplitQuantV2 is efficient and does not require GPUs, making it versatile for different platforms. Testing on the Llama 3.2 1B Instruct model showed that it improved accuracy by 11.76% compared to the INT4 quantization model, matching the original floating-point model's performance. Remarkably, it only took 2 minutes and 6 seconds to preprocess and quantize the model using an Apple M4 CPU. SplitQuantV2 offers a practical way to perform low-bit quantization on LLMs, especially when more complex methods aren't feasible due to hardware or framework issues.",
      "ko": "대형 언어 모델(LLM)의 양자화는 처리 능력이 제한된 장치에서 이를 실행하는 데 중요합니다. 고급 양자화 방법은 성능을 향상시킬 수 있지만, 종종 고급 GPU, 특정 프레임워크, 그리고 보정 데이터셋이 필요해 다양한 장치에서 사용하기 어렵습니다. 이 논문에서는 LLM의 저비트 선형 양자화를 개선하고 고급 방법과 유사한 결과를 달성하는 새로운 알고리즘인 SplitQuantV2를 소개합니다. 이 알고리즘은 모델의 레이어를 양자화하기 쉬운 구조로 재편성하여 작동합니다. SplitQuantV2는 효율적이며 GPU가 필요 없어 다양한 플랫폼에서 활용할 수 있습니다. Llama 3.2 1B Instruct 모델을 테스트한 결과, INT4 양자화 모델에 비해 정확도가 11.76% 향상되었고, 원래의 부동소수점 모델과 동일한 성능을 보였습니다. 특히, Apple M4 CPU를 사용하여 모델을 전처리하고 양자화하는 데 단 2분 6초가 걸렸습니다. SplitQuantV2는 하드웨어나 프레임워크 문제로 인해 더 복잡한 방법이 어려운 경우, LLM에서 저비트 양자화를 수행하는 실용적인 방법을 제공합니다.",
      "ja": "大規模言語モデル（LLM）の量子化は、処理能力が限られたデバイスでの運用において重要です。高度な量子化手法は性能を向上させることができますが、高性能なGPUや特定のフレームワーク、キャリブレーションデータセットが必要なため、さまざまなデバイスでの利用が難しいことがあります。この論文では、LLMの低ビット線形量子化を強化し、高度な手法と同様の結果を達成する新しいアルゴリズム「SplitQuantV2」を紹介します。このアルゴリズムは、モデルの層を量子化しやすい構造に再編成することで機能します。SplitQuantV2は効率的で、GPUを必要としないため、さまざまなプラットフォームでの利用が可能です。\n\nLlama 3.2 1B Instructモデルでのテストでは、INT4量子化モデルと比較して精度が11.76%向上し、元の浮動小数点モデルの性能に匹敵する結果が得られました。特筆すべきは、Apple M4 CPUを使用してモデルの前処理と量子化を行うのにわずか2分6秒しかかからなかったことです。SplitQuantV2は、ハードウェアやフレームワークの制約により、より複雑な手法が実行できない場合でも、LLMの低ビット量子化を実現する実用的な方法を提供します。"
    }
  },
  {
    "id": "12e39ff4c61a5f07",
    "title": {
      "en": "Better Shell History Search",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://tratt.net/laurie/blog/2025/better_shell_history_search.html",
    "score": 170,
    "by": "ltratt",
    "time": 1742942117,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "e8919d9385bd4d24",
    "title": {
      "en": "Show HN: Cocommit – A copilot for git commit",
      "ko": "코코밋: 깃 커밋의 조력자",
      "ja": "ココミット：Gitの相棒"
    },
    "type": "story",
    "url": "https://github.com/andrewromanenco/cocommit",
    "score": 15,
    "by": "AndrewRDev",
    "time": 1742753760,
    "content": "Cocommit: A Copilot for Git\n\nCocommit is a command-line tool that works with your HEAD commit and leverages an LLM of your choice to enhance commit quality.\nA good commit consists of multiple elements, but at a minimum, it should have a well-crafted commit message. Cocommit analyzes the message from the last (HEAD) commit and suggests improvements, highlighting both strengths and areas for enhancement.\nCocommit v2 is currently in development and will introduce many new features—see the v2 documentation for details.\nCocommit utilizes LangChain as an abstraction layer to access various Large Language Models (LLMs).\nWhy Use Cocommit?\n\nWorks with the LLM of your choice\nProvides a simple foundation for building custom AI-powered tools\nEasily integrates into your development workflow\nAllows customization of the LLM experience to fit your project needs\n\nTable of Contents\n\nExample CLI Session\nInstallation\nUsage\n\nExample: Using OpenAI\nSimplifying OpenAI Usage with Shortcuts\nExample: Using Claude 3.7 on Bedrock\nSimplifying Bedrock Claude 3.7 Usage with Shortcuts\nViewing Available Shortcuts\nUsing Other LLMs\nUseful CLI Options\n\nContributing\nLicense\n\nExample CLI Session\nSession Start\ngit add .\ngit commit\ncocommit -s bedrock-claude37\n\nExecution Output\nCalling with: --model_provider bedrock --model us.anthropic.claude-3-7-sonnet-20250219-v1:0 --region_name us-east-1\nCalling LLM....\nDone in 9.6 seconds.\n\nAbout your commit:\nThis is a good quality commit message that follows most best practices. It has a clear, concise title in imperative mood and a brief explanation of why the change was made.\n\nStrengths:\n  - Concise first line under 80 characters\n  - Uses imperative mood correctly (\"Add\" not \"Added\")\n  - Provides context in the description about why the change was made\n  - Clearly specifies what was changed\n  - Follows proper structure with title, blank line, and description\n\nImprovements:\n  - The description could be slightly more specific about which Python versions are now supported\n\n********** Proposed Git Message: ********************\n\nAdd Python version classifiers to project metadata\n\nThis change lists supported Python versions for better visibility on PyPI.\n\n****************************************************\n\nFixes:\n  - Consider specifying which Python versions are now supported in the description for more detail\n\nAmend the commit message? [Y/n]: y\n********** Previous Message **********\nAdd Python version classifiers metadata\n\nLists supported Python versions for PyPI.\n**************************************\nAmend ... done!\n\nInstallation\nTo install Cocommit, run:\npip install cocommit\n\nInstalling from Source\nYou can also install Cocommit from the source code, which allows for customization. For details, see the Contributing Guide.\nHandling on-demand Dependencies\nWhen calling a specific LLM, you may encounter a message like this:\ncocommit --model llama3-8b-8192 --model_provider groq\n\nUnable to import langchain_groq. Please install with `pip install -U langchain-groq`\n\nTo resolve this, execute the suggested pip install command. Since Cocommit supports a wide variety of LLMs, dependencies are installed only when needed.\nUsage\nCocommit interacts with Large Language Models (LLMs) through an abstraction layer provided by LangChain. This allows you to use any LLM provider supported by LangChain’s init_chat_model function.\nExample: Using OpenAI\nTo use OpenAI, set your API key as the OPENAI_API_KEY environment variable. Alternatively, you can provide the key via the command line using the --api_key <your key> option:\ncocommit --model_provider openai --model gpt-4o\n\nNote: On the first run, you may need to install additional dependencies by running: pip install -U langchain-openai.\nSimplifying OpenAI Usage with Shortcuts\nCocommit provides shortcuts for common LLM providers and models, allowing you to avoid specifying every parameter manually.\nEnsure your chosen LLM provider is authorized (e.g., OpenAI API key or AWS credentials).\nRun:\ncocommit -s NAME\n\nFor example, if OPENAI_API_KEY is set:\ncocommit -s gpt4o\n\nThis command is equivalent to the full OpenAI GPT-4o example above.\nExample: Using Claude 3.7 on Bedrock\nBefore using Amazon Bedrock, ensure that:\n\nThe Claude 3.7 model is enabled in your AWS account (region: us-east-1)\nYou have valid credentials to access the model (typically configured in ~/.aws/credentials or via environment variables; refer to AWS documentation for details)\n\nTo analyze and enhance the last commit message in a Git repository, run:\ncocommit --model_provider bedrock --model us.anthropic.claude-3-7-sonnet-20250219-v1:0 --region us-east-1\n\nTo simplify execution for future use, save the above command in a shell script.\nSimplifying Bedrock Claude 3.7 Usage with Shortcuts\nIf AWS credentials are configured and Claude 3.7 is enabled in us-east-1, run:\ncocommit -s bedrock-claude37\n\nThis command is equivalent to the previous Bedrock example.\nViewing Available Shortcuts\nTo see all available shortcuts, run:\ncocommit --show-shortcuts\n\nIf a shortcut you need is missing, consider contributing! See the Contributing Guide for details.\nUsing Other LLMs\nCocommit leverages LangChain’s init_chat_model function to call different LLMs. Command-line arguments map directly to its parameters.\n\nThe --model parameter corresponds to the model argument in init_chat_model. It's the first positional parameter in LangChain's documentation.\nOther command-line parameters are passed directly to init_chat_model (ensure you use _ instead of - when required by LangChain’s documentation).\n\nRecommended usage: Always specify --model and --model_provider explicitly, unless using a shortcut.\n\ninit_chat_model documentation\nmodels (certain examples demonstrate the use of  init_chat_model  with its required parameters)\n\nUseful CLI Options\nCocommit supports debugging features, including:\n\nViewing the raw LLM prompt\nDisplaying the raw LLM response\n\nTo explore available options, run:\ncocommit --help\n\nContributing\nContributions are appreciated! If you'd like to get started, please review the contributing guidelines.\nLicense\nThis project is licensed under the MIT License.",
    "summary": {
      "en": "**Cocommit: A Tool for Enhancing Git Commits**\n\nCocommit is a command-line tool designed to improve the quality of Git commit messages using a Large Language Model (LLM) of your choice. It analyzes the most recent commit message and suggests improvements, pointing out both strengths and areas for enhancement. \n\n### Key Features:\n- Works with any LLM you prefer.\n- Easy to integrate into your development process.\n- Allows customization to fit specific project needs.\n- A new version, Cocommit v2, is in development with additional features.\n\n### How to Use Cocommit:\n1. **Installation**: \n   - Install it via pip: `pip install cocommit`.\n   - You can also install from source for customization.\n\n2. **Basic Usage**: \n   - After making changes, use `git add .` and `git commit`.\n   - Run `cocommit -s <model>` to analyze and enhance the commit message.\n\n3. **Examples**:\n   - For OpenAI: Set your API key and run `cocommit --model_provider openai --model gpt-4o`.\n   - For Claude 3.7: Ensure it’s enabled in your AWS account and run the appropriate command.\n\n4. **Shortcuts**: \n   - Cocommit offers shortcuts for common LLMs to simplify usage.\n   - To view available shortcuts, use `cocommit --show-shortcuts`.\n\n5. **Debugging**: \n   - Cocommit includes options to view the raw LLM prompt and response for troubleshooting.\n\n### Contribution and License:\n- Contributions are welcome, and the project is licensed under the MIT License.\n\nCocommit is a valuable tool for developers looking to enhance their commit quality efficiently.",
      "ko": "Cocommit은 Git 커밋 메시지의 품질을 향상시키기 위해 설계된 명령줄 도구입니다. 사용자가 선택한 대형 언어 모델(LLM)을 활용하여 가장 최근의 커밋 메시지를 분석하고 개선점을 제안합니다. 이 도구는 강점과 개선이 필요한 부분을 모두 지적합니다.\n\nCocommit의 주요 기능은 사용자가 선호하는 모든 LLM과 함께 작동하며, 개발 과정에 쉽게 통합할 수 있습니다. 특정 프로젝트의 요구에 맞게 사용자 정의할 수 있는 기능도 제공합니다. 현재 Cocommit v2 버전이 개발 중이며, 추가 기능이 포함될 예정입니다.\n\nCocommit을 사용하는 방법은 간단합니다. 먼저, pip를 통해 설치할 수 있습니다. 설치 명령어는 `pip install cocommit`입니다. 사용자 정의를 원할 경우 소스에서 직접 설치할 수도 있습니다. 기본 사용법은 변경 사항을 만든 후 `git add .`와 `git commit`을 실행하고, `cocommit -s <모델>` 명령어로 커밋 메시지를 분석하고 개선하는 것입니다.\n\n예를 들어 OpenAI를 사용할 경우 API 키를 설정한 후 `cocommit --model_provider openai --model gpt-4o` 명령어를 실행하면 됩니다. Claude 3.7을 사용할 때는 AWS 계정에서 활성화되어 있는지 확인한 후 적절한 명령어를 실행하면 됩니다. Cocommit은 일반적인 LLM을 위한 단축키를 제공하여 사용을 간편하게 합니다. 사용 가능한 단축키를 보려면 `cocommit --show-shortcuts` 명령어를 사용하면 됩니다.\n\n또한 Cocommit은 문제 해결을 위한 원시 LLM 프롬프트와 응답을 볼 수 있는 옵션도 포함되어 있습니다. 기여는 환영하며, 이 프로젝트는 MIT 라이센스 하에 운영됩니다. Cocommit은 개발자들이 커밋 품질을 효율적으로 향상시키는 데 유용한 도구입니다.",
      "ja": "Cocommitは、選択した大規模言語モデル（LLM）を使用してGitのコミットメッセージの質を向上させるために設計されたコマンドラインツールです。このツールは、最新のコミットメッセージを分析し、改善点を提案します。強みや改善が必要な部分を指摘することで、より良いコミットメッセージの作成をサポートします。\n\nCocommitの主な特徴には、好みのLLMと連携できること、開発プロセスへの統合が簡単であること、特定のプロジェクトのニーズに合わせてカスタマイズできることがあります。また、新しいバージョンであるCocommit v2も開発中で、追加機能が予定されています。\n\nCocommitの使い方は簡単です。まず、インストールはpipを使って行います。コマンドは「pip install cocommit」です。カスタマイズが必要な場合は、ソースからインストールすることも可能です。基本的な使用方法としては、変更を加えた後に「git add .」と「git commit」を実行し、その後「cocommit -s <model>」を使ってコミットメッセージを分析し、改善を図ります。\n\n具体例として、OpenAIを使用する場合はAPIキーを設定し、「cocommit --model_provider openai --model gpt-4o」を実行します。Claude 3.7を使用する場合は、AWSアカウントで有効にしてから適切なコマンドを実行します。また、Cocommitは一般的なLLM用のショートカットを提供しており、使用を簡素化します。利用可能なショートカットを確認するには「cocommit --show-shortcuts」を使います。デバッグ機能もあり、LLMの生のプロンプトや応答を表示してトラブルシューティングが可能です。\n\nCocommitへの貢献は歓迎されており、プロジェクトはMITライセンスのもとで公開されています。Cocommitは、開発者が効率的にコミットの質を向上させるための貴重なツールです。"
    }
  },
  {
    "id": "aab10c3ec8409e75",
    "title": {
      "en": "The Gang of Four is wrong and you don't understand delegation (2012)",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://www.saturnflyer.com/blog/the-gang-of-four-is-wrong-and-you-dont-understand-delegation",
    "score": 9,
    "by": "Tomte",
    "time": 1742996589,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "8f66d681a53dadcd",
    "title": {
      "en": "Deciphering language processing in the human brain through LLM representations",
      "ko": "인간 뇌의 언어 해독하기",
      "ja": "脳の言語解析法"
    },
    "type": "story",
    "url": "https://research.google/blog/deciphering-language-processing-in-the-human-brain-through-llm-representations/",
    "score": 175,
    "by": "Korling",
    "time": 1742582677,
    "content": "Home\n\n            Blog\n\n        Deciphering language processing in the human brain through LLM representations\n\n            March 21, 2025Mariano Schain, Software Engineer, and Ariel Goldstein, Visiting Researcher, Google Research\n\nLarge Language Models (LLMs) optimized for predicting subsequent utterances and adapting to tasks using contextual embeddings can process natural language at a level close to human proficiency. This study shows that neural activity in the human brain aligns linearly with the internal contextual embeddings of speech and language within large language models (LLMs) as they process everyday conversations.\n\nQuick links\n\n                        Paper\n\n                    Share\n\n              Copy link\n\n              ×\n\nCopy link\n\n              ×\n\nHow does the human brain process natural language during everyday conversations? Theoretically, large language models (LLMs) and symbolic psycholinguistic models of human language provide a fundamentally different computational framework for coding natural language. Large language models do not depend on symbolic parts of speech or syntactic rules. Instead, they utilize simple self-supervised objectives, such as next-word prediction and generation enhanced by reinforcement learning. This allows them to produce context-specific linguistic outputs drawn from real-world text corpora, effectively encoding the statistical structure of natural speech (sounds) and language (words) into a multidimensional embedding space.Inspired by the success of LLMs, our team at Google Research, in collaboration with Princeton University, NYU, and HUJI, sought to explore the similarities and differences in how the human brain and deep language models process natural language to achieve their remarkable capabilities. Through a series of studies over the past five years, we explored the similarity between the internal representations (embeddings) of specific deep learning models and human brain neural activity during natural free-flowing conversations, demonstrating the power of deep language model’s embeddings to act as a framework for understanding how the human brain processes language. We demonstrate that the word-level internal embeddings generated by deep language models align with the neural activity patterns in established brain regions associated with speech comprehension and production in the human brain.\n\nSimilar embedding-based representations of language.Our most recent study, published in Nature Human Behaviour, investigated the alignment between the internal representations in a Transformer-based speech-to-text model and the neural processing sequence in the human brain during real-life conversations. In the study, we analyzed neural activity recorded using intracranial electrodes during spontaneous conversations. We compared patterns of neural activity with the internal representations — embeddings — generated by the Whisper speech-to-text model, focusing on how the model's linguistic features aligned with the brain's natural speech processing.For every word heard (during speech comprehension) or spoken (during speech production), two types of embeddings were extracted from the speech-to-text model — speech embeddings from the model’s speech encoder and word-based language embeddings from the model's decoder. A linear transformation was estimated to predict the brain’s neural signals from the speech-to-text embeddings for each word in each conversation. The study revealed a remarkable alignment between the neural activity in the human brain's speech areas and the model's speech embeddings and between the neural activity in the brain’s language area and the model's language embeddings. The alignment is illustrated in the following animation, modeling the sequence of the brain’s neural responses to subjects’ language comprehension:\n\nplay silent looping video\n                  pause silent looping video\n\n        Sequence of the brain’s neural responses to subjects' language comprehension as they listen to the sentence “How are you doing?”.\n\nAs the listener processes the incoming spoken words, we observe a sequence of neural responses: Initially, as each word is articulated, speech embeddings enable us to predict cortical activity in speech areas along the superior temporal gyrus (STG). A few hundred milliseconds later, when the listener starts to decode the meaning of the words, language embeddings predict cortical activity in Broca’s area (located in the inferior frontal gyrus; IFG).Turning to participants' production, we observe a different (reversed!) sequence of neural responses:\n\nplay silent looping video\n                  pause silent looping video\n\n        Sequence of neural responses to subjects’ language production as they answer “feeling fantastic\".\n\nLooking at this alignment more closely, about 500 milliseconds before articulating the word (as the subject prepares to articulate the next word), language embeddings (depicted in blue) predict cortical activity in Broca’s area. A few hundred milliseconds later (still before word onset), speech embeddings (depicted in red) predict neural activity in the motor cortex (MC) as the speaker plans the articulatory speech sequence. Finally, after the speaker articulates the word, speech embeddings predict the neural activity in the STG auditory areas as the listener listens to their own voice. This dynamic reflects the sequence of neural processing, starting with planning what to say in language areas, then how to articulate it in motor areas, and finally monitoring what was spoken in perceptual speech areas.The quantitative results of the whole-brain analysis are illustrated in figure below: for each word, given its speech embeddings (red) and language embedding (blue), we predicted the neural response in each electrode at time lags ranging from -2 seconds before to +2 seconds after the word onset (x-axis value of 0 in the figure). This was done during speech production (left panel) and speech comprehension (right panel). The related graphs illustrate the accuracy of our predictions of neural activity (correlation) for all words as a function of the lag in the electrodes across various brain regions.\n\nFitting speech and language embeddings to human brain signals at production and comprehension.\n\nDuring speech production, it is evident that language embeddings (blue) in the IFG peaked before speech embeddings (red) peaked in the sensorimotor area, followed by the peak of speech encoding in the STG. In contrast, during speech comprehension, the peak encoding shifted to after the word onset, with speech embeddings (red) in the STG peaking significantly before language encoding (blue) in the IFG.All in all, our findings suggest that the speech-to-text model embeddings provide a cohesive framework for understanding the neural basis of processing language during natural conversations. Surprisingly, while Whisper was developed solely for speech recognition, without considering how the brain processes language, we found that its internal representations align with neural activity during natural conversations. This alignment was not guaranteed — a negative result would have shown little to no correspondence between the embeddings and neural signals, indicating that the model's representations did not capture the brain's language processing mechanisms.A particularly intriguing concept revealed by the alignment between LLMs and the human brain is the notion of a \"soft hierarchy\" in neural processing. Although regions of the brain involved in language, such as the IFG, tend to prioritize word-level semantic and syntactic information — as indicated by stronger alignment with language embeddings (blue) — they also capture lower-level auditory features, which is evident from the lower yet significant alignment with speech embeddings (red). Conversely, lower-order speech areas such as the STG tend to prioritize acoustic and phonemic processing — as indicated by stronger alignment with speech embeddings (red) — they also capture word-level information, evident from the lower yet significant alignment with language embeddings (blue).\n\nShared objectives and geometry between LLMs and the human brainLLMs are trained to process natural language by using a simple objective: predicting the next word in a sequence. In a paper published in Nature Neuroscience, we discovered that, similar to LLMs, the language areas of a listener’s brain attempt to predict the next word before it is spoken. Furthermore, like LLMs, listeners' confidence in their predictions before the word’s onset modifies their surprise level (prediction error) after the word is articulated. These findings provide compelling new evidence for fundamental computational principles of pre-onset prediction, post-onset surprise, and embedding-based contextual representation shared by autoregressive LLMs and the human brain. In another paper published in Nature Communications, the team also discovered that the relation among words in natural language, as captured by the geometry of the embedding space of an LLM, is aligned with the geometry of the representation induced by the brain (i.e., brain embeddings) in language areas.\n\nDifferences between how LLMs and the human brain process natural languageWhile the human brain and Transformer-based LLMs share fundamental computational principles in processing natural language, their underlying neural circuit architectures are markedly different. For example, in a follow-up study, we investigated how information is processed across layers in Transformer-based LLMs compared to the human brain. The team found that while the non-linear transformations across layers are similar in LLMs and language areas in the human brain, the implementations differ significantly. Unlike the Transformer architecture, which processes hundreds to thousands of words simultaneously, the language areas appear to analyze language serially, word by word, recurrently, and temporally.\n\nSummary and future directionsThe accumulated evidence from the team’s work uncovered several shared computational principles between how the human brain and deep learning models process natural language. These findings indicate that deep learning models could offer a new computational framework for understanding the brain's neural code for processing natural language based on principles of statistical learning, blind optimization, and a direct fit to nature. At the same time, there are significant differences between the neural architecture, types and scale of linguistic data, the training protocols of Transformer-based language models, and the biological structure and developmental stages through which the human brain naturally acquires language in social settings environments. Moving forward, our goal is to create innovative, biologically inspired artificial neural networks that have improved capabilities for processing information and functioning in the real world. We plan to achieve this by adapting neural architecture, learning protocols, and training data that better match human experiences.\n\nAcknowledgmentsThe work described is the result of Google Research's long-term collaboration with the Hasson Lab at the Neuroscience Institute and the Psychology Department at Princeton University, the DeepCognitionLab at the Hebrew University Business School and Cognitive Department, and researchers from the NYU Langone Comprehensive Epilepsy Center.\n\nLabels:\n\n            General Science\n\n            Health & Bioscience\n\n            Natural Language Processing\n\n            Speech Processing\n\nQuick links\n\n                        Paper\n\n                    Share\n\n              Copy link\n\n              ×\n\nCopy link\n\n              ×\n\nOther posts of interest\n\n    March 20, 2025\n\n    Loss of Pulse Detection on the Google Pixel Watch 3\n\n                    Health & Bioscience\n\n                    ·\n\n                    Mobile Systems\n\n                    ·\n\n                    Product\n\n    March 18, 2025\n\n    Generating synthetic data with differentially private LLM inference\n\n                    Machine Intelligence\n\n                    ·\n\n                    Natural Language Processing\n\n                    ·\n\n                    Security, Privacy and Abuse Prevention\n\n    March 6, 2025\n\n    From diagnosis to treatment: Advancing AMIE for longitudinal disease management\n\n                    Generative AI\n\n                    ·\n\n                    Health & Bioscience\n\nFollow us\n\nAbout Google\n\n                        Google Products\n\n                        Privacy\n\n                        Terms\n\n                        Help\n\n                            Submit feedback",
    "summary": {
      "en": "The article discusses a study that explores how the human brain processes natural language and how this relates to Large Language Models (LLMs). Researchers from Google and various universities found that neural activity in the brain aligns closely with the internal representations (embeddings) used by LLMs during everyday conversations.\n\nKey Points:\n\n1. **LLMs and Language Processing**: LLMs are designed to predict the next word in a sequence and can process language similarly to humans, but they do not use traditional grammar rules.\n\n2. **Research Findings**: The study demonstrated that the internal embeddings from a speech-to-text model align with neural activity in the human brain. This means that as people listen or speak, the brain's responses can be predicted by the model's embeddings.\n\n3. **Neural Response Sequence**: During listening, the brain first processes the sound of words, followed by understanding their meaning. In speaking, the brain plans what to say before articulating the words.\n\n4. **Shared Principles**: Both LLMs and the human brain share computational principles, such as predicting upcoming words and adjusting responses based on prior predictions.\n\n5. **Differences**: Despite similarities, the brain processes language differently than LLMs, handling information one word at a time rather than all at once.\n\n6. **Future Research**: The goal is to develop more advanced artificial neural networks inspired by how the human brain works, improving their ability to process language in real-world contexts.\n\nOverall, the findings suggest that LLMs can help enhance our understanding of human language processing, while also highlighting important differences between artificial and biological systems.",
      "ko": "이 기사는 인간의 뇌가 자연어를 처리하는 방식과 이것이 대형 언어 모델(LLMs)과 어떻게 관련되는지를 탐구한 연구에 대해 다룹니다. 구글과 여러 대학의 연구자들은 뇌의 신경 활동이 일상 대화 중 LLM이 사용하는 내부 표현(임베딩)과 밀접하게 일치한다는 사실을 발견했습니다.\n\nLLM은 다음 단어를 예측하도록 설계되어 있으며, 인간과 유사하게 언어를 처리할 수 있지만 전통적인 문법 규칙을 사용하지는 않습니다. 연구 결과, 음성을 텍스트로 변환하는 모델의 내부 임베딩이 인간의 뇌에서 발생하는 신경 활동과 일치한다는 것이 입증되었습니다. 이는 사람들이 듣거나 말할 때, 뇌의 반응이 모델의 임베딩으로 예측될 수 있음을 의미합니다.\n\n듣는 동안 뇌는 먼저 단어의 소리를 처리하고, 그 다음에 의미를 이해합니다. 말을 할 때는 단어를 발음하기 전에 무엇을 말할지 계획합니다. LLM과 인간의 뇌는 다가오는 단어를 예측하고 이전 예측에 따라 반응을 조정하는 등의 계산 원리를 공유합니다. \n\n하지만 비슷한 점이 있음에도 불구하고, 뇌는 LLM과는 다르게 언어를 처리하며, 정보를 한 번에 모두 처리하는 것이 아니라 한 단어씩 처리합니다. 앞으로의 연구 목표는 인간의 뇌 작동 방식을 바탕으로 더 발전된 인공 신경망을 개발하여 실제 상황에서 언어를 처리하는 능력을 향상시키는 것입니다.\n\n이 연구 결과는 LLM이 인간의 언어 처리 이해를 높이는 데 도움을 줄 수 있음을 시사하며, 인공 시스템과 생물학적 시스템 간의 중요한 차이점도 강조합니다.",
      "ja": "この記事では、人間の脳が自然言語をどのように処理するか、そしてそれが大規模言語モデル（LLM）とどのように関連しているかを探る研究について述べています。Googleやさまざまな大学の研究者たちは、脳内の神経活動が日常会話中にLLMが使用する内部表現（エンベディング）と密接に一致することを発見しました。\n\nLLMは、文の中で次に来る単語を予測するように設計されており、人間と同様に言語を処理できますが、従来の文法ルールは使用しません。この研究では、音声からテキストへのモデルの内部エンベディングが人間の脳の神経活動と一致することが示されました。つまり、人々が聞いたり話したりする際に、脳の反応はモデルのエンベディングによって予測できるということです。\n\n聞くとき、脳はまず単語の音を処理し、その後に意味を理解します。話すときは、言葉を発する前に何を言うかを計画します。LLMと人間の脳は、次の単語を予測し、以前の予測に基づいて反応を調整するなど、計算の原則を共有しています。\n\nただし、脳はLLMとは異なり、情報を一度に処理するのではなく、単語を一つずつ処理します。今後の研究の目標は、人間の脳の働きにインスパイアされたより高度な人工ニューラルネットワークを開発し、実際の文脈での言語処理能力を向上させることです。\n\nこれらの発見は、LLMが人間の言語処理の理解を深める手助けになる可能性がある一方で、人工システムと生物学的システムの重要な違いも浮き彫りにしています。"
    }
  },
  {
    "id": "8be6bb17aa359e6c",
    "title": {
      "en": "Kylie Minogue song about a typeface",
      "ko": "타입페이스의 멜로디",
      "ja": "フォントの歌"
    },
    "type": "story",
    "url": "https://abcdinamo.com/news/german-bold-italic",
    "score": 237,
    "by": "fauverism",
    "time": 1742921469,
    "content": "“I Contrast, It’s Cool”: When Kylie Minogue Was a FontVideo is loading ...Kylie Minogue announces “I am a typeface” in a 1997 song she made with producer Towa Tei. As this lyric suggests, the techno-pop track in question, “GBI (German Bold Italic)”, is delivered from the perspective of a font. Minogue’s breathy, almost robotic vocals bring the absurdist premise to life, reciting declarations of design compatibility over a minimalist reverb-drenched beat. “You will like my sense of style” is her most oft-repeated refrain.German Bold Italic (three words Minogue intones throughout the track with staccato punctuation) is a real typeface, which was created to accompany the musical release. To develop it, Tei tapped artist Hiro Sugiyama, who had that same year launched the commercial design studio Enlightenment. The high-impact techno typography not only defined the record’s text-centric cover, but a glyph set was made available as a data track on Tei’s Sound Museum CD and also downloadable from both Tei’s and Minogue’s official websites. Extra-thick and geometric, the font had something in common with the heavy black frames that were Tei’s hallmark at the time. Another line from the song: “I contrast, it’s cool.”   When this offbeat track came out, Minogue was one of the biggest pop stars in the world. The Australian “I Should Be So Lucky” singer rose to fame as a teenager in the late 1980s for clear vocals that complemented the precision of disco and dance-pop perfectly. She’s like Donna Summer in that way, a vessel for songs that can be hugely innovative and futuristic without compromising mainstream appeal. By her fifth studio album, the eponymously titled Kylie Minogue (1994), she was starting to show she was curious about experimenting with different sounds and high-concept visuals. In 1995 she collaborated on a murder ballad duet with Nick Cave, and by the time she joined forces with Tei, she was dating music video director (and Björk ex) Stéphane Sednaoui, who’s often credited with influencing Minogue’s art-pop risk-taking. Sednaoui directed the video for “GBI (German Bold Italic).” In it, Minogue is dressed like a geisha roaming the streets of Tokyo (despite Tei’s involvement, the video no doubt reads today as cultural appropriation.)Tei was a big deal back then too. Originally from Japan, he had moved to New York to study fashion in the 1980s and became one of the founding members, along with Lady Miss Kier and DJ Dmitry, of the dance music group Dee-Lite. Their breakthrough hit, “Groove is In the Heart” (1990), undeniably one of the decade’s defining house music tracks, peaked at #4 on the Billboard Hot 100. A few years before Tei’s collaboration with Minogue, at Dee-Lite’s height, he decided to quit the group and move back to Japan to focus on solo projects — in part because he’d suffered a back injury from a fall which affected his ability to tour. Sound Museum — which “GBI” the song and glyph set feature on — was his second solo album. In addition to Minogue, he recruited an eclectic group of artists for the project, from rappers Biz Markie and Mos Def to bossa nova royalty Bebel Gilberto. “GBI,” however, is the only song about a font.   Leading up to the turn of the millennium, typography trends included a revival of thick, rounded, condensed, futuristic san-serifs from the late ’60s and early ’70s. German Bold Italic feels part of this wave. So does The Powerpuff Girls logo, designed for the TV show which first aired in 1998, a year after Tei and Minogue’s song. In the comments section of fontsinsuse.com, the site’s editor Florian Hardwig compares German Bold Italic to Futura Extra Bold Italic. He points out, however, that while Futura is German, released by the Bauer Foundry in Frankfurt in 1927, Futura Extra Bold isn’t German at all: “It was added by Edwin W. Shaar for Intertype in the US in 1952, based on Paul Renner’s design. The oblique followed in 1955, made by Shaar together with Tommy Thompson.” Another user named Thiago, points out that, rather ironically, the glyph set for German Bold Italic doesn’t support the German language.   Despite being made available for anyone to download (you can still download it via an old version of Minogue’s website, accessible using the Wayback Machine), German Bold Italic’s only documented usage outside of Tei and Minogue’s promo is by artist Cory Arcangel. In 2015, Arcangel used the font for merch he designed for the Brooklyn pop group Wet. Heather grey sweatshirts were screenprinted “WWW. / KANYEWET / .BIZ” in super chunky black all-caps. (The band long used this URL for their website as a cheeky gag, though today the domain is dead.) In an interview with The Fader, Arcangel explained:I’ve used the font a few times in the past for artworks (I showed some drawings on paper watermarked with my name in GBI at my Whitney show in 2011) but I’ve always wanted to use it to make a shirt for a pop group… one pop group used to advertise the next. Also it’s a sick classic vector techno font, and super rare these days.It’s a style that’s less rare today. But still, German Bold Italic in particular, I’d love to see it more.Minogue sings, “Let me adorn you / The bold design of you.”\n\nMore\nClaire Marie Healy on the Coquette Font\nOur New Show on NTS Radio\n\nWhat’s in Your Bag\n            That bag is empty 😢",
    "summary": {
      "en": "In the 1997 song \"GBI (German Bold Italic),\" Kylie Minogue humorously declares, “I am a typeface,” presenting the track from the perspective of a font. The song features her breathy vocals and minimalist beats, frequently repeating phrases about style and design compatibility. The German Bold Italic font was created specifically for this song by producer Towa Tei and artist Hiro Sugiyama, and it became part of the album's promotional materials.\n\nAt the time, Minogue was a major pop star known for her dance-pop hits. She began experimenting with different sounds and visuals in her career, influenced by her relationship with music video director Stéphane Sednaoui. The music video for \"GBI\" features Minogue in a geisha-inspired outfit in Tokyo, but it has been criticized for cultural appropriation.\n\nTowa Tei, a notable figure in the music scene, had previously been part of the group Dee-Lite, known for their hit \"Groove is In the Heart.\" \"GBI\" is unique as it is the only song about a font. The font itself aligns with typography trends of the late '90s, which favored thick, bold designs.\n\nAlthough German Bold Italic was available for public download, its only significant use outside of Minogue and Tei’s work was by artist Cory Arcangel for merchandise related to the band Wet. Arcangel appreciates the font for its retro techno aesthetic and rarity. Overall, the song and the font reflect a playful intersection of music and design.",
      "ko": "1997년의 노래 \"GBI (German Bold Italic)\"에서 카일리 미노그는 유머러스하게 \"나는 글꼴이다\"라고 선언하며, 글꼴의 시각에서 곡을 표현합니다. 이 곡은 그녀의 부드러운 보컬과 미니멀한 비트로 구성되어 있으며, 스타일과 디자인의 조화에 대한 문구를 자주 반복합니다. 독일어 볼드 이탤릭 글꼴은 프로듀서 토와 테이와 아티스트 히로 스기야마가 이 곡을 위해 특별히 제작하였고, 앨범의 홍보 자료에도 사용되었습니다.\n\n당시 미노그는 댄스 팝 히트곡으로 유명한 주요 팝 스타였습니다. 그녀는 음악 비디오 감독 스테판 세드나우이와의 관계에서 영향을 받아 다양한 사운드와 비주얼을 실험하기 시작했습니다. \"GBI\"의 뮤직 비디오는 도쿄에서 게이샤에서 영감을 받은 의상을 입은 미노그를 보여주지만, 문화적 전유에 대한 비판을 받기도 했습니다.\n\n음악계에서 주목받는 인물인 토와 테이는 이전에 히트곡 \"Groove is In the Heart\"로 알려진 그룹 디라이트의 일원이었습니다. \"GBI\"는 글꼴에 관한 유일한 노래로 독특합니다. 이 글꼴은 90년대 후반의 타이포그래피 트렌드와 일치하며, 두껍고 볼드한 디자인을 선호했습니다.\n\n독일어 볼드 이탤릭 글꼴은 대중이 다운로드할 수 있었지만, 미노그와 테이의 작업 외에 주목할 만한 사용 사례는 아티스트 코리 아르켄젤이 밴드 웻 관련 상품에 사용한 것이 전부입니다. 아르켄젤은 이 글꼴의 복고풍 테크노 미학과 희소성을 높이 평가합니다. 전반적으로 이 노래와 글꼴은 음악과 디자인의 유쾌한 교차점을 반영합니다.",
      "ja": "1997年の曲「GBI (German Bold Italic)」で、カイリー・ミノーグはユーモラスに「私はフォントです」と宣言し、フォントの視点から曲を展開しています。この曲では、彼女の柔らかいボーカルとミニマルなビートが特徴で、スタイルやデザインの互換性についてのフレーズが繰り返し歌われています。ドイツ語のボールドイタリックフォントは、プロデューサーのテイ・トワとアーティストの杉山裕によってこの曲のために特別に作られ、アルバムのプロモーション素材の一部となりました。\n\n当時、ミノーグはダンス・ポップのヒット曲で知られる大物ポップスターでした。彼女は音楽ビデオ監督のステファン・セドナウイとの関係から影響を受け、さまざまな音やビジュアルを試みるようになりました。「GBI」のミュージックビデオでは、ミノーグが東京で芸者風の衣装を着て登場しますが、文化の盗用として批判されています。\n\n音楽シーンで著名なテイ・トワは、以前にヒット曲「Groove is In the Heart」で知られるグループDee-Liteのメンバーでした。「GBI」はフォントについての唯一の曲であり、フォント自体は90年代後半のタイポグラフィのトレンドに合致しており、太くて大胆なデザインが好まれていました。\n\nドイツ語のボールドイタリックは一般にダウンロード可能でしたが、ミノーグとテイの作品以外での重要な使用例は、アーティストのコリー・アーカンジェルによるバンドWetの関連商品での利用のみでした。アーカンジェルは、このフォントのレトロなテクノ美学と希少性を評価しています。全体として、この曲とフォントは音楽とデザインの遊び心あふれる交差点を反映しています。"
    }
  },
  {
    "id": "b7abe683ca73c9af",
    "title": {
      "en": "Why Is It Lovely",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://www.solipsys.co.uk/new/WhyIsItLovely.html",
    "score": 17,
    "by": "akbarnama",
    "time": 1742975396,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "0ed1890c1786ba1c",
    "title": {
      "en": "C++26 Expansion Tricks",
      "ko": "C++26 확장 비법",
      "ja": "C++26の拡張術"
    },
    "type": "story",
    "url": "https://pydong.org/posts/ExpansionTricks/",
    "score": 4,
    "by": "HeliumHydride",
    "time": 1742687472,
    "content": "C++26 Expansion Tricks  Posted Mar 21, 2025   Updated Mar 22, 2025   By  Che    12 min readP1306 gives us compile time repetition of a statement for each element of a range - what if we instead want the elements as a pack without introducing a new function scope?In this blog post we’ll look at the expand helper, expansion statements and how arbitrary ranges can be made decomposable via structured bindings to reduce the need for IILEs.Element-wise expansionThe expand patternThe reflection features introduced in P2996 by themselves are sufficient to iterate over a compile time range. The paper introduces a helper expand for this purpose, here’s a slightly modified version:  1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\ntemplate <auto... Elts>\nstruct Replicator {\n    template <typename F>\n    constexpr void operator>>(F fnc) const {\n        (fnc.template operator()<Elts>(), ...);\n    }\n};\n\ntemplate <auto... Elts>\nconstexpr inline Replicator<Elts...> replicator{};\n\ntemplate <std::ranges::range R>\nconsteval std::meta::info expand(R const& range) {\n    std::vector<std::meta::info> args{};\n    for (auto item : range) {\n        args.push_back(std::meta::reflect_value(item));\n    }\n    return substitute(^^replicator, args);\n}\nThis allows us to write the following code. Note that Member needs to be a constant to be usable in a splice.  1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\ntemplate <typename T>\nvoid print_members(T const& obj) {\n    [:expand(nonstatic_data_members_of(^^T)):]\n    >> [&]<auto Member>{\n        std::println(\"{}: {}\", identifier_of(Member), obj.[:Member:]);\n    };\n}\n\nstruct Test {\n    int x;\n    char p;\n};\n\nint main() {\n    print_members(Test{42, 'y'});\n    // prints:\n    // x: 42\n    // p: y\n}\nRun on Compiler ExplorerEarly returnThis does not yet match loop semantics closely enough. continue can be expressed as return; but we cannot yet express break or return a value.First, let’s introduce a way to stop iteration at any point. The short-circuiting property of && and || is useful for this, we just need to let the lambda return a bool to indicate whether we should keep iterating.  1\n2\n3\n4\n5\n6\n7\ntemplate <auto... Elts>\nstruct Replicator {\n    template <typename F>\n    constexpr void operator>>(F fnc) const {\n        (fnc.template operator()<Elts>() && ...);\n    }\n};\nTo reuse the example from before, we can now let it stop as soon as some arbitrary condition is met. In the following example we stop as soon as a member named x is reached - therefore the second member of Test will not be printed.  1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\ntemplate <typename T>\nvoid print_members(T const& obj) {\n    [:expand(nonstatic_data_members_of(^^T)):]\n    >> [&]<auto Member>{\n        std::println(\"{}: {}\", identifier_of(Member), obj.[:Member:]);\n\n        // stop after we've reached a member named \"p\"\n        return identifier_of(Member) == \"p\";\n    };\n}\n\nstruct Test {\n    int x;\n    char p;\n};\n\nint main() {\n    print_members(Test{42, 'y'});\n    // prints:\n    // x: 42\n}\nRun on Compiler ExplorerReturning valuesReturning values is a little more difficult. To do this let’s circle back a bit - instead of expressing our intent to continue iteration by returning a bool, we stop iterating once the first evaluation of the lambda returns something other than a void.So, let’s first define a metafunction to retrieve the first non-void type in a pack of types.  1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\ntemplate <typename...>\nstruct FirstNonVoid;\n\ntemplate <>\nstruct FirstNonVoid<> {\n    using type = void;\n};\n\ntemplate <typename T, typename... Ts>\nstruct FirstNonVoid<T, Ts...> {\n    using type = std::conditional_t<\n        std::is_void_v<T>,\n        typename FirstNonVoid<Ts...>::type,\n        T\n    >;\n};\n\ntemplate <typename... Ts>\nusing first_non_void = typename FirstNonVoid<Ts...>::type;\nWith this utility we can now tell if any specialization of fnc’s operator() returned something other than void. This unfortunately matters since void is not a regular type.Let’s first do the trivial case where no F::operator() specialization returns a value. This also means that no early return is going to happen - we can safely fold over , instead.  1\n2\n3\n4\n5\n6\n7\n8\n9\ntemplate <typename F>\nconstexpr auto operator>>(F fnc) const {\n    using ret_t = first_non_void<decltype(fnc.template operator()<Elts>())...>;\n    if constexpr (std::is_void_v<ret_t>){\n        (fnc.template operator()<Elts>(), ...);\n    } else {\n      // ...\n    }\n}\nReturning a value is a little more involved.We already know that sooner or later a F::operator() specialization will return something other than a void, so we can prepare an object of this type to be returned later. To avoid a default-constructibility requirement on the return type, the return object can be wrapped in a union. Note however that this will imply that the return type must be copy-constructible.This issue can also be worked around, but the primary point here is to see just how much code is required to roughly emulate expansion statements.  1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\ntemplate <typename F>\nconstexpr auto operator>>(F fnc) const {\n    using ret_t = first_non_void<decltype(fnc.template operator()<Elts>())...>;\n    if constexpr (std::is_void_v<ret_t>){\n        (fnc.template operator()<Elts>(), ...);\n    } else {\n        union {\n            char dummy;\n            ret_t obj;\n        } ret {};\n\n        if(!(invoke<Elts>(fnc, &ret.obj) && ...)){\n            return ret.obj;\n        } else {\n            std::unreachable();\n        }\n    }\n}\nTo keep using the short-circuiting property of &&, another helper invoke must be introduced. If the requested F::operator() specialization returned void, invoke shall return true. Otherwise it must return false to stop iteration and finally copy construct ret.obj from the return value.  1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\ntemplate <auto E, typename F, typename R>\nconstexpr bool invoke(F fnc, R* result) {\n    using return_type = decltype(fnc.template operator()<E>());\n\n    if constexpr (std::is_void_v<return_type>){\n        fnc.template operator()<E>();\n        return true;\n    } else {\n        std::construct_at(result, fnc.template operator()<E>());\n        return false;\n    }\n}\nFinally we can write the following code.  1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\ntemplate <typename T>\nauto get_p(T const& obj) {\n    return [:expand(nonstatic_data_members_of(^^T)):]\n    >> [&]<auto Member>{\n        if constexpr (identifier_of(Member) == \"p\") {\n            return obj.[:Member:];\n        }\n  };\n}\n\nstruct Test {\n    int x;\n    char p;\n};\n\nint main() {\n    std::print(\"{}\", get_p(Test{42, 'y'}));\n    // prints:\n    // y\n}\nRun on Compiler ExplorerHowever, note that a if constexpr statement must be used to guard the early return.Expansion statementsUnfortunately using expand implies having to use a lambda expression and therefore introduce a new function scope. While this isn’t typically all that problematic, it can for instance cause issues with reflections of function parameters (P3096) since they are only splicable within their corresponding function body.P1306 template for expansion statements allow us to avoid the extra function scope.  1\n2\n3\n4\n5\n6\n7\n-[:expand(some_range):] >> []<auto Elt>{\n-    // ...\n-};\n\n+template for (constexpr auto Elt : define_static_array(some_range)) {\n+    // ...\n+}\nThe define_static_array from P3491 is required because we do not yet have non-transient constexpr allocation. This is unfortunate, but oh well.Amazingly expansion statements also support break, continue and early return.Transforming ranges to packsThe expand patternSo, we’ve established that expansion statements are pretty useful. What if we need the elements as a pack though? We might want to use the elements in a fold expression or expand them into an argument list.To do this, let’s introduce operator->* for Replicator. Unlike operator>> we want to expand all elements into the template argument list of a single call to F::operator().  1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\ntemplate <auto... Elts>\nstruct Replicator {\n    template <typename F>\n    constexpr void operator>>(F fnc) const {\n        (fnc.template operator()<Elts>(), ...);\n    }\n\n    template <typename F>\n    constexpr decltype(auto) operator->*(F fnc) const {\n        return fnc.template operator()<Elts...>();\n    }\n};\nWe can now write  1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\nvoid print_args(auto... args){\n    ((std::cout << args << ' '), ...) << '\\n';\n}\n\ntemplate <typename T>\nvoid print_t(T obj) {\n    [:expand(nonstatic_data_members_of(^^T)):]\n    ->* [&]<auto... Members>{\n        print_args(obj.[:Members:]...);\n    };\n}\n\nstruct Test {\n    int x;\n    char p;\n};\n\nint main() {\n    print_t(Test{42, 'y'});\n    // prints\n    // 42 y\n}\nRun on Compiler ExplorerOperator choiceNote that the choice of operator ->* is mostly arbitrary. It just happens to be a rarely used operator that looks different enough to >> to not confuse the two.You might as well use regular member function templates instead of user-defined operator templates to achieve the following syntax:  1\n2\n3\n[:expand(some-range):].for_each([]<auto Elt>{\n   // ...\n});\nand respectively  1\n2\n3\n[:expand(some-range):].into([]<auto... Elts>{\n   // ...\n});\nStructured bindingsUnfortunately this suffers from the same problem as before - we are introducing another function scope.To get around that, it’s possible to use a structured binding to introduce a pack of the elements within the current scope. For this P1061 Structured Bindings can introduce a Pack and P2686 constexpr structured bindings are essential.Promoting rangesThe simplest way to make an arbitrary range decomposable is to promote it to a constexpr C-style array. Unfortunately define_static_array from P3491 gives us a constexpr span, not the actual array. The underlying machinery is extremely simple though:  1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\ntemplate <typename T, T... Vs>\nconstexpr inline T fixed_array[sizeof...(Vs)]{Vs...};\n\ntemplate <std::ranges::input_range R>\nconsteval std::meta::info promote(R&& iterable) {\n    std::vector args = {^^std::ranges::range_value_t<R>};\n    for (auto element : iterable) {\n        args.push_back(std::meta::reflect_value(element));\n    }\n    return substitute(^^fixed_array, args);\n}\nWith promote in place, we can now write the following code.  1\n2\n3\n4\nvoid foo(int x, char c) {\n    constexpr auto [...Param] = [:promote(parameters_of(^^foo)):];\n    bar([:Param:]...);\n}\nPromoting stringsIn a lot of existing C++(20 and upwards) code you see the following pattern to accept string literals as constant template arguments.  1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\ntemplate <std::size_t N>\nstruct fixed_string {\n   constexpr explicit(false) fixed_string(const char (&str)[N]) noexcept {\n       std::ranges::copy(str, str+N, data);\n   }\n\n   char data[N]{};\n};\n\ntemplate <fixed_string S>\nstruct Test{};\nP2996’s reflect_value does not allow reflecting string literals directly (see P2996) and the way define_static_string is currently specified, it does not help with this either since the generated character array has already decayed to a pointer at that point. Consider the following code:  1\n2\n3\n4\n5\n6\n7\n8\n9\n10\nusing a = Test<\"foo\">; // ok\n\n// error: cannot reflect \"foo\"\nusing b = [:substitute(^^Test, {reflect_value(\"foo\")}):];\n\n// error: cannot deduce N\nusing c = Test<define_static_string(\"foo\")>;\n\n// error: cannot deduce N\nusing d = [:substitute(^^Test, {define_static_string(\"foo\")}):];\nRun on Compiler ExplorerUnfortunately define_static_array cannot be used for this either, since the generated array is wrapped in a constexpr span for extraction.However, with promote this is rather easy to solve.  1\n2\n3\n4\n5\ntemplate <fixed_string S>\nstruct Test{};\n\nusing e = Test<[:promote(\"foo\"):]>; // ok\nusing f = [:substitute(^^Test, {promote(\"foo\")}):]; // ok\nRun on Compiler ExplorerImplementing the tuple protocolAnother way to make something decomposable via structured bindings is to implement the tuple protocol. If you’ve been paying attention you might have noticed the similarity between promote and expand. If Replicator were to implement the tuple protocol, expand would be sufficient.This is very easy to do:  1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\ntemplate <std::size_t Idx, auto... Elts>\nconstexpr auto get(Replicator<Elts...> const&){\n    return Elts...[Idx];\n}\n\ntemplate <auto... Elts>\nstruct std::tuple_size<Replicator<Elts...>>\n    : std::integral_constant<std::size_t, sizeof...(Elts)> {};\n\ntemplate <std::size_t Idx, auto... Elts>\nstruct std::tuple_element<Idx, Replicator<Elts...>> {\n    using type = decltype(Elts...[Idx]);\n};\nNow that Replicator is decomposable, we can finally get rid of the lambda expression.  1\n2\n3\n4\n-[:expand(some_range):] >> []<auto... Elts>{\n-    // ...\n-};\n+constexpr auto [...Elts] = [:expand(some_range):];\nRun on Compiler Explorer. At the time of writing constexpr structured bindings (P2686) are not yet implemented in clang, which is why the example does not make use of it.On a side note, this also means expand is usable in expansion statements and can be used to replace define_static_array.  1\n2\n3\n4\n5\n6\n7\n-template for (constexpr auto Elt : define_static_array(some_range)) {\n-    // ...\n-}\n\n+template for (constexpr auto Elt : [:expand(some_range):]) {\n+    // ...\n+}\nSequencesWhile all of the aforementioned examples make use of reflection features, generating a pack of constants is not actually a new concept.By far the most common range to expand into a constant template parameter pack is a sequence of integers. In fact, this is common enough for C++14 to have introduced std::integer_sequence, std::index_sequence and std::make_index_sequence for this very purpose.In a lot of code we see IILEs being used to retrieve the pack. The following pattern is rather popular:  1\n2\n3\n[]<std::size_t... Idx>(std::index_sequence<Idx...>){\n    // ...\n}(std::make_index_sequence<Count>());\nSince we already have the ability to expand arbitrary ranges through the expand helper, we can simply make use of C++20’s std::ranges::iota_view to generate the sequence.  1\n2\n3\nconsteval std::meta::info sequence(unsigned maximum) {\n    return expand(std::ranges::iota_view{0U, maximum});\n}\nThis now allows us to introduce an integer sequence as a pack as follows.  1\nconstexpr auto [...Idx] = [:sequence(Count):];\nDecomposing integer_sequenceInterestingly, reflection features are not actually needed for this. We could instead implement the tuple protocol for std::integer_sequence in exactly the same way we’ve already done for Replicator.P1789 suggests exactly that, which if accepted would allow us to write the following code.  1\nconstexpr auto [...Idx] = std::make_index_sequence<Count>();\nRun on Compiler Explorer  C++  C++ C++26 reflection tricks TMP metaprogramming This post is licensed under  CC BY 4.0  by the author. Share",
    "summary": {
      "en": "This blog post discusses new features in C++26 that enhance compile-time programming, focusing on the use of expansion tricks to simplify code. Key points include:\n\n1. **Compile-Time Repetition**: Introduced by P1306, this feature allows repeating statements for each element in a range without needing new function scopes.\n\n2. **Element-wise Expansion**: The `expand` helper allows for easy iteration over compile-time ranges, enabling developers to print non-static data members of a structure efficiently.\n\n3. **Early Returns and Short-Circuiting**: The post explains how to implement early returns during iteration using lambda functions, allowing the iteration to stop based on conditions.\n\n4. **Returning Values**: Enhancements allow functions to return values during iteration, which can be done using a union to manage return types.\n\n5. **Expansion Statements**: P1306 allows for a new syntax that avoids additional function scopes, enabling the use of control flow statements like break and continue.\n\n6. **Transforming Ranges to Packs**: The `Replicator` structure can be used to expand elements into a template argument list, simplifying the use of member variables.\n\n7. **Structured Bindings**: New structured bindings in C++26 make it easier to handle packs of elements directly in the current scope.\n\n8. **Promoting Ranges**: The `promote` feature allows arbitrary ranges to be converted into decomposable structures.\n\n9. **Implementing the Tuple Protocol**: By implementing tuple methods for `Replicator`, developers can use structured bindings without needing lambda expressions.\n\n10. **Integer Sequences**: The post also discusses generating integer sequences at compile time using C++20 features and how it can be simplified with the new `expand` capabilities.\n\nOverall, these features streamline metaprogramming and make it easier to work with compile-time constructs in C++.",
      "ko": "이번 블로그 포스트에서는 C++26의 새로운 기능에 대해 다루고 있으며, 코드 단순화를 위한 확장 기법의 사용에 중점을 두고 있습니다. 주요 내용은 다음과 같습니다.\n\n첫 번째로, P1306에서 도입된 컴파일 타임 반복 기능이 있습니다. 이 기능은 새로운 함수 스코프 없이 범위 내의 각 요소에 대해 문장을 반복할 수 있게 해줍니다.\n\n두 번째로, `expand` 헬퍼를 통해 컴파일 타임 범위를 쉽게 반복할 수 있으며, 이를 통해 개발자는 구조체의 비정적 데이터 멤버를 효율적으로 출력할 수 있습니다.\n\n세 번째로, 반복 중 조기 반환과 단축 평가를 구현하는 방법이 설명됩니다. 람다 함수를 사용하여 조건에 따라 반복을 중단할 수 있습니다.\n\n네 번째로, 반복 중에 값을 반환할 수 있는 기능이 향상되었습니다. 이를 위해 반환 타입을 관리하는 유니온을 사용할 수 있습니다.\n\n다섯 번째로, P1306은 추가적인 함수 스코프 없이 제어 흐름 문장인 break와 continue를 사용할 수 있는 새로운 구문을 허용합니다.\n\n여섯 번째로, `Replicator` 구조체를 사용하여 요소를 템플릿 인자 목록으로 확장할 수 있어 멤버 변수를 더 쉽게 사용할 수 있습니다.\n\n일곱 번째로, C++26의 새로운 구조적 바인딩은 현재 스코프에서 요소 패킷을 직접 처리하는 것을 더 쉽게 만들어 줍니다.\n\n여덟 번째로, `promote` 기능을 통해 임의의 범위를 분해 가능한 구조로 변환할 수 있습니다.\n\n아홉 번째로, `Replicator`에 튜플 메서드를 구현함으로써 개발자는 람다 표현식 없이도 구조적 바인딩을 사용할 수 있습니다.\n\n마지막으로, 포스트에서는 C++20 기능을 사용하여 컴파일 타임에 정수 시퀀스를 생성하는 방법과 새로운 `expand` 기능으로 이를 간소화할 수 있는 방법에 대해서도 논의합니다.\n\n이러한 기능들은 메타프로그래밍을 간소화하고 C++에서 컴파일 타임 구조를 다루는 것을 더 쉽게 만들어 줍니다.",
      "ja": "このブログ記事では、C++26の新機能について説明しています。特に、コードを簡素化するための展開トリックを用いたコンパイル時プログラミングの強化に焦点を当てています。\n\nまず、P1306によって導入された「コンパイル時の繰り返し」機能があります。これにより、関数のスコープを新たに作成することなく、範囲内の各要素に対して文を繰り返すことが可能になります。\n\n次に、「要素ごとの展開」についてです。`expand`というヘルパーを使うことで、コンパイル時の範囲を簡単に反復処理でき、開発者は構造体の非静的データメンバーを効率的に表示できます。\n\nまた、イテレーション中に早期リターンを実装する方法も説明されています。ラムダ関数を利用することで、条件に基づいてイテレーションを停止することができます。\n\nさらに、イテレーション中に値を返すことができる機能が強化されました。これは、戻り値の型を管理するために共用体を使用することで実現できます。\n\nP1306では、追加の関数スコープを避ける新しい構文が導入され、breakやcontinueといった制御フロー文を使用できるようになります。\n\n「範囲をパックに変換する」ために、`Replicator`構造体を使用して要素をテンプレート引数リストに展開することができ、メンバ変数の利用が簡素化されます。\n\nC++26の新しい構造化バインディングにより、現在のスコープ内で要素のパックを直接扱うことが容易になります。\n\n「範囲の昇格」機能を使うことで、任意の範囲を分解可能な構造体に変換することができます。\n\n`Replicator`にタプルメソッドを実装することで、開発者はラムダ式を使わずに構造化バインディングを利用できるようになります。\n\n最後に、C++20の機能を使ってコンパイル時に整数列を生成する方法についても触れられており、新しい`expand`機能を使うことで簡素化できることが説明されています。\n\nこれらの機能は、メタプログラミングを効率化し、C++におけるコンパイル時構造の扱いを容易にします。"
    }
  },
  {
    "id": "4f7793a5e80d6336",
    "title": {
      "en": "Whose code am I running in GitHub Actions?",
      "ko": "내 코드, 누구의 것?",
      "ja": "誰のコード？GitHub Actions"
    },
    "type": "story",
    "url": "https://alexwlchan.net/2025/github-actions-audit/",
    "score": 203,
    "by": "ingve",
    "time": 1742923025,
    "content": "Whose code am I running in GitHub Actions?     Tagged with github, shell scripting   Posted  25 March 2025    A week ago, somebody added malicious code to the tj-actions/changed-files GitHub Action. If you used the compromised action, it would leak secrets to your build log. Those build logs are public for public repositories, so anybody could see your secrets. Scary! Mutable vs immutable references This attack was possible because it’s common practice to refer to tags in a GitHub Actions workflow, for example:jobs:\n  changed_files:\n    ...\n    steps:\n      - name: Get changed files\n        id: changed-files\n        uses: tj-actions/changed-files@v2\n      ...At a glance, this looks like an immutable reference to an already-released “version 2” of this action, but actually this is a mutable Git tag. If somebody changes the v2 tag in the tj-actions/changed-files repo to point to a different commit, this action will run different code the next time it runs. If you specify a Git commit ID instead (e.g. a5b3abf), that’s an immutable reference that will run the same code every time. Tags vs commit IDs is a tradeoff between convenience and security. Specifying an exact commit ID means the code won’t change unexpectedly, but tags are easier to read and compare. Do I have any mutable references? I wasn’t worried about this particular attack because I don’t use tj-actions, but I was curious about what other GitHub Actions I’m using. I ran a short shell script in the folder where I have local clones of all my repos: find . -path '*/.github/workflows/*' -type f -name '*.yml' -print0 \\\n  | xargs -0 grep --no-filename \"uses:\" \\\n  | sed 's/\\- uses:/uses:/g' \\\n  | tr '\"' ' ' \\\n  | awk '{print $2}' \\\n  | sed 's/\\r//g' \\\n  | sort \\\n  | uniq --count \\\n  | sort --numeric-sort\n This prints a tally of all the actions I’m using. Here’s a snippet of the output:  1 hashicorp/setup-terraform@v3\n 2 dtolnay/rust-toolchain@v1\n 2 taiki-e/create-gh-release-action@v1\n 2 taiki-e/upload-rust-binary-action@v1\n 4 actions/setup-python@v4\n 6 actions/cache@v4\n 9 ruby/setup-ruby@v1\n31 actions/setup-python@v5\n58 actions/checkout@v4\n I went through the entire list and thought about how much I trust each action and its author.   Is it from a large organisation like actions or ruby? They’re not perfect, but they’re likely to have good security procedures in place to protect against malicious changes.   Is it from an individual developer or small organisation? Here I tend to be more wary, especially if I don’t know the author personally. That’s not to say that individuals can’t have good security, but there’s more variance in the security setup of random developers on the Internet than among big organisations.   Do I need to use somebody else’s action, or could I write my own script to replace it? This is what I generally prefer, especially if I’m only using a small subset of the functionality offered by the action. It’s a bit more work upfront, but then I know exactly what it’s doing and there’s less churn and risk from upstream changes.   I feel pretty good about my list. Most of my actions are from large organisations, and the rest are a few actions specific to my Rust command-line tools which are non-critical toys, where the impact of a compromised GitHub repo would be relatively slight. How this script works This is a classic use of Unix pipelines, where I’m chaining together a bunch of built-in text processing tools. Let’s step through how it works.   find . -path '*/.github/workflows/*' -type f -name '*.yml' -print0    This looks for any GitHub Actions workflow file – any file whose name ends with .yml in a folder like .github/workflows/. It prints a list of filenames, like:  ./alexwlchan.net/.github/workflows/build_site.yml ./books.alexwlchan.net/.github/workflows/build_site.yml ./concurrently/.github/workflows/main.yml   It prints them with a null byte (\\0) between them, which makes it possible to split the filenames in the next step. By default it uses a newline, but a null byte is a bit safer, in case you have filenames which include newline characters.   I know that I always use .yml as a file extension, but if you sometimes use .yaml, you can replace -name '*.yml' with \\( -name '*.yml' -o -name '*.yaml' \\)   I have a bunch of local repos that are clones of open-source projects, and not my code, so I care less about what GitHub Actions they’re using. I excluded them by adding extra -path rules, like -not -path './cpython/*'.    xargs -0 grep --no-filename \"uses:\"    Then we use xargs to go through the filenames one-by-one. The `-0` flag tells it to split on the null byte, and then it runs grep to look for lines that include \"uses:\" – this is how you use an action in your workflow file.   The --no-filename option means this just prints the matching line, and not the name of the file it comes from. Not all of my files are formatted or indented consistently, so the output is quite messy:  - uses: actions/checkout@v4 uses: \"actions/cache@v4\" uses: ruby/setup-ruby@v1   sed 's/\\- uses:/uses:/g' \\    Sometimes there's a leading hyphen, sometimes there isn’t – it depends on whether uses: is the first key in the YAML dictionary. This sed command replaces \"- uses:\" with \"uses:\" to start tidying up the data.  uses: actions/checkout@v4 uses: \"actions/cache@v4\" uses: ruby/setup-ruby@v1  I know sed is a pretty powerful tool for making changes to text, but I only know a couple of simple commands, like this pattern for replacing text: sed 's/old/new/g'.    tr '\"' ' '    Sometimes the name of the action is quoted, sometimes it isn’t. This command removes any double quotes from the output.  uses: actions/checkout@v4 uses: actions/cache@v4 uses: ruby/setup-ruby@v1  Now I’m writing this post, it occurs to me I could use sed to make this substitution as well. I reached for tr because I've been using it for longer, and the syntax is simpler for doing single character substitutions: tr '<oldchar>' '<newchar>'    awk '{print $2}'    This splits the string on spaces, and prints the second token, which is the name of the action:  actions/checkout@v4 actions/cache@v4 ruby/setup-ruby@v1  awk is another powerful text utility that I’ve never learnt properly – I only know how to print the nth word in a string. It has a lot of pattern-matching features I’ve never tried.    sed 's/\\r//g'    I had a few workflow files which were using carriage returns (\\r), and those were included in the awk output. This command gets rid of them, which makes the data more consistent for the final step.    sort | uniq --count | sort --numeric-sort    This sorts the lines so identical lines are adjacent, then it groups and counts the lines, and finally it re-sorts to put the most frequent lines at the bottom.   I have this as a shell alias called tally.  6 actions/cache@v4 9 ruby/setup-ruby@v1 59 actions/checkout@v4   This step-by-step approach is how I build Unix text pipelines: I can write a step at a time, and gradually refine and tweak the output until I get the result I want. There are lots of ways to do it, and because this is a script I’ll use once and then discard, I don’t have to worry too much about doing it in the “purest” way – as long as it gets the right result, that’s good enough. If you use GitHub Actions, you might want to use this script to check your own actions, and see what you’re using. But more than that, I recommend becoming familiar with the Unix text processing tools and pipelines – even in the age of AI, they’re still a powerful and flexible way to cobble together one-off scripts for processing data.",
    "summary": {
      "en": "Recently, malicious code was added to a GitHub Action called tj-actions/changed-files, which could leak sensitive information from public build logs. This issue arose because many users refer to mutable tags (like version numbers) in their GitHub Actions workflows, which can be changed to point to different code. A more secure practice is to use immutable commit IDs, ensuring the same code runs every time.\n\nTo check for mutable references in my own GitHub Actions, I ran a shell script that searched through my YAML workflow files. The script identified all the actions I was using and counted how many times each action appeared. Most of my actions came from reputable organizations, which generally have better security practices.\n\nThe script utilized various Unix text processing tools to gather and sort the data effectively. It helped me assess the trustworthiness of the actions I was using and consider whether I should write my own scripts instead of relying on third-party actions, especially for non-critical tasks. \n\nOverall, if you use GitHub Actions, it’s wise to review the actions you depend on for security and consider using Unix tools for data processing.",
      "ko": "최근 tj-actions/changed-files라는 GitHub Action에 악성 코드가 추가되어, 공개 빌드 로그에서 민감한 정보가 유출될 수 있는 문제가 발생했습니다. 이 문제는 많은 사용자가 GitHub Actions 워크플로우에서 변경 가능한 태그(예: 버전 번호)를 참조하기 때문에 발생했습니다. 이러한 태그는 다른 코드로 변경될 수 있습니다. 더 안전한 방법은 변경 불가능한 커밋 ID를 사용하는 것으로, 이를 통해 매번 동일한 코드가 실행되도록 보장할 수 있습니다.\n\n내 GitHub Actions에서 변경 가능한 참조를 확인하기 위해, YAML 워크플로우 파일을 검색하는 셸 스크립트를 실행했습니다. 이 스크립트는 내가 사용하는 모든 액션을 식별하고 각 액션이 몇 번 나타나는지 세었습니다. 대부분의 액션은 신뢰할 수 있는 조직에서 제공한 것으로, 일반적으로 보안 관행이 더 우수합니다.\n\n이 스크립트는 다양한 유닉스 텍스트 처리 도구를 활용하여 데이터를 효과적으로 수집하고 정리했습니다. 이를 통해 내가 사용하는 액션의 신뢰성을 평가하고, 특히 중요하지 않은 작업에 대해서는 제3자 액션에 의존하기보다는 직접 스크립트를 작성하는 것이 좋을지 고민하게 되었습니다.\n\n전반적으로 GitHub Actions를 사용하는 경우, 의존하는 액션의 보안을 검토하고 데이터 처리를 위해 유닉스 도구를 사용하는 것이 현명합니다.",
      "ja": "最近、tj-actions/changed-filesというGitHub Actionに悪意のあるコードが追加され、公開ビルドログから機密情報が漏洩する可能性がある問題が発生しました。この問題は、多くのユーザーがGitHub Actionsのワークフローで可変タグ（バージョン番号のようなもの）を参照しているために起こりました。可変タグは異なるコードを指すように変更できるため、より安全な方法として不変のコミットIDを使用することが推奨されています。これにより、毎回同じコードが実行されることが保証されます。\n\n自分のGitHub Actionsで可変参照を確認するために、YAMLワークフローファイルを検索するシェルスクリプトを実行しました。このスクリプトは、使用しているすべてのアクションを特定し、それぞれのアクションが何回登場するかをカウントしました。私のアクションのほとんどは信頼できる組織からのもので、一般的にセキュリティ対策が優れています。\n\nこのスクリプトは、さまざまなUnixのテキスト処理ツールを利用してデータを効果的に収集し、整理しました。これにより、使用しているアクションの信頼性を評価し、特に重要でないタスクについてはサードパーティのアクションに依存するのではなく、自分のスクリプトを書くことを検討する手助けとなりました。\n\n全体として、GitHub Actionsを使用している場合は、依存しているアクションのセキュリティを見直し、データ処理のためにUnixツールを使用することが賢明です。"
    }
  },
  {
    "id": "1712776a31155bea",
    "title": {
      "en": "Ruby, Ractors, and lock-free data structures",
      "ko": "루비의 혁신: 락프리 데이터 구조",
      "ja": "ルビーの革新"
    },
    "type": "story",
    "url": "https://iliabylich.github.io/ruby-ractors-and-lock-free-data-structures/",
    "score": 123,
    "by": "ksec",
    "time": 1742712911,
    "content": "Intro\nThis story is about concurrent data structures in the context of Ruby. The goal here is to demonstrate how true parallelism can be achieved with global mutable state (which at the time of writing, is not supported by built-in Ruby primitives).\nFamiliarity with Ruby, Rust, C, (and a bit of other tooling) is nice to have, but hopefully not mandatory.\nThe repository with code examples can be found on GitHub, to run it you need a relatively new version of Ruby (master branch is probably the best option if you can compile it locally), Rust and C compilers.",
    "summary": {
      "en": "This story discusses concurrent data structures in Ruby, focusing on achieving true parallelism with global mutable state, which Ruby's built-in features currently do not support. While having knowledge of Ruby, Rust, C, and some other tools is helpful, it's not essential. You can find code examples on GitHub, but you'll need a recent version of Ruby, along with Rust and C compilers, to run them.",
      "ko": "이 이야기는 루비에서 동시 데이터 구조에 대해 다루고 있으며, 전역 가변 상태를 활용한 진정한 병렬성을 달성하는 데 초점을 맞추고 있습니다. 현재 루비의 기본 기능은 이러한 병렬성을 지원하지 않습니다. 루비, 러스트, C 및 기타 도구에 대한 지식이 있으면 도움이 되지만 필수는 아닙니다. 코드 예제는 깃허브에서 찾을 수 있지만, 이를 실행하려면 최신 버전의 루비와 함께 러스트 및 C 컴파일러가 필요합니다.",
      "ja": "この話は、Rubyにおける同時データ構造について述べています。特に、Rubyの組み込み機能が現在サポートしていないグローバルな可変状態を持つ真の並列性の実現に焦点を当てています。Ruby、Rust、C、そしてその他のツールについての知識があると役立ちますが、必須ではありません。コードの例はGitHubで見つけることができますが、それを実行するには最新のRubyのバージョンと、RustおよびCのコンパイラが必要です。"
    }
  },
  {
    "id": "607dbb2d301d2887",
    "title": {
      "en": "Open-sourcing OpenPubkey SSH (OPKSSH): integrating single sign-on with SSH",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://blog.cloudflare.com/open-sourcing-openpubkey-ssh-opkssh-integrating-single-sign-on-with-ssh/",
    "score": 245,
    "by": "PranaFlux",
    "time": 1742908929,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "2f3ae4b64aff6ff6",
    "title": {
      "en": "Scientists break down plastic using a simple, inexpensive catalyst and air",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://phys.org/news/2025-03-scientists-plastic-simple-inexpensive-catalyst.html",
    "score": 160,
    "by": "PaulHoule",
    "time": 1742587969,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "a802eba4eeccd3c4",
    "title": {
      "en": "If you get the chance, always run more extra network fiber cabling",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://utcc.utoronto.ca/~cks/space/blog/sysadmin/RunMoreExtraNetworkFiber",
    "score": 198,
    "by": "hggh",
    "time": 1742910059,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "805d8e49e7c5a3cd",
    "title": {
      "en": "Intel RealSense Stereo Depth Cameras",
      "ko": "인텔 리얼센스 스테레오 카메라",
      "ja": "インテル深度カメラ"
    },
    "type": "story",
    "url": "https://www.intelrealsense.com",
    "score": 76,
    "by": "1sembiyan",
    "time": 1742733391,
    "content": "D421Intel RealSense Depth Camera Module D421An entry level stereo depth camera module.\nLearn MoreBuy.lumenCase study3D Vision for the Visually ImpairedEquipped with Intel RealSense modules, .lumen assistive glasses allow the blind to move confidently for greater independence and enhanced navigation capabilities.\nRead MoreThruvisionCase studyVision AI for Advanced People ScreeningIntel RealSense depth cameras power advanced security solutions for airport screening, loss prevention, customs and border control, and venue security.\nRead MoreSimbe RoboticsCASE STUDYAutonomous In-store OperationsCapture real-time inventory and ecommerce grade insights to optimize in-store operations.\nRead MoreANYBoticsCase studyAutonomous Industrial Inspection SolutionsLearn how ANYBotics robots map facilities, avoid obstacles, and navigate to dynamic docking stations.\nRead More\n\n                        D456\n\n                        D457\n\n                        D455f\n\n                        D455\n\n                        D435if\n\n                        D435f\n\n                        D435i\n\n                        D435\n\n                        D415\n\n                    Compare models\n\n                        Depth camera D456\n\n                                    Field of View: 87° × 58°\n\n                                    IP67 / Global Shutter / IMU\n\n                                    Ideal Range: 60 cm to 6 m\n\n                        Buy\n\n                            Learn more\n\n                        Depth camera D457\n\n                                    Field of View: 87° × 58°\n\n                                    GMSL/FAKRA\n\n                                    Ideal Range: 60 cm to 6 m\n\n                        Buy\n\n                            Learn more\n\n                        Depth camera D455f\n\n                                    Field of View: 87° × 58°\n\n                                    Global Shutter / IR Pass Filter / IMU\n\n                                    Ideal Range: 60 cm to 6 m\n\n                        Buy\n\n                            Learn more\n\n                        Depth camera D455\n\n                                    Field of View: 87° × 58°\n\n                                    Global Shutter / IMU\n\n                                    Ideal Range: 60 cm to 6 m\n\n                        Buy\n\n                            Learn more\n\n                        Depth camera D435if\n\n                                    Field of View:  87° × 58°\n\n                                    Global Shutter / IR Pass Filter / IMU\n\n                                    Ideal Range: 30 cm to 3 m\n\n                        Buy\n\n                            Learn more\n\n                        Depth camera D435f\n\n                                    Field of View:  87° × 58°\n\n                                    Global Shutter / IR Pass Filter\n\n                                    Ideal Range: 30 cm to 3 m\n\n                        Buy\n\n                            Learn more\n\n                        Depth camera D435i\n\n                                    Field of View:  87° × 58°\n\n                                    Global Shutter / IMU\n\n                                    Ideal Range: 30 cm to 3 m\n\n                        Buy\n\n                            Learn more\n\n                        Depth camera D435\n\n                                    Field of View: 87° × 58°\n\n                                    Global Shutter\n\n                                    Ideal Range: 30 cm to 3 m\n\n                        Buy\n\n                            Learn more\n\n                        Depth camera D415\n\n                                    Field of View: 65° × 40°\n\n                                    Rolling Shutter\n\n                                    Ideal Range: 50 cm to 3 m\n\n                        Buy\n\n                            Learn more\n\n      Which camera is best for me?\n\n        Find Your Camera\n\n                Find your Camera\n                Find the best camera that meets your needs by answering these questions.\n\n                Find Camera\n\n                What is the main use for the camera?\n\n                                   Robotics\n\n                                   Retail\n\n                                   Scanning\n\n                                   Facial Authentication\n\n                                   Other\n\n                    Back\n                    Next\n                    Shop All Products\n            Send Me the Results\n\n\t\tEnterprise-ready\n\n            Learn more\n\n            Talk to sales\n\n                Developers\n\n                        SDK 2.0\n\n                        Get the latest Intel RealSense SDK 2.0\nto kick-off your project.\n\n                        Documentation\n\n                        Make the most out of your Intel RealSense devices with extensive documentation and whitepapers.\n\n                        Code samples\n\n                        Get started fast with depth development.\n\n                        Videos and tutorials\n\n                        Check out tutorials and camera tuning hints.\n\n                        Webinars and events\n\n                        View our library of webinars from computer vision experts and sign up for the next one.\n\n                        GitHub\n\n                        Our main code repository where you can find latest releases and source code.\n\n        Perfect\n\n        for Robotics\n\n\t\tComputer vision in robotics comes into focus.\n\n\tIn the last few years demand for computer vision technology that reliably works and performs across a variety of conditions has grown rapidly. Learn more about how robots see and understand the world.\n\n            Download the full story\n\n        Perfect\n\n        for Robotics\n\n                Where to Buy\n                                    Get the latest Intel RealSense productsnow.\n\n                        Buy online\n\n                        Buy directly from Intel RealSense. Fast worldwide shipping.\n\n                        Authorized distributor\n\n                        Find an authorized distributor near you.\n\n                        Talk to sales\n\n                        Let our sales team help you with the purchase\n\nStay Updated\n\n\t\tStay Updated\n\n\tGet the latest Intel RealSense computer vision news, product updates, events and webinars notifications and more.\n\n    .custom-select, .form-control {\n        border-bottom: 1px solid #cccccc !important;\n    }\n\n    #sub_embedded .sub_body #stay_updated .submit-form {\n        \tdisplay: inline-flex;\n    \talign-items: center;\n    \tjustify-content: center;\n    \tborder: none;\n    \tborder-radius: 23px;\n    \tmargin: 0;\n    \tpadding: 10px 20px 12px;\n    \tmin-height: 45px;\n    \tmin-width: 150px;\n    \toutline-offset: 4px;\n    \tbackground: #0068b5;\n    \tcolor: #ffffff;\n    \tfont-family: \"Intel Clear\", \"Menlo\", \"san-serif\";\n    \tfont-style: normal;\n    \tfont-weight: normal;\n    \tfont-size: 18px;\n    \tline-height: 1;\n    \ttext-align: center;\n    \tletter-spacing: -0.02em;\n    \tcursor: pointer;\n    \ttext-decoration: none;\n    \ttransition: background 200ms ease-in-out 0ms;\n    }\n\n    #sub_embedded .sub_body #stay_updated .submit-form:hover {\n    \tbackground: #0294dc;\n    \tborder: none;\n    \tcolor: #ffffff;\n    \ttext-decoration: none;\n    }\n\n\t\t\t\t\t\tCountry/Region *\n\t\t\t\t\t\tAfghanistan\n\t\t\t\t\t\tAland Islands\n\t\t\t\t\t\tAlbania\n\t\t\t\t\t\tAlgeria\n\t\t\t\t\t\tAmerican Samoa\n\t\t\t\t\t\tAndorra\n\t\t\t\t\t\tAngola\n\t\t\t\t\t\tAnguilla\n\t\t\t\t\t\tAntarctica\n\t\t\t\t\t\tAntigua and Barbuda\n\t\t\t\t\t\tArgentina\n\t\t\t\t\t\tArmenia\n\t\t\t\t\t\tAruba\n\t\t\t\t\t\tAustralia\n\t\t\t\t\t\tAustria\n\t\t\t\t\t\tAzerbaijan\n\t\t\t\t\t\tBahamas\n\t\t\t\t\t\tBahrain\n\t\t\t\t\t\tBangladesh\n\t\t\t\t\t\tBarbados\n\t\t\t\t\t\tBelarus\n\t\t\t\t\t\tBelgium\n\t\t\t\t\t\tBelize\n\t\t\t\t\t\tBenin\n\t\t\t\t\t\tBermuda\n\t\t\t\t\t\tBhutan\n\t\t\t\t\t\tBolivia\n\t\t\t\t\t\tBonaire\n\t\t\t\t\t\tBosnia and Herzegovina\n\t\t\t\t\t\tBotswana\n\t\t\t\t\t\tBouvet Island\n\t\t\t\t\t\tBrazil\n\t\t\t\t\t\tBritish Indian Ocean Territory\n\t\t\t\t\t\tBrunei Darussalam\n\t\t\t\t\t\tBulgaria\n\t\t\t\t\t\tBurkina Faso\n\t\t\t\t\t\tBurundi\n\t\t\t\t\t\tCambodia\n\t\t\t\t\t\tCameroon\n\t\t\t\t\t\tCanada\n\t\t\t\t\t\tCape Verde\n\t\t\t\t\t\tCayman Islands\n\t\t\t\t\t\tCentral African Republic\n\t\t\t\t\t\tChad\n\t\t\t\t\t\tChile\n\t\t\t\t\t\tChina\n\t\t\t\t\t\tChristmas Island\n\t\t\t\t\t\tCocos (Keeling) Islands\n\t\t\t\t\t\tColombia\n\t\t\t\t\t\tComoros\n\t\t\t\t\t\tCongo\n\t\t\t\t\t\tCongo, The Democratic Republic of the\n\t\t\t\t\t\tCook Islands\n\t\t\t\t\t\tCosta Rica\n\t\t\t\t\t\tCote D'ivoire\n\t\t\t\t\t\tCroatia\n\t\t\t\t\t\tCuba\n\t\t\t\t\t\tCuracao\n\t\t\t\t\t\tCyprus\n\t\t\t\t\t\tCzech Republic\n\t\t\t\t\t\tDenmark\n\t\t\t\t\t\tDjibouti\n\t\t\t\t\t\tDominica\n\t\t\t\t\t\tDominican Republic\n\t\t\t\t\t\tEcuador\n\t\t\t\t\t\tEgypt\n\t\t\t\t\t\tEl Salvador\n\t\t\t\t\t\tEquatorial Guinea\n\t\t\t\t\t\tEritrea\n\t\t\t\t\t\tEstonia\n\t\t\t\t\t\tEthiopia\n\t\t\t\t\t\tFalkland Islands (Malvinas)\n\t\t\t\t\t\tFaroe Islands\n\t\t\t\t\t\tFiji\n\t\t\t\t\t\tFinland\n\t\t\t\t\t\tFrance\n\t\t\t\t\t\tFrench Guiana\n\t\t\t\t\t\tFrench Poly.\n\t\t\t\t\t\tFrench S. Terr.\n\t\t\t\t\t\tGabon\n\t\t\t\t\t\tGambia\n\t\t\t\t\t\tGeorgia\n\t\t\t\t\t\tGermany\n\t\t\t\t\t\tGhana\n\t\t\t\t\t\tGibraltar\n\t\t\t\t\t\tGreece\n\t\t\t\t\t\tGreenland\n\t\t\t\t\t\tGrenada\n\t\t\t\t\t\tGuadeloupe\n\t\t\t\t\t\tGuam\n\t\t\t\t\t\tGuatemala\n\t\t\t\t\t\tGuernsey\n\t\t\t\t\t\tGuinea\n\t\t\t\t\t\tGuinea-Bissau\n\t\t\t\t\t\tGuyana\n\t\t\t\t\t\tHaiti\n\t\t\t\t\t\tHeard Island and Mcdonald Islands\n\t\t\t\t\t\tHoly See (Vatican City State)\n\t\t\t\t\t\tHonduras\n\t\t\t\t\t\tHong Kong\n\t\t\t\t\t\tHungary\n\t\t\t\t\t\tIceland\n\t\t\t\t\t\tIndia\n\t\t\t\t\t\tIndonesia\n\t\t\t\t\t\tIran, Islamic Republic of\n\t\t\t\t\t\tIraq\n\t\t\t\t\t\tIreland\n\t\t\t\t\t\tIsle of Man\n\t\t\t\t\t\tIsrael\n\t\t\t\t\t\tItaly\n\t\t\t\t\t\tJamaica\n\t\t\t\t\t\tJapan\n\t\t\t\t\t\tJersey\n\t\t\t\t\t\tJordan\n\t\t\t\t\t\tKazakhstan\n\t\t\t\t\t\tKenya\n\t\t\t\t\t\tKiribati\n\t\t\t\t\t\tKorea, Democratic People's Republic of\n\t\t\t\t\t\tKorea, Republic of\n\t\t\t\t\t\tKuwait\n\t\t\t\t\t\tKyrgyzstan\n\t\t\t\t\t\tLao People's Democratic Republic\n\t\t\t\t\t\tLatvia\n\t\t\t\t\t\tLebanon\n\t\t\t\t\t\tLesotho\n\t\t\t\t\t\tLiberia\n\t\t\t\t\t\tLibya\n\t\t\t\t\t\tLiechtenstein\n\t\t\t\t\t\tLithuania\n\t\t\t\t\t\tLuxembourg\n\t\t\t\t\t\tMacau\n\t\t\t\t\t\tMacedonia\n\t\t\t\t\t\tMadagascar\n\t\t\t\t\t\tMalawi\n\t\t\t\t\t\tMalaysia\n\t\t\t\t\t\tMaldives\n\t\t\t\t\t\tMali\n\t\t\t\t\t\tMalta\n\t\t\t\t\t\tMarshall Islands\n\t\t\t\t\t\tMartinique\n\t\t\t\t\t\tMauritania\n\t\t\t\t\t\tMauritius\n\t\t\t\t\t\tMayotte\n\t\t\t\t\t\tMexico\n\t\t\t\t\t\tMicronesia, Federated States of\n\t\t\t\t\t\tMoldova, Republic of\n\t\t\t\t\t\tMonaco\n\t\t\t\t\t\tMongolia\n\t\t\t\t\t\tMontenegro\n\t\t\t\t\t\tMontserrat\n\t\t\t\t\t\tMorocco\n\t\t\t\t\t\tMozambique\n\t\t\t\t\t\tMyanmar\n\t\t\t\t\t\tNamibia\n\t\t\t\t\t\tNauru\n\t\t\t\t\t\tNepal\n\t\t\t\t\t\tNetherlands\n\t\t\t\t\t\tNetherlands Antilles\n\t\t\t\t\t\tNew Caledonia\n\t\t\t\t\t\tNew Zealand\n\t\t\t\t\t\tNicaragua\n\t\t\t\t\t\tNiger\n\t\t\t\t\t\tNigeria\n\t\t\t\t\t\tNiue\n\t\t\t\t\t\tNorfolk Island\n\t\t\t\t\t\tNorthern Mariana Islands\n\t\t\t\t\t\tNorway\n\t\t\t\t\t\tOman\n\t\t\t\t\t\tPakistan\n\t\t\t\t\t\tPalau\n\t\t\t\t\t\tPalestine, State\n\t\t\t\t\t\tPanama\n\t\t\t\t\t\tPapua New Guinea\n\t\t\t\t\t\tParaguay\n\t\t\t\t\t\tPeru\n\t\t\t\t\t\tPhilippines\n\t\t\t\t\t\tPitcairn\n\t\t\t\t\t\tPoland\n\t\t\t\t\t\tPortugal\n\t\t\t\t\t\tPuerto Rico\n\t\t\t\t\t\tQatar\n\t\t\t\t\t\tReunion\n\t\t\t\t\t\tRomania\n\t\t\t\t\t\tRussian Federation\n\t\t\t\t\t\tRwanda\n\t\t\t\t\t\tSaint Helena\n\t\t\t\t\t\tSaint Kitts and Nevis\n\t\t\t\t\t\tSaint Lucia\n\t\t\t\t\t\tSaint Martin\n\t\t\t\t\t\tSaint Pierre\n\t\t\t\t\t\tSaint Vincent and The Grenadines\n\t\t\t\t\t\tSamoa\n\t\t\t\t\t\tSan Marino\n\t\t\t\t\t\tSao Tome and Principe\n\t\t\t\t\t\tSaudi Arabia\n\t\t\t\t\t\tSenegal\n\t\t\t\t\t\tSerbia\n\t\t\t\t\t\tSerbia and Montenegro\n\t\t\t\t\t\tSeychelles\n\t\t\t\t\t\tSierra Leone\n\t\t\t\t\t\tSingapore\n\t\t\t\t\t\tSint Maarten\n\t\t\t\t\t\tSlovakia\n\t\t\t\t\t\tSlovenia\n\t\t\t\t\t\tSolomon Islands\n\t\t\t\t\t\tSomalia\n\t\t\t\t\t\tSouth Africa\n\t\t\t\t\t\tSouth Georgia and The South Sandwich Islands\n\t\t\t\t\t\tSouth Sudan\n\t\t\t\t\t\tSpain\n\t\t\t\t\t\tSri Lanka\n\t\t\t\t\t\tSt. Barthelemy\n\t\t\t\t\t\tSudan\n\t\t\t\t\t\tSuriname\n\t\t\t\t\t\tSvalbard\n\t\t\t\t\t\tSwaziland\n\t\t\t\t\t\tSweden\n\t\t\t\t\t\tSwitzerland\n\t\t\t\t\t\tSyrian Arab Republic\n\t\t\t\t\t\tTaiwan\n\t\t\t\t\t\tTajikistan\n\t\t\t\t\t\tTanzania, United Republic of\n\t\t\t\t\t\tThailand\n\t\t\t\t\t\tTimor-Leste\n\t\t\t\t\t\tTogo\n\t\t\t\t\t\tTokelau\n\t\t\t\t\t\tTonga\n\t\t\t\t\t\tTrinidad and Tobago\n\t\t\t\t\t\tTunisia\n\t\t\t\t\t\tTurkey\n\t\t\t\t\t\tTurkmenistan\n\t\t\t\t\t\tTurks and Caicos Islands\n\t\t\t\t\t\tTuvalu\n\t\t\t\t\t\tUganda\n\t\t\t\t\t\tUkraine\n\t\t\t\t\t\tUnited Arab Emirates\n\t\t\t\t\t\tUnited Kingdom\n\t\t\t\t\t\tUnited States\n\t\t\t\t\t\tUnited States Minor Outlying Islands\n\t\t\t\t\t\tUruguay\n\t\t\t\t\t\tUzbekistan\n\t\t\t\t\t\tVanuatu\n\t\t\t\t\t\tVenezuela\n\t\t\t\t\t\tVietnam\n\t\t\t\t\t\tVirgin Islands, British\n\t\t\t\t\t\tVirgin Islands, U.S.\n\t\t\t\t\t\tWallis and Futuna\n\t\t\t\t\t\tWestern Sahara\n\t\t\t\t\t\tYemen\n\t\t\t\t\t\tYugoslavia\n\t\t\t\t\t\tZambia\n\t\t\t\t\t\tZimbabwe\n\n\t\t\t\t    Thank you!You were successfully subscribed.\n\n\tBy submitting this form, you are confirming you are an adult 18 years or older and you agree to Intel contacting you with marketing-related emails or by telephone. You may unsubscribe at any time. Intel’s web sites and communications are subject to ourPrivacy NoticeandTerms ofUse.\n\n    /* Container for the entire section */\n    .sales-section {\n      display: flex;\n      align-items: center;\n      justify-content: center;\n      flex-wrap: wrap;\n    }\n\n    /* Text inside the section */\n    .sales-section .sales-text {\n      font-family: \"Intel One\", \"Intel Clear\", sans-serif;\n      font-style: normal;\n      font-weight: 500;\n      font-size: 46px;\n      line-height: 153.51%;\n      color: white;\n      margin-right: 20px;\n      leading-trim: both;\n      text-edge: cap;\n      letter-spacing: 0.01em;\n    }\n\n    /* Button inside the section */\n    .sales-section .sales-button {\n      background-color: #0054AE; /* Blue button background */\n      color: white;\n      display: flex;\n      flex-direction: row;\n      justify-content: center;\n      align-items: center;\n      flex: none;\n      order: 1;\n      font-weight: 500;\n      font-family: Intel One Text;\n      flex-grow: 0;\n      padding: 10px 20px 12px;\n      border: none;\n      border-radius: 5px;\n      font-size: 18px;\n      cursor: pointer;\n      text-decoration: none;\n      width: 162px;\n      height: 45px;\n    }\n\n    /* Responsive design for mobile viewports */\n    @media (max-width: 765px) {\n      .sales-section {\n        flex-direction: column;\n        text-align: center;\n      }\n\n      .sales-section .sales-text {\n        margin-right: 0;\n        margin-bottom: 10px;\n        line-height: 100%;\n      }\n    }\n\n  Ready to talk to sales?\n  Contact Sales",
    "summary": {
      "en": "The Intel RealSense Depth Camera Module D421 is an entry-level stereo depth camera. It supports various applications, including:\n\n1. **Assistive Technology**: Used in .lumen glasses to help visually impaired individuals navigate more independently.\n2. **Security**: Powers advanced security solutions for airport screening, customs, and venue security.\n3. **Retail**: Helps optimize in-store operations by capturing real-time inventory data.\n4. **Industrial Inspection**: ANYBotics robots utilize it for mapping, obstacle avoidance, and navigation.\n\nSeveral camera models are available, each with specific features and ideal ranges. For example, models like D456 and D457 have a field of view of 87° × 58° and an ideal range of 60 cm to 6 m. Other models, such as D415, have a narrower field of view and different ranges.\n\nIntel offers resources for developers, including SDKs, documentation, tutorials, and webinars. Customers can purchase cameras directly from Intel or through authorized distributors.\n\nFor those interested, there's an option to receive updates on Intel RealSense products and news.",
      "ko": "인텔 리얼센스 깊이 카메라 모듈 D421은 입문용 스테레오 깊이 카메라입니다. 이 카메라는 여러 가지 용도로 사용됩니다. 첫째, 보조 기술 분야에서는 시각 장애인이 보다 독립적으로 이동할 수 있도록 돕는 .lumen 안경에 사용됩니다. 둘째, 보안 분야에서는 공항 검색, 세관 및 행사 보안을 위한 고급 보안 솔루션을 지원합니다. 셋째, 소매업에서는 실시간 재고 데이터를 수집하여 매장 운영을 최적화하는 데 기여합니다. 넷째, 산업 검사에서는 ANYBotics 로봇이 매핑, 장애물 회피 및 내비게이션을 위해 이 카메라를 활용합니다.\n\n여러 가지 카메라 모델이 있으며, 각 모델은 특정 기능과 이상적인 범위를 가지고 있습니다. 예를 들어, D456 및 D457 모델은 87° × 58°의 시야각과 60cm에서 6m까지의 이상적인 범위를 제공합니다. 반면 D415와 같은 다른 모델은 더 좁은 시야각과 다른 범위를 가지고 있습니다.\n\n인텔은 개발자를 위한 리소스를 제공하며, 여기에는 소프트웨어 개발 키트(SDK), 문서, 튜토리얼 및 웨비나가 포함됩니다. 고객은 인텔에서 직접 카메라를 구매하거나 공인 유통업체를 통해 구입할 수 있습니다.\n\n관심 있는 분들은 인텔 리얼센스 제품 및 뉴스에 대한 업데이트를 받을 수 있는 옵션도 있습니다.",
      "ja": "IntelのRealSense深度カメラモジュールD421は、エントリーレベルのステレオ深度カメラです。このカメラはさまざまな用途に対応しています。\n\nまず、支援技術として、視覚障害者がより自立して移動できるように.lumenメガネに使用されています。次に、セキュリティ分野では、空港の検査、税関、会場の安全対策に役立つ高度なセキュリティソリューションを提供しています。また、小売業では、リアルタイムの在庫データを取得することで店舗運営の最適化を支援します。さらに、産業検査では、ANYBoticsのロボットが地図作成や障害物回避、ナビゲーションにこのカメラを利用しています。\n\n複数のカメラモデルがあり、それぞれ特定の機能と理想的な範囲を持っています。例えば、D456やD457モデルは、視野角が87° × 58°で、理想的な範囲は60 cmから6 mです。一方、D415モデルは視野角が狭く、異なる範囲を持っています。\n\nIntelは開発者向けにSDK、ドキュメント、チュートリアル、ウェビナーなどのリソースを提供しています。顧客はIntelから直接、または認定販売代理店を通じてカメラを購入できます。\n\n興味のある方には、Intel RealSense製品やニュースの更新を受け取るオプションも用意されています。"
    }
  },
  {
    "id": "1516ef9966ad2839",
    "title": {
      "en": "Rest Easy",
      "ko": "편안한 휴식",
      "ja": "安らぎの時"
    },
    "type": "story",
    "url": "https://www.commentary.org/articles/joseph-epstein/rest-work-purpose/",
    "score": 40,
    "by": "lermontov",
    "time": 1742701343,
    "content": "April 2025\n\n                Culture & Civilization\n\n          Rest Easy\n\n            I can’t. Can you?\n\n          by Joseph Epstein\n\n                  The Russian novelist Ivan Goncharov once said of writers, “And to write and write, like a wheel or a machine, tomorrow, the day after, on holidays; summer will come—and he must still be writing. When is he to stop and rest? Unfortunate man?” Goncharov was born in 1812 and died in 1891, so I am clearly not the model for the writer he was talking about—even though, my prolificacy having often been commented upon, I could otherwise well be. The eponymous hero of his novel Oblomov feels the same way about another character in the book who loves travel, and a second one who enjoys a lively social life, and a third who works hard in the hope of promotion. All of them are viewed by Oblomov as absurdly out of synch with life’s real purpose. This purpose, as Oblomov sees it, is to lie abed doing nothing all the days of one’s life. If rest may be said to have a champion, it is Oblomov, a gentleman by birth for whom “life was divided, in his opinion, into two halves: one consisted of work and boredom—these words were for him synonymous—the other of rest and peaceful good-humor.” Rest, unrelenting rest, is the name of Oblomov’s game.“Just as there are polysyllabic words that say very little,” Georg Christoph Lichtenberg wrote, “so there are also monosyllabic words of infinite meaning.” “Rest” is one of those words, simple-sounding yet not easily defined. As a verb, rest means to “cease work or movement in order to relax, refresh oneself, or recover strength”; as a noun, “an instance or period of relaxing or ceasing to engage in strenuous or stressful activity.” Why isn’t this very helpful?Rest is not quite synonymous with sleep, leisure, or laziness. When a man in his mid-70s or older asks another man of roughly the same age if he is “getting much,” he probably isn’t referring to sex but to sleep. Like as not, neither man is getting much sleep, for few older men I know make it through the night without having to get up two, three, or more times. Some are compelled to do so to visit the House of Commons, as Dylan Thomas called the bathroom. Others find their minds racing, or their sleep invaded by goofy dreams. I had a friend, a contemporary, who suffered the trifecta of insomnia, megalomania, and paranoia, and so spent the better parts of his nights awake, worrying about losing power he didn’t really have.As an adolescent, I remember sleeping eight-, nine-, 10-hour periods. Now if I can do two or three hours at a stretch, I feel vaguely triumphant. Conversations with friends, though they bring much pleasure, tend toward the stimulating and so do not necessarily qualify as rest. Working out of my apartment, as I have for many years now, I often take afternoon naps, but these naps do not so much bring on a restful feeling as they ward off the inevitable fatigue of a man in his 80s.Twenty-five years ago, I wrote an essay called “The Art of the Nap,” in which I set out my prowess at the act. What I remember about the essay today is an anecdote involving Hugh Lloyd-Jones, then regius professor of Greek at Oxford (because he was still alive, I didn’t use his name). Lloyd-Jones seemed to me in those days an Englishman to the highest power: He seemed to have 50 or 60 teeth, Himalayas of dandruff covered the shoulders of his blue blazer, and he spoke with a slight Oxbridge stammer. When I asked him if he napped, he replied, “Whenever possible.” Supine or prone? “Supine.” On couch or bed? “Bed.” Trousers on or off? “Generally off.” And for how long? “That depends,” he answered, “on when the cats get up.”_____________The concept of rest is as old as the Bible. On the seventh day, after creating the world and all that was in it, we are told that the Lord rested. Not, however, in His case, from fatigue, but to contemplate His further creations. Alain Corbin, a French scholar who has recently published a brief History of Rest, holds that for God, the day of rest was “a creative pause.” Later on, God tells Moses: “Speak to the sons of Israel and say, ‘You must keep my sabbaths carefully, because the sabbath is a sign between myself and you from generation to generation to show that it is I who sanctify you. You must keep the sabbath, then; it is to be held sacred by you.’”Keeping the Sabbath, in Corbin’s words, is not about rest alone but “the holy nature of that rest.” Mutatis mutandis, Christians, who were of course initially mostly Jews, took up the notion of a holy day of rest, with theirs being Sunday. In some quarters, both religions are even now defined by their days of rest. Militant Islamists have been known to claim that “after we finish off the Saturday people, we shall finish you, the Sunday people.” Meanwhile, it is understood that there is no rest for the wicked, which is to say none in Hell, which in good part is what must make it so hellish.Orthodox Jews continue meticulously to observe the Sabbath, and serious Christians to take communion on Sundays. One of the three elevators in the 15-story building in Chicago in which my parents lived was set to stop at every floor all through Saturday, so as not to force Orthodox Jews to violate the Sabbath by having to push a button and make the elevator move. Or consider the institution of the Shabbos goy, the Gentile hired by Orthodox Jews to attend to all the turning on of furnaces, lighting of lamps, warming of meals, and other exertions outlawed on the Sabbath in the books of Leviticus, Deuteronomy, and Numbers.In classical antiquity, the upper classes of both Greece and Rome looked down upon standard notions of work. Nearly full-time leisure, otium, was among the entitlements of aristocracy in Rome. In both countries, trades were considered nugatory, left largely to slaves. Nor was art much esteemed. Defending one’s polis or state and arguing ideas was where the action was. Lycurgus, the great lawgiver of Sparta, created a society wholly devoted to producing warriors. In Plato’s Republic, no honor is attributed to business, which, it was understood, was done by vile mercenaries.Rest has not been a subject that philosophers have shown much interest in, but it has been taken up by the great French belle-lettrists. In A History of Rest, Corbin quotes Montaigne, Pascal, La Rochefoucauld, La Bruyère, Diderot, Joubert, Rousseau, and others on the subject. Pascal is perhaps most trenchant among them, for he understood that human beings both seek and detest rest. “Man finds nothing so intolerable as to be in a state of complete rest,” Pascal wrote, “without passion, without occupation, without diversion, without effort.” The most famous of Pascal’s comments, from the notebooks he called his Pensées, is that “the sole cause of man’s unhappiness is that he does not know how to stay quietly in his room.”For Montaigne, rest was where tranquility was to be found, and tranquility precludes ambition. “Glory and tranquility,” he writes, “cannot dwell in the same lodgings.” For La Rochefoucauld, rest brings on retirement, in which “taste turns then to silent, insensible objects . . . a blissful state of the soul, which comforts it for all its losses, and which acts as a substitute for all good things.” For La Bruyère, “life is short and tedious, and is wholly spent in wishing; we trust to find rest and enjoyment at some future time, often at an age when our blessings, youth and health, have already left us.” Joubert held that “being deprived of rest means much to the soul. Rest is of no small matter to it. It represents a state where the soul is uniquely free to follow its own movement without outside impulses.”Corbin considers the toll of enforced rest through imprisonment or exile. He reminds us that rest was once considered the main cure for tuberculosis and was also recommended as a remedy for impotence. In more recent times, rest has also been prescribed for its therapeutic value generally. Corbin writes of a Dr. Charles Féré, who in the late-19th century “associated rest with the power to reduce the number of suicides, to lower crime levels and even…to encourage savings.” As it began to lose its holy existence, rest was increasingly becoming part of what Corbin terms “a secular morality.”Most of us simultaneously seek rest and yet are wary of the boredom implicit in it. The contradiction would appear to be irresolvable. Perhaps the only creature known to resolve it is cats. In his Journal, Jules Renard writes that “the ideal of calm exists in a sitting cat.” He notes that “a cat, who sleeps twenty hours out of twenty-four, is God’s most perfect creation,” and goes on to remark on “the vitality of the cat, who appears so lazy,” adding that “laziness is the habit of resting before fatigue sets in.”“The Right to Be Lazy” is the title of an essay by Paul Lafargue (1842–1911), who married the second of Karl Marx’s four daughters and is said to have been the first person to use the word “Marxist.” Writing at the height of the Industrial Revolution, with workers, many of them children, working a 10-, 12-, sometimes 15-hour day, Lafargue held that such a heavy workload was, on all counts, unnecessary, indeed insufferable. Noting that the English had reduced their factory workday by two hours while the country’s production increased, he suggested eliminating “the fuming madness for work” in France and elsewhere. Evoking the “dizzying effect…limiting the workday to three hours [would] have on French production” Lafargue concludes his essay on this vocative note: “Oh, Laziness, take pity on our long destitution! Oh, Laziness, mother of the arts and noble virtues, be thou balm to human suffering!”_____________Imay have achieved Lafargue’s ideal of the three-hour day. I rarely spent more than that at my computer, attempting to write essays, book reviews, short stories. I put in more time reading for some of this work, but then, I have never been able to consider reading real work. Writing is not an hourly job. Ideas, thoughts, notions, phrases, single words about things I am currently writing come to me at odd, which is to say just about all, times: upon waking, in the shower, when preparing a meal. I have taken to keeping my cellphone on my bedside table to take notes on things that occur to me at various hours of the night about compositions at which I am currently at work.The closest I come to rest, I suppose, are the hours I spend watching television, much of it news and sports. But I don’t feel especially well rested after arising from having spent the past few hours listening to accounts of the world’s woes on the news or staring at large men crash into one another on a basketball court or football field. Emmitt Smith, formerly of the Dallas Cowboys, claimed that being a running back on any Sunday in the National Football League was akin to getting into 30 car accidents, which doesn’t sound like an exaggeration to me and is not exactly stress-reducing for the onlooker.Boredom does not worry me. I have been bored only in the company of bores, but never when alone. The world is too interesting, often too amusing, a place to allow for boredom. When not writing, or thinking about what I shall be writing, I find interest in contemplating the richness of life, its comedy, yes, its sadness. Work can be onerous or glorious. Either way, it is at the center of most of our lives. When work is withdrawn, even through retirement on the most generous terms, it leaves a hole, one often filled by a feeling of desolation sometimes bordering on trauma. Though not in the same punishing category as imprisonment or exile, retirement can be a form of enforced rest. I have heard stories of (chiefly) men seeking therapy to get past the staggering dislocation retirement has brought them. Rest, it seems, has to be self-chosen, never imposed, to be truly restorative.Work itself brings its pleasures and displeasures. As for mine, a great deal has been said about the difficulties of writing. The sportswriter Red Smith once claimed that “writing is easy. You just sit down at your typewriter until little drops of blood appear on your forehead.” I have never found it so. I have always found writing an act of discovery, and the discovery, for me, often comes in the very composition of sentences whose shape and form are often a surprise. Rewriting, or revisions of what I have earlier written, brings its own pleasure. Ernest Hemingway claimed that “the only kind of writing is rewriting,” which, in an age I otherwise think of as techno-tyranny, the computer has made much easier.I feel fortunate in being able to continue scribbling away late into my 80s, holding retirement at bay, rendering it (I hope against hope) coterminous with death. Writers tend to divide between those who do not really need to write and those who urgently need to do so. I am among the latter. If a week or so goes by in which I haven’t written anything, I feel my life to be pointless, my place in the world dubious. Plenty of time to rest later. Cemeteries, as Corbin writes, “are sometimes referred to as gardens of rest.”Meanwhile, except for in the lives of seriously religious Christians, Sunday long ago lost its connection to the holy and became a secular Sabbath. For many years, it remained a day apart. As a European, Corbin makes no mention of American blue laws. A heritage of American Puritanism, blue laws prevented the sale of liquor or the exhibition of public entertainment on Sundays in many American states and cities. They also often prevented shopping generally, forcing most stores to remain closed. While they were in force, blue laws lent Sunday an aura of dullness, of boredom. Sunday Bloody Sunday, the title of a 1971 movie, touches on this aspect of enforced rest.Corbin makes more than one mention of seaside resorts as places of rest. Beach holidays, once quite popular for people who could afford them, have become less so owing to the fear of the skin cancer brought on by extended exposure to the sun. Travel on cruise ships was once regarded by many as organized rest, though anyone who has read David Foster Wallace’s “A Supposedly Fun Thing I’ll Never Do Again” is unlikely to set off on a cruise, with all its planned activities, lectures, endless food trolleys, not to speak of entrapment by one’s fellow travelers—whom Henry James, in a slightly different context, referred to as his “detested fellow pilgrims.”One definition of the good life is a perfect balance between useful work and contented rest. Michael Oakeshott, a thinker always worth considering, argues otherwise. He writes: “We spend our lives trying to discover how to live, a perfect way of life, sens de la vie. But we shall never find it. Life is the search for it; the successful life is that which is given up to this search; and when we think we have found it, we are farthest from it. Delude ourselves that we have found it, persuade ourselves that here at least there is a point at which we can rest—and life has become at once moribund. Just as to remain in love we must be continually falling in love, so to remain living we must be continually striving to live.”Oakeshott is doubtless right. The perfect way of life is probably unattainable. Which doesn’t mean we are allowed to give up the search. The goal is elusive, the striving endless, and to carry it on through life requires—yes, you will have guessed it—lots of rest.We want to hear your thoughts about this article. Click here to send a letter to the editor.\n\n\t\t\t\t\tShare via:\n\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tMore\n\n  \t\tLetter\n\n    +\n\n  \t\tA\n      A\n\n\t\t-\n\n              Trending Now\n\n                    Does the Signal Scandal Matter?\n\n                    Hamas’s American Mouthpieces\n\n                    The Signal Scandal and the COVID Conmen\n\n                    Speechless in London\n\n                    Why Is Steve Witkoff Repeating Putin’s War Propaganda?\n\n              Fight the insanity. Subscribe to reason.\n              Start your risk free trial with unlimited access.\n\n              Choose a plan\n\n              Listen to the best podcast anywhere, everywhere.\n\n              Get it on Soundcloud.\n\n                What’s in the latest issue?\n\n                  Explore the scintillating April 2025 issue of Commentary.\n                                      Subscribe\n\n        You may also like\n\n                Happy Anniversary to Us\n\n                    by\n\n                      John Podhoretz\n\n                The Evil of Rationalism\n\n                    by\n\n                      Christine Rosen\n\n                The Bibas Children and Ivan Karamazov’s Rebellion\n\n                    by\n\n                      Gary Saul Morson\n\n        Scroll Down For the Next Article",
    "summary": {
      "en": "In \"Rest Easy,\" Joseph Epstein reflects on the concept of rest and its complexities, drawing on historical and literary references. He quotes Russian novelist Ivan Goncharov, who emphasizes the relentless nature of writing and the absurdity of constant work compared to the value of rest, as exemplified by the character Oblomov.\n\nEpstein explores the meaning of rest, distinguishing it from sleep, leisure, and laziness. He shares personal anecdotes about his own struggles with rest as he ages, noting that conversations and activities often do not provide true relaxation. The piece also intersects with religious traditions, highlighting that rest has been a sacred concept in Judaism and Christianity, symbolized by the Sabbath.\n\nPhilosophers and writers have historically viewed rest as both desirable and frustrating. For instance, Pascal noted that humans struggle to be at rest without distractions, while Montaigne saw rest as a source of tranquility. Epstein also reflects on the societal view of work, referencing Paul Lafargue, who argued for the right to laziness during the Industrial Revolution.\n\nUltimately, Epstein suggests that true rest must be self-chosen and that retirement can feel like enforced rest, leading to feelings of emptiness. He argues that the search for a meaningful life requires a balance of work and rest, and this pursuit is an ongoing journey rather than a final destination.",
      "ko": "\"Rest Easy\"에서 조셉 엡스타인은 휴식의 개념과 그 복잡성에 대해 성찰하며 역사적, 문학적 참고자료를 인용합니다. 그는 러시아 소설가 이반 곤차로프의 말을 인용하여, 글쓰기가 끊임없는 성격을 지니고 있으며, 휴식의 가치에 비해 지속적인 노동이 얼마나 부조리한지를 강조합니다. 이는 소설 속 캐릭터인 오블로모프를 통해 잘 드러납니다.\n\n엡스타인은 휴식의 의미를 탐구하며, 이를 수면, 여가, 게으름과 구별합니다. 그는 나이가 들면서 자신의 휴식에 대한 어려움을 개인적인 일화로 나누며, 대화나 활동이 진정한 이완을 제공하지 않는 경우가 많다고 언급합니다. 이 글은 종교적 전통과도 연결되어 있으며, 유대교와 기독교에서 휴식이 성스러운 개념으로 여겨졌음을 강조합니다. 이는 안식일로 상징됩니다.\n\n역사적으로 철학자들과 작가들은 휴식을 바람직하면서도 답답한 것으로 여겨왔습니다. 예를 들어, 파스칼은 인간이 방해 없이 휴식하는 데 어려움을 겪는다고 지적했고, 몽테뉴는 휴식을 평온의 원천으로 보았습니다. 엡스타인은 또한 노동에 대한 사회적 시각을 반영하며, 산업 혁명 시기에 게으름의 권리를 주장한 폴 라파르그를 언급합니다.\n\n결국 엡스타인은 진정한 휴식은 스스로 선택해야 하며, 은퇴가 강제된 휴식처럼 느껴질 수 있어 공허함을 초래할 수 있다고 제안합니다. 그는 의미 있는 삶을 추구하는 데 있어 노동과 휴식의 균형이 필요하며, 이 과정은 최종 목적지가 아닌 지속적인 여정이라고 주장합니다.",
      "ja": "「レスト・イージー」において、ジョセフ・エプスタインは休息の概念とその複雑さについて考察し、歴史的および文学的な引用を用いています。彼はロシアの小説家イワン・ゴンチャロフを引用し、執筆の厳しさと、休息の価値に対する常に働き続けることの不条理さを強調しています。この考えは、ゴンチャロフの小説『オブロモフ』のキャラクターに象徴されています。\n\nエプスタインは休息の意味を探求し、睡眠やレジャー、怠惰とは異なることを明確にします。彼自身の年齢を重ねる中での休息に関する苦労を語り、会話や活動が真のリラクゼーションをもたらさないことが多いと述べています。また、休息はユダヤ教やキリスト教において神聖な概念であり、安息日によって象徴されることにも触れています。\n\n哲学者や作家たちは、歴史的に休息を望ましいものと同時にフラストレーションの源と見なしてきました。たとえば、パスカルは人間が気を散らさずに休むことが難しいと指摘し、モンテーニュは休息を静けさの源と見なしました。エプスタインは、労働に対する社会的な見方についても考察し、産業革命の時代に怠惰の権利を主張したポール・ラファルグを引用しています。\n\n最終的に、エプスタインは真の休息は自ら選ぶものでなければならず、退職は強制的な休息のように感じられ、空虚感をもたらすことがあると提案します。彼は、意味のある人生を求めるためには、仕事と休息のバランスが必要であり、この追求は最終的な目的地ではなく、継続的な旅であると主張しています。"
    }
  },
  {
    "id": "7b3afdc1159f6bba",
    "title": {
      "en": "Gemini 2.5",
      "ko": "쌍둥이 2.5",
      "ja": "双子座2.5"
    },
    "type": "story",
    "url": "https://blog.google/technology/google-deepmind/gemini-model-thinking-updates-march-2025/",
    "score": 877,
    "by": "meetpateltech",
    "time": 1742922114,
    "content": "Breadcrumb\n\n              Technology\n\n              Google DeepMind\n\n    Gemini 2.5: Our most intelligent AI model\n\n            Mar 25, 2025\n\n            ·\n\n            3 min read\n\n    Share\n\n  Twitter\n\n  Facebook\n\n  LinkedIn\n\n  Mail\n\n    Copy link\n\n          Gemini 2.5 is a thinking model, designed to tackle increasingly complex problems. Our first 2.5 model, Gemini 2.5 Pro Experimental, leads common benchmarks by meaningful margins and showcases strong reasoning and code capabilities.\n\n  Koray Kavukcuoglu\n\n      CTO of Google DeepMind\n\n    Share\n\n  Twitter\n\n  Facebook\n\n  LinkedIn\n\n  Mail\n\n    Copy link\n\n  class ProgressiveImage {\n    EVENTS = {\n      TRANSITION_END: 'transitionend',\n    };\n\n    CSS_CLASSES = {\n      BLUR: 'uni-progressive-image--blur',\n      NO_BLUR: 'uni-progressive-image--no-blur',\n    };\n\n    init(el) {\n      this.el = el;\n      this._events();\n      this._upgradeImage();\n    }\n\n    _upgradeImage() {\n      // For gif format images we don't include data-srcset and data-sizes\n      // We can safely remove the blur filter.\n      if (!this.el.dataset.srcset || !this.el.dataset.sizes) {\n        this.el.classList.add(this.CSS_CLASSES.NO_BLUR);\n\n        return;\n      }\n\n      this.el.setAttribute('srcset', this.el.dataset.srcset);\n      this.el.setAttribute('sizes', this.el.dataset.sizes);\n      requestAnimationFrame(() => {\n        this.el.classList.add(this.CSS_CLASSES.NO_BLUR);\n      });\n    }\n\n    _events() {\n      // Once the transition completes is safe to clean some attributes\n      this.el.addEventListener(this.EVENTS.TRANSITION_END, () => {\n        this.el.classList.remove(this.CSS_CLASSES.BLUR, this.CSS_CLASSES.NO_BLUR);\n        this.el.removeAttribute('data-srcset');\n        this.el.removeAttribute('data-sizes');\n      });\n    }\n  }\n\n  document.addEventListener('DOMContentLoaded', () => {\n    const images = document.querySelectorAll('[data-component=\"uni-progressive-image\"]');\n    images.forEach((el) => {\n      el.setAttribute('data-compononent-initialized', true);\n      new ProgressiveImage().init(el);\n    });\n  });\n\n      In this story\n\n      In this story\n\n          Introducing Gemini 2.5\n\n          Gemini 2.5 Pro\n\n          Enhanced reasoning\n\n          Advanced coding\n\n          The best of Gemini\n\n@keyframes spin{0%{transform:rotate(0)}100%{transform:rotate(360deg)}}.uni-spinner{display:flex;margin:100px auto;animation:spin 1.5s linear infinite;width:50px}.uni-spinner--small{width:24px;margin:0 auto}.uni-spinner--medium{width:36px}.uni-spinner--large{width:50px}.uni-spinner .loader-path{stroke:#1a73e8}.uni-article-feed .uni-spinner .loader-path{stroke:#1a73e8}\n\n        Today we’re introducing Gemini 2.5, our most intelligent AI model. Our first 2.5 release is an experimental version of 2.5 Pro, which is state-of-the-art on a wide range of benchmarks and debuts at #1 on LMArena by a significant margin.Gemini 2.5 models are thinking models, capable of reasoning through their thoughts before responding, resulting in enhanced performance and improved accuracy.In the field of AI, a system’s capacity for “reasoning” refers to more than just classification and prediction. It refers to its ability to analyze information, draw logical conclusions, incorporate context and nuance, and make informed decisions.For a long time, we’ve explored ways of making AI smarter and more capable of reasoning through techniques like reinforcement learning and chain-of-thought prompting. Building on this, we recently introduced our first thinking model, Gemini 2.0 Flash Thinking.Now, with Gemini 2.5, we've achieved a new level of performance by combining a significantly enhanced base model with improved post-training. Going forward, we’re building these thinking capabilities directly into all of our models, so they can handle more complex problems and support even more capable, context-aware agents.\n\n        Introducing Gemini 2.5 ProGemini 2.5 Pro Experimental is our most advanced model for complex tasks. It tops the LMArena leaderboard — which measures human preferences — by a significant margin, indicating a highly capable model equipped with high-quality style. 2.5 Pro also shows strong reasoning and code capabilities, leading on common coding, math and science benchmarks.Gemini 2.5 Pro is available now in Google AI Studio and in the Gemini app for Gemini Advanced users, and will be coming to Vertex AI soon. We’ll also introduce pricing in the coming weeks, enabling people to use 2.5 Pro with higher rate limits for scaled production use.\n\n        Enhanced reasoningGemini 2.5 Pro is state-of-the-art across a range of benchmarks requiring advanced reasoning. Without test-time techniques that increase cost, like majority voting, 2.5 Pro leads in math and science benchmarks like GPQA and AIME 2025.It also scores a state-of-the-art 18.8% across models without tool use on Humanity’s Last Exam, a dataset designed by hundreds of subject matter experts to capture the human frontier of knowledge and reasoning.\n\n        Advanced codingWe’ve been focused on coding performance, and with Gemini 2.5 we’ve achieved a big leap over 2.0 — with more improvements to come. 2.5 Pro excels at creating visually compelling web apps and agentic code applications, along with code transformation and editing. On SWE-Bench Verified, the industry standard for agentic code evals, Gemini 2.5 Pro scores 63.8% with a custom agent setup.Here’s an example of how 2.5 Pro can use its reasoning capabilities to create a video game by producing the executable code from a single line prompt.\n\n  00:00\n\n        Building on the best of GeminiGemini 2.5 builds on what makes Gemini models great — native multimodality and a long context window. 2.5 Pro ships today with a 1 million token context window (2 million coming soon), with strong performance that improves over previous generations. It can comprehend vast datasets and handle complex problems from different information sources, including text, audio, images, video and even entire code repositories.Developers and enterprises can start experimenting with Gemini 2.5 Pro in Google AI Studio now, and Gemini Advanced users can select it in the model dropdown on desktop and mobile. It will be available on Vertex AI in the coming weeks.As always, we welcome feedback so we can continue to improve Gemini’s impressive new abilities at a rapid pace, all with the goal of making our AI more helpful.\n\n    POSTED IN:\n\nGoogle DeepMind\n\nGemini Models",
    "summary": {
      "en": "**Summary of Gemini 2.5 Announcement**\n\nGoogle DeepMind has introduced Gemini 2.5, its latest and most advanced AI model, designed to solve complex problems with enhanced reasoning and coding capabilities. The initial release, called Gemini 2.5 Pro Experimental, has achieved top scores across various benchmarks, demonstrating significant improvements over previous models.\n\nKey features of Gemini 2.5 include:\n\n- **Enhanced Reasoning**: This model goes beyond simple predictions, analyzing information and making logical decisions. It excels in math and science tests without using costly techniques.\n  \n- **Advanced Coding**: Gemini 2.5 Pro shows a major leap in coding tasks, capable of creating web apps and executing complex coding operations efficiently.\n\n- **Multimodal Capabilities**: With a long context window that can handle vast amounts of information across different formats (text, audio, images, and more), Gemini 2.5 is built to tackle intricate tasks.\n\nDevelopers can start using Gemini 2.5 Pro in Google AI Studio, with plans for wider availability on Vertex AI soon. Feedback is encouraged to further enhance the model's capabilities.",
      "ko": "구글 딥마인드가 최신 인공지능 모델인 제미니 2.5를 발표했습니다. 이 모델은 복잡한 문제를 해결하기 위해 향상된 추론 및 코딩 능력을 갖추고 있습니다. 초기 출시된 제미니 2.5 프로 실험판은 여러 벤치마크에서 최고 점수를 기록하며 이전 모델들보다 상당한 개선을 보여주었습니다.\n\n제미니 2.5의 주요 특징은 다음과 같습니다. 첫째, 향상된 추론 능력입니다. 이 모델은 단순한 예측을 넘어서 정보를 분석하고 논리적인 결정을 내릴 수 있습니다. 수학과 과학 시험에서도 비싼 기술을 사용하지 않고도 뛰어난 성과를 보입니다.\n\n둘째, 고급 코딩 기능입니다. 제미니 2.5 프로는 코딩 작업에서 큰 도약을 이루어 웹 애플리케이션을 만들고 복잡한 코딩 작업을 효율적으로 수행할 수 있습니다.\n\n셋째, 다중 모드 기능입니다. 다양한 형식의 방대한 정보를 처리할 수 있는 긴 맥락 창을 갖춘 제미니 2.5는 복잡한 작업을 수행하기 위해 설계되었습니다.\n\n개발자들은 구글 AI 스튜디오에서 제미니 2.5 프로를 사용할 수 있으며, 곧 Vertex AI에서도 더 널리 제공될 예정입니다. 모델의 기능을 더욱 향상시키기 위해 피드백을 적극적으로 수렴할 계획입니다.",
      "ja": "Google DeepMindは、最新のAIモデル「Gemini 2.5」を発表しました。このモデルは、複雑な問題を解決するために設計されており、推論能力とコーディング能力が向上しています。初期リリースの「Gemini 2.5 Pro Experimental」は、さまざまなベンチマークで高得点を達成し、従来のモデルに比べて大幅な改善を示しています。\n\nGemini 2.5の主な特徴には、まず「強化された推論能力」があります。このモデルは単なる予測を超え、情報を分析して論理的な判断を下すことができます。数学や科学のテストで優れた成績を収めており、高価な技術を使用することなく成果を上げています。\n\n次に「高度なコーディング能力」が挙げられます。Gemini 2.5 Proは、ウェブアプリを作成したり、複雑なコーディング作業を効率的に実行したりする能力において大きな進歩を遂げています。\n\nさらに「マルチモーダル機能」も特徴です。Gemini 2.5は、テキスト、音声、画像などさまざまな形式の情報を扱える長いコンテキストウィンドウを持ち、複雑なタスクに対応できるように設計されています。\n\n開発者はGoogle AI StudioでGemini 2.5 Proを使用開始でき、今後Vertex AIでも広く利用可能になる予定です。モデルの能力をさらに向上させるために、フィードバックが奨励されています。"
    }
  },
  {
    "id": "8cad349fd68f13a5",
    "title": {
      "en": "VGGT: Visual Geometry Grounded Transformer",
      "ko": "비주얼 기하학 변환기",
      "ja": "VGGT: 視覚幾何変換器"
    },
    "type": "story",
    "url": "https://github.com/facebookresearch/vggt",
    "score": 181,
    "by": "xnx",
    "time": 1742907566,
    "content": "VGGT: Visual Geometry Grounded Transformer\n\nVisual Geometry Group, University of Oxford; Meta AI\nJianyuan Wang, Minghao Chen, Nikita Karaev, Andrea Vedaldi, Christian Rupprecht, David Novotny\n\n@inproceedings{wang2025vggt,\n  title={VGGT: Visual Geometry Grounded Transformer},\n  author={Wang, Jianyuan and Chen, Minghao and Karaev, Nikita and Vedaldi, Andrea and Rupprecht, Christian and Novotny, David},\n  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},\n  year={2025}\n}\n\nOverview\nVisual Geometry Grounded Transformer (VGGT, CVPR 2025) is a feed-forward neural network that directly infers all key 3D attributes of a scene, including extrinsic and intrinsic camera parameters, point maps, depth maps, and 3D point tracks, from one, a few, or hundreds of its views, within seconds.\nQuick Start\nFirst, clone this repository to your local machine, and install the dependencies (torch, torchvision, numpy, Pillow, and huggingface_hub).\ngit clone git@github.com:facebookresearch/vggt.git\ncd vggt\npip install -r requirements.txt\n\nAlternatively, you can install VGGT as a package (click here for details).\nNow, try the model with just a few lines of code:\nimport torch\nfrom vggt.models.vggt import VGGT\nfrom vggt.utils.load_fn import load_and_preprocess_images\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n# bfloat16 is supported on Ampere GPUs (Compute Capability 8.0+)\ndtype = torch.bfloat16 if torch.cuda.get_device_capability()[0] >= 8 else torch.float16\n\n# Initialize the model and load the pretrained weights.\n# This will automatically download the model weights the first time it's run, which may take a while.\nmodel = VGGT.from_pretrained(\"facebook/VGGT-1B\").to(device)\n\n# Load and preprocess example images (replace with your own image paths)\nimage_names = [\"path/to/imageA.png\", \"path/to/imageB.png\", \"path/to/imageC.png\"]\nimages = load_and_preprocess_images(image_names).to(device)\n\nwith torch.no_grad():\n    with torch.cuda.amp.autocast(dtype=dtype):\n        # Predict attributes including cameras, depth maps, and point maps.\n        predictions = model(images)\n\nThe model weights will be automatically downloaded from Hugging Face. If you encounter issues such as slow loading, you can manually download them here and load, or:\nmodel = VGGT()\n_URL = \"https://huggingface.co/facebook/VGGT-1B/resolve/main/model.pt\"\nmodel.load_state_dict(torch.hub.load_state_dict_from_url(_URL))\n\nDetailed Usage\nYou can also optionally choose which attributes (branches) to predict, as shown below. This achieves the same result as the example above. This example uses a batch size of 1 (processing a single scene), but it naturally works for multiple scenes.\nfrom vggt.utils.pose_enc import pose_encoding_to_extri_intri\nfrom vggt.utils.geometry import unproject_depth_map_to_point_map\n\nwith torch.no_grad():\n    with torch.cuda.amp.autocast(dtype=dtype):\n        images = images[None]  # add batch dimension\n        aggregated_tokens_list, ps_idx = model.aggregator(images)\n\n    # Predict Cameras\n    pose_enc = model.camera_head(aggregated_tokens_list)[-1]\n    # Extrinsic and intrinsic matrices, following OpenCV convention (camera from world)\n    extrinsic, intrinsic = pose_encoding_to_extri_intri(pose_enc, images.shape[-2:])\n\n    # Predict Depth Maps\n    depth_map, depth_conf = model.depth_head(aggregated_tokens_list, images, ps_idx)\n\n    # Predict Point Maps\n    point_map, point_conf = model.point_head(aggregated_tokens_list, images, ps_idx)\n\n    # Construct 3D Points from Depth Maps and Cameras\n    # which usually leads to more accurate 3D points than point map branch\n    point_map_by_unprojection = unproject_depth_map_to_point_map(depth_map.squeeze(0),\n                                                                extrinsic.squeeze(0),\n                                                                intrinsic.squeeze(0))\n\n    # Predict Tracks\n    # choose your own points to track, with shape (N, 2) for one scene\n    query_points = torch.FloatTensor([[100.0, 200.0],\n                                        [60.72, 259.94]]).to(device)\n    track_list, vis_score, conf_score = model.track_head(aggregated_tokens_list, images, ps_idx, query_points=query_points[None])\n\nFurthermore, if certain pixels in the input frames are unwanted (e.g., reflective surfaces, sky, or water), you can simply mask them by setting the corresponding pixel values to 0 or 1. Precise segmentation masks aren't necessary - simple bounding box masks work effectively (check this issue for an example).\nVisualization\nWe provide multiple ways to visualize your 3D reconstructions and tracking results. Before using these visualization tools, install the required dependencies:\npip install -r requirements_demo.txt\n\nInteractive 3D Visualization\nPlease note: VGGT typically reconstructs a scene in less than 1 second. However, visualizing 3D points may take tens of seconds due to third-party rendering, independent of VGGT's processing time. The visualization is slow especially when the number of images is large.\nGradio Web Interface\nOur Gradio-based interface allows you to upload images/videos, run reconstruction, and interactively explore the 3D scene in your browser. You can launch this in your local machine or try it on Hugging Face.\npython demo_gradio.py\n\nClick to preview the Gradio interactive interface\n\nViser 3D Viewer\nRun the following command to run reconstruction and visualize the point clouds in viser. Note this script requires a path to a folder containing images. It assumes only image files under the folder. You can set --use_point_map to use the point cloud from the point map branch, instead of the depth-based point cloud.\npython demo_viser.py --image_folder path/to/your/images/folder\n\nTrack Visualization\nTo visualize point tracks across multiple images:\nfrom vggt.utils.visual_track import visualize_tracks_on_images\ntrack = track_list[-1]\nvisualize_tracks_on_images(images, track, (conf_score>0.2) & (vis_score>0.2), out_dir=\"track_visuals\")\n\nThis plots the tracks on the images and saves them to the specified output directory.\nSingle-view Reconstruction\nOur model shows surprisingly good performance on single-view reconstruction, although it was never trained for this task. The model does not need to duplicate the single-view image to a pair, instead, it can directly infer the 3D structure from the tokens of the single view image. Feel free to try it with our demos above, which naturally works for single-view reconstruction.\nWe did not quantitatively test monocular depth estimation performance ourselves, but @kabouzeid generously provided a comparison of VGGT to recent methods here. VGGT shows competitive or better results compared to state-of-the-art monocular approaches such as DepthAnything v2 or MoGe, despite never being explicitly trained for single-view tasks.\nRuntime and GPU Memory\nWe benchmark the runtime and GPU memory usage of VGGT's aggregator on a single NVIDIA H100 GPU across various input sizes.\n\nInput Frames\n1\n2\n4\n8\n10\n20\n50\n100\n200\n\nTime (s)\n0.04\n0.05\n0.07\n0.11\n0.14\n0.31\n1.04\n3.12\n8.75\n\nMemory (GB)\n1.88\n2.07\n2.45\n3.23\n3.63\n5.58\n11.41\n21.15\n40.63\n\nNote that these results were obtained using Flash Attention 3, which is faster than the default Flash Attention 2 implementation while maintaining almost the same memory usage. Feel free to compile Flash Attention 3 from source to get better performance.\nResearch Progression\nOur work builds upon a series of previous research projects. If you're interested in understanding how our research evolved, check out our previous works:\n\n      Deep SfM Revisited\n\n    ──┐\n\n      PoseDiffusion\n\n    ─────►\n\n      VGGSfM ──►\n      VGGT\n\n      CoTracker\n\n    ──┘\n\nAcknowledgements\nThanks to these great repositories: PoseDiffusion, VGGSfM, CoTracker, DINOv2, Dust3r, Moge, PyTorch3D, Sky Segmentation, Depth Anything V2, Metric3D and many other inspiring works in the community.\nChecklist\n\n Release the training code\n Release VGGT-500M and VGGT-200M\n\nLicense\nSee the LICENSE file for details about the license under which this code is made available.",
    "summary": {
      "en": "**VGGT: Visual Geometry Grounded Transformer Overview**\n\nVGGT is a new neural network developed by researchers from the University of Oxford and Meta AI, designed to quickly infer important 3D attributes of a scene from one or more images. It can determine camera parameters, depth maps, and 3D point tracks in just seconds.\n\n**Getting Started:**\n1. Clone the repository and install necessary packages:\n   ```bash\n   git clone git@github.com:facebookresearch/vggt.git\n   cd vggt\n   pip install -r requirements.txt\n   ```\n2. Use a few lines of code to load and run the model:\n   ```python\n   import torch\n   from vggt.models.vggt import VGGT\n   ...\n   model = VGGT.from_pretrained(\"facebook/VGGT-1B\").to(device)\n   ```\n\n**Key Features:**\n- **Attribute Prediction:** You can choose which attributes to predict, such as camera parameters, depth maps, and point maps.\n- **Masking:** You can mask out unwanted pixels in images without needing precise segmentation.\n- **Visualization Tools:** VGGT provides various ways to visualize 3D reconstructions and tracking results, including an interactive Gradio web interface.\n\n**Performance:**\n- VGGT can perform single-view reconstruction effectively, even without training explicitly for it, showing competitive results against other methods.\n- The model runs efficiently on NVIDIA GPUs, with specific benchmarks available for runtime and memory usage.\n\n**Research Background:** VGGT builds on previous research projects, showing a progression of development in this field.\n\n**Acknowledgements:** The development acknowledges contributions from various related projects and communities.\n\n**License:** Refer to the provided LICENSE file for licensing details.",
      "ko": "VGGT는 옥스포드 대학교와 메타 AI의 연구자들이 개발한 새로운 신경망으로, 하나 이상의 이미지에서 장면의 중요한 3D 속성을 신속하게 추론할 수 있도록 설계되었습니다. 이 모델은 카메라 매개변수, 깊이 맵, 3D 포인트 트랙을 몇 초 만에 결정할 수 있습니다.\n\n시작하려면 먼저 저장소를 복제하고 필요한 패키지를 설치해야 합니다. 이를 위해 명령어를 입력하여 저장소를 클론하고, 해당 디렉토리로 이동한 후 요구 사항 파일에 따라 패키지를 설치합니다. 그런 다음 몇 줄의 코드로 모델을 로드하고 실행할 수 있습니다. 예를 들어, PyTorch를 사용하여 VGGT 모델을 불러오고 장치에 맞게 설정할 수 있습니다.\n\nVGGT의 주요 기능 중 하나는 속성 예측입니다. 사용자는 카메라 매개변수, 깊이 맵, 포인트 맵 등 예측할 속성을 선택할 수 있습니다. 또한, 불필요한 픽셀을 마스킹할 수 있는 기능이 있어 정밀한 분할 없이도 이미지를 처리할 수 있습니다. VGGT는 3D 재구성과 추적 결과를 시각화할 수 있는 다양한 도구를 제공하며, 인터랙티브한 Gradio 웹 인터페이스를 통해 쉽게 사용할 수 있습니다.\n\n성능 면에서 VGGT는 단일 뷰 재구성을 효과적으로 수행할 수 있으며, 이를 위해 특별히 훈련하지 않아도 경쟁력 있는 결과를 보여줍니다. 이 모델은 NVIDIA GPU에서 효율적으로 실행되며, 런타임과 메모리 사용에 대한 특정 벤치마크도 제공됩니다.\n\nVGGT는 이전 연구 프로젝트를 기반으로 하여 이 분야의 발전을 보여줍니다. 개발 과정에서 여러 관련 프로젝트와 커뮤니티의 기여를 인정하고 있습니다. 라이센스 관련 세부사항은 제공된 라이센스 파일을 참조하면 됩니다.",
      "ja": "VGGTは、オックスフォード大学とMeta AIの研究者によって開発された新しいニューラルネットワークです。この技術は、1枚または複数の画像からシーンの重要な3D属性を迅速に推測することができます。カメラのパラメータ、深度マップ、3Dポイントトラックを数秒で特定することが可能です。\n\n始めるには、まずリポジトリをクローンし、必要なパッケージをインストールします。コマンドラインで以下の手順を実行します。最初にリポジトリをクローンし、次に必要な依存関係をインストールします。その後、数行のコードを使ってモデルを読み込み、実行します。\n\nVGGTの主な機能には、属性予測、マスキング、視覚化ツールがあります。属性予測では、カメラのパラメータや深度マップ、ポイントマップなど、予測したい属性を選択できます。マスキング機能を使えば、正確なセグメンテーションなしに画像内の不要なピクセルを除去できます。また、VGGTは3D再構成やトラッキング結果を視覚化するためのさまざまなツールを提供しており、インタラクティブなGradioウェブインターフェースも利用できます。\n\n性能面では、VGGTは単一視点の再構成を効果的に行うことができ、特にそのために訓練されていなくても、他の手法と競争力のある結果を示します。このモデルはNVIDIAのGPU上で効率的に動作し、実行時間やメモリ使用量に関する特定のベンチマークも提供されています。\n\nVGGTは、これまでの研究プロジェクトを基にしており、この分野での開発の進展を示しています。また、開発にはさまざまな関連プロジェクトやコミュニティからの貢献があったことが認められています。ライセンスの詳細については、提供されたLICENSEファイルを参照してください。"
    }
  },
  {
    "id": "40cb2f12b7e646c2",
    "title": {
      "en": "The highest-ranking personal blogs of Hacker News",
      "ko": "해커뉴스 인기 블로그",
      "ja": "ハッカーニュースの人気ブログ"
    },
    "type": "story",
    "url": "https://refactoringenglish.com/tools/hn-popularity/",
    "score": 380,
    "by": "sharjeelsayed",
    "time": 1742928537,
    "content": "HN Popularity ContestThe highest-ranking personal blogs of Hacker News\n[ Methodology]Dates:\nAll timeLast yearYear to dateLast 12 monthsLast 5 yearsCustomStart:\nEnd:\nRankDomainTotal ScoreAuthorBioTopicsSubmissions1paulgraham.com96,443Paul GrahamCo-founder of Y Combinator, entrepreneur, and essayiststartups, technology, essaysStories2krebsonsecurity.com83,047Brian KrebsIndependent journalistsecurity, malware, fraudStories3jvns.ca50,092Julia EvansDeveloper and zine authorlinux, debugging, dnsStories4danluu.com48,169Dan LuuEngineer and writerhardware, software, performanceStories5daringfireball.net47,248John GruberTechnology bloggerApple, technology, designStories6simonwillison.net46,596Simon WillisonDeveloper and co-creator of Djangosoftware development, data journalism, AIStories7stratechery.com44,237Ben ThompsonTechnology analystbusiness, technology, mediaStories8righto.com41,876Ken ShirriffVintage computer enthusiastcomputer history, vintage computers, reverse engineeringStories9troyhunt.com41,875Troy HuntSecurity expert and instructorsecurity, data breaches, web securityStories10kalzumeus.com41,254Patrick McKenzieDeveloper and consultantproduct pricing, a-b testing, conversion optimizationStories11rachelbythebay.com40,899Rachel KrollInfrastructure engineersoftware engineering, personal experiences, technologyStories12schneier.com40,332Bruce SchneierSecurity technologist and authorsecurity, cryptography, privacyStories13jacquesmattheij.com39,362Jacques MattheijEntrepreneur and technologiststartups, technology, personal projectsStories14shkspr.mobi38,163Terence EdenTechnology consultant and writeropen data, technology, digital rightsStories15blog.samaltman.com35,470Sam AltmanEntrepreneur and investorstartups, technology, economicsStories16marco.org34,476Marco ArmentDeveloper and podcastertechnology, software development, podcastsStories17utcc.utoronto.ca/~cks33,462Chris SiebenmannUnix system administrator at University of TorontoUnix, system administration, linuxStories18blog.codinghorror.com32,629Jeff AtwoodDeveloper and co-founder of Stack Overflowsoftware development, coding practices, technologyStories19drewdevault.com31,984Drew DeVaultDeveloper and open-source advocateopen-source, software development, technologyStories20ciechanow.ski30,956Bartosz CiechanowskiAuthor of interactive articlesphysics, engineering, visualizationsStories21tbray.org30,299Tim BrayTechnologist and writertechnology, software development, XMLStories22sive.rs29,822Derek SiversEntrepreneur and authorentrepreneurship, music, personal developmentStories23antirez.com28,879Salvatore SanfilippoCreator of Redisdatabases, open-source, software developmentStories24jeffgeerling.com26,783Jeff GeerlingDeveloper and YouTube creatorRaspberry Pi, Ansible, open-sourceStories25fabiensanglard.net26,489Fabien SanglardSoftware developer and authorgame development, software engineering, retro computingStories26jgc.org25,390John Graham-CummingCTO of Cloudflareprogramming, technology, historyStories27devblogs.microsoft.com/oldnewthing25,242Raymond ChenVeteran Microsoft engineerWindows development, programming, software historyStories28daniel.haxx.se24,850Daniel StenbergCreator of cURLnetworking, open-source, software developmentStories29gwern.net23,580Gwern BranwenResearcher and writerpsychology, statistics, technologyStories30steveblank.com21,287Steve BlankEntrepreneur and educatorstartups, entrepreneurship, lean startup methodologyStories31lemire.me20,717Daniel LemireComputer science professoralgorithms, performance, data scienceStories32johndcook.com20,450John D. CookConsultant and mathematicianmathematics, statistics, software developmentStories33hanselman.com20,431Scott HanselmanDeveloper and speakersoftware development, productivity, technologyStories34martinfowler.com20,269Martin FowlerSoftware development expertsoftware architecture, refactoring, agile developmentStories35gatesnotes.com18,493Bill GatesPhilanthropist and technologistglobal health, education, technologyStories36tonsky.me18,166Nikita ProkopovDeveloper and designersoftware development, design, typographyStories37nullprogram.com18,002Chris WellonsSoftware developerprogramming, emacs, software engineeringStories38filfre.net17,938Jimmy MaherWriter and historiancomputer history, interactive fiction, technologyStories39blog.plover.com17,815Mark DominusPerl software developer and amateur mathematicianPerl, mathematics, software developmentStories40antipope.org17,784Charles StrossScience fiction authorscience fiction, technology, politicsStories41blog.acolyer.org17,622Adrian ColyerTechnology analystcomputer science research, technology, software engineeringStories42pluralistic.net17,595Cory DoctorowAuthor and activistactivism, technology, copyrightStories43idlewords.com17,157Maciej CegłowskiDeveloper and writertechnology, culture, travelStories44slatestarcodex.com17,128Scott AlexanderPsychiatrist and bloggerrationality, psychology, cultureStories45dynomight.net16,960Anonymousscience, existential angstStories46brendangregg.com16,814Brendan GreggPerformance engineerperformance engineering, systems, technologyStories47mjg59.dreamwidth.org16,589Matthew GarrettSecurity developersecurity, Linux, open-sourceStories48mtlynch.io 16,119Michael LynchIndie founder and s'mores enthusiastsoftware engineering, entrepreneurship, homelabStories49scottaaronson.com15,703Scott AaronsonComputer science professorquantum computing, computer science, philosophyStories50pragmaticengineer.com15,501Gergely OroszSoftware engineersoftware engineering, career development, technologyStories51blog.cryptographyengineering.com15,447Matthew GreenCryptographercryptography, security, privacyStories52daemonology.net15,331Colin PercivalFreeBSD contributor and founder of Tarsnapsecurity, backups, open-sourceStories53justine.lol15,082Justine TunneySoftware developer and creator of cosmopolitan libcprogramming, operating systems, technologyStories54joelonsoftware.com14,717Joel SpolskySoftware developer and entrepreneursoftware development, startups, project managementStories55xeiaso.net14,488Xe IasoSoftware developersoftware development, Rust programming, NixStories56zachholman.com14,231Zach HolmanDeveloper and speakersoftware development, startups, GitHubStories57prog21.dadgum.com14,132James HagueGame designer and software developersoftware development, game developmentStories58neal.fun14,126Neal AgarwalInteractive web developer and designerweb development, creative coding, interactive designStories59catonmat.net13,978Peteris KruminsDeveloper and entrepreneurprogramming, productivity, technologyStories60randomascii.wordpress.com13,907Bruce DawsonSoftware developerprogramming, debugging, performanceStories61worrydream.com13,866Bret VictorDesigner and engineeruser interfaces, programming, technologyStories62bunniestudios.com13,796Andrew \"Bunnie\" HuangHacker and hardware developerhardware hacking, open-source, technologyStories63lucumr.pocoo.org13,652Armin RonacherSoftware developer and creator of FlaskPython, open-source, software developmentStories64hillelwayne.com13,175Hillel WayneConsultant and authorformal methods, software engineering, technologyStories65matt.might.net13,105Matt MightComputer science professorcomputer science, healthcare, technologyStories66apenwarr.ca13,086Avery PennarunCEO of Tailscalenetworking, software development, technologyStories67astralcodexten.com12,994Scott AlexanderPsychiatrist and bloggerrationalism, psychology, cultureStories68acoup.blog12,821Bret DevereauxHistorianhistory, military history, cultureStories69buttondown.com/hillelwayne12,618Hillel WayneConsultant and authorformal methods, software engineering, technologyStories70eli.thegreenplace.net12,572Eli BenderskySoftware developerprogramming, compilers, technologyStories71gabrielweinberg.com12,567Gabriel WeinbergCEO of DuckDuckGoprivacy, entrepreneurship, technologyStories72xkcd.com12,460Randall MunroeCartoonist and authorcomics, science, technologyStories73asmartbear.com12,409Jason CohenFounder of WPEngine and Smart Bearstartups, entrepreneurship, software developmentStories74austinhenley.com12,229Austin HenleySoftware developer and researcherprogramming, software development, researchStories75blog.regehr.org12,162John RegehrComputer science professorcompilers, software engineering, programming languagesStories76stephendiehl.com12,103Stephen DiehlSoftware developer and Haskell enthusiastHaskell, software development, programming languagesStories77robertheaton.com11,981Robert HeatonSoftware developerprogramming, security, technologyStories78jwz.org11,768Jamie ZawinskiSoftware developer and early Netscape engineersoftware development, technology, personal blogStories79marginalia.nu11,445Viktor LofgrenFounder of Marginalia search engineweb development, design, technologyStories80lapcatsoftware.com11,398Jeff JohnsonmacOS security researchersecurity, macOS, iOSStories81filippo.io11,226Filippo ValsordaSecurity engineer and cryptographersecurity, cryptography, software engineeringStories82robert.ocallahan.org11,023Robert O'CallahanSoftware developerprogramming, debugging, technologyStories83bellard.org10,935Fabrice BellardSoftware prodigy and creator of FFmpeg and QEMUsoftware development, multimedia processing, emulationStories84yosefk.com10,910Yosef MendelsohnSoftware engineer and bloggersoftware development, C++, programming languagesStories85blog.benjojo.co.uk10,797Ben CoxSoftware engineer and infrastructure expertsoftware development, infrastructure, networkingStories86fasterthanli.me10,760Amos WengerRust enthusiast and YouTube creatorRust programming, software development, programming languagesStories87backreaction.blogspot.com10,760Sabine HossenfelderTheoretical physicistphysics, science communication, researchStories88berthub.eu10,757Bert HubertSoftware developer and entrepreneurDNS, software development, technologyStories89blog.fogus.me10,744Michael FogusSoftware developer and authorfunctional programming, software development, ClojureStories90ctrl.blog10,730Daniel AleksandersenDevelopersecurity, Windows, web browsersStories91brandur.org10,717Brandur LeachSoftware engineer and writersoftware development, databases, infrastructureStories92aphyr.com10,608Kyle KingsburyDistributed systems engineer and researcherdistributed systems, databases, software engineeringStories93evanmiller.org10,603Evan MillerSoftware developer and statisticiansoftware development, statistics, data analysisStories94mattstoller.substack.com10,488Matt StollerAuthor and antitrust policy expertantitrust, politics, economyStories95research.swtch.com10,366Russ CoxPrincipal engineer at Googleprogramming, software engineering, Go languageStories96calnewport.com10,334Cal NewportComputer science professor and authorproductivity, deep work, computer scienceStories97norvig.com10,297Peter NorvigDirector of Research at Google and AI expertartificial intelligence, programming, researchStories98joshwcomeau.com10,270Josh W. ComeauSoftware developer and educatorweb development, React, JavaScriptStories99aaronsw.com10,090Aaron SwartzInternet activist and programmerinternet freedom, programming, activismStories100matklad.github.io9,999Alex KladovSoftware developer and Rust contributorRust, software development, programming languagesStoriesLimit:\n10025050010005000 Correctionsfunction formatDate(e){const t=e.getFullYear(),n=String(e.getMonth()+1).padStart(2,\"0\"),s=String(e.getDate()).padStart(2,\"0\");return`${t}-${n}-${s}`}function getUrlParam(e,t=null){const n=new URLSearchParams(window.location.search);return n.get(e)||t}function setUrlParams(e){const t=new URLSearchParams(window.location.search);for(const[n,s]of Object.entries(e))s?t.set(n,s):t.delete(n);const n=`${window.location.pathname}${t.toString()?`?${t.toString()}`:\"\"}`;window.history.pushState({},\"\",n)}function parseCSV(e){const t=Papa.parse(e,{header:!0,delimiter:\",\",skipEmptyLines:!0});return t.data}const timeSelect=document.getElementById(\"time-choose\"),startDateInput=document.getElementById(\"start-date\"),endDateInput=document.getElementById(\"end-date\"),limitInput=document.getElementById(\"result-limit\"),tableBody=document.querySelector(\"#resultsTable tbody\"),HN_LAUNCH_DATE=\"2006-10-09\",CURRENT_DATE=formatDate(new Date),DOMAINS_META_URL=\"https://hn-popularity.cdn.refactoringenglish.com/domains-meta.csv\",HN_DATA_URL=\"https://hn-popularity.cdn.refactoringenglish.com/hn-data.csv\",authors={},rows=[];startDateInput.min=HN_LAUNCH_DATE,startDateInput.max=CURRENT_DATE,endDateInput.min=HN_LAUNCH_DATE,endDateInput.max=CURRENT_DATE;const startParam=getUrlParam(\"start\"),endParam=getUrlParam(\"end\");startDateInput.value=startParam||(timeSelect.value===\"All time\"?HN_LAUNCH_DATE:\"\"),endDateInput.value=endParam||CURRENT_DATE,(startParam||endParam)&&(timeSelect.value=\"Custom\");const limitFromUrl=getUrlParam(\"limit\");limitFromUrl&&(limitInput.value=limitFromUrl);function renderTableAndUpdateUrl(){renderTable(),setUrlParams({start:startDateInput.value,end:endDateInput.value,limit:limitInput.value})}function generateAlgoliaUrl(e,t,n){const s=Math.floor(new Date(t).getTime()/1e3),o=Math.floor(new Date(n).getTime()/1e3);return`https://hn.algolia.com/?dateRange=custom&dateStart=${s}&dateEnd=${o}&page=0&prefix=true&sort=byPopularity&type=story&minWordSizefor1Typo=1000&minWordSizefor2Typos=1000&query=${e}`}function showLoadingIndicator(){tableBody.innerHTML=`\n          <tr>\n            <td colspan=\"7\" class=\"text-center p-5\">\n              <div class=\"spinner-border text-primary\" role=\"status\">\n                <span class=\"visually-hidden\">Loading...</span>\n              </div>\n              <p class=\"mt-2\">Loading data...</p>\n            </td>\n          </tr>\n        `}function showNoDataMessage(){tableBody.innerHTML=`\n          <tr>\n            <td colspan=\"7\" class=\"text-center p-3\">\n              <div class=\"alert alert-info\">\n                No data found for the selected date range.\n              </div>\n            </td>\n          </tr>\n        `}function filterRowsByDateRange(e,t,n){return e.filter(e=>e.date>=t&&e.date<n)}function calculateDomainScores(e){return e.reduce((e,{domain:t,score:n})=>(e[t]=(e[t]||0)+parseInt(n.trim(),10),e),{})}function createTableRow(e,t,n,s,o){let a=0;const i=tableBody.insertRow();e===\"mtlynch.io\"&&i.classList.add(\"mtlynch-row\"),i.insertCell(a++).textContent=n+1;const r=i.insertCell(a++);r.classList.add(\"domain-col\");const c=document.createElement(\"a\");if(c.href=`https://${e}`,c.textContent=e,r.appendChild(c),e===\"mtlynch.io\"){r.appendChild(document.createTextNode(\" \"));const t=document.createElement(\"span\");t.classList.add(\"thumbnail-container\");const n=document.createElement(\"a\");n.href=\"https://www.kickstarter.com/projects/mtlynch/refactoring-english\",n.target=\"_blank\";const s=document.createElement(\"img\");s.src=\"buy-my-book.webp\",s.alt=\"Refactoring English book\",s.classList.add(\"domain-thumbnail\"),n.appendChild(s);const e=document.createElement(\"a\");e.href=\"https://www.kickstarter.com/projects/mtlynch/refactoring-english\",e.target=\"_blank\",e.classList.add(\"full-size-link\");const o=document.createElement(\"img\");o.src=\"buy-my-book.webp\",o.alt=\"Refactoring English book\",o.classList.add(\"full-size-image\"),e.appendChild(o),t.appendChild(n),t.appendChild(e),r.appendChild(t)}const d=i.insertCell(a++);d.classList.add(\"score-col\"),d.textContent=(new Intl.NumberFormat).format(t);const u=i.insertCell(a++);u.classList.add(\"name-col\");const h=i.insertCell(a++);h.classList.add(\"bio-col\");const m=i.insertCell(a++);m.classList.add(\"topics-col\");const f=authors[e];if(f){const{name:e,bio:t,topics:n}=f;u.textContent=e??\"\",h.textContent=t??\"\",m.textContent=n??\"\"}const p=i.insertCell(a++),l=document.createElement(\"a\");l.href=generateAlgoliaUrl(e,s,o),l.textContent=\"Stories\",p.appendChild(l)}function renderTableContent(e,t,n){if(tableBody.innerHTML=\"\",e.length===0){showNoDataMessage();return}e.forEach(([e,s],o)=>{createTableRow(e,s,o,t,n)})}function renderTable(){const e=startDateInput.value||HN_LAUNCH_DATE,t=endDateInput.value||CURRENT_DATE;if(showLoadingIndicator(),rows.length===0)return;const n=filterRowsByDateRange(rows,e,t),s=calculateDomainScores(n),o=parseInt(limitInput.value,10),i=Object.entries(s).sort((e,t)=>t[1]-e[1]).slice(0,o);renderTableContent(i,e,t)}function showFetchingIndicator(){tableBody.innerHTML=`\n          <tr>\n            <td colspan=\"7\" class=\"text-center p-5\">\n              <div class=\"spinner-border text-primary\" role=\"status\">\n                <span class=\"visually-hidden\">Loading...</span>\n              </div>\n              <p class=\"mt-2\">Fetching data...</p>\n            </td>\n          </tr>\n        `}function showErrorMessage(e){console.error(\"Error fetching or processing data:\",e),tableBody.innerHTML=`\n          <tr>\n            <td colspan=\"7\" class=\"text-center text-danger\">\n              <div class=\"alert alert-danger\">\n                <i class=\"fa-solid fa-circle-exclamation me-2\"></i>\n                Failed to load data. Please try refreshing the page.\n                <div class=\"mt-2 small\">${e.message}</div>\n              </div>\n            </td>\n          </tr>\n        `}function processDomainMetadata(e){const t=parseCSV(e);t.forEach(e=>{const t=e.domain;if(!t)return;authors[t]={name:e[\"author name\"]||\"\",bio:e.bio||\"\",topics:e.topics||\"\"}})}function processHnData(e){const t=parseCSV(e);t.forEach(e=>rows.push(e))}async function fetchAndProcessData(){try{showFetchingIndicator();const[e,t]=await Promise.all([fetch(DOMAINS_META_URL),fetch(HN_DATA_URL)]);if(!e.ok||!t.ok)throw new Error(\"One or more network requests failed\");const n=await e.text(),s=await t.text();processDomainMetadata(n),processHnData(s),renderTable()}catch(e){showErrorMessage(e)}}startDateInput.addEventListener(\"change\",()=>{timeSelect.value=\"Custom\",renderTableAndUpdateUrl()}),endDateInput.addEventListener(\"change\",()=>{timeSelect.value=\"Custom\",renderTableAndUpdateUrl()}),limitInput.addEventListener(\"change\",renderTableAndUpdateUrl),timeSelect.addEventListener(\"change\",e=>{const t=new Date;switch(e.target.value){case\"All time\":{startDateInput.value=HN_LAUNCH_DATE,endDateInput.value=CURRENT_DATE;break}case\"Year to date\":{const e=new Date(t.getFullYear(),0,1);startDateInput.value=formatDate(e),endDateInput.value=formatDate(t);break}case\"Last 12 months\":{const e=new Date(t.getFullYear()-1,t.getMonth(),t.getDate());startDateInput.value=formatDate(e),endDateInput.value=formatDate(t);break}case\"Last 5 years\":{const e=new Date(t.getFullYear()-5,t.getMonth(),t.getDate());startDateInput.value=formatDate(e),endDateInput.value=formatDate(t);break}case\"Last year\":{const e=new Date(t.getFullYear()-1,0,1),n=new Date(t.getFullYear()-1,11,31);startDateInput.value=formatDate(e),endDateInput.value=formatDate(n);break}case\"Custom\":break;default:console.error(`Unexpected time option: '${e.target.value}'`);return}renderTableAndUpdateUrl()}),fetchAndProcessData()",
    "summary": {
      "en": "The Hacker News Popularity Contest ranks personal blogs based on their popularity scores. Here are the top 10 blogs:\n\n1. **Paul Graham** (paulgraham.com) - Focuses on startups, technology, and essays.\n2. **Brian Krebs** (krebsonsecurity.com) - An independent journalist covering security and fraud.\n3. **Julia Evans** (jvns.ca) - A developer writing about Linux and debugging.\n4. **Dan Luu** (danluu.com) - Engineer discussing hardware and software performance.\n5. **John Gruber** (daringfireball.net) - A blogger on Apple and design topics.\n6. **Simon Willison** (simonwillison.net) - Developer focusing on software development and AI.\n7. **Ben Thompson** (stratechery.com) - An analyst writing about business and media.\n8. **Ken Shirriff** (righto.com) - Enthusiast of vintage computers and history.\n9. **Troy Hunt** (troyhunt.com) - Expert in web security and data breaches.\n10. **Patrick McKenzie** (kalzumeus.com) - Developer discussing product pricing and optimization.\n\nThese blogs cover a range of topics including technology, security, startups, and personal insights, making them popular among Hacker News users.",
      "ko": "해커 뉴스 인기 블로그 순위는 개인 블로그의 인기 점수를 기준으로 합니다. 다음은 상위 10개 블로그입니다.\n\n첫 번째는 폴 그레이엄의 블로그로, 스타트업, 기술, 에세이에 대한 내용을 다룹니다. 두 번째는 브라이언 크렙스의 블로그로, 보안과 사기를 다루는 독립 저널리스트입니다. 세 번째는 줄리아 에반스의 블로그로, 리눅스와 디버깅에 관한 글을 쓰는 개발자입니다. 네 번째는 댄 루의 블로그로, 하드웨어와 소프트웨어 성능에 대해 이야기하는 엔지니어입니다. 다섯 번째는 존 그루버의 블로그로, 애플과 디자인 주제를 다루는 블로거입니다.\n\n여섯 번째는 사이먼 윌리슨의 블로그로, 소프트웨어 개발과 인공지능에 집중하는 개발자입니다. 일곱 번째는 벤 톰슨의 블로그로, 비즈니스와 미디어에 대해 글을 쓰는 분석가입니다. 여덟 번째는 켄 시리프의 블로그로, 빈티지 컴퓨터와 역사에 대한 열정을 가진 사람입니다. 아홉 번째는 트로이 헌트의 블로그로, 웹 보안과 데이터 유출 전문가입니다. 마지막으로 열 번째는 패트릭 맥켄지의 블로그로, 제품 가격 책정과 최적화에 대해 논의하는 개발자입니다.\n\n이 블로그들은 기술, 보안, 스타트업, 개인적인 통찰 등 다양한 주제를 다루고 있어 해커 뉴스 사용자들 사이에서 인기가 높습니다.",
      "ja": "Hacker Newsの人気コンテストでは、個人ブログの人気スコアに基づいてランキングが作成されています。以下はトップ10のブログです。\n\n1. ポール・グレアム（paulgraham.com） - スタートアップやテクノロジー、エッセイに焦点を当てています。\n2. ブライアン・クレブス（krebsonsecurity.com） - セキュリティや詐欺を扱う独立したジャーナリストです。\n3. ジュリア・エバンス（jvns.ca） - Linuxやデバッグについて書く開発者です。\n4. ダン・ルー（danluu.com） - ハードウェアとソフトウェアのパフォーマンスについて議論するエンジニアです。\n5. ジョン・グルーバー（daringfireball.net） - Appleやデザインに関するブログを書いています。\n6. サイモン・ウィリソン（simonwillison.net） - ソフトウェア開発やAIに焦点を当てた開発者です。\n7. ベン・トンプソン（stratechery.com） - ビジネスやメディアについて書くアナリストです。\n8. ケン・シリフ（righto.com） - ヴィンテージコンピュータやその歴史に熱中している愛好者です。\n9. トロイ・ハント（troyhunt.com） - ウェブセキュリティやデータ漏洩の専門家です。\n10. パトリック・マッケンジー（kalzumeus.com） - プロダクトの価格設定や最適化について議論する開発者です。\n\nこれらのブログは、テクノロジー、セキュリティ、スタートアップ、個人的な洞察など、さまざまなトピックを扱っており、Hacker Newsのユーザーに人気があります。"
    }
  },
  {
    "id": "f384cec40c455fe2",
    "title": {
      "en": "Show HN: A website for sharing the \"Good, Bad, and Why\"s of urban spaces",
      "ko": "도시 공간 이야기",
      "ja": "都市の声を共有しよう"
    },
    "type": "story",
    "url": "https://dedede.de/en",
    "score": 73,
    "by": "kappasan",
    "time": 1742852887,
    "content": "Community Atlas of Urban Phenomena\n\n    What is dédédé? >>\n\n      Display Options\n\n      Display Options\n\n        Collection:\n\n              All\n              Good\n              Bad\n              Why\n\n              Others\n\n                Title:\n\n        Date:\n\n        All\n\n          Custom Range\n\n            2024/1/1 – 2025/3/27\n\n                    From (Year/Month/Day):\n\n                        2024\n                        2025\n\n                        1\n                        2\n                        3\n                        4\n                        5\n                        6\n                        7\n                        8\n                        9\n                        10\n                        11\n                        12\n\n                        1\n                        2\n                        3\n                        4\n                        5\n                        6\n                        7\n                        8\n                        9\n                        10\n                        11\n                        12\n                        13\n                        14\n                        15\n                        16\n                        17\n                        18\n                        19\n                        20\n                        21\n                        22\n                        23\n                        24\n                        25\n                        26\n                        27\n                        28\n                        29\n                        30\n                        31\n\n                    To (Year/Month/Day):\n\n                        2024\n                        2025\n\n                        1\n                        2\n                        3\n                        4\n                        5\n                        6\n                        7\n                        8\n                        9\n                        10\n                        11\n                        12\n\n                        1\n                        2\n                        3\n                        4\n                        5\n                        6\n                        7\n                        8\n                        9\n                        10\n                        11\n                        12\n                        13\n                        14\n                        15\n                        16\n                        17\n                        18\n                        19\n                        20\n                        21\n                        22\n                        23\n                        24\n                        25\n                        26\n                        27\n                        28\n                        29\n                        30\n                        31\n\n        Tags:\n\n          Others\n\n              Name:\n\n          Design / ArtCulture / HistoryTransportEnergy / InfrastructureTechnologySafety / HealthNature / EnvironmentAccessibilityCommerce / IndustryCommunity\n\n        Area:\n\n          Everywhere\n\n          Set on Map\n\n      Apply\n      Close\n\n        Newest First\n\n        Random\n\n      Everyone's \"dedede\"\n\n  Date SpecifiedTags SpecifiedArea Specified\n\n    162 posts\n\n          Japan\n\n                  Bad\n\n  1000 yen stuck!\n\n      by かっぱちゃん\n\n          Japan\n\n                  Good\n\n  イベント会場へのナビゲーション\n\n      by yt\n\n          Japan\n\n                  Why\n\n  木をくるむ紐\n\n      by yt\n\n          Japan\n\n                  Why\n\n  マンホール周りの印\n\n      by yt\n\n          Japan\n\n                  Good\n\n  うねったベンチ\n\n      by yt\n\n          Japan\n\n                  Good\n                  Why\n\n  角に公園\n\n      by yt\n\n          Japan\n\n                  Good\n                  なつかしいで\n\n  バス運行案内\n\n      by yt\n\n          Japan\n\n                  Good\n\n  みなも\n\n      by ユッタイ\n\n          Japan\n\n                  Good\n                  なつかしいで\n\n  土管！！\n\n      by yt\n\n          コメント機能、返信ができなかったり自分の投稿にはコメント付けられなかったりと現状では不備が多くて使えないですね。次期バージョンでこの辺り改善します！\n\n            Uncategorized\n\n  開発予定\n\n      by yt\n\n            Japan\n\n                  かわいいで\n\n  うるま市のシーサーボラード\n\n      by yt\n\n          Japan\n\n                  かわいいで\n\n  亀塚公園入口のカメ\n\n      by yt\n\n          Japan\n\n                  Good\n\n  うるま市のシーサーボラード\n\n      by ahoelken\n\n          Japan\n\n                  Bad\n\n  ミャクミャク\n\n      by yt\n\n            Japan\n\n                  Good\n\n  シャーデンフロイデ\n\n      by dededekun\n\n          Japan\n\n                  Good\n\n  神戸パークレット\n\n      by yt\n\n          Japan\n\n                  Why\n                  歴史やで\n\n  ミニ鳥居\n\n      by yt\n\n          Japan\n\n                  Good\n                  So Kyoto\n\n  Gion Festival\n\n      by UrbanCow\n\n          Japan\n\n                  Good\n                  かっこいいで\n\n  天王洲の水辺活用\n\n      by かっぱちゃん\n\n          Vietnam\n\n                  Bad\n                  あぶないで\n\n  ハノイの交通事情\n\n      by yt\n\n            Japan\n\n                  Good\n\n  シャーデンフロイデ\n\n      by イタめしお\n\n            Japan\n\n            Uncategorized\n\n  レトロなロゴ\n\n      by yt\n\n          Japan\n\n                  Good\n                  うつくしいで\n\n  レトロなロゴ\n\n      by かっぱちゃん\n\n          Japan\n\n                  Good\n                  Why\n\n  空中園芸\n\n      by かっぱちゃん\n\n          United Kingdom\n\n                  Good\n\n  シャボン玉おじさん with シルクハット\n\n      by イタめしお\n\n          Japan\n\n                  Good\n                  こわいで\n\n  ちょいコワ壁画\n\n      by かっぱちゃん\n\n          Japan\n\n                  Good\n\n  じじあんどばば\n\n      by yt\n\n          Japan\n\n                  Bad\n                  Why\n\n  今にも落ちそうな鉄柵\n\n      by yt\n\n          Japan\n\n                  Bad\n                  Why\n\n  ベランダ？\n\n      by yt\n\n          Japan\n\n                  Good\n\n  今のところ盗まれていない\n\n      by yt\n\n          United Kingdom\n\n                  Good\n\n  このシルエットは？\n\n      by イタめしお\n\n          Italy\n\n                  Bad\n\n  標識が見えない\n\n      by イタめしお\n\n          Japan\n\n                  Good\n                  かわいいで\n\n  TAXI\n\n      by かっぱちゃん\n\n          Vietnam\n\n                  Good\n\n  路上でボードゲーム\n\n      by yt\n\n          Japan\n\n                  Good\n\n  丸の内の花壇＋ファニチャー\n\n      by yt\n\n          Japan\n\n                  Good\n\n  水の通り道\n\n      by yt\n\n          Japan\n\n                  Why\n\n  私たち「も」きれいにしています\n\n      by かっぱちゃん\n\n          Japan\n\n                  Bad\n\n  読めない\n\n      by かっぱちゃん\n\n          Japan\n\n            Uncategorized\n\n  トラクター\n\n      by かっぱちゃん\n\n          Singapore\n\n                  Good\n\n  ブランコ\n\n      by yt\n\n          Australia\n\n                  Why\n\n  チャイナタウン\n\n      by yt\n\n          Japan\n\n                  Good\n                  かっこいいで\n\n  グルチッチ\n\n      by かっぱちゃん\n\n          Japan\n\n                  かっこいいで\n\n  シャーデンフロイデ\n\n      by かっぱちゃん\n\n          Japan\n\n                  Bad\n\n  ベーグル屋\n\n      by かっぱちゃん\n\n          Italy\n\n                  Why\n\n  顔が怖い\n\n      by イタめしお\n\n          Italy\n\n                  Good\n\n  POSTE\n\n      by イタめしお\n\n          Italy\n\n                  Good\n                  Why\n\n  何のためのスペース？\n\n      by イタめしお\n\n          Japan\n\n                  Why\n\n  御所\n\n      by yt\n\n          Japan\n\n                  Good\n                  かわいいで\n\n  ピカ！ピカ！ピカ！\n\n      by かっぱちゃん\n\n          Italy\n\n                  Good\n\n  わかりやすい\n\n      by イタめしお\n\n          Italy\n\n                  Good\n                  Why\n\n  車止めの上に地図\n\n      by イタめしお\n\n          Japan\n\n                  Good\n\n  カッパの皿の乾かないまちづくり！\n\n      by かっぱちゃん\n\n          Japan\n\n                  Bad\n\n  車椅子の人は遠回り\n\n      by yt\n\n          Japan\n\n                  Good\n\n  ええ木や\n\n      by yt\n\n          Italy\n\n                  Good\n\n  チェスのルーク\n\n      by イタめしお\n\n          Italy\n\n                  Why\n\n  妙に高い通路\n\n      by イタめしお\n\n          Italy\n\n                  Good\n\n  ローマ帝国の名残り\n\n      by イタめしお\n\n          Italy\n\n                  Good\n\n  薬局の看板\n\n      by イタめしお\n\n          Japan\n\n                  Good\n\n  ゾウ（？）\n\n      by yt\n\n          Japan\n\n                  Good\n\n  アーケード\n\n      by yonetake\n\n        Load More\n\n  Leaflet | © OpenStreetMap\n\n      RELOAD\n\n    gjgslEgmsf\n\n    1000 yen stuck!\n\n        by かっぱちゃん\n\n    35.643989\n    139.73645\n\n    f9AhztPxHV\n\n    イベント会場へのナビゲーション\n\n        by yt\n\n    35.631744\n    139.742692\n\n    hKOjEJV9mf\n\n    木をくるむ紐\n\n        by yt\n\n    34.996042\n    135.7538\n\n    eL520jFspj\n\n    マンホール周りの印\n\n        by yt\n\n    34.996314\n    135.759217\n\n    ujIY0o28Wn\n\n    うねったベンチ\n\n        by yt\n\n    35.534378\n    135.199769\n\n    j2x0pPGB0P\n\n    角に公園\n\n        by yt\n\n    35.536686\n    135.191789\n\n    cwo9hegEzZ\n\n    バス運行案内\n\n        by yt\n\n    35.029342\n    135.752122\n\n    3p6nC6LrK7\n\n    みなも\n\n        by ユッタイ\n\n    35.621419\n    139.746614\n\n    AHZi3XRmj4\n\n    土管！！\n\n        by yt\n\n    35.658597\n    139.662797\n\n    zljPn1UWVe\n\n    うるま市のシーサーボラード\n\n        by yt\n\n    26.434048\n    127.834253\n\n    5vw862mu5C\n\n    亀塚公園入口のカメ\n\n        by yt\n\n    35.643244\n    139.74005\n\n    zljPn1UWVe\n\n    うるま市のシーサーボラード\n\n        by ahoelken\n\n    26.434048\n    127.834253\n\n    jTTzj3ETe4\n\n    ミャクミャク\n\n        by yt\n\n    34.98725\n    135.755906\n\n    CimzQqTYi4\n\n    シャーデンフロイデ\n\n        by dededekun\n\n    35.651097\n    139.724975\n\n    NU9FneoQA3\n\n    神戸パークレット\n\n        by yt\n\n    34.691806\n    135.191697\n\n    dItxcaqt23\n\n    ミニ鳥居\n\n        by yt\n\n    35.010656\n    135.765611\n\n    GkZt7RSFOu\n\n    Gion Festival\n\n        by UrbanCow\n\n    35.008628\n    135.756689\n\n    DWpjib8icR\n\n    天王洲の水辺活用\n\n        by かっぱちゃん\n\n    35.621217\n    139.747575\n\n    r15HxNV2PO\n\n    ハノイの交通事情\n\n        by yt\n\n    21.033833\n    105.853303\n\n    CimzQqTYi4\n\n    シャーデンフロイデ\n\n        by イタめしお\n\n    35.651097\n    139.724975\n\n    yaf0EjTaUr\n\n    レトロなロゴ\n\n        by yt\n\n    35.008431\n    135.718444\n\n    yaf0EjTaUr\n\n    レトロなロゴ\n\n        by かっぱちゃん\n\n    35.008431\n    135.718444\n\n    TXWvIOdNOg\n\n    空中園芸\n\n        by かっぱちゃん\n\n    35.639797\n    139.736511\n\n    P0e8kSZujS\n\n    ちょいコワ壁画\n\n        by かっぱちゃん\n\n    36.762256\n    137.230347\n\n    b2oP8z1tjF\n\n    じじあんどばば\n\n        by yt\n\n    34.998689\n    135.756775\n\n    cJf2qf0SUg\n\n    今にも落ちそうな鉄柵\n\n        by yt\n\n    35.033139\n    135.743928\n\n    WYBxwjvn55\n\n    ベランダ？\n\n        by yt\n\n    34.997642\n    135.763108\n\n    YD38kUYyxf\n\n    今のところ盗まれていない\n\n        by yt\n\n    35.032786\n    135.745636\n\n    9F0ZedficC\n\n    TAXI\n\n        by かっぱちゃん\n\n    34.689036\n    135.189956\n\n    AqQt5Aatxf\n\n    路上でボードゲーム\n\n        by yt\n\n    21.037906\n    105.849953\n\n    SXpMhNR7gO\n\n    丸の内の花壇＋ファニチャー\n\n        by yt\n\n    35.680544\n    139.763703\n\n    5Rz950WXQT\n\n    水の通り道\n\n        by yt\n\n    35.644406\n    139.734389\n\n    lliNc29upe\n\n    私たち「も」きれいにしています\n\n        by かっぱちゃん\n\n    34.996289\n    135.759506\n\n    TNNJv1sdI8\n\n    読めない\n\n        by かっぱちゃん\n\n    35.665211\n    139.736192\n\n    Dj0GSUA3tX\n\n    トラクター\n\n        by かっぱちゃん\n\n    43.815167\n    142.4747\n\n    j4T61bJXwm\n\n    グルチッチ\n\n        by かっぱちゃん\n\n    35.623389\n    139.749694\n\n    CimzQqTYi4\n\n    シャーデンフロイデ\n\n        by かっぱちゃん\n\n    35.651097\n    139.724975\n\n    RgJLwlLccB\n\n    ベーグル屋\n\n        by かっぱちゃん\n\n    35.669072\n    139.689103\n\n    GPzcn7sz3D\n\n    御所\n\n        by yt\n\n    35.021319\n    135.763961\n\n    oHu7OOo9OY\n\n    ピカ！ピカ！ピカ！\n\n        by かっぱちゃん\n\n    35.715436\n    139.744369\n\n    6XBOPrizOH\n\n    カッパの皿の乾かないまちづくり！\n\n        by かっぱちゃん\n\n    35.713997\n    139.791839\n\n    vBe8i9TKvn\n\n    車椅子の人は遠回り\n\n        by yt\n\n    35.008542\n    135.771331\n\n    12qY1kkdFF\n\n    ええ木や\n\n        by yt\n\n    34.992531\n    135.759828\n\n    zI2o0JYUtl\n\n    ゾウ（？）\n\n        by yt\n\n    36.708064\n    137.212172\n\n    3HIJIXw1qi\n\n    アーケード\n\n        by yonetake\n\n    34.654442\n    135.150467\n\n    eesxjYO7NO\n\n    綺麗だ\n\n        by yonetake\n\n    34.700364\n    135.192854\n\n    avMOehKqrb\n\n    鷹取だけに\n\n        by yt\n\n    34.653175\n    135.139878\n\n    vtXCR75mTi\n\n    何屋かな？米屋だよ\n\n        by yt\n\n    34.652717\n    135.139022\n\n    RlKOJ79I8K\n\n    カゴにゴミ\n\n        by yt\n\n    34.651622\n    135.137878\n\n    lLZ7sId9eR\n\n    井戸\n\n        by Yokokawa\n\n    34.653236\n    135.145663\n\n    lxbEXZmt4W\n\n    雨が降ると室内に水が流れる\n\n        by yt\n\n    34.651383\n    135.138489\n\n    Fzb0VWvfK2\n\n    ブタも住民\n\n        by atsushi\n\n    34.654853\n    135.152153\n\n    k45Y3Admeq\n\n    パークレット\n\n        by matsumoto\n\n    34.653234\n    135.147222\n\n    EtdGy4ThGg\n\n    オーストリアの漁船？\n\n        by Yokokawa\n\n    34.649229\n    135.148946\n\n    BHsxK4IFr4\n\n    手書きのお知らせ\n\n        by yt\n\n    34.655383\n    135.149567\n\n    LyxDGikYoU\n\n    なぜか懐かしい電柱\n\n        by yt\n\n    34.655369\n    135.150283\n\n    XJbQa4driS\n\n    spice up\n\n        by atsushi\n\n    34.654236\n    135.149536\n\n    9l3XCOdLrX\n\n    路地探検\n\n        by NKZW\n\n    34.654755\n    135.151476\n\n    8tecWyxv5g\n\n    靴の部品\n\n        by yonetake\n\n    34.654898\n    135.150522\n\n    2YQEHjp69w\n\n    鉄人街灯\n\n        by yt\n\n    34.655994\n    135.144989\n\n    KTkGFoWfjp\n\n    DIY\n\n        by atsushi\n\n    34.652683\n    135.139042\n\n    CuVRF7pCsN\n\n    綺麗だ\n\n        by yonetake\n\n    34.651507\n    135.138832\n\n    afTYRZIMac\n\n    日本語は三番目\n\n        by furbiko2000\n\n    34.651386\n    135.138581\n\n    iUFeQDhky1\n\n    ごみの問題？\n\n        by furbiko2000\n\n    34.653961\n    135.141097\n\n    4nLrDfmDuo\n\n    稲葉じゃない物置き\n\n        by furbiko2000\n\n    34.653061\n    135.139664\n\n    nzompAHj31\n\n    ふりがな・ベトナム語\n\n        by furbiko2000\n\n    34.651378\n    135.138519\n\n    U60pHBoCis\n\n    ここを見れば\n\n        by furbiko2000\n\n    34.653994\n    135.142975\n\n    y4BQkcAgKS\n\n    激安\n\n        by yonetake\n\n    34.651244\n    135.138379\n\n    xqvSDApIcY\n\n    ラウンドアバウト\n\n        by yonetake\n\n    34.65184\n    135.137764\n\n    CGin9QvW3L\n\n    カラフル住宅\n\n        by yt\n\n    34.653781\n    135.141983\n\n    UBB8FwJfga\n\n    なんだろ\n\n        by yonetake\n\n    34.654259\n    135.1459\n\n    e1d4KKcWFP\n\n    ランチ\n\n        by yonetake\n\n    34.654258\n    135.149108\n\n    rpSzrWWycE\n\n    風にも負けず\n\n        by Kunihiko.Tasai@sony.com\n\n    34.651483\n    135.146628\n\n    nzChX5E0s2\n\n    てつじん！\n\n        by NKZW\n\n    34.655295\n    135.145025\n\n    1w97jaeayi\n\n    はいいろれんが 鉱滓煉瓦\n\n        by asama37\n\n    33.578819\n    130.397839\n\n    emEtsITGtQ\n\n    自宅近くの空き地\n\n        by Atsushi Shimizu(Republic)\n\n    34.692165\n    135.17522\n\n    kGB6oBCpas\n\n    Tropical trees in Kyoto\n\n        by dededekun\n\n    35.013631\n    135.764206\n\n    JB1ujDjgN1\n\n    レトロな路面電車\n\n        by yt\n\n    36.700083\n    137.213286\n\n    BYaMur2qgv\n\n    ベンチのランプ\n\n        by yt\n\n    36.703339\n    137.21425\n\n    AGxg5pntB7\n\n    しょうきさん\n\n        by yt\n\n    35.032872\n    135.745636\n\n    lbsub3MV7S\n\n    禁止事項\n\n        by yt\n\n    35.629806\n    139.746614\n\n    nTzlokbUgR\n\n    消火バケツ\n\n        by yt\n\n    35.03035\n    135.748931\n\n    OAP30J1NCf\n\n    読めない案内板\n\n        by yt\n\n    35.665211\n    139.736192\n\n    WWj4WgfMRJ\n\n    🐿️@芝公園\n\n        by yt\n\n    35.655444\n    139.750014\n\n    qXFgVaEKnC\n\n    ええロゴや\n\n        by yt\n\n    36.688881\n    137.214522\n\n    Ulp85jhjPC\n\n    Chic bench at Takanawa Gateway\n\n        by yt\n\n    35.635608\n    139.740708\n\n    HJeh2rYuD7\n\n    Inflated crows\n\n        by yt\n\n    35.026131\n    135.751372\n\n    LB04Y6dClG\n\n    京都っぽい\n\n        by yt\n\n    34.991528\n    135.759811\n\n    PcHK6LmIsO\n\n    Raised entrances\n\n        by yt\n\n    21.035286\n    105.8525\n\n    RxOKPmR5eJ\n\n    ハワーワーク？\n\n        by yt\n\n    36.704606\n    137.215103\n\n    OEV9FfPJap\n\n    みんなで雪かき\n\n        by yt\n\n    36.700011\n    137.213439\n\n    dnUg1haI5w\n\n    Painted power boxes\n\n        by yt\n\n    21.030931\n    105.848503\n\n    IKhlTxmG3F\n\n    Eating on the street\n\n        by yt\n\n    21.030803\n    105.848131\n\n    feJ1AQj9LG\n\n    謎のタオル\n\n        by yt\n\n    34.997711\n    135.763353\n\n    glenruPYS1\n\n    パークレット@静岡\n\n        by yt\n\n    34.974044\n    138.383956\n\n    rxFP9Msd11\n\n    なつかしい坂\n\n        by yt\n\n    35.644519\n    139.738097\n\n    E9ff2WpMRG\n\n    Mobile flower shop\n\n        by yt\n\n    21.037819\n    105.848944\n\n    zsSyKC9uyG\n\n    Digital display glitch\n\n        by yt\n\n    35.656599\n    139.701778\n\n    xwZNiCXWwD\n\n    東京タワー撮影スポット\n\n        by yt\n\n    35.657875\n    139.743744\n\n    HhcC9WG7UR\n\n    丼太郎\n\n        by yt\n\n    35.716928\n    139.738067\n\n    TKYmpuNtsO\n\n    ええ通路\n\n        by yt\n\n    35.665931\n    139.72525\n\n    5dPJVSirF8\n\n    Electrocution hazard?\n\n        by yt\n\n    21.035406\n    105.852814\n\n    BSVQxO7RTS\n\n    水たまり\n\n        by yt\n\n    35.579406\n    135.197617\n\n    O6mQ8fwy2P\n\n    謎の番号\n\n        by yt\n\n    21.026422\n    105.843575\n\n    EfcRlJV7ej\n\n    読めない\n\n        by yt\n\n    34.997272\n    135.950028\n\n    uPH5Rjo8Gi\n\n    ビール型の街灯\n\n        by yt\n\n    35.646217\n    139.712875\n\n    dEtAHH2RK2\n\n    うなぎ@恵比寿\n\n        by yt\n\n    35.647972\n    139.710372\n\n      Display Options\n\n      Display Options\n\n        Collection:\n\n              All\n              Good\n              Bad\n              Why\n\n              Others\n\n                Title:\n\n        Date:\n\n        All\n\n          Custom Range\n\n            2024/1/1 – 2025/3/27\n\n                    From (Year/Month/Day):\n\n                        2024\n                        2025\n\n                        1\n                        2\n                        3\n                        4\n                        5\n                        6\n                        7\n                        8\n                        9\n                        10\n                        11\n                        12\n\n                        1\n                        2\n                        3\n                        4\n                        5\n                        6\n                        7\n                        8\n                        9\n                        10\n                        11\n                        12\n                        13\n                        14\n                        15\n                        16\n                        17\n                        18\n                        19\n                        20\n                        21\n                        22\n                        23\n                        24\n                        25\n                        26\n                        27\n                        28\n                        29\n                        30\n                        31\n\n                    To (Year/Month/Day):\n\n                        2024\n                        2025\n\n                        1\n                        2\n                        3\n                        4\n                        5\n                        6\n                        7\n                        8\n                        9\n                        10\n                        11\n                        12\n\n                        1\n                        2\n                        3\n                        4\n                        5\n                        6\n                        7\n                        8\n                        9\n                        10\n                        11\n                        12\n                        13\n                        14\n                        15\n                        16\n                        17\n                        18\n                        19\n                        20\n                        21\n                        22\n                        23\n                        24\n                        25\n                        26\n                        27\n                        28\n                        29\n                        30\n                        31\n\n        Tags:\n\n          Others\n\n              Name:\n\n          Design / ArtCulture / HistoryTransportEnergy / InfrastructureTechnologySafety / HealthNature / EnvironmentAccessibilityCommerce / IndustryCommunity\n\n        Area:\n\n          Everywhere\n\n            Custom Area\n\n                5km around Pin\n\n                  Radius (km, 0.5 – 500):\n\n      Apply\n      Close\n\n  +− Leaflet | © OpenStreetMap",
    "summary": {
      "en": "**Community Atlas of Urban Phenomena Summary**\n\nThe Community Atlas of Urban Phenomena is a platform that collects various urban observations, categorized by their nature (good, bad, or why). Users can view and filter posts by collection type, date, tags, and location. \n\nKey features include:\n- A variety of posts from different locations, particularly Japan, with themes related to design, culture, history, technology, and community.\n- Users can share their experiences and present urban phenomena, marked by tags that describe their observations.\n- The interface allows users to apply filters and view posts in different orders, making it easy to find specific content.\n\nOverall, the platform encourages community engagement and sharing of urban experiences, highlighting unique aspects of city life.",
      "ko": "커뮤니티 도시 현상 아틀라스는 다양한 도시 관찰을 수집하는 플랫폼으로, 관찰의 성격에 따라 좋거나 나쁘거나 그 이유로 분류됩니다. 사용자들은 수집 유형, 날짜, 태그, 위치에 따라 게시물을 조회하고 필터링할 수 있습니다.\n\n주요 기능으로는 일본을 포함한 여러 지역에서의 다양한 게시물이 있으며, 디자인, 문화, 역사, 기술, 커뮤니티와 관련된 주제를 다룹니다. 사용자들은 자신의 경험을 공유하고 도시 현상을 소개할 수 있으며, 관찰 내용을 설명하는 태그로 표시됩니다. \n\n인터페이스는 사용자가 필터를 적용하고 게시물을 다양한 순서로 볼 수 있게 하여 특정 내용을 쉽게 찾을 수 있도록 돕습니다. 전반적으로 이 플랫폼은 커뮤니티 참여와 도시 경험 공유를 장려하며, 도시 생활의 독특한 측면을 강조합니다.",
      "ja": "コミュニティアトラス・オブ・アーバンフェノメナは、さまざまな都市の観察を集めたプラットフォームです。これらの観察は、その性質に応じて（良い、悪い、またはその理由）分類されています。ユーザーは、投稿を収集タイプ、日付、タグ、場所によって表示したりフィルターをかけたりすることができます。\n\n主な特徴としては、特に日本のさまざまな場所からの投稿があり、デザイン、文化、歴史、技術、コミュニティに関連するテーマが取り上げられています。ユーザーは自分の体験を共有し、都市現象を紹介することができ、観察内容を示すタグが付けられます。インターフェースは、ユーザーがフィルターを適用し、投稿を異なる順序で表示できるようになっており、特定のコンテンツを見つけやすくなっています。\n\nこのプラットフォームは、コミュニティの参加を促し、都市での体験を共有することを奨励しています。都市生活のユニークな側面を強調することが目的です。"
    }
  },
  {
    "id": "c2487c67e5bef92a",
    "title": {
      "en": "Optimizing ML training with metagradient descent",
      "ko": "메타그래디언트 최적화",
      "ja": "メタ勾配で最適化"
    },
    "type": "story",
    "url": "https://arxiv.org/abs/2503.13751",
    "score": 79,
    "by": "ladberg",
    "time": 1742937755,
    "content": "A major challenge in training large-scale machine learning models is configuring the training process to maximize model performance, i.e., finding the best training setup from a vast design space. In this work, we unlock a gradient-based approach to this problem. We first introduce an algorithm for efficiently calculating metagradients -- gradients through model training -- at scale. We then introduce a \"smooth model training\" framework that enables effective optimization using metagradients. With metagradient descent (MGD), we greatly improve on existing dataset selection methods, outperform accuracy-degrading data poisoning attacks by an order of magnitude, and automatically find competitive learning rate schedules.",
    "summary": {
      "en": "Training large machine learning models is challenging because it requires finding the best setup for optimal performance. This work presents a new method to tackle this issue using metagradients, which are gradients calculated during model training. The authors introduce a framework called \"smooth model training\" that helps optimize the training process with these metagradients. With a technique called metagradient descent (MGD), they enhance existing methods for selecting datasets, significantly outperform data poisoning attacks, and automatically determine effective learning rate schedules.",
      "ko": "대규모 기계 학습 모델을 훈련하는 것은 최적의 성능을 위한 최상의 설정을 찾는 것이 필요하기 때문에 어려운 작업입니다. 이 연구에서는 메타그래디언트라는 훈련 중에 계산되는 그래디언트를 활용하여 이 문제를 해결하는 새로운 방법을 제시합니다. 저자들은 \"부드러운 모델 훈련\"이라는 프레임워크를 도입하여 메타그래디언트를 통해 훈련 과정을 최적화하는 데 도움을 줍니다. 메타그래디언트 하강법(MGD)이라는 기법을 사용하여 데이터셋 선택을 위한 기존 방법을 개선하고, 데이터 오염 공격을 크게 능가하며, 효과적인 학습률 스케줄을 자동으로 결정할 수 있습니다.",
      "ja": "大規模な機械学習モデルのトレーニングは、最適なパフォーマンスを引き出すための最適な設定を見つける必要があるため、非常に難しい作業です。この研究では、モデルのトレーニング中に計算されるメタ勾配を用いてこの問題に取り組む新しい方法が提案されています。著者たちは「スムーズモデルトレーニング」と呼ばれるフレームワークを導入し、メタ勾配を活用してトレーニングプロセスを最適化します。メタ勾配降下法（MGD）という手法を用いることで、データセットの選択に関する既存の方法を強化し、データポイズニング攻撃に対して大幅に優れた性能を発揮し、効果的な学習率のスケジュールを自動的に決定します。"
    }
  },
  {
    "id": "df3b3e0e55315ec3",
    "title": {
      "en": "DuckDB: Development Roadmap",
      "ko": "덕DB 개발 로드맵",
      "ja": "DuckDBの未来図"
    },
    "type": "story",
    "url": "https://duckdb.org/docs/stable/dev/roadmap.html",
    "score": 5,
    "by": "tosh",
    "time": 1742986589,
    "content": "Search Shortcut cmd + k | ctrl + k\n\n\t\t\t\t Installation\n\n\t\t\t\t    Documentation\n\n\t\t\t\t\t\t\t Getting Started\n\n\t\t\t\t\t\t\t Connect\n\n\t\t\t\t\t\t\t\t Overview\n\n\t\t\t\t\t\t\t\t Concurrency\n\n\t\t\t\t\t\t\t Data Import\n\n\t\t\t\t\t\t\t\t Overview\n\n\t\t\t\t\t\t\t\t Data Sources\n\n\t\t\t\t\t\t\t\t CSV Files\n\n\t\t\t\t\t\t\t\t\t  Overview\n\n\t\t\t\t\t\t\t\t\t  Auto Detection\n\n\t\t\t\t\t\t\t\t\t  Reading Faulty CSV Files\n\n\t\t\t\t\t\t\t\t\t  Tips\n\n\t\t\t\t\t\t\t\t JSON Files\n\n\t\t\t\t\t\t\t\t\t  Overview\n\n\t\t\t\t\t\t\t\t\t  Creating JSON\n\n\t\t\t\t\t\t\t\t\t  Loading JSON\n\n\t\t\t\t\t\t\t\t\t  Writing JSON\n\n\t\t\t\t\t\t\t\t\t  JSON Type\n\n\t\t\t\t\t\t\t\t\t  JSON Functions\n\n\t\t\t\t\t\t\t\t\t  Format Settings\n\n\t\t\t\t\t\t\t\t\t  Installing and Loading\n\n\t\t\t\t\t\t\t\t\t  SQL to / from JSON\n\n\t\t\t\t\t\t\t\t\t  Caveats\n\n\t\t\t\t\t\t\t\t Multiple Files\n\n\t\t\t\t\t\t\t\t\t  Overview\n\n\t\t\t\t\t\t\t\t\t  Combining Schemas\n\n\t\t\t\t\t\t\t\t Parquet Files\n\n\t\t\t\t\t\t\t\t\t  Overview\n\n\t\t\t\t\t\t\t\t\t  Metadata\n\n\t\t\t\t\t\t\t\t\t  Encryption\n\n\t\t\t\t\t\t\t\t\t  Tips\n\n\t\t\t\t\t\t\t\t Partitioning\n\n\t\t\t\t\t\t\t\t\t  Hive Partitioning\n\n\t\t\t\t\t\t\t\t\t  Partitioned Writes\n\n\t\t\t\t\t\t\t\t Appender\n\n\t\t\t\t\t\t\t\t INSERT Statements\n\n\t\t\t\t\t\t\t Client APIs\n\n\t\t\t\t\t\t\t\t Overview\n\n\t\t\t\t\t\t\t\t ADBC\n\n\t\t\t\t\t\t\t\t C\n\n\t\t\t\t\t\t\t\t\t  Overview\n\n\t\t\t\t\t\t\t\t\t  Startup\n\n\t\t\t\t\t\t\t\t\t  Configuration\n\n\t\t\t\t\t\t\t\t\t  Query\n\n\t\t\t\t\t\t\t\t\t  Data Chunks\n\n\t\t\t\t\t\t\t\t\t  Vectors\n\n\t\t\t\t\t\t\t\t\t  Values\n\n\t\t\t\t\t\t\t\t\t  Types\n\n\t\t\t\t\t\t\t\t\t  Prepared Statements\n\n\t\t\t\t\t\t\t\t\t  Appender\n\n\t\t\t\t\t\t\t\t\t  Table Functions\n\n\t\t\t\t\t\t\t\t\t  Replacement Scans\n\n\t\t\t\t\t\t\t\t\t  API Reference\n\n\t\t\t\t\t\t\t\t C++\n\n\t\t\t\t\t\t\t\t CLI\n\n\t\t\t\t\t\t\t\t\t  Overview\n\n\t\t\t\t\t\t\t\t\t  Arguments\n\n\t\t\t\t\t\t\t\t\t  Dot Commands\n\n\t\t\t\t\t\t\t\t\t  Output Formats\n\n\t\t\t\t\t\t\t\t\t  Editing\n\n\t\t\t\t\t\t\t\t\t  Safe Mode\n\n\t\t\t\t\t\t\t\t\t  Autocomplete\n\n\t\t\t\t\t\t\t\t\t  Syntax Highlighting\n\n\t\t\t\t\t\t\t\t Dart\n\n\t\t\t\t\t\t\t\t Go\n\n\t\t\t\t\t\t\t\t Java (JDBC)\n\n\t\t\t\t\t\t\t\t Julia\n\n\t\t\t\t\t\t\t\t Node.js (deprecated)\n\n\t\t\t\t\t\t\t\t\t  Overview\n\n\t\t\t\t\t\t\t\t\t  API Reference\n\n\t\t\t\t\t\t\t\t Node.js (Neo)\n\n\t\t\t\t\t\t\t\t\t  Overview\n\n\t\t\t\t\t\t\t\t ODBC\n\n\t\t\t\t\t\t\t\t\t  Overview\n\n\t\t\t\t\t\t\t\t\t  Linux Setup\n\n\t\t\t\t\t\t\t\t\t  Windows Setup\n\n\t\t\t\t\t\t\t\t\t  macOS Setup\n\n\t\t\t\t\t\t\t\t\t  Configuration\n\n\t\t\t\t\t\t\t\t Python\n\n\t\t\t\t\t\t\t\t\t  Overview\n\n\t\t\t\t\t\t\t\t\t  Data Ingestion\n\n\t\t\t\t\t\t\t\t\t  Conversion between DuckDB and Python\n\n\t\t\t\t\t\t\t\t\t  DB API\n\n\t\t\t\t\t\t\t\t\t  Relational API\n\n\t\t\t\t\t\t\t\t\t  Function API\n\n\t\t\t\t\t\t\t\t\t  Types API\n\n\t\t\t\t\t\t\t\t\t  Expression API\n\n\t\t\t\t\t\t\t\t\t  Spark API\n\n\t\t\t\t\t\t\t\t\t  API Reference\n\n\t\t\t\t\t\t\t\t\t  Known Python Issues\n\n\t\t\t\t\t\t\t\t R\n\n\t\t\t\t\t\t\t\t Rust\n\n\t\t\t\t\t\t\t\t Swift\n\n\t\t\t\t\t\t\t\t Wasm\n\n\t\t\t\t\t\t\t\t\t  Overview\n\n\t\t\t\t\t\t\t\t\t  Instantiation\n\n\t\t\t\t\t\t\t\t\t  Data Ingestion\n\n\t\t\t\t\t\t\t\t\t  Query\n\n\t\t\t\t\t\t\t\t\t  Extensions\n\n\t\t\t\t\t\t\t SQL\n\n\t\t\t\t\t\t\t\t Introduction\n\n\t\t\t\t\t\t\t\t Statements\n\n\t\t\t\t\t\t\t\t\t  Overview\n\n\t\t\t\t\t\t\t\t\t  ANALYZE\n\n\t\t\t\t\t\t\t\t\t  ALTER TABLE\n\n\t\t\t\t\t\t\t\t\t  ALTER VIEW\n\n\t\t\t\t\t\t\t\t\t  ATTACH and DETACH\n\n\t\t\t\t\t\t\t\t\t  CALL\n\n\t\t\t\t\t\t\t\t\t  CHECKPOINT\n\n\t\t\t\t\t\t\t\t\t  COMMENT ON\n\n\t\t\t\t\t\t\t\t\t  COPY\n\n\t\t\t\t\t\t\t\t\t  CREATE INDEX\n\n\t\t\t\t\t\t\t\t\t  CREATE MACRO\n\n\t\t\t\t\t\t\t\t\t  CREATE SCHEMA\n\n\t\t\t\t\t\t\t\t\t  CREATE SECRET\n\n\t\t\t\t\t\t\t\t\t  CREATE SEQUENCE\n\n\t\t\t\t\t\t\t\t\t  CREATE TABLE\n\n\t\t\t\t\t\t\t\t\t  CREATE VIEW\n\n\t\t\t\t\t\t\t\t\t  CREATE TYPE\n\n\t\t\t\t\t\t\t\t\t  DELETE\n\n\t\t\t\t\t\t\t\t\t  DESCRIBE\n\n\t\t\t\t\t\t\t\t\t  DROP\n\n\t\t\t\t\t\t\t\t\t  EXPORT and IMPORT DATABASE\n\n\t\t\t\t\t\t\t\t\t  INSERT\n\n\t\t\t\t\t\t\t\t\t  LOAD / INSTALL\n\n\t\t\t\t\t\t\t\t\t  PIVOT\n\n\t\t\t\t\t\t\t\t\t  Profiling\n\n\t\t\t\t\t\t\t\t\t  SELECT\n\n\t\t\t\t\t\t\t\t\t  SET / RESET\n\n\t\t\t\t\t\t\t\t\t  SET VARIABLE\n\n\t\t\t\t\t\t\t\t\t  SUMMARIZE\n\n\t\t\t\t\t\t\t\t\t  Transaction Management\n\n\t\t\t\t\t\t\t\t\t  UNPIVOT\n\n\t\t\t\t\t\t\t\t\t  UPDATE\n\n\t\t\t\t\t\t\t\t\t  USE\n\n\t\t\t\t\t\t\t\t\t  VACUUM\n\n\t\t\t\t\t\t\t\t Query Syntax\n\n\t\t\t\t\t\t\t\t\t  SELECT\n\n\t\t\t\t\t\t\t\t\t  FROM and JOIN\n\n\t\t\t\t\t\t\t\t\t  WHERE\n\n\t\t\t\t\t\t\t\t\t  GROUP BY\n\n\t\t\t\t\t\t\t\t\t  GROUPING SETS\n\n\t\t\t\t\t\t\t\t\t  HAVING\n\n\t\t\t\t\t\t\t\t\t  ORDER BY\n\n\t\t\t\t\t\t\t\t\t  LIMIT and OFFSET\n\n\t\t\t\t\t\t\t\t\t  SAMPLE\n\n\t\t\t\t\t\t\t\t\t  Unnesting\n\n\t\t\t\t\t\t\t\t\t  WITH\n\n\t\t\t\t\t\t\t\t\t  WINDOW\n\n\t\t\t\t\t\t\t\t\t  QUALIFY\n\n\t\t\t\t\t\t\t\t\t  VALUES\n\n\t\t\t\t\t\t\t\t\t  FILTER\n\n\t\t\t\t\t\t\t\t\t  Set Operations\n\n\t\t\t\t\t\t\t\t\t  Prepared Statements\n\n\t\t\t\t\t\t\t\t Data Types\n\n\t\t\t\t\t\t\t\t\t  Overview\n\n\t\t\t\t\t\t\t\t\t  Array\n\n\t\t\t\t\t\t\t\t\t  Bitstring\n\n\t\t\t\t\t\t\t\t\t  Blob\n\n\t\t\t\t\t\t\t\t\t  Boolean\n\n\t\t\t\t\t\t\t\t\t  Date\n\n\t\t\t\t\t\t\t\t\t  Enum\n\n\t\t\t\t\t\t\t\t\t  Interval\n\n\t\t\t\t\t\t\t\t\t  List\n\n\t\t\t\t\t\t\t\t\t  Literal Types\n\n\t\t\t\t\t\t\t\t\t  Map\n\n\t\t\t\t\t\t\t\t\t  NULL Values\n\n\t\t\t\t\t\t\t\t\t  Numeric\n\n\t\t\t\t\t\t\t\t\t  Struct\n\n\t\t\t\t\t\t\t\t\t  Text\n\n\t\t\t\t\t\t\t\t\t  Time\n\n\t\t\t\t\t\t\t\t\t  Timestamp\n\n\t\t\t\t\t\t\t\t\t  Time Zones\n\n\t\t\t\t\t\t\t\t\t  Union\n\n\t\t\t\t\t\t\t\t\t  Typecasting\n\n\t\t\t\t\t\t\t\t Expressions\n\n\t\t\t\t\t\t\t\t\t  Overview\n\n\t\t\t\t\t\t\t\t\t  CASE Expression\n\n\t\t\t\t\t\t\t\t\t  Casting\n\n\t\t\t\t\t\t\t\t\t  Collations\n\n\t\t\t\t\t\t\t\t\t  Comparisons\n\n\t\t\t\t\t\t\t\t\t  IN Operator\n\n\t\t\t\t\t\t\t\t\t  Logical Operators\n\n\t\t\t\t\t\t\t\t\t  Star Expression\n\n\t\t\t\t\t\t\t\t\t  Subqueries\n\n\t\t\t\t\t\t\t\t Functions\n\n\t\t\t\t\t\t\t\t\t  Overview\n\n\t\t\t\t\t\t\t\t\t  Aggregate Functions\n\n\t\t\t\t\t\t\t\t\t  Array Functions\n\n\t\t\t\t\t\t\t\t\t  Bitstring Functions\n\n\t\t\t\t\t\t\t\t\t  Blob Functions\n\n\t\t\t\t\t\t\t\t\t  Date Format Functions\n\n\t\t\t\t\t\t\t\t\t  Date Functions\n\n\t\t\t\t\t\t\t\t\t  Date Part Functions\n\n\t\t\t\t\t\t\t\t\t  Enum Functions\n\n\t\t\t\t\t\t\t\t\t  Interval Functions\n\n\t\t\t\t\t\t\t\t\t  Lambda Functions\n\n\t\t\t\t\t\t\t\t\t  List Functions\n\n\t\t\t\t\t\t\t\t\t  Map Functions\n\n\t\t\t\t\t\t\t\t\t  Nested Functions\n\n\t\t\t\t\t\t\t\t\t  Numeric Functions\n\n\t\t\t\t\t\t\t\t\t  Pattern Matching\n\n\t\t\t\t\t\t\t\t\t  Regular Expressions\n\n\t\t\t\t\t\t\t\t\t  Struct Functions\n\n\t\t\t\t\t\t\t\t\t  Text Functions\n\n\t\t\t\t\t\t\t\t\t  Time Functions\n\n\t\t\t\t\t\t\t\t\t  Timestamp Functions\n\n\t\t\t\t\t\t\t\t\t  Timestamp with Time Zone Functions\n\n\t\t\t\t\t\t\t\t\t  Union Functions\n\n\t\t\t\t\t\t\t\t\t  Utility Functions\n\n\t\t\t\t\t\t\t\t\t  Window Functions\n\n\t\t\t\t\t\t\t\t Constraints\n\n\t\t\t\t\t\t\t\t Indexes\n\n\t\t\t\t\t\t\t\t Meta Queries\n\n\t\t\t\t\t\t\t\t\t  Information Schema\n\n\t\t\t\t\t\t\t\t\t  Metadata Functions\n\n\t\t\t\t\t\t\t\t DuckDB's SQL Dialect\n\n\t\t\t\t\t\t\t\t\t  Overview\n\n\t\t\t\t\t\t\t\t\t  Indexing\n\n\t\t\t\t\t\t\t\t\t  Friendly SQL\n\n\t\t\t\t\t\t\t\t\t  Keywords and Identifiers\n\n\t\t\t\t\t\t\t\t\t  Order Preservation\n\n\t\t\t\t\t\t\t\t\t  PostgreSQL Compatibility\n\n\t\t\t\t\t\t\t\t\t  SQL Quirks\n\n\t\t\t\t\t\t\t\t Samples\n\n\t\t\t\t\t\t\t Configuration\n\n\t\t\t\t\t\t\t\t Overview\n\n\t\t\t\t\t\t\t\t Pragmas\n\n\t\t\t\t\t\t\t\t Secrets Manager\n\n\t\t\t\t\t\t\t Extensions\n\n\t\t\t\t\t\t\t\t Overview\n\n\t\t\t\t\t\t\t\t Core Extensions\n\n\t\t\t\t\t\t\t\t Community Extensions\n\n\t\t\t\t\t\t\t\t Installing Extensions\n\n\t\t\t\t\t\t\t\t Advanced Installation Methods\n\n\t\t\t\t\t\t\t\t Distributing Extensions\n\n\t\t\t\t\t\t\t\t Versioning of Extensions\n\n\t\t\t\t\t\t\t\t Arrow\n\n\t\t\t\t\t\t\t\t AutoComplete\n\n\t\t\t\t\t\t\t\t Avro\n\n\t\t\t\t\t\t\t\t AWS\n\n\t\t\t\t\t\t\t\t Azure\n\n\t\t\t\t\t\t\t\t Delta\n\n\t\t\t\t\t\t\t\t Excel\n\n\t\t\t\t\t\t\t\t Full Text Search\n\n\t\t\t\t\t\t\t\t httpfs (HTTP and S3)\n\n\t\t\t\t\t\t\t\t\t  Overview\n\n\t\t\t\t\t\t\t\t\t  HTTP(S) Support\n\n\t\t\t\t\t\t\t\t\t  Hugging Face\n\n\t\t\t\t\t\t\t\t\t  S3 API Support\n\n\t\t\t\t\t\t\t\t\t  Legacy Authentication Scheme for S3 API\n\n\t\t\t\t\t\t\t\t Iceberg\n\n\t\t\t\t\t\t\t\t\t  Overview\n\n\t\t\t\t\t\t\t\t\t  Amazon S3 Tables\n\n\t\t\t\t\t\t\t\t\t  Amazon SageMaker Lakehouse (AWS Glue)\n\n\t\t\t\t\t\t\t\t\t  Troubleshooting\n\n\t\t\t\t\t\t\t\t ICU\n\n\t\t\t\t\t\t\t\t inet\n\n\t\t\t\t\t\t\t\t jemalloc\n\n\t\t\t\t\t\t\t\t MySQL\n\n\t\t\t\t\t\t\t\t PostgreSQL\n\n\t\t\t\t\t\t\t\t Spatial\n\n\t\t\t\t\t\t\t\t\t  Overview\n\n\t\t\t\t\t\t\t\t\t  Function Reference\n\n\t\t\t\t\t\t\t\t\t  R-Tree Indexes\n\n\t\t\t\t\t\t\t\t\t  GDAL Integration\n\n\t\t\t\t\t\t\t\t SQLite\n\n\t\t\t\t\t\t\t\t TPC-DS\n\n\t\t\t\t\t\t\t\t TPC-H\n\n\t\t\t\t\t\t\t\t UI\n\n\t\t\t\t\t\t\t\t VSS\n\n\t\t\t\t\t\t\t Guides\n\n\t\t\t\t\t\t\t\t Overview\n\n\t\t\t\t\t\t\t\t Data Viewers\n\n\t\t\t\t\t\t\t\t\t  Tableau\n\n\t\t\t\t\t\t\t\t\t  CLI Charting with YouPlot\n\n\t\t\t\t\t\t\t\t Database Integration\n\n\t\t\t\t\t\t\t\t\t  Overview\n\n\t\t\t\t\t\t\t\t\t  MySQL Import\n\n\t\t\t\t\t\t\t\t\t  PostgreSQL Import\n\n\t\t\t\t\t\t\t\t\t  SQLite Import\n\n\t\t\t\t\t\t\t\t File Formats\n\n\t\t\t\t\t\t\t\t\t  Overview\n\n\t\t\t\t\t\t\t\t\t  CSV Import\n\n\t\t\t\t\t\t\t\t\t  CSV Export\n\n\t\t\t\t\t\t\t\t\t  Directly Reading Files\n\n\t\t\t\t\t\t\t\t\t  Excel Import\n\n\t\t\t\t\t\t\t\t\t  Excel Export\n\n\t\t\t\t\t\t\t\t\t  JSON Import\n\n\t\t\t\t\t\t\t\t\t  JSON Export\n\n\t\t\t\t\t\t\t\t\t  Parquet Import\n\n\t\t\t\t\t\t\t\t\t  Parquet Export\n\n\t\t\t\t\t\t\t\t\t  Querying Parquet Files\n\n\t\t\t\t\t\t\t\t\t  File Access with the file: Protocol\n\n\t\t\t\t\t\t\t\t Network and Cloud Storage\n\n\t\t\t\t\t\t\t\t\t  Overview\n\n\t\t\t\t\t\t\t\t\t  HTTP Parquet Import\n\n\t\t\t\t\t\t\t\t\t  S3 Parquet Import\n\n\t\t\t\t\t\t\t\t\t  S3 Parquet Export\n\n\t\t\t\t\t\t\t\t\t  S3 Iceberg Import\n\n\t\t\t\t\t\t\t\t\t  S3 Express One\n\n\t\t\t\t\t\t\t\t\t  GCS Import\n\n\t\t\t\t\t\t\t\t\t  Cloudflare R2 Import\n\n\t\t\t\t\t\t\t\t\t  DuckDB over HTTPS / S3\n\n\t\t\t\t\t\t\t\t\t  Fastly Object Storage Import\n\n\t\t\t\t\t\t\t\t Meta Queries\n\n\t\t\t\t\t\t\t\t\t  Describe Table\n\n\t\t\t\t\t\t\t\t\t  EXPLAIN: Inspect Query Plans\n\n\t\t\t\t\t\t\t\t\t  EXPLAIN ANALYZE: Profile Queries\n\n\t\t\t\t\t\t\t\t\t  List Tables\n\n\t\t\t\t\t\t\t\t\t  Summarize\n\n\t\t\t\t\t\t\t\t\t  DuckDB Environment\n\n\t\t\t\t\t\t\t\t ODBC\n\n\t\t\t\t\t\t\t\t\t  ODBC Guide\n\n\t\t\t\t\t\t\t\t Performance\n\n\t\t\t\t\t\t\t\t\t  Overview\n\n\t\t\t\t\t\t\t\t\t  Environment\n\n\t\t\t\t\t\t\t\t\t  Import\n\n\t\t\t\t\t\t\t\t\t  Schema\n\n\t\t\t\t\t\t\t\t\t  Indexing\n\n\t\t\t\t\t\t\t\t\t  Join Operations\n\n\t\t\t\t\t\t\t\t\t  File Formats\n\n\t\t\t\t\t\t\t\t\t  How to Tune Workloads\n\n\t\t\t\t\t\t\t\t\t  My Workload Is Slow\n\n\t\t\t\t\t\t\t\t\t  Benchmarks\n\n\t\t\t\t\t\t\t\t Python\n\n\t\t\t\t\t\t\t\t\t  Installation\n\n\t\t\t\t\t\t\t\t\t  Executing SQL\n\n\t\t\t\t\t\t\t\t\t  Jupyter Notebooks\n\n\t\t\t\t\t\t\t\t\t  SQL on Pandas\n\n\t\t\t\t\t\t\t\t\t  Import from Pandas\n\n\t\t\t\t\t\t\t\t\t  Export to Pandas\n\n\t\t\t\t\t\t\t\t\t  Import from Numpy\n\n\t\t\t\t\t\t\t\t\t  Export to Numpy\n\n\t\t\t\t\t\t\t\t\t  SQL on Arrow\n\n\t\t\t\t\t\t\t\t\t  Import from Arrow\n\n\t\t\t\t\t\t\t\t\t  Export to Arrow\n\n\t\t\t\t\t\t\t\t\t  Relational API on Pandas\n\n\t\t\t\t\t\t\t\t\t  Multiple Python Threads\n\n\t\t\t\t\t\t\t\t\t  Integration with Ibis\n\n\t\t\t\t\t\t\t\t\t  Integration with Polars\n\n\t\t\t\t\t\t\t\t\t  Using fsspec Filesystems\n\n\t\t\t\t\t\t\t\t SQL Editors\n\n\t\t\t\t\t\t\t\t\t  DBeaver SQL IDE\n\n\t\t\t\t\t\t\t\t SQL Features\n\n\t\t\t\t\t\t\t\t\t  AsOf Join\n\n\t\t\t\t\t\t\t\t\t  Full-Text Search\n\n\t\t\t\t\t\t\t\t\t  query and query_table Functions\n\n\t\t\t\t\t\t\t\t Snippets\n\n\t\t\t\t\t\t\t\t\t  Creating Synthetic Data\n\n\t\t\t\t\t\t\t\t\t  Sharing Macros\n\n\t\t\t\t\t\t\t\t\t  Analyzing a Git Repository\n\n\t\t\t\t\t\t\t\t\t  Importing Duckbox Tables\n\n\t\t\t\t\t\t\t\t\t  Copying an In-Memory Database to a File\n\n\t\t\t\t\t\t\t\t Glossary of Terms\n\n\t\t\t\t\t\t\t\t Browsing Offline\n\n\t\t\t\t\t\t\t Operations Manual\n\n\t\t\t\t\t\t\t\t Overview\n\n\t\t\t\t\t\t\t\t DuckDB's Footprint\n\n\t\t\t\t\t\t\t\t\t  Files Created by DuckDB\n\n\t\t\t\t\t\t\t\t\t  Gitignore for DuckDB\n\n\t\t\t\t\t\t\t\t\t  Reclaiming Space\n\n\t\t\t\t\t\t\t\t Logging\n\n\t\t\t\t\t\t\t\t\t  Overview\n\n\t\t\t\t\t\t\t\t Securing DuckDB\n\n\t\t\t\t\t\t\t\t\t  Overview\n\n\t\t\t\t\t\t\t\t\t  Embedding DuckDB\n\n\t\t\t\t\t\t\t\t\t  Securing Extensions\n\n\t\t\t\t\t\t\t\t Non-Deterministic Behavior\n\n\t\t\t\t\t\t\t\t Limits\n\n\t\t\t\t\t\t\t Development\n\n\t\t\t\t\t\t\t\t DuckDB Repositories\n\n\t\t\t\t\t\t\t\t Profiling\n\n\t\t\t\t\t\t\t\t Release Calendar\n\n\t\t\t\t\t\t\t\t Roadmap\n\n\t\t\t\t\t\t\t\t Building DuckDB\n\n\t\t\t\t\t\t\t\t\t  Overview\n\n\t\t\t\t\t\t\t\t\t  Build Configuration\n\n\t\t\t\t\t\t\t\t\t  Building Extensions\n\n\t\t\t\t\t\t\t\t\t  Android\n\n\t\t\t\t\t\t\t\t\t  Linux\n\n\t\t\t\t\t\t\t\t\t  macOS\n\n\t\t\t\t\t\t\t\t\t  Raspberry Pi\n\n\t\t\t\t\t\t\t\t\t  Windows\n\n\t\t\t\t\t\t\t\t\t  Python\n\n\t\t\t\t\t\t\t\t\t  R\n\n\t\t\t\t\t\t\t\t\t  Troubleshooting\n\n\t\t\t\t\t\t\t\t\t  Unofficial and Unsupported Platforms\n\n\t\t\t\t\t\t\t\t Benchmark Suite\n\n\t\t\t\t\t\t\t\t Testing\n\n\t\t\t\t\t\t\t\t\t  Overview\n\n\t\t\t\t\t\t\t\t\t  sqllogictest Introduction\n\n\t\t\t\t\t\t\t\t\t  Writing Tests\n\n\t\t\t\t\t\t\t\t\t  Debugging\n\n\t\t\t\t\t\t\t\t\t  Result Verification\n\n\t\t\t\t\t\t\t\t\t  Persistent Testing\n\n\t\t\t\t\t\t\t\t\t  Loops\n\n\t\t\t\t\t\t\t\t\t  Multiple Connections\n\n\t\t\t\t\t\t\t\t\t  Catch\n\n\t\t\t\t\t\t\t Internals\n\n\t\t\t\t\t\t\t\t Overview\n\n\t\t\t\t\t\t\t\t Storage Versions and Format\n\n\t\t\t\t\t\t\t\t Execution Format\n\n\t\t\t\t\t\t\t\t Pivot\n\n\t\t\t\t Why DuckDB\n\n\t\t\t\t FAQ\n\n\t\t\t\t Code of Conduct\n\n\t\t\t\t Sitemap\n\n\t\t\t\t Live Demo\n\n  Documentation\n\n          / Development\n\n\t\t\t\t\tDevelopment Roadmap\n\n        Overview\n\nThe DuckDB project is governed by the non-profit DuckDB Foundation.\nThe Foundation and DuckDB Labs are not funded by external investors (e.g., venture capital).\nInstead, the Foundation is funded by contributions from its members,\nwhile DuckDB Labs' revenue is based on commercial support and feature prioritization services.\n\n        Planned Features (March 2025)\n\nThis section lists the features that the DuckDB team plans to work on in the coming year.\n\n  Documentation for the C extension API\n  Generic ODBC catalog, similarly to the existing PostgreSQL / MySQL / SQLite integrations\n  Go and Rust support for extensions\n  Improved support for the Iceberg format through the iceberg extension\n  MATCH RECOGNIZE for pattern matching\n  Remote file content caching using buffer manager (e.g., when querying Parquet files on S3)\n\nThis list was compiled by the DuckDB maintainers and is based on the long-term strategic vision for the DuckDB project and general interactions with users in the open-source community (GitHub Issues and Discussions, social media, etc.).\nFor details on to request features in DuckDB, please refer to the FAQ item “I would like feature X to be implemented in DuckDB”.\n\nPlease note that there are no guarantees that a particular feature will be released within the next year. Everything on this page is subject to change without notice.\n\n        Future Work\n\nThere are several items that we plan to implement at some point in the future.\nIf you would like to expedite the development of these features, please get in touch with DuckDB Labs.\n\n  Time series optimizations\n  Partition-aware optimizations\n  Sorting-aware optimizations\n  Database file encryption\n  Better Filter Cardinality Estimation using automatically maintained table samples\n  Parallel Python UDFs\n  ALTER TABLE support for adding foreign keys\n  Improvements of query profiling (especially for concurrently running queries)\n  XML read support\n  Materialized views\n  MERGE statement\n  Support for async I/O\n  Support for PL/SQL stored procedures\n\n\t\t\t\t\t\tAbout this page\n\n\t\t\t\t\t\t\tReport content issue\n\t\t\t\t\t\t\tSee this page as Markdown\n\t\t\t\t\t\t\tEdit this page on GitHub\n\n\t\t\t\t\t\tIn this article\n\nOverview\nPlanned Features (March 2025)\nFuture Work",
    "summary": {
      "en": "**Summary of DuckDB Documentation Overview**\n\nDuckDB is a database management system supported by the non-profit DuckDB Foundation, funded by member contributions and commercial services. The documentation covers various areas including:\n\n- **Installation and Getting Started**: Guidance on initial setup and connecting to data sources.\n- **Data Import**: Instructions for importing data from formats like CSV, JSON, Parquet, and more, with tips for handling errors and schema combinations.\n- **Client APIs**: Overview of APIs for various programming languages (like Python, Java, and C++) and their functionalities.\n- **SQL Features**: Comprehensive details on SQL syntax, data types, functions, and query operations.\n- **Configuration and Extensions**: Information on configuring DuckDB and installing extensions to enhance functionality.\n- **Performance and Guides**: Tips on optimizing performance, using data viewers, and integrating with other databases.\n- **Planned Features**: A list of future updates and enhancements, including support for new data formats and optimizations for time series data.\n\nFor any issues or feature requests, users are encouraged to refer to the FAQ or contact DuckDB Labs for assistance. Future work includes optimizations, additional data handling capabilities, and improved SQL support.",
      "ko": "DuckDB는 비영리 단체인 DuckDB 재단이 지원하는 데이터베이스 관리 시스템으로, 회원 기부와 상업 서비스로 자금을 조달합니다. 문서에서는 여러 가지 주제를 다루고 있습니다.\n\n설치 및 시작하기 섹션에서는 초기 설정과 데이터 소스에 연결하는 방법에 대한 안내를 제공합니다. 데이터 가져오기 부분에서는 CSV, JSON, Parquet 등 다양한 형식에서 데이터를 가져오는 방법과 오류 처리 및 스키마 조합에 대한 팁을 설명합니다. 클라이언트 API 섹션에서는 Python, Java, C++와 같은 여러 프로그래밍 언어에 대한 API 개요와 그 기능을 소개합니다.\n\nSQL 기능에 대한 부분에서는 SQL 구문, 데이터 유형, 함수 및 쿼리 작업에 대한 상세한 정보를 제공합니다. 구성 및 확장 섹션에서는 DuckDB를 설정하고 기능을 향상시키기 위한 확장을 설치하는 방법에 대한 정보를 포함하고 있습니다. 성능 및 가이드에서는 성능 최적화, 데이터 뷰어 사용, 다른 데이터베이스와의 통합에 대한 팁을 제공합니다. 계획된 기능 섹션에서는 새로운 데이터 형식 지원 및 시계열 데이터 최적화와 같은 향후 업데이트 및 개선 사항 목록을 제시합니다.\n\n문제나 기능 요청이 있는 경우, 사용자는 FAQ를 참조하거나 DuckDB Labs에 도움을 요청할 수 있습니다. 향후 작업에는 최적화, 추가 데이터 처리 기능 및 향상된 SQL 지원이 포함될 예정입니다.",
      "ja": "DuckDBは、非営利のDuckDB Foundationによって支えられているデータベース管理システムで、メンバーの寄付や商業サービスによって資金が提供されています。このドキュメントでは、さまざまな分野について説明しています。\n\nまず、インストールと初期設定に関するガイダンスがあり、データソースへの接続方法が紹介されています。次に、CSV、JSON、Parquetなどの形式からデータをインポートする手順が説明されており、エラー処理やスキーマの組み合わせに関するヒントも含まれています。\n\nクライアントAPIに関しては、Python、Java、C++などのプログラミング言語向けのAPIの概要とその機能が示されています。また、SQLの機能については、SQL構文、データ型、関数、クエリ操作に関する詳細が網羅されています。\n\nDuckDBの設定や機能を向上させるための拡張機能のインストールに関する情報も提供されています。パフォーマンスの最適化やデータビューアの使用、他のデータベースとの統合に関するヒントも含まれています。さらに、今後の機能として、新しいデータ形式のサポートや時系列データの最適化など、将来的な更新や改善のリストも掲載されています。\n\n問題や機能リクエストがある場合は、FAQを参照するか、DuckDB Labsに連絡することが推奨されています。今後の作業には、最適化や追加のデータ処理機能、SQLサポートの改善が含まれています。"
    }
  },
  {
    "id": "3987d64ff9c82ba4",
    "title": {
      "en": "Is Robert Frost Even a Good Poet?",
      "ko": "로버트 프로스트, 과연 좋은 시인인가?",
      "ja": "ロバート・フロストは名詩人か？"
    },
    "type": "story",
    "url": "https://www.theparisreview.org/blog/2025/03/17/is-robert-frost-even-a-good-poet/",
    "score": 87,
    "by": "lermontov",
    "time": 1742883106,
    "content": "She Who Helps See\n            \t\t\t\t\tBy George Saunders\n            \t\t\t\t\tMarch 24, 2025",
    "summary": {
      "en": "\"She Who Helps See\" by George Saunders is a piece that likely explores themes of assistance, perception, and perhaps enlightenment. The title suggests a focus on someone or something that aids in understanding or clarity. \n\nIn this work, key points may include the importance of support in gaining insight, the role of perspective in shaping our understanding, and the value of compassion and guidance in navigating challenges. The writing is expected to be reflective and thought-provoking, encouraging readers to consider how they help others and how they receive help in their own lives.\n\nOverall, the text emphasizes the interconnectedness of human experiences and the significance of helping one another to see more clearly.",
      "ko": "조지 손더스의 \"그녀는 돕는 사람\"은 도움, 인식, 그리고 깨달음과 같은 주제를 탐구하는 작품으로 보입니다. 제목은 이해나 명확성을 돕는 사람이나 사물에 초점을 맞추고 있음을 암시합니다.\n\n이 작품에서 중요한 내용은 통찰력을 얻기 위한 지원의 중요성, 우리의 이해를 형성하는 데 있어 관점의 역할, 그리고 어려움을 헤쳐 나가는 데 있어 연민과 안내의 가치일 수 있습니다. 글은 사색적이고 생각을 자극하는 내용으로, 독자들이 다른 사람을 어떻게 돕고 자신이 어떻게 도움을 받는지를 고민하도록 유도할 것으로 예상됩니다.\n\n전반적으로 이 글은 인간 경험의 상호 연결성을 강조하며, 서로를 돕는 것이 더 명확하게 볼 수 있는 중요성을 부각시킵니다.",
      "ja": "ジョージ・サンダースの「助けてくれる者」は、支援や認識、さらには啓発といったテーマを探求している作品です。タイトルからは、理解や明瞭さを助ける存在に焦点を当てていることが伺えます。\n\nこの作品では、洞察を得るための支援の重要性や、私たちの理解を形作る視点の役割、そして困難を乗り越えるための思いやりや指導の価値が取り上げられているかもしれません。文章は反省的で考えさせられる内容であり、読者に他者をどのように助けているか、また自分自身がどのように助けを受けているかを考えるよう促すことが期待されます。\n\n全体として、このテキストは人間の経験の相互関連性を強調し、お互いに助け合うことの重要性を伝えています。"
    }
  },
  {
    "id": "5511d899a0c841ea",
    "title": {
      "en": "AMC Theatres will screen a Swedish movie 'visually dubbed' with the help of AI",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://www.engadget.com/ai/amc-theatres-will-screen-a-swedish-movie-visually-dubbed-with-the-help-of-ai-130022232.html",
    "score": 71,
    "by": "bookofjoe",
    "time": 1742686663,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "eaeea5c111224246",
    "title": {
      "en": "Evolving Scala",
      "ko": "스칼라의 진화",
      "ja": "進化するスカラ"
    },
    "type": "story",
    "url": "https://www.scala-lang.org/blog/2025/03/24/evolving-scala.html",
    "score": 156,
    "by": "pjmlp",
    "time": 1742890178,
    "content": "Evolving Scala\n\nMonday 24 March 2025\n\t\t\t\t\t\tMartin Odersky and Haoyi Li\n\n\t\t\t\t\tBLOG\n\n\t\t\t\t\tThere is always ongoing discussion about the future direction of the Scala language.\nHow fast should it move?\nWhat needs to be improved?\nShould the language change at all?\nThis article discusses how Scala must keep evolving, why that evolution is necessary, and what directions we expect that evolution to take.\nWe hope that this will cover many of the frequently asked questions on the direction of the Scala language, and help the community understand where the language will go in the months and years to come.\n\nSummary\n\nAlthough Scala is no longer riding the wave of hype it had in the mid-2010s, by most surveys the language maintains its position just outside the list of mainstream languages.\nFrom a technical perspective, the core language and ecosystem have improved greatly over the past decade.\nIn many ways Scala is on much better foundations today than it was 10 years ago.\n\nScala has a history of leading the way for the rest of the programming field.\nIn exchange for a bit less polish and stability than mainstream languages, people chose Scala to get next decade’s language features today.\nThe value of Scala has always been the unique combination of safety and convenience that these language features have enabled, and its fusion of object oriented and functional programming ideas that can elegantly accommodate these features.\n\nBut other languages are also improving, and so Scala must continue to innovate, improving on both its strengths and weaknesses with a particular focus on the newcomer onboarding experience.\nThere are of course ongoing issues, especially around IDE support and the learnability of the ecosystem, and there will always be concerns about tooling, compatibility, and migration cost as a language evolves.\nBut Scala has no choice but to move forward if it is to maintain its appeal and relevance in the years to come.\n\nWhere Scala stands today\n\nAlthough the hype has died down, popularity-wise Scala is about where it has always been: not quite in the mainstream, but with far greater adoption than more niche languages.\nFor example, the RedMonk Language Rankings had Scala in 14th place in 2014 and still in 14th place 10 years later in 2024.\nIn those years, the programming landscape changed significantly: Swift replacing Objective C, the emergence of Go and Kotlin and Dart and Rust, the decline of CoffeeScript and Perl.\nYet throughout this Scala’s place remains unchanged.\nAlthough individuals in the community come and go, Scala as a whole seems to be holding strong with a solid base of enthusiasts.\n\nTechnically, Scala is on stronger foundations than it was 10 years ago.\nThe ecosystem has matured and the various Reactive or Pure-FP styles have found their audiences.\nAlternative styles like the Scala Toolkit and the com.lihaoyi platform are now available.\nNew build tools like Scala-CLI and Mill have emerged, and developer tools like Scalafmt and Scalafix have become widely used.\nIDEs remain a pain point, but we expect them to improve over the course of 2025.\nHeavy use of symbolic operators has thankfully fallen out of style.\n\nScala has always been a language on the leading edge, proving the viability of language features like lambdas, records, and pattern matching that were adopted 10–15 years later by Java, Python, and other mainstream languages.\nIt remains to be seen which current Scala features the mainstream languages will adopt 10-15 years from now.\n\nWhere is Scala going?\n\nIn this section, we will discuss some areas where the core Scala developers will focus their efforts.\n\nSafety and convenience: pick two\n\nScala has always been a hybrid language.\nThe fusion of object-oriented and functional styles was often talked about.\nBut its other fusion has been of safety and convenience.\nTraditionally, “scripting” languages like Python were unsafe but convenient, while “application” languages like Java were safe but inconvenient.\nScala was the first to prove that you can do both in the same language.\nMore modern languages like Swift or Kotlin have progressed in this direction as well, the idea was unheard of when Scala first started.\n\nHowever, the programming landscape has not stood still for the last two decades.\nMuch of what used to be unique to Scala is now common.\nAll modern languages provide generics, type inference, lambdas, records, pattern matching, and other such features.\nTo continue to attract users, Scala must continue to innovate in both directions:\n\n  Increasing safety without compromising convenience: features like capture checking, explicit nulls, safe initialization, multiversal equality.\n  Increasing convenience without compromising safety: features like enums, optional braces, named tuples.\nA discussion about aggregate data literals has sparked a lot of interest, although it is still too early to see what will come out of it.\n\nThe Scala ecosystem is broad and diverse, but we think these twin goals are the common thread.\nWhether you are building a backend service using Akka actors on the JVM, web UIs in the browser via Scala.js, or custom silicon chips via Chisel, Scala’s safety and convenience is why people choose the language.\n\nOther languages are also pursuing these goals, but we believe that Scala delivers better than most: its type system, pattern matching, collections library, multiple-inheritance system, etc. are all best-in-class even if other languages have their own offerings.\nSo it is possible to simply execute and combine features better than others do, with a design that unifies these features in a clean and principled way instead of grafting them on ad-hoc.\n\nGoing forward, Scala must continue to pursue these twin goals of safety and convenience.\nTomorrow’s popular frameworks may be different from those of today, which are different from those of years past.\nBut developers have wanted safety and convenience for the past several decades, and we expect it to continue being in demand in the years to come.\n\nSanding off rough edges\n\nScala is no longer a new language.\nA lot of things seemed like good ideas two decades ago, but not all such decisions panned out.\nAlthough long-time Scala developers may have gotten used to these idiosyncrasies, Scala-the-language needs to continually polish off such rough edges:\n\n  Some features like scala-actors, scala-parser-combinators, or scala-xml have since been removed.\nThey are now in separate libraries, which you may use or not use as you desire, but are no longer a core part of the language or standard library.\nOther such cleanups include the Scala 2.13 collections overhaul.\n  More issues are being dealt with as we speak: @unroll to avoid binary-compatibility issues with default parameters and case classes is experimental (SIP-61), and for-comprehension improvements is in preview (SIP-62), and should help both resolve long-standing issues in using these Scala language features to their fullest.\n  Some other long-standing issues have yet to be dealt with, but are being discussed: flexible varargs, unpack, other warts involving for-comprehension syntax, and so on.\n\nProgramming has changed a lot in the past 20 years, with languages like Swift, Kotlin, Java, C#, and Python all evolving rapidly.\nSometimes discovering new approaches, sometimes converging on similar solutions for common use cases.\nJust because Scala made a design decision back in 2005 that we lived with for 20 years does not mean that decision is still optimal in 2025.\nSometimes, we can and should do better.\n\nScala’s core has always been its fusion of OO and FP features and fusion of safety and convenience, but everything else is up for debate.\nFor example, Scala has cycled through three collections libraries to get to where we are today, and the language is better off for it despite the churn.\nWhat long-standing annoyances can we fix today that we will be grateful to have fixed 5–10 years down the road?\nWhat features and conventions can we adopt from other languages, rather than re-inventing the wheel in our own idiosyncratic manner?\n\nAn easier language for newcomers\n\nWe believe Scala can be made easier for newcomers to pick up.\nAll advanced Scala users were newcomers at some point.\nAll the big Scala projects you’ve heard about today started off as a bunch of newcomers:\n\n  University students trying out a language for their research project\n  Python/Ruby folks trying out a language to improve the stability of their production systems\n  Java veterans wanting more flexibility, power, and rapid development\n\nWe support advanced users and advanced frameworks, but advanced users by definition are able to take care of themselves: solve their own issues, write their own docs, and propose their own language changes.\nAdvanced users of Scala have always been submitting their own patches and improvements — scala.concurrent.Future coming from Akka world, partial unification, generic tuples, and kind-projector coming from the pure-FP world — and we hope they will continue to do so.\nIn contrast, newcomers must rely on the core Scala maintainers to ensure they have a good experience.\n\nPractically this means:\n\n  Prioritizing code and documentation support for simpler, easier libraries like the Scala Toolkit and the com.lihaoyi platform.\n  Aligning Scala syntax with other languages where it diverges unnecessarily.\nWildcard imports via import foo.* and vararg splices via foo* have already landed (the latter replacing the old snail operator foo@_*).\n\nThe next big Scala projects will likely be started by newcomers picking up the language to solve a problem that nobody before had thought of solving.\nThey will be smart, but they won’t be experts pushing the limits of the Scala language, and they won’t be using the most sophisticated language features or design patterns.\nThey will know Java or Python or JavaScript because that’s what they learned in school.\nThat is who we need to make sure has an easy on-ramp to the Scala language.\n\nConsidered alternatives\n\nThere are always differing opinions about where Scala should go.\nWe’ll discuss two ideas that repeatedly come up around the direction of the language.\n\nWhy not go all in on Framework X?\n\nOne common request from the community is to go “all in” on some framework or toolchain in the Scala community.\nFor example:\n\n  Going all in on Scala as a pure functional programming language\n  Going all in on IO monads as the way to structure applications\n\nThese ideas are reasonable to discuss; after all the Scala sub-communities using it for pure functional programming with IO monads have been healthy and vibrant.\nHowever, there are a few issues with this approach when analyzed more deeply:\n\n  Scala is by design a flexible and expressive language.\nThis enables innovation, as history shows: a decade ago, Akka and Scalaz were the popular frameworks.\nScalaz gave way to newer functional libraries like ZIO, Cats-Effect, Monix and FS2.\nKyo seems to have promise but is still young.\nThe Scala language must be general enough to support this natural evolution, and cannot commit itself to specific frameworks that rise and fall over the years.\n  The core Scala developers are not framework experts.\nThey were not experts in the actor model when Akka was popular, and they are not experts in IO monads today.\nThus we need the advanced users in those sub-communities to advocate for themselves and drive the improvements in the language that their community needs.\n\nAs such, Scala has to remain general by building features that any framework or library can benefit from.\nWe encourage framework enthusiasts to propose improvements to the Scala language: although not every specific idea may be accepted, the feedback drives language changes that benefit all frameworks.\n\nWhy not freeze all feature development?\n\nAnother common request is to “stop implementing features”.\nThis comes up regularly in language discussions from people who are dissatisfied: with tooling support, the job market, or other things.\nThese sentiments are understandable.\nBut realistically, freezing feature development would doom the Scala language.\n\nScala has always been more featureful with less polish and stability than languages like Java.\nThe core value proposition for Scala was that in exchange, you received language features from the future that other languages didn’t have and would only get 10–15 years later:\n\n  Apache Spark picked Scala in 2014 as a language with lambdas and pattern matching on the JVM.\n  Akka picked Scala because it was a concise, performant language with support for lightweight concurrency with Futures or Actors.\n  Scalaz and Cats picked Scala as a concise language with a rich type system.\n\nOther languages picking up these features puts pressure on Scala to innovate.\nIn 2025, basically every language in the RedMonk top 20 has lambdas, pattern matching, lightweight concurrency, and type systems!\nSo why would any project pick Scala?\n\nScala cannot compete with mainstream languages on stability and polish alone, so if we halt feature development today, Scala would end up as a language with worse features, worse polish and stability, and no reason to exist.\nScala thus needs a steady stream of improvements to sustain it, to give people and projects a reason to pick the language.\nWe might get things wrong — there is no guaranteed path to success — but a feature freeze is a guaranteed path to stagnation and failure.\n\nOpen problems in the Scala ecosystem\n\nThe Scala ecosystem is not without its issues.\nHere we will briefly cover what we think are the biggest challenges that Scala faces today, and what we have done or will do about them going forward.\n\nTooling: IDEs\n\n“Tooling” was the biggest area for improvement highlighted in the last VirtusLab Scala Survey.\nThis primarily means IDEs (IntelliJ and VSCode) and build tooling (such as sbt), which are the tools that everyone writing Scala must also interact with.\n\nThe two primary IDEs used in the Scala community are IntelliJ and VSCode.\nThe aforementioned survey has ~80% of respondents using IntelliJ and ~50% using VSCode, with some using both.\n\nIntelliJ\n\nIntelliJ support for Scala 3 still has some catching up to do with the quality of support it has traditionally had for Scala 2.\nNevertheless, there is steady progress, and the recent improvements show an accelerated pace.\n\n  Scala 3 has recently introduced the concept of “preview” features: features that have stabilized from experimental, but have not yet gained support in IDEs and the rest of the ecosystem.\nThis is intended to help give IntelliJ and other IDEs time to catch so it does not fall behind as the language evolves.\n  JetBrains is now a member of the Scala Center advisory board.\nThis has already improved communication and coordination between JetBrains and the Scala compiler team and helped avoid the problems seen in the past where IntelliJ takes time to catch up with changes in Scala.\n  Recent language changes have been making their way into IntelliJ relatively promptly: SIP-64 Improved Given Syntax and SIP-58 Named Tuples already work since IntelliJ 2024.3, while SIP-62 For Comprehension Improvements will be available in 2025.1.\n\nWe acknowledge that there is still work to do.\nThe IntelliJ team is working hard on bringing the best support for Scala 3, and you can expect more improvements in the following months.\n\nMetals - the Scala Language Server\n\nMetals is most often used with VSCode, but also supports other editors.\nMetals has different challenges than IntelliJ: it has always used the actual Scala compiler for its code intelligence, and so it is always in sync with the actual language.\nBut it has had problems with stability (e.g. #6478), some of which stem from the complexity of its multi-process architecture, others from of its newer integrations with Scala 3 (e.g. #6628).\nThe Metals maintainers are currently focusing on fixing most prominent problems, but if you are aware of any problems within your codebase please open an issue at https://github.com/scalameta/metals/issues and the team at VirtusLab would be happy to take a look (even signing NDAs if necessary).\n\nThe Scala 3 compiler developers already heavily use both IntelliJ and Metals, and we are aware of the problems developers face using both IDEs.\nWe will continue to report issues as they are found, and we will work with the maintainers of both IntelliJ and Metals to improve the integration between the compiler and the IDEs.\nBut we also need people from the community to take an active role in reporting problems so the IDE maintainers can investigate and fix them.\n\nBuild tooling\n\nThe complexity of the build tool sbt has been a long-standing problem in the Scala community for the past decade or more.\nHowever, we think there is light at the end of the tunnel:\n\n  Scala-CLI has become popular.\nIt is now the default Scala launcher (since Scala 3.5.0).\nThe last VirtusLab Scala Survey had 35% of folks enjoying using it and another 35% wanting to learn it.\nWhile not suitable for large multi-module projects, Scala-CLI has virtually everything needed for almost any single-module project.\nIt is also a great tool for exploratory coding on small projects and experiments.\n  Alternatives such as Mill exist.\nThe survey found 10% of Scala developers enjoyed using Mill, but almost 50% wanting to learn it, and foundational projects like Scala-CLI and Coursier are built using Mill.\nWe think that Mill provides larger projects with a great alternative to sbt.\nBleep, while still young, offers a different take in the build tool space that also shows a lot of promise.\n  sbt itself has improved greatly over time.\nThe last few years have seen improvements like the Unified Slash Syntax, sbt Project-Matrix, and the upcoming sbt 2.0 release is bringing build queries, remote caching, and other improvements.\nWhile still not perfect, the experience using sbt in 2025 is greatly improved from the experience a decade ago.\n  Maven and Gradle can also be used.\nThese build tools have long been popular and familiar in Java shops.\nWhile not as popular in the open source community, we see them being used in many commercial Scala codebases.\n\nOverall we expect this problem will sort itself out going forward: both by sbt itself improving over time, and by projects choosing other tools that provide great alternatives.\n\nEcosystem learnability\n\nThe third biggest issue we see in the Scala language is the learnability of the ecosystem.\n\n  The Scala ecosystem has always had frameworks for sophisticated users: Akka, Cats-Effect, ZIO, and others.\nBut it has lacked a platform for less-sophisticated users: e.g. your student semester project, your new-grad startup codebase, your devops or data-analysis scripts maintained by non-engineers.\nThese are areas where Scala frameworks have not been a good fit, but the Scala language could be.\n  Documentation in the Scala ecosystem has also traditionally been a problem.\nThis compounds the problem above: learning a powerful framework or library is difficult enough, but doing it with poor documentation makes learning even more difficult than it needs to be.\n\nTraditionally, although someone may like the Scala language, the moment they reach out to do something simple like “make a HTTP request” or “start a server” they hit a wall where they suddenly have to learn about Actors, IO monads or other advanced topics, with insufficient documentation or learning materials.\n\nBut here too we see reasons for optimism:\n\n  The Scala Toolkit and the heavily overlapping com-lihaoyi platform, which include many of the same libraries.\nThese provide close to a complete and usable “newcomer friendly” platform.\nIt may not have all the bells and whistles of more sophisticated frameworks, but it is certainly enough for many production deployments, and with an easy transition to more sophisticated frameworks if and when they become necessary.\n  The recent partnership of the Scala Center with Rock the JVM promises to help improve the pedagogical side of Scala.\nDaniel Ciocîrlan from Rock the JVM has always been an excellent educator and creator of high-quality educational materials.\nWe hope this partnership will help expand the reach of Rock the JVM and help Scala newbies discover and benefit from his excellent videos and courses.\n\nThis is an area where we have been slowly making progress, and we hope this “newcomer friendly” Scala style will grow over time: not at the expense of the more advanced frameworks, but in tandem with them as the increased number of newcomers leads to more people picking up the more sophisticated frameworks if and when the need arises.\n\nHow you can help\n\nScala is a community effort; there is no huge corporate sponsor driving Scala development like there is in other languages.\nWe thus need help from the community to help drive the language forward.\nThis help can come in a variety of ways.\n\nFinancially\n\nIf you want to support Scala financially, there are two main groups you can support:\n\nThe Scala Center\n\nThe Scala Center supports two things:\n\n  The development of the core Scala language and compiler: exploration, prototyping, implementation, maintenance and debugging.\n  Support for the Scala community.\nThis includes the Scala Days conference, the Scala Ambassador program, and the tooling summits.\n\nYou can donate to the Scala center in two ways:\n\n  Individually donate or get your company to donate to the Scala Center https://scala.epfl.ch/donate.html\n  You can encourage your company to join the Scala Center advisory board to fund it on an ongoing basis.\n\nDonate to the Scala Center if you want to support the core Scala language and community work.\nMuch of their work is not glamorous, but it plays a key role in helping ensure the ongoing health of the Scala ecosystem.\n\nVirtusLab\n\nVirtusLab does the core development on much Scala tooling:\n\n  Metals and VSCode Metals plugin\n  Scala-CLI\n  Scala 3 LTS, release process and general project management for Scala\n  Tools within Scalameta organization\n\nIf you are hitting issues with Metals or Scala-CLI and would like to help fund fixes or improvements, you should reach out to VirtusLab at scala@virtuslab.com.\n\nCode\n\nMost of the Scala ecosystem is open source.\nThis means you can directly dig into the code and make the fixes or improvements you yourself want:\n\n  You can fix bugs in Scala3, IntelliJ, and Metals yourself.\nAlthough the codebases are large, it’s not unheard of that someone can dive in and make the fixes necessary for their own use case\n  A Compiler Spree and a Tooling Spree are run every three weeks.\nThese are remote coding sessions where you can collaborate with core Scala language and tooling contributors on bite-sized bugs and acquire the skills and knowledge to tackle more ambitious issues.\n\nContributing fixes and improvements to tooling and infrastructure is not easy, but neither is it impossible.\nMost of the Scala toolchain is open source and has received drive-by contributions many times in the past by individuals and corporations who just needed something fixed.\nSubmitting pull requests to these projects is no different from the kind of work any professional software engineer already does every day, and could help improve your own experience using Scala on a regular basis.\n\nLanguage Design\n\nThe Scala Improvement Process is not limited to the core Scala contributors.\nAnyone can propose one, e.g. SIP-42 Binary Integer Literals, SIP-61 @unroll default arguments for binary compatability, SIP-67 Improved strict equality.\nIf the core Scala team is not prioritizing what you want, you can always step in and propose improvements to the language yourself. After all, you know your own needs better than anyone else!\n\nSIPs are not easy to get into the language.\nThere is no guarantee a SIP will be accepted.\nEven SIPs that do make it through typically take months or even a year to go through the whole process of review, implementation, and experimentation and finally land in a Scala release.\nConversely, even ideas that were initially rejected may find their way in later, perhaps after months or years of additional experimentation and refinement.\nBut we need more contributors here proposing changes, rather than it being limited to Martin Odersky and the folks at EPFL.\n\nIf you have ideas to propose but need help with the implementation and have money to pay for it, please contact scala.center@epfl.ch and we can help find the expertise to contract.\n\nConclusion\n\nLanguage development is an indirect process.\nThe core Scala team cannot build the next big Scala success story themselves, nor will it happen overnight.\nWhat we can do is improve the Scala experience in all aspects: language, tooling, and community, and hope someone out there somewhere will pick Scala for a new project that could become the “next big thing”.\n\nWe believe the core appeal of the Scala language is its combination of safety and convenience.\nThe strong type system and compiler guard against mistakes, provide excellent runtime performance, while the concise syntax and type inference make it feel as flexible and expressive as any scripting language.\nNo doubt other languages are aiming for the same goals, and we think Scala with its unique hybrid functional-object-oriented design can do it better in enough ways to attract and retain users.\n\nBut the details of the Scala language and ecosystem will evolve over time, and we should not be overly attached to the incidental complexity we have grown accustomed to.\nJust as the Scala collections were greatly simplified in 2.13, and type-level gymnastics were replaced with simpler generic tuples and other type-system features in Scala 3, we expect to continue to find areas where we can make changes to improve Scala.\nThere will always be concerns around backwards compatibility, migration, and teachability, but nevertheless Scala needs to continually and critically inspect itself and draw upon what other languages have learned over the past two decades to improve the developer experience.\n\nScala has always been a community project, and we need the community to help drive it forward: whether financially, with pull requests, or in language design.\nWe hope everyone in the community is able to contribute in their own way and help drive the language forward.\n\n\t\tContents\n\n\t\tSummaryWhere Scala stands todayWhere is Scala going?Safety and convenience: pick twoSanding off rough edgesAn easier language for newcomersConsidered alternativesWhy not go all in on Framework X?Why not freeze all feature development?Open problems in the Scala ecosystemTooling: IDEsIntelliJMetals - the Scala Language ServerBuild toolingEcosystem learnabilityHow you can helpFinanciallyThe Scala CenterVirtusLabCodeLanguage DesignConclusion\n\n\t\t Problem with this page?Please help us fix it!",
    "summary": {
      "en": "### Summary of \"Evolving Scala\"\n\n**Overview**: The article discusses the future of the Scala programming language, emphasizing the need for continuous evolution to maintain its relevance and appeal.\n\n**Current Status**: \n- Scala remains popular but is not mainstream, ranking 14th in the RedMonk Language Rankings for the past decade.\n- The language and its ecosystem have significantly improved technically over the past 10 years.\n\n**Core Strengths**: \n- Scala combines object-oriented and functional programming, offering safety and convenience.\n- It has pioneered features like lambdas and pattern matching, which have only recently been adopted by mainstream languages.\n\n**Future Directions**:\n1. **Safety and Convenience**: Scala must enhance both aspects by introducing new features that increase safety (like explicit nulls) while maintaining convenience (like enums).\n2. **Sanding Off Rough Edges**: The language will continue to refine and remove outdated features or inconsistencies that have accumulated over the years.\n3. **Onboarding Newcomers**: Scala aims to be more accessible for beginners, improving documentation and simplifying libraries.\n\n**Challenges**:\n- **Tooling**: IDE support, particularly for IntelliJ and VSCode, needs improvement. Despite progress, challenges remain.\n- **Build Tools**: The complexity of sbt has been a long-standing issue, but new tools like Scala-CLI show promise.\n- **Ecosystem Learnability**: The Scala ecosystem is seen as complex, especially for new users. Initiatives like the Scala Toolkit aim to address this.\n\n**Community Involvement**: The article encourages community members to contribute financially, write code, or propose language improvements to help Scala evolve.\n\n**Conclusion**: Scala must adapt and innovate to remain attractive, focusing on improving user experience while leveraging its unique strengths. The community plays a crucial role in driving this evolution forward.",
      "ko": "이 글은 스칼라 프로그래밍 언어의 미래에 대해 다루고 있으며, 지속적인 발전이 필요하다는 점을 강조합니다. 스칼라는 여전히 인기가 있지만 주류 언어는 아니며, 지난 10년간 레드몽크 언어 순위에서 14위를 유지하고 있습니다. 이 언어와 그 생태계는 지난 10년 동안 기술적으로 크게 발전했습니다.\n\n스칼라의 핵심 강점은 객체 지향 프로그래밍과 함수형 프로그래밍을 결합하여 안전성과 편리함을 제공한다는 점입니다. 스칼라는 람다 표현식과 패턴 매칭과 같은 기능을 선도했으며, 이러한 기능은 최근에야 주류 언어에서 채택되었습니다.\n\n앞으로의 방향으로는 첫째, 안전성과 편리함을 모두 강화해야 합니다. 이를 위해 명시적인 널(null) 처리와 같은 새로운 기능을 도입하면서도 열거형(enum)과 같은 편리함을 유지해야 합니다. 둘째, 언어의 낡은 기능이나 불일치를 정리하고 개선해 나가야 합니다. 셋째, 초보자들이 더 쉽게 접근할 수 있도록 문서화 작업을 개선하고 라이브러리를 단순화해야 합니다.\n\n그러나 몇 가지 도전 과제가 남아 있습니다. 첫째, 도구 지원이 부족합니다. 특히 IntelliJ와 VSCode에 대한 지원이 개선되어야 합니다. 둘째, sbt의 복잡성은 오랫동안 문제로 지적되어 왔지만, Scala-CLI와 같은 새로운 도구들이 희망을 주고 있습니다. 셋째, 스칼라 생태계는 특히 신규 사용자에게 복잡하게 느껴질 수 있습니다. 이를 해결하기 위한 이니셔티브로 스칼라 툴킷이 있습니다.\n\n이 글은 커뮤니티 구성원들이 재정적으로 기여하거나 코드를 작성하거나 언어 개선을 제안하여 스칼라의 발전에 도움을 줄 것을 권장합니다. 스칼라는 매력적인 언어로 남기 위해 적응하고 혁신해야 하며, 사용자 경험을 개선하는 동시에 독특한 강점을 활용하는 데 집중해야 합니다. 커뮤니티는 이러한 발전을 이끌어가는 중요한 역할을 합니다.",
      "ja": "この記事では、Scalaプログラミング言語の未来について述べており、その関連性と魅力を維持するために継続的な進化が必要であることを強調しています。\n\n現在の状況として、Scalaは人気がありますが、主流ではなく、過去10年間のRedMonk言語ランキングでは14位に位置しています。この10年間で、言語とそのエコシステムは技術的に大きく改善されました。\n\nScalaの主な強みは、オブジェクト指向と関数型プログラミングを組み合わせて、安全性と利便性を提供している点です。Scalaは、ラムダ式やパターンマッチングといった機能を先駆けて導入しており、これらは最近になって主流の言語でも採用されるようになりました。\n\n今後の方向性としては、まず安全性と利便性の向上が求められています。具体的には、明示的なヌル値の導入など、安全性を高める新機能を追加しつつ、列挙型のような利便性を維持することが重要です。また、言語の洗練を進め、古くなった機能や矛盾を取り除くことも必要です。さらに、初心者がよりアクセスしやすくなるように、ドキュメントの改善やライブラリの簡素化を目指しています。\n\n課題としては、ツールの改善が挙げられます。特にIntelliJやVSCodeのIDEサポートは向上が必要です。進展は見られるものの、依然として課題が残っています。また、sbtの複雑さは長年の問題ですが、Scala-CLIのような新しいツールには期待が寄せられています。さらに、Scalaエコシステムは特に新しいユーザーにとって複雑と見なされており、Scala Toolkitのような取り組みがこの問題に対処しようとしています。\n\nコミュニティの関与も重要で、メンバーには財政的な支援やコードの作成、言語改善の提案を通じてScalaの進化を助けることが奨励されています。\n\nScalaは魅力を保つために適応し、革新を続ける必要があります。ユーザー体験の向上に焦点を当てつつ、その独自の強みを活かすことが求められています。コミュニティはこの進化を推進する上で重要な役割を果たします。"
    }
  },
  {
    "id": "11a7bc1663e6b59d",
    "title": {
      "en": "My Favorite C++ Pattern: X Macros (2023)",
      "ko": "내가 사랑하는 C++ 패턴: X 매크로",
      "ja": "お気に入りのC++パターン: Xマクロ"
    },
    "type": "story",
    "url": "https://danilafe.com/blog/chapel_x_macros/",
    "score": 118,
    "by": "ibobev",
    "time": 1742914679,
    "content": "My Favorite C++ Pattern: X Macros\n\n    C++\n        Chapel\n        Compilers\n\n    Posted on October 14, 2023.\n\n            Table of Contents\n\n    Application 1: String Interning\n\nApplication 2: AST Class Hierarchy\n\n        Tags and Dynamic Casting\n        The Visitor Pattern without Double Dispatch\n        Generating a Python Class Hierarchy\n\n    Application 3: CPython Method Tables and Getters\n    Discussion\n\nWhen I first joined the Chapel\n\n team,\none pattern used in its C++-based compiler made a strong impression on me. Since\nthen, I’ve used the pattern many more times, and have been very satisfied with\nhow it turned out. However, it feels like the pattern is relatively unknown, so\nI thought I’d show it off, and some of its applications in the\nChapel compiler\n\n. I’ve slightly tweaked\na lot of the snippets I directly show in this article for the sake of simpler\npresentation; I’ve included links to the original code (available on GitHub)\nif you want to see the unabridged version.\nBroadly speaking, the “X Macros” pattern is about generating code. If you have a lot\nof repetitive code to write (declaring many variables or classes, performing\nmany very similar actions, etc.), this pattern can save a lot of time, lead\nto much more maintainable code, and reduce the effort required to add more\ncode.\nI will introduce the pattern in its simplest form with my first example:\ninterning strings\n\n.\n\n  Application 1: String Interning\n\nThe Chapel compiler interns a lot of its strings. This way, it can reduce the\nmemory footprint of keeping identifiers in memory (every string \"x\" is\nactually the same string) and make for much faster equality comparisons\n(you can just perform a pointer comparison!). Generally, a Context class\nis used to manage interning state. A new interned string can be constructed\nusing the context object in the following manner:\nUniqueString::get(ctxPtr, \"the string\");\n\nEffectively, this performs a search of the currently existing unique strings.\nIf one with the content (\"the string\" in this case) doesn’t exist, it’s\ncreated and registered with the Context. Otherwise, the existing string is\nreturned. Some strings, however, occur a lot in the compiler, to the point that\nit would be inefficient to perform the whole “find-or-create” operation every\ntime. One example is the \"this\" string, which is an identifier with a lot of\nspecial behavior in the language (much like this in languages such as Java).\nTo support such frequent flier strings, the compiler initializes them once,\nand creates a variable per-string that can be accessed to get that string’s value.\nThere’s that repetitive code. Defining a brand new variable for each string,\nof which there are around 100 at the time of writing, is a lot of boilerplate.\nThere are also at least two places where code needs to be added:\n\nonce in the declaration of the variables, once in the code that initializes them.\n[note:\nA third use in the compiler is actually a variadic template defined over\ncharacter arrays. The template is defined and specialized in such a way that\nyou can refer to a variable by its string contents (i.e., you can write\nUSTR(\"the string\") instead of\ntheStringVariable).\n]\n\nIt would be very easy to accidentally modify the former but not the latter,\nespecially for developers not familiar with how these “common strings” are\nimplemented.\nThis is where the X Macros come in. If you look around the compiler source code,\nthere’s a header file that looks something like the following:\n\n    From all-global-strings.h, around line 31\nX(align          , \"align\")\nX(atomic         , \"atomic\")\nX(bool_          , \"bool\")\nX(borrow         , \"borrow\")\nX(borrowed       , \"borrowed\")\nX(by             , \"by\")\nX(bytes          , \"bytes\")\n// A lot more of these...\n\nWhat’s this X thing? That right there is the essence of the pattern: the macro\nX isn’t defined in the header! Effectively, all-global-strings.h is just\na list, and we can “iterate” over this list to generate some code for each\none of its elements, in as many places as we want. What I mean by this is\nthat we can then write code like the following:\n\n    From global-strings.h, around line 76\n    struct GlobalStrings {\n#define X(field, str) UniqueString field;\n#include \"all-global-strings.h\"\n#undef X\n    };\n\nIn this case, we define the macro X to ignore the value of the string (we’re\njust declaring it here), and create a new UniqueString variable declaration.\nSince the declaration is inside the GlobalStrings struct, this ends up\ncreating a field. Just like that, we’ve declared a class with over 100\nfields. Initialization is equally simple:\n\n    From Context.cpp, around line 49\n    GlobalStrings globalStrings;\n    Context rootContext;\n\n    static void initGlobalStrings() {\n#define X(field, str) globalStrings.field = UniqueString::get(&rootContext, str);\n#include \"chpl/framework/all-global-strings.h\"\n#undef X\n    }\n\nWith this, we’ve completely automated the code for for both declaring and\ninitializing all 100 of our unique strings. Adding a new string doesn’t require\na developer to know all of the places where this is implemented: just by\nmodifying the all-global-strings.h header with a new call to X, they can\nadd both a new variable and code to initialize it. Pretty robust!\n\n  Application 2: AST Class Hierarchy\n\nAltough the interned strings are an excellent first example, it wasn’t the\nfirst usage of X Macros that I encountered in the Chapel compiler. Beyond\nstrings, the compiler uses X Macros to represent the whole class hierarchy\nof abstract syntax tree (AST)\n\nnodes that it uses. Here, the code is actually a bit more complicated; the\nclass hierarchy isn’t a list like the strings were; it is itself a tree.\nTo represent such a structure, we need more than a single X macro; the\ncompiler went with AST_NODE, AST_BEGIN_SUBCLASSES, and AST_END_SUBCLASSES.\nHere’s what that looks like:\n\n    From uast-classes-list.h, around line 96\n  // Other AST nodes above...\n\n  AST_BEGIN_SUBCLASSES(Loop)\n      AST_NODE(DoWhile)\n      AST_NODE(While)\n\n    AST_BEGIN_SUBCLASSES(IndexableLoop)\n      AST_NODE(BracketLoop)\n      AST_NODE(Coforall)\n      AST_NODE(For)\n      AST_NODE(Forall)\n      AST_NODE(Foreach)\n    AST_END_SUBCLASSES(IndexableLoop)\n\n  AST_END_SUBCLASSES(Loop)\n\n  // Other AST nodes below...\n\nThe class hierarchy defined in this header, called uast-classes-list.h, is\nused for a lot of things, both in the compiler itself and in some libraries\nthat use the compiler. I’ll go through the use cases in turn.\n\n  Tags and Dynamic Casting\n\nFirst, to deal with a general absence of\nRTTI\n\n, the hierarchy header\nis used to declare a “tag” enum. Each AST node has a tag matching its class;\nthis allows us inspect the AST and perform safe casts similar to dynamic_cast.\nNote that for parent classes (defined via BEGIN_SUBCLASSES), we actually\nend up creating two tags: one START_... and one END_.... The reason\nfor this will become clear in a moment.\n\n    From AstTag.h, around line 36\nenum AstTag {\n#define AST_NODE(NAME) NAME ,\n#define AST_BEGIN_SUBCLASSES(NAME) START_##NAME ,\n#define AST_END_SUBCLASSES(NAME) END_##NAME ,\n#include \"chpl/uast/uast-classes-list.h\"\n#undef AST_NODE\n#undef AST_BEGIN_SUBCLASSES\n#undef AST_END_SUBCLASSES\n  NUM_AST_TAGS,\n  AST_TAG_UNKNOWN\n};\n\nThe above snippet makes AstTag contain elements such as DoWhile,\nWhile, START_Loop, and END_Loop. For convenience, we also add a couple\nof other elements: NUM_AST_TAGS, which is\n\nautomatically assigned the number of tags we generated,\n[note:\nThis is because C++ assigns integer values to enum elements sequentially, starting\nat zero.\n]\n\nand a generic “unknown tag” value.\nHaving generated the enum elements in this way, we can write query functions.\nThis way, the API consumer can write isLoop(tag) instead of manually performing\na comparison. Code generation here is actually split into two distinct forms\nof “is bla” methods: those for concrete AST nodes (DoWhile, While) and\nthose for abstract base classes (Loop). The reason for this is simple:\nonly a AstTag::DoWhile represents a do-while loop, but both DoWhile\nand While are instances of Loop. So, isLoop should return true for both.\nThis is where the START_... and END_... enum elements come in. Reading\nthe header file top-to-bottom, we first end up generating START_Loop,\nthen DoWhile and While, and then END_Loop. Since C++ assigns integer\nvalue to enums sequentially, to check if a tag “extends” a base class, it’s\nsufficient to check if its value is greater than the START token, and\nsmaller than the END token – this means it was declared within the\nmatching pair of BEGIN_SUBCLASSES and END_SUBCLASES.\n\n    From AstTag.h, around line 59\n// define is___ for leaf and regular nodes\n// (not yet for abstract parent classes)\n#define AST_NODE(NAME) \\\n  static inline bool is##NAME(AstTag tag) { \\\n    return tag == NAME; \\\n  }\n#define AST_BEGIN_SUBCLASSES(NAME)\n#define AST_END_SUBCLASSES(NAME)\n// Apply the above macros to uast-classes-list.h\n#include \"chpl/uast/uast-classes-list.h\"\n// clear the macros\n#undef AST_NODE\n#undef AST_BEGIN_SUBCLASSES\n#undef AST_END_SUBCLASSES\n\n// define is___ for abstract parent classes\n#define AST_NODE(NAME)\n#define AST_BEGIN_SUBCLASSES(NAME) \\\n  static inline bool is##NAME(AstTag tag) { \\\n    return START_##NAME < tag && tag < END_##NAME; \\\n  }\n#define AST_END_SUBCLASSES(NAME)\n// Apply the above macros to uast-classes-list.h\n#include \"chpl/uast/uast-classes-list.h\"\n// clear the macros\n#undef AST_NODE\n#undef AST_BEGIN_SUBCLASSES\n#undef AST_END_SUBCLASSES\n\nThese helpers are quite convenient. Here are a few examples of what we end up\nwith:\nisFor(AstTag::For)             // Returns true; a 'for' loop is indeed a 'for' loop.\nisIndexableLoop(AstTag::For)   // Returns true; a 'for' loop is \"indexable\" ('for i in ...')\nisLoop(AstTag::For)            // Returns true; a 'for' loop is a loop.\nisFor(AstTag::While)           // Returns false; a 'while' loop is not a 'for' loop.\nisIndexableLoop(AstTag::While) // Returns false; a 'while' loop uses a boolean condition, not an index\nisLoop(AstTag::While)          // Returns true; a 'while' loop is a loop.\n\nOn the top-level AST node class, we generate isWhateverNode and\ntoWhateverNode for each AST subclass. Thus, user code is able to inspect the\nAST and perform (checked) casts using plain methods. I omit isWhateverNode\nhere for brevity (its definition is very simple), and include only\ntoWhateverNode.\n\n    From AstNode.h, around line 313\n  #define AST_TO(NAME) \\\n    const NAME * to##NAME() const { \\\n      return this->is##NAME() ? (const NAME *)this : nullptr; \\\n    } \\\n    NAME * to##NAME() { \\\n      return this->is##NAME() ? (NAME *)this : nullptr; \\\n    }\n  #define AST_NODE(NAME) AST_TO(NAME)\n  #define AST_LEAF(NAME) AST_TO(NAME)\n  #define AST_BEGIN_SUBCLASSES(NAME) AST_TO(NAME)\n  #define AST_END_SUBCLASSES(NAME)\n  // Apply the above macros to uast-classes-list.h\n  #include \"chpl/uast/uast-classes-list.h\"\n  // clear the macros\n  #undef AST_NODE\n  #undef AST_LEAF\n  #undef AST_BEGIN_SUBCLASSES\n  #undef AST_END_SUBCLASSES\n  #undef AST_TO\n\nThese methods are used heavily in the compiler. For example, here’s a completely\nrandom snippet of code I pulled out:\n\n    From Resolver.cpp, around line 1161\n  if (auto var = decl->toVarLikeDecl()) {\n    // Figure out variable type based upon:\n    //  * the type in the variable declaration\n    //  * the initialization expression in the variable declaration\n    //  * the initialization expression from split-init\n\n    auto typeExpr = var->typeExpression();\n    auto initExpr = var->initExpression();\n\n    if (auto var = decl->toVariable())\n      if (var->isField())\n        isField = true;\n\nThus, developers adding new AST nodes are not required to manually implement\nthe isWhatever, toWhatever, and other functions. This and a fair bit\nof other AST functionality (which I will cover in the next subsection) is\nautomatically generated using X Macros.\n\nYou haven't actually shown how the AST node classes are declared, only the\ntags. It seems implausible that they be generated using this same strategy -\ndoesn't each AST node have its own different methods and implementation code?\n\nYou're right. The AST node classes are defined \"as usual\", and their constructors\nmust explicitly set their tag field to the corresponding\nAstTag value. It's also on the person defining the new class to\nextend the node that they promise to extend in uast-classes-list.h.\n\nThis seems like an opportunity for bugs. Nothing is stopping a developer\nfrom returning the wrong tag, which would break the auto-casting behavior.\n\nYes, it's not bulletproof. Just recently, a team meber found\n a bug in which\na node was listed to inherit from AstNode, but actually inherited\nfrom NamedDecl. The toNamedDecl method would not\nhave worked on it, even though it inherited from the class.\n\nStill, this pattern provides the Chapel compiler with a lot of value; I will\nshow more use cases in the next subsection, like promised.\n\n  The Visitor Pattern without Double Dispatch\n\nThe Visitor Pattern is very important in general, but it’s beyond ubiquitous\nfor us compiler developers. It helps avoid bloating AST node classes with methods\nand state required for the various operations we perform on them. It also often\nsaves us from writing AST traversal code.\nEssentially, rather than adding each new operation (e.g. convert to string,\ncompute the type, assign IDs) as methods on each AST node class, we extract\nthis code into a per-operation visitor. This visitor is a class that has methods\nimplementing the custom behavior on the AST nodes. A visit(WhileLoop*) method\nmight be used to perform the operation on ‘while’ loops, and visit(ForLoop*) might\ndo the same for ‘for’ loops. The AST nodes themselves only have a traverse\nmethod that accepts a visitor, whatever it may be, and calls the appropriate\nvisit methods. This way, the AST node implementations remain simple and relatively\nstable.\nAs a very simple example, suppose you wanted to count the number of loops used\nin a program for an unspecified reason. You could add a countLoops method,\nbut then you’ve introduced a method to the AST node API for what might be a\none-time, throwaway operation. With the visitor pattern, you don’t need to do\nthat; you can just create a new class:\nstruct MyVisitor {\n    int count = 0;\n\n    void visit(const Loop*) { count += 1; }\n    void visit(const AstNode*) { /* do nothing for other nodes */ }\n}\n\nint countLoops(const AstNode* root) {\n    MyVisitor visitor;\n    root->traverse(visitor);\n    return visitor.count;\n}\n\nThe traverse method is a nice API, isn’t it? It’s very easy to add operations\nthat work on your syntax trees, without modifying them. There is still an important\nopen question, though: how does traverse know to call the right visit function?\nIf traverse were only defined on AstNode*, and it simply called visit(this),\nwe’d always end up calling the AstNode version of the visit function. This\nis because C++ doesn’t dynamic dispatch\n\nbased on the types of method arguments.\n[note:\nObviously, C++ has the ability to pick the right method based on the runtime\ntype of the receiver: that's just virtual functions\nand vtables.\n]\n\nStatically, the call clearly accepts an AstNode, and nothing more specific.\nThe compiler therefore picks that version of the visit method.\nThe “traditional” way to solve this problem in a language like C++ or Java\nis called double dispatch. Using our example as reference, this involves\nmaking each AST node class have its own traverse method. This way,\ncalls to visit(this) have more specific type information, and are resolved\nto the appropriate overload. But that’s more boilerplate code: each new AST\nnode will need to have a virtual traverse method that looks something like this:\nvoid MyNode::traverse(Visitor& v) {\n  v.visit(this);\n}\n\nIt would also require all visitors to extend from Visitor. So now you have:\n\nBoilerplate code on every AST node that looks the same but needs to be duplicated\nA parent Visitor class that must have a visit method for each AST node in\nthe language (so that children can override it).\nTo make it easier to write code like our MyVisitor above, the visit\nmethods in the Visitor must be written such that visit(ChildNode*) calls\nvisit(ParentNode*) by default. Otherwise, the Loop overload wouldn’t\nhave been called by the DoWhile overload (e.g.).\n\nSo there’s a fair bit of tedious boilerplate, and more code to manually modify\nwhen adding an AST node: you have to go and adjust the Visitor class with\nnew visit stub.\nThe reason all of this is necessary is that everyone (myself included) generally\nagrees that code like the following is generally a bad idea:\nstruct AstNode {\n  void traverse(Visitor& visitor) {\n    if (auto forLoop = toForLoop()) {\n      visitor.visit(forLoop);\n    } else if (auto whileLoop = toWhileLoop()) {\n      visitor.visit(whileLoop);\n    } else {\n      // 100 more lines like this...\n    }\n  }\n}\n\nAfter all, what happens when you add a new AST node? You’d still have to modify\nthis list, and since everything still extends Visitor, you’d still need to\nadd a new visit stub there. But what if there were no base class? Instead,\nwhat if traverse were a template?\nstruct AstNode {\n  template <typename VisitorType>\n  void traverse(VisitorType& visitor) {\n    if (auto forLoop = toForLoop()) {\n      visitor.visit(forLoop);\n    } else if (auto whileLoop = toWhileLoop()) {\n      visitor.visit(whileLoop);\n    } else {\n      // 100 more lines like this...\n    }\n  }\n}\n\nNote that this wouldn’t be possible to write in C++ if visit were a virtual\nmethod; have you ever heard of a virtual template? With code like this, the\nVisitorType wouldn’t need to define every overload, as long as it had\na version for AstNode. Furthermore, C++’s regular overload resolution rules\nwould take care of calling the Loop overload if a more specific one for\nDoWhile didn’t exist.\nThe only problem that remains is that of having a 100-line if-else (which could\nbe a switch to little aesthetic benefit). But this is exactly where the\nX Macro pattern shines again! We already have a list of all AST node classes,\nand the code for invoking them is nearly identical. Thus, the Chapel compiler\nhas a doDispatch function (used by traverse) that looks like this:\n\n    From AstNode.h, around line 377\n    static void doDispatch(const AstNode* ast, Visitor& v) {\n\n      switch (ast->tag()) {\n        #define CONVERT(NAME) \\\n          case chpl::uast::asttags::NAME: \\\n          { \\\n            v.visit((const chpl::uast::NAME*) ast); \\\n            return; \\\n          }\n\n        #define IGNORE(NAME) \\\n          case chpl::uast::asttags::NAME: \\\n          { \\\n            CHPL_ASSERT(false && \"this code should never be run\"); \\\n          }\n\n        #define AST_NODE(NAME) CONVERT(NAME)\n        #define AST_BEGIN_SUBCLASSES(NAME) IGNORE(START_##NAME)\n        #define AST_END_SUBCLASSES(NAME) IGNORE(END_##NAME)\n\n        #include \"chpl/uast/uast-classes-list.h\"\n\n        IGNORE(NUM_AST_TAGS)\n        IGNORE(AST_TAG_UNKNOWN)\n\n        #undef AST_NODE\n        #undef AST_BEGIN_SUBCLASSES\n        #undef AST_END_SUBCLASSES\n        #undef CONVERT\n        #undef IGNORE\n      }\n\n      CHPL_ASSERT(false && \"this code should never be run\");\n    }\n\nAnd that’s it. We have automatically generated the traversal code, allowing\nus to use the visitor pattern in what I think is a very elegant way. Assuming\na developer adding a new AST node updates the uast-classes-list.h header,\nthe traversal logic will be auto-modified to properly handle the new node.\n\n  Generating a Python Class Hierarchy\n\nThis is a fun one. For a while, in my spare time, I was working on\nPython bindings for Chapel\n\n.\nThese bindings are oriented towards developing language tooling: it feels much\neasier to write a language linter, auto-formatter, or maybe even a language\nserver in Python rather than in C++. It’s definitely much easier to use Python to\ndevelop throwaway scripts that work with Chapel programs, which is something\nthat developers on the Chapel team tend to do quite often.\nI decided I wanted the Python AST node class hierarchy to match the C++ version.\nThis is convenient for many reasons, including being able to wrap methods on\nparent AST nodes and have them be available through child AST nodes and having\nisinstance work properly. It’s also advantageous from the point of view\nof conceptual simplicity. However, I very much did not want to write CPython\nAPI code to define the many AST node classes that are available in the Chapel\nlanguage.\nOnce again, the uast-classes-list.h header came into play here. With little\neffort, I was able to auto-generate PyTypeObjects for each AST node in the\nclass hierarchy:\n\n    From chapel.cpp, around line 563\n#define DEFINE_PY_TYPE_FOR(NAME, TAG, FLAGS)\\\n  PyTypeObject NAME##Type = { \\\n    PyVarObject_HEAD_INIT(NULL, 0) \\\n    .tp_name = #NAME, \\\n    .tp_basicsize = sizeof(NAME##Object), \\\n    .tp_itemsize = 0, \\\n    .tp_flags = FLAGS, \\\n    .tp_doc = PyDoc_STR(\"A Chapel \" #NAME \" AST node\"), \\\n    .tp_methods = (PyMethodDef*) PerNodeInfo<TAG>::methods, \\\n    .tp_base = parentTypeFor(TAG), \\\n    .tp_init = (initproc) NAME##Object_init, \\\n    .tp_new = PyType_GenericNew, \\\n  };\n\n#define AST_NODE(NAME) DEFINE_PY_TYPE_FOR(NAME, chpl::uast::asttags::NAME, Py_TPFLAGS_DEFAULT)\n#define AST_BEGIN_SUBCLASSES(NAME) DEFINE_PY_TYPE_FOR(NAME, chpl::uast::asttags::START_##NAME, Py_TPFLAGS_BASETYPE)\n#define AST_END_SUBCLASSES(NAME)\n#include \"chpl/uast/uast-classes-list.h\"\n#undef AST_NODE\n#undef AST_BEGIN_SUBCLASSES\n#undef AST_END_SUBCLASSES\n\nYou may have noticed that I snuck templates into the code above. The motivation there\nis to avoid writing out the (usually empty) Python method table for every single\nAST node. In particular, I have a template that, by default, provides an empty\nmethod table, which can be specialized per node to add methods when necessary.\nThis detail is useful for application 3 below, but not necessary to understand\nthe use of X Macros here.\nI used the same < and > trick to generate the parentTypeFor each tag:\n\n    From chapel.cpp, around line 157\nstatic PyTypeObject* parentTypeFor(chpl::uast::asttags::AstTag tag) {\n#define AST_NODE(NAME)\n#define AST_LEAF(NAME)\n#define AST_BEGIN_SUBCLASSES(NAME)\n#define AST_END_SUBCLASSES(NAME) \\\n  if (tag > chpl::uast::asttags::START_##NAME && tag < chpl::uast::asttags::END_##NAME) { \\\n    return &NAME##Type; \\\n  }\n#include \"chpl/uast/uast-classes-list.h\"\n#include \"chpl/uast/uast-classes-list.h\"\n#undef AST_NODE\n#undef AST_LEAF\n#undef AST_BEGIN_SUBCLASSES\n#undef AST_END_SUBCLASSES\n  return &AstNodeType;\n}\n\nA few more invocations of the uast-classes-list.h macro, and I had a working\nclass hierarchy. I didn’t explicitly mention any AST node at all; all was derived\nfrom the Chapel compiler header. This also meant that as the language changed\nand the AST class hierarchy developed, the Python bindings’ code would not need\nto be updated. As long as it was compiled with an up-to-date version of the\nheader, the hierarchy would match that present within the language.\nThis allows for code like the following to be written in Python:\ndef print_decls(mod):\n    \"\"\"\n    Print all the things declared in this Chapel module.\n    \"\"\"\n    for child in mod:\n        if isinstance(child, NamedDecl):\n            print(child.name())\n\n  Application 3: CPython Method Tables and Getters\n\nThe Chapel Python bindings use the X Macro pattern another time, actually.\nLike I mentioned earlier, I use template specialization\n\nto reduce the amount of boilerplate code required for declaring Python objects.\nIn particular, there’s a general method table declared as follows:\n\n    From chapel.cpp, around line 541\ntemplate <chpl::uast::asttags::AstTag tag>\nstruct PerNodeInfo {\n  static constexpr PyMethodDef methods[] = {\n    {NULL, NULL, 0, NULL}  /* Sentinel */\n  };\n};\n\nThen, when I need to add methods, I use template specialization by writing\nsomething like the following:\ntemplate <>\nstruct PerNodeInfo<TheAstTag> {\n  static constexpr PyMethodDef methods[] = {\n    {\"method_name\", TheNode_method_name, METH_NOARGS, \"Documentation string\"},\n    // ... more like the above ...\n    {NULL, NULL, 0, NULL}  /* Sentinel */\n  };\n};\n\nWhen reviewing a PR that adds more methods to the Python bindings (by\ndefining new TheNode_methodname functions and then including them in the\nmethod table), I noticed that in the PR, the developer added some methods\nbut forgot to put them into the respective table, leaving them unusable by\nthe Python client code. This came with the additional observation that there\nwas a moderate amount of duplication when declaring the C++ functions and then\nlisting them in the table. The name (method_name in the code) occurred many\ntimes.\nThe developer who opened the PR suggesting using X Macros to combine the\ninformation (declaration of function and its use in the corresponding method table)\ninto a single list. This led to the following header file:\n\n    From method-tables.h, around line 323\nCLASS_BEGIN(FnCall)\n  METHOD_PROTOTYPE(FnCall, actuals, \"Get the actuals of this FnCall node\")\n  PLAIN_GETTER(FnCall, used_square_brackets, \"Check if this FnCall was made using square brackets\",\n               \"b\", return node->callUsedSquareBrackets())\nCLASS_END(FnCall)\n\nThe PLAIN_GETTER macro in this case is used to define trivial getters\n(precluding the need for handling the Python-object-to-AST-node conversion,\nand other CPython-specific things), whereas the METHOD_PROTOTYPE is used\nto refer to methods that needed explicit implementations. With\nthis, the method tables are generated as follows:\n\n    From chapel.cpp, around line 548\n#define CLASS_BEGIN(TAG) \\\n  template <> \\\n  struct PerNodeInfo<chpl::uast::asttags::TAG> { \\\n    static constexpr PyMethodDef methods[] = {\n#define CLASS_END(TAG) \\\n      {NULL, NULL, 0, NULL}  /* Sentinel */ \\\n    }; \\\n  };\n#define PLAIN_GETTER(NODE, NAME, DOCSTR, TYPESTR, BODY) \\\n  {#NAME, NODE##Object_##NAME, METH_NOARGS, DOCSTR},\n#define METHOD_PROTOTYPE(NODE, NAME, DOCSTR) \\\n  {#NAME, NODE##Object_##NAME, METH_NOARGS, DOCSTR},\n#include \"method-tables.h\"\n\nThe CLASS_BEGIN generates the initial template <> header and the code up\nto the opening curly brace of the table definition. Then, for each method,\nPLAIN_GETTER and METHOD_PROTOTYPE generate the relevant entries. Finally,\nCLASS_END inserts the sentinel and the closing curly brace.\nAnother invocation of the macros in method-tables.h is used to generate the\nimplementations of “plain getters”, which is boilerplate that I won’t get into\nit here, since it’s pretty CPython specific.\n\n  Discussion\n\nI’ve presented to you a three applications of the pattern, in an order that happens\nto be from least to most “extreme”. It’s possible that some of these are\nover the line for using macros, especially for those who think of macros as\nunfortunate remnants of C++’s past. However, I think that what I’ve demonstrated\ndemonstrates the versatility of the X Macro pattern – feel free to apply it to\nthe degree that you find appropriate.\nThe thing I like the most about this pattern is that the header files read quite nicely:\nyou end up with a very declarative “scaffold” of what’s going on. The\nuast-classes-list.h makes for an excellent and fairly readable reference of\nall the AST nodes in the Chapel compiler. The method-tables.h header provides\na fairly concise summary of what methods are available on what (Python) AST\nnode.\nOf course, this approach is not without its drawbacks. Drawback zero is\nthe heavy use of macros: to the best of my knowledge, modern C++ tends to\ndiscourage the usage of macros in favor of C++-specific features. Of course,\nthis “pure C++” preference is applicable to variable degrees in different use\ncases and code bases; because of this, I won’t count macros as (too much of)\na drawback.\nThe more significant downside is that this approach introduces a lot of dependencies\nbetween source files. Any time the header changes, anything that uses any part\nof the code generated by the header must be recompiled. Thus, if you’re generating\nclasses, changing any one class will “taint” any code that uses any of the\ngenerated classes. In the Chapel compiler, touching the AST class hierarchy\nrequires a recompilation of all the AST nodes, and any compiler code that uses\nthe AST nodes (a lot). This is because each AST node needs access to the\nAstTag enum, and that enum is generated from the hierarchy header.\nThat’s all I have for today! Thanks for reading. I hope you got something useful\nfor your day-to-day programming out of this.",
    "summary": {
      "en": "### Summary of \"My Favorite C++ Pattern: X Macros\"\n\nThe article discusses the \"X Macros\" pattern in C++, highlighting its usefulness in generating repetitive code, particularly in the Chapel compiler. The author shares three applications of this pattern, explaining how it simplifies code maintenance and reduces errors.\n\n1. **String Interning**: The Chapel compiler uses X Macros for efficient string management. By defining common strings in a header file, the code can automatically generate variable declarations and initializations, reducing boilerplate and the risk of inconsistency.\n\n2. **Abstract Syntax Tree (AST) Class Hierarchy**: The pattern is applied to create a class hierarchy for AST nodes. X Macros help generate tags for safe type casting and methods for checking node types without repetitive code. This approach avoids boilerplate while maintaining a clean structure for AST node classes.\n\n3. **Generating Python Bindings**: The author describes using X Macros to create corresponding Python class hierarchies for Chapel's AST nodes automatically. This ensures that as the C++ code evolves, the Python bindings remain consistent without extra effort.\n\nThe article concludes with a discussion on the benefits and drawbacks of using X Macros, emphasizing their ability to create readable and maintainable code while also acknowledging potential issues with macro-heavy code and dependencies in the codebase.",
      "ko": "이 글에서는 C++에서 \"X 매크로\" 패턴에 대해 설명하며, 이 패턴이 반복적인 코드를 생성하는 데 유용하다는 점을 강조합니다. 특히 Chapel 컴파일러에서의 활용 사례를 통해 코드 유지 관리가 어떻게 간소화되고 오류가 줄어드는지를 보여줍니다.\n\n첫 번째로, 문자열 관리에서의 활용을 다룹니다. Chapel 컴파일러는 X 매크로를 사용하여 효율적인 문자열 관리를 구현합니다. 공통 문자열을 헤더 파일에 정의함으로써, 코드가 자동으로 변수 선언과 초기화를 생성하게 되어 불필요한 코드가 줄어들고 일관성의 위험이 감소합니다.\n\n두 번째로, 추상 구문 트리(AST) 클래스 계층을 만드는 데 이 패턴이 적용됩니다. X 매크로는 안전한 타입 캐스팅을 위한 태그와 노드 타입을 확인하는 메서드를 생성하는 데 도움을 줍니다. 이 방식은 반복적인 코드를 피하면서도 AST 노드 클래스의 구조를 깔끔하게 유지할 수 있게 합니다.\n\n세 번째로, Python 바인딩 생성을 설명합니다. 저자는 X 매크로를 사용하여 Chapel의 AST 노드에 해당하는 Python 클래스 계층을 자동으로 생성하는 방법을 소개합니다. 이를 통해 C++ 코드가 발전하더라도 Python 바인딩이 일관성을 유지할 수 있습니다.\n\n마지막으로, X 매크로 사용의 장점과 단점에 대해 논의하며, 가독성이 좋고 유지 관리가 용이한 코드를 생성할 수 있는 능력을 강조합니다. 그러나 매크로가 많은 코드와 코드베이스 내의 의존성 문제에 대한 잠재적인 우려도 함께 언급합니다.",
      "ja": "この記事では、C++における「Xマクロ」パターンについて説明し、その有用性を強調しています。特に、Chapelコンパイラにおける繰り返しコードの生成に役立つことが紹介されています。著者はこのパターンの三つの応用例を挙げ、コードの保守性を向上させ、エラーを減らす方法を説明しています。\n\nまず一つ目は「文字列インターニング」です。Chapelコンパイラでは、Xマクロを使用して効率的な文字列管理を行っています。共通の文字列をヘッダーファイルに定義することで、コードは自動的に変数の宣言や初期化を生成し、冗長なコードを減らし、一貫性のリスクを軽減します。\n\n二つ目は「抽象構文木（AST）クラス階層」です。このパターンを用いて、ASTノードのクラス階層を作成します。Xマクロは、安全な型キャストのためのタグや、ノードの型をチェックするメソッドを生成するのに役立ち、繰り返しのコードを避けながらASTノードクラスの構造を整然と保ちます。\n\n三つ目は「Pythonバインディングの生成」です。著者は、Xマクロを使用してChapelのASTノードに対応するPythonクラス階層を自動的に作成する方法を説明しています。これにより、C++コードが進化しても、Pythonバインディングは追加の手間なく一貫性を保つことができます。\n\n最後に、Xマクロの利点と欠点について議論し、可読性と保守性の高いコードを生成する能力を強調していますが、マクロが多用されるコードやコードベース内の依存関係に関する潜在的な問題も認識しています。"
    }
  },
  {
    "id": "691d28780a329a49",
    "title": {
      "en": "What Killed Innovation?",
      "ko": "혁신의 죽음",
      "ja": "革新を殺したもの"
    },
    "type": "story",
    "url": "https://www.shirleywu.studio/notebook/2025-02-innovation-killer",
    "score": 112,
    "by": "speckx",
    "time": 1742909161,
    "content": "what killed innovation? ← back to notebook Find the discussion on Linkedin or\n        Bluesky. Mar 05, 2025 This is part of a trilogy on the state of our industry: Part 1: Outside a client’s comfort zone Part 2: What killed innovation? A brief history Part 3: (Coming soon) I entered the data visualization field in 2012, when D3.js had just come out and interactive graphics were going through a digital Renaissance. By the time I was fully steeped in the field in 2016, it felt like a new, experimental project was coming out every week—each one pushing the boundaries of how we think about, visualize, and communicate data. New York Times' 512 Paths to the White House from 2012.  When I think of the pre-scrollytelling era, it's always the first one I point to.  But fast forward a decade, and it feels like I’m seeing the same polished but predictable formats over and over. At first, I thought I had gotten jaded (a decade in tech feels like forever and maybe I’m now just the old granny shaking my fist about the “good old days” 😂), but after talking to a few friends and mulling on it for a couple years, I now have some hypotheses on how we might have gotten here. To test these hypotheses, I asked a few very respected voices in our industry—all known for their beautiful, bespoke work and responsible for driving the field forward in one way or another. So I’d like to thank everyone who kindly contributed: Nadieh Bremer, Giorgia Lupi, Federica Fragapane, Caitlin Ralph, Matt Daniels, RJ Andrews, Alberto Cairo, Eric William Lin, and Moritz Stefaner. While some of them are quoted directly, all of them provided insightful and nuanced answers that helped to shape my own whirlwind of ideas about where we are today, how we got here, and where we’re headed. A brief history (of a plateau) Let me come out swinging: our industry’s creativity has plateaued. Ok, I don’t fully mean that (but it’s got a lot of potential for a click-bait title, no? 😂). Let me provide a bit more nuance: the craft of telling data-informed stories on the web has plateaued. As Alberto recounts, newsrooms started digitizing in the mid-to-late 1990s, and by the time I started in the early 2010s, the foundations were laid out for really interesting web-based experiments. It was the perfect storm: Javascript was maturing, browser performance was improving, and D3.js was releasing interesting new layouts and supporting chart-specific interactions every year. I was constantly coming across new chart forms, and new ways to add interactions and animations to layer information. Just look at these two New York Times pieces from 2012 and 2013:   Four Ways to Slice Obama’s 2013 Budget Proposal (2012, left) and Among the Oscar Contenders, a Host of Connections (2013, right). From a technical perspective, I remember being so mind-blown about how the different budget items animated so smoothly between the different views, and so inspired by the use of force-directed graph to lay out the Oscar nominees (and that visual elegance!). It really seemed like no two data visualizations looked the same. RJ agrees that web interactives “hit some kind of romantic peak” in the mid-to-late 2010s. Nadieh dreamily recalls the advent of D3 visuals like chord diagrams and circle packing. “I can’t tell you what other mind boggling new technique or technology since then has, I’ve felt, made an impact,” she laments. “And that makes me very sad.” Moritz summarizes his recent observations with the precision and insight of an industry veteran who has put out inspiration after inspiration for decades: The few viral, well-known data visualizations tend to be static images or movies or small, personalized apps rather than elaborate interactive web pieces. Visual styles are more homogenous, with many projects looking similar due to the prevalence of established formats, templated solutions and software defaults. On the commercial side, investments in bespoke data visualization from freelancers and independent studios have declined. Moritz has written a whole blog post in response, with the most amazing title: “Why 2024 was a dead year for indie dataviz — and how we’ll do much better in 2025”. It’s well worth a thorough read. He declares: “it’s a polycrisis”. But how did we get here (polycrisis)? Over the past decade, I’ve noticed two fundamental shifts that have changed how we design interactive graphics on the web. The first: scrollies. I still remember when I first saw Stephanie Yee and Tony Chu’s “A visual introduction to machine learning” in 2016, I was blown away:  It felt so exciting that web performance had come so far, that browsers could continuously scroll and animate thousands of elements at the same time. Scrollytelling was so quickly adopted that there was even a big debate about whether scrollies or steppers were “better” (beautifully summarized in this blog post by Zan Armstrong). But the scrolly won out as more and more readers consumed data visualizations through mobile screens, where scrolling was the native behavior. Newsrooms brought scrollytelling to the masses, but the format almost worked too well. Many newsrooms began to treat it as the default storytelling method and, due to its success, had less reason to test other formats. Eric, who has direct newsroom experience, says that “data journalists found the forms that best fit their needs, and their audiences’. It’s not that there’s no more experimentation within graphics and data desks in newsrooms, but they’ve become more isolated and case-by-case rather than the general cultural norm. Repeatability and efficiency are now more important.” I used to look forward to the Information is Beautiful Awards every year for inspiration. But I distinctly remember the 2022 Awards, when I went through the shortlist and was inundated by scrollytelling pieces. It’s not that they weren’t good, but that after a while I couldn’t distinguish one from the next. That was the year I realized I was experiencing scrollytelling fatigue™️. My best hypothesis for why this happened is that judges just don’t have the time to deep-dive into any one piece. What makes scrollytelling easy for us as readers also makes for easier judging: Just scroll and the information is spoonfed; there’s no need to tap, no need to explore, no need to think and draw our own conclusions. After all, when judges are going through dozens or even hundreds of entries, the ones that are easiest to grok leave the most lasting impression. (I’m guilty of this.) I noticed the second shift during the Covid-19 pandemic. We saw charts about cases, and hospitalizations, and deaths, and vaccination rates…they were everywhere we looked online. At the time, I thought that data literacy might improve on a massive scale. A public that recognized the importance of data, that recognized the need to interpret charts, could perhaps also recognize that some data stories are just too complex and nuanced to be aggregated in bar charts and line charts. Surely, they’d be curious about more complex visualizations. I could dream. Instead, though there was indeed an increase in public awareness of charts, the majority of people—as I wrote in my previous blog post—were only interested in those standard charts. I’ve found in recent years that my clients have started to shy away from anything too unconventional because they’re concerned about getting pushback from their stakeholders and readers. Giorgia puts it best: “Some information will always be best conveyed in a straightforward bar or line chart, particularly for audiences that don’t have time to engage deeply. And as data literacy expanded—especially post-pandemic—the demand for intuitive, quick-to-grasp visuals naturally increased.” Why, though? In both of those shifts, there is a common refrain: the demand for easier, quicker, more bite-sized content. It’s underpinned by a cultural shift towards mobile phones as our primary mode of content consumption. The shift, as RJ notes, has shrunk the canvas, trained audiences to engage in short bursts, and has generally “made the Internet a not-fun place to hang out.” Matt of The Pudding echoes this observation: Audiences want more video and images that can fit on Instagram, “which means it can’t carry too much detail on mobile phone screens.” Audiences are also just less easily impressed these days: “The idea of visualizing data for artistic ‘wow-ness’ is far less novel than it used to be,” Matt says. “The idea of visualizing big data is not as new anymore, and in many ways expected and benign. Data viz as art just doesn’t hit the same way that it used to.” Matt shared this map of Facebook friendships, created by Paul Butler in 2010, that “broke the internet”. He’s seeing similar maps since, but “it just doesn’t turn heads like it used to”. There’s a really interesting tangent there that I want to explore one day, about the connection between novelty, a technical difficulty (“a good challenge”), and the motivation to experiment.  He has a point. All the New York Times graphics I shared earlier were ground-breaking when they first came out, but if I saw them now, I probably wouldn’t bat an eye. (Except the Oscars piece, that one still gets me.) The bar has been set. Which leads to an interesting conundrum: The most successful charts and formats get rolled up into chart-building tools and templatized. On one hand, this is a great thing—we all benefit from easier and more accessible ways of creating. But, as Moritz notes, it also leads to less investment in truly original data visuals and an overabundance of more homogenous visual styles. And that’s how we end up with scrollytelling fatigue™️ and our clients and their stakeholders asking for bar charts and line charts. Speaking of clients, Moritz notes that in economic downturns like the one we’ve been in, everybody tends to play it safe: “In an uncertain economy, clients—especially startups, nonprofits, or mid-sized firms—may cut creative budgets or prioritize ‘good enough’ solutions over innovative, artisanal visualizations.” Bespoke interactive graphics are often big and expensive to build, and their impact might be hard to measure. On the other hand, those same no-code or low-code chart-building tools have become increasingly impressive and easier for clients to maintain. These days, he says, “there are many more ways to create good-enough dynamic charts and charts… with little or no coding effort, with the additional benefit of integrating directly into existing information ecosystems.” Zooming out Giorgia contextualizes what we’re experiencing as the natural ebb and flow of an innovation cycle: “I think every wave of technological or methodological change follows a predictable pattern: an initial hype cycle, a period of widespread adoption, and then an eventual plateau where only the most practical elements endure.” We’re currently smack in the middle of that plateau, but, as Alberto reminds me, that’s not a bad thing. “Sometimes we have periods of very rapid development and innovation, like a new technology shows up, a new programming language, a new technique, and there’s very quick adoption of that, a lot of experimentation, a lot of excitement. And suddenly we reach a plateau in which that new technology feels a little bit dated or overused,” he says. “Sometimes there are periods in which we withdraw a little bit from that innovation and we go back to traditional forms. But then there will be another period of innovation. Somebody will come up with a novel way of doing things, and there will be another period of excitement. So maybe the period that we are in right now is a time of regrouping. But that’s not necessarily a bad thing.” After all, he was part of a very small group of newspapers pushing for interactive graphics in the late 90’s, when journalists and designers were getting pushback from their editors for scatterplots and histograms. He’s lived through an innovation cycle already, and he’s unfazed. So what next? As an experimenter that thrives off of novelty, I’ve been restless for our next cycle of innovation—and I have thoughts. Lots of thoughts, actually, especially after hearing from so many amazing perspectives. So don’t forget to like, subscribe, and hit that notification bell! (Sorry I’ve always wanted to pretend I’m an Youtuber 😂) (But if you do want to subscribe, the next one should be a really good one 🎊)",
    "summary": {
      "en": "The text discusses the decline of innovation in the field of data visualization, outlining a historical perspective and current challenges. \n\nKey points include:\n\n1. **Initial Innovation**: The author entered the data visualization field in 2012 during a creative boom, where new projects and techniques emerged frequently.\n\n2. **Current State**: Now, the industry feels stagnant, with many visualizations looking similar and relying on established formats, leading to \"scrollytelling fatigue.\"\n\n3. **Contributing Factors**:\n   - **Scrollytelling**: This popular storytelling format became the default in newsrooms, limiting experimentation with new methods.\n   - **Pandemic Impact**: While data literacy increased during COVID-19, there was a preference for simple charts, leading clients to favor conventional visuals over innovative designs.\n\n4. **Cultural Shift**: The rise of mobile consumption has led to a demand for quick, easy-to-understand content, affecting the complexity and creativity of visualizations.\n\n5. **Economic Pressures**: In uncertain times, clients often prioritize \"good enough\" solutions rather than investing in original, bespoke graphics.\n\n6. **Innovation Cycle**: The current stagnation is seen as a natural phase in the innovation cycle, suggesting that a new wave of creativity will eventually emerge.\n\nThe author expresses a desire for the next cycle of innovation and plans to share more insights in future discussions.",
      "ko": "데이터 시각화 분야에서 혁신이 감소하고 있는 현상에 대해 역사적 관점과 현재의 도전 과제를 다루고 있다. \n\n저자는 2012년에 데이터 시각화 분야에 진입했으며, 그 당시에는 창의적인 붐이 일어나 새로운 프로젝트와 기법이 자주 등장했다. 그러나 현재 이 산업은 정체된 느낌이 강하며, 많은 시각화가 비슷하게 보이고 기존 형식에 의존하고 있어 \"스크롤텔링 피로\"를 초래하고 있다. \n\n이러한 현상의 원인으로는 스크롤텔링이라는 인기 있는 이야기 형식이 뉴스룸에서 기본으로 자리 잡으면서 새로운 방법에 대한 실험이 제한된 점이 있다. 또한 COVID-19 팬데믹 동안 데이터 이해력이 증가했지만, 간단한 차트에 대한 선호가 커져 고객들이 혁신적인 디자인보다 전통적인 시각화를 선호하게 되었다. \n\n모바일 소비의 증가로 인해 빠르고 쉽게 이해할 수 있는 콘텐츠에 대한 수요가 높아지면서 시각화의 복잡성과 창의성에도 영향을 미쳤다. 경제적 불확실성이 커지는 상황에서는 고객들이 독창적이고 맞춤형 그래픽에 투자하기보다는 \"충분히 좋은\" 솔루션을 우선시하는 경향이 있다. \n\n현재의 정체는 혁신 주기의 자연스러운 단계로 여겨지며, 결국 새로운 창의력의 물결이 나타날 것이라는 전망이 있다. 저자는 다음 혁신 주기에 대한 기대를 표현하며, 향후 논의에서 더 많은 통찰을 공유할 계획이다.",
      "ja": "データビジュアライゼーションの分野における革新の減少について、歴史的な視点と現在の課題が述べられています。\n\n著者は2012年にデータビジュアライゼーションの分野に入った際、創造的なブームの中で新しいプロジェクトや技術が頻繁に登場していたと振り返っています。しかし、現在は業界が停滞していると感じられ、多くのビジュアライゼーションが似たようなものになり、既存のフォーマットに依存しているため、「スクロリーテリング疲れ」が生じています。\n\nこの停滞の要因として、まず「スクロリーテリング」が挙げられます。この人気のあるストーリーテリング形式はニュースルームでデフォルトとなり、新しい手法の実験が制限されています。また、COVID-19の影響でデータリテラシーは向上しましたが、シンプルなグラフが好まれ、クライアントは革新的なデザインよりも従来のビジュアルを選ぶ傾向が強まりました。\n\nさらに、モバイルコンテンツの消費が増えたことで、迅速でわかりやすいコンテンツへの需要が高まり、ビジュアライゼーションの複雑さや創造性に影響を与えています。経済的な圧力も影響しており、不確実な時代にはクライアントが「十分良い」解決策を優先し、オリジナルのグラフィックへの投資を避けることが多くなっています。\n\n現在の停滞は革新サイクルの自然な段階と見なされており、新たな創造性の波がいずれ現れることが期待されています。著者は次の革新のサイクルを望んでおり、今後の議論でさらに洞察を共有する計画を持っています。"
    }
  },
  {
    "id": "c9a9fbc461784e46",
    "title": {
      "en": "Activeloop (YC S18) Is Hiring Senior Python Back End and AI Search Engineers",
      "ko": null,
      "ja": null
    },
    "type": "job",
    "url": "https://careers.activeloop.ai/",
    "score": 1,
    "by": "davidbuniat",
    "time": 1742922036,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "db9ac46dc2d5db70",
    "title": {
      "en": "U.S. national-security leaders included me in a group chat",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://www.theatlantic.com/politics/archive/2025/03/trump-administration-accidentally-texted-me-its-war-plans/682151/",
    "score": 2147,
    "by": "_tk_",
    "time": 1742833435,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "74cb0c47f4e73b9b",
    "title": {
      "en": "Why is C the symbol for the speed of light? (2004)",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://math.ucr.edu/home/baez/physics/Relativity/SpeedOfLight/c.html",
    "score": 137,
    "by": "fanf2",
    "time": 1742917323,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "245e3e53ffa9e1ca",
    "title": {
      "en": "The Jakt Programming Language",
      "ko": "잭트 프로그래밍",
      "ja": "ジャクト言語"
    },
    "type": "story",
    "url": "https://github.com/SerenityOS/jakt",
    "score": 103,
    "by": "gw2",
    "time": 1742574866,
    "content": "The Jakt programming language\nJakt is a memory-safe systems programming language.\nIt currently transpiles to C++.\nNOTE: The language is under heavy development.\nNOTE If you're cloning to a Windows PC (not WSL), make sure that your Git client keeps the line endings as \\n. You can set this as a global config via git config --global core.autocrlf false.\nUsage\nThe transpilation to C++ requires clang. Make sure you have that installed.\njakt file.jakt\n./build/file\n\nBuilding\nSee here.\nGoals\n\nMemory safety\nCode readability\nDeveloper productivity\nExecutable performance\nFun!\n\nMemory safety\nThe following strategies are employed to achieve memory safety:\n\nAutomatic reference counting\nStrong typing\nBounds checking\nNo raw pointers in safe mode\n\nIn Jakt, there are three pointer types:\n\n T (Strong pointer to reference-counted class T.)\n weak T (Weak pointer to reference-counted class T. Becomes empty on pointee destruction.)\n raw T (Raw pointer to arbitrary type T. Only usable in unsafe blocks.)\n\nNull pointers are not possible in safe mode, but pointers can be wrapped in Optional, i.e Optional<T> or T? for short.\nMath safety\n\n Integer overflow (both signed and unsigned) is a runtime error.\n Numeric values are not automatically coerced to int. All casts must be explicit.\n\nFor cases where silent integer overflow is desired, there are explicit functions that provide this functionality.\nCode readability\nFar more time is spent reading code than writing it. For that reason, Jakt puts a high emphasis on readability.\nSome of the features that encourage more readable programs:\n\n Immutable by default.\n Argument labels in call expressions (object.function(width: 10, height: 5))\n Inferred enum scope. (You can say Foo instead of MyEnum::Foo).\n Pattern matching with match.\n Optional chaining (foo?.bar?.baz (fallible) and foo!.bar!.baz (infallible))\n None coalescing for optionals (foo ?? bar yields foo if foo has a value, otherwise bar)\n defer statements.\n Pointers are always dereferenced with . (never ->)\n Trailing closure parameters can be passed outside the call parentheses.\n Error propagation with ErrorOr<T> return type and dedicated try / must keywords.\n\nCode reuse\nJakt is flexible in how a project can be structured with a built-in module system.\nimport a                                // (1)\nimport a { use_cool_things }            // (2)\nimport fn()                             // (3)\nimport relative foo::bar                // (4)\nimport relative parent::foo::baz        // (5)\nimport relative parent(3)::foo::baz     // (6)\n\nImport a module from the same directory as the file.\nImport only use_cool_things() from module a.\nImports can be calculated at compile time. See Comptime Imports\nImport a module using the relative keyword when the module is a sub path of the directory containing the file.\nImport a module in a parent path one directory up from the directory containing the file.\nSyntactic sugar for importing a module three parent paths up from the directory containing the file.\n\nThe Jakt Standard Library\nJakt has a Standard Library that is accessed using the jakt:: namespace:\nimport jakt::arguments\nimport jakt::libc::io { system }\n\nThe Jakt Standard Library is in its infancy, so please consider making a contribution!\nFunction calls\nWhen calling a function, you must specify the name of each argument as you're passing it:\nrect.set_size(width: 640, height: 480)\n\nThere are two exceptions to this:\n\n If the parameter in the function declaration is declared as anon, omitting the argument label is allowed.\n When passing a variable with the same name as the parameter.\n\nStructures and classes\nThere are two main ways to declare a structure in Jakt: struct and class.\nstruct\nBasic syntax:\nstruct Point {\n    x: i64\n    y: i64\n}\n\nStructs in Jakt have value semantics:\n\nVariables that contain a struct always have a unique instance of the struct.\nCopying a struct instance always makes a deep copy.\n\nlet a = Point(x: 10, y: 5)\nlet b = a\n// \"b\" is a deep copy of \"a\", they do not refer to the same Point\n\nJakt generates a default constructor for structs. It takes all fields by name. For the Point struct above, it looks like this:\nPoint(x: i64, y: i64)\n\nStruct members are public by default.\nclass\n\n basic class support\n private-by-default members\n inheritance\n class-based polymorphism (assign child instance to things requiring the parent type)\n Super type\n Self type\n\nSame basic syntax as struct:\nclass Size {\n    width: i64\n    height: i64\n\n    public fn area(this) => .width * .height\n}\n\nClasses in Jakt have reference semantics:\n\nCopying a class instance (aka an \"object\") copies a reference to the object.\nAll objects are reference-counted by default. This ensures that objects don't get accessed after being deleted.\n\nClass members are private by default.\nMember functions\nBoth structs and classes can have member functions.\nThere are three kinds of member functions:\nStatic member functions don't require an object to call. They have no this parameter.\nclass Foo {\n    fn func() => println(\"Hello!\")\n}\n\n// Foo::func() can be called without an object.\nFoo::func()\n\nNon-mutating member functions require an object to be called, but cannot mutate the object. The first parameter is this.\nclass Foo {\n    fn func(this) => println(\"Hello!\")\n}\n\n// Foo::func() can only be called on an instance of Foo.\nlet x = Foo()\nx.func()\n\nMutating member functions require an object to be called, and may modify the object. The first parameter is mut this.\nclass Foo {\n    x: i64\n\n    fn set(mut this, anon x: i64) {\n        this.x = x\n    }\n}\n\n// Foo::set() can only be called on a mut Foo:\nmut foo = Foo(x: 3)\nfoo.set(9)\n\nShorthand for accessing member variables\nTo reduce repetitive this. spam in methods, the shorthand .foo expands to this.foo.\nStrings\nStrings are provided in the language mainly as the type String, which is a reference-counted (and heap-allocated) string type.\nString literals are written with double quotes, like \"Hello, world!\".\nOverloaded string literals\nString literals are of type String by default; however, they can be used to implicitly construct any type that implements the FromStringLiteral (or ThrowingFromStringLiteral) trait. In the language prelude, currently only StringView implements this trait, which can be used only to refer to strings with a static lifetime:\nlet foo: StringView = \"foo\" // This string is not allocated on the heap, and foo is only a fat pointer to the static string.\n\nOverloaded string literals can be used by providing a type hint, whether by explicit type annotations, or by passing the literal to a function that expects a specific type:\nstruct NotString implements(FromStringLiteral) {\n    fn from_string_literal(anon string: StringView) -> NotString => NotString()\n}\n\nfn test(x: NotString) {}\n\nfn main() {\n    let foo: NotString = \"foo\"\n    test(x: \"Some string literal\")\n}\n\nArrays\nDynamic arrays are provided via a built-in Array<T> type. They can grow and shrink at runtime.\nArray is memory safe:\n\nOut-of-bounds will panic the program with a runtime error.\nSlices of an Array keep the underlying data alive via automatic reference counting.\n\nDeclaring arrays\n// Function that takes an Array<i64> and returns an Array<String>\nfn foo(numbers: [i64]) -> [String] {\n    ...\n}\n\nShorthand for creating arrays\n// Array<i64> with 256 elements, all initialized to 0.\nlet values = [0; 256]\n\n// Array<String> with 3 elements: \"foo\", \"bar\" and \"baz\".\nlet values = [\"foo\", \"bar\", \"baz\"]\n\nDictionaries\n\n Creating dictionaries\n Indexing dictionaries\n Assigning into indexes (aka lvalue)\n\nfn main() {\n    let dict = [\"a\": 1, \"b\": 2]\n\n    println(\"{}\", dict[\"a\"])\n}\n\nDeclaring dictionaries\n// Function that takes a Dictionary<i64, String> and returns an Dictionary<String, bool>\nfn foo(numbers: [i64:String]) -> [String:bool] {\n    ...\n}\n\nShorthand for creating dictionaries\n// Dictionary<String, i64> with 3 entries.\nlet values = [\"foo\": 500, \"bar\": 600, \"baz\": 700]\n\nSets\n\n Creating sets\n Reference semantics\n\nfn main() {\n    let set = {1, 2, 3}\n\n    println(\"{}\", set.contains(1))\n    println(\"{}\", set.contains(5))\n}\n\nTuples\n\n Creating tuples\n Index tuples\n Tuple types\n\nfn main() {\n    let x = (\"a\", 2, true)\n\n    println(\"{}\", x.1)\n}\n\nEnums and Pattern Matching\n\n Enums as sum-types\n Generic enums\n Enums as names for values of an underlying type\n match expressions\n Enum scope inference in match arms\n Yielding values from match blocks\n Nested match patterns\n Traits as match patterns\n Support for interop with the ?, ?? and ! operators\n\nenum MyOptional<T> {\n    Some(T)\n    None\n}\n\nfn value_or_default<T>(anon x: MyOptional<T>, default: T) -> T {\n    return match x {\n        Some(value) => {\n            let stuff = maybe_do_stuff_with(value)\n            let more_stuff = stuff.do_some_more_processing()\n            yield more_stuff\n        }\n        None => default\n    }\n}\n\nenum Foo {\n    StructLikeThingy (\n        field_a: i32\n        field_b: i32\n    )\n}\n\nfn look_at_foo(anon x: Foo) -> i32 {\n    match x {\n        StructLikeThingy(field_a: a, field_b) => {\n            return a + field_b\n        }\n    }\n}\n\nenum AlertDescription: i8 {\n    CloseNotify = 0\n    UnexpectedMessage = 10\n    BadRecordMAC = 20\n    // etc\n}\n\n// Use in match:\nfn do_nothing_in_particular() => match AlertDescription::CloseNotify {\n    CloseNotify => { ... }\n    UnexpectedMessage => { ... }\n    BadRecordMAC => { ... }\n}\n\nGenerics\n\n Generic types\n Constant generics (minimal support)\n Constant generics (full support)\n Generic type inference\n Traits\n\nJakt supports both generic structures and generic functions.\nfn id<T>(anon x: T) -> T {\n    return x\n}\n\nfn main() {\n    let y = id(3)\n\n    println(\"{}\", y + 1000)\n}\n\nstruct Foo<T> {\n    x: T\n}\n\nfn main() {\n    let f = Foo(x: 100)\n\n    println(\"{}\", f.x)\n}\n\nstruct MyArray<T, comptime U> {\n    // NOTE: There is currently no way to access the value 'U', referring to 'U' is only valid as the type at the moment.\n    data: [T]\n}\n\nNamespaces\n\n Namespace support for functions and struct/class/enum\n Deep namespace support\n\nnamespace Greeters {\n    fn greet() {\n        println(\"Well, hello friends\")\n    }\n}\n\nfn main() {\n    Greeters::greet()\n}\n\nType casts\nThere are two built-in casting operators in Jakt.\n\nas? T: Returns an Optional<T>, empty if the source value isn't convertible to T.\nas! T: Returns a T, aborts the program if the source value isn't convertible to T.\n\nThe as cast can do these things (note that the implementation may not agree yet):\n\nCasts to the same type are infallible and pointless, so might be forbidden in the future.\nIf the source type is unknown, the cast is valid as a type assertion.\nIf both types are primitive, a safe conversion is done.\n\nInteger casts will fail if the value is out of range. This means that promotion casts like i32 -> i64 are infallible.\nFloat -> Integer casts truncate the decimal point (?)\nInteger -> Float casts resolve to the closest value to the integer representable by the floating-point type (?). If the integer value is too large, they resolve to infinity (?)\nAny primitive -> bool will create true for any value except 0, which is false.\nbool -> any primitive will do false -> 0 and true -> 1, even for floats.\n\nIf the types are two different pointer types (see above), the cast is essentially a no-op. A cast to T will increment the reference count as expected; that's the preferred way of creating a strong reference from a weak reference. A cast from and to raw T is unsafe.\nIf the types are part of the same type hierarchy (i.e. one is a child type of another):\n\nA child can be cast to its parent infallibly.\nA parent can be cast to a child, but this will check the type at runtime and fail if the object was not of the child type or one of its subtypes.\n\nIf the types are incompatible, a user-defined cast is attempted to be used. The details here are not decided yet.\nIf nothing works, the cast will not even compile.\n\nAdditional casts are available in the standard library. Two important ones are as_saturated and as_truncated, which cast integral values while saturating to the boundaries or truncating bits, respectively.\nTraits\nTo make generics a bit more powerful and expressive, you can add additional information to them:\ntrait Hashable<Output> {\n    fn hash(self) -> Output\n}\n\nclass Foo implements(Hashable<i64>) {\n    fn hash(self) => 42\n}\n\nTraits can be used to add constraints to generic types, but also provide default implementations based on a minimal set of requirements - for instance:\ntrait Fancy {\n    fn do_something(this) -> void\n    fn do_something_twice(this) -> void {\n        .do_something()\n        .do_something()\n    }\n}\n\nstruct Boring implements(Fancy) {\n    fn do_something(this) -> void {\n        println(\"I'm so boring\")\n    }\n\n    // Note that we don't have to implement `do_something_twice` here, because it has a default implementation.\n}\n\nstruct Better implements(Fancy) {\n    fn do_something(this) -> void {\n        println(\"I'm not boring\")\n    }\n\n    // However, a custom implementation is still valid.\n    fn do_something_twice(this) -> void {\n        println(\"I'm not boring, but I'm doing it twice\")\n    }\n}\n\nTraits can have methods that reference other traits as types, which can be used to describe a hierarchy of traits:\ntrait ConstIterable<T> {\n    fn next(this) -> T?\n}\n\ntrait IntoIterator<T> {\n    // Note how the return type is a reference to the ConstIterable trait (and not a concrete type)\n    fn iterator(this) -> ConstIterable<T>\n}\n\nOperator Overloading and Traits\nOperators are implemented as traits, and can be overloaded by implementing them on a given type:\nstruct Foo implements(Add<Foo, Foo>) {\n    x: i32\n\n    fn add(this, anon rhs: Foo) -> Foo {\n        return Foo(x: .x + other.x)\n    }\n}\n\nThe relationship between operators and traits is as follows (Note that @ is used as a placeholder for any binary operator's name or sigil):\n\nOperator\nTrait\nMethod Name\nDerived From Method\n\n+\nAdd\nadd\n-\n\n-\nSubtract\nsubtract\n-\n\n*\nMultiply\nmultiply\n-\n\n/\nDivide\ndivide\n-\n\n%\nModulo\nmodulo\n-\n\n<\nCompare\nless_than\ncompare\n\n>\nCompare\ngreater_than\ncompare\n\n<=\nCompare\nless_than_or_equal\ncompare\n\n>=\nCompare\ngreater_than_or_equal\ncompare\n\n==\nEqual\nequals\n-\n\n!=\nEqual\nnot_equals\nequals\n\n@=\n@Assignment\n@_assign\n-\n\nOther operators have not yet been converted to traits, decided on, or implemented:\n\nOperator\nDescription\nStatus\n\n&\nBitwise And\nNot Decided\n\n|\nBitwise Or\nNot Decided\n\n^\nBitwise Xor\nNot Decided\n\n~\nBitwise Not\nNot Decided\n\n<<\nBitwise Shift Left\nNot Decided\n\n>>\nBitwise Shift Right\nNot Decided\n\nand\nLogical And\nNot Decided\n\nor\nLogical Or\nNot Decided\n\nnot\nLogical Not\nNot Decided\n\n=\nAssignment\nNot Decided\n\nSafety analysis\n(Not yet implemented)\nTo keep things safe, there are a few kinds of analysis we'd like to do (non-exhaustive):\n\nPreventing overlapping of method calls that would collide with each other. For example, creating an iterator over a container, and while that's live, resizing the container\nUsing and manipulating raw pointers\nCalling out to C code that may have side effects\n\nError handling\nFunctions that can fail with an error instead of returning normally are marked with the throws keyword:\nfn task_that_might_fail() throws -> usize {\n    if problem {\n        throw Error::from_errno(EPROBLEM)\n    }\n    ...\n    return result\n}\n\nfn task_that_cannot_fail() -> usize {\n    ...\n    return result\n}\n\nUnlike languages like C++ and Java, errors don't unwind the call stack automatically. Instead, they bubble up to the nearest caller.\nIf nothing else is specified, calling a function that throws from within a function that throws will implicitly bubble errors.\nSyntax for catching errors\nIf you want to catch errors locally instead of letting them bubble up to the caller, use a try/catch construct like this:\ntry {\n    task_that_might_fail()\n} catch error {\n    println(\"Caught error: {}\", error)\n}\n\nThere's also a shorter form:\ntry task_that_might_fail() catch error {\n    println(\"Caught error: {}\", error)\n}\n\nRethrowing errors\n(Not yet implemented)\nInline C++\nFor better interoperability with existing C++ code, as well as situations where the capabilities of Jakt within unsafe blocks are not powerful enough, the possibility of embedding inline C++ code into the program exists in the form of cpp blocks:\nmut x = 0\nunsafe {\n    cpp {\n        \"x = (i64)&x;\"\n    }\n}\nprintln(\"{}\", x)\n\nReferences\nValues and objects can be passed by reference in some situations where it's provably safe to do so.\nA reference is either immutable (default) or mutable.\nReference type syntax\n\n&T is an immutable reference to a value of type T.\n&mut T is a mutable reference to a value of type T.\n\nReference expression syntax\n\n&foo creates an immutable reference to the variable foo.\n&mut foo creates a mutable reference to the variable foo.\n\nDereferencing a reference\nTo \"get the value out\" of a reference, it must be dereferenced using the * operator, however the compiler will automatically dereference references if the dereferencing is the single unambiguous correct use of the reference (in practice, manual dereferencing is only required where the reference is being stored or passed to functions).\nfn sum(a: &i64, b: &i64) -> i64 {\n    return a + b\n    // Or with manual dereferencing:\n    return *a + *b\n}\n\nfn test() {\n    let a = 1\n    let b = 2\n    let c = sum(&a, &b)\n}\n\nFor mutable references to structs, you'll need to wrap the dereference in parentheses in order to do a field access:\nstruct Foo {\n    x: i64\n}\nfn zero_out(foo: &mut Foo) {\n    foo.x = 0\n    // Or with manual dereferencing:\n    (*foo).x = 0\n}\n\nReferences (first version) feature list:\n\n Reference types\n Reference function parameters\n Local reference variables with basic lifetime analysis\n No references in structs\n No references in return types\n No mutable references to immutable values\n Allow &foo and &mut foo without argument label for parameters named foo\n Auto-dereference references where applicable\n\nReferences TODO:\n\n (unsafe) references and raw pointers bidirectionally convertible\n No capture-by-reference in persistent closures\n\nClosures (first version) feature list:\n\n Function as parameter to function\n Functions as variables\n No returning functions from functions\n Lambdas can throw\n Explicit captures\n\nClosures TODO:\n\n Return function from function\n\nCompiletime Execution\nCompiletime Function Execution (or CTFE) in Jakt allows the execution of any jakt function at compiletime, provided that the result value\nmay be synthesized using its fields - currently this only disallows a few prelude objects that cannot be constructed by their fields (like Iterator objects and StringBuilders).\nAny regular Jakt function can be turned into a compiletime function by replacing the function keyword in its declaration with the comptime keyword, which will force all calls to that specific function to be evaluated at compile time.\nInvocation Restrictions\nComptime functions may only be invoked by constant expressions; this restriction includes the this object of methods.\nThrowing in a comptime context\nThrowing behaves the same way as normal error control flow does, if the error leaves the comptime context (by reaching the original callsite), it will be promoted to a compilation error.\nSide effects\nCurrently all prelude functions with side effects behave the same as they would in runtime. This allows e.g. pulling in files into the binary; some functions may be changed later to perform more useful actions.\nComptime imports\nIt is possible to design custom import handling based on data available at compile time. An excellent example of this in the Jakt compiler is the Platform Module.\nSee a smaller example in the comptime imports sample.\nComptime TODO\n\n Implement execution of all Jakt expressions",
    "summary": {
      "en": "**Summary of Jakt Programming Language**\n\nJakt is a new programming language designed for memory safety and ease of use, currently transpiling to C++. Here are the key points:\n\n- **Memory Safety**: Jakt ensures memory safety through features like automatic reference counting, strong typing, bounds checking, and the absence of raw pointers in safe mode. It uses three pointer types: strong, weak, and raw. Null pointers are avoided in safe mode.\n\n- **Math Safety**: Integer overflow is treated as a runtime error, and all type casts must be explicit.\n\n- **Readability and Productivity**: Jakt emphasizes code readability with features like immutable variables by default, argument labels in function calls, and pattern matching syntax.\n\n- **Code Reusability**: The language has a flexible module system allowing various import styles.\n\n- **Standard Library**: Jakt includes a standard library under the `jakt::` namespace, which is still being developed.\n\n- **Function Calls**: Argument names must be specified when calling functions, enhancing clarity.\n\n- **Structures and Classes**: Jakt supports both structs (value semantics) and classes (reference semantics), with automatic deep copying for structs and reference counting for classes.\n\n- **Generics and Traits**: The language supports generics and traits to add functionality and constraints to types, allowing for more expressive code.\n\n- **Error Handling**: Functions can indicate potential errors with the `throws` keyword, and errors can be caught using try/catch syntax.\n\n- **Inline C++ Support**: Jakt allows embedding C++ code for better interoperability.\n\n- **References and Closures**: Jakt supports immutable and mutable references, with automatic dereferencing. Closures can also be used, although returning functions from functions is not yet implemented.\n\n- **Compile-time Execution**: Jakt allows certain functions to be executed at compile time, enabling optimizations.\n\nOverall, Jakt aims to enhance memory safety, readability, and developer productivity while allowing high-performance executable outputs.",
      "ko": "Jakt는 메모리 안전성과 사용의 용이성을 위해 설계된 새로운 프로그래밍 언어로, 현재 C++로 변환되고 있습니다. 주요 특징은 다음과 같습니다.\n\nJakt는 자동 참조 카운팅, 강력한 타입, 경계 검사와 같은 기능을 통해 메모리 안전성을 보장합니다. 안전 모드에서는 원시 포인터가 없으며, 세 가지 포인터 유형인 강한 포인터, 약한 포인터, 원시 포인터를 사용합니다. 안전 모드에서는 널 포인터를 피합니다.\n\n정수 오버플로우는 런타임 오류로 처리되며, 모든 타입 변환은 명시적이어야 합니다. Jakt는 코드 가독성을 강조하며, 기본적으로 불변 변수를 사용하고 함수 호출 시 인수 레이블을 지원하며 패턴 매칭 문법을 제공합니다.\n\n이 언어는 다양한 가져오기 스타일을 허용하는 유연한 모듈 시스템을 갖추고 있어 코드 재사용성을 높입니다. Jakt는 아직 개발 중인 `jakt::` 네임스페이스 아래에 표준 라이브러리를 포함하고 있습니다.\n\n함수 호출 시 인수 이름을 명시해야 하므로 코드의 명확성이 향상됩니다. Jakt는 구조체(값 의미론)와 클래스(참조 의미론)를 모두 지원하며, 구조체는 자동 깊은 복사를, 클래스는 참조 카운팅을 사용합니다.\n\n제네릭과 트레이트를 지원하여 타입에 기능과 제약을 추가할 수 있어 더 표현력 있는 코드를 작성할 수 있습니다. 함수는 `throws` 키워드를 사용해 잠재적인 오류를 나타낼 수 있으며, try/catch 문법을 통해 오류를 처리할 수 있습니다.\n\nJakt는 C++ 코드를 내장할 수 있어 상호 운용성을 개선합니다. 불변 및 가변 참조를 지원하며 자동으로 역참조가 이루어집니다. 클로저도 사용할 수 있지만, 함수에서 함수를 반환하는 기능은 아직 구현되지 않았습니다.\n\nJakt는 특정 함수를 컴파일 타임에 실행할 수 있게 하여 최적화를 가능하게 합니다. 전반적으로 Jakt는 메모리 안전성, 가독성 및 개발자 생산성을 향상시키면서 고성능 실행 파일 출력을 목표로 하고 있습니다.",
      "ja": "Jaktは、メモリの安全性と使いやすさを重視して設計された新しいプログラミング言語で、現在C++に変換されています。主な特徴は以下の通りです。\n\nJaktは、メモリの安全性を確保するために、自動参照カウント、強い型付け、境界チェック、安全モードでの生ポインタの不使用などの機能を備えています。ポインタの種類は強いポインタ、弱いポインタ、生ポインタの3種類があり、安全モードではヌルポインタを避けます。\n\n整数のオーバーフローは実行時エラーとして扱われ、すべての型キャストは明示的に行う必要があります。\n\nJaktは、コードの可読性を重視しており、デフォルトで不変の変数、関数呼び出し時の引数ラベル、パターンマッチングの構文などの機能があります。\n\nこの言語は柔軟なモジュールシステムを持ち、さまざまなインポートスタイルをサポートしています。\n\nJaktにはまだ開発中の標準ライブラリがあり、`jakt::`という名前空間の下に含まれています。\n\n関数を呼び出す際には引数名を指定する必要があり、これによりコードの明確さが向上します。\n\nJaktは構造体（値セマンティクス）とクラス（参照セマンティクス）の両方をサポートしており、構造体は自動的に深いコピーが行われ、クラスは参照カウントが適用されます。\n\nこの言語は、ジェネリクスやトレイトをサポートしており、型に機能や制約を追加することで、より表現力豊かなコードを書くことができます。\n\n関数は`throws`キーワードを使って潜在的なエラーを示すことができ、try/catch構文を使ってエラーを捕捉することが可能です。\n\nJaktは、C++コードを埋め込むことができ、相互運用性を向上させます。\n\n不変および可変の参照をサポートし、自動的にデリファレンスが行われます。クロージャも使用可能ですが、関数から関数を返す機能はまだ実装されていません。\n\n特定の関数をコンパイル時に実行できるため、最適化が可能です。\n\n全体として、Jaktはメモリの安全性、可読性、開発者の生産性を向上させ、高性能な実行可能な出力を提供することを目指しています。"
    }
  },
  {
    "id": "4f4f3cef9fb3edcc",
    "title": {
      "en": "How to use an en-dash and em-dash correctly? (BrE)",
      "ko": "대시 완벽 가이드",
      "ja": "ダッシュの使い方"
    },
    "type": "story",
    "url": "https://www.lighthouseproofreading.co.uk/blog/how-to-use-an-en-dash-and-em-dash-correctly",
    "score": 30,
    "by": "susam",
    "time": 1742670238,
    "content": "What’s the difference between an en dash and em dash?\n\nThere are hyphens. Then there are dashes. There’s the en dash. Then there’s the em dash.\nAnd these diddy lines can cause all sorts of confusion when you’re writing your marketing copy. If you spot them at all.\nAt a glance, you might not notice the difference between these three punctuation marks. And even if you do, they’re not the easiest things to add in when you actually want to use them.\nSo let’s break down the difference between an en dash and an em dash. And I’ll tell you exactly where you can find them.\nA fine line\nLet’s rule out the smallest of the three marks.\nHere’s the hyphen: /-/\n\nIt’s used to create a compound word. It gathers two words together and snuggles them in without any spaces. We need these so there’s no uncertainty and confusion in meaning.\nCompare these...\nIs Brenda living her best life with some extra marital sex? Lucky Bernadette! After eight years together they’re gearing things back up.\nOr is Brenda having extra-marital sex? I bet it’s with Tabitha. From book club. Tut.\nWe’re not looking at these here. So head over to how to use hyphens for the ins and outs\nCut a dash\nNow onto the dashes.\nHere’s the en dash: /–/\n\nIt’s the width of an ‘n’ and it shows an inclusive range. A ‘from and to’ situation. And there are no spaces.\nRule 1: Book club was 7–10pm.\nYou don’t use ‘from’ or ‘between’ with an en dash. If you want to use it then you need a ‘to’ between the range instead. Like this…\nRule 2: Book club ran from 7pm to 10pm.\nAnd this is the em dash: /—/\n\nUnsurprisingly, it’s around the width of an ‘m’ and there are no spaces either side either. Here are the three ways you’ll most likely use it.\nRule 1: When more emphasis is needed than a pair of commas, or just like a pair of brackets. We don't use this so much in UK English now. I'll fill you in on that later.\nBook club—more like wine club—was every Wednesday night.\nRule 2: An aside or afterthought.\nLast week’s book was Tipping the Velvet—she preferred Fingersmith.\nRule 3: A sudden break in speech.\n“But Tabitha is just a—\"\nBUT…\nIn the UK, we tend to have ditched the em dash unless it’s for punctuating speech. Instead, we use the en dash with a space either side. It’s easier on the eye. You can use them to replace the en dash in rules 1 and 2 above. Like this…\nBook club – more like wine club – was every Wednesday night.\nLast week’s book was Tipping the Velvet – she preferred Fingersmith.\nSlapdash\nWhen we use Word it tries to make it easy for you to type the symbol you need. From now on, anything in forward slashes is what you need to key in. Don’t type the //.\nHere’s what to type:\n►En dash: /number space hyphen space number/ so /1999 - 2001/ to get /1999 – 2001/\n►Em dash: /word hyphen hyphen word/ so /word--word/ to get /word—word/\nBUT… that date range is wrong.\nThe ‘from and to’ ranges that use an en dash with numbers shouldn’t have a space either side of them. This autotyping in Word works well if we want to use an en dash with a space either side, like brackets. But not for ranges.\nKeep an eye on what Word’s up to without you realising as you type.\nTake a shortcut\nYou can type shortcuts so you don’t even need to look up from your screen. Make sure you have Number Lock switched on and use these keystrokes:\n►En dash: /Ctrl+Minus/ and /Alt+0150/\n►Em dash: /Ctrl+Alt+Minus/ and /Alt+0151/\nBut are you really going to remember those codes? I sure don’t.\nAnd if you have a laptop that doesn’t have a number keypad on the right of the keyboard then it doesn’t even work.\nIt’s easier to insert the symbol manually. Then copy and paste if you need it again. Here’s how…\nChoose your character\nHead up to Insert on the toolbar. Click Symbol in Word or Special Characters in Google Docs. Look for the dashes.\nIt’s not always easy to tell which dash is which. If you hover over or click on it then it’ll tell you:\n►En dash: symbol #45 or unicode /U+2013/\n►Em dash: symbol #190 or unicode /U+2014/\n\n  Work it on the webIf you’re writing for the web, you DO need to type in a code to get your dashes. (There isn’t at the time of writing, but that might change). Instead, you need to write your copy in HTML or markdown and use these codes:En dash: /&ndash;/ or /&#8211;/Em dash: /&mdash;/ or /&#8212;/(I know, I know, the bullets are inconsistent. The markdown text box I’ve used so far in this article converts the keystrokes to the symbols, so I’ve had to use a basic text box to spell them out for you.)\n\nOh, dash it!\nWhat if you don’t want to mess with HTML or add markdown blocks to your webpage?\nDon’t if you don’t want to.\nI hardly use them for the web these days as it’s more effort. I use punchier sentences instead. And I’ve developed my writing style from it.\nYou can’t type dashes straight into social media posts either. You can copy and paste them. But, really? It’s a lot of faffing around for something we consume and scroll past so quickly.\nSo don’t do that either if you don’t want to.\nThe punctuation. The point?\nFor those that know the difference between a hyphen, en dash and em dash, it makes it easier to follow the flow of a sentence. If we see something that’s not correct, it’s a distraction. And, ideally, we don’t want distractions.\nI don’t work on books. But if you’re writing to publish (or self-publish) your work, you need to get it right.\nWriting white papers, pitch decks or account based marketing copy? If you’re writing anything that’s got a whopping financial element to it, you need to get it right. Don’t risk all that marketing insight and effort. Or the money.\nThen there’s web copy. If you already write in HTML or markdown then add it in whilst you’re in there. If you’re selling your copywriting and marketing expertise, you want to show you know your stuff.\nBut social media? I don’t personally see the point. Yes, you’re there to sell. If you’ve already written the post in Word and are copying it across then include it. But fannying about just to copy and paste a symbol isn’t the best use of your time.\nThere’s no loss of meaning. And there’s no point me telling you to do something that I wouldn’t do. I’d adjust the sentence to remove the dash, rather than use something I knew was incorrect. But that’s me.\nYep, some people will notice. Some people will wince. They’ll live.\nMad dash\nJust like any other punctuation, dashes are there to help us understand what’s being said.\nEn dashes make ranges clear. Em dashes give us more options to choose how we pace a sentence. They show when we’re adding a little something extra. En dashes can do that for us too if we like a more clean and clear style.\nIf you’re writing high-end copy that’s not going online, follow the rules.\nIf you’re writing for the web, it’d be nice. Especially if words are your thing.\nBut for social media? If you ask me, it’s a nope.\n\n  And if you want to keep track of your style decisions, the Proofreading for Marketing guide has space to note your choices aaaand leads you through each proofing stage. Make it all easier for yourself!\n\n    More resources\n\n          Proofreading blog for copywriters and marketers | Lighthouse Proofreading\n\n      CopywritingLorraine Williams3 January 2020emdash, en dash, punctuation\n\n        Facebook0\n\n        Twitter\n\n        LinkedIn0\n\n        2 Likes",
    "summary": {
      "en": "**Summary: Difference Between En Dash and Em Dash**\n\n- **Hyphen (-)**: A small mark used to connect words (like in \"mother-in-law\") without spaces.\n\n- **En Dash (–)**: The width of an 'n', used to show ranges (e.g., \"7–10 pm\"). Do not use \"from\" or \"between\" with it.\n\n- **Em Dash (—)**: The width of an 'm', used for emphasis, asides, or breaks in speech (e.g., \"Book club—more like wine club—was fun\"). In UK English, it’s often replaced with spaced en dashes.\n\n**How to Type Them**:\n- **En Dash**: Type \"number space hyphen space number\" (e.g., \"1999 - 2001\") without spaces for ranges.\n- **Em Dash**: Type \"word hyphen hyphen word\" (e.g., \"word--word\").\n\n**Shortcuts**:\n- En Dash: Ctrl + Minus or Alt + 0150\n- Em Dash: Ctrl + Alt + Minus or Alt + 0151\n\n**Web Writing**: Use HTML codes for dashes:\n- En Dash: &ndash; or &#8211;\n- Em Dash: &mdash; or &#8212;\n\n**Usage Advice**:\n- Use proper punctuation in formal writing (e.g., white papers, marketing). \n- For social media, focus less on dashes and more on concise communication. \n\nOverall, knowing the difference between these punctuation marks helps improve clarity and flow in writing.",
      "ko": "하이픈(-)은 단어를 연결하는 데 사용되는 작은 기호로, 예를 들어 \"mother-in-law\"와 같이 공백 없이 사용됩니다. \n\n엔 대시(–)는 'n'의 너비로, 범위를 나타내는 데 사용됩니다. 예를 들어 \"7–10 pm\"처럼 사용하며, 이와 함께 \"from\"이나 \"between\"을 사용하지 않습니다. \n\n엠 대시(—)는 'm'의 너비로, 강조, 부가 설명, 또는 말의 중단을 나타내는 데 사용됩니다. 예를 들어 \"Book club—more like wine club—was fun\"과 같이 사용됩니다. 영국 영어에서는 종종 공백이 있는 엔 대시로 대체되기도 합니다. \n\n타이핑 방법은 다음과 같습니다. 엔 대시는 \"숫자 공백 하이픈 공백 숫자\" 형식으로 입력합니다. 예를 들어 \"1999 - 2001\"처럼 범위를 나타낼 때는 공백 없이 입력해야 합니다. 엠 대시는 \"단어 하이픈 하이픈 단어\" 형식으로 입력합니다. 예를 들어 \"word--word\"와 같이 입력합니다. \n\n단축키도 있습니다. 엔 대시는 Ctrl + Minus 또는 Alt + 0150으로 입력할 수 있고, 엠 대시는 Ctrl + Alt + Minus 또는 Alt + 0151로 입력할 수 있습니다. \n\n웹 작성 시에는 대시를 위한 HTML 코드를 사용할 수 있습니다. 엔 대시는 &ndash; 또는 &#8211;로, 엠 대시는 &mdash; 또는 &#8212;로 입력합니다. \n\n사용에 대한 조언으로는, 공식적인 글쓰기에서는 적절한 구두점을 사용하는 것이 중요합니다. 예를 들어 백서나 마케팅 자료에서는 구두점 사용에 신경 써야 합니다. 반면 소셜 미디어에서는 대시보다는 간결한 소통에 더 집중하는 것이 좋습니다. \n\n이러한 구두점의 차이를 아는 것은 글의 명확성과 흐름을 개선하는 데 도움이 됩니다.",
      "ja": "ハイフン（-）は、単語をつなげるために使う小さな記号で、スペースなしで使用します（例：「義理の母」）。エンダッシュ（–）は「n」の幅を持ち、範囲を示すために使われます（例：「午後7時から10時」）。この場合、「from」や「between」を使う必要はありません。エムダッシュ（—）は「m」の幅を持ち、強調や補足、会話の中での区切りに使われます（例：「読書クラブ—ワインクラブのようなもの—は楽しかった」）。イギリス英語では、エンダッシュをスペースを入れて使うことがよくあります。\n\nエンダッシュを入力するには、「数字 スペース ハイフン スペース 数字」と入力します（例：「1999 - 2001」）。範囲を示す場合はスペースを入れません。エムダッシュは、「単語 ハイフン ハイフン 単語」と入力します（例：「単語--単語」）です。\n\nショートカットキーもあります。エンダッシュは「Ctrl + マイナス」または「Alt + 0150」で、エムダッシュは「Ctrl + Alt + マイナス」または「Alt + 0151」で入力できます。\n\nウェブライティングでは、ダッシュのためにHTMLコードを使います。エンダッシュは「&ndash;」または「&#8211;」、エムダッシュは「&mdash;」または「&#8212;」です。\n\n正式な文書（例：ホワイトペーパーやマーケティング資料）では、適切な句読点を使用することが重要です。ソーシャルメディアでは、ダッシュにこだわらず、簡潔なコミュニケーションを重視しましょう。\n\nこれらの句読点の違いを理解することで、文章の明確さや流れを向上させることができます。"
    }
  },
  {
    "id": "0686fe42e20538e4",
    "title": {
      "en": "GhidraMCP: Now AI Can Reverse Malware [video]",
      "ko": "AI로 악성코드 역전!",
      "ja": "AIでマルウェア逆解析！"
    },
    "type": "story",
    "url": "https://www.youtube.com/watch?v=u2vQapLAW88",
    "score": 35,
    "by": "surprisetalk",
    "time": 1742931645,
    "content": "Back\n\n  KR\n\n    Skip navigation\n\n        Search\n\n  Search with your voice\n\n  KR\n\n{\"@context\":\"https://schema.org\",\"@type\":\"VideoObject\",\"description\":\"Just built an MCP for Ghidra.\\n\\nNow basically any LLM (Claude, Gemini, local...) can Reverse Engineer malware for you.  With the right prompting, it automates a *ton* of tedious tasks.\\n\\nOne-shot markups of entire binaries with just a click.\\n\\nOpen source, on Github now.\\n\\n--\\n\\nLink the tool:\\nhttps://github.com/LaurieWired/GhidraMCP/\\n\\n--\\n\\nTimestamps\\n\\n00:00 What is MCP?\\n02:22 LLM + Ghidra Demo (Claude)\\n05:02 Gemini Test\\n06:44 Backend Implementation\\n09:23 Connecting MCP Clients\\n11:02 Java Integration\\n12:45 Conclusion + Extensions\\n\\n---\\n\\nFollow LaurieWired on Social Media:\\n►https://linktr.ee/lauriewired\",\"duration\":\"PT842S\",\"embedUrl\":\"https://www.youtube.com/embed/u2vQapLAW88\",\"interactionCount\":\"51283\",\"name\":\"ghidraMCP: Now AI Can Reverse Malware\",\"thumbnailUrl\":[\"https://i.ytimg.com/vi/u2vQapLAW88/maxresdefault.jpg\"],\"uploadDate\":\"2025-03-25T10:13:26-07:00\",\"@id\":\"https://www.youtube.com/watch?v=u2vQapLAW88\",\"genre\":\"Science & Technology\",\"author\":\"LaurieWired\"}\n\nghidraMCP: Now AI Can Reverse MalwareSearchWatch laterShareCopy linkInfoShoppingTap to unmute2xIf playback doesn't begin shortly, try restarting your device.•Up nextLiveUpcomingCancelPlay NowYou're signed outVideos you watch may be added to the TV's watch history and influence TV recommendations. To avoid this, cancel and sign in to YouTube on your computer.CancelConfirmLaurieWiredSubscribeSubscribedHi!  I'm LaurieWired, and I reverse engineer malware, focusing on cross-platform and mobile analysis.Analyzing Deepseek's \"undefined\" NVIDIA PTX optimizations (with benchmarks!)13:46ShareInclude playlistAn error occurred while retrieving sharing information. Please try again later.0:000:00 / 14:01•Watch full videoLive•What is MCP?•Scroll for details\n\n      ghidraMCP: Now AI Can Reverse Malware\n\n    LaurieWired\n\n    LaurieWired\n\n166K subscribers\n      SubscribeSubscribed\n\n        12345678901234567890123456789.12345678901234567890123456789KShareDownload\n  Download\n\nSave\n\n  51,283 views  22 hours ago\n\n  51,283 views • Mar 25, 2025\n\n          Show less\n\n        Just built an MCP for Ghidra.\n\nNow basically any LLM (Claude, Gemini, local...) can Reverse Engineer malware for you.  With the right prompting, it aut…...more\n...more\n\n      Chapters\n\n  View all\n\n    What is MCP?\n    What is MCP?\n    0:00\n\n    What is MCP?\n\n  0:00\n\n    LLM + Ghidra Demo (Claude)\n    LLM + Ghidra Demo (Claude)\n    2:22\n\n    LLM + Ghidra Demo (Claude)\n\n  2:22\n\n    Gemini Test\n    Gemini Test\n    5:02\n\n    Gemini Test\n\n  5:02\n\n    Backend Implementation\n    Backend Implementation\n    6:44\n\n    Backend Implementation\n\n  6:44\n\n    Connecting MCP Clients\n    Connecting MCP Clients\n    9:23\n\n    Connecting MCP Clients\n\n  9:23\n\n    Java Integration\n    Java Integration\n    11:02\n\n    Java Integration\n\n  11:02\n\n    Conclusion + Extensions\n    Conclusion + Extensions\n    12:45\n\n    Conclusion + Extensions\n\n  12:45\n\n  Transcript\n\n  Follow along using the transcript.\n\n  Show transcript\n\n    LaurieWired\n\n      166K subscribers\n\n  Videos\n  About\n\n    VideosAboutTwitterReddit\n\n          Show less\n\n            ghidraMCP: Now AI Can Reverse Malware51,283 viewsMar 25, 202512345678901234567890123456789.12345678901234567890123456789KShareDownload\n  Download\n\nSave\n\n      Comments\n      310\n\n              Top comments\n\n              Newest first\n\n      In this video\n\nTimelineChaptersTranscript\n\n      Chapters\n\n    What is MCP?\n    What is MCP?\n    0:00\n\n    What is MCP?\n\n  0:00\n\n    LLM + Ghidra Demo (Claude)\n    LLM + Ghidra Demo (Claude)\n    2:22\n\n    LLM + Ghidra Demo (Claude)\n\n  2:22\n\n    Gemini Test\n    Gemini Test\n    5:02\n\n    Gemini Test\n\n  5:02\n\n    Backend Implementation\n    Backend Implementation\n    6:44\n\n    Backend Implementation\n\n  6:44\n\n    Connecting MCP Clients\n    Connecting MCP Clients\n    9:23\n\n    Connecting MCP Clients\n\n  9:23\n\n    Java Integration\n    Java Integration\n    11:02\n\n    Java Integration\n\n  11:02\n\n    Conclusion + Extensions\n    Conclusion + Extensions\n    12:45\n\n    Conclusion + Extensions\n\n  12:45\n\n    Sync to video time\n\n  Sync to video time\n\n      Description\n\n  ghidraMCP: Now AI Can Reverse Malware\n\n4.5KLikes51,283Views22hAgo\nJust built an MCP for Ghidra.\n\nNow basically any LLM (Claude, Gemini, local...) can Reverse Engineer malware for you.  With the right prompting, it automates a ton of tedious tasks.\n\nOne-shot markups of entire binaries with just a click.\n\nOpen source, on Github now.\n\n--\n\nLink the tool:\nhttps://github.com/LaurieWired/Ghidra...\n\n--\n\nTimestamps\n\n00:00 What is MCP?\n02:22 LLM + Ghidra Demo (Claude)\n05:02 Gemini Test\n06:44 Backend Implementation\n09:23 Connecting MCP Clients\n11:02 Java Integration\n12:45 Conclusion + Extensions\n\n---\n\nFollow LaurieWired on Social Media:\n►https://linktr.ee/lauriewired…...more\n...more\nShow less\n\n      Chapters\n\n  View all\n\n    What is MCP?\n    What is MCP?\n    0:00\n\n    What is MCP?\n\n  0:00\n\n    LLM + Ghidra Demo (Claude)\n    LLM + Ghidra Demo (Claude)\n    2:22\n\n    LLM + Ghidra Demo (Claude)\n\n  2:22\n\n    Gemini Test\n    Gemini Test\n    5:02\n\n    Gemini Test\n\n  5:02\n\n    Backend Implementation\n    Backend Implementation\n    6:44\n\n    Backend Implementation\n\n  6:44\n\n  Transcript\n\n  Follow along using the transcript.\n\n  Show transcript\n\n    LaurieWired\n\n      166K subscribers\n\n  Videos\n  About\n\n    VideosAboutTwitterReddit\n\n      Transcript\n\nNaN / NaN\n\n            Google won. (Gemini 2.5 Pro is INSANE)\n\n    Theo - t3․gg\n\n    Theo - t3․gg\n\n    •\n\n    •\n\n      79K views\n\n      8 hours ago\n\n          New",
    "summary": {
      "en": "The video titled \"ghidraMCP: Now AI Can Reverse Malware,\" created by LaurieWired, introduces a new tool called MCP for Ghidra. This tool allows any large language model (LLM), such as Claude or Gemini, to assist in reverse engineering malware. It automates many tedious tasks, enabling users to analyze entire binary files with just one click.\n\nThe video covers various topics, including:\n- An explanation of what MCP is.\n- A demonstration of the tool using the Claude LLM.\n- Testing with the Gemini model.\n- Details about the backend implementation and connecting clients.\n- Integration with Java.\n- A conclusion with potential extensions of the tool.\n\nThe MCP tool is open source and available on GitHub. \n\nFor more information, visit the GitHub link: [GhidraMCP on GitHub](https://github.com/LaurieWired/GhidraMCP/).",
      "ko": "\"ghidraMCP: 이제 AI가 악성코드를 역공학할 수 있다\"라는 제목의 영상은 LaurieWired가 제작한 것으로, Ghidra를 위한 새로운 도구인 MCP를 소개합니다. 이 도구는 Claude나 Gemini와 같은 대형 언어 모델(LLM)이 악성코드의 역공학을 도와줄 수 있도록 합니다. MCP는 많은 번거로운 작업을 자동화하여 사용자가 단 한 번의 클릭으로 전체 바이너리 파일을 분석할 수 있게 해줍니다.\n\n영상에서는 MCP가 무엇인지에 대한 설명과 함께 Claude LLM을 사용한 도구 시연, Gemini 모델을 활용한 테스트, 백엔드 구현 및 클라이언트 연결에 대한 세부사항, Java와의 통합, 그리고 도구의 잠재적 확장 가능성에 대한 결론이 포함되어 있습니다.\n\nMCP 도구는 오픈 소스이며 GitHub에서 사용할 수 있습니다. 추가 정보는 GitHub 링크를 방문해 주세요: [GhidraMCP on GitHub](https://github.com/LaurieWired/GhidraMCP/).",
      "ja": "「ghidraMCP: Now AI Can Reverse Malware」というタイトルの動画は、LaurieWiredによって制作され、新しいツールMCPをGhidraに導入しています。このツールは、ClaudeやGeminiのような大規模言語モデル（LLM）がマルウェアの逆解析を支援できるようにします。多くの面倒な作業を自動化し、ユーザーはバイナリファイル全体をワンクリックで分析できるようになります。\n\n動画では、MCPの説明や、Claude LLMを使用したツールのデモ、Geminiモデルでのテスト、バックエンドの実装やクライアントの接続に関する詳細、Javaとの統合、そしてツールの将来的な拡張についての結論が紹介されています。\n\nMCPツールはオープンソースで、GitHubで入手可能です。詳細については、GitHubのリンクを訪れてください。"
    }
  },
  {
    "id": "29803211a6f61815",
    "title": {
      "en": "German parliament votes as a Git contribution graph",
      "ko": "독일 의회, 기트 그래프로 투표!",
      "ja": "ドイツ議会の投票グラフ"
    },
    "type": "story",
    "url": "https://abstimmung.eu/git/2024",
    "score": 596,
    "by": "mxschll",
    "time": 1742858943,
    "content": "Abstimmungen 2024Namentliche Abstimmungen im BundestagJanFebMärAprMaiJunJulAugSepOktNovDezMoMiFrWenigerMehr17. Januar 2024Jahresbericht 2022 der Wehrbeauftragten (Entschließungsantrag)VerteidigungAußenpolitikUkraineBundeswehrMilitärDie Abstimmung betrifft den Entschließungsantrag der CDU/CSU-Fraktion zum Jahresbericht 2022 der Wehrbeauftragten, der die Bundesregierung auffordert, einsatzbereite TAURUS-Marschflugkörper an die Ukraine zu liefern und diese unverzüglich nachzubeschaffen.Ergebnisse des BundestagsJa: 178(27%)Nein: 485(73%)Enthaltung: 3(0%)17. Jan. 2024Gesamtstimmen: 66618. Januar 2024Entlastung der LandwirtschaftLandwirtschaftWirtschaftSteuerpolitikAgrarpolitikInnovationBürokratieDer Antrag der CDU/CSU-Fraktion betrifft die Unterstützung der Landwirtschaft und zielt darauf ab, die Wettbewerbsfähigkeit der Landwirtschaft zu erhalten und zu verbessern, anstatt sie durch politische Maßnahmen zu schwächen. Der Antrag fordert die Bundesregierung auf, Maßnahmen zu ergreifen, um die Landwirtschaft zu fördern und zu entlasten.Ergebnisse des BundestagsJa: 188(28%)Nein: 420(62%)Enthaltung: 69(10%)18. Jan. 2024Gesamtstimmen: 677Friedensinitiative für die Ukraine und Russland (Beschlussempfehlung)AußenpolitikSicherheitspolitikFriedenspolitikUkraineRusslandDie Abstimmung betrifft einen Antrag der AfD-Fraktion, der eine Friedensinitiative mit Sicherheitsgarantien für die Ukraine und Russland fordert, um Deutschlands Verantwortung für den Frieden in Europa gerecht zu werden.Ergebnisse des BundestagsJa: 605(89%)Nein: 75(11%)Enthaltung: 2(0%)18. Jan. 2024Gesamtstimmen: 68219. Januar 2024Modernisierung des Staatsangehörigkeitsrechts (GesEntw BReg)StaatsangehörigkeitIntegrationRechtGesellschaftMigrationDie Abstimmung betrifft die Modernisierung des Staatsangehörigkeitsrechts (StARModG), um den Zugang zur deutschen Staatsangehörigkeit zu erleichtern und die Integration von Ausländern zu fördern.Ergebnisse des BundestagsJa: 382(60%)Nein: 234(37%)Enthaltung: 23(3%)19. Jan. 2024Gesamtstimmen: 63901. Februar 2024Änderung des BundeswahlgesetzesWahlrechtInnenpolitikBevölkerungsentwicklungKommunalpolitikGesetzgebungDie Abstimmung betrifft die Änderung des Bundeswahlgesetzes, um die Wahlkreiseinteilung an die aktuelle Bevölkerungsentwicklung anzupassen und kommunale Gebietsänderungen zu berücksichtigen. Ziel ist es, sicherzustellen, dass die Wahl zum Deutschen Bundestag auf einer fairen und gleichmäßigen Grundlage stattfindet.Ergebnisse des BundestagsJa: 382(57%)Nein: 276(41%)Enthaltung: 12(2%)1. Feb. 2024Gesamtstimmen: 67022. Februar 2024Zehn Jahre russischer Krieg gegen die UkraineUkraineRusslandSicherheitspolitikAußenpolitikMilitärVölkerrechtDer Antrag betrifft die Unterstützung der Ukraine angesichts des russischen Krieges und zielt darauf ab, die deutsche und europäische Sicherheit zu stärken sowie die Verantwortlichen für Kriegsverbrechen zur Rechenschaft zu ziehen.Ergebnisse des BundestagsJa: 381(57%)Nein: 284(43%)Enthaltung: 2(0%)22. Feb. 2024Gesamtstimmen: 667Deutsche Außen- und Sicherheitspolitik (Antrag CDU/CSU)AußenpolitikSicherheitspolitikVerteidigungInternationale BeziehungenBevölkerungsschutzDer Antrag der CDU/CSU betrifft eine Neuausrichtung der deutschen Außen- und Sicherheitspolitik, um auf die veränderte Bedrohungslage durch Russland zu reagieren und Deutschlands Rolle in Europa und der Welt zu stärken. Er fordert eine \"echte Zeitenwende\" mit konkreten Maßnahmen zur Stärkung der Verteidigungsfähigkeit, des Bevölkerungsschutzes und der internationalen Zusammenarbeit.Ergebnisse des BundestagsJa: 182(27%)Nein: 479(72%)Enthaltung: 5(1%)22. Feb. 2024Gesamtstimmen: 66623. Februar 2024Wachstumschancengesetz;Kfz-Haftpflichtversicherung (BeschlEmpf Vermittlungsausschuss)WirtschaftSteuerrechtInvestitionInnovationFinanzenDie Beschlussempfehlung des Vermittlungsausschusses betrifft das Gesetz zur Stärkung von Wachstumschancen, Investitionen und Innovation sowie Steuervereinfachung und Steuerfairness (Wachstumschancengesetz). Sie zielt darauf ab, Änderungen an diesem Gesetz vorzunehmen, um Wachstum, Investitionen und Innovation zu fördern sowie das Steuersystem zu vereinfachen und fairer zu gestalten.Ergebnisse des BundestagsJa: 376(58%)Nein: 267(41%)Enthaltung: 1(1%)23. Feb. 2024Gesamtstimmen: 644Cannabisgesetz (GesEntwurf BReg)GesundheitDrogenpolitikJugendschutzJustizSicherheitDas Cannabisgesetz regelt den kontrollierten Umgang mit Cannabis und ändert weitere Vorschriften. Es zielt darauf ab, den Gesundheitsschutz zu verbessern, den illegalen Markt einzudämmen und den Kinder- und Jugendschutz zu stärken.Ergebnisse des BundestagsJa: 404(64%)Nein: 226(36%)Enthaltung: 4(0%)23. Feb. 2024Gesamtstimmen: 634Bundeswehreinsatz EUNAVFOR ASPIDES (BeschlEmpf)AußenpolitikSicherheitspolitikEuropäische UnionMilitärInternationaler HandelDie Abstimmung betrifft die Beteiligung bewaffneter deutscher Streitkräfte an der von der Europäischen Union geführten Operation EUNAVFOR ASPIDES, die zum Schutz der Schifffahrt im Roten Meer und angrenzenden Gebieten beitragen soll. Der Bundestag stimmt über den Antrag der Bundesregierung zur Entsendung von bis zu 700 Soldaten bis maximal zum 28. Februar 2025 ab.Ergebnisse des BundestagsJa: 538(94%)Nein: 31(5%)Enthaltung: 4(1%)23. Feb. 2024Gesamtstimmen: 57314. März 2024Ablehnung von Lieferung des Taurus-Marschflugkörpers (Beschlussempfehlung)AußenpolitikVerteidigungSicherheitspolitikUkraineMilitärDie Abstimmung betrifft den Antrag der CDU/CSU, die Bundesregierung aufzufordern, der Ukraine Taurus-Marschflugkörper aus Bundeswehrbeständen zu liefern, die Integration des Waffensystems in ukrainische Flugzeuge zu unterstützen, ukrainische Soldaten auszubilden, Hemmnisse bei der Weitergabe sensibler Informationen zu beseitigen, Ausrüstungslücken bei der Bundeswehr durch Nachbeschaffung zu schließen, die Produktionskapazitäten der Industrie zu erhöhen und weitere Taurus-Marschflugkörper zu beschaffen. Der Antrag wird abgelehnt.Ergebnisse des BundestagsJa: 494(72%)Nein: 188(27%)Enthaltung: 5(1%)14. März 2024Gesamtstimmen: 68720. März 2024Steuervergünstigung für Agrardiesel (Antrag AfD)LandwirtschaftSteuerpolitikSubventionenHaushaltspolitikAgrardieselDie Abstimmung betrifft den Antrag der AfD-Fraktion, die Steuervergünstigung für Agrardiesel beizubehalten, um die deutsche Landwirtschaft nicht zusätzlich zu belasten und die Lebensmittelpreise nicht künstlich zu verteuern. Der Antrag sieht vor, Kürzungen in anderen Bereichen des Haushalts vorzunehmen, falls Einsparungen notwendig sind, und die Bundesregierung aufzufordern, Beschlüsse der Parlamentsgremien zu respektieren.Ergebnisse des BundestagsJa: 553(90%)Nein: 64(10%)Enthaltung: 0(0%)20. März 2024Gesamtstimmen: 61721. März 2024Bundeswehreinsatz SEA GUARDIAN im Mittelmeer (Antrag BReg)SicherheitspolitikMilitärNATOMittelmeerTerrorismusbekämpfungInternationale BeziehungenDie Abstimmung betrifft die Fortsetzung der Beteiligung bewaffneter deutscher Streitkräfte an der NATO-geführten maritimen Sicherheitsoperation SEA GUARDIAN (MSO SG) im Mittelmeer, um zur Sicherheit und Stabilität in der Region beizutragen. Der Deutsche Bundestag stimmt über den Antrag der Bundesregierung zur Verlängerung dieses Einsatzes ab.Ergebnisse des BundestagsJa: 563(84%)Nein: 109(16%)Enthaltung: 2(0%)21. März 2024Gesamtstimmen: 674Bundeswehreinsatz in der Republik Südsudan (UNMISS)AußenpolitikSicherheitspolitikVerteidigungHumanitäre HilfeFriedensmissionUNDie Abstimmung betrifft die Fortsetzung der Beteiligung bewaffneter deutscher Streitkräfte an der UN-Friedensmission UNMISS (United Nations Mission in South Sudan) in der Republik Südsudan. Es geht darum, ob der Bundestag der von der Bundesregierung beschlossenen Verlängerung des Einsatzes zustimmt.Ergebnisse des BundestagsJa: 610(92%)Nein: 48(7%)Enthaltung: 2(1%)21. März 2024Gesamtstimmen: 66012. April 2024Selbstbestimmung in Bezug auf den GeschlechtseintragGesellschaftspolitikGleichstellungSelbstbestimmungTransgenderRechtDie Abstimmung betrifft den Entwurf eines Gesetzes über die Selbstbestimmung in Bezug auf den Geschlechtseintrag und zur Änderung weiterer Vorschriften. Das Gesetz zielt darauf ab, die Regelungen zur Änderung des Geschlechtseintrags zu vereinfachen und zu vereinheitlichen.Ergebnisse des BundestagsJa: 372(59%)Nein: 251(40%)Enthaltung: 11(1%)12. Apr. 2024Gesamtstimmen: 634Änderung des EnergiewirtschaftsgesetzesEnergiewirtschaftWasserstoffInfrastrukturNetzentwicklungFinanzierungDie Abstimmung betrifft ein Gesetz zur Änderung des Energiewirtschaftsgesetzes (EnWG), um den Aufbau einer nationalen Wasserstoffinfrastruktur zu fördern und die Finanzierung des Wasserstoff-Kernnetzes zu regeln.Ergebnisse des BundestagsJa: 347(61%)Nein: 202(36%)Enthaltung: 16(3%)12. Apr. 2024Gesamtstimmen: 56525. April 2024Operation EUNAVFOR MED IRINI (Beschlussempfehlung)AußenpolitikSicherheitspolitikEuropäische UnionMilitärLibyenDie Abstimmung betrifft die Fortsetzung der Beteiligung bewaffneter deutscher Streitkräfte an der Operation EUNAVFOR MED IRINI der Europäischen Union. Ziel ist es, das Waffenembargo gegen Libyen weiterhin durchzusetzen und zur Stabilisierung des Landes beizutragen.Ergebnisse des BundestagsJa: 554(84%)Nein: 100(15%)Enthaltung: 2(1%)25. Apr. 2024Gesamtstimmen: 65626. April 2024Erneuerbare-Energien-Gesetz (Solarpaket)Erneuerbare EnergienPhotovoltaikKlimaschutzEnergiewendeBürokratieabbauNetzausbauDas Gesetz zur Änderung des Erneuerbare-Energien-Gesetzes (EEG) zielt darauf ab, den Ausbau der Photovoltaik (PV) in Deutschland zu beschleunigen und zu steigern, um die Klimaziele zu erreichen. Es werden Anreize für Solaranlagen geschaffen und Bürokratie abgebaut.Ergebnisse des BundestagsJa: 384(58%)Nein: 79(12%)Enthaltung: 200(30%)26. Apr. 2024Gesamtstimmen: 66316. Mai 2024Ablehnung eines Antrags gegen den WHO-PandemievertragGesundheitspolitikInternationale BeziehungenSouveränitätWHOPandemieDemokratieDie Abstimmung betrifft den Antrag der AfD-Fraktion, den WHO-Pandemievertrag und die überarbeiteten Internationalen Gesundheitsvorschriften abzulehnen. Der Antrag zielt darauf ab, die Souveränität Deutschlands in Gesundheitsfragen zu wahren und eine vermeintliche Machtausweitung der WHO zu verhindern.Ergebnisse des BundestagsJa: 578(89%)Nein: 71(11%)Enthaltung: 1(0%)16. Mai 2024Gesamtstimmen: 65005. Juni 2024Ablehnung eines Antrags zur Abschaffung des SolidaritätszuschlagsSteuerpolitikFinanzenWirtschaftSolidaritätszuschlagAbgabenlastSteuerreformDie Abstimmung betrifft den Antrag der AfD-Fraktion zur Abschaffung des Solidaritätszuschlags als ersten Schritt einer umfassenden Steuerreform zur Entlastung von Mittelstand, Unternehmen und Arbeitnehmern. Der Finanzausschuss empfiehlt die Ablehnung des Antrags.Ergebnisse des BundestagsJa: 537(90%)Nein: 62(10%)Enthaltung: 0(0%)5. Juni 2024Gesamtstimmen: 59906. Juni 2024Ablehnung eines Antrags zur Bekämpfung des politischen IslamInneres und HeimatPolitischer IslamDemokratieRechtSicherheitMigrationDie Abstimmung betrifft den Antrag der CDU/CSU-Fraktion, den politischen Islam als Gefahr für die freiheitliche Demokratie wirksam zu bekämpfen. Der Ausschuss für Inneres und Heimat empfiehlt die Ablehnung des Antrags.Ergebnisse des BundestagsJa: 406(63%)Nein: 241(37%)Enthaltung: 1(0%)6. Juni 2024Gesamtstimmen: 648Beschleunigung immissionsschutzrechtlicher GenehmigungsverfahrenUmweltKlimaschutzEnergieWirtschaftGenehmigungsverfahrenErneuerbare EnergienDie Abstimmung betrifft ein Gesetz zur Verbesserung des Klimaschutzes, zur Beschleunigung von Genehmigungsverfahren im Immissionsschutz und zur Umsetzung von EU-Recht, mit dem Ziel, Verfahren zu vereinfachen und den Ausbau erneuerbarer Energien zu fördern.Ergebnisse des BundestagsJa: 377(59%)Nein: 257(40%)Enthaltung: 9(1%)6. Juni 2024Gesamtstimmen: 64313. Juni 2024Antrag zu Konsequenzen aus dem Terror von MannheimInnere SicherheitMigrationIntegrationTerrorismusbekämpfungRechtspolitikDer Antrag der CDU/CSU-Fraktion betrifft die Forderung nach klaren Konsequenzen aus dem Terroranschlag von Mannheim und zielt darauf ab, die Migrations- und Integrationspolitik zu verschärfen sowie die Sicherheitsmaßnahmen zu erhöhen.Ergebnisse des BundestagsJa: 253(38%)Nein: 399(60%)Enthaltung: 11(2%)13. Juni 2024Gesamtstimmen: 663Ablehnung eines Antrags zum Verbot des Vereins Muslim InteraktivInneres und HeimatVereinsrechtExtremismusIslamismusSicherheitspolitikDie Abstimmung betrifft den Antrag der AfD-Fraktion, den Verein Muslim Interaktiv zu verbieten, da dieser als extremistisch und gegen die freiheitliche demokratische Grundordnung gerichtet angesehen wird. Der Bundestag lehnt den Antrag ab.Ergebnisse des BundestagsJa: 577(88%)Nein: 68(10%)Enthaltung: 11(2%)13. Juni 2024Gesamtstimmen: 656Antrag zum Eintritt in die zweite Beratung zur Aufhebung des LieferkettengesetzesWirtschaftRechtSozialesEuropäische UnionDie Abstimmung betrifft einen Antrag der CDU/CSU-Fraktion, direkt in die zweite Beratung eines Gesetzentwurfs zur Aufhebung des Lieferkettensorgfaltspflichtengesetzes (LkSG) einzutreten.Ergebnisse des BundestagsJa: 250(38%)Nein: 401(62%)Enthaltung: 1(0%)13. Juni 2024Gesamtstimmen: 65227. Juni 2024Bundeswehreinsatz EUFOR ALTHEAAußenpolitikSicherheitspolitikEuropäische UnionBundeswehrBosnien und HerzegowinaDie Abstimmung betrifft die Fortsetzung der Beteiligung bewaffneter deutscher Streitkräfte an der EU-geführten Sicherheitsoperation EUFOR ALTHEA in Bosnien und Herzegowina bis zum 30. Juni 2025.Ergebnisse des BundestagsJa: 553(87%)Nein: 74(12%)Enthaltung: 8(1%)27. Juni 2024Gesamtstimmen: 635Bundeswehreinsatz im Kosovo (KFOR)AußenpolitikSicherheitspolitikVerteidigungKosovoBundeswehrInternationale BeziehungenDie Abstimmung betrifft die Fortsetzung der Beteiligung bewaffneter deutscher Streitkräfte an der internationalen Sicherheitspräsenz im Kosovo (KFOR). Es geht darum, das Mandat für den Einsatz der Bundeswehr im Rahmen von KFOR zu verlängern.Ergebnisse des BundestagsJa: 535(85%)Nein: 91(14%)Enthaltung: 2(1%)27. Juni 2024Gesamtstimmen: 628Bundeswehreinsatz im Libanon (UNIFIL)AußenpolitikSicherheitspolitikBundeswehrLibanonUNIFILFriedensmissionDie Abstimmung betrifft die Fortsetzung der Beteiligung bewaffneter deutscher Streitkräfte an der \"United Nations Interim Force in Lebanon\" (UNIFIL), einer Friedensmission der Vereinten Nationen im Libanon. Es geht um die Verlängerung des Mandats und die damit verbundenen Aufgaben und Befugnisse der deutschen Soldaten.Ergebnisse des BundestagsJa: 534(85%)Nein: 88(14%)Enthaltung: 3(1%)27. Juni 2024Gesamtstimmen: 62505. Juli 2024Änderung des SchwangerschaftskonfliktgesetzesSozialesFamilieFrauenrechteGesundheitRechtDie Abstimmung betrifft die Änderung des Schwangerschaftskonfliktgesetzes (SchKG) und zielt darauf ab, einen bundeseinheitlichen und rechtssicheren Umgang mit sogenannten Gehsteigbelästigungen vor Schwangerschaftsberatungsstellen und Einrichtungen zur Vornahme von Schwangerschaftsabbrüchen sicherzustellen.Ergebnisse des BundestagsJa: 381(69%)Nein: 169(31%)Enthaltung: 0(0%)5. Juli 2024Gesamtstimmen: 55017. Oktober 2024Entwurf zur Aufhebung des LieferkettengesetzesWirtschaftMenschenrechteUmweltLieferkettenGesetzgebungEuropäische UnionDie Abstimmung betrifft den Gesetzentwurf der CDU/CSU zur Aufhebung des Lieferkettensorgfaltspflichtengesetzes (LkSG), das Unternehmen zur Einhaltung von Menschenrechten in ihren Lieferketten verpflichtet.Ergebnisse des BundestagsJa: 247(37%)Nein: 412(62%)Enthaltung: 1(1%)17. Okt. 2024Gesamtstimmen: 660Gesetzentwurf zur KrankenhausreformGesundheitKrankenhausVersorgungFinanzierungQualitätssicherungDie Abstimmung betrifft den Entwurf eines Gesetzes zur Verbesserung der Versorgungsqualität im Krankenhaus und zur Reform der Vergütungsstrukturen (KHVVG), das darauf abzielt, die Krankenhausversorgung zu verbessern und die Finanzierung zu reformieren.Ergebnisse des BundestagsJa: 373(57%)Nein: 285(43%)Enthaltung: 1(0%)17. Okt. 2024Gesamtstimmen: 659Bundeswehreinsatz im IrakAußenpolitikSicherheitspolitikMilitärIrakTerrorismusbekämpfungDie Abstimmung betrifft die Fortsetzung des Einsatzes bewaffneter deutscher Streitkräfte im Irak, um die Stabilisierung des Landes zu sichern, ein Wiedererstarken des IS (Islamischer Staat) zu verhindern und die Versöhnung im Irak zu fördern. Der Bundestag stimmt über den Antrag der Bundesregierung ab, diesen Einsatz bis zum 31. Januar 2026 mit bis zu 500 Soldatinnen und Soldaten zu verlängern.Ergebnisse des BundestagsJa: 539(85%)Nein: 93(15%)Enthaltung: 2(0%)17. Okt. 2024Gesamtstimmen: 63418. Oktober 2024Änderungsantrag zur „Verbesserung der inneren Sicherheit“Innere SicherheitAsylrechtMigrationspolitikGrenzschutzTerrorismusbekämpfungWaffenrechtDie Abstimmung betrifft einen Änderungsantrag der CDU/CSU-Fraktion zu einem Gesetzentwurf, der die innere Sicherheit und das Asylsystem verbessern soll, insbesondere durch Änderungen im Asylgesetz und im Ausweisungsrecht.Ergebnisse des BundestagsJa: 254(39%)Nein: 404(61%)Enthaltung: 1(0%)18. Okt. 2024Gesamtstimmen: 659Artikel 5 des Entwurfs „Verbesserung der inneren Sicherheit“ (2. Beratung)InneresSicherheitWaffenrechtExtremismusTerrorismusÖffentliche SicherheitDie Abstimmung betrifft Artikel 5 eines Gesetzentwurfs, der darauf abzielt, das Waffenrecht zu verschärfen, um Extremisten und Terroristen den Zugang zu Waffen zu erschweren und die öffentliche Sicherheit zu erhöhen.Ergebnisse des BundestagsJa: 375(57%)Nein: 275(42%)Enthaltung: 4(1%)18. Okt. 2024Gesamtstimmen: 654Gesetzentwurf „Verbesserung der Terrorismusbekämpfung“Innere SicherheitTerrorismusbekämpfungExtremismuspräventionDatenschutzBürgerrechteWaffenrechtDer Gesetzentwurf zur Verbesserung der Terrorismusbekämpfung zielt darauf ab, den Sicherheitsbehörden im digitalen Raum zusätzliche Befugnisse zu geben und die Zusammenarbeit zwischen Bund, Ländern und zivilgesellschaftlichen Akteuren zu stärken, um extremistischen und islamistischen Tendenzen entgegenzuwirken.Ergebnisse des BundestagsJa: 367(56%)Nein: 280(43%)Enthaltung: 4(1%)18. Okt. 2024Gesamtstimmen: 651Gesetzentwurf „Verbesserung der inneren Sicherheit“Innere SicherheitAsylrechtWaffenrechtExtremismusTerrorismusbekämpfungDer Gesetzentwurf zur Verbesserung der inneren Sicherheit und des Asylsystems betrifft die Anpassung von Gesetzen, um die innere Sicherheit Deutschlands zu stärken und das Asylsystem effektiver zu gestalten. Er reagiert auf aktuelle Bedrohungen und soll den Behörden mehr Handlungsspielraum geben.Ergebnisse des BundestagsJa: 357(55%)Nein: 289(44%)Enthaltung: 8(1%)18. Okt. 2024Gesamtstimmen: 654Erster Entschließungsantrag zur „Verbesserung der inneren Sicherheit“Innere SicherheitAsylpolitikMigrationspolitikWaffenrechtIslamismusExtremismusbekämpfungDie Abstimmung betrifft den Entschließungsantrag der CDU/CSU zum Gesetzentwurf zur Verbesserung der inneren Sicherheit und des Asylsystems, der sich mit der Migrationspolitik, dem Waffenrecht und der Bekämpfung des Islamismus auseinandersetzt.Ergebnisse des BundestagsJa: 237(36%)Nein: 405(62%)Enthaltung: 8(2%)18. Okt. 2024Gesamtstimmen: 650Zweiter Entschließungsantrag zur „Verbesserung der inneren Sicherheit“Innere SicherheitAsylpolitikWaffenrechtMigrationspolitikExtremismuspräventionDie Abstimmung betrifft einen Entschließungsantrag der CDU/CSU zum Gesetzentwurf zur Verbesserung der inneren Sicherheit und des Asylsystems, der sich gegen die Schwerpunkte der Regierungsfraktionen im Bereich Waffenrecht richtet und stattdessen eine andere Migrations- und Sicherheitspolitik fordert.Ergebnisse des BundestagsJa: 185(29%)Nein: 373(59%)Enthaltung: 73(12%)18. Okt. 2024Gesamtstimmen: 631Dritter Entschließungsantrag zur „Verbesserung der inneren Sicherheit“Innere SicherheitAsylrechtMigrationGrenzschutzEU-RechtDie Abstimmung betrifft einen Entschließungsantrag der CDU/CSU-Fraktion zu einem Gesetzentwurf, der die innere Sicherheit und das Asylsystem verbessern soll. Der Antrag zielt darauf ab, die Bundesregierung zu umfassenden Zurückweisungen von Personen ohne Einreiserecht an den deutschen Grenzen aufzufordern.Ergebnisse des BundestagsJa: 249(39%)Nein: 394(61%)Enthaltung: 1(0%)18. Okt. 2024Gesamtstimmen: 644Ablehnung eines Antrags zu MesserangriffenInneresRechtKriminalitätWaffenrechtMigrationSicherheitDie Beschlussempfehlung des Ausschusses für Inneres und Heimat betrifft die Ablehnung eines Antrags der AfD-Fraktion, der eine gezielte Sanktionierung von Messerangriffen anstelle von Verschärfungen im Waffenrecht fordert.Ergebnisse des BundestagsJa: 567(89%)Nein: 62(10%)Enthaltung: 7(1%)18. Okt. 2024Gesamtstimmen: 636Ablehnung eines Antrags zu DrittstaatenangehörigenAsylrechtMigrationspolitikGrenzkontrolleRücknahmeabkommenDie Abstimmung betrifft den Antrag der AfD-Fraktion, die Bundesregierung zu verpflichten, Drittstaatsangehörige an den Außengrenzen Deutschlands zurückzuweisen und bilaterale Rücknahmeabkommen mit Nachbarstaaten anzuwenden.Ergebnisse des BundestagsJa: 572(89%)Nein: 62(10%)Enthaltung: 8(1%)18. Okt. 2024Gesamtstimmen: 64216. Dezember 2024Antrag gemäß Artikel 68 des Grundgesetzes (Vertrauensfrage)PolitikRegierungGrundgesetzVertrauensfrageDie Abstimmung betrifft die Vertrauensfrage gemäß Artikel 68 des Grundgesetzes, bei der der Bundeskanzler das Vertrauen des Bundestages ausspricht. Der Bundeskanzler beabsichtigt, vor der Abstimmung eine Erklärung abzugeben.Ergebnisse des BundestagsJa: 207(29%)Nein: 394(55%)Enthaltung: 116(16%)16. Dez. 2024Gesamtstimmen: 71719. Dezember 2024Gesetzentwurf zur Änderung von Artikel 93 und 94 des Grundgesetzes (Bundesverfassungsgericht)VerfassungsrechtBundesverfassungsgerichtRechtsstaatPolitikJustizDer Gesetzentwurf betrifft die Änderung des Grundgesetzes in Bezug auf die Stellung und Struktur des Bundesverfassungsgerichts, indem Artikel 93 und 94 punktuell ergänzt und deren Inhalte systematisch neu geordnet werden. Ziel ist es, die Organqualität des Bundesverfassungsgerichts sowie die unmittelbare Bindung der öffentlichen Gewalt an seine Entscheidungen stärker hervorzuheben.Ergebnisse des BundestagsJa: 600(90%)Nein: 69(10%)Enthaltung: 0(0%)19. Dez. 2024Gesamtstimmen: 669",
    "summary": {
      "en": "In 2024, several key votes took place in the Bundestag (German Parliament) on various issues:\n\n1. **Military Support for Ukraine**: A proposal to supply TAURUS missiles to Ukraine was rejected with 73% opposing.\n2. **Agricultural Support**: Another proposal aimed at supporting the agricultural sector was also rejected, with 62% against it.\n3. **Peace Initiative**: A peace initiative for Ukraine and Russia was approved, with 89% in favor.\n4. **Citizenship Law Modernization**: A law to simplify access to German citizenship passed with 60% approval.\n5. **Election Law Change**: Adjustments to the electoral law based on population changes were approved with 57% support.\n6. **Support for Ukraine Amid War**: A proposal to strengthen support for Ukraine was approved with 57% backing.\n7. **Defense Policy Changes**: A CDU/CSU proposal for a shift in defense policy was rejected with 72% against.\n8. **Cannabis Regulation**: A law to regulate cannabis use was passed with 64% support.\n9. **Military Operations**: Several votes approved German military participation in EU and UN missions, including in the Mediterranean and South Sudan.\n10. **Gender Entry Self-Determination**: A law simplifying rules for changing gender entries was approved with 59% support.\n11. **Renewable Energy Expansion**: A law to promote solar energy was passed with 58% approval.\n12. **Health and Security Laws**: Votes included changes to health laws and security measures, with varying levels of support and rejection.\n13. **Internal Security Proposals**: Multiple proposals related to internal security and immigration were debated, with several rejected.\n\nOverall, the Bundestag engaged in significant discussions around defense, agriculture, health, and internal security, reflecting current political and social issues in Germany.",
      "ko": "2024년 독일 의회인 분데스탁에서는 여러 중요한 투표가 진행되었습니다. \n\n첫 번째로, 우크라이나에 TAURUS 미사일을 지원하자는 제안은 73%의 반대 의견으로 부결되었습니다. 농업 부문 지원을 위한 또 다른 제안도 62%의 반대에 부딪혀 거부되었습니다. 반면, 우크라이나와 러시아를 위한 평화 이니셔티브는 89%의 찬성으로 통과되었습니다. 독일 시민권 접근을 간소화하는 법안은 60%의 지지를 얻어 통과했습니다. 인구 변화에 따른 선거법 조정도 57%의 찬성으로 승인되었습니다. 전쟁 중 우크라이나에 대한 지원을 강화하자는 제안은 57%의 지지를 받아 통과했습니다. \n\nCDU/CSU의 국방 정책 변화 제안은 72%의 반대에 의해 거부되었습니다. 대마초 사용을 규제하는 법안은 64%의 지지를 얻어 통과했습니다. 독일 군대의 EU 및 유엔 임무 참여에 대한 여러 투표가 승인되었으며, 지중해와 남수단에서의 작전도 포함되었습니다. 성별 변경 규정을 간소화하는 법안은 59%의 찬성으로 통과했습니다. 태양광 에너지를 촉진하는 법안도 58%의 지지를 받아 통과되었습니다. 건강 법률 및 보안 조치에 대한 투표도 있었으며, 지지와 반대가 엇갈렸습니다. \n\n내부 보안 및 이민과 관련된 여러 제안이 논의되었고, 그 중 일부는 거부되었습니다. 전반적으로 분데스탁은 국방, 농업, 건강, 내부 보안과 관련된 중요한 논의를 진행하며 독일의 현재 정치 및 사회 문제를 반영했습니다.",
      "ja": "2024年、ドイツの国会であるブンデスタグでは、さまざまな重要な投票が行われました。\n\nウクライナへの軍事支援に関する提案として、TAURUSミサイルを供給する案が73%の反対で却下されました。また、農業セクターを支援するための別の提案も62%の反対で否決されました。一方、ウクライナとロシアのための平和イニシアティブは89%の賛成を得て承認されました。\n\nドイツ国籍へのアクセスを簡素化する法律は60%の賛成で通過しました。人口変動に基づく選挙法の変更も57%の支持を受けて承認されました。戦争の最中にウクライナへの支援を強化する提案も57%の賛成で可決されました。\n\n防衛政策の変更を求めるCDU/CSUの提案は72%の反対で却下されました。大麻使用を規制する法律は64%の支持を得て成立しました。また、ドイツ軍のEUや国連のミッションへの参加に関するいくつかの投票も行われ、地中海や南スーダンでの活動が承認されました。\n\n性別の変更手続きを簡素化する法律は59%の支持で可決され、再生可能エネルギーを促進するための太陽光発電に関する法律も58%の賛成で通過しました。健康法や安全対策に関する投票も行われ、支持と反対の意見が分かれました。内部安全や移民に関連する複数の提案も議論されましたが、いくつかは却下されました。\n\n全体として、ブンデスタグでは防衛、農業、健康、内部安全に関する重要な議論が行われ、ドイツの現在の政治的および社会的な問題を反映しています。"
    }
  },
  {
    "id": "5c0419a56e096f9f",
    "title": {
      "en": "Abel Prize Awarded to Japanese Mathematician Who Abstracted Abstractions",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://www.nytimes.com/2025/03/26/science/abel-prize-math-masaki-kashiwara.html",
    "score": 4,
    "by": "donohoe",
    "time": 1742992404,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "1aea2b8ff2ff8449",
    "title": {
      "en": "You should know this before choosing Next.js",
      "ko": "Next.js 선택 전 필수 체크!",
      "ja": "Next.js選びの前に"
    },
    "type": "story",
    "url": "https://eduardoboucas.com/posts/2025-03-25-you-should-know-this-before-choosing-nextjs/",
    "score": 195,
    "by": "tobr",
    "time": 1742990928,
    "content": "You should know this before choosing Next.js\n\n        You should know this\n\n        before choosing Next.js\n\n            March 25th, 2025\n\n          Picking the technology stack for a project is an important and consequential decision. In the enterprise space in particular, it often involves a multi-year commitment with long-lasting implications on the roadmap of the project, the pace of its development, the quality of the deliverables, and even the ability to assemble and maintain a happy team.\nThe open-source software model is a fundamental answer to this. By using software that is developed in the open, anyone is free to extend it or modify it in whatever way fits their use case. More crucially, the portability of open-source software gives developers and organisations the freedom to move their infrastructure between different providers without fear of getting locked in to a specific vendor.\nThis is the expectation with Next.js, an open-source web development framework created and governed by Vercel, a cloud provider that offers managed hosting of Next.js as a service.\nThere is nothing wrong with a company profiting from an open-source software it created, especially when that helps fund the development of the project. In fact, there are plenty of examples of that model working successfully in our industry.\nBut I think that can only work sustainably if the boundaries between the company and the open-source project are abundantly clear, with well-defined expectations between the maintainers, the hosting providers and the users about how and where each feature of the framework can be used.\nI want to explain why I don't think this transparency exists today.\nMy goal is not to stop anyone from using Next.js, but to lay out as much information as possible so developers and businesses can make an informed decision about their technology stack.\n¶ Declaration of interest\nLet me lead with a declaration of interest:\n\nI work at Netlify and have done so for over four years\nNetlify is a frontend cloud platform that supports Next.js and other web frameworks as part of its product offering\nNetlify and Vercel are direct competitors\n\nIt's important for me to establish this for a few reasons.\nMy job involves building the infrastructure and tooling needed to support the full feature set of Next.js on Netlify, which has exposed me to the internals of the framework in a way that most people won't see. Over the years, I have seen concerning patterns of tight coupling between the open-source framework and the infrastructure of the company that builds it.\nMy employment is also the reason why I have always been very wary of voicing these concerns in public. As a Netlify employee, I don't really get to voice an objective concern about Next.js without people dismissing my claims as Netlify unleashing one of its minions to spread FUD about a competitor.\nI'm not keen on exposing myself and the company to that type of debate, so I have always chosen to work behind the scenes in supporting the developers who decide to deploy their sites on Netlify and shield them from all the complexity that goes into making that possible.\nBut then something happened.\nLast weekend, Vercel disclosed a critical security vulnerability with Next.js. This type of issue is normal, but the way Vercel chose to handle it was so poor, reckless and disrespectful to the community that it has exacerbated my concerns about the governance of the project.\nFor me, things change once your decisions put other people at risk, so I felt the urge to speak up.\n¶ Openness and governance\nI'll come back to this incident later, but before that I want to back up a little and give you a peek behind the curtain. My history of reservations about the openness and governance of Next.js stem from a series of decisions made by Vercel over the years that make it incredibly challenging for other providers to support the full feature set of the framework.\nI'll cover these by laying out a series of facts about how Next.js is built. I'll then add some of my own considerations about how those facts live up to the expectations of an open, interoperable, enterprise-grade software product.\n¶ Fact #1: No adapters\nMost modern web development frameworks use the concept of adapters to configure the output of the framework to a specific deployment target: Remix, Astro, Nuxt, SvelteKit and Gatsby are just a few examples. This pattern allows developers to keep the core of their applications untouched, and simply swap the adapter if they decide to start deploying to a different provider.\nThese adapters can be maintained by framework authors, by the hosting providers, by the community, or all of the above. Frameworks are typically structured in such a way that it’s possible for anyone to build their own adapter in case one isn’t available for the provider of their choice.\nNext.js does not have the concept of adapters and they have stated in the past that they would not support them. The output of a Next.js build has a proprietary and undocumented format that is used in Vercel deployments to provision the infrastructure needed to power the application.\nVercel's alternative to this was the Build Output API, a documented specification for the output format of frameworks who wish to deploy to Vercel.\nThis is not an adapter interface for Next.js, and in fact has nothing to do with Next.js. The announcement blog post said that Next.js supports this format, but as of today that isn’t true.\nIn November 2023, the Next.js documentation has been updated to say that Next.js would adopt the Build Output API in the following major version of the framework (which would be version 15):\n\nNext.js produces a standard deployment output used by managed and self-hosted Next.js. This ensures all features are supported across both methods of deployment. In the next major version, we will be transforming this output into our Build Output API specification.\n\nNext.js 15.0.0 was released in October 2024 without support for the Build Output API\nVercel have built the Build Output API because they wanted their customers to leverage the rich ecosystem of frameworks in the space, but their own framework doesn't support it to this day.\nThis means that any hosting providers other than Vercel must build on top of undocumented APIs that can introduce unannounced breaking changes in minor or patch releases. (And they have.)\nLate last year, Cloudflare and Netlify have joined OpenNext, a movement of different cloud providers that collaborate on open-source adapters for Next.js. Shortly after, Vercel have engaged with the movement and committed to building support for adapters. They haven't made any timeline commitments, but have recently said they are actively working on it.\nIt's important to remember that it's been almost three years since the launch of the Build Output API, and to this day the framework still isn't portable. I'm cautiously optimistic about that actually changing this time.\n¶ Fact #2: No official serverless support\nThe official methods for self-hosting Next.js require running the application in a stateful way, as long-running servers. While technically possible, this is very hard to operate in any real-world production environment where a single instance isn’t sufficient.\nThe setup needs to be able to dynamically scale up very quickly in order to handle sudden bursts of traffic, while at the same time being able to scale down to zero in order to be cost-effective. This last part is essential when working with server components, for example, where the deep tangling between client and server code can break older clients unless every version of the server code ever deployed is available indefinitely.\nOne obvious answer to these requirements is serverless computing, as attested by official Next.js documentation that confirms the benefits of this model:\n\nServerless allows for distributed points of failure, infinite scalability, and is incredibly affordable with a \"pay for what you use\" model.\n\nThis clearly advantageous computing paradigm is precisely how Vercel has run Next.js sites in their own infrastructure for years. Given that Next.js is an open framework, it is reasonable to expect that you'd be able to use that same model in any serverless provider of your choice. But it's not that simple.\nNext.js once had a serverless mode that you could enable with a configuration property, but it was removed without further explanation in October 2022. No equivalent mode was ever introduced.\nThe official React documentation, which is the Next.js team help maintain, says that Next.js can be deployed to any serverless hosting, but there is no official documentation whatsoever for this.\nThis means that any providers who want to offer support for Next.js with the same computing model that the framework itself promotes must reverse-engineer their way to a custom implementation.\n¶ Fact #3: Vercel-specific code paths\nNext.js has code paths that are only ever executed for sites deployed to Vercel. An example of this is a private flag called minimal mode, which allows Vercel to shift work away from the framework and run it on their edge infrastructure.\nHere's an example of why that matters. Next 12 introduced middleware, a way to address use cases such as feature flags, A/B tests and advanced routing. What's common in all of these use cases is the need to run logic on the hot path, behind the cache, with very low latency.\nThe announcement included this:\n\nThis works out of the box using next start, as well as on Edge platforms like Vercel, which use Edge Middleware.\n\nIn practice, this means that you have two options: use next start and run middleware alongside the rest of your application in your origin server (which is typically running in a single region, after the cache), or use one of the «Edge platforms like Vercel» to run middleware at the edge, before the cache, unlocking all the incredible use cases that Vercel boasted in the resources linked in the announcement.\nThe phrase «Edge platforms like Vercel» surely means that there are many alternatives out there because other providers were given the option to also implement middleware at the edge, right? No.\nThis secret minimal mode is what allowed Vercel to break out middleware from the rest of the application so they could run it at the edge, but only Vercel has access to it.\nNetlify does support running middleware at the edge, but we've done it at the expense of having a full team of engineers dedicated to reverse-engineering the framework and building our own edge middleware implementation on top of undocumented APIs. This type of commitment is just impossible for smaller companies that simply do not have the resources to fight this battle, which makes most of them stop trying.\nAs far as I know, Netlify is the only cloud provider to support the full feature set of Next.js outside of Vercel, which doesn't make sense to me. With Next.js having such a sizeable share of the market, I would expect a lot more hosting options, which would foster competition and innovation across the board, ultimately benefitting users and the web.\nSo why is there a hidden door in Next.js for which only Vercel holds the key? I think it's expected that the framework maintainers regularly experiment with features before they're launched, but minimal mode isn't that. We're talking about entirely different operation mode for the framework, which has been in the code base for many years and which unlocks capabilities that are reserved for the for-profit company that owns the framework.\nIf WordPress had a privileged code path that was only accessible to sites deployed to Automattic properties, would it be trusted as a truly open project and would it have the dominance it has today?\n¶ Security posture\nLet's go back to the security incident. On Friday, March 21st at 10:17 AM (UTC), Vercel published a CVE for a critical security incident, ranked with a severity of 9.1 out of 10.\nIn essence, it was possible for anyone to completely bypass Next.js middleware by sending a specific header in the request. This is important because authorisation was one of the flagship use cases of middleware, and this exploit meant that anyone could bypass the authentication layer and gain access to protected resources.\nAs the incident unravelled, a few things became apparent. First of all, the vulnerability was reported to the Next.js team on February 27th, but it wasn't until March 14th that the team started looking into it. Once they did, they started pushing fixes for Next 14 and Next 15 within a couple of hours.\nSo by March 14th (at the latest), Vercel knew they had a serious incident on their hands. The responsible thing to do at that point would be immediately disclosing the vulnerability to other providers, so that they could assess the impact to their own customers and take any necessary actions to protect them as quickly as possible. At times like these, our duty to protect users should rise above any competition between companies.\nThat is not what happened. It took Vercel 8 (eight) days to reach out to Netlify. In that time, they managed to push patches to Next.js, cut two releases, and even write a blog post that framed the incident as something that Vercel's firewall had «proactively protected» their customers from (even though their CTO later said that their firewall had nothing to do with it).\nI think it's incredibly disingenuous to spin a critical security vulnerability in your open-source project as a strength of your product, with absolutely no consideration for whether users in other providers were also affected and what they should do to mitigate. In fact, they wouldn't even know this, because they hadn't even reached out to us at this point.\nAfter being called out on social media, Vercel have rewritten the blog post to remove any mention of their firewall and clarify which providers had been affected whether their customers had to take any action.\n\nVercel has then released a postmortem where they said — for the first time — that on March 21st they were able to «verify Netlify and Cloudflare Workers were not impacted». This is directly contradicted by their staff reaching out to Netlify on March 22nd offering help to «get a patch up». If we were not impacted, what was there to patch?\nThis lack of consideration for any users outside of Vercel has created unnecessary anxiety and confusion for a lot of people, leaving some providers scrambling to find a solution and then having to partially roll it back, others announcing that they were not vulnerable when in reality they were, etc.\nAs you read this, it's impossible for anyone to know how many sites out there are still vulnerable to this exploit, many of which would've been safe if things were handled differently.\nAnd at the height of all this mess, Vercel's leadership had... a different focus.\n¶ But Vercel owns Next.js\nThey do. And they have every right to make a business out of the framework that they've put so much work, talent, time and energy into building and growing. I'm not disputing that.\nBut that growth holds them to a high bar of standards that, in my opinion, they have repeatedly failed to meet.\n«If Vercel own Next.js, what incentive do they have to open it up to other providers?» is a question I sometimes see and which I find intriguing. What incentives does Redis have for opening up their software when they own Redis Cloud? Why make Grafana open when Grafana Cloud is owned by the same company? Or WordPress, ClickHouse and many others?\nThe incentive is that they have to do those things if they choose to publish their software as open-source and not as a closed, proprietary solution. Their success is intrinsically associated their users having the guarantee that they are free to choose whatever provider offers the service that meets their needs at any given time.\n¶ Wrapping up\nIt's not my business to say which framework you should use. If you like Next.js and you still think it's the best tool for the problem you need to solve, you should absolutely use it. But I hope that this information helps you feel more confident about your decision, whichever way you're leaning.\nAs for me, I'll keep doing my job to help support the developers who chose to deploy their sites to Netlify, whatever their framework of choice is. And competition aside, I'm genuinely looking forward to help Vercel make Next.js more open and interoperable through the OpenNext movement. ∎\n¶ Vercel's response\nThis is a placeholder where I will share any response I receive from Vercel to this post.\nUpdate (March 26th): Added a note about Vercel's most recent postmortem and a section for Vercel's response.",
    "summary": {
      "en": "### Summary of Key Points About Next.js\n\n1. **Choosing Technology**: Choosing a technology stack for a project, especially in enterprise settings, is a significant decision with long-term effects on development and team dynamics.\n\n2. **Open-Source Benefits**: Open-source software allows developers to modify and extend it freely, which fosters portability and prevents vendor lock-in. Next.js, an open-source framework by Vercel, is expected to meet these standards.\n\n3. **Concerns About Next.js**: The author, a Netlify employee, raises concerns about Next.js's governance and transparency, suggesting that Vercel's influence may limit its true open-source nature.\n\n4. **Lack of Adapters**: Unlike many frameworks, Next.js does not support adapters for different hosting environments, making it less flexible for users who want to deploy on various platforms.\n\n5. **No Official Serverless Support**: Next.js does not officially support serverless deployment, which complicates its use in scalable applications, despite Vercel's successful use of serverless for its own deployments.\n\n6. **Vercel-Specific Features**: Some functionalities in Next.js are only available when deployed on Vercel, raising questions about its openness and fairness to other providers.\n\n7. **Recent Security Incident**: A critical security vulnerability was disclosed by Vercel, but the handling of the incident was criticized for not properly informing other providers, leading to confusion and risk for users.\n\n8. **Ownership and Accountability**: While Vercel has the right to profit from Next.js, the author argues that they should maintain high standards of openness and interoperability, which they believe Vercel has not consistently met.\n\n9. **Final Thoughts**: The author encourages readers to make informed choices about using Next.js while expressing a desire for improved openness in the framework to benefit the broader community.",
      "ko": "Next.js에 대한 주요 사항을 정리하면 다음과 같습니다. \n\n프로젝트를 위한 기술 스택을 선택하는 것은 특히 기업 환경에서 중요한 결정으로, 개발과 팀의 역학에 장기적인 영향을 미칩니다. 오픈 소스 소프트웨어는 개발자들이 자유롭게 수정하고 확장할 수 있도록 하여 이동성을 높이고 특정 공급업체에 종속되는 것을 방지합니다. Vercel에서 개발한 오픈 소스 프레임워크인 Next.js는 이러한 기준을 충족할 것으로 기대됩니다. \n\n그러나 Netlify의 직원인 저자는 Next.js의 관리와 투명성에 대한 우려를 제기하며, Vercel의 영향력이 진정한 오픈 소스 특성을 제한할 수 있다고 지적합니다. 많은 프레임워크와 달리 Next.js는 다양한 호스팅 환경을 위한 어댑터를 지원하지 않아 여러 플랫폼에 배포하고자 하는 사용자에게 유연성이 떨어집니다. 또한 Next.js는 공식적으로 서버리스 배포를 지원하지 않아 확장 가능한 애플리케이션에서의 사용이 복잡해집니다. 비록 Vercel이 자체 배포에 서버리스를 성공적으로 사용하고 있지만, 공식 지원이 부족합니다. \n\nNext.js의 일부 기능은 Vercel에 배포할 때만 사용할 수 있어, 다른 제공업체에 대한 공정성과 개방성에 의문을 제기합니다. 최근 Vercel에서 심각한 보안 취약점이 공개되었지만, 사건 처리 방식이 다른 제공업체에 제대로 알리지 않아 사용자에게 혼란과 위험을 초래했다는 비판을 받았습니다. \n\nVercel은 Next.js로부터 이익을 얻을 권리가 있지만, 저자는 그들이 높은 수준의 개방성과 상호 운용성을 유지해야 한다고 주장합니다. 저자는 Vercel이 이를 일관되게 충족하지 못했다고 믿고 있습니다. 마지막으로, 저자는 독자들이 Next.js 사용에 대해 정보에 기반한 선택을 하기를 권장하며, 프레임워크의 개방성이 개선되어 더 넓은 커뮤니티에 도움이 되기를 바라는 마음을 표현합니다.",
      "ja": "Next.jsに関する重要なポイントをまとめます。\n\nプロジェクトの技術スタックを選ぶことは、特に企業環境では重要な決定であり、開発やチームのダイナミクスに長期的な影響を与えます。オープンソースソフトウェアは、開発者が自由に変更や拡張を行えるため、移植性が高く、特定のベンダーに依存することを防ぎます。Next.jsはVercelによって提供されるオープンソースのフレームワークであり、これらの基準を満たすことが期待されています。\n\nしかし、Netlifyの社員である著者は、Next.jsのガバナンスや透明性について懸念を示しています。Vercelの影響が、Next.jsの真のオープンソース性を制限する可能性があると指摘しています。また、Next.jsは多くのフレームワークとは異なり、異なるホスティング環境向けのアダプターをサポートしていないため、さまざまなプラットフォームにデプロイしたいユーザーには柔軟性が欠けています。\n\nさらに、Next.jsは公式にサーバーレスデプロイをサポートしておらず、スケーラブルなアプリケーションでの使用が難しくなっています。これは、Vercelが自社のデプロイにサーバーレスを成功裏に使用しているにもかかわらずです。Next.jsの一部の機能はVercelでデプロイした場合にのみ利用可能であり、他のプロバイダーに対するオープンさや公平性について疑問が生じます。\n\n最近、Vercelから重要なセキュリティ脆弱性が公表されましたが、その対応が不十分で、他のプロバイダーへの情報提供が適切に行われなかったため、ユーザーに混乱やリスクをもたらしました。VercelはNext.jsから利益を得る権利がありますが、著者は彼らが高いオープン性と相互運用性の基準を維持すべきだと主張しています。著者は、Vercelがその基準を一貫して満たしていないと考えています。\n\n著者は、読者にNext.jsの使用について十分な情報に基づいた選択をするよう促し、フレームワークのオープン性が向上することを望んでいます。これは、より広いコミュニティに利益をもたらすためです。"
    }
  },
  {
    "id": "7ca71811523f267c",
    "title": {
      "en": "Chicago-Sized Iceberg Hid Ancient Ecosystem, Scientists Reveal",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://gizmodo.com/chicago-sized-iceberg-hid-ancient-ecosystem-scientists-reveal-2000579125",
    "score": 38,
    "by": "rbanffy",
    "time": 1742735947,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "fe4536a67db801ea",
    "title": {
      "en": "Polypane, The browser for ambitious web developers",
      "ko": "야망 있는 웹 개발자를 위한 폴리페인",
      "ja": "野心的な開発者のためのPolypane"
    },
    "type": "story",
    "url": "https://polypane.app/",
    "score": 196,
    "by": "ulrischa",
    "time": 1742720837,
    "content": "All-in-onePolypane helps with every aspect of web development.Develop and test your site in all the ways your real users view it: different screen sizes, device capabilities, color schemes, accessibility settings and more.responsive designAll the viewports you need.Don't manually resize and test websites screen-by-screen. Get all your viewports in one overview, no browser resizing needed.Mobile screens, 5K monitors, all your CSS breakpoints or any size you want.Synced panesAnd they're all in sync.Scrolling, clicking, typing and even hovers are synced across all viewports.Don't test viewports or devices one-by-one, check them all at once.Cross-browser and Cross-deviceEven across browsers.Share your local development environment anywhere, on any browser, on any device. Polypane Portal keeps everything in sync whether that's the scroll position, interactions, style edits or layout debugging.Debug toolsFrom A11y to Z-index.Apply over 40 different debug tools to each viewport. Test your site in completely new ways.Meta panelSocial media share card previews.X / TwitterFacebookSlackLinkedinDiscordGoogleTelegramBlueskyMastodonThreadsPixel-perfect previews of social media cards for X/Twitter, Facebook, Slack, LinkedIn, Discord, Telegram, Bluesky, Threads and Google Search. In dark and light mode. Even with your localhost.Deep dive into our social media previewsUser testimonialsDevelopers and designers love Polypane.Here's what they say:Polypane is easily one of the most useful tools for modern web designers and developers.Stephen Hay Author of Responsive Design WorkflowIt is convenient seeing your work in multiple responsive views at the same time. Love it, 💯Sara Soueidan Independent front-end UI engineer, Speaker/TrainerThis thing is FAST and the synchronized scrolling works amazingly. Prepare to be impressed.Vivian Guillen Frontend Developer & Curator at Tailwind WeeklyPolypane is really saving my bacon. Kilian knocked it out of the park, this is my new favorite development tool.Scott Tolinski Syntax.fm host, Level Up TutorialsIf you’re designing modern applications and websites, you should try Polypane! It’s worth every penny!Segun \"Sage\" Adebayo Creator of Chakra UI and Zag.jsI've started playing around with Polypane and 🤯. It has awesome debugging tools, accessibility checks and tests, and more. I'm really impressed.Kevin Powell CSS EvangelistRead more testimonials Join our Slack community Polypane has all the tools you need to build great web experiences.Try for free EmulationDark mode media feature testing.No need to change your entire operating system! Test light and dark mode side-by-side in the same view. Also works for reduced motion, reduced data and even print styles.DevtoolsYour favorite DevTools extensions.Install and use your favorite Chromium devtools, with support for React DevTools, Vue.js DevTools, Redux DevTools, Angular, Svelte and many more.…And that's only scratching the surface.Polypane has everything you need to make awesome web experiences.Unlimited ViewportsScroll SyncingHover SyncingGrid OverlaysUnified ConsoleKeyboard SyncingJSON ViewerDevice PresetsFreeform ResizingHorizontal Overflow DetectionDeveloper ToolsPixel-perfect Social Media PreviewsDifferent Layout ModesDevice EmulationHandoff SupportLive ReloadingAccessibility AuditsCustom SessionsPage OutlinesLive CSS EditingColor Blindness SimulatorsFull Page ScreenshotsVisual Design DiffingMeta Data OverviewCSS Breakpoint DetectionOverview ScreenshotsUnified Element InspectorTouch EmulationAutomated Form TestingScreenshot EditorWeb Vitals InspectorColor PickerBrowser ExtensionsBroken Link CheckingShare LinksCustom HeadersDark ModeWorkspaces…and more added monthly!Full product tour\n\nPolypane syncs everythingScrollHoverClickTypeTry it:0 clicksBuild, Debug and TestCreate as many panes as you needFind the overview that works for you. Store your favorite configurations in workspaces and share them with your team.Resize panes whenever you wantUse our device presets, your own CSS breakpoints or freeform resize panes right on the main canvas.Synced element inspector and consoleAn element inspector and a fully functional console that works seamlessly across all panes, eliminating duplicate tasks.Dozens and dozens of debug toolsLayout debugging, color blindness testers, built-in live reloading, screenshotting, device and media emulation...The list goes on.Everything you need to create amazing sites and webappsStart your free trial\n\nPolypane syncs everythingScrollHoverClickTypeTry it:0 clicksBuild, Debug and TestCreate as many panes as you needFind the overview that works for you. Store your favorite configurations in workspaces and share them with your team.Resize panes whenever you wantUse our device presets, your own CSS breakpoints or freeform resize panes right on the main canvas.Synced element inspector and consoleAn element inspector and a fully functional console that works seamlessly across all panes, eliminating duplicate tasks.Dozens and dozens of debug toolsLayout debugging, color blindness testers, built-in live reloading, screenshotting, device and media emulation...The list goes on.Everything you need to create amazing sites and webappsStart your free trial\n\nPolypane syncs everythingScrollHoverClickTypeTry it:0 clicksBuild, Debug and TestCreate as many panes as you needFind the overview that works for you. Store your favorite configurations in workspaces and share them with your team.Resize panes whenever you wantUse our device presets, your own CSS breakpoints or freeform resize panes right on the main canvas.Synced element inspector and consoleAn element inspector and a fully functional console that works seamlessly across all panes, eliminating duplicate tasks.Dozens and dozens of debug toolsLayout debugging, color blindness testers, built-in live reloading, screenshotting, device and media emulation...The list goes on.Everything you need to create amazing sites and webappsStart your free trial",
    "summary": {
      "en": "Polypane is a comprehensive tool for web development that allows you to build and test websites across various devices and screen sizes all at once. Here are the key features:\n\n- **All-in-One Viewports**: No need to resize browsers manually; you can see all viewports together, from mobile to 5K monitors.\n- **Synchronized Interaction**: Actions like scrolling and clicking are synced across all viewports, making testing easier.\n- **Cross-Browser Compatibility**: Share your local development environment across different browsers and devices without issues.\n- **Debugging Tools**: Access over 40 different debugging tools to test your site's performance and accessibility.\n- **Social Media Previews**: Get pixel-perfect previews of how your site will look on various social media platforms in both light and dark modes.\n- **User Feedback**: Developers praise Polypane for its speed, synchronization features, and useful debugging capabilities.\n- **Device Emulation**: Test different modes such as dark mode or reduced motion without altering your system settings.\n- **Customizable Workspaces**: Create and store preferred layouts and configurations to streamline your workflow.\n\nPolypane is designed to help developers create better web experiences efficiently. You can try it for free to see its benefits firsthand.",
      "ko": "Polypane는 웹 개발을 위한 종합 도구로, 다양한 기기와 화면 크기에서 웹사이트를 동시에 구축하고 테스트할 수 있게 해줍니다. 주요 기능은 다음과 같습니다.\n\n모든 뷰포트를 한눈에 볼 수 있어 브라우저를 수동으로 크기를 조정할 필요가 없습니다. 모바일 기기부터 5K 모니터까지 모든 뷰포트를 함께 확인할 수 있습니다. 스크롤이나 클릭과 같은 동작이 모든 뷰포트에서 동기화되어 테스트가 더 쉬워집니다. 또한, 로컬 개발 환경을 여러 브라우저와 기기에서 문제 없이 공유할 수 있어 호환성도 뛰어납니다.\n\n40개 이상의 다양한 디버깅 도구에 접근할 수 있어 사이트의 성능과 접근성을 테스트할 수 있습니다. 소셜 미디어 플랫폼에서 사이트가 어떻게 보일지를 밝은 모드와 어두운 모드 모두에서 픽셀 단위로 정확하게 미리 볼 수 있습니다. 개발자들은 Polypane의 속도, 동기화 기능, 유용한 디버깅 능력에 대해 긍정적인 평가를 하고 있습니다.\n\n어두운 모드나 움직임 감소와 같은 다양한 모드를 테스트할 수 있으며, 시스템 설정을 변경하지 않고도 사용할 수 있습니다. 또한, 선호하는 레이아웃과 구성을 만들어 저장하여 작업 흐름을 효율적으로 관리할 수 있습니다.\n\nPolypane는 개발자들이 더 나은 웹 경험을 효율적으로 만들 수 있도록 설계되었습니다. 무료로 사용해 보며 그 장점을 직접 체험할 수 있습니다.",
      "ja": "Polypaneは、ウェブ開発のための包括的なツールで、さまざまなデバイスや画面サイズで同時にウェブサイトを構築・テストすることができます。主な機能は以下の通りです。\n\nすべてのビューポートを一度に表示できるため、ブラウザを手動でリサイズする必要がありません。モバイルから5Kモニターまで、すべてのビューポートを同時に確認できます。また、スクロールやクリックなどの操作がすべてのビューポートで同期されるため、テストが簡単になります。\n\n異なるブラウザやデバイス間でローカル開発環境を問題なく共有できるため、クロスブラウザ互換性も確保されています。さらに、サイトのパフォーマンスやアクセシビリティをテストするために、40以上のデバッグツールにアクセスできます。\n\nさまざまなソーシャルメディアプラットフォームでのサイトの表示を、ライトモードとダークモードの両方でピクセル単位でプレビューできます。開発者たちは、Polypaneの速度や同期機能、便利なデバッグ機能を高く評価しています。\n\nダークモードや動作を抑えたモードなど、システム設定を変更せずにさまざまなモードをテストすることも可能です。また、好みのレイアウトや設定を作成・保存できるカスタマイズ可能なワークスペースが用意されており、作業の効率を向上させます。\n\nPolypaneは、開発者がより良いウェブ体験を効率的に作成するために設計されています。無料で試すことができ、その利点を実際に体験できます。"
    }
  },
  {
    "id": "e49db46a233384da",
    "title": {
      "en": "Reflecting on WikiTok",
      "ko": "위키톡 반성하기",
      "ja": "ウィキトックの考察"
    },
    "type": "story",
    "url": "https://www.aizk.sh/posts/reflecting-on-wikitok",
    "score": 153,
    "by": "aizk",
    "time": 1742882951,
    "content": "Reflecting on WikiTok\n\nThree weeks ago, I launched Wikitok at 1:53 AM EST from the corner of my Brooklyn bedroom.\nAll the great software engineers I admire take time to write out their thoughts, so I'd like to do the same for WikiTok, while also sharing my experience in software in general. So much has transpired in a very short amount of time - I'm certain the lessons I learned will be valuable to anyone reading this.\nThe Background\nI built wikitok.io in about 2 hours (but not the iphone app that doesn't work, nor the play store rip off, nor wikitok.net but I'm getting ahead of myself). It all came from this tweet. Simply put it's infinite scrolling wikipedia. The details of the initial process can be found in this Ars Technica article - instead of rehashing those details too much I'm going to focus more on the code as well as the aftermath / what I learned from virality.\nThe Codebase\nThe tech stack is bun, react and typescript. I combined the code from the very first working commit and pasted it below, and we'll go through it line by line.\nimport React, { useState, useEffect, useRef, useCallback } from 'react';\n\n// Types\ninterface WikiArticle {\n   title: string;\n   extract: string;\n   pageid: number;\n   thumbnail?: {\n       source: string;\n       width: number;\n       height: number;\n   };\n}\n\ninterface WikiCardProps {\n   article: WikiArticle;\n   key?: React.Key;\n}\nRight now we're just defining the shape of the wiki data. Thumbnails are technically optional, which is why we have a ? after the type definition, but in later iterations I ditched articles without thumbnails altogether. The key helps React understand which items are new or have been removed from the list, but is actually just extra code from Claude in this instance.\n// WikiCard Component\nfunction WikiCard({ article }: WikiCardProps) {\n   return (\n       <div className=\"h-screen w-full flex items-center justify-center snap-start\">\n           <div className=\"bg-white max-w-lg w-full mx-4 rounded-xl shadow-xl p-6\">\n               {article.thumbnail && (\n                   <img\n                       src={article.thumbnail.source}\n                       alt={article.title}\n                       className=\"w-full h-48 object-cover rounded-lg mb-4\"\n                   />\n               )}\n               <h2 className=\"text-2xl font-bold mb-3\">{article.title}</h2>\n               <p className=\"text-gray-700\">{article.extract}</p>\n               <a\n                   href={`https://en.wikipedia.org/?curid=${article.pageid}`}\n                   target=\"_blank\"\n                   rel=\"noopener noreferrer\"\n                   className=\"mt-4 inline-block text-blue-500 hover:text-blue-600\"\n               >\n                   Read more →\n               </a>\n           </div>\n       </div>\n   );\n}\nThis component is the heart of the UI. We are essentially saying, \"for each article, render a div with a thumbnail, title, extract, and a link to the full article\", and it must be in the shape of the WikiCardProps interface. The only minor issue with this is that the curid parameter is technically the wrong way to query articles - as pointed out by an engineer from Wikipedia here.\nSo, what does it look like?\n\nBesides the accidental white text on the white background, not bad! It is however way too tiny, but we can fix that later. It seems Claude designed it from the start to only be TikTok sized.\n// Custom Hook for Wiki Articles\nfunction useWikiArticles() {\n   const [articles, setArticles] = useState<WikiArticle[]>([]);\n   const [loading, setLoading] = useState(false);\n\n   const fetchArticles = async () => {\n       setLoading(true);\n       try {\n           const response = await fetch(\n               \"https://en.wikipedia.org/w/api.php?\" +\n               new URLSearchParams({\n                   action: \"query\",\n                   format: \"json\",\n                   generator: \"random\",\n                   grnnamespace: \"0\",\n                   prop: \"extracts|pageimages\",\n                   grnlimit: \"5\",\n                   exchars: \"200\",\n                   exlimit: \"max\",\n                   explaintext: \"1\",\n                   piprop: \"thumbnail\",\n                   pithumbsize: \"400\",\n                   origin: \"*\",\n               })\n           );\n           const data = await response.json();\n           const newArticles = Object.values(data.query.pages).map((page: any) => ({\n               title: page.title,\n               extract: page.extract,\n               pageid: page.pageid,\n               thumbnail: page.thumbnail,\n           }));\n           setArticles((prev) => [...prev, ...newArticles]);\n       } catch (error) {\n           console.error(\"Error fetching articles:\", error);\n       }\n       setLoading(false);\n   };\n\n   return { articles, loading, fetchArticles };\n}\nThis is a custom hook that fetches the articles from Wikipedia's API.\nWe call the Wikipedia API for 5 new articles every fetch, parse the JSON response, and extend our existing article list using the spread operator.\nThe only thing that immediately jumps out is the \"any\" type - but I've spent a lot of time agonizing over needless type complexity in typescript projects without actually moving the project forward at all, essentially just using it as some sort of procrastination tool. This is a really devious trap to find yourself in.\nThe \"proper\" solution would be to define an interface like WikiApiResponse that describes the shape of the response, and then use that to type the response, but in a project this simple, it's clear that the use of \"any\" won't make a difference to the safety of the code - so don't worry too hard!\nWhat matters above all is that you ship something, anything at all.\nGet feedback, get users, and then iterate. The codebase has changed significantly since this initial commit, shaped by user feedback and bug fixes - your users will tell you what needs to be changed.\nI mentioned before that the hook helps us fetch articles, but how do we know when to fetch more articles?\n// Main App Component\nfunction App() {\n   const { articles, loading, fetchArticles } = useWikiArticles();\n   const observerTarget = useRef(null);\n\n   const handleObserver = useCallback(\n       (entries: IntersectionObserverEntry[]) => {\n           const [target] = entries;\n           if (target.isIntersecting && !loading) {\n               fetchArticles();\n           }\n       },\n       [loading, fetchArticles]\n   );\n\n   useEffect(() => {\n       const observer = new IntersectionObserver(handleObserver, {\n           threshold: 0.5,\n       });\n\n       if (observerTarget.current) {\n           observer.observe(observerTarget.current);\n       }\n\n       return () => observer.disconnect();\n   }, [handleObserver]);\n\n   useEffect(() => {\n       fetchArticles();\n   }, []);\n\n   return (\n       <div className=\"h-screen w-full bg-black text-white overflow-y-scroll snap-y snap-mandatory\">\n           {articles.map((article: WikiArticle) => (\n               <WikiCard key={article.pageid} article={article} />\n           ))}\n           <div ref={observerTarget} className=\"h-10\" />\n           {loading && (\n               <div className=\"h-screen w-full flex items-center justify-center\">\n                   Loading...\n               </div>\n           )}\n       </div>\n   );\n}\n\nexport default App;\nThis is the most interesting bit of code in the project. In my head, the way I conceptualized this was that there should always be a buffer of articles underneath the current article, and it's triggered as the user continues to scroll. Not too many fetched where it slows the user experience but enough so that they never reach the \"end\" of wikipedia.\nClaude's idea was to create an invisible div at the bottom of our article list and attach an observer to it. When this div becomes visible (meaning the user has scrolled near the bottom), we fetch more articles. All in all, pretty clever. Truthfully, I've never designed an infinite scrolling interface before, so I was completely winging it.\nIs this code excellent? No. But was this code ready to be shipped? No not even close, I had to go back and make a dozen more fast commits before I felt comfortable publishing the project.\nBut did this get the ball rolling and made me realize what I could build? Yes.\nThe Development Process\nMy thought process working on wikitok was completely backwards to what standard software engineering principles would tell you - I let Claude with Cursor do the vast majority of the work, where I gave it the specs I wanted and I prompted away. I maintained a running list of all the features I wanted, testing and checking things off one by one, committing quick wins. Get the feature, take a peek at the code, move on to the next requirement, maybe compartmentalize some of the code here and there so it's nice and functional (I mean that both in a programming sense and literal sense). It worked out well - for instance Claude surprised me at the start letting me know I wouldn't even need a backend to access Wikipedia's API (no CORS restriction) which made deployment far easier for me. Interestingly, Wikimedia themselves later asked about my experience using their API, noting that many developers struggle with finding and parsing their documentation - they were surprised when I mentioned I hadn't used their docs for the MVP at all. You can find their docs here.\nThis approach can backfire if you try it in a professional setting. So why did I roll with it?\nWell for a start - I've had thousands of conversations with different AIs, and I've developed a pretty decent radar for their capabilities, when they make things up, when to completely ignore them, etc. The caveat to this is I'd imagine this wouldn't be the case if I started building in a language I've never used before. I also had a gut feeling from the start the MVP would be less than 500 lines, which is more than enough for the context of any modern LLM. The last point is that speed was the real priority here. There was already a tweet gaining momentum asking for \"All of wikipedia on one page\", which is what inspired the entire project. Building wikitok with that exact tweet in mind, knowing people might see the two tweets side by side proved to be wildly helpful.\nTo be clear to any junior engineers reading this (I'm kinda talking to myself here) - with current AI models, vibing your way to success will completely break down once you try to contribute to a serious production codebase. I think about this a lot, and I learned this the hard way when it came time to contribute to the Minecraft Benchmark, as the project is thousands and thousands of lines of code. But for simple, small projects? Some random super specific, monotonous office task? Lean in on the AI.\nUltimately, even with AI, software engineering will still be the job of giving computers precise instructions to do things, but how we do that will change. The field reinvents itself each decade, and AI is no exception.\nLessons from Going Viral\nGoing viral is stressful. It's a bit like winning the lottery, except there's a catch. As you improve your skills, you get to enter more tickets into the lottery. This is really critical - it's still the lottery, it's unfair, but your odds can just keep getting better and better, and eventually one day everyone will notice what you've built. I've had viral tweets before, and I've made a bunch of quick websites, but this is the first time I combined the two.\nThe other point in this is that you have to know what to do when you get lucky. If this was the first ever React project I made, I am certain I would've fumbled the launch and completely screwed it up, but thankfully it wasn't! I quite like this point from Brandon Sanderson, he mentioned in his writing lectures that if you haven't written 3 novels, your job is not to sell books. You job is to write enough books to learn your process and what works for you.\nSo you're viral, now what? Focus your energy on the platform that helped you achieve virality because that's where the most eyeballs are. You won't be able to answer every question and comment people throw at you. I made that mistake, getting way too caught up in the frenzy.\nOn answering comments - not all comment sections are equal. I spent quite a lot of time responding to questions in the initial hacker news post because I knew going viral on hacker news and making a good positive impression on that site would push my post up, and from there I'd get an enormous amount of traffic. Hacker news also tends to be more critical of specific technical details than lets say a random news subreddit, so you might get more value out of it (well, not always). The general flow of information was something like twitter → hacker news → mainstream news outlets → reddit / youtube.\nAlso be prepared to not sleep much for the first day of the launch. You're trading a bit of your health for the experience, but it's worth it. I got 4 and a half hours of sleep when I launched WikiTok.\nSorry Bryan Johnson\nAt the height of the frenzy, I had two people knock on my door and I briefly freaked out, wondering if they were journalists that somehow decided it would be a good idea to show up to my house. Thankfully they were just 2 Verizon technicians conducting routine surveys.\nDealing with Journalists\nI would advise anyone who goes viral to only do interviews with journalists via email or dms (unless it's an actual in-person news interview). There's nothing explicitly wrong with a phone call, but it's far easier to be extremely precise with your words when it's in a written format. It will take longer to write and more often than not most of it will get discarded, but the writing process is extremely valuable.\nWhen a journalist does contact you, do some research on their account. Reminder: a blue checkmark doesn't mean anything on Twitter anymore, as I would later be reminded when dealing with a scammer posing as a journalist. Ask to chat only via email and dms if you have the time. You really want to collect your thoughts and make sure you say exactly what you want to say, compared to freewheeling a conversation. I learned that first when I had a conversation with Business Insider, and it was a pleasant experience, even though I don't think I relayed my message and ideas as well as I could have.\nI wrote about 2000 words for the Washington Post, which took me roughly 3 and a half hours (longer than WikiTok did to make). They only used a paragraph, but now I have a detailed written record of my process and reasoning.\nStill that wasn't enough, and even after explicitly ignoring a question about Elon Musk, they took an angle of \"Insert Elon Musk for clicks,\" which I found to be a bit annoying. There's a lesson here that there's only so much you can control when you go viral.\n(Illustration by Elena Lacey/The Washington Post; Tom Brenner/The Washington Post; iStock)\nYou'll need that precision because information degrades like a game of telephone as it spreads. I counted at least 5 international articles that had the wrong URL (somebody sniped wikitok.net, and people ran with it saying it was mine). You won't be able to correct every mistake, but call out the big ones (like journalists screwing up coverage, which I promise will happen). Focus on the main sources of information - that's all you can really control. Ultimately that's what it means for something to go viral - spreading rapidly across the internet, partially out of your control.\nThe other thing about virality that shocked me, and this is more specific to software engineering - is how strange of an experience it is to have an open source project go viral. It felt like I was on a fishing boat, and suddenly a dozen people climbed aboard and offered their advice on how I should steer the ship. Some people had good points, but others wanted to steer the ship completely in the wrong direction, and I had to be the ones to shut them down. A very weird feeling. A frequent request was adding some sort of \"algorithm\" to the project, which I'm sure would be neat and all, but it's not what I set out to build.\nSome journalists picked up on my sentiment and frustration from dealing with so many requests (specifically, the ones who wanted to add an algorithm to the project), and eventually labeled wikitok as a \"cure\" for doomscrolling, or saying that I built it out explicitly due to frustration with algorithms. I wouldn't really agree with that, but it's a good conversation to have. Personally, I felt it would be strange to add an algorithm and store user data on a project that's based off of Wikipedia's data - it just feels wrong and probably violates their creative commons license. How would I even ethically monetize that? Maybe everyone 100 scrolls you get a giant, annoying popup of Jimmy Wales asking for a donation or something. The omni-presence of algorithms, good and bad, deserves a blog post all of its own.\nCoincidentally, Alec Watson of Technology Connections just uploaded a fantastic video talking about the pitfalls of living lives served by algorithms, I'd encourage you to watch it here. He refers to the issue as \"Algorithmic Complacency\" and goes into great detail about it.\nWatch Out for Scams\nWatch out for phishing attempts. I had a sophisticated phishing attempt show up in my inbox.\n\nA TechCrunch journalist DM'd saying they wanted to chat, and they offered a calendar link to allow me to schedule something on their end. The link will send you to a twitter oauth screen asking if you wish to allow Calendly to access your account, but it's completely fake! It's a clever man-in-the-middle attack, completely bypassing your password or 2FA, and they get permission to post on your behalf. The last step from their end is to use your account as a crypto pump and dump scheme, making thousands. An example of such coin would be something like this random wikitok coin somebody made, but with 99.8% of the coin being held by the owner, I don't think even the most degenerate crypto bros would invest in that.\nFor me, I googled the TechCrunch journalist and realized that wasn't actually their account - and I also got lucky that I had happened to see a tweet about someone's experience with a phishing attempt on my feed a few hours earlier. I wonder if I hadn't seen that tweet, would I have fallen for it? The best thing I can do is post a tweet about it, write up this blog, and make sure people know. I'll leave two more very good threads here from Alex Banks and Danny Postma who both dealt with the same exact scam.\nIn retrospect, it seems like an obvious scam. But when you have 5 different real journalists DMing you and asking for interviews, on top of maintaining the site itself, I could have very easily fell for it, and I'm sure others have.\nI went through about maybe 200 DMs total. The vast majority were really positive, mostly people who were just excited and reaching out to me about Wikitok, which was wonderful! But I had to filter through the craziest shit imaginable. Here's a really unhinged crypto scam:\n\nBut those aren't the worst ones. The worst ones are the death threats. Not because I'm scared of them, but it's just sad to see what insane things people's brains were pretrained on as they grew up. I'm Jewish, I was cancelled before I was even born, 3000 years ago. I didn't get as many death threats as I usually do when I get viral tweet or something, but I did get a few. I'm not going to share them in this post but you can use your imagination. Maybe one day I'll write a detailed blog post about the Jewish experience in the 21st century.\nAbout Me\nI'm actually in the middle of a career transition. Less than a year ago, I was a civil engineer, doing everything from AutoCAD drafting to literally being in the trenches. I quit 2 years out of college because everyday I came home with a deep seated feeling that I chose the wrong career path. I dropped everything, moved to Brooklyn, and found communities where I could really learn to ship. Why did I decide to quit, even in the face of AI and a perfectly fine degree in civil engineering? One reason - I already had some actual programming experience at an internship in college. I wasn't hired to code at all, I just picked it up on my own at the company and started to make serious contributions, one stack overflow page at a time, so I knew it must be possible. The downside to this was that it made the tail end of college rather depressing, as this deep-seated internal conflict started to brew. Am I a software engineer? A civil engineer? Do these classes matter in the slightest? I suppose college really did prepare me for the real world.\nAnd with regards to AI taking jobs - it obviously will become a serious problem in future. But being a doomer right now is like lying down in a parking lot waiting to get run over - you're surrendering to a pointless outcome while the rest of the world keeps moving. There's still so much to build and accomplish. We don't know when AGI is coming, so why stand around and wait for it? Even when some sort of thing that we can agree on is AGI gets released, do you think it will be able to solve problems like creating peace in the Middle East? AGI does not encompass the human condition - there will still be work to do.\nWhat's Next?\nFor wikitok - not much. The website is mostly complete and currently I'm only reviewing simple pull requests. Before I wrote code, I used to make music as a hobby. In the world of music, when you put a song out there, it's set in stone. I'm still adjusting to the fact that software is the opposite - endlessly evolving, 24/7. I did create a sequel to wikitok called spacetok.io that allows you to scroll through images from NASA, after seeing some tweets talking about the idea. I knew the sequel wouldn't go viral, but I made it simply because it was fun. If you know anyone at NASA who'd like it, let them know!\nWhat's next for me? I'll be working on more projects like mcbench.ai. I'll also be diving into theoretical study to fill in my knowledge gaps that Claude is not able to provide, but my big priority is looking for a job. That was one reason I made wikitok - it seemed like fun and something I could put on my resume (so hey, why not check it out and send me an email if you're hiring).\nThanks for reading!Share",
    "summary": {
      "en": "**Summary of \"Reflecting on WikiTok\"**\n\nThree weeks ago, I launched WikiTok, a website that offers an infinite scrolling experience of Wikipedia articles. I created it quickly, inspired by a tweet, and it took about two hours to build the initial version using technologies like React and TypeScript.\n\n### Key Points:\n\n1. **Development Process**:\n   - The tech stack includes bun, React, and TypeScript.\n   - I used a custom hook to fetch articles from Wikipedia's API, allowing for continuous loading as users scroll.\n   - I learned that speed and getting user feedback are crucial in early development stages.\n\n2. **Going Viral**:\n   - Achieving virality can be overwhelming and requires quick adaptation.\n   - It's important to focus on the platform where you gained attention and prioritize responding to comments that can help boost visibility.\n   - Managing expectations and understanding the unpredictability of virality is essential.\n\n3. **Interactions with Media**:\n   - I recommend handling journalist inquiries through written communication to maintain clarity and control over your message.\n   - Be cautious of scams and misinformation that can arise during a viral moment.\n\n4. **Personal Journey**:\n   - I transitioned from being a civil engineer to a software developer, driven by a desire for fulfilling work.\n   - While AI may impact jobs, there's still ample opportunity for innovation and problem-solving.\n\n5. **Future Plans**:\n   - The current focus for WikiTok is mainly maintenance, with plans to explore more projects for fun and skill development.\n\nOverall, my experience with WikiTok has been a mix of technical challenges, unexpected attention, and valuable lessons in software development and public engagement.",
      "ko": "세 주 전, 저는 위키피디아 기사를 무한히 스크롤할 수 있는 웹사이트인 WikiTok을 출시했습니다. 이 아이디어는 트윗에서 영감을 받아 빠르게 구현했으며, 초기 버전을 만드는 데 약 두 시간이 걸렸습니다. React와 TypeScript 같은 기술을 사용했습니다.\n\n개발 과정에서 bun, React, TypeScript를 포함한 기술 스택을 사용했습니다. 위키피디아의 API에서 기사를 가져오기 위해 커스텀 훅을 만들어 사용자가 스크롤할 때마다 계속 로딩할 수 있도록 했습니다. 초기 개발 단계에서는 속도와 사용자 피드백이 매우 중요하다는 것을 배웠습니다.\n\n바이럴 효과를 얻는 것은 압도적일 수 있으며, 빠르게 적응해야 합니다. 주목을 받은 플랫폼에 집중하고, 가시성을 높이는 데 도움이 되는 댓글에 우선적으로 응답하는 것이 중요합니다. 바이럴 현상의 예측 불가능성을 이해하고 기대치를 관리하는 것도 필수적입니다.\n\n언론과의 소통에 있어서는 명확성과 메시지 통제를 위해 서면으로 문의를 처리하는 것을 추천합니다. 바이럴 순간에는 사기와 잘못된 정보에 주의해야 합니다.\n\n저는 토목 엔지니어에서 소프트웨어 개발자로 전환했으며, 보람 있는 일을 하고자 하는 열망이 있었습니다. AI가 일자리에 영향을 미칠 수 있지만, 여전히 혁신과 문제 해결의 기회는 많습니다.\n\n현재 WikiTok의 초점은 주로 유지 관리이며, 재미와 기술 개발을 위한 더 많은 프로젝트를 탐색할 계획입니다. 전반적으로 WikiTok 경험은 기술적 도전, 예상치 못한 관심, 소프트웨어 개발과 대중 소통에서의 귀중한 교훈이 어우러진 시간이었습니다.",
      "ja": "三週間前、私はWikiTokというウェブサイトを立ち上げました。このサイトは、無限にスクロールできるウィキペディアの記事を提供します。ツイートに触発されて急いで作成し、初期バージョンを構築するのに約二時間かかりました。使用した技術には、ReactやTypeScriptが含まれています。\n\n開発プロセスでは、bun、React、TypeScriptを使用しました。ウィキペディアのAPIから記事を取得するためにカスタムフックを作成し、ユーザーがスクロールする際に連続して読み込むことができるようにしました。初期の開発段階では、スピードとユーザーからのフィードバックが非常に重要であることを学びました。\n\nバイラルになることは圧倒されることもあり、迅速な適応が求められます。注目を集めたプラットフォームに焦点を当て、可視性を高めるために役立つコメントへの返信を優先することが大切です。また、バイラルの予測不可能性を理解し、期待を管理することも重要です。\n\nメディアとのやり取りについては、記者からの問い合わせには書面で対応することをお勧めします。そうすることで、メッセージの明確さとコントロールを保つことができます。バイラルな瞬間には詐欺や誤情報に注意が必要です。\n\n私自身の経歴としては、土木技師からソフトウェア開発者に転身しました。充実した仕事を求める気持ちがその原動力です。AIが仕事に影響を与える可能性はありますが、革新や問題解決の機会はまだ十分にあります。\n\n今後の計画としては、WikiTokの維持管理に主に焦点を当てつつ、楽しみやスキル向上のために新しいプロジェクトにも取り組む予定です。全体として、WikiTokでの経験は、技術的な課題や予期しない注目、ソフトウェア開発や公共の関与における貴重な教訓の混在でした。"
    }
  },
  {
    "id": "fff7d9904f659462",
    "title": {
      "en": "Hann: A Fast Approximate Nearest Neighbor Search Library for Go",
      "ko": "한: 고속 근접 이웃 탐색 라이브러리",
      "ja": "Hann: 高速近傍検索ライブラリ"
    },
    "type": "story",
    "url": "https://github.com/habedi/hann",
    "score": 88,
    "by": "habedi0",
    "time": 1742903831,
    "content": "Hann\n\nA fast approximate nearest neighbor search library for Go\n\nHann is a high-performance approximate nearest neighbor search (ANN) library for Go.\nIt provides a collection of index data structures for efficient similarity search in high-dimensional spaces.\nCurrently, supported indexes include Hierarchical Navigable Small World (HNSW),\nProduct Quantization Inverted File (PQIVF), and Random Projection Tree (RPT).\nHann can be seen as a core component of a vector database (like Milvus, Pinecone, Weaviate, Qdrant, etc.).\nIt can be used to add fast in-memory similarity search capabilities to your Go applications.\nFeatures\n\nUnified interface for different indexes (see core/index.go)\nSupport for indexing and searching vectors of arbitrary dimension\nFast distance computation using SIMD (AVX) instructions (see core/simd_distance.c)\nSupport for bulk insertion, deletion, and update of vectors\nSupport for saving indexes to disk and loading them back\n\nIndexes\n\nIndex Name\nSpace Complexity\nBuild Complexity\nSearch Complexity\n\nHNSW\n$O(nd + nM)$\n$O(n\\log n)$\n\n$O(\\log n)$ average case$O(n)$ worst case\n\nPQIVF\n$O(nk + kd)$\n$O(nki)$\n$O(\\frac{n}{k})$\n\nRPT\n$O(nd)$\n$O(n\\log n)$\n\n$O(\\log n)$ average case$O(n)$ worst case\n\n$n$: number of vectors\n\n$d$: number of dimensions (vector length)\n\n$M$: links per node (HNSW)\n\n$k$: number of clusters (PQIVF)\n\n$i$: iterations for clustering (PQIVF)\n\nSupported Distances\nThe HNSW index supports the use of Euclidean, squared Euclidean, Manhattan, and cosine distances.\nIf cosine distance is used, the vectors are normalized on read (before they are used in the index or for search).\nNote that squared Euclidean distance is slightly faster to compute than Euclidean distance\nand gives the same order of closest vectors as Euclidean distance.\nIt can be used in place of Euclidean distance if only the order of closest vectors to\nquery vector is needed, not the actual distances.\nThe PQIVF and RPT indexes support Euclidean distance only.\nInstallation\nHann can be installed as a typical Go module using the following command:\ngo get github.com/habedi/hann@main\n\nHann requires Go 1.21 or later, a C (or C++) compiler, and a CPU that supports AVX instructions.\nExamples\n\nExample File\nDescription\n\nsimple_hnsw.go\nCreate and use an HNSW index with inline data\n\nhnsw.go\nCreate and use an HNSW index\n\nhnsw_large.go\nCreate and use an HNSW index (using large datasets)\n\npqivf.go\nCreate and use a PQIVF index\n\npqivf_large.go\nCreate and use a PQIVF index (using large datasets)\n\nrpt.go\nCreate and use an RPT index\n\nrpt_large.go\nCreate and use an RPT index (using large datasets)\n\nload_data.go\nHelper functions for loading example datasets\n\nutils.go\nExtra helper functions for the examples\n\nrun_datasets.go\nThe code to create different indexes and try them with different datasets\n\nDatasets\nUse the following commands to download the datasets used in the examples:\nmake download-data\n\n# Only needed to run the examples that use large datasets\nmake download-data-large\n\nNote that to run the examples using large datasets, possibly a machine with large amounts of memory is needed\nlike 32 GB or more.\nCheck the data directory for information about the datasets.\n\nDocumentation\nThe detailed documentation for Hann packages is available on pkg.go.dev.\nHNSW Index\nThe hnsw package provides an implementation of the HNSW graph index introduced\nby Malkov and Yashunin (2016).\nHNSW organizes data into multiple layers of a proximity graph, which allows fast approximate nearest neighbor searches\nby greedily traversing the graph from top to bottom.\nThe index has the following parameters:\n\nM: Controls the maximum number of neighbor connections per node. Higher values improve accuracy but increase\nmemory and indexing time (typical range: 5–48).\nEf: Defines search breadth during insertion and searching. Higher values improve accuracy but\nincrease computational cost (typical range: 10–200).\n\nPQIVF Index\nThe pqivf package provides an implementation of the PQIVF index introduced\nby Jegou et al. (2011).\nPQIVF first clusters data into coarse groups (inverted lists), then compresses vectors in each cluster using product\nquantization.\nThis allows fast approximate nearest neighbor searches by limiting queries to relevant clusters and\nefficiently comparing compressed vectors, which reduces search time and storage requirements.\nThe index has the following parameters:\n\ncoarseK: Controls the number of coarse clusters for initial quantization. Higher values improve search performance\nbut increase indexing time (typical range: 50–4096).\nnumSubquantizers: Determines the number of subspaces for product quantization. More subquantizers improve\ncompression and accuracy at the cost of increased indexing time (typical range: 4–16).\npqK: Sets the number of codewords per subquantizer. Higher values increase accuracy and storage usage (typical\nvalue: 256).\nkMeansIters: Number of iterations used to train the product quantization codebooks (recommended value: 25).\n\nRPT Index\nThe rpt package provides an implementation of the RPT index introduced\nby Dasgupta and Freund (2008).\nRPT recursively partitions data using randomly generated hyperplanes to build a tree structure, which allows efficient\napproximate nearest neighbor searches through a tree traversal process.\nThe index has the following parameters:\n\nleafCapacity: Controls the maximum number of vectors stored in each leaf node. Lower values increase tree depth,\nimproving search speed but slightly increasing indexing time (typical range: 5–50).\ncandidateProjections: Number of random projections considered at each tree split. Higher values improve split\nquality at the cost of increased indexing time (typical range: 1–10).\nparallelThreshold: Minimum number of vectors in a subtree to trigger parallel construction. Higher values lead to\nbetter concurrency during indexing but use more memory (typical value: 100).\nprobeMargin: Margin used to determine additional branches probed during searches. Higher values improve recall but\nincrease search overhead because of additional distance computations (typical range: 0.1–0.5).\n\nLogging\nThe verbosity level of logs produced by Hann can be controlled using the HANN_LOG environment variable.\nPossible values include:\n\n0, false, or off to disable logging altogether;\nfull or all to enable full logging (DEBUG level);\nUse any other value (including not setting the HANN_LOG environment variable) to enable basic logging (INFO level;\ndefault behavior).\n\nRandom Seed\nFor more consistent indexing and search results across different runs, set the HANN_SEED environment variable to an\ninteger.\nThis will initialize the random number generator, but some variations are still possible (for example, due to\nmultithreading).\n\nContributing\nSee CONTRIBUTING.md for details on how to make a contribution.\nLogo\nThe logo is named the \"Hiking Gopher\" and was created by Egon Elbre.\nLicense\nHann is licensed under the MIT License (LICENSE).",
    "summary": {
      "en": "**Hann: A Fast Nearest Neighbor Search Library for Go**\n\nHann is a high-performance library designed for approximate nearest neighbor (ANN) searches in Go. It allows efficient similarity searches in high-dimensional spaces using different index structures, including:\n\n- **HNSW (Hierarchical Navigable Small World)**\n- **PQIVF (Product Quantization Inverted File)**\n- **RPT (Random Projection Tree)**\n\n**Key Features:**\n- Unified interface for various index types.\n- Support for vectors of any dimension.\n- Fast distance calculations using SIMD (AVX) instructions.\n- Capability for bulk vector operations (insertion, deletion, updates).\n- Ability to save and load indexes from disk.\n\n**Index Performance:**\n- HNSW: Moderate space and build complexity, fast in average search time.\n- PQIVF: Efficient for large datasets, supports clustering.\n- RPT: Good for recursive partitioning and tree-based searches.\n\n**Supported Distances:**\n- HNSW supports various distance metrics (Euclidean, Manhattan, etc.), with options for normalization.\n- PQIVF and RPT support only Euclidean distance.\n\n**Installation:**\nTo install Hann, use:\n```\ngo get github.com/habedi/hann@main\n```\nIt requires Go 1.21+, a C/C++ compiler, and AVX support.\n\n**Examples and Datasets:**\nHann provides example files for using different indexes and datasets. Large datasets may require substantial memory.\n\n**Documentation:**\nDetailed documentation is available on pkg.go.dev, explaining the implementations and parameters for each index type.\n\n**Logging and Configuration:**\nLogging can be controlled via the HANN_LOG environment variable, and consistent results can be achieved by setting the HANN_SEED variable.\n\n**License:**\nHann is licensed under the MIT License. \n\nFor contributions and more details, refer to the contributing guidelines.",
      "ko": "Hann은 Go 언어로 작성된 고성능 근접 이웃 검색 라이브러리입니다. 이 라이브러리는 다양한 인덱스 구조를 사용하여 고차원 공간에서 효율적인 유사성 검색을 가능하게 합니다. 지원하는 인덱스 구조로는 HNSW(계층적 탐색 가능한 작은 세계), PQIVF(제품 양자화 역 파일), RPT(무작위 프로젝션 트리)가 있습니다.\n\nHann의 주요 특징으로는 다양한 인덱스 유형에 대한 통합 인터페이스 제공, 모든 차원의 벡터 지원, SIMD(AVX) 명령어를 이용한 빠른 거리 계산, 대량 벡터 작업(삽입, 삭제, 업데이트) 기능, 디스크에서 인덱스를 저장하고 불러오는 기능이 있습니다.\n\n인덱스 성능 측면에서 HNSW는 적당한 공간과 구축 복잡성을 가지며 평균 검색 시간이 빠릅니다. PQIVF는 대규모 데이터셋에 효율적이며 클러스터링을 지원합니다. RPT는 재귀적 분할 및 트리 기반 검색에 적합합니다.\n\nHNSW는 유클리드 거리, 맨하탄 거리 등 다양한 거리 측정 방법을 지원하며, 정규화 옵션도 제공합니다. 반면 PQIVF와 RPT는 유클리드 거리만 지원합니다.\n\nHann을 설치하려면 다음 명령어를 사용하면 됩니다. go get github.com/habedi/hann@main. 이 라이브러리는 Go 1.21 이상, C/C++ 컴파일러, AVX 지원이 필요합니다.\n\nHann은 다양한 인덱스와 데이터셋을 사용하는 예제 파일을 제공합니다. 대규모 데이터셋은 상당한 메모리를 요구할 수 있습니다.\n\n자세한 문서는 pkg.go.dev에서 확인할 수 있으며, 각 인덱스 유형의 구현 및 매개변수에 대한 설명이 포함되어 있습니다.\n\n로깅은 HANN_LOG 환경 변수를 통해 제어할 수 있으며, HANN_SEED 변수를 설정하면 일관된 결과를 얻을 수 있습니다.\n\nHann은 MIT 라이선스 하에 배포됩니다. 기여 및 더 많은 정보는 기여 가이드라인을 참조하시기 바랍니다.",
      "ja": "Hannは、Go言語用に設計された高性能な近似最近傍検索ライブラリです。このライブラリは、高次元空間における効率的な類似性検索を可能にし、さまざまなインデックス構造を使用します。主なインデックス構造には、HNSW（階層的ナビゲーション小世界）、PQIVF（プロダクト量子化逆ファイル）、RPT（ランダム投影木）があります。\n\nHannの主な特徴には、さまざまなインデックスタイプに対する統一されたインターフェース、任意の次元のベクトルのサポート、SIMD（AVX）命令を使用した高速な距離計算、ベクトルの一括操作（挿入、削除、更新）の能力、ディスクからのインデックスの保存と読み込みが含まれます。\n\nインデックスの性能については、HNSWは適度なメモリ使用量と構築の複雑さを持ち、平均検索時間が速いです。PQIVFは大規模データセットに対して効率的で、クラスタリングをサポートします。RPTは再帰的な分割と木構造の検索に適しています。\n\nサポートされている距離については、HNSWはユークリッド距離やマンハッタン距離など、さまざまな距離指標をサポートし、正規化のオプションもあります。一方、PQIVFとRPTはユークリッド距離のみをサポートしています。\n\nHannをインストールするには、次のコマンドを使用します。go get github.com/habedi/hann@main。Go 1.21以上、C/C++コンパイラ、AVXサポートが必要です。\n\nHannは、異なるインデックスやデータセットを使用するためのサンプルファイルを提供しています。大規模なデータセットは、かなりのメモリを必要とする場合があります。\n\n詳細なドキュメントはpkg.go.devで入手可能で、各インデックスタイプの実装やパラメータについて説明しています。\n\nログの管理はHANN_LOG環境変数を通じて行え、HANN_SEED変数を設定することで一貫した結果を得ることができます。\n\nHannはMITライセンスの下で提供されています。貢献や詳細については、貢献ガイドラインを参照してください。"
    }
  },
  {
    "id": "4ea41d504e487ba9",
    "title": {
      "en": "The Lost Towers of the Guelph-Ghibelline Wars",
      "ko": "잃어버린 전쟁의 탑들",
      "ja": "失われた塔の物語"
    },
    "type": "story",
    "url": "https://www.exurbe.com/the-lost-towers-of-the-guelph-ghibelline-wars/",
    "score": 113,
    "by": "wallflower",
    "time": 1742734721,
    "content": "The Lost Towers of the Guelph-Ghibelline Wars\n\n\t\t Posted by\n\n\t\t\t\t exurbe\n\n\t\t\ton\n\n\t\t\t\t\t January 15, 2025\n\n\t\t\t\t Florence, History, Inventing the Renaissance, Italy\n\n\t\t\t\t 12\n\nLooks fake, doesn’t it? This implausible Medieval forest of towers, as dense as Manhattan skyscrapers, is our best reconstruction of the town of Bologna at its height, toward the end of the Medieval Guelph-Ghibelline wars. We don’t see many such towers today… or think we don’t, but actually their remnants are all over Italy.\nOften when in Florence one sees buildings like this, where one section is rough stone standing out amid stucco neighbors.\n\nThese are actually the bottom nubs of Medieval stone towers. The town of San Gimigniano (below) is famous for having several still intact. Wealthy families built these as mini-fortresses within the city, where they could defend against riots, enemy families (think Montagues and Capulets) and invasion:\n\nSigns of wealth and prestige, these all-stone buildings were also fireproof, leading to a terrible but effective tactic: take your family, treasures & goods up into your tower then set fire to enemies’ homes and let the city burn around you while you sit safe above. This was VERY BAD for cities.\nstreet corner in San Gimigniano\nAfter many disasters, Florence’s solution was to BAN private buildings over a certain height, forcing everyone who had a tower to knock the top off down to regulation height, leaving these recognizable stone nubs all around the city. This round one below is the oldest (now a restaurant).\n\nMy favorite tower stub is this one, in Via dei Cerchi. I lived on the top floor for a year as a grad student, up 111 steps! I had calves of steel by spring, but the views from the top looked like someone had put a poster of Florence on the wall except it was a window!\n\nOnly city buildings were allowed to exceed the mandated height, which is why Florence’s skyline is now all special buildings: monastery bell towers, the cathedral & baptistery, Orsanmichele the city’s granary (tall to keep grain away from water & mice), the seat of government, and one special guy…\n\nThe tower on the right here is part of Bargello, the prison & police fortress, but it didn’t start that way. It was built by a private family, who sold it to the city when the law banning towers was passed, and the city incorporated it into their prison fort.\n\nThe city jail had to be a fortress in case someone from a powerful family was arrested and the family sent goons to break them out (those guys who bite their thumbs in the opening scene of Romeo & Juliet would *totally* have stormed the jail to bust Romeo out!).\n\nIn this photo you can see how the brick battlements are a later addition, added to the tower as part of its transformation from private fortress to public.\n\nWhat did Florence look like back when it had all its towers? Its long-time ally across the mountains Bologna is famous for still having two intact towers, but in the Middle Ages Bologna was known as the City of 100 Towers because so many families built them. The reconstructions look absolutely incredible. Florence didn’t have so many but did have dozens, so the richest part of the city center would have looked much like this. Much to the despair of the city fire brigade!\n\nSo, whether in a film or on the street, if you ever see a historic Italian city and walk along a block where for some reason one chunk of wall is stone and all the others smooth, you’re probably looking at a relic of the faction feuds that Guido Ruggiero aptly calls “The Italian 300 Years’ War.”\n\nI talk about this long war in “Inventing the Renaissance,” one of many points of continuity which show how the supposed difference between a bad “Dark Ages” and Renaissance “golden age” is 100% propaganda, but fascinating propaganda with a deep history.\nAnd I’ll share more tidbits like over the coming days as we countdown to the book’s release!\n\n                FacebookLiveJournalTwitterRedditLinkedInTumblrPush to KindleShare\n\n\t Bologna, Florence, Guelph, Inventing the Renaissance\n\n\t\t 12 Responses to “The Lost Towers of the Guelph-Ghibelline Wars”\n\n\t\t\t\tOllie said:\n\n\t\t\t 01-16-2025 11:00 AM\n\n\t\t\t\tYour photography is pretty great.\n\n\t\t\t\tJasonium said:\n\n\t\t\t 01-16-2025 12:49 PM\n\n\t\t\t\tI would like to commend you on your restraint. You had the perfect opportunity to write, “Looks like a bunch of baloney, doesn’t it?” in your opening, and you resisted.\n\n\t\t\t\tAbout that history you were taught… – Pylimitics said:\n\n\t\t\t 01-20-2025 11:55 AM\n\n\t\t\t\t[…] an era we know much less about than we think we do, and most of what we do think we know is wrong. The photo is from her site Ex Urbe, where you can read more about these things, and see some photos of modern-day Bologna and the […]\n\n\t\t\t\tMedieval Skyscrapers, Cars for Justice, and Russian Noir - JSTOR Daily said:\n\n\t\t\t 01-21-2025 1:45 PM\n\n\t\t\t\t[…] The Skyscrapers of Medieval Italy (Ex Urbe) by Ada Palmer In medieval Italy, factional wars led powerful families to build huge towers that served as little urban fortresses. Their stubs are still there today. […]\n\n\t\t\t\t2:00PM Water Cooler 1/21/2025 | naked capitalism said:\n\n\t\t\t 01-21-2025 7:12 PM\n\n\t\t\t\t[…] Lost Towers of the Guelph-Ghibelline Wars” [Ex Urbe]. “Looks fake, doesn’t it? This implausible Medieval forest of towers, as dense as […]\n\n\t\t\t\t2:00PM Water Cooler 1/21/2025 | naked capitalism – Buddy CRM News Test said:\n\n\t\t\t 01-21-2025 11:33 PM\n\n\t\t\t\t[…] Lost Towers of the Guelph-Ghibelline Wars” [Ex Urbe]. “Looks fake, doesn’t it? This implausible Medieval forest of towers, as dense as Manhattan […]\n\n\t\t\t\t2:00PM Water Cooler 1/21/2025 | bare capitalism - Lucky to know | All rights reserved. said:\n\n\t\t\t 01-22-2025 12:22 AM\n\n\t\t\t\t[…] Misplaced Towers of the Guelph-Ghibelline Wars” [Ex Urbe]. “Seems to be faux, doesn’t it? This implausible Medieval forest of towers, as dense as […]\n\n\t\t\t\tGorgeous Gary said:\n\n\t\t\t 01-22-2025 2:06 AM\n\n\t\t\t\tI feel like a certain structural engineer of your acquaintance will find this post quite intriguing! (LOL)\n\n\t\t\t\t2:00PM Water Cooler 1/21/2025 | naked capitalism - Neclink said:\n\n\t\t\t 01-22-2025 2:42 AM\n\n\t\t\t\t[…] Lost Towers of the Guelph-Ghibelline Wars” [Ex Urbe]. “Looks fake, doesn’t it? This implausible Medieval forest of towers, as dense as Manhattan […]\n\n\t\t\t\t2:00PM Water Cooler 1/21/2025 | naked capitalism - Agoku said:\n\n\t\t\t 01-22-2025 5:30 AM\n\n\t\t\t\t[…] Lost Towers of the Guelph-Ghibelline Wars” [Ex Urbe]. “Looks fake, doesn’t it? This implausible Medieval forest of towers, as dense as Manhattan […]\n\n\t\t\t\tThe Lost Towers of the Guelph-Ghibelline Wars – Mirabilis.ca said:\n\n\t\t\t 01-25-2025 10:37 PM\n\n\t\t\t\t[…] From Ex Urbe: The Lost Towers of the Guelph-Ghibelline Wars. […]\n\n\t\t\t\tEx Urbe said:\n\n\t\t\t 01-27-2025 4:04 PM\n\n\t\t\t\t[…] a post last week, I talked about how Renaissance towns used to be full of tall stone towers, built by rich families […]\n\n\t\t\t\tComments are closed.",
    "summary": {
      "en": "The article discusses the historical towers built during the Guelph-Ghibelline wars in Medieval Italy, particularly focusing on Bologna and Florence. These towers served as fortresses for wealthy families who needed protection from riots and enemies. They were often used in battles, where families would retreat to the safety of their towers while setting fire to rival neighborhoods.\n\nDue to the dangers posed by these tall structures, Florence eventually banned towers over a certain height, leading to many being shortened. Today, remnants of these towers can still be seen as stone bases among modern buildings. The article highlights San Gimignano as a town that still has several intact towers and notes that Florence's skyline is now characterized by special buildings like churches and government structures instead of private towers.\n\nThe author reflects on the misconception that there was a clear divide between the so-called \"Dark Ages\" and the Renaissance, suggesting that the history of these towers illustrates a more complex narrative. The article is part of a countdown to the author's upcoming book, \"Inventing the Renaissance.\"",
      "ko": "이 기사는 중세 이탈리아의 구엘프와 기벨린 전쟁 동안 세워진 역사적인 탑들에 대해 다루고 있으며, 특히 볼로냐와 피렌체에 초점을 맞추고 있습니다. 이 탑들은 부유한 가문들이 폭동과 적으로부터 보호받기 위해 세운 요새 역할을 했습니다. 전투 중에는 가문들이 적의 동네에 불을 지르면서 자신의 탑으로 후퇴하기도 했습니다.\n\n이러한 높은 구조물들이 가져오는 위험 때문에 피렌체는 결국 일정 높이 이상의 탑 건축을 금지하게 되었고, 많은 탑들이 낮아지게 되었습니다. 오늘날에도 현대 건물 사이에서 이 탑들의 돌 기초가 남아 있는 모습을 볼 수 있습니다. 기사는 산 지미냐노를 언급하며, 이곳에는 여전히 여러 개의 온전한 탑이 남아 있다고 전합니다. 현재 피렌체의 스카이라인은 개인 탑 대신 교회와 정부 건물 같은 특별한 건축물로 특징지어집니다.\n\n저자는 이른바 \"암흑 시대\"와 르네상스 사이에 명확한 경계가 있었다는 오해에 대해 반성하며, 이러한 탑들의 역사가 더 복잡한 이야기를 보여준다고 제안합니다. 이 기사는 저자의 곧 출간될 책 \"르네상스의 발명\"에 대한 카운트다운의 일환으로 작성되었습니다.",
      "ja": "この記事では、中世イタリアのグエルフとギベリンの戦争の際に建てられた歴史的な塔について、特にボローニャとフィレンツェに焦点を当てています。これらの塔は、暴動や敵からの保護が必要な裕福な家族のための要塞として機能しました。戦闘の際には、家族が塔の安全な場所に退避し、敵の地域に火を放つこともありました。\n\nこれらの高い構造物がもたらす危険性から、フィレンツェでは一定の高さを超える塔が禁止され、多くの塔が短くされました。現在でも、現代の建物の中に石の基礎として残された塔の跡を見ることができます。この記事では、サン・ジミニャーノという町がいくつかの完全な塔を持っていることを紹介し、フィレンツェのスカイラインがもはや私的な塔ではなく、教会や政府の建物などの特別な建物によって特徴づけられていることを指摘しています。\n\n著者は、「暗黒時代」とルネサンスの間に明確な区分があったという誤解について考察し、これらの塔の歴史がより複雑な物語を示していることを示唆しています。この記事は、著者の新しい本「ルネサンスの発明」に向けたカウントダウンの一部です。"
    }
  },
  {
    "id": "e6cec4fc32fec04b",
    "title": {
      "en": "We're Still Not Done with Jesus",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://www.newyorker.com/magazine/2025/03/31/miracles-and-wonder-elaine-pagels-book-review-heretic-catherine-nixey",
    "score": 53,
    "by": "diodorus",
    "time": 1742873028,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "1d73542f2e363dfb",
    "title": {
      "en": "Borne Back Ceaselessly into the Past: Fitzgerald, Gatsby and WWI",
      "ko": "과거로의 회귀: 피츠제럴드와 개츠비",
      "ja": "過去への帰還：フィッツジェラルドとギャツビー"
    },
    "type": "story",
    "url": "https://www.theworldwar.org/learn/about-wwi/borne-back-ceaselessly-past-fitzgerald-gatsby-and-wwi",
    "score": 44,
    "by": "gmays",
    "time": 1742915516,
    "content": "Image\n\n            “The Great Gatsby,” written by F. Scott Fitzgerald in 1925, offers a vivid portrayal of post-World WarI America.Fitzgerald, and the characters in his novel, were deeply shaped by the Great War. By placing the story in its historical context, he reveals the complex societal shifts in the United States in the years afterWWI.\n\n      F. Scott Fitzgerald and WWI\n\n            Born in September 1896, Francis Scott Key (F. Scott) Fitzgerald was 20 years old and attending Princeton University in 1917. He had been courting a young girl named Ginevra King. (That failed relationship is thought to be one of the inspirations for the character Daisy in “The Great Gatsby.”) Fitzgerald was already writing for university clubs and nearing graduation when Congress declared war. Despite this, he chose to drop out of Princeton to join the U.S. military, accepting a commission as a second lieutenant in the U.S.Army.\n\n    Image\n\nPhotograph of F. Scott Fitzgerald from The Nassau Herald, published in 1917 by Princeton University. Source: Mudd Manuscript Library\n\n            The Army assigned Fitzgerald to the Officer Training Corps at Fort Leavenworth, Kansas, where he was trained as an infantry officer. He wrote his first draft for “This Side of Paradise” during this period – and (as he later told it to the Saturday Evening Post) was reprimanded for writing it instead of studying infantry tactics by his training officer, future five-star general and 34th President of the United States Dwight D.Eisenhower.\n\n    Image\n\nA postcard showing life at Fort Leavenworth, Kansas: soldiers lining up with mess kits; soldiers having their goods and cots inspected; a practice trench; and two men having breakfast in a tent. Object ID: 1998.58.47\n\n    Image\n\nPhoto of Lieutenant Dwight D. Eisenhower and his wife, Mamie, taken during WWI. Eisenhower never left the U.S. during WWI but was responsible for training soldiers across various camps. In the interwar years, Eisenhower continued his military career and by the outbreak of WWII, was a Brigadier General. In December 1944, he became General of the Army. Source: Library of Congress\n\n            In June 1918, Fitzgerald was on the move. He went with the 9th Division to Camp Sheridan, a mobilization camp just outside Montgomery, Alabama.By day, his brigade was busy building new units, training recruits and draftees and preparing to ship overseas to the Western Front – typical for many of the newly-activated units of the American Expeditionary Forces (A.E.F.). By night, young officers found themselves with time on their hands to explore Montgomery and take in the social life. For Fitzgerald, this relatively calm period gave him time to edit his manuscript for “This Side ofParadise.”\n\n    Image\n\nAn oversized souvenir postcard depicting drawings of Camp Sheridan, 1917. Object ID: 2006.74.2b\n\n            It was during one of those jaunts to Montgomery when he met his future wife, Zelda Sayre. Their stormy relationship is thought to be another inspiration for Daisy in “The Great Gatsby.” He even appropriates a quote from Zelda about their own daughter as one of Daisy’s lines.\n\n    Image\n\nPhotograph of a young Zelda Sayre as a senior in high school, 1918. Source: Alabama Dept. of Archives and History\n\n            “I’m glad it’s a girl. And I hope she’ll be a fool—that’s the best thing a girl can be in this world, a beautiful littlefool.”—Daisy Buchanan in “The Great Gatsby,” originally spoken by ZeldaFitzgerald\n\n    Image\n\nPhotograph of F. Scott Fitzgerald in uniform, commissioned by himself in 1917. Source: F. Scott Fitzgerald Archives\n\n            On Oct.26, 1918, Fitzgerald and his unit were moved again – this time to Camp Mills on Long Island, New York, with plans to be sent to France. Fate would intervene: the Armistice was signed on Nov.11. He never went “OverThere.”Fitzgerald always seemed to regret never experiencing the war firsthand, as suggested in his 1936 story “I Didn’t Get Over.” Yet World WarI, its veterans and the new world that emerged from it deeply shaped his post-war writings, including “This Side of Paradise” (1920), “May Day” (1920), “The Crack-Up” (1936), “The Beautiful and the Damned” (1922) and “Winter Dreams” (1922). And of course “The Great Gatsby,” published in1925.\n\n    Image\n\nOriginal cover for \"The Great Gatsby.\" Click to read on the Gutenberg Project\n\n            Based on a True Story? Historical Context for “The Great Gatsby” Characters\n\n            Jay GatsbyThe rumors fly around Gatsby’s social circle, tarnishing hisreputation:“A German spy during the war,” somesay.He is “a nephew or a cousin of KaiserWilhelm’s.”There are even whispers Gatsby is a murderer connected “to VonHindenburg.”The novel later reveals his true identity as a U.S. WWI veteran, but at that time in history, accusations of German loyalty in the United States could ruin lives. German and Austro-Hungarian nationals in the U.S. faced bans, registration requirements and restrictions on firearms and communications devices. Law enforcement arrested many under the 1798 Alien Enemies Act, detaining over 10,000 people and interning around 2,300 German-born individuals at camps like Fort Oglethorpe in Georgia and Fort Douglas in Utah. Among those arrested were ordinary citizens, often involved in labor disputes or “radical”politics.\n\n    Image\n\nDormitory of Germans interned at Fort Douglas. Source: Library of Congress\n\n    Image\n\nPolitical cartoon published in the New York Times in 1915 after the sinking of the RMS Lusitania. Source: New York Times\n\n            Anti-German sentiment lingered into 1921 – the novel’s setting – affecting Gatsby’s image even at his funeral. Some characters know of his U.S. military service, but the facts of his stories are questionable.Gatsby served as a first lieutenant in the 7th Infantry Regiment at Camp Taylor inKentucky. The 7th Infantry Regiment (part of the 3rd Division) fought in the Meuse-Argonne Offensive in France, which was a crucial battle in WWI. The entire 3rd Division was sent to hold the line for the Allies, while the 5th Division advanced to capture more land from the Central Powers. If Gatsby were involved in anything heroic, it would have been during thisoperation.\n\n    Image\n\nA photograph taken by the Signal Corps of the 3rd Division shelling Bois de Foret, Oct.18, 1918. The town of Cunel was in this area, which the division was tasked with holding. Object ID: 2010.125.42\n\n    Image\n\nPhotograph of battlefield in the Argonne Forest, including a large plume of smoke, 1918. Object ID: 1985.47.5\n\n            Yet his heroic stories contain historical inconsistencies. He claims to have led a machine gun battalion deep into enemy lines, but such a unit would have been separate from infantry regiments – as the character Nick Carraway, a veteran of the 9th Machine Gun Battalion, wouldknow.\n\n            “In the Argonne Forest I took the remains of my machine-gun battalion so far forward that there was a half mile gap on either side of us where the infantry couldn’t advance. We stayed there two days and two nights, a hundred and thirty men with sixteen Lewis guns, and when the infantry came up at last they found the insignia of three German divisions among the piles ofdead.”—Jay Gatsby telling his story to Nick Carraway\n\n            For Gatsby’s account to be true, he would have had to be reassigned andretrained.Another inconsistency: Gatsby describes his regiment’s firearm as the Lewis gun, which would raise doubts for Nick since over 80 percent of the machine guns used by the U.S. Army in 1918 were Vickers field machine guns. The likelihood of an American unit using a Lewis gun on the Western Front in France in late 1918 would have been verylow.\n\n    Image\n\nPhotograph of a Vickers machine gun. Object ID: 1926.12.9\n\n    Image\n\nPhotograph of a Lewis light machine gun. Object ID: 1992.56.19\n\n            “I was promoted to be a major, and every Allied government gave me a decoration—even Montenegro, little Montenegro down on the AdriaticSea!”Little Montenegro! [Gatsby] lifted up the words and nodded at them—with his smile. The smile comprehended Montenegro’s troubled history and sympathized with the brave struggles of the Montenegrin people. It appreciated fully the chain of national circumstances which had elicited this tribute from Montenegro’s warm little heart. My incredulity was submerged in fascination now; it was like skimming hastily through a dozenmagazines.—Nick Carraway listening to Jay Gatsby’sstory\n\n    Image\n\nMontenegro medal awarded to Peter Bulatovich for military bravery. Source: National Museum of American History\n\n            Gatsby shows Nick a medal awarded by Montenegro, a small nation that faced significant challenges in the early 20th century. At the end of the Second Balkan War in 1913, the Central Powers were negotiating to split Montenegro between Albania and Serbia. However, when Archduke Franz Ferdinand of Austria-Hungary was assassinated on June28, 1914, the split had not been finalized, leaving Montenegro’s leaders to make a difficult decision during the July Crisis of 1914. Initially, they considered neutrality but ultimately chose to join the Allied Powers to support Serbia andRussia.\n\n    Image\n\nMap of the Kingdom of Montenegro in 1914. Source: Manatū Taonga — Ministry for Culture and Heritage\n\n            Montenegro struggled throughout 1914 and 1915 to maintain its independence. By January1916, it was forced to disband its army as the King fled the country. With no political authority remaining, peace negotiations were impossible, and the Austro-Hungarian military occupied Montenegro. After the Armistice, the fate of the nation was in the hands of the Allies. Although U.S. President Woodrow Wilson favored King Nikola and an independent Montenegro, the country’s occupation by Serbia led to its dissolution and integration into neighboring states in 1919.\n\n    Image\n\nPrincesses Xenia and Vera of Montenegro working at a canteen for Allied soldiers. Object ID: 2006.33.4.6\n\n            Several characters refer to Gatsby as an “Oxford man,” and he shares a photo of himself with a cricket bat among other scholars in a courtyard at the university. He later tells Tom Buchanan that he spent five months at Oxford in 1919, claiming,“It was an opportunity they gave to some of the officers after the Armistice. We could go to any of the Universities in England orFrance.”\n\n    Image\n\nA cricket team of British soldiers, recalling Gatsby’s photo with a cricket bat, though he was in a more formal setting at Oxford. Object ID: 2017.66.1.57\n\n            Gatsby is referring to a portion of General Orders No. 30 from the General Headquarters of the A.E.F. on Feb.13, 1919, a program which aimed to promote education and gave selected officers “the privilege of attending educational institutions of the nations associated with the United States in this war. Arrangements have already been made whereby selected members of the A.E.F. may be ordered to detached service in attendance on French and British universities during the current spring term which will terminate June30, 1919.”\n\n            Nick CarrawayThroughout the novel, Fitzgerald writes very little about Nick Carraway’s experiences during the Great War. He was in the 1st Division of the 9th Machine Gun Battalion, which was also part of the 3rd Division that Gatsby was assigned to. Nick shares almost nothing with any other character about his service and does not bring the reader into those details of his life. There could be a variety of reasons for this, but we know some soldiers who came home from the war were discouraged from staying too attached to emotions rooted in theirexperiences.\n\n            The 9th Machine Gun Battalion participated in six battles in France from June1918 through October1918, one of which would have placed Nick on the same front that Gatsby describes, though in a different area. The entire 3rd Division had a total of 16,117 casualties. Machine gunners’ missions were “primarily to hold their positions in spite of all enemy pressure, even after being completely surrounded,” which implies that holding the position was more important than their individuallives.\n\n    Image\n\nPhotograph of the 315th Machine Gun Battalion advancing through the woods. Meuse, France, Oct.29, 1918. Object ID: 2014.131.74\n\n    Image\n\nPhotograph of a machine gun crew about to open fire while taking cover in a shell crater, 1918. Object ID: 2006.33.2.1\n\n            We don’t know what Nick went through, but WWI changed the lives of its veterans forever.Some soldiers returned home physically maimed – yet even they were pressured to figure out how to continue life as normal. Soldiers with mental and emotional trauma struggled in different ways to go back to life as it was before the war. “Shell shock” emerged as a new diagnosis, describing symptoms now associated with post-traumatic stress disorder (PTSD).\n\n    Image\n\nPoster encouraging disabled veterans to go back to work. Object ID: 1920.1.235\n\n    Image\n\n1919 U.S. poster aimed at veterans. Object ID: 2007.207.1\n\n            Daisy Buchanan and Jordan BakerFitzgerald does not provide much of the women’s wartime backstories (though their characterizations might have been greatly different if the novel had been set pre-WWI). Nick does learn of Daisy’s contribution during the GreatWar:\n\n            [Daisy] asked me if I was going to the Red Cross and make bandages. I was. Well then, would I tell them that she couldn’t come thatday?—Jordan Baker telling a story about Daisy Buchanan\n\n            Although Fitzgerald made only one passing reference to it, American women significantly contributed to the wareffort.\n\n            Not only did they volunteer for organizations like the Red Cross, Salvation Army and the YMCA/YWCA at home and overseas, but many entered the paid workforce for the first time, filling roles as factory workers, switchboard operators, technicians and jobs in countless otherindustries.\n\n    Image\n\nPhotograph of male and female factory workers canning corn beef hash for American soldiers. Object ID: 2006.33.5.46\n\n            Over 20,000 women served in the U.S. Army Nurse Corps. Others joined the U.S. Navy as yeomanettes or “Yeoman (F),” working as truck drivers, mechanics, translators and radio operators while receiving the same pay as their malepeers.\n\n    Image\n\nA Navy recruitment poster. A woman named Helen O’Neill posed for the artwork while she was a civilian employee in the secretary of the Navy’s office. When the Navy started accepting women, she joined as a yeoman. Object ID: 1920.1.103\n\n            The Signal Corps Female Telephone Operators Unit, established by General John J. Pershing, improved battlefield communications on the Western Front – a key to Alliedvictory.\n\n    Image\n\nPhotograph of U.S. Signal Corps Female Telephone Operators, also known as the Hello Girls, working three kilometers (1.8 miles) from the trenches in France. Object ID: 1984.70.4\n\n            In their homes and communities, women conserved food, ran Liberty Bond drives and generally kept up positive morale andpatriotism.\n\n    Image\n\nPoster calling on women to help the American Red Cross and soldiers by making bandages, just as Daisy and Jordan did during the war. Object ID: 2009.112.2\n\n            The details of the characters’ lives reflect the changes that WWI made in society: Daisy and Jordan have the right to vote, for example. Congress ratified the 19th Amendment on August 18, 1920, a civic landmark that granted most women the right to votenationwide.\n\n    Image\n\nWomen protesting for their right to vote outside of the White House, January 1919. Source: Library of Congress\n\n            It wasn’t just a political whim of the 1920s; activists had agitated for more than a century for this cause, and the enormous efforts women went to during World WarI played a significant role in the passage of the amendment. As President Wilson said, “we have made partners of the women in this war... Shall we admit them only to a partnership of suffering and sacrifice and toil and not to a partnership of privilege andright?”\n\n    Image\n\nPhotograph of women in Dayton, Ohio learning how to vote in preparation for the next election, October 1920. Source: NCR Archives at Dayton History\n\n            Daisy and Jordan also live more freely than many women could before the war. Jordan stays single, becomes a competitive golfer and wears whatever she likes. How? Women transformed traditional gender roles when they proved their capabilities in the workforce during the war. The casual acceptance of women wearing pants, as Jordan does when she plays golf, can be traced back to women in positions such as ambulance driving who needed practical clothing for their work.Throughout the Roaring Twenties women used fashion and work, and the social freedoms extended to them during wartime, to push for moreindependence.\n\n    Image\n\nPhotograph of Zelda and F.Scott Fitzgerald in 1920. Zelda was considered to be a fashion icon of the flapper style in the 1920s. Source: Princeton Library Archives\n\n    Image\n\nPhotograph of Edith Cummings, the women’s championship golfer who acted as inspiration for Jordan Baker. Source: Vogue Magazine\n\n            The historical and cultural context of 1920s America paints Gatsby, Nick, Daisy and Jordan’s stories more vividly for thereader.But understanding that context also shows that as the Great War shaped F.Scott Fitzgerald and the world of his novel, so too does it shape the world oftoday.",
    "summary": {
      "en": "\"The Great Gatsby,\" written by F. Scott Fitzgerald in 1925, reflects the changes in American society after World War I. Fitzgerald’s experiences during the war influenced his writing, including the novel itself.\n\nFitzgerald, born in 1896, left Princeton University to join the military in 1917. While in training, he began writing and met his future wife, Zelda Sayre, whose tumultuous relationship inspired the character Daisy Buchanan in the novel. He was stationed at various camps but never saw combat, which he regretted.\n\nThe character Jay Gatsby, a WWI veteran, faces rumors about his past, highlighting the anti-German sentiment of the time. Despite his military service, Gatsby's stories about his heroism are questionable, reflecting the inconsistencies veterans faced in society.\n\nOther characters, like Nick Carraway, also served in the war but share little about their experiences, illustrating the emotional struggles many veterans faced upon returning home. Women like Daisy and Jordan Baker contributed significantly to the war effort, entering the workforce and supporting the military, which helped advance women's rights, including the right to vote.\n\nOverall, Fitzgerald's characters and their lives are deeply connected to the societal shifts of the 1920s, shaped by the war's impact, illustrating how history influences both literature and contemporary life.",
      "ko": "\"위대한 개츠비\"는 1925년 F. 스콧 피츠제럴드가 쓴 소설로, 제1차 세계대전 이후 미국 사회의 변화를 반영하고 있다. 피츠제럴드는 전쟁 중의 경험이 그의 글쓰기, 특히 이 소설에 큰 영향을 미쳤다.\n\n1896년에 태어난 피츠제럴드는 1917년 프린스턴 대학교를 중퇴하고 군에 입대했다. 훈련 중에 그는 글쓰기를 시작했으며, 미래의 아내인 젤다 세이어를 만났다. 그들의 격동적인 관계는 소설 속 캐릭터인 데이지 뷰캐넌에 영감을 주었다. 그는 여러 군사 캠프에서 복무했지만 전투를 경험하지 못한 것을 아쉬워했다.\n\n소설의 주인공 제이 개츠비는 제1차 세계대전 참전자로, 자신의 과거에 대한 소문에 시달린다. 이는 당시의 반독일 감정을 드러내며, 그의 군 복무에도 불구하고 개츠비의 영웅담은 의심스러운 부분이 많아, 참전 용사들이 사회에서 겪는 불일치를 반영하고 있다.\n\n닉 캐러웨이와 같은 다른 캐릭터들도 전쟁에 참전했지만, 그들의 경험에 대해 거의 이야기하지 않는다. 이는 많은 참전 용사들이 고향으로 돌아온 후 겪는 감정적 고통을 보여준다. 데이지와 조던 베이커와 같은 여성들은 전쟁 노력에 크게 기여하며, 노동 시장에 진출하고 군을 지원함으로써 여성의 권리, 특히 투표권을 발전시키는 데 도움을 주었다.\n\n전반적으로 피츠제럴드의 캐릭터와 그들의 삶은 1920년대의 사회적 변화와 깊은 연관이 있으며, 전쟁의 영향으로 형성된 이들은 역사와 문학, 그리고 현대 생활이 어떻게 연결되는지를 보여준다.",
      "ja": "『グレート・ギャツビー』は、F・スコット・フィッツジェラルドが1925年に書いた作品で、第一次世界大戦後のアメリカ社会の変化を反映しています。フィッツジェラルド自身の戦争体験が彼の執筆に影響を与え、この小説にもその影響が見られます。\n\nフィッツジェラルドは1896年に生まれ、1917年に軍に入隊するためにプリンストン大学を中退しました。訓練中に彼は執筆を始め、将来の妻であるゼルダ・セイヤーと出会いました。彼らの波乱に満ちた関係は、小説のキャラクターであるデイジー・ブキャナンに影響を与えました。フィッツジェラルドはさまざまなキャンプに配属されましたが、戦闘には参加せず、それを後悔していました。\n\nキャラクターのジェイ・ギャツビーは、第一次世界大戦の退役軍人であり、彼の過去に関する噂に直面します。これは当時の反ドイツ感情を浮き彫りにしています。彼の軍務にもかかわらず、ギャツビーの英雄的な物語には疑問があり、退役軍人が社会で直面する矛盾を反映しています。\n\n他のキャラクターであるニック・キャラウェイも戦争に従事しましたが、彼の体験についてはあまり語りません。これは、多くの退役軍人が帰国後に抱える感情的な苦悩を示しています。デイジーやジョーダン・ベイカーのような女性たちは、労働力に参加し、軍を支援することで戦争努力に大きく貢献しました。これにより、女性の権利、特に投票権の向上が促進されました。\n\n全体として、フィッツジェラルドのキャラクターと彼らの生活は、1920年代の社会的変化と深く結びついており、戦争の影響によって形成されています。これは、歴史が文学や現代生活にどのように影響を与えるかを示しています。"
    }
  },
  {
    "id": "200ef48890eaf3ff",
    "title": {
      "en": "Show HN: Fingernotes – handwritten notes which become their own preview image",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://fingernotes.com/note/97513380",
    "score": 62,
    "by": "sumolessons",
    "time": 1742711539,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "39377b593bb66aa1",
    "title": {
      "en": "A study reveals that deciduous trees' roots remain active in winter",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://www.creaf.cat/en/articules/deciduous-trees-roots-remain-active-winter",
    "score": 69,
    "by": "bryanrasmussen",
    "time": 1742671996,
    "content": "",
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "6ad84f71b7c8ff6c",
    "title": {
      "en": "The Great Scrape",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://herman.bearblog.dev/the-great-scrape/",
    "score": 11,
    "by": "Tomte",
    "time": 1742985083,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "f17416a31f347ec2",
    "title": {
      "en": "Were large soda lakes the cradle of life?",
      "ko": "거대한 소다호, 생명의 요람?",
      "ja": "巨大ソーダ湖は生命の源か？"
    },
    "type": "story",
    "url": "https://ethz.ch/en/news-and-events/eth-news/news/2025/03/were-large-soda-lakes-the-cradle-of-life.html",
    "score": 48,
    "by": "geox",
    "time": 1742917378,
    "content": "You are here\n\n\t                            Homepage\n\n\t                        chevron_right\n\n\t                                  News & events\n\n\t                              chevron_right\n\n\t                        …\n\n\t                                  ETH News\n\n\t                              chevron_right\n\n\t                                  All articles\n\n\t                              chevron_right\n\n\t                                  2025\n\n\t                              chevron_right\n\n\t                                  03\n\n\t                              chevron_right\n\n\t                              Were large soda lakes the cradle of life?\n\n            Were large soda lakes the cradle of life?\n\n                    Geochemistry and PetrologyResearch\n\n            Life needs sufficient phosphorus. However, the element is scarce, not only today but also at the time of the origin of life. So where was there sufficient phosphorus four billion years ago for life to emerge? A team of origin-of-life researchers has an answer.\n\n            25.03.2025\n\n                by\n\n                Peter Rüegg, Corporate Communications\n\n                    volume_upRead\n\n                    mode_comment\n                    Number of comments\n\n            shareSharetwitterTwitterfacebookFacebooklinkedinLinkedinemailEmaillinkCopy link\n\n\t\t\t      In closed soda lakes, such as Mono Lake in California, phosphorus accumulates to such an extent that it triggers prebiotic chemistry.(Image: Rikk Flohr / AdobeStock)\n\n                \tIn brief\n\n Phosphorus is a key molecule for life, but the element is relatively rare on Earth.\n However, a very high concentration of phosphorus was necessary to set the first chemical reactions in motion that preceded life and led to the formation of important molecules such as RNA.\n Large, phosphorus-rich soda lakes are the most likely places to have met this requirement. Researchers believe that it was in such lakes that prebiotic chemistry began and life emerged.\n\n                Along with nitrogen and carbon, phosphorus is an essential element for life on Earth. It is a central component of molecules such as DNA and RNA, which serve to transmit and store genetic information, and ATP (adenosine triphosphate), which cells need to produce energy.\nPhosphorus may also have played a key role in the origin of life. Certain conditions are needed to trigger the start of the biochemical processes that precede life. One of these is the presence of sufficient phosphorus. Its availability regulates the growth and activities of organisms. Unlike nitrogen or carbon, however, phosphorus is relatively rare at Earth's surface – which was the case in the era before life existed as well as today.\nIt is precisely because phosphorus is rare and so difficult to obtain, yet subject to high demand by living organisms, that scientists have long wondered how life could have arisen at all.\nTo answer this question, they conducted experiments in the laboratory. These showed that prebiotic chemistry requires very high concentrations of phosphorus – about 10,000 times more phosphorus than naturally occurs in water. This raises the question of how and where such high concentrations of phosphorus in water occurred on Earth billions of years ago.\nEarth scientist Craig Walton has a new answer: large soda lakes without natural runoff could maintain phosphorus concentrations for a sufficiently long time, even if life begins to exist in them at some point (and continuously consumes phosphorus). The results of the study have just been published in the journal Science Advances.\nSuch lakes lose water only through evaporation. This means that phosphorus is left in the water instead of being washed away through rivers and streams. As a result, very high concentrations of phosphorus can build up in these soda lakes.\nAs early as 2020, researchers from the University of Washington had suggested that soda lakes could be the cradle of life. Walton has now taken this further. The researcher is investigating questions about the origin of life from a geochemical perspective as part of a Nomis fellowship at ETH Zurich’s Centre for Origin and Prevalence of Life(COPL).\nNot every soda lake is suitable; Walton excludes small ones. “As soon as life develops in them, their phosphorus supply would be depleted faster than it is replenished. This would nip in the bud both the chemical reactions and the developing life,” says Walton. In large soda lakes, on the other hand, the phosphorus concentrations are high enough to sustain both the basic chemical reactions and life over the long term. These high concentrations are achieved through a high volume of inflowing river water, which contains phosphorus, while water only leaves the lake through evaporation. Since phosphorus does not evaporate easily, it stays behind and accumulates in the lake.\nOne example of such a large soda lake is Mono Lake in California. It is about twice the size of Lake Zurich. In Mono Lake, the phosphorus concentration remains constantly high, allowing a wide variety of organisms to flourish. This is crucial because in small lakes, the phosphorus is used up before new amounts can be formed. Phosphorus in Mono Lake is therefore maintained at a high concentration, which means that a lot of phosphorus regularly flows in without the phosphorus content dropping too quickly.\nWalton and his team therefore consider large soda lakes that had a constant high phosphorus supply in the early history of the Earth to have been an ideal environment for the origin of life. The researchers assume that life is more likely to have originated in such large bodies of water than in small pools, as Charles Darwin had suspected.\nThe origin of life could therefore be closely linked to the special environment of large soda lakes, which, due to their geological setting and phosphorus balance, provided ideal conditions for prebiotic chemistry. “This new theory helps to solve another piece of the puzzle of the origin of life on Earth,” says Walton.\n\n                \tReference\n\n                Walton CR, Hao J, Schönbächler M, Shorttle O: Large closed-basin lakes sustainably supplied phosphate during the origins of life, Science Advances, eadq0027(2025). DOI:external page 10.1126/sciadv.adq0027\n\n            Further information\n\n            chevron_right\n            Centre for Origin and Prevalence of Life COPL\n\n            Newsletter subscription\n\n            chevron_right\n            Get the latest ETH News everyday\n\n            Share articletwitterTwitterfacebookFacebooklinkedinLinkedinemailSend article by maillinkCopy link\n\n    Related articlesDo we have cosmic dust to thank for life on Earth?Category: Earth sciences28.02.2024The rocky road to the beginningCategory: Geology03.01.2024Molecular cooperation at the threshold of lifeCategory: Chemistry27.11.2023\n\n                Similar topics\n                ResearchGeochemistry and PetrologyEarth sciencesChemistry\n\n\t\t        CommentsLeave a commentLeave a commentWe are happy if you comment on articles on ETH channels, ask questions or respond to comments from other readers. Please note our comment policy when doing so.CommentNo comments yet\n\nWere large soda lakes the cradle of life?\n\n                    Geochemistry and PetrologyResearch\n\n            Life needs sufficient phosphorus. However, the element is scarce, not only today but also at the time of the origin of life. So where was there sufficient phosphorus four billion years ago for life to emerge? A team of origin-of-life researchers has an answer.\n\n            25.03.2025\n\n                by\n\n                Peter Rüegg, Corporate Communications\n\n                    volume_upRead\n\n                    mode_comment\n                    Number of comments\n\n            shareSharetwitterTwitterfacebookFacebooklinkedinLinkedinemailEmaillinkCopy link\n\n\t\t\t      In closed soda lakes, such as Mono Lake in California, phosphorus accumulates to such an extent that it triggers prebiotic chemistry.(Image: Rikk Flohr / AdobeStock)\n\n                \tIn brief\n\n Phosphorus is a key molecule for life, but the element is relatively rare on Earth.\n However, a very high concentration of phosphorus was necessary to set the first chemical reactions in motion that preceded life and led to the formation of important molecules such as RNA.\n Large, phosphorus-rich soda lakes are the most likely places to have met this requirement. Researchers believe that it was in such lakes that prebiotic chemistry began and life emerged.\n\n                Along with nitrogen and carbon, phosphorus is an essential element for life on Earth. It is a central component of molecules such as DNA and RNA, which serve to transmit and store genetic information, and ATP (adenosine triphosphate), which cells need to produce energy.\nPhosphorus may also have played a key role in the origin of life. Certain conditions are needed to trigger the start of the biochemical processes that precede life. One of these is the presence of sufficient phosphorus. Its availability regulates the growth and activities of organisms. Unlike nitrogen or carbon, however, phosphorus is relatively rare at Earth's surface – which was the case in the era before life existed as well as today.\nIt is precisely because phosphorus is rare and so difficult to obtain, yet subject to high demand by living organisms, that scientists have long wondered how life could have arisen at all.\nTo answer this question, they conducted experiments in the laboratory. These showed that prebiotic chemistry requires very high concentrations of phosphorus – about 10,000 times more phosphorus than naturally occurs in water. This raises the question of how and where such high concentrations of phosphorus in water occurred on Earth billions of years ago.\nEarth scientist Craig Walton has a new answer: large soda lakes without natural runoff could maintain phosphorus concentrations for a sufficiently long time, even if life begins to exist in them at some point (and continuously consumes phosphorus). The results of the study have just been published in the journal Science Advances.\nSuch lakes lose water only through evaporation. This means that phosphorus is left in the water instead of being washed away through rivers and streams. As a result, very high concentrations of phosphorus can build up in these soda lakes.\nAs early as 2020, researchers from the University of Washington had suggested that soda lakes could be the cradle of life. Walton has now taken this further. The researcher is investigating questions about the origin of life from a geochemical perspective as part of a Nomis fellowship at ETH Zurich’s Centre for Origin and Prevalence of Life(COPL).\nNot every soda lake is suitable; Walton excludes small ones. “As soon as life develops in them, their phosphorus supply would be depleted faster than it is replenished. This would nip in the bud both the chemical reactions and the developing life,” says Walton. In large soda lakes, on the other hand, the phosphorus concentrations are high enough to sustain both the basic chemical reactions and life over the long term. These high concentrations are achieved through a high volume of inflowing river water, which contains phosphorus, while water only leaves the lake through evaporation. Since phosphorus does not evaporate easily, it stays behind and accumulates in the lake.\nOne example of such a large soda lake is Mono Lake in California. It is about twice the size of Lake Zurich. In Mono Lake, the phosphorus concentration remains constantly high, allowing a wide variety of organisms to flourish. This is crucial because in small lakes, the phosphorus is used up before new amounts can be formed. Phosphorus in Mono Lake is therefore maintained at a high concentration, which means that a lot of phosphorus regularly flows in without the phosphorus content dropping too quickly.\nWalton and his team therefore consider large soda lakes that had a constant high phosphorus supply in the early history of the Earth to have been an ideal environment for the origin of life. The researchers assume that life is more likely to have originated in such large bodies of water than in small pools, as Charles Darwin had suspected.\nThe origin of life could therefore be closely linked to the special environment of large soda lakes, which, due to their geological setting and phosphorus balance, provided ideal conditions for prebiotic chemistry. “This new theory helps to solve another piece of the puzzle of the origin of life on Earth,” says Walton.\n\n                \tReference\n\n                Walton CR, Hao J, Schönbächler M, Shorttle O: Large closed-basin lakes sustainably supplied phosphate during the origins of life, Science Advances, eadq0027(2025). DOI:external page 10.1126/sciadv.adq0027\n\n            Further information\n\n            chevron_right\n            Centre for Origin and Prevalence of Life COPL\n\n            Newsletter subscription\n\n            chevron_right\n            Get the latest ETH News everyday\n\n            Share articletwitterTwitterfacebookFacebooklinkedinLinkedinemailSend article by maillinkCopy link\n\n    Related articlesDo we have cosmic dust to thank for life on Earth?Category: Earth sciences28.02.2024The rocky road to the beginningCategory: Geology03.01.2024Molecular cooperation at the threshold of lifeCategory: Chemistry27.11.2023\n\n                Similar topics\n                ResearchGeochemistry and PetrologyEarth sciencesChemistry\n\n\t\t        CommentsLeave a commentLeave a commentWe are happy if you comment on articles on ETH channels, ask questions or respond to comments from other readers. Please note our comment policy when doing so.CommentNo comments yet\n\nManaging cookie preferencesStrictly necessary cookiesAlways activeThe website requires these cookies in order to function and you cannot deactivate them on your system. Usually, these cookies are used in response to actions initiated by you and fulfil a service requirement, such as applying your privacy settings, logging in or filling in a form. You can configure your browser to block or notify you about these cookies. In this case, some parts of the website might not work. These cookies do not store any personal data.Functional cookies  Functional cookies These cookies enable the website to provide additional features and to be personalised. They may be set by us or by third parties whose services we use on our site. If you do not allow these cookies, some or all of these services might not work properly.Performance cookies  Performance cookies These cookies enable us to record visits and traffic sources so that we can measure and improve the performance of our website. For example, they help us to answer questions, find out which pages are the most popular, which website features are used the least or how visitors navigate the ETH web pages. All information collected by these cookies is stored anonymously. If you do not allow these cookies, we will not be able to know whether and which pages you have visited.Marketing cookies  Marketing cookies These cookies may be set by our advertising partners via our website. They may be used by these companies to create a profile of your interests and show you relevant advertisements on other websites. They do not save personal data directly, but are based on a unique identifier of your browser and internet device. If you do not allow these cookies, the advertising you see will be less targeted to you.\n\nBack ButtonCookie List Search IconFilter IconClear checkbox label labelApply CancelConsent Leg.Interest checkbox label label checkbox label label checkbox label label\n\nClear checkbox label labelApply Cancel\n\nConsent Leg.Interest checkbox label label checkbox label label checkbox label label",
    "summary": {
      "en": "Researchers believe that large soda lakes, like Mono Lake in California, may have been the birthplace of life on Earth due to their ability to concentrate phosphorus. Phosphorus is essential for life, as it is a key component of DNA, RNA, and ATP, but it is relatively rare on Earth. For life to emerge, very high levels of phosphorus—much higher than found naturally—are necessary to trigger the chemical reactions that lead to life.\n\nLarge soda lakes can maintain these high phosphorus levels because they lose water mainly through evaporation, allowing phosphorus to accumulate instead of being washed away. This environment is ideal for sustaining both the necessary chemical reactions and developing life. In contrast, smaller lakes would deplete their phosphorus supplies too quickly for life to develop.\n\nThe findings support the idea that life likely originated in these large, stable environments rather than in smaller pools. This new theory helps clarify how life may have first emerged on Earth.",
      "ko": "연구자들은 캘리포니아의 모노 호수와 같은 대규모 소다 호수가 지구 생명의 탄생지일 수 있다고 믿고 있습니다. 이는 이 호수들이 인산을 농축할 수 있는 능력 때문입니다. 인산은 생명에 필수적인 요소로, DNA, RNA, ATP의 주요 성분이지만 지구에서는 상대적으로 드물게 존재합니다. 생명이 나타나기 위해서는 자연에서 발견되는 것보다 훨씬 높은 수준의 인산이 필요하며, 이는 생명으로 이어지는 화학 반응을 촉발하는 데 필수적입니다.\n\n대규모 소다 호수는 주로 증발을 통해 물을 잃기 때문에 이러한 높은 인산 농도를 유지할 수 있습니다. 이로 인해 인산이 씻겨 나가지 않고 축적됩니다. 이러한 환경은 필요한 화학 반응을 지속하고 생명이 발전하는 데 이상적입니다. 반면, 작은 호수는 인산 공급이 너무 빨리 고갈되어 생명이 발전하기 어려운 상황이 됩니다.\n\n이 연구 결과는 생명이 작은 웅덩이보다는 이러한 크고 안정적인 환경에서 기원했을 가능성이 높다는 주장을 뒷받침합니다. 이 새로운 이론은 지구에서 생명이 처음 어떻게 나타났는지를 명확히 하는 데 도움을 줍니다.",
      "ja": "研究者たちは、カリフォルニアのモノ湖のような大きなソーダ湖が、地球上の生命の発生地であった可能性があると考えています。これは、これらの湖がリンを濃縮する能力を持っているためです。リンは生命にとって不可欠な元素であり、DNAやRNA、ATPの重要な成分ですが、地球上では比較的希少です。生命が誕生するためには、自然に存在するよりもはるかに高いリンの濃度が必要であり、それが化学反応を引き起こすのです。\n\n大きなソーダ湖は、主に蒸発によって水を失うため、高いリン濃度を維持することができます。これにより、リンが流されることなく蓄積されます。このような環境は、必要な化学反応を持続させ、生命が発展するのに理想的です。一方で、小さな湖ではリンの供給が早く枯渇してしまい、生命が発展することは難しいでしょう。\n\nこの研究結果は、生命が小さな水たまりではなく、これらの大きく安定した環境で発生した可能性が高いことを支持しています。この新しい理論は、地球上で生命がどのように最初に誕生したのかを明らかにする手助けとなります。"
    }
  },
  {
    "id": "f5a7072d27ca574a",
    "title": {
      "en": "How 'animal methods bias' is affecting research careers",
      "ko": "동물 연구의 편향",
      "ja": "動物研究の偏り"
    },
    "type": "story",
    "url": "https://www.nature.com/articles/d41586-025-00593-3",
    "score": 34,
    "by": "LinuxBender",
    "time": 1742586702,
    "content": "CAREER FEATURE\n                20 March 2025\n\n            How ‘animal methods bias’ is affecting research careers\n\n                    Some early-career researchers report feeling pressure to use animal models to meet journal and grant requirements, even in disciplines and projects that don’t require them.\n\n                By\n\n                Christine Ro0\n\n                    Christine Ro\n\n                            Christine Ro is a freelance writer in London, UK.\n\n                            View author publications\n\n                                You can also search for this author in PubMed\n                                    Google Scholar\n\n            Twitter\n\n            Facebook\n\n            Email\n\n            Find a new job\n\n                You have full access to this article via your institution.\n\n                         Animals do not always need to be used in preclinical studies.Credit: Evgenyi Eg / GettyWhile Catharine Krebs was working in a human-genetics laboratory during her PhD at the University of California, Los Angeles, there was a line that she got used to seeing at the end of papers: “These findings will need to be confirmed in vivo.“What that usually means is in an animal model. “You just say it without even thinking, because you’ve been trained to think that that’s the next best line of investigation,” she reflects. Krebs is now the medical-research programme manager for the Physicians Committee for Responsible Medicine (PCRM), a non-profit organization in Washington DC that advocates for alternatives to animal-based research.In this role, she and other attendees at a 2022 workshop coined a term that helped to make sense of what she’d noticed as a researcher: animal-methods bias.They define animal-methods bias as indicating “a reliance on or preference for animal-based methods despite the availability of potentially suitable non-animal-based methods”.In 2023, Krebs and her co-authors at the PCRM and at Humane Society International Europe in Brussels, published the results of a survey of life-sciences researchers and peer reviewers1.The authors note that the sample of 90 respondents was small, but provides preliminary evidence of animal-methods bias.Some researchers felt that some of the requests from peer reviewers to add an animal-research component to their studies were unjustified and unnecessary, such as for researchers doing purely computational work.“The issues are mostly with journals and funders,” Krebs says. In her experience, researchers who are using animal-free models are “extremely frustrated” by such pushback.A spokeperson for Springer Nature, which publishes Nature, says: “As part of the peer-review process, our editors carefully evaluate requests by reviewers for animal studies and any arguments made against this by the authors.\"The spokeperson adds that at all times, its journal editors follow the Animal Research: Reporting In Vivo Experiments guidelines 2.0, which were last updated in 20202. Nature is editorially independent of its publisher.Animal research is not always king: researchers should explore the alternativesKrebs and her colleagues are now following up with larger-scale research. One aspect Krebs is interested in investigating is whether the bias interacts with researchers’ experience. “The impact of animal-methods bias may be especially strong with early-career researchers,” Krebs hypothesizes. “If they undergo an experience where they feel like they have to use an animal research model to publish or get a grant or publish in a high-impact journal, then that just reinforces it, and it can set them on a career path where they’re using animals instead of other models that may more reliably mimic human biology but are not yet as common in the field.” “We all know that our in vitro studies do not capture every aspect of biology or physiology,” says Abhijit Majumder, a chemical engineer at the Indian Institute of Technology (IIT) Bombay in Mumbai. “But at the same time, animal studies do not capture the many aspects of human physiology.” A commonly cited statistic is that about 90% of candidate drugs in early-stage clinical trials fail before reaching the market, in part owing to heavy reliance on animal models in preclinical research. Majumder thinks that broader scientific acceptance of NAMs (an acronym that has been applied variously to “new approach methodologies”, “novel alternative methods”, “new alternative methods” and “non-animal models”) will take some time.Funding opportunities opening upFunding from non-governmental organizations (NGOs) has been crucial for Laura Sinclair, a postdoctoral research associate at the University of Exeter, UK. She started out doing a non-funded PhD related to adipose tissue and diabetes. She then switched to a PhD on cellular ageing in an animal-research-free lab. She took advantage of an innovative funding model offered by the London-based charity Animal Free Research UK, which provided three years of funding for her PhD studentship, three years for her postdoc and three years for another fellowship. The stability has been very welcome for her as an early-career researcher, she says.In general, Krebs says, NGO grants for animal-free research tend to be smaller than the longer-term, multimillion-dollar awards offered by government sources such as the US National Institutes of Health (NIH), the world’s biggest funder of biomedical research.Another change is the number of grants awarded to support the use of alternative methods. In 2021, alternative methods made up about 8% of competitive (non-clinical, non-invertebrate) awards disbursed by the NIH. In the early 1980s, that figure was essentially zero.“It’s still small compared to the overall NIH funding,” acknowledges Danilo Tagle, director of the Office for Special Initiatives at the National Center for Advancing Translational Sciences (NCATS), an NIH institute based in Rockville, Maryland.Laura Sinclair was grateful for an animal-free-research grant that gave her stability in the early stages of her career.Credit: Dr Laura R SinclairTagle started his science career as a geneticist modelling human diseases in mice, which exposed him to some of the weaknesses in rodent models. He says that there’s been a gradual increase in NIH funding for NAMs, especially in the past decade. In 2010, a European Union directive established an ambitious goal to fully replace live animals used for scientific purposes with non-animal methods such as organoids or computer simulations. However, the number of animals used in science in the EU barely moved between 2017 and 2022.In terms of EU funding schemes and general acceptance of non-animal methods, there are more doors open to emerging researchers today, says Mathieu Vinken, who obtained his PhD in pharmaceutical sciences in 2006. Vinken is now a professor at the Free University of Brussels, with research interests including reducing the use of animals in space toxicology. His funding sources have included large EU grant programmes.Overall, Majumder thinks that funders are further along than many scientists in being open to alternative models. For instance, a 2025 call for discovery research proposals from the Indian Council of Medical Research in New Delhi explicitly states that both animal and non-animal models are covered, and gives examples of non-animal methods. Majumder and other scientists have found niches in which alternative methods are especially needed to plug research gaps. One example is investigating how safe medicines are likely to be during pregnancy because “most of the drugs, when they go through clinical trials, cannot be tested on pregnant women”, Majumder explains. For this, researchers are working on developing an organ-on-a-chip model, a microfluidic system that uses cultured cells to simulate the processes in various organs — in this case, the placenta.Similarly, the NIH programme Complement Animal Research In Experimentation, established in 2024, is identifying areas in which animal models are lacking, including rare diseases and sepsis. The programme is a coordinated approach to funding NAMs across the NIH, says Tagle, who spoke to Nature’s careers team before the Trump administration paused some external communications and related activities at the organization.“We’re looking at at least $30 million per year over the course of the next 10 years to develop NAMs,” Tagle says.How a shift in research methodology could reduce animal useAlthough there is uncertainty about the future of US government funding of biomedical research, Krebs thinks that there’s a case to be made that animal research can be quite wasteful, which could align with the new administration’s messaging about reducing government waste.For the time being, duplicating research using different models — while more funders, regulators and scientists become comfortable with NAMs — can add time and expense.“Essentially today we are in the cusp period where doing all this research has become expensive,” says Deepak Modi, a biologist focused on reproductive health at India’s National Institute for Research in Reproductive and Child Health in Mumbai, who collaborates with Majumder.Modi thinks that in the future, some steps in the chain could be omitted, which would speed up the process and bring down costs without losing rigour. There might also be more “ready-to-play” organ-on-chip solutions once the technology matures, Modi says.Sinclair thinks costs are coming down in response to consumer demand, noting a shift towards more synthetic, reproducible materials since she did her animal-free PhD. She and her colleagues have created a guide to working with tissue cultures that are relevant to humans and not derived from animals — the type of resource that would have been useful to her earlier in her career, she says.From a funder’s perspective, value for money can be complex. “The translational implications have to be weighed in, because one can invest in animal models, but if the animal models are not necessarily human-relevant ... then that’s a big waste in terms of time and resources,” says Tagle, who adds that with organs-on-chips, there are examples of moving from developing models to screening drugs and then going on to clinical trials much faster than when animal models were used. An example is researchers who used a lung tissue-chip to test the chemical azeliragon as a treatment for inflammatory lung diseases, an application that has moved on to phase III clinical trials. Publication perils\n\n                                    Enjoying our latest content?\n                                    Login or create an account to continue\n\n                                            Access the most recent journalism from Nature's award-winning team\n                                            Explore the latest features & opinion covering groundbreaking research\n\n                                            Access through your institution\n\n                                    or\n\n                                            Sign in or create an account\n\n                                            Continue with Google\n\n                                            Continue with ORCiD\n\n                doi: https://doi.org/10.1038/d41586-025-00593-3\n\n                ReferencesKrebs, C. E., Lam, A., McCarthy, J., Constantino, H. & Sullivan, K. ALTEX 40, 665–676 (2023).Article\n\n                    Google Scholar\n                Percie du Sert, N. et al. PLoS Biol. 18, e3000411 (2020).Article\n    PubMed\n\n                    Google Scholar\n                Download references\n\n                Related Articles\n\n                        Animal research is not always king: researchers should explore the alternatives\n\n                        How a shift in research methodology could reduce animal use\n\n                        Researchers and regulators plan for a future without lab animals\n\n                        Openness about animal research increases public support\n\n                Subjects\n\n                Careers\n\n                Funding\n\n                Peer review\n\n                Lab life\n\n    Latest on:\n\n                Careers\n\n                                    How a scientist–pop industry partnership slashed a live gig’s carbon emissions by 98%\n                                    Career News 25 MAR 25\n\n                                    Trump administration sued over huge funding cuts at Columbia University\n                                    News 25 MAR 25\n\n                                    Why Africans should be telling the story of human origins\n                                    Career Q&A 24 MAR 25\n\n                Funding\n\n                                    Exclusive: NIH to cut grants for COVID research, documents reveal\n                                    News 26 MAR 25\n\n                                    Give grants to female scientists in war zones\n                                    Correspondence 25 MAR 25\n\n                                    Trump administration sued over huge funding cuts at Columbia University\n                                    News 25 MAR 25\n\n                Peer review\n\n                                    Sexual harassment allegations linked to drop in citations\n                                    News 05 MAR 25\n\n                                    ‘Omg, did PubMed go dark?’ Blackout stokes fears about database’s future\n                                    News 04 MAR 25\n\n                                    Want to become a professor? Here’s how hiring criteria differ by country\n                                    News 22 JAN 25\n\n                                    How a scientist–pop industry partnership slashed a live gig’s carbon emissions by 98%\n                                    Career News 25 MAR 25\n\n                                    Trump administration sued over huge funding cuts at Columbia University\n                                    News 25 MAR 25\n\n                                    Why Africans should be telling the story of human origins\n                                    Career Q&A 24 MAR 25\n\n            Jobs\n\n                        Department Chairs, School of Medicine at Southern University of Science and Technology (copy)\n\n                            Shenzhen, Guangdong, China\n                            Southern University of Science and Technology, School of Medicine\n\n                        Aggregate Report Senior Scientist\n\n                            Joining us as an Aggregate Report Senior Scientist, you will be a key member of the Safety Surveillance and Aggregate (SSA) Reports team\n                            Maidenhead, Berkshire\n                            Biogen\n\n                        Manager, Clinical Quality Management\n\n                            We are a global team with a commitment to excellence, and a pioneering spirit.\n                            Tokyo (JP)\n                            Biogen\n\n                        Executive Assistant to Head of Biogen's West Coast Hub\n\n                            The Executive Administrative Assistant will be a dynamic and self-motivated individual able to provide administrative support...\n                            South San Francisco, California\n                            Biogen\n\n                        Principal Associate Scientist, Gene Therapy\n\n                            Biogen are seeking a Principal Associate Scientist, Gene Therapy.\n                            Cambridge, Massachusetts (US)\n                            Biogen",
    "summary": {
      "en": "**Summary: How 'Animal Methods Bias' Affects Research Careers**\n\nMany early-career researchers face pressure to use animal models in their studies due to journal and grant requirements, even when it's unnecessary. This phenomenon, termed \"animal-methods bias,\" suggests a preference for animal research despite the availability of non-animal alternatives.\n\nResearchers like Catharine Krebs highlight that this bias can frustrate those using animal-free models, especially when peer reviewers demand animal components in studies that do not need them. A small survey indicated that many researchers found such requests unjustified.\n\nWhile funding for animal-free research from NGOs is growing, it remains limited compared to traditional government grants. However, there has been a gradual increase in funding for non-animal methods, especially with initiatives like the NIH's Complement Animal Research program and calls for proposals that include non-animal models.\n\nDespite the benefits of alternative methods, such as organ-on-a-chip models, the scientific community still faces challenges in fully embracing these approaches. Researchers believe that as funding and acceptance grow, the reliance on animal methods may reduce, ultimately leading to more efficient and relevant research outcomes.",
      "ko": "많은 초기 경력 연구자들은 저널과 연구비 지원 요건 때문에 불필요한 경우에도 동물 모델을 사용해야 한다는 압박을 받고 있습니다. 이러한 현상을 '동물 방법 편향'이라고 하며, 동물 연구에 대한 선호가 비동물 대안이 존재함에도 불구하고 나타나는 것을 의미합니다.\n\n캐서린 크레브스와 같은 연구자들은 이 편향이 동물 없는 모델을 사용하는 연구자들에게 불만을 초래할 수 있다고 강조합니다. 특히 동료 심사자들이 필요하지 않은 연구에 동물 요소를 요구할 때 더욱 그렇습니다. 한 작은 설문조사에서는 많은 연구자들이 이러한 요청이 정당하지 않다고 느꼈다는 결과가 나왔습니다.\n\n비정부기구(NGO)에서 동물 없는 연구에 대한 자금 지원이 증가하고 있지만, 전통적인 정부 지원에 비하면 여전히 제한적입니다. 그러나 NIH의 보완 동물 연구 프로그램과 비동물 모델을 포함한 제안 요청과 같은 이니셔티브 덕분에 비동물 방법에 대한 자금 지원이 점차 증가하고 있습니다.\n\n장기 칩 모델과 같은 대체 방법의 장점에도 불구하고, 과학계는 이러한 접근 방식을 완전히 수용하는 데 여전히 어려움을 겪고 있습니다. 연구자들은 자금 지원과 수용이 증가함에 따라 동물 방법에 대한 의존도가 줄어들고, 궁극적으로 더 효율적이고 관련성 높은 연구 결과로 이어질 것이라고 믿고 있습니다.",
      "ja": "多くの若手研究者は、ジャーナルや助成金の要件により、必要のない場合でも動物モデルを使用するよう圧力を受けています。この現象は「動物方法バイアス」と呼ばれ、動物研究が非動物の代替手段があるにもかかわらず好まれる傾向を示しています。\n\nキャサリン・クレブスのような研究者は、このバイアスが動物を使わないモデルを使用している研究者を frustrate させることがあると指摘しています。特に、査読者が必要のない研究に動物成分を求める場合、問題が生じます。小規模な調査では、多くの研究者がそのような要求を正当化できないと感じていることが示されました。\n\n非動物研究への資金提供はNGOから増加していますが、従来の政府助成金と比べると依然として限られています。しかし、NIHの補完動物研究プログラムや非動物モデルを含む提案の呼びかけなどの取り組みにより、非動物手法への資金が徐々に増加しています。\n\nオルガン・オン・ア・チップモデルなどの代替手法には多くの利点がありますが、科学コミュニティはこれらのアプローチを完全に受け入れるにはまだ課題があります。研究者たちは、資金と受け入れが増えることで動物方法への依存が減少し、最終的にはより効率的で関連性のある研究成果につながると考えています。"
    }
  },
  {
    "id": "5044e4e2985eaff0",
    "title": {
      "en": "Brain scans of infants reveal the moment we start making memories",
      "ko": "아기 뇌 스캔, 기억 시작 순간 포착!",
      "ja": "赤ちゃんの脳が記憶の瞬間を暴く"
    },
    "type": "story",
    "url": "https://singularityhub.com/2025/03/20/new-baby-brain-scans-reveal-the-moment-we-start-making-memories/",
    "score": 124,
    "by": "Brajeshwar",
    "time": 1742574750,
    "content": "ScienceBrain Scans of Infants Reveal the Moment We Start Making MemoriesKids form fleeting memories at around 12 months, even as their brains are rapidly rewiring themselves.Shelly FanMar 20, 2025Image CreditJuan Encalada on UnsplashShareA giggling toddler in a pink dress and matching headphones lies down on her back in front of a gigantic whirling machine. A pillowy headrest cushions her head. She seems unfazed as she’s slowly shuttled into the claustrophobic brain scanner. Once settled, a projection showing kaleidoscope-like animations holds her attention as the magnetic resonance imaging (MRI) machine scans her brain.The girl is part of a new study seeking to answer a century-old mystery: Why can’t most us remember the first three years of our lives? Dubbed “infantile amnesia” by Sigmund Freud, the study could provide insight into how the brain develops during our early years. And if we can form memories at a young age, are they fleeting, or are they still buried somewhere in the adult brain?It seems like a simple question, but an answer has eluded scientists.Though infants and toddlers aren’t yet able to give detailed verbal feedback, studying their behavior has begun to shed light on if and when they remember people, things, or places. Still, the approach can’t peek in on what’s happening in the brain in those early years. MRI can.A team from Columbia and Yale University scanned the brains of 26 infants and toddlers aged 4 to 25 months as they completed a memory task. They found that at roughly a year old, a part of the brain crucial to memory formation spun into action and began generating neural signals related to things the kids remembered from the tests.Called the hippocampus, this sea-horse-shaped structure deep inside the brain is crucial to the encoding of our life stories—who, when, where, what. Adults with a damaged hippocampus suffer memory problems. But because wiring inside the hippocampus is still developing during our earliest years, scientists believe it may be too immature to form memories.“It’s not that we don’t have any memories from that period [infancy],” said study author Nicholas Turk-Browne in a press briefing. “In fact, early life is when we learn our language. It’s when we learn how to walk…learn the names of objects and form social relationships.”“What happens during that period when we learn so much, but remember so little?” he added.Stages of MemoryMemory seems like all-or-none: You either remember something, or you don’t.It’s not that simple. Decades of research have identified the hippocampus as the main orchestrator of episodic memories. These allow you to remember an acquaintance at a party, where you parked your car, or what you had for dinner three nights ago.Each everyday experience is encoded in neural connections in the hippocampus. Groups of neurons called engrams capture different memories and keep them separate, so that they don’t bleed into each other.Once encoded, the brain etches important memories into long-term storage during sleep. Studies of slumbering rodents and humans after learning a new task found that the hippocampus replayed brain activity at higher speed during the night, correlating with better performance on a trained memory task the next day.The last step is retrieval. This is when the brain fishes out stored memories and delivers them to our conscious brain—and so, we “remember.”Failure of any of these steps causes amnesia. So, which steps are responsible for the erosion of baby memories?Bundles of JoyBrain scans from 26 infants now offer some intriguing clues.The team behind the new study scanned the children’s brains with functional MRI (fMRI) as they looked at a screen in the scanner and took a memory test. fMRI captures brain oxygen levels (BOLD) as a proxy for local neuron signaling—higher levels mean more brain activity.The head needs to keep very still throughout the scans to avoid blurring. That’s not easily accomplished with babies and toddlers. Previous studies circumvented the problem by imaging their brains while sleeping, but the results couldn’t capture memory processes.Be Part of the FutureSign up to receive top stories about groundbreaking technologies and visionary thinkers from SingularityHub.ruidWeekly NewsletterDaily NewsletterI agree to receive other communications from Singularity.I agree to allow Singularity to store and process my personal data in accordance with the company's Terms of Use and Privacy Policy.*Subscribe100% Free. No Spam. Unsubscribe any time.To keep the infants happy, engaged, and safe, parents brought favorite blankets and pacifiers, and younger infants were wrapped inside a comfortable vacuum pillow to reduce movement. A video system projected images onto the ceiling of the scanner within their line of sight.As the kids looked at a bright kaleidoscope-like video, images of faces, scenes, and objects would flash for a few seconds. These included toys or landscapes of an alpine cabin with mountains in the background. Previous studies found infants like to stare at objects or images they’ve seen before compared to new objects, suggesting they remember previous encounters.Throughout the sessions the team added projections showing a previously seen picture and a new one and monitored the infants’ eye movement using a video camera.“The ingenuity of their experimental approach should not be understated,” wrote Adam Ramsaran and Paul Frankland at the Hospital for Sick Children in Toronto, Canada, who were not involved in the study.BOLD FindingsThe kids often squirmed during the sessions. Some weren’t interested in the pictures; others fell asleep in the scanner.Still, the team managed to capture hippocampal BOLD signals averaging roughly eight minutes per participant and matched them to memory performance. On average, parts of the hippocampus ramped up activity for images that the infants later remembered—that is, they looked at it for longer during the test phases.But not all infants performed the same. The younger cohort, under a year, didn’t show the surge of BOLD signals suggesting memory encoding. They also ignored already seen images compared to new ones.It seems babies start encoding memories around a year of age, even as their hippocampus is still developing.The results are similar to those in baby rodents. The early years are chaotic. The brain undergoes extensive rewiring. This makes it a difficult to form lasting memories. Yet some supposedly lost memories encoded at a young age can be recovered later in life with reminder cues or by directly activating the set of neurons that originally encoded the memory.That’s not to say infants can acquire rich recollections—stories including multiple people, places, and things—at a year. The study only tested brain signatures for individual components.Future studies tracking the hippocampus might shed light on the minimal brain architecture needed to support vivid autobiographical memories. Examining other stages of memory could shine more light on infantile amnesia. For example, do infants also replay neural signals as they sleep to etch new experiences into long-term memory?And maybe—just maybe—our earliest memories could one day be retrieved later in childhood or beyond.NeuroscienceShelly FanShelly FanDr. Shelly Xuelai Fan is a neuroscientist-turned-science-writer. She's fascinated with research about the brain, AI, longevity, biotech, and especially their intersection. As a digital nomad, she enjoys exploring new cultures, local foods, and the great outdoors.Related ArticlesNew Tech Bends Sound Through Space So It Reaches Only Your Ear in a CrowdJiaxin ZhongandYun JingMar 18, 2025A Massive AI Analysis Found Genes Related to Brain Aging—and Drugs to Slow It DownShelly FanMar 17, 2025Scientists Discover Thousands of New Microbial Species Thriving in the Mariana TrenchShelly FanMar 06, 2025ScienceNew Tech Bends Sound Through Space So It Reaches Only Your Ear in a CrowdJiaxin ZhongandYun JingMar 18, 2025ScienceA Massive AI Analysis Found Genes Related to Brain Aging—and Drugs to Slow It DownShelly FanMar 17, 2025ScienceScientists Discover Thousands of New Microbial Species Thriving in the Mariana TrenchShelly FanMar 06, 2025What we’re readingA New, Challenging AGI Test Stumps Most AI ModelsTechCrunchCould Nvidia’s Revolutionary Optical Switch Transform AI Data Centers Forever?IEEE SpectrumJust One Exo-Earth Pixel Can Reveal Continents, Oceans, and MoreBig Think23andMe Site Went Down as Customers Struggled to Delete DataThe Wall Street JournalScientists Find Giant Organic Molecules on Mars as Old as Life on EarthGizmodoThe Quantum Apocalypse Is Coming. Be Very AfraidWiredA Mysterious Startup Is Developing a New Form of Solar GeoengineeringWiredInside Google’s Two-Year Frenzy to Catch Up With OpenAIWired1X Will Test Humanoid Robots in ‘a Few Hundred’ Homes in 2025TechCrunchWatch the Atlas Robot Bust a Move in Boston Dynamics’ Latest VideoEngadgetIs Dark Energy Getting Weaker? New Evidence Strengthens the Case.QuantaSatellite Internet Will Enable AI in EverythingWiredAI-Driven Weather Prediction Breakthrough ReportedThe GuardianIn Las Vegas, a Former SpaceX Engineer Is Pulling CO2 From the Air to Make ConcreteFast CompanyThe Unbelievable Scale of AI’s Pirated-Books ProblemThe AtlanticTop Developers Want Nvidia Blackwell Chips. Everyone Else, Not So MuchThe InformationOpenAI’s Deep Research Agent Is Coming for White-Collar WorkWiredNot Everyone Is Convinced by Microsoft’s Topological QubitsIEEE SpectrumJudge Disses Star Trek Icon Data’s Poetry While Ruling AI Can’t Author WorksArs TechnicaSee the First Ever Footage of Sunset on the Moon Captured by Blue GhostDigital Trends",
    "summary": {
      "en": "A recent study using brain scans has shown that infants begin forming memories around the age of 12 months. Researchers from Columbia and Yale University scanned the brains of 26 infants and toddlers while they engaged in a memory task. They discovered that the hippocampus, a brain structure essential for memory, starts to become active around this age, indicating the beginning of memory formation.\n\nThe study aims to understand \"infantile amnesia,\" the phenomenon where most people cannot recall memories from their first three years of life. While infants learn many skills during this time, their ability to create lasting memories is limited due to ongoing brain development. \n\nThe research involved observing infants as they watched images on a screen. The infants tended to remember previously seen images better than new ones, but younger infants (under one year) did not show the same memory encoding activity as older ones. \n\nOverall, these findings suggest that while babies can start to form memories, the chaotic nature of early brain development makes it difficult to retain them long-term. Future studies may help uncover more about how early memories can be accessed later in life.",
      "ko": "최근 뇌 스캔을 이용한 연구에 따르면, 아기들은 약 12개월이 되면 기억을 형성하기 시작한다고 합니다. 컬럼비아 대학교와 예일 대학교의 연구자들은 26명의 아기와 유아의 뇌를 스캔하며 기억 과제를 수행하는 모습을 관찰했습니다. 그 결과, 기억 형성에 중요한 역할을 하는 해마라는 뇌 구조가 이 시기에 활성화되기 시작한다는 것을 발견했습니다.\n\n이 연구는 대부분의 사람들이 생후 3년 동안의 기억을 회상할 수 없는 현상인 '유아기 기억상실증'을 이해하는 데 목적이 있습니다. 이 시기에 아기들은 많은 기술을 배우지만, 뇌 발달이 계속 진행 중이기 때문에 지속적인 기억을 형성하는 능력은 제한적입니다.\n\n연구는 아기들이 화면에서 이미지를 보는 모습을 관찰하는 방식으로 진행되었습니다. 아기들은 이전에 본 이미지를 새로운 이미지보다 더 잘 기억하는 경향이 있었지만, 1세 미만의 어린 아기들은 나이가 더 많은 아기들처럼 기억을 인코딩하는 활동을 보이지 않았습니다.\n\n이러한 발견은 아기들이 기억을 형성하기 시작할 수 있지만, 초기 뇌 발달의 혼란스러운 특성 때문에 장기적으로 기억을 유지하기가 어렵다는 것을 시사합니다. 앞으로의 연구는 초기 기억이 나중에 어떻게 접근될 수 있는지에 대한 더 많은 정보를 밝혀낼 수 있을 것으로 기대됩니다.",
      "ja": "最近の研究によると、赤ちゃんは約12ヶ月の時点で記憶を形成し始めることが脳スキャンを通じて示されました。コロンビア大学とイェール大学の研究者たちは、26人の赤ちゃんと幼児の脳を記憶タスクを行っている間にスキャンしました。その結果、記憶に重要な役割を果たす海馬という脳の構造がこの時期に活発になり始めることがわかりました。これは記憶形成の始まりを示しています。\n\nこの研究は「幼児期の健忘症」を理解することを目的としています。これは、多くの人が生まれてからの最初の3年間の記憶を思い出せない現象です。この時期、赤ちゃんは多くのスキルを学びますが、脳の発達が進行中であるため、持続的な記憶を作る能力は限られています。\n\n研究では、赤ちゃんが画面上の画像を見ている様子を観察しました。赤ちゃんは以前に見た画像を新しい画像よりもよく覚えている傾向がありましたが、1歳未満の赤ちゃんは、年上の赤ちゃんと同じような記憶の符号化活動を示しませんでした。\n\n全体として、これらの発見は、赤ちゃんが記憶を形成し始めることができる一方で、初期の脳の発達の混沌とした性質が長期的に記憶を保持することを難しくしていることを示唆しています。今後の研究では、初期の記憶が後の人生でどのようにアクセスされるかについてさらに明らかにされる可能性があります。"
    }
  },
  {
    "id": "9309ddd8ca516468",
    "title": {
      "en": "'A walking billboard': The history of San Francisco's most recognizable bag",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://www.sfgate.com/sf-culture/article/history-san-franciscos-most-recognizable-bag-20228921.php",
    "score": 21,
    "by": "cainxinth",
    "time": 1742902878,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "4b1f965afbbce709",
    "title": {
      "en": "Ollama Models Atom Feed",
      "ko": "올라마 모델 소식",
      "ja": "オラマモデルの新潮流"
    },
    "type": "story",
    "url": "https://simonwillison.net/2025/Mar/22/ollama-models-atom-feed/",
    "score": 45,
    "by": "mdp2021",
    "time": 1742718760,
    "content": "simonw/ollama-models-atom-feed. I setup a GitHub Actions + GitHub Pages Atom feed of scraped recent models data from the Ollama latest models page - Ollama remains one of the easiest ways to run models on a laptop so a new model release from them is worth hearing about.\nI built the scraper by pasting example HTML into Claude and asking for a Python script to convert it to Atom - here's the script we wrote together.\nUpdate 25th March 2025: The first version of this included all 160+ models in a single feed. I've upgraded the script to output two feeds - the original atom.xml one and a new atom-recent-20.xml feed containing just the most recent 20 items.\nI modified the script using Google's new Gemini 2.5 Pro model, like this:\ncat to_atom.py | llm -m gemini-2.5-pro-exp-03-25 \\\n  -s 'rewrite this script so that instead of outputting Atom to stdout it saves two files, one called atom.xml with everything and another called atom-recent-20.xml with just the most recent 20 items - remove the output option entirely'\n\nHere's the full transcript.\n\nPosted 22nd March 2025 at 10:04 pm",
    "summary": {
      "en": "The text describes a project by the user simonw, where they created an Atom feed to track new model releases from Ollama, a platform for running models on laptops. They built a web scraper to gather data from Ollama's models page and initially created a single feed containing over 160 models. On March 25, 2025, they upgraded the script to generate two feeds: one with all models (atom.xml) and another with just the 20 most recent models (atom-recent-20.xml). They used Google's Gemini 2.5 Pro model to help rewrite the script for this purpose. The project was posted on March 22, 2025.",
      "ko": "사용자 simonw는 Ollama라는 플랫폼에서 새로운 모델 출시를 추적하기 위해 Atom 피드를 만들었습니다. Ollama는 노트북에서 모델을 실행할 수 있는 서비스입니다. 그들은 Ollama의 모델 페이지에서 데이터를 수집하기 위해 웹 스크래퍼를 구축했고, 처음에는 160개 이상의 모델을 포함하는 단일 피드를 만들었습니다. 2025년 3월 25일, 그들은 스크립트를 업그레이드하여 모든 모델을 포함하는 피드(atom.xml)와 최근 20개 모델만 포함하는 피드(atom-recent-20.xml) 두 개를 생성했습니다. 이 작업을 위해 구글의 Gemini 2.5 Pro 모델을 사용하여 스크립트를 재작성했습니다. 이 프로젝트는 2025년 3월 22일에 게시되었습니다.",
      "ja": "ユーザーのsimonwは、Ollamaというノートパソコンでモデルを実行するためのプラットフォームから新しいモデルのリリースを追跡するために、Atomフィードを作成するプロジェクトを行いました。彼はOllamaのモデルページからデータを収集するためにウェブスクレイパーを構築し、最初は160以上のモデルを含む単一のフィードを作成しました。2025年3月25日には、スクリプトをアップグレードし、すべてのモデルを含むフィード（atom.xml）と、最新の20モデルだけを含むフィード（atom-recent-20.xml）の2つを生成するようにしました。この目的のために、GoogleのGemini 2.5 Proモデルを使用してスクリプトの書き直しを行いました。このプロジェクトは2025年3月22日に投稿されました。"
    }
  },
  {
    "id": "fe9393cf35fc4200",
    "title": {
      "en": "Show HN: I built a chatbot that lets you talk to any GitHub repository",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://www.sentientdocs.com/",
    "score": 20,
    "by": "simssousa15",
    "time": 1742930016,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "94dd7a5cb320f1fa",
    "title": {
      "en": "Spammers are better at SPF, DKIM, and DMARC than everyone else",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://toad.social/@grumpybozo/114213600922816869",
    "score": 409,
    "by": "pabs3",
    "time": 1742890490,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "2fe01a4dc45a027a",
    "title": {
      "en": "Triforce – a beamformer for Apple Silicon laptops",
      "ko": "트라이포스: 애플 실리콘의 빔포머",
      "ja": "トライフォース：Appleシリコン用ビームフォーマー"
    },
    "type": "story",
    "url": "https://github.com/chadmed/triforce",
    "score": 574,
    "by": "tosh",
    "time": 1742827534,
    "content": "Triforce - a beamformer for Apple Silicon laptops\nTriforce implements a Minimum Variance Distortionless Response adaptive beamformer\nfor the microphone array found in the following Apple Silicon laptops:\n\nMacBook Pro 13\" (M1/M2)\nMacBook Air 13\" (M1/M2)\nMacBook Pro 14\" (M1 Pro/Max, M2 Pro/Max)\nMacBook Pro 16\" (M1 Pro/Max, M2 Pro/Max)\nMacBook Air 15\" (M2)\n\nDependencies\nTriforce tries to keep dependencies to a minimum. On top of the\ncrates specified in Cargo.lock, you will only require:\n\nLV2\n\nWhy?\nThe Apple Silicon laptops mentioned above have an array of microphones arranged\neither in a triangle or in a straight line. Much like with the speakers, Apple are trying way too hard to be\nfancy here, and implement an adaptive beamformer in userspace to try and isolate\nthe desired signal from background noise. Without beamforming, the array is far\ntoo sensitive and omnidirectional to be at all useful. Thus, to make it useful outside\nof macOS, we need a beamformer.\nExpectation management\nFinding accessible literature on any DSP-related topics, let alone something like\nwideband adaptive beamforming, is challenging to say the least. This is an attempt\nat a beamformer armed only with first year undergrad level engineering maths and some vague\nidea of the principles gleaned from various webpages and PDFs. Do not expect it to\noutperform Apple's implementation at this time. Patches to improve it are always welcome!\nKnown limitations\n\nnalgebra does not do any explicit SIMD optimisation, relying only on LLVM auto-vectorisation.\nPerformance and efficiency of matrix math routines are not very good.\nFollowing from that, we are not doing wideband decomposition due to the added computational\nburden. Without SIMD/NEON support, this is simply too slow for a realtime audio plugin.\nOutput is mono only. Much like with wideband decomposition, adding additional matrix processing\nto fake stereo output would be too computationally intensive",
    "summary": {
      "en": "**Summary of Triforce - a Beamformer for Apple Silicon Laptops**\n\nTriforce is a software tool designed to improve the microphone performance on certain Apple Silicon laptops, including various models of the MacBook Pro and MacBook Air. It uses a technology called Minimum Variance Distortionless Response adaptive beamforming to help isolate the desired sound from background noise.\n\n**Key Points:**\n- **Supported Devices**: Includes MacBook Pro 13\", MacBook Air 13\", MacBook Pro 14\", MacBook Pro 16\", and MacBook Air 15\" with M1 and M2 chips.\n- **Dependencies**: Requires minimal additional software, mainly the LV2 library.\n- **Purpose**: The built-in microphone arrays in these laptops are too sensitive and need beamforming to be useful in noisy environments.\n- **Expectations**: The project is based on basic engineering concepts and may not perform as well as Apple's built-in solutions. Improvements and contributions are welcome.\n- **Limitations**: \n  - Lacks advanced optimizations for speed and efficiency.\n  - Only supports mono audio output, as creating stereo output would be too demanding on resources.\n\nTriforce aims to provide a better audio experience by adapting the microphone's capabilities for users outside of macOS.",
      "ko": "Triforce는 특정 Apple Silicon 노트북에서 마이크 성능을 향상시키기 위해 설계된 소프트웨어 도구입니다. 이 도구는 다양한 모델의 MacBook Pro와 MacBook Air에서 사용할 수 있으며, 최소 분산 왜곡 없는 반응(adaptive beamforming) 기술을 활용하여 원하는 소리를 배경 소음으로부터 분리하는 데 도움을 줍니다.\n\n지원되는 기기는 M1 및 M2 칩이 탑재된 MacBook Pro 13인치, MacBook Air 13인치, MacBook Pro 14인치, MacBook Pro 16인치, MacBook Air 15인치 등이 포함됩니다. Triforce는 LV2 라이브러리와 같은 최소한의 추가 소프트웨어를 필요로 합니다. 이 노트북에 내장된 마이크 배열은 너무 민감하여 시끄러운 환경에서 유용하게 사용되기 위해서는 빔포밍 기술이 필요합니다.\n\n이 프로젝트는 기본적인 공학 개념에 기반하고 있으며, Apple의 내장 솔루션만큼 성능이 뛰어나지 않을 수 있습니다. 개선 사항이나 기여는 환영합니다. 그러나 Triforce는 속도와 효율성을 위한 고급 최적화가 부족하며, 자원 소모가 크기 때문에 스테레오 출력은 지원하지 않고 모노 오디오 출력만 가능합니다.\n\nTriforce는 macOS 외부 사용자들을 위해 마이크의 기능을 조정하여 더 나은 오디오 경험을 제공하는 것을 목표로 하고 있습니다.",
      "ja": "Triforceは、特定のApple Silicon搭載のノートパソコン、特にMacBook ProやMacBook Airのマイク性能を向上させるために設計されたソフトウェアツールです。このツールは、最小分散歪みのない応答適応ビームフォーミングという技術を使用して、背景ノイズから目的の音を分離するのに役立ちます。\n\n対応デバイスには、M1およびM2チップを搭載した13インチのMacBook Pro、13インチのMacBook Air、14インチのMacBook Pro、16インチのMacBook Pro、15インチのMacBook Airが含まれます。Triforceは、主にLV2ライブラリという最小限の追加ソフトウェアを必要とします。\n\nこれらのノートパソコンに内蔵されているマイクアレイは感度が高すぎるため、騒がしい環境で有用にするためにはビームフォーミングが必要です。プロジェクトは基本的な工学の概念に基づいており、Appleの内蔵ソリューションほどの性能は期待できないかもしれませんが、改善や貢献は歓迎されています。\n\n制限としては、高速性や効率性のための高度な最適化が欠けていること、また、リソースの要求が高いためステレオ出力には対応しておらず、モノラル音声出力のみをサポートしている点があります。Triforceは、macOS以外のユーザーに向けてマイクの機能を適応させることで、より良い音声体験を提供することを目指しています。"
    }
  },
  {
    "id": "a0735b9804bfb6a7",
    "title": {
      "en": "If only someone told me this before my first startup",
      "ko": "첫 스타트업 전 꼭 알아야 할 것",
      "ja": "初めての起業、知っておきたかったこと"
    },
    "type": "story",
    "url": "https://johnrushx.substack.com/p/if-only-someone-told-me-this-before",
    "score": 24,
    "by": "mixmastamyk",
    "time": 1742933236,
    "content": "Share this postJohn RushIf only someone told me this before my 1st startupCopy linkFacebookEmailNotesMoreDiscover more from John RushSharing startup tips while building SaaS Empire.\n\n20k followers. 30 million views on X.Over 6,000 subscribersSubscribeBy subscribing,  I agree to Substack's Terms of Use, and acknowledge its Information Collection Notice and Privacy Policy.Already have an account? Sign inIf only someone told me this before my 1st startupJohn RushFeb 11, 202568Share this postJohn RushIf only someone told me this before my 1st startupCopy linkFacebookEmailNotesMore1313Share1. Validate.I wasted at least 5 years building stuff nobody needed.2. Kill your EGO.Make your users happy instead of yourself.3. Don’t chaise investors; chase users, and then investors will chase you.4. Never hire managers. Only hire doers until PMF.5. Landing page isn't important.Go for an average template and edit texts, and that’s it.The sale happens outside of the website anyway (in the early stages).6. Hire only fullstack devs.There is nothing less productive in this world than a team of developers.One full stack dev building the whole product. That’s it.7. Chase global market from day 1.If the product and marketing are good, it will work on the global market too, if it’s bad, it won’t work on the local market too. So better go global from day 1, so that if it works, the upside is 100x bigger.8. Do SEO from day 2.As early as you can. I ignored this for 14 years. It’s my biggest regret.9. Sell features, before building them.Ask existing users if they want this feature. I run DMs with 10-20 users every day, where I chat about all my ideas and features I wanna add. I clearly see what resonates with me most and only go build those.10. Hire only people you'd wanna hug.My mentor said this to me in 2015. And it was a big shift. I realized that if I don’t wanna hug the person, it means I dislike them. Sooner or later, we would have a conflict and eventually break up.11. Invest all your money into yourself and your friends.I did some math; if I kept investing all my money into all my friends’ startups, I'd be worth $100M+ by now.12. Post on X/Linkedin daily.I started posting here in 2023. I wish I started earlier. It’s my primary source of new connections, news, marketing, and networking.13. Don’t work/partner with corporates.They seem like a fantastic opportunity; they promise millions of users, etc. But none of this happens. Cuz you talk to a regular employees there. They waste your time, destroy focus, shift priorities, and eventually bring in no users/money.14. Don’t get ever distracted by hype, e.g. crypt0.I lost years of my life this way.I met the worst people along the way. Fricks, scammers, thieves. Some of my close friends turned into thieves along the way.15. Don’t build consumer apps. Only b2b.16. Don’t hold on to the lousy project for too long.17. Tech conferences are a waste of time.18. Scrum is a Scam.If I had a team that had to be nagged every morning with questions as if they were kindergarten children, things would eventually fail.Once I killed scrum, things changed; lazy folks left, grownups entered my team & we've been concurring the world.19. Outsource nothing until PMF.20. Bootstrap.I raised over 10 times, preseed, seed, and series A.Today, I bootstrap all my startups.The difference is huge. I'm totally obsessed with products & users now, while in the past, I was obsessed with funding rounds, events, news coverage.21. Some of my bootstrapped startups:↳ Nocode web builder↳ List your project on most relevant directories↳ AI Agent for Blog SEOMore about me: johnrush.me or my twitter!Subscribe for free to receive new posts and support my work.SubscribeThis post is public, so feel free to share it.Share68 Likes∙13 Restacks68Share this postJohn RushIf only someone told me this before my 1st startupCopy linkFacebookEmailNotesMore1313Share",
    "summary": {
      "en": "John Rush shares important lessons he's learned from his startup experiences. Here are the key points:\n\n1. **Validate Your Idea**: Ensure there's a need for your product before investing time in it.\n2. **Set Aside Ego**: Focus on satisfying your users rather than your own preferences.\n3. **Prioritize Users Over Investors**: Attract users first; investors will follow.\n4. **Hire Doers, Not Managers**: Employ practical workers until your product-market fit (PMF) is achieved.\n5. **Simple Landing Page**: Use a basic template; most sales happen outside your website in early stages.\n6. **Fullstack Developers**: Hire versatile developers to build the entire product efficiently.\n7. **Global Market Focus**: Aim for a global audience from the start for greater potential.\n8. **Start SEO Early**: Begin search engine optimization as soon as possible to avoid regrets later.\n9. **Feature Validation**: Discuss potential features with users before development to ensure demand.\n10. **Hire for Compatibility**: Only work with people you genuinely like to avoid future conflicts.\n11. **Invest in Yourself and Friends**: Supporting your friends' startups can yield high returns.\n12. **Daily Online Presence**: Post on social media regularly for networking and marketing benefits.\n13. **Avoid Corporate Partnerships**: They often promise much but deliver little and can distract you.\n14. **Ignore Hype**: Stay focused and steer clear of trends that lead to wasted time and poor connections.\n15. **B2B Focus**: Concentrate on business-to-business applications rather than consumer ones.\n16. **Let Go of Bad Projects**: Don’t cling to unsuccessful ventures.\n17. **Skip Tech Conferences**: They often don't provide valuable returns on time invested.\n18. **Scrum Methodology Issues**: Traditional management methods can hinder productivity; find a better fit for your team.\n19. **Outsourcing Caution**: Don’t outsource tasks until you have product-market fit.\n20. **Bootstrap Your Startup**: Focus on building products and serving users rather than seeking external funding.\n\nThese insights aim to help new entrepreneurs avoid common pitfalls and focus on what truly matters for success.",
      "ko": "존 러시는 스타트업 경험에서 배운 중요한 교훈을 공유했습니다. 여기 주요 내용이 있습니다.\n\n첫째, 아이디어를 검증하세요. 제품에 대한 수요가 있는지 확인한 후에 시간을 투자하는 것이 중요합니다. 둘째, 자아를 내려놓으세요. 자신의 취향보다 사용자 만족에 집중해야 합니다. 셋째, 투자자보다 사용자를 우선시하세요. 먼저 사용자를 끌어모은 후 투자자들이 따라올 것입니다. 넷째, 관리자보다는 실행 가능한 인재를 고용하세요. 제품과 시장의 적합성을 이룰 때까지 실무형 인력을 채용하는 것이 좋습니다.\n\n다섯째, 간단한 랜딩 페이지를 만드세요. 초기 단계에서는 대부분의 판매가 웹사이트 외부에서 이루어지므로 기본 템플릿을 사용하는 것이 효과적입니다. 여섯째, 풀스택 개발자를 고용하세요. 다양한 기술을 가진 개발자를 통해 제품을 효율적으로 구축할 수 있습니다. 일곱째, 글로벌 시장을 목표로 하세요. 처음부터 전 세계의 잠재 고객을 염두에 두는 것이 중요합니다.\n\n여덟째, SEO를 조기에 시작하세요. 검색 엔진 최적화를 가능한 빨리 시작하여 나중에 후회하지 않도록 해야 합니다. 아홉째, 기능 검증을 하세요. 개발 전에 사용자와 잠재적인 기능에 대해 논의하여 수요를 확인하는 것이 필요합니다. 열째, 호환성을 고려하여 인재를 채용하세요. 진정으로 좋아하는 사람들과만 일하는 것이 미래의 갈등을 피하는 데 도움이 됩니다.\n\n열한째, 자신과 친구에게 투자하세요. 친구의 스타트업을 지원하는 것이 높은 수익을 가져올 수 있습니다. 열두째, 매일 온라인에 존재감을 유지하세요. 소셜 미디어에 정기적으로 게시하여 네트워킹과 마케팅 효과를 누릴 수 있습니다. 열세째, 기업 파트너십을 피하세요. 이들은 종종 많은 것을 약속하지만 실질적인 결과는 적고, 주의를 분산시킬 수 있습니다.\n\n열네째, 과대 광고를 무시하세요. 집중력을 유지하고 시간 낭비와 잘못된 연결로 이어지는 트렌드를 피해야 합니다. 열다섯째, B2B에 집중하세요. 소비자보다는 기업 간의 응용 프로그램에 초점을 맞추는 것이 좋습니다. 열여섯째, 실패한 프로젝트는 과감히 포기하세요. 성공하지 못한 사업에 집착하지 않는 것이 중요합니다.\n\n열일곱째, 기술 컨퍼런스를 건너뛰세요. 이들은 종종 투자한 시간에 비해 가치 있는 결과를 제공하지 않습니다. 열여덟째, 스크럼 방법론의 문제를 인식하세요. 전통적인 관리 방법이 생산성을 저해할 수 있으므로 팀에 더 적합한 방법을 찾아야 합니다. 마지막으로, 아웃소싱에 주의하세요. 제품과 시장의 적합성을 이루기 전까지는 작업을 아웃소싱하지 않는 것이 좋습니다. \n\n스타트업을 자립적으로 운영하는 데 집중하고 외부 자금을 찾기보다는 제품을 만들고 사용자에게 서비스를 제공하는 데 중점을 두세요. 이러한 통찰력은 새로운 기업가들이 일반적인 함정을 피하고 성공에 필요한 진정한 요소에 집중하는 데 도움을 줄 것입니다.",
      "ja": "ジョン・ラッシュは、自身のスタートアップ経験から得た重要な教訓を共有しています。以下はその主なポイントです。\n\nまず、アイデアの検証が重要です。製品に対するニーズがあるかどうかを確認してから、時間を投資しましょう。次に、自分のエゴを脇に置き、ユーザーの満足を優先することが大切です。投資家よりもまずユーザーを引きつけることが必要で、そうすれば投資家もついてきます。\n\nまた、実行力のある人材を雇うことが推奨されます。製品と市場の適合性が確立されるまで、実務的な人を採用しましょう。初期段階では、シンプルなランディングページを使用することが効果的です。多くの販売はウェブサイト外で行われるため、基本的なテンプレートで十分です。\n\nフルスタック開発者を雇うことも重要です。全体の製品を効率的に構築できる多才な開発者が必要です。さらに、初めからグローバル市場を意識することで、より大きな可能性を追求できます。検索エンジン最適化（SEO）も早めに始めるべきで、後悔しないために早期の取り組みが求められます。\n\n機能の検証も忘れずに。開発前にユーザーと潜在的な機能について話し合い、需要を確認しましょう。また、相性の良い人とだけ仕事をすることが大切です。そうすることで、将来的な対立を避けられます。\n\n自分自身や友人のスタートアップに投資することも有益です。友人を支援することで、高いリターンが期待できます。日々のオンラインプレゼンスを維持し、ソーシャルメディアで定期的に投稿することで、ネットワーキングやマーケティングの効果が得られます。\n\n企業とのパートナーシップは避けるべきです。約束が多い割に実際の成果が少なく、注意をそらされることが多いからです。また、流行に惑わされず、集中力を保ち、時間を無駄にするトレンドからは距離を置くことが重要です。\n\nビジネス向けのアプリケーションに焦点を当て、消費者向けよりもB2Bに集中しましょう。失敗したプロジェクトに執着せず、手放すことも必要です。技術系のカンファレンスは、投資した時間に対して価値が少ないことが多いので、参加を避けるべきです。\n\nスクラム手法などの伝統的な管理方法は、生産性を妨げることがあるため、チームに合った方法を見つけることが大切です。製品と市場の適合性が確立されるまで、業務を外注することは避けましょう。最後に、外部資金を求めるのではなく、製品を構築し、ユーザーにサービスを提供することに集中することが重要です。\n\nこれらの洞察は、新しい起業家が一般的な落とし穴を避け、成功に必要なことに集中する手助けをすることを目的としています。"
    }
  },
  {
    "id": "dd21d9bbd9e6583f",
    "title": {
      "en": "Search My Site – open-source search engine for personal and independent websites",
      "ko": "내 사이트 검색기",
      "ja": "サイト検索エンジン"
    },
    "type": "story",
    "url": "https://searchmysite.net",
    "score": 258,
    "by": "OuterVale",
    "time": 1742869143,
    "content": "Browse\n\n\t\t\t\t\t\t\t\t\tNewest\n\n\t\t\t\t\t\t\t\t\t\tRandom\n\n\t\t\t\t\t\t\tSearch real content by real people from the indieweb / the small web / digital gardens.\n\t\t\t\t\t\t\tSites are ranked higher when they have no ads.\n\t\t\t\t\t\t\tFully open source. Also a search as a service.\n\n\t\t\t\t\tAbout searchmysite.net\n\n\t\t\t\t\t\tWhat is the search engine and why should I use it?\n\n\t\t\t\t\t\tThe searchmysite.net search engine is a niche search, focussing on the \"indieweb\" or \"small web\" or \"digital gardens\", i.e. non-commercial content, primarily personal and independent websites.\n\n\t\t\t\t\t\tIf you want to research people's personal experiences of or deep-dives into certain topics, hobbies or interests, then you may find the searchmysite.net public search useful to avoid having to wade through all the marketing websites and blog spam that fill the big search engines. It differs from the commercial search engines because it:\n\n\t\t\t\t\t\tIndexes only user-submitted and moderated sites, rather than indexing the entire internet with all of its spam, \"search engine optimisation\" and \"click-bait\" content.\n\t\t\t\t\t\tDoes not show adverts and promotes advert-free results pages, to remove the incentives for spam and surveillance capitalism.\n\t\t\t\t\t\tAims to have a sustainable and user-aligned operating model, planning to pay running costs via the \"search as a service\" features, rather than relying on advertising which could put it in conflict with user needs.\n\t\t\t\t\t\tOffers an unusually high level of privacy for a search engine, thanks to the operating model which is not based on advertising or collecting personal information for sale to advertisers (see the Privacy Policy for full details).\n\t\t\t\t\t\tIs fully open source, for even greater transparency of the searching, ranking and indexing processes, and for greater community involvement in improving the service.",
    "summary": {
      "en": "**Summary of searchmysite.net**\n\nsearchmysite.net is a niche search engine focused on the \"indieweb,\" \"small web,\" or \"digital gardens,\" which includes non-commercial, personal, and independent websites. It is useful for finding personal experiences and in-depth information on various topics without the clutter of ads and spam present in larger search engines.\n\nKey features include:\n- **User-Submitted Sites**: It only indexes sites that users submit and moderate, avoiding irrelevant content.\n- **Ad-Free Experience**: There are no advertisements, promoting cleaner results and reducing spam.\n- **Sustainable Model**: It plans to cover costs through \"search as a service\" rather than relying on advertising.\n- **Privacy Focus**: It prioritizes user privacy, not collecting personal data for advertising.\n- **Open Source**: The platform is fully open source, encouraging community involvement and transparency in its operations.",
      "ko": "searchmysite.net은 \"인디웹\", \"소규모 웹\", 또는 \"디지털 정원\"에 초점을 맞춘 틈새 검색 엔진입니다. 이 사이트는 비상업적이고 개인적인 독립 웹사이트를 포함하여, 광고와 스팸이 넘치는 대형 검색 엔진에서 벗어나 개인적인 경험과 다양한 주제에 대한 심층 정보를 찾는 데 유용합니다.\n\n주요 특징으로는 사용자 제출 사이트만 색인화하여 관련 없는 콘텐츠를 피하는 점이 있습니다. 광고가 없기 때문에 결과가 더 깔끔하고 스팸이 줄어드는 장점도 있습니다. 이 플랫폼은 광고에 의존하지 않고 \"서비스로서의 검색\"을 통해 비용을 충당할 계획입니다. 또한 사용자 개인 정보를 수집하지 않아 프라이버시를 우선시합니다. 마지막으로, 이 플랫폼은 완전한 오픈 소스이며, 커뮤니티의 참여와 운영의 투명성을 장려합니다.",
      "ja": "searchmysite.netは、「インディウェブ」や「スモールウェブ」、または「デジタルガーデン」に特化したニッチな検索エンジンです。これらは非商業的で個人の独立したウェブサイトを含みます。この検索エンジンは、広告やスパムが多い大手の検索エンジンとは異なり、個人の体験やさまざまなトピックに関する深い情報を見つけるのに役立ちます。\n\n主な特徴としては、ユーザーが提出したサイトのみをインデックスすることが挙げられます。これにより、関連性のないコンテンツを避けることができます。また、広告が一切表示されないため、クリーンな結果が得られ、スパムも減少します。さらに、広告に依存せず「検索サービス」としてコストを賄う持続可能なモデルを目指しています。\n\nプライバシーにも配慮しており、広告のために個人データを収集することはありません。加えて、プラットフォームは完全にオープンソースであり、コミュニティの参加や運営の透明性を促進しています。"
    }
  },
  {
    "id": "2cabaee1145596a6",
    "title": {
      "en": "The long-awaited Friend Compound laws in California",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://supernuclear.substack.com/p/the-long-awaited-friend-compound",
    "score": 38,
    "by": "simonebrunozzi",
    "time": 1742995311,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "5fd9323b53e01869",
    "title": {
      "en": "HoarePrompt: Structural Reasoning About Program Correctness in Natural Language",
      "ko": "호어프롬프트: 자연어로 프로그램 정확성 분석",
      "ja": "プログラムの正しさを考える"
    },
    "type": "story",
    "url": "https://github.com/msv-lab/HoarePrompt",
    "score": 4,
    "by": "mechtaev",
    "time": 1742967316,
    "content": "HoarePrompt: Structural Reasoning About Program Correctness in Natural Language\n\nHoarePrompt structurally reasons about program correctness in natural language using large language models (LLMs). Drawing inspiration from the strongest postcondition calculus, it employs a step-by-step process to generate natural language descriptions of reachable program states at various program points. By aligning formal semantics with informal requirements, HoarePrompt enables LLMs to detect bugs that violate natural language specifications.\nKey features:\n\nCorrectness assessment: classify program correctness with respect to natural language specifications, providing a verdict of CORRECT or INCORRECT.\nDescriptions of reachable states: infer natural language descriptions of reachable program states without executing the program.\nLoop summarization: apply a novel few-shot-driven k-induction to precisely summarize the semantics of loops in natural language.\n\nPreprint:\n\nHoarePrompt: Structural Reasoning About Program Correctness in Natural LanguageDimitrios Stamatios Bouras, Yihan Dai, Tairan Wang, Yingfei Xiong, Sergey Mechtaevhttps://arxiv.org/abs/2503.19599\n\nInstallation\n1. Set up a Virtual Environment\nTo ensure dependency isolation and compatibility, it's recommended to create a virtual environment:\n# Create a virtual environment\npython3 -m venv hoareprompt-env\n\n# Activate the virtual environment\nsource hoareprompt-env/bin/activate\n\n2. Install Dependencies\nInstall the necessary dependencies by running:\npip install -r requirements.txt\n\n3. Set API Keys\nDepending on the LLM service you're using, set environment variables for the API keys.\nFor OpenAI models:\nexport OPENAI_API_KEY=\"your-openai-api-key\"\n\nFor Qwen models:\nexport DASHSCOPE_API_KEY=\"your-dashscope-api-key\"\n\nYou can add these export commands to your .bashrc or .zshrc file to avoid having to set them every time.\nAdditional providers and models can be configured in src/model.py.\nMotivating Example\nTo motivate our approach, we first show that annotating a program with natural language descriptions of reachable program states enhances an LLM's reasoning about program correctness.\nState Descriptions Enhance LLM Reasoning\nConsider the problem: Given an integer list, the task is to find the maximum product of any sublist. The left side of the figure below presents a flawed implementation of Kadane’s algorithm for solving this problem.\nThe description and code for this example can be found at examples/motivating_example/description.txt and examples/motivating_example/program.py.\n\nThe bug in this implementation stems from incorrect indentation, which results in best_so_far being updated only once—after the loop ends—instead of being updated during each iteration.\nDespite the simplicity of this bug, state-of-the-art  LLMs often fail to identify it consistently, misclassifying the program as correct. Because LLMs exhibit non-deterministic behavior and are sensitive to prompt design, testing their effectiveness in detecting such errors is challenging. To provide objective evidence, we crafted six distinct prompts—including a simple \"Vanilla\" prompt, a Zero-shot-CoT prompt, and an open-ended prompt—each containing the problem description and the code snippet. We generated 10 responses for each prompt using three different LLMs and various temperature settings.\n\nModel\nNot Annotated\nAnnotated\n\nQwen2.5-7B\n0%\n11.7%\n\nQwen2.5-Coder-32B\n15%\n85%\n\nQwen2.5-72B\n35%\n85%\n\nThe results above show that without state annotations, LLMs rarely detect the bug. An example of an incorrect response from the Vanilla prompt is presented on the left side of the figure. However, HoarePrompt enhances this process by systematically inferring natural preconditions and postconditions from the problem description, then propagating reachable program states across the control flow.\nBy iteratively applying this process, HoarePrompt constructs a structured representation of program states, making it easier for LLMs to reason about correctness. With these annotations, the bug detection rate increases significantly.\nRunning the Motivational Example\nYou can run the motivational example using the following command:\npython src/hoareprompt.py --description examples/motivating_example/description.txt --program examples/motivating_example/program.py --config configs/config_motivational.json\n\nAlternatively, specify the type of command and the log path too:\npython src/hoareprompt.py --command assess --description examples/motivating_example/description.txt --program examples/motivating_example/program.py --config configs/config_motivational.json --log logs/motivating_example/\n\nUsage\nHoarePrompt provides several commands to analyze programs.\n1. Assess (Default Command)\nThis command evaluates whether a program conforms to a given problem description. If no specific command is provided, HoarePrompt defaults to assess.\nUsage:\npython src/hoareprompt.py --description <FILE> --program <FILE>\n\nOR\npython src/hoareprompt.py --command assess --description <FILE> --program <FILE>\n\nOR\npython src/hoareprompt.py --command assess --description <FILE> --program <FILE> --config <FILE> --log <FILE>\n\nThis outputs either CORRECT or INCORRECT based on the program assessment.\n2. Extract Precondition\nGenerates a precondition from the problem description.\nUsage:\npython src/hoareprompt.py --command extract-precondition --description example/description.txt --program example/program.py\n\n3. Compute Postcondition\nComputes the postcondition for a program fragment.\nUsage:\npython src/hoareprompt.py --command compute-postcondition --precondition example/precondition.txt --program example/program.py\n\n4. Check Entailment\nVerifies if the computed postcondition satisfies the problem description.\nUsage:\npython src/hoareprompt.py --command check-entailment --description example/description.txt --program example/program.py --postcondition example/postcondition.txt\n\nLog and Counterexample Options\n\nLog Directory: Specify --log to save detailed logs.\nCounterexample Generation: Use --cex <FILE> with assess or check-entailment to generate counterexamples.\n\nConfiguration\nHoarePrompt allows users to customize its behavior using a JSON configuration file. By default, it uses default-config.json.\nSpecify a custom config:\npython src/hoareprompt.py --config <FILE>\n\nAssessment Modes\n\nnaive: Directly assesses if the program aligns with its description.\npostcondition-entailment: Uses postcondition analysis to check specification adherence.\nnaive-test: Asks the LLM to generate input-output test pairs to determine correctness. Always used with 'verify-answer' as entailement-mode.\n\nAdditional Configuration Options\n\nloop-unrolling-count: Controls loop unrolling (set 0 to disable summarization).\n\nconcat-simple: Determines whether simple statements are combined for token efficiency (default true).\n\nannotated: Enables annotated code trees for entailment checking.\n\nfsl: Enables Few-Shot Learning (true by default).\n\nCOT : Use or don't use Chain of Thgough reasoning with vanilla clasisifiers\n\nentailment-mode: Options include naive, cot, and verify-answer.\n\nReady-to-Use Configurations\nPredefined configurations for classifiers used in the HoarePrompt paper are available in the configs folder:\n\nVanilla: configs/config_tester_*.json\nZero-Shot-CoT: configs/config_zero_shot_COT_*.json\nTester-based: configs/config_tester_*.json\nHoarePrompt (3 unrolls): configs/config_hoareprompt_*.json\nHoarePrompt (no unrolls): configs/config_hoareprompt_no_unroll_*.json\n\nRelated Repositories\nThe HoarePrompt project consists of multiple repositories, each serving a specific function:\n\nHoarePrompt (Main Repo)  (This is the current repo you are on)\n\nThe core repository containing the implementation of HoarePrompt, including the logic for analyzing programs, state propagation, and correctness verification.\n\nHoarePrompt-data\n\nA dedicated repository for storing experimental results and datasets related to HoarePrompt evaluations. This includes correctness assessments, counterexamples, and other findings from our testing.\n\nHoarePrompt-experiments\n\nThis repository provides scripts and configurations to run large-scale experiments with HoarePrompt on various datasets. It includes automated evaluation scripts and batch processing tools.\n\nCoCoClaNeL\n\na dataset of recent submissions to Codeforces contests, and associated documentation.\n\nLicense\nThis dataset is released under the MIT License. See the LICENSE file for details.",
    "summary": {
      "en": "**Summary of HoarePrompt: Structural Reasoning About Program Correctness in Natural Language**\n\nHoarePrompt is a tool that uses large language models (LLMs) to check if computer programs are correct based on natural language descriptions. It follows a structured approach inspired by formal logic to help LLMs identify bugs in code that don't meet specifications.\n\n**Key Features:**\n1. **Correctness Assessment**: It evaluates programs and classifies them as CORRECT or INCORRECT based on given descriptions.\n2. **State Descriptions**: It generates understandable descriptions of program states without running the code.\n3. **Loop Summarization**: It summarizes loop behaviors in a clear way using advanced techniques.\n\n**Motivating Example**: An example shows that adding natural language descriptions helps LLMs find bugs more effectively. For instance, a coding error in a flawed implementation of Kadane’s algorithm was often missed by LLMs without state annotations. With these annotations, bug detection improved significantly.\n\n**Installation Steps**:\n1. Create and activate a virtual environment.\n2. Install necessary dependencies.\n3. Set API keys for the LLM services being used.\n\n**Usage**: HoarePrompt can analyze programs with various commands, including assessing correctness, extracting preconditions, and verifying postconditions. Users can customize its behavior with configuration files.\n\n**Additional Information**: The project includes multiple repositories for core functions, experimental results, and large-scale testing. It is released under the MIT License.",
      "ko": "HoarePrompt는 자연어 설명을 기반으로 컴퓨터 프로그램의 정확성을 확인하는 도구입니다. 이 도구는 형식 논리에서 영감을 받은 구조적 접근 방식을 사용하여 대형 언어 모델이 사양을 충족하지 않는 코드의 버그를 식별하도록 돕습니다.\n\n주요 기능으로는 프로그램의 정확성을 평가하고 주어진 설명에 따라 프로그램을 CORRECT 또는 INCORRECT로 분류하는 기능이 있습니다. 또한 코드를 실행하지 않고도 프로그램 상태에 대한 이해하기 쉬운 설명을 생성합니다. 반복문 동작을 명확하게 요약하는 고급 기술도 포함되어 있습니다.\n\n예를 들어, 자연어 설명을 추가하면 대형 언어 모델이 버그를 더 효과적으로 찾아낼 수 있다는 것을 보여주는 사례가 있습니다. 예를 들어, 카다네 알고리즘의 잘못된 구현에서 발생한 코딩 오류는 상태 주석 없이 대형 언어 모델이 자주 놓쳤습니다. 그러나 이러한 주석이 추가되자 버그 탐지가 크게 향상되었습니다.\n\n설치 과정은 가상 환경을 생성하고 활성화한 후 필요한 종속성을 설치하고 사용하는 LLM 서비스에 대한 API 키를 설정하는 단계로 이루어집니다.\n\nHoarePrompt는 정확성 평가, 전제 조건 추출, 후 조건 검증 등 다양한 명령어로 프로그램을 분석할 수 있습니다. 사용자는 구성 파일을 통해 도구의 동작을 맞춤 설정할 수 있습니다.\n\n이 프로젝트는 핵심 기능, 실험 결과 및 대규모 테스트를 위한 여러 저장소를 포함하고 있으며, MIT 라이선스 하에 배포됩니다.",
      "ja": "HoarePromptは、大規模言語モデル（LLM）を利用して、自然言語の説明に基づいてコンピュータプログラムの正しさを確認するツールです。形式論理に触発された構造的アプローチを採用しており、LLMが仕様を満たさないコードのバグを特定するのを助けます。\n\nこのツールの主な機能には、プログラムの正しさを評価し、与えられた説明に基づいて「正しい」または「誤り」と分類することが含まれます。また、コードを実行することなくプログラムの状態を理解しやすく説明する機能や、ループの動作を明確に要約する高度な技術も備えています。\n\n具体的な例として、自然言語の説明を追加することで、LLMがバグをより効果的に見つけられることが示されています。例えば、Kadaneのアルゴリズムの不完全な実装におけるコーディングエラーは、状態の注釈がない場合にはLLMによって見逃されることが多かったですが、注釈を加えることでバグ検出が大幅に改善されました。\n\nインストール手順は、まず仮想環境を作成して有効化し、必要な依存関係をインストールし、使用するLLMサービスのAPIキーを設定するという流れです。\n\nHoarePromptは、正しさの評価や前提条件の抽出、後条件の検証など、さまざまなコマンドを使ってプログラムを分析できます。ユーザーは設定ファイルを使って動作をカスタマイズすることも可能です。\n\nこのプロジェクトには、コア機能、実験結果、大規模テスト用の複数のリポジトリが含まれており、MITライセンスのもとで公開されています。"
    }
  },
  {
    "id": "d17a965f16c65d75",
    "title": {
      "en": "GSA Announces FedRAMP 20x",
      "ko": "GSA, FedRAMP 20배 발표!",
      "ja": "GSAがFedRAMP 20倍を発表"
    },
    "type": "story",
    "url": "https://www.gsa.gov/about-us/newsroom/news-releases/gsa-announces-fedramp-20x-03242025",
    "score": 19,
    "by": "duck",
    "time": 1742935851,
    "content": "GSA announces FedRAMP 20x\n\n          March 24, 2025\n\n          Implementing a new approach to accelerate cloud adoptionWASHINGTON— The U.S. General Services Administration (GSA), a leader in providing tools and guidance to help federal agencies deliver seamless digital services to American taxpayers, announced today that the Federal Risk and Authorization Management Program (FedRAMPⓇ) will focus on working with industry to develop a new, cloud-native approach to authorizations.FedRAMP 20x will focus on innovating alternative approaches to make automated authorization simpler, easier, and cheaper while continuously improving security. The FedRAMP team will also continue to support traditional agency authorizations.“Since the start of this Administration, we’ve focused on improving government operations to make them more efficient and effective for every employee and the American taxpayer,” said GSA Acting Administrator Stephen Ehikian. “Our partnership with the commercial cloud industry needs serious improvement. Strengthening this relationship will help us fulfill our commitment to cutting waste and adopting the best available technologies to modernize the government’s aging IT infrastructure. FedRAMP 20x will give agencies access to the latest technology now — not months or years down the road.”FedRAMP 20x is built on these core principles:GSA will set the foundation for private sector innovation: FedRAMP will make it easier for cloud providers to follow modern security practices and show their leadership in developing secure cloud solutions for the government. FedRAMP will also hold public working groups to gather input from industry, ensure equal access to information, encourage pilot programs, and provide technical guidance before formal public comment and release.Cutting red tape through automation: FedRAMP is required for all federal agency cloud services, but getting approved currently involves a lot of paperwork and a slow manual process. FedRAMP 20x will reduce unnecessary paperwork and aim to automate as much of the process as possible to accelerate approvals in a cost efficient manner.Faster, more secure cloud adoption: Currently, it can take months or even years for a cloud provider to get FedRAMP approval, which slows down how quickly agencies can adopt new technology. FedRAMP 20x will simplify and clarify security requirements so that new cloud services can be approved in weeks instead of years.More flexibility and better collaboration: FedRAMP has traditionally acted as a middleman between agencies and cloud providers. FedRAMP 20x will build on existing trust and make it easier for providers and agencies to work together directly.“FedRAMP is a shared service that meets the critical needs of agencies government-wide,” saidTechnology Transformation Services Director and Deputy Commissioner of the Federal Acquisition Service Thomas Shedd. “We’re not just modernizing a process; we’re reimagining how federal cloud security can work and providing agencies the ability to determine their own risk posture. FedRAMP 20x represents our commitment to cutting through complexity, empowering innovation, and ensuring that security keeps pace with technological advancement. FedRAMP 20x will keep driving faster, smarter, and more customer-focused service for years to come.”Some of the changes being made to further position the program where it belongs, at the pace of technology, include:No federal agency sponsor needed for simple, low-impact service offeringsNo unnecessary or duplicative paperworkTurn-key adoption for simple, cloud-native environmentsEngineer-friendly security requirements that are easy to implementAuthorization in weeks for most cloud offerings“As a member of the FedRAMP Board, I am incredibly excited about FedRAMP 20x,” saidChief Product Officer and Deputy Chief Information Officer, Product Delivery Service (PDS), in the Office of Information and Technology at the Department of Veterans Affairs Carrie Lee. “This transformative vision will streamline FedRAMP processes, leveraging automation and modern technologies to accelerate secure cloud adoption across federal agencies. By reducing authorization times from years to weeks and enhancing security postures through our modernization efforts, we are setting a new standard for efficiency and innovation. This initiative will lower vendor costs, increase competition, and build greater trust with industry. FedRAMP 20x is a game-changer, and I am proud to be part of this journey towards a more secure and efficient federal cloud landscape.”The private sector has already shared their excitement about FedRAMP 20x. FedRAMP stakeholders stated:“Increased government efficiency and transformation are imperative for all agencies as they work to modernize legacy technology, streamline complex processes, and improve operations. GSA’s new approach is no exception… streamlining FedRAMP will expedite the adoption of secure, innovative technologies across government. We look forward to continuing to work closely with FedRAMP as an early adopter of FedRAMP 20x and accelerating our customers’ adoption of our solutions.” - From a Cloud Service Provider (CSP)“We would appreciate the ability to make changes without bureaucracy.” - From a CSP“This is aligned to how compliance should be.” - From a CSP“The concept of government as consumers rather than approvers represents a fundamental shift.” - From an Industry Trade Association“It’s a step in the right direction.” - From a Third Party Assessment Association (3PAO)For more information about FedRAMP 20x, please visitfedramp.gov,read theFedRAMP 20x blog postor download theFedRAMP 20x industry engagement kit.###About GSA:GSA provides centralized procurement and shared services for the federal government. GSA manages a nationwide real estate portfolio of over 360 million rentable square feet, oversees more than $110 billion in products and services via federal contracts, and delivers technology services that serve millions of people across dozens of federal agencies. GSA’s mission is to deliver the best customer experience and value in real estate, acquisition, and technology services to the government and the American people. For more information, visitGSA.gov and follow us at@USGSA.\n\n          Contact\npress@gsa.gov",
    "summary": {
      "en": "**Summary of FedRAMP 20x Announcement**\n\nOn March 24, 2025, the U.S. General Services Administration (GSA) announced a new initiative called FedRAMP 20x aimed at speeding up cloud adoption in federal agencies. The program will simplify the authorization process for cloud services, making it quicker, easier, and more affordable while maintaining strong security.\n\nKey points of FedRAMP 20x include:\n\n- **Innovation and Collaboration**: GSA will work with cloud providers to encourage modern security practices and support innovation, including public working groups for industry input.\n- **Reduced Bureaucracy**: The process for cloud service approval will be streamlined to cut down on paperwork and automate many steps, allowing approvals to happen in weeks instead of months or years.\n- **Direct Agency-Provider Interactions**: Agencies will have more flexibility to work directly with cloud providers, enhancing collaboration.\n- **Simplified Security Requirements**: Security standards will be clarified to help cloud providers comply more easily.\n\nThe initiative is expected to improve government efficiency, lower costs for vendors, and foster a more secure federal cloud environment. Many stakeholders in the private sector have expressed support for these changes, emphasizing the need for streamlined processes in government technology adoption.\n\nFor more details, visit the FedRAMP website or check their blog.",
      "ko": "2025년 3월 24일, 미국 일반서비스청(GSA)은 연방 기관의 클라우드 도입을 가속화하기 위한 새로운 이니셔티브인 FedRAMP 20x를 발표했습니다. 이 프로그램은 클라우드 서비스의 승인 절차를 간소화하여 더 빠르고 쉽게, 그리고 저렴하게 진행할 수 있도록 하면서도 강력한 보안을 유지하는 것을 목표로 하고 있습니다.\n\nFedRAMP 20x의 주요 내용은 다음과 같습니다. 첫째, GSA는 클라우드 제공업체와 협력하여 현대적인 보안 관행을 장려하고 혁신을 지원할 것입니다. 이를 위해 업계의 의견을 반영하기 위한 공개 작업 그룹도 운영할 예정입니다. 둘째, 클라우드 서비스 승인을 위한 절차가 간소화되어 서류 작업이 줄어들고 많은 단계가 자동화됩니다. 이로 인해 승인이 몇 개월 또는 몇 년이 아닌 몇 주 안에 이루어질 수 있게 됩니다. 셋째, 기관들은 클라우드 제공업체와 직접 협력할 수 있는 더 많은 유연성을 가지게 되어 협업이 강화될 것입니다. 넷째, 보안 기준이 명확해져 클라우드 제공업체가 보다 쉽게 준수할 수 있도록 도와줄 것입니다.\n\n이 이니셔티브는 정부의 효율성을 높이고 공급업체의 비용을 줄이며, 보다 안전한 연방 클라우드 환경을 조성할 것으로 기대됩니다. 민간 부문의 많은 이해관계자들은 이러한 변화에 지지를 표명하며, 정부의 기술 도입 과정이 간소화될 필요성을 강조하고 있습니다.\n\n자세한 내용은 FedRAMP 웹사이트를 방문하거나 블로그를 확인하시기 바랍니다.",
      "ja": "2025年3月24日、アメリカ合衆国一般調達庁（GSA）は、連邦機関におけるクラウド導入を加速させる新しい取り組み「FedRAMP 20x」を発表しました。このプログラムは、クラウドサービスの認可プロセスを簡素化し、迅速かつ容易に、そして手頃な価格で利用できるようにしながら、強固なセキュリティを維持することを目指しています。\n\nFedRAMP 20xの主なポイントは以下の通りです。まず、GSAはクラウドプロバイダーと協力し、現代的なセキュリティプラクティスを促進し、イノベーションを支援します。業界からの意見を取り入れるための公開作業部会も設けられます。次に、クラウドサービスの承認プロセスは簡素化され、書類作業が削減され、多くのステップが自動化されるため、承認が数週間で行えるようになります。さらに、各機関はクラウドプロバイダーと直接やり取りする柔軟性が増し、協力が強化されます。最後に、セキュリティ要件が明確化され、クラウドプロバイダーがより容易に遵守できるようになります。\n\nこの取り組みにより、政府の効率が向上し、ベンダーのコストが削減され、より安全な連邦クラウド環境が促進されることが期待されています。民間セクターの多くの関係者は、政府の技術導入におけるプロセスの簡素化の必要性を強調し、これらの変更を支持しています。\n\n詳細については、FedRAMPのウェブサイトやブログを訪れてください。"
    }
  },
  {
    "id": "6a58398196f79699",
    "title": {
      "en": "Chewing gum can shed microplastics into saliva, pilot study finds",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://www.acs.org/pressroom/presspacs/2025/march/chewing-gum-can-shed-microplastics-into-saliva-pilot-study-finds.html",
    "score": 31,
    "by": "giuliomagnifico",
    "time": 1742930769,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "51a4532ce8e8b965",
    "title": {
      "en": "Show HN: macOS app to reduce eye strain (open-source)",
      "ko": "눈 피로 줄이는 macOS 앱",
      "ja": "目に優しいmacOSアプリ"
    },
    "type": "story",
    "url": "https://github.com/oxremy/BlinkMore",
    "score": 33,
    "by": "Remy42",
    "time": 1742906580,
    "content": "BlinkMoreFree\nBlinkMoreFree is an open source macOS menu bar application that helps reduce eye strain by fading your screen when you stare at it for too long without blinking. Using automated eye-tracking and customized settings to encourage you to blink more.\nBlinkMore\nIf you like the free version consider BlinkMore. Main difference: eye tracking turns on/off based on the app you are using, saving energy by only turning on for apps you choose. I like to use with text-heavy tasks like reading/research.\nRequirements\n\nmacOS 14 (Sonoma) or later\nUses Mac's built-in front facing camera\n\nPrivacy\nEverything happens right on your Mac—no data leaves your device or sticks around after you close the app. No accounts or personal information needed.\nTips for Best Experience\n\nMake sure your Mac's camera has a clear view of your eyes (heads-up: glasses at certain angles may have reflections that obstruct camera view).\nConsider the angle of your camera. Blink detection may not work at extreme angles, like laying in bed with Mac on your lap.\nBlinkMoreFree is perfect for text-heavy tasks like reading––just know it uses a good chunk of your Mac's power.\n\nCredits\nMade with ❤️ by oxremy and AI (Grok/Claude)",
    "summary": {
      "en": "**Summary of BlinkMoreFree and BlinkMore**\n\nBlinkMoreFree is a free, open-source app for macOS that helps reduce eye strain by reminding you to blink when you stare at your screen for too long. It uses your Mac's camera to track your eyes and encourages you to blink more often.\n\nIf you enjoy BlinkMoreFree, you might consider upgrading to BlinkMore, which offers better eye-tracking that activates based on the app you are using, helping to save energy during text-heavy tasks like reading or research.\n\n**Requirements:**\n- Works on macOS 14 (Sonoma) or later\n- Uses the built-in front-facing camera\n\n**Privacy:**\nAll data processing happens on your device, so no personal information is collected or stored.\n\n**Tips for Best Use:**\n- Ensure the camera has a clear view of your eyes.\n- Avoid extreme angles for better blink detection.\n\nBlinkMoreFree is ideal for reading but may use a lot of your Mac's power. \n\n**Credits:** Created by oxremy and AI (Grok/Claude).",
      "ko": "BlinkMoreFree는 macOS용 무료 오픈소스 앱으로, 화면을 너무 오래 바라볼 때 눈의 피로를 줄이기 위해 사용자가 눈을 깜박이도록 상기시켜 줍니다. 이 앱은 Mac의 카메라를 이용해 사용자의 눈을 추적하고, 더 자주 깜박이도록 유도합니다.\n\nBlinkMoreFree가 마음에 드신다면, 더 나은 눈 추적 기능을 제공하는 BlinkMore로 업그레이드하는 것도 고려해볼 수 있습니다. BlinkMore는 사용 중인 앱에 따라 활성화되어, 읽기나 연구와 같은 텍스트 중심 작업에서 에너지를 절약하는 데 도움을 줍니다.\n\n이 앱은 macOS 14(소노마) 이상에서 작동하며, 내장된 전면 카메라를 사용합니다. 모든 데이터 처리는 사용자의 기기에서 이루어지므로 개인 정보가 수집되거나 저장되지 않습니다.\n\n최고의 사용을 위해 카메라가 눈을 잘 볼 수 있는 위치에 있는지 확인하고, 극단적인 각도를 피하면 깜박임 감지가 더 잘 이루어집니다. BlinkMoreFree는 독서에 적합하지만, Mac의 전력을 많이 소모할 수 있습니다.\n\n이 앱은 oxremy와 AI(Grok/Claude)에 의해 제작되었습니다.",
      "ja": "BlinkMoreFreeは、macOS向けの無料オープンソースアプリで、画面を長時間見つめることで目の疲れを軽減する手助けをします。このアプリは、Macのカメラを使用して目の動きを追跡し、まばたきを促します。\n\nBlinkMoreFreeを気に入った場合は、BlinkMoreへのアップグレードを検討してみてください。BlinkMoreは、使用中のアプリに応じて目の追跡機能が向上し、読書やリサーチなどのテキストが多い作業中にエネルギーを節約するのに役立ちます。\n\nこのアプリはmacOS 14（Sonoma）以降で動作し、内蔵の前面カメラを使用します。すべてのデータ処理はデバイス上で行われるため、個人情報は収集または保存されることはありません。\n\n最適に使用するためのポイントとしては、カメラが目をしっかりと捉えられる位置にあること、そして極端な角度を避けることが挙げられます。BlinkMoreFreeは読書に最適ですが、Macの電力を多く消費する可能性があります。\n\nこのアプリはoxremyとAI（Grok/Claude）によって作成されました。"
    }
  },
  {
    "id": "dece63737e377a4b",
    "title": {
      "en": "Status as a Service (2019)",
      "ko": "서비스로서의 상태",
      "ja": "ステータス提供サービス"
    },
    "type": "story",
    "url": "https://www.eugenewei.com/blog/2019/2/19/status-as-a-service",
    "score": 80,
    "by": "simonebrunozzi",
    "time": 1742885984,
    "content": "Status as a Service (StaaS)\n\n          February 26, 2019\n           by Eugene Wei\n\n  Editor's Note 1: I have no editor. Editor’s Note 2: I would like to assure new subscribers to this blog that most my posts are not as long as this one. Or as long as my previous one. My long break from posting here means that this piece is a collection of what would’ve normally been a series of shorter posts. I put section titles below, so skip any that don’t interest you. My short takes are on Twitter. All that said, I apologize for nothing. Editor's Note 3: I lied, I apologize for one thing, and that is my long writing hiatus. Without a work computer, I had to resort to using my 7 year old 13\" Macbook Pro as my main computer, and sometime last year my carpal tunnel syndrome returned with a vengeance and left my wrists debilitated with pain. I believe all of you who say your main computer is a laptop or, shudder, an iPad, but goodness gracious I cannot type on a compact keyboard for long periods of time without having my hands turn into useless stumps. It was only the return to typing almost exclusively on my old friend the Kinesis Advantage 2 ergo keyboard that put me back in the game. Editor’s Note 4: I was recently on Patrick O'Shaughnessy's podcast Invest Like the Best, and near the end of that discussion, I mentioned a new essay I'd been working on about the similarities between social networks and ICO's. This is that piece.Status-Seeking Monkeys\"It is a truth universally acknowledged, that a person in possession of little fortune, must be in want of more social capital.\"So wrote Jane Austen, or she would have, I think, if she were chronicling our current age (instead we have Taylor Lorenz, and thank goodness for that).Let's begin with two principles:People are status-seeking monkeys*People seek out the most efficient path to maximizing social capital* Status-Seeking Monkeys will also be the name of my indie band, if I ever learn to play the guitar and start a bandI begin with these two observations of human nature because few would dispute them, yet I seldom see social networks, some of the largest and fastest-growing companies in the history of the world, analyzed on the dimension of status or social capital.It’s in part a measurement issue. Numbers lend an air of legitimacy and credibility. We have longstanding ways to denominate and measure financial capital and its flows. Entire websites, sections of newspapers, and a ton of institutions report with precision on the prices and movements of money.We have no such methods for measuring the values and movement of social capital, at least not with anywhere near the accuracy or precision. The body of research feels both broad and yet meager. If we had better measures besides user counts, this piece and many others would be full of charts and graphs that added a sense of intellectual heft to the analysis. There would be some annual presentation called the State of Social akin to Meeker's Internet Trends Report, or perhaps it would be a fifty page sub-section of her annual report.Despite this, most of the social media networks we study generate much more social capital than actual financial capital, especially in their early stages; almost all such companies have internalized one of the popular truisms of Silicon Valley, that in the early days, companies should postpone revenue generation in favor of rapid network scaling. Social capital has much to say about why social networks lose heat, stall out, and sometimes disappear altogether. And, while we may not be able to quantify social capital, as highly attuned social creatures, we can feel it.Social capital is, in many ways, a leading indicator of financial capital, and so its nature bears greater scrutiny. Not only is it good investment or business practice, but analyzing social capital dynamics can help to explain all sorts of online behavior that would otherwise seem irrational.In the past few years, much progress has been made analyzing Software as a Service (SaaS) businesses. Not as much has been made on social networks. Analysis of social networks still strikes me as being like economic growth theory long before Paul Romer's paper on endogenous technological change. However, we can start to demystify social networks if we also think of them as SaaS businesses, but instead of software, they provide status. This post is a deep dive into what I refer to as Status as a Service (StaaS) businesses.Think of this essay as a series of strongly held hypotheses; without access to the types of data which i’m not even sure exists, it’s difficult to be definitive. As ever, my wise readers will add or push back as they always do.Traditional Network Effects Model of Social NetworksOne of the fundamental lessons of successful social networks is that they must first appeal to people when they have few users. Typically this is done through some form of single-user utility. This is the classic cold start problem of social.  The answer to the traditional chicken-and-egg question is actually answerable: what comes first is a single chicken, and then another chicken, and then another chicken, and so on. The harder version of the question is why the first chicken came and stayed when no other chickens were around, and why the others followed.The second fundamental lessons is that social networks must have strong network effects so that as more and more users come aboard, the network enters a positive flywheel of growth, a compounding value from positive network effects that leads to hockey stick growth that puts dollar signs in the eyes of investors and employees  alike. \"Come for the tool, stay for the network\" wrote Chris Dixon, in perhaps the most memorable maxim for how this works.Even before social networks, we had Metcalfe's Law on telecommunications networks:The value of a telecommunications network is proportional to the square of the number of connected users of the system (n^2)This ported over to social networks cleanly. It is intuitive, and it includes that tantalizing math formula that explains why growth curves for social networks bends up sharply at the ankle of the classic growth S-curve.But dig deeper and many many questions remain. Why do some large social networks suddenly fade away, or lose out to new tiny networks? Why do some new social networks with great single-player tools fail to transform into networks, while others with seemingly frivolous purposes make the leap? Why do some networks sometimes lose value when they add more users? What determines why different networks stall out at different user base sizes? Why do some networks cross international borders easily while others stay locked within specific countries? Why, if Metcalfe's Law holds, do many of Facebook's clones of other social network features fail, while some succeed, like Instagram Stories?What ties many of these explanations together is social capital theory, and how we analyze social networks should include a study of a social network's accumulation of social capital assets and the nature and structure of its status games. In other words, how do such companies capitalize, either consciously or not, on the fact that people are status-seeking monkeys, always trying to seek more of it in the most efficient way possible?To paraphrase Nicki Minaj, “If I'm fake I ain't notice cause my followers ain't.”[Editor’s note: sometimes the followers actually are fake.]Utility vs. Social Capital FrameworkClassic network effects theory still holds, I’m not discarding it. Instead, let's append some social capital theory. Together, those form the two axes on which I like to analyze social network health.Actually, I tend to use three axes to dissect social networks.\n\n              View fullsize\n\n            The three axes on which I evaluate social network strength\n\n  For this post, though, I'm only going to look at two of them, utility and social capital, as the entertainment axis adds a whole lot of complexity which I'll perhaps explain another time.\n\n              View fullsize\n\n            The basic two axis framework guiding much of the social network analysis in this piece\n\n  Utility doesn't require much explanation, though we often use the term very loosely and categorize too many things as utility when they aren't that useful (we generally confuse circuses for bread and not the reverse; Fox News, for example, is more entertainment than utility, as is common of many news outlets). A social network like Facebook allows me to reach lots of people I would otherwise have a harder time tracking down, and that is useful. A messaging app like WhatsApp allows me to communicate with people all over the world without paying texting or incremental data fees, which is useful. Quora and Reddit and Discord and most every social network offer some forms of utility.The other axis is, for a lack of a more precise term, the social capital axis, or the status axis. Can I use the social network to accumulate social capital? What forms? How is it measured? And how do I earn that status?There are several different paths to success for social networks, but those which compete on the social capital axis are often more mysterious than pure utilities. Competition on raw utility tends to be Darwinian, ruthless, and highly legible. This is the world, for example, of communication services like messaging and video conferencing.  Investing in this space also tends to be a bit more straightforward: how useful is your app or service, can you get distribution, etc. When investors send me decks on things in this category, I am happy to offer an opinion, but I enjoy puzzling over the world of artificial prestige even more.The creation of a successful status game is so mysterious that it often smacks of alchemy. For that reason, entrepreneurs who succeed in this space are thought of us a sort of shaman, perhaps because most investors are middle-aged white men who are already so high status they haven't the first idea why people would seek virtual status (more on that later).With the rise of Instagram, with its focus on photos and filters, and Snapchat, with its ephemeral messaging, and Vine, with its 6-second video limit, for a while there was a thought that new social networks would be built on some new modality of communications. That's a piece of it, but it's not the complete picture, and not for the reasons many people think, which is why we have seen a whole bunch of strange failed experiments in just about every odd combinations of features and filters and artificial constraints in how we communicate with each other through our phones. Remember Facebook's Snapchat competitor Slingshot, in which you had to unlock any messages you received by responding with a message? It felt like product design by mad libs.When modeling how successful social networks create a status game worth playing, a useful metaphor is one of the trendiest technologies: cryptocurrency.Social Networks as ICO'sHow is a new social network analogous to an ICO? Each new social network issues a new form of social capital, a token.You must show proof of work to earn the token.Over time it becomes harder and harder to mine new tokens on each social network, creating built-in scarcity. Many people, especially older folks, scoff at both social networks and cryptocurrencies. [\"Why does anyone care what you ate for lunch?\" is the canonical retort about any social network, though it’s fading with time. Both social networks and ICO's tend to drive skeptics crazy because they seem to manufacture value out of nothing. The shifting nature of scarcity will always leave a wake of skepticism and disbelief.]Years ago, I stayed at the house of a friend whose high school daughter was home upstairs with a classmates. As we adults drank wine in the kitchen downstairs while waiting for dinner to finish in the oven, we heard lots of music and stomping and giggling coming from upstairs. When we finally called them down for dinner, I asked them what all the ruckus had been. My friend's daughter proudly held up her phone to show me a recording they'd posted to an app called Musical.ly. It was a lip synch and dance routine replete with their own choreography. They'd rehearsed the piece more times than they could count. It showed. Their faces were shiny with sweat, and they were still breathing hard from the exertion. Proof of work indeed.I spent the rest of the dinner scrolling through the app, fascinated, interviewing the girls about what they liked about the app, why they were on it, what share of their free time it had captured. I can't tell if parents are offended or glad when I spend much of the time visiting them interviewing their sons and daughters instead, but in the absence of good enough metrics with which to analyze this space, I subscribe to the Jane Goodall theory of how to study your subject. Besides, status games of adults are already well covered by the existing media, from literature to film. Children's status games, once familiar to us, begin to fade from our memory as time passes, and its modern forms have been drastically altered by social media.Other examples abound. Perhaps you've read a long and thoughtful response by a random person on Quora or Reddit, or watched YouTube vloggers publishing night after night, or heard about popular Vine stars living in houses together, helping each other shoot and edit 6-second videos. While you can outsource Bitcoin mining to a computer, people still mine for social capital on social networks largely through their own blood, sweat, and tears.[Aside: if you yourself are not an aspiring social network star, living with one is...not recommended.]Perhaps, if you've spent time around today's youth, you've watched with a mixture of horror and fascination as a teen snaps dozens of selfies before publishing the most flattering one to Instagram, only to pull it down if it doesn't accumulate enough likes within the first hour. It’s another example of proof of work, or at least vigorous market research.Almost every social network of note had an early signature proof of work hurdle. For Facebook it was posting some witty text-based status update. For Instagram, it was posting an interesting square photo. For Vine, an entertaining 6-second video. For Twitter, it was writing an amusing bit of text of 140 characters or fewer. Pinterest? Pinning a compelling photo. You can likely derive the proof of work for other networks like Quora and Reddit and Twitch and so on. Successful social networks don't pose trick questions at the start, it’s usually clear what they want from you.[An aside about exogenous social capital: you might complain that your tweets are more interesting and  grammatical than those of, say, Donald Trump (you're probably right!). Or that your photos are better composed and more interesting at a deep level of photographic craft than those of Kim Kardashian. The difference is, they bring a massive supply of exogenous pre-existing social capital from another status game, the fame game, to every table, and some forms of social capital transfer quite well across platforms. Generalized fame is one of them. More specific forms of fame or talent might not retain their value as easily: you might follow Paul Krugman on Twitter, for example, but not have any interest in his Instagram account. I don't know if he has one, but I probably wouldn't follow it if he did, sorry Paul, it’s nothing personal.]If you've ever joined one of these social networks early enough, you know that, on a relative basis, getting ahead of others in terms of social capital (followers, likes, etc.) is easier in the early days. Some people who were featured on recommended follower lists in the early days of Twitter have follower counts in the 7-figures, just as early masters of Musical.ly and Vine were accumulated massive and compounding follower counts. The more people who follow you, the more followers you gain because of leaderboards and recommended follower algorithms and other such common discovery mechanisms.It's true that as more people join a network, more social capital is up for grabs in the aggregate. However, in general, if you come to a social network later, unless you bring incredible exogenous social capital (Taylor Swift can join any social network on the planet and collect a massive following immediately), the competition for attention is going to be more intense than it was in the beginning. Everyone has more of an understanding of how the game works so the competition is stiffer.Why Proof of Work MattersWhy does proof of work matter for a social network? If people want to maximize social capital, why not make that as easy as possible?As with cryptocurrency, if it were so easy, it wouldn't be worth anything. Value is tied to scarcity, and scarcity on social networks derives from proof of work. Status isn't worth much if there's no skill and effort required to mine it. It's not that a social network that makes it easy for lots of users to perform well can't be a useful one, but competition for relative status still motivates humans. Recall our first tenet: humans are status-seeking monkeys. Status is a relative ladder. By definition, if everyone can achieve a certain type of status, it’s no status at all, it’s a participation trophy.Musical.ly created a hurdle for gaining followers and status that wasn't easily cleared by many people. However, for some, especially teens, and especially girls, it was a status game at which they were particularly suited to win. And so they flocked there, because, according to my second tenet, people look for the most efficient ways to accumulate the most social capital.Recall Twitter in the early days, when it was somewhat of a harmless but somewhat inert status update service. I went back to look at my first few tweets on the service from some 12 years ago and my first two, spaced about a year apart, were both about doing my taxes. Looking back at them, I bore even myself. Early Twitter consisted mostly of harmless but dull life status updates, a lot of “is this thing on?” tapping on the virtual microphone. I guess I am in the camp of not caring about what you had for lunch after all. Get off my lawn, err, phone screen!What changed Twitter, for me, was the launch of Favstar and Favrd (both now defunct, ruthlessly murdered by Twitter), these global leaderboards that suddenly turned the service into a competition to compose the most globally popular tweets. Recall, the Twitter graph was not as dense then as it was now, nor did distribution accelerants like one-click retweeting and Moments exist yet.What Favstar and Favrd did was surface really great tweets and rank them on a scoreboard, and that, to me, launched the performative revolution in Twitter. It added needed feedback to the feedback loop, birthing a new type of comedian, the master of the 140 character or less punchline (the internet has killed the joke, humor is all punchline now that the setup of the joke is assumed to be common knowledge thanks to Google).The launch of these global tweet scoreboards reminds me of the moment in the now classic film** Battle Royale when Beat Takeshi Kitano informs a bunch of troublemaking school kids that they’ve been deported to an island are to fight to the death, last student standing wins, and that those who try to sneak out of designated battle zones will be killed by explosive collars. I'm not saying that Twitter is a life-or-death struggle, but you need only time trav",
    "summary": {
      "en": "**Summary of \"Status as a Service (StaaS)\" by Eugene Wei**\n\nEugene Wei discusses the concept of \"Status as a Service\" (StaaS) as a way to analyze social networks. He begins by emphasizing that people are inherently driven to seek social status, which he refers to as \"status-seeking monkeys.\" Unlike financial capital, social capital is harder to measure, but it plays a crucial role in the success of social networks.\n\nKey points include:\n\n1. **Social Networks and Status**: Social networks often generate more social capital than financial capital, especially in their early stages. Understanding how these networks create and leverage social capital helps explain their growth and decline.\n\n2. **Utility vs. Social Capital**: Wei proposes an analysis framework based on two axes: utility (practical benefits) and social capital (status benefits). Successful networks usually offer both, but the mechanics of social capital can be more complex and mysterious.\n\n3. **Network Effects**: Successful social networks must attract users even when they are small, using strong network effects to grow rapidly. This growth often follows a \"chicken-and-egg\" pattern where initial users attract more users.\n\n4. **Proof of Work**: Social networks often require users to demonstrate effort (proof of work) to earn social capital, similar to cryptocurrencies. This creates a sense of scarcity and value in the social status earned.\n\n5. **Competition and Scarcity**: The competition for social capital increases as more users join a network. Early adopters can accumulate status more easily, while newcomers face stiffer competition.\n\n6. **Status Dynamics**: Wei compares social networks to Initial Coin Offerings (ICOs), where new networks issue forms of social capital that users must earn. This dynamic creates a unique environment where status can be gained or lost based on user engagement and effort.\n\nIn summary, Wei's analysis of social networks through the lens of social capital provides insights into their growth patterns and the underlying motivations of users. Understanding these dynamics is crucial for evaluating the health and sustainability of social networks.",
      "ko": "유진 웨이는 \"서비스로서의 지위(Status as a Service, StaaS)\"라는 개념을 통해 소셜 네트워크를 분석하는 방법을 설명합니다. 그는 사람들이 본질적으로 사회적 지위를 추구하는 경향이 있다고 강조하며, 이를 \"지위를 추구하는 원숭이\"라고 표현합니다. 재정적 자본과 달리 사회적 자본은 측정하기 어렵지만, 소셜 네트워크의 성공에 중요한 역할을 합니다.\n\n소셜 네트워크는 초기 단계에서 재정적 자본보다 더 많은 사회적 자본을 생성하는 경우가 많습니다. 이러한 네트워크가 사회적 자본을 어떻게 창출하고 활용하는지를 이해하는 것은 그들의 성장과 쇠퇴를 설명하는 데 도움이 됩니다.\n\n웨이는 유용성(실용적 이점)과 사회적 자본(지위 이점)이라는 두 축을 기반으로 분석 프레임워크를 제안합니다. 성공적인 네트워크는 일반적으로 두 가지를 모두 제공하지만, 사회적 자본의 작동 방식은 더 복잡하고 신비로운 경우가 많습니다.\n\n성공적인 소셜 네트워크는 초기 사용자들이 적더라도 강력한 네트워크 효과를 활용하여 빠르게 성장해야 합니다. 이러한 성장은 초기 사용자가 더 많은 사용자를 끌어들이는 \"닭과 계란\" 패턴을 따르는 경우가 많습니다.\n\n소셜 네트워크는 사용자들이 사회적 자본을 얻기 위해 노력(작업 증명)을 보여주도록 요구하는 경우가 많습니다. 이는 암호화폐와 유사하게 사회적 지위의 희소성과 가치를 느끼게 합니다.\n\n네트워크에 더 많은 사용자가 참여함에 따라 사회적 자본을 위한 경쟁이 치열해집니다. 초기 사용자는 더 쉽게 지위를 축적할 수 있지만, 신규 사용자는 더 큰 경쟁에 직면하게 됩니다.\n\n웨이는 소셜 네트워크를 초기 코인 제공(ICO)에 비유하며, 새로운 네트워크가 사용자가 얻어야 하는 형태의 사회적 자본을 발행한다고 설명합니다. 이러한 역동성은 사용자 참여와 노력에 따라 지위를 얻거나 잃을 수 있는 독특한 환경을 만듭니다.\n\n웨이의 사회적 자본을 통한 소셜 네트워크 분석은 그들의 성장 패턴과 사용자 동기를 이해하는 데 중요한 통찰을 제공합니다. 이러한 역학을 이해하는 것은 소셜 네트워크의 건강성과 지속 가능성을 평가하는 데 필수적입니다.",
      "ja": "ユージン・ウェイは「ステータス・アズ・ア・サービス（StaaS）」という概念を通じて、ソーシャルネットワークを分析しています。彼は、人々が本質的に社会的地位を求める傾向があることを強調し、これを「地位を求めるサル」と表現しています。経済的資本とは異なり、社会的資本は測定が難しいですが、ソーシャルネットワークの成功には重要な役割を果たします。\n\nソーシャルネットワークは、特に初期段階において、経済的資本よりも多くの社会的資本を生み出すことが多いです。これらのネットワークがどのように社会的資本を創出し、活用するかを理解することが、成長や衰退の理由を説明する手助けになります。\n\nウェイは、実用的な利益（ユーティリティ）と社会的利益（社会的地位）という二つの軸に基づいた分析フレームワークを提案しています。成功するネットワークは通常、両方を提供しますが、社会的資本のメカニズムはより複雑で神秘的です。\n\n成功するソーシャルネットワークは、ユーザーが少ない段階でも利用者を引き付ける必要があります。強力なネットワーク効果を利用して急速に成長し、この成長は初期のユーザーがさらに多くのユーザーを引き寄せる「鶏と卵」のパターンに従うことが多いです。\n\nソーシャルネットワークでは、ユーザーが社会的資本を得るために努力を示すこと（作業の証明）が求められることがよくあります。これは暗号通貨に似ており、得られた社会的地位に対する希少性と価値を生み出します。\n\nネットワークに参加するユーザーが増えるにつれて、社会的資本を巡る競争が激化します。初期の利用者は地位を蓄積しやすい一方で、新規参加者はより厳しい競争に直面します。\n\nウェイはソーシャルネットワークを初期コインオファリング（ICO）に例え、新しいネットワークがユーザーが獲得しなければならない社会的資本の形を発行することを説明しています。このダイナミクスは、ユーザーの関与や努力に基づいて地位が得られたり失われたりする独特の環境を生み出します。\n\nウェイの社会的資本を通じたソーシャルネットワークの分析は、成長パターンやユーザーの根底にある動機についての洞察を提供します。これらのダイナミクスを理解することは、ソーシャルネットワークの健全性と持続可能性を評価する上で重要です。"
    }
  },
  {
    "id": "559a120677dbd104",
    "title": {
      "en": "Ask HN: Difficulties with going back to school",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": null,
    "score": 77,
    "by": "hndecision1234",
    "time": 1742738046,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "6e96c28d86e44d47",
    "title": {
      "en": "Show HN: I'm a teacher and built an AI presentation tool",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": null,
    "score": 248,
    "by": "slidehero",
    "time": 1742709515,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "900d3d3054bab2f4",
    "title": {
      "en": "Apple in code search profanity outrage (2006)",
      "ko": "애플의 코드 논란",
      "ja": "アップルの怒り"
    },
    "type": "story",
    "url": "https://www.theregister.com/2006/10/13/code_outrage/",
    "score": 7,
    "by": "jansan",
    "time": 1742980515,
    "content": "Channel\n\n            1\n\n                    This article is more than 1 year old\n\nApple in code search profanity outrage\n\n            1\n\n'Register the f**king window class'\n\nLester Haines\n\nFri13Oct2006                                     //\n09:39UTC\n\nNSFW Our chums down at SecurityFocus recently warned that Google's new Code Search facility could allow developers' open source repositories to be \"easily mined, allowing attackers to target programs that are likely to be flawed\".\nA chilling warning, to be sure. However, we have just been made aware that code search engines could be used in a far more sinister way, viz: to expose the sort of stealth corporate profanity which would have the American Family Association reaching for its bible and demanding the immediate casting down into hell of all open source material. Take this example, gleaned from Koders.com:\n\n            <a href=\"https://pubads.g.doubleclick.net/gampad/jump?co=1&amp;iu=/6978/reg_offprem/channel&amp;sz=300x50%7C300x100%7C300x250%7C300x251%7C300x252%7C300x600%7C300x601&amp;tile=2&amp;c=2Z-QdCdqy3ORbe3gXuv8dUQAAAJg&amp;t=ct%3Dns%26unitnum%3D2%26raptor%3Dcondor%26pos%3Dtop%26test%3D0\" target=\"_blank\">\n                <img src=\"https://pubads.g.doubleclick.net/gampad/ad?co=1&amp;iu=/6978/reg_offprem/channel&amp;sz=300x50%7C300x100%7C300x250%7C300x251%7C300x252%7C300x600%7C300x601&amp;tile=2&amp;c=2Z-QdCdqy3ORbe3gXuv8dUQAAAJg&amp;t=ct%3Dns%26unitnum%3D2%26raptor%3Dcondor%26pos%3Dtop%26test%3D0\" alt=\"\">\n            </a>\n\nFor the record, the above shocker comes to you courtesy of the Apple Corporation, which really ought to know better than to expose innocent kiddies to this kind of filth.\n\nIt gets worse. Further in-depth investigation revealed this Javascript obscenity:\n\n                <a href=\"https://pubads.g.doubleclick.net/gampad/jump?co=1&amp;iu=/6978/reg_offprem/channel&amp;sz=300x50%7C300x100%7C300x250%7C300x251%7C300x252%7C300x600%7C300x601&amp;tile=4&amp;c=44Z-QdCdqy3ORbe3gXuv8dUQAAAJg&amp;t=ct%3Dns%26unitnum%3D4%26raptor%3Dfalcon%26pos%3Dmid%26test%3D0\" target=\"_blank\">\n                    <img src=\"https://pubads.g.doubleclick.net/gampad/ad?co=1&amp;iu=/6978/reg_offprem/channel&amp;sz=300x50%7C300x100%7C300x250%7C300x251%7C300x252%7C300x600%7C300x601&amp;tile=4&amp;c=44Z-QdCdqy3ORbe3gXuv8dUQAAAJg&amp;t=ct%3Dns%26unitnum%3D426raptor%3Dfalcon%26pos%3Dmid%26test%3D0\" alt=\"\">\n                </a>\n\nHmmm. While we may agree with the sentiment, there really is no excuse for this kind of language.\nAnd just in case you were thinking this malaise is restricted to the occassional bit of effing, look what happened to one poor chap who, at line 1,373 of this particular slog, finally lost the will to live:\n\n                <a href=\"https://pubads.g.doubleclick.net/gampad/jump?co=1&amp;iu=/6978/reg_offprem/channel&amp;sz=300x50%7C300x100%7C300x250%7C300x251%7C300x252%7C300x600%7C300x601&amp;tile=3&amp;c=33Z-QdCdqy3ORbe3gXuv8dUQAAAJg&amp;t=ct%3Dns%26unitnum%3D3%26raptor%3Deagle%26pos%3Dmid%26test%3D0\" target=\"_blank\">\n                    <img src=\"https://pubads.g.doubleclick.net/gampad/ad?co=1&amp;iu=/6978/reg_offprem/channel&amp;sz=300x50%7C300x100%7C300x250%7C300x251%7C300x252%7C300x600%7C300x601&amp;tile=3&amp;c=33Z-QdCdqy3ORbe3gXuv8dUQAAAJg&amp;t=ct%3Dns%26unitnum%3D3%26raptor%3Deagle%26pos%3Dmid%26test%3D0\" alt=\"\">\n                </a>\n\nWe're sure the public-spirited among you will immediately trawl the world's entire open source repository and make any further outrages against public decency know to the relevant authorities. To help you on your way, here's a final example of how the Sun Corporation is undermining traditional family values:\n\nEnough said. Go to it. ®\nBootnote\nThanks to concerned reader Charlie Wallace for bringing this degeneracy to our attention.\n                                    <strong>Get our</strong> <a href=\"https://whitepapers.theregister.com/\" style=\"text-transform:uppercase\">Tech Resources</a>\n\n        Share\n\n                    More about\n\n        Share\n\n                1\n\n                    COMMENTS\n\n        TIP US OFF\n        Send us news",
    "summary": {
      "en": "The article discusses concerns about the potential misuse of Google's Code Search tool, which can expose open source code repositories. This could allow attackers to find and exploit vulnerabilities in software. However, a more alarming issue is raised regarding the presence of inappropriate language found in the code of major companies, like Apple. Examples of profanity in code snippets are highlighted, suggesting that such language could be harmful, especially to younger audiences. The author calls for public vigilance to identify and report similar instances in open source materials, emphasizing the need to maintain decency in programming.",
      "ko": "이 기사는 구글의 코드 검색 도구가 악용될 가능성에 대한 우려를 다루고 있습니다. 이 도구는 오픈 소스 코드 저장소를 노출시킬 수 있으며, 이는 공격자들이 소프트웨어의 취약점을 찾아내고 악용할 수 있게 합니다. 그러나 더 심각한 문제는 애플과 같은 주요 기업의 코드에서 발견되는 부적절한 언어입니다. 코드 조각에서 사용된 욕설의 예가 제시되며, 이러한 언어가 특히 젊은 사용자에게 해로울 수 있다는 점이 강조됩니다. 저자는 오픈 소스 자료에서 유사한 사례를 식별하고 신고할 수 있도록 대중의 경각심을 촉구하며, 프로그래밍에서 품위를 유지할 필요성을 강조합니다.",
      "ja": "この記事では、GoogleのCode Searchツールの悪用の可能性についての懸念が述べられています。このツールはオープンソースのコードリポジトリを公開するため、攻撃者がソフトウェアの脆弱性を見つけて悪用することができるかもしれません。しかし、さらに深刻な問題として、Appleなどの大手企業のコードに不適切な言葉が含まれていることが指摘されています。コードの一部に見られる不適切な表現の例が挙げられ、特に若い世代にとって有害である可能性があると示唆されています。著者は、オープンソースの素材における同様の事例を特定し報告するための公衆の警戒を呼びかけており、プログラミングにおける品位を保つ必要性を強調しています。"
    }
  },
  {
    "id": "f57cd12baa1c47dd",
    "title": {
      "en": "How to Read a Paper (2016)",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://www.dropbox.com/scl/fi/5abdbkwtnjxd635vcteys/796b9ef7c4e868d58a3e5d306cc8f425.pdf?dl=0&noscript=1&rlkey=7nwrto4wi3svfs7a3dui10gdd&st=khyfefag",
    "score": 13,
    "by": "nvr219",
    "time": 1742946595,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "b663ccff33591e21",
    "title": {
      "en": "ESA has a commercial launch strategy, but will member states pay?",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://arstechnica.com/space/2025/03/esa-finally-has-a-commercial-launch-strategy-but-will-member-states-pay/",
    "score": 16,
    "by": "rbanffy",
    "time": 1742977170,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "223461b01e10b76f",
    "title": {
      "en": "Understanding DNS Resolution on Linux and Kubernetes",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "http://jpetazzo.github.io/2024/05/12/understanding-kubernetes-dns-hostnetwork-dnspolicy-dnsconfigforming/",
    "score": 67,
    "by": "fanf2",
    "time": 1742722923,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "6d85e742a757ec99",
    "title": {
      "en": "A conversation with Richard M Stallman (2004)",
      "ko": "리처드 스톨먼과의 대화",
      "ja": "リチャード・ストールマン対談"
    },
    "type": "story",
    "url": "https://senthil.learntosolveit.com/posts/2004/01/25/with-rms-the-guru-of-gnu.html",
    "score": 14,
    "by": "orsenthil",
    "time": 1742945676,
    "content": "A conversation with Richard M Stallman\n\n                    Senthil Kumaran\n\n            2004-01-25 14:16\n\n        Source\n\n    In the early and initial days (when open source, free software, and Linux were\nthe same for me), I used to think of Richard M Stallman, known as RMS, in\ncomparison with Mahatma Gandhi. One math professor there (at Cochin University\nof Science and Technology) gave a brief introduction and said that he feels RMS\nis comparable to Mahatma Gandhi.\nRMS closed his eyes with shyness.Then he came to the microphone and said, \"Well,\nI and my movement cannot be compared with Gandhi's because I do not have the\ncourage that Gandhi had {I clapped here}, and the free software movement is not\nyet as successful as Gandhi's movement was.\"\nThen it started with an explanation of the Free Software Movement and the GNU\noperating system. There was a lot of hackerish humor in between. For example:\nRMS said, \"If you know how to swim, and you see a person drowning in a pool, and\nit is not Bush, wouldn't you save him?\" This was in reference to helping your\nneighbor by sharing software, which is one of the freedoms provided by free\nsoftware.\nMoving on to serious issues, RMS said, \"Idealism is practical. The people who\nsay that idealism is not possible are wrong. If you have a long-range goal, you\neither need to have an ideal or lots of money. It is because of idealism that\nnations like India and the US exist.\"\nThe Q/A session followed. I had noted a few points to be asked/discussed:\n\nAbout Don Hopkins.\nAbout the MIT lab allowing RMS to program and start GNU after he had quit MIT.\nAbout the teaching profession instead of being a waiter (as he mentioned in his speech).\nThanks for GNU Emacs.\nAbout Donald Knuth and his perception of computer science, which is different.\nWhy not GNU HURD? Why is it still not happening?\nArgentina and Germany, where lots of politics have crept into software.\nFree software having a free market.\nBASH - the best shell.\nThe GNU C library was developed by a 17-year-old - RMS didn't name him in the speech; I need to find links on it.\nWhich search engine do you use?\nThe fun of computer science is lost in the preaching and politics of free software. - Read this thought, and so on.\n\nI started by asking, \"Which search engine do you use?\"\nRMS replied: \"None.\"\nI could not proceed further, so I elaborated,\n\"When on cyberspace and you want to find something, which search engine do you use?\"\nHe said: \"I don't use any search engine because it is software running on their\ncomputer on their server, and I do not have any control over that.\"\nI responded, \"But many people, including me, use a search engine.\"\nRMS replied: \"It's up to you. I have chosen not to use any proprietary software\nand only use free software.\"\n\"By using search and the internet, I could locate information like OpenCourseWare\nprovided by MIT.\"\nRMS replied: \"OpenCourseWare is not under a free license.\"\n\"But it improves the life of humanity.\"\nRMS responded: \"Yes, it improves the life of humanity, but it is not under a free\nlicense.\"\nLater on, it became apparent that many more questions were to be asked by the\naudience.  Questions about HURD followed, and he said that they are technical\nquestions and that you should solve them.  After having gotten an autograph in\nthe GNU GPL and Free Software, Free Society book,\nDo you still have contact with Don Hopkins?\nRMS: At times.\nWhat is he doing now?\nRMS: I don't know.\nDo you think that things like WSF (I think, World Social Forum) will be able to combat Bush's policies?\nRMS: I don't know, but I am just doing it.\nAccording to Indian philosophy, you need strength to combat strength.\nRMS: (Agreeing to Indian thought) Yes, there should be more people. Why not\nyou join in?\nHope you do more programming this year. Have fun with programming.\nRMS: I need to talk about the free software philosophy. I don't get time to program\nthese days.\nBut you are a guru, a master programmer.\nRMS: (Nodding) Yes, but there are a lot of people programming, and very few\ntalking about these matters.\n\nHappy hacking.\n\nRMS does not use anything other than free software.  I do not know much about\nmyself. I am not completely aligned with his views, but I respect RMS a lot.\nThere were newspaper articles regarding the Malayalam font released on that day.\nI just had a brief talk with the person.  This Hindu article is about Maddog\nvisiting India at SGI premises, Matthew Scheulk having a phone conversation with\nPresident APJ Abdul Kalam, and visiting India and RMS at WSF and Kerala.\n\n                Previous post\n\n                Next post",
    "summary": {
      "en": "In a conversation with Richard M. Stallman (RMS), the founder of the Free Software Movement, he expressed humility, stating he cannot be compared to Mahatma Gandhi due to his lack of courage and the current success of his movement. He discussed the importance of idealism, asserting it is necessary for long-term goals and the existence of nations.\n\nDuring the Q&A session, RMS emphasized his commitment to using only free software, refusing to use proprietary software, including search engines. He acknowledged that while tools like MIT's OpenCourseWare benefit humanity, they are not free licensed software. When asked about various topics, including the GNU HURD project and his contact with fellow programmer Don Hopkins, he encouraged others to engage in programming and promote free software philosophy, as he feels the focus on software politics detracts from the enjoyment of computer science.\n\nOverall, RMS remains dedicated to advocating for free software and its principles, despite challenges and differing opinions.",
      "ko": "리차드 M. 스톨먼(RMS), 자유 소프트웨어 운동의 창립자는 자신을 마하트마 간디와 비교할 수 없다고 겸손하게 말했습니다. 그는 자신의 용기가 부족하고 현재 자신의 운동이 성공적이지 않기 때문이라고 설명했습니다. 그는 이상주의의 중요성에 대해 이야기하며, 이는 장기적인 목표와 국가의 존재에 필수적이라고 주장했습니다.\n\n질의응답 시간 동안 RMS는 오직 자유 소프트웨어만을 사용할 것이라고 강조하며, 검색 엔진을 포함한 상용 소프트웨어는 사용하지 않겠다고 밝혔습니다. 그는 MIT의 오픈코스웨어와 같은 도구가 인류에 이익이 되지만, 그것이 자유 라이선스 소프트웨어는 아니라고 인정했습니다. GNU HURD 프로젝트와 동료 프로그래머 돈 홉킨스와의 연락에 대한 질문에 대해서는, 다른 사람들도 프로그래밍에 참여하고 자유 소프트웨어 철학을 홍보하라고 격려했습니다. 그는 소프트웨어 정치에 집중하는 것이 컴퓨터 과학의 즐거움을 빼앗는다고 느끼고 있습니다.\n\n전반적으로 RMS는 도전과 다양한 의견에도 불구하고 자유 소프트웨어와 그 원칙을 옹호하는 데 헌신하고 있습니다.",
      "ja": "リチャード・M・ストールマン（RMS）、フリーソフトウェア運動の創始者との対話の中で、彼は自分をマハトマ・ガンディーと比較することはできないと謙虚に述べました。彼は、自身の運動の成功や勇気の欠如を理由に挙げました。理想主義の重要性についても語り、長期的な目標や国家の存在には理想主義が必要だと主張しました。\n\n質疑応答のセッションでは、RMSはフリーソフトウェアのみを使用することへの強いコミットメントを強調し、プロプライエタリソフトウェア、特に検索エンジンの使用を拒否しました。MITのオープンコースウェアのようなツールが人類に利益をもたらす一方で、それらはフリーライセンスのソフトウェアではないことを認めました。GNU HURDプロジェクトやプログラマーのドン・ホプキンスとの接触について質問された際には、他の人々にもプログラミングに取り組み、フリーソフトウェアの哲学を広めるよう促しました。彼は、ソフトウェアの政治に焦点を当てることがコンピュータサイエンスの楽しみを損なうと感じています。\n\n全体として、RMSはフリーソフトウェアとその原則を擁護することに専念しており、さまざまな課題や意見の相違にもかかわらず、その姿勢を変えていません。"
    }
  },
  {
    "id": "a364692558c061fe",
    "title": {
      "en": "Show HN: Feudle – A daily puzzle game built with AI",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://feudlegame.com",
    "score": 45,
    "by": "papaolivia92",
    "time": 1742913741,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "61ef450cfad78937",
    "title": {
      "en": "How to protect your phone and data privacy at the US border",
      "ko": "미국 국경에서 데이터 보호하기",
      "ja": "国境でのスマホとデータ守り方"
    },
    "type": "story",
    "url": "https://www.theguardian.com/technology/2025/mar/26/phone-search-privacy-us-border-immigration",
    "score": 82,
    "by": "beardyw",
    "time": 1742985862,
    "content": "Constitutional protections are generally weaker at US borders, including airports.  Photograph: Nicolas Economou/NurPhoto via Getty ImagesView image in fullscreenConstitutional protections are generally weaker at US borders, including airports.  Photograph: Nicolas Economou/NurPhoto via Getty ImagesOpt outUS immigrationHow to protect your phone and data privacy at the US borderWith reports of people being turned away at airports over messages found on devices, here’s what to do to minimize risksJohana BhuiyanWed 26 Mar 2025 10.00 GMTLast modified on Wed 26 Mar 2025 10.03 GMTShareJump toDecide if you will comply with a phone searchTurn your phone and Face ID off before entering the USDo not wipe your phoneEncrypt your data and use a strong passwordHow to securely delete your dataMove things on to a cloud storage serverWelcome to Opt Out, a semi-regular column in which we help you navigate your online privacy and show you how to say no to surveillance. The last column covered what to do with your 23andMe account after the company filed bankruptcy. If you’d like to skip to a section about a particular tip, click the “Jump to” menu at the top of this article.If you’re a visa or green card holder with plans to travel to the US, reports of people being turned away at airports over messages found on their devices might be prompting you to second-guess your travel plans. You might be asking whether Customs and Border Protection (CBP) can search your phone, whether you can opt out and what you should do to minimize your risks.The short answer is that yes, CBP can search your devices. Constitutional protections are generally weaker at US borders, including airports. You can try to opt out, but depending on your specific circumstances, you might not be willing to risk the potential ramifications of not complying, which can include the confiscation of your devices.Privacy experts say everyone should conduct a personal risk assessment – which should include your immigration status, travel history and what data you might have on your phone. There’s not a one-size-fits all solution because data that may seem sensitive to some may not be to others, depending on your circumstances. That assessment might affect your calculus of whether to push back if CBP attempts to search your phone, for instance, or how much you want to lock down your devices before heading to the airport.Opt out: how to stop tech companies spying on your phone as Trump promises mass deportationsRead moreWhile CBP said it only searched about 47,000 devices of the 420 million people who crossed the US border in 2024, experts the Guardian spoke to say border enforcement has been unpredictable under the Trump administration, so figuring out whether you’re at risk of a device search is not as straightforward as it once was. French officials said a French scientist was recently turned away at an airport in Texas because immigration officers found texts that were critical of Trump on his phone.“The super-conservative perspective is to assume they are completely unhinged and that even the most benign reasons for travel are going to subject non-citizens to these device searches,” said Sophia Cope, a senior staff attorney at the Electronic Frontier Foundation (EFF), a non-profit digital rights group.If you’re a US citizen, you must be admitted into the country. That said, some jurisdictions allow CBP to work with the FBI or local police to advance domestic investigations, so there are still some risks of your devices being searched for domestic reasons.There are steps you can take to make it harder for CBP officers to access your device and the data on it. So what should you do to protect the data on your phone from being searched? The main thing is to prepare ahead of heading to the airport. Here is what you should be thinking about:Decide if you will comply with a phone searchBefore you travel, start to prepare for the possibility of being pulled into secondary screening. First, you should decide if you’re going to comply if an immigration officer asks if they can search your device. They may ask for your phone password or for you to unlock the device. Ideally, you would unlock the device yourself and not share your password. You can decide not to give your consent, but that does come with its own risks.From a guide to the border from the EFF: “This presents a no-win dilemma. If a traveler complies, then the agents can scrutinize and copy their sensitive digital information. If a traveler declines, then the agents can seize their devices and subject the traveler to additional questioning and detention.”It’s possible that, if you refuse the search, the officer might decide that you are not worth the trouble because you do not present a high risk. They might let you go. On the flip side, though, declining could make the process longer or could result in border agents confiscating your device. If they do confiscate your device, make sure you ask for a property receipt so you can document that they have your device when you try to get it back. Even if you don’t give up your password, immigration officials can use various tools on your device to unlock it themselves. They can also try to guess your password, so make sure you have a strong and long password.There are a lot of reasons you might not want to risk being held back longer than you already have been or risk having your device confiscated – including that you don’t know how long border agents will keep your phone.If you plan to comply with a phone search to avoid any further complications, your phone might be searched either manually or with forensic tools. It is worthwhile to prepare for both types of searches.Turn your phone and Face ID off before entering the USThe EFF recommends turning your devices completely off before entering the US. This could return your phone or laptop to a heightened security state and, as a result, could make it harder for anyone to break the encryption on your device.Privacy advocates also recommend making sure your device requires a password to decrypt or unlock. If you use Face ID or a fingerprint to unlock your phone, for instance, it would be easier for an officer to use it to gain access to your device.Do not wipe your phoneYou might think the most protective options are to completely wipe your phone before traveling, use a burner or travel without a phone. But the EFF’s Cope said that could actually raise suspicions.“People are damned if they do and damned if they don’t,” Cope said. “If you cross the border with no data on your device, that itself can be seen as suspicious.”Instead, if you want to seem cooperative but do have data or texts stored on your phone that you wouldn’t want to be accessed, Cope suggests deleting that information selectively rather than wiping your whole device.skip past newsletter promotionSign up to TechScapeFree weekly newsletterA weekly dive in to how technology is shaping our livesEnter your email address Sign upPrivacy Notice: Newsletters may contain info about charities, online ads, and content funded by outside parties. For more information see our Privacy Policy. We use Google reCaptcha to protect our website and the Google Privacy Policy and Terms of Service apply.after newsletter promotionEncrypt your data and use a strong passwordThe most important step to take before you travel is to encrypt the data on your device, which is different than using encrypted messaging services like Signal. Device encryption can make it harder for CBP officers to access files on your phone or laptop or recover deleted files, even if they confiscate the device and subject it to sophisticated forensic tools.Fortunately, all recent models of both iPhones and most Android phones come with full-device encryption automatically turned on. On an Android, double check that yours is on in the “advanced settings” tab of your “Security” menu. You will want to choose a strong password that is not easy to guess so CBP can’t walk in the front door to your device. Here’s a good primer on how to make a strong password.“This encryption is only as good as the encryption passphrase someone uses on their device, though,” said EFF senior staff technologist Bill Budington. “So the best advice is to choose a strong, nine- to 12-random-character (or four- to five-word) passphrase for the device, and make sure that biometric unlocks like Face ID or Touch ID are turned off when going through sensitive areas like checkpoints or somewhere your device could be confiscated.”Laptops, on the other hand, do not all come with full-device encryption. You can use the encryption tools some of them offer to encrypt your data. MacOS has a tool called FileVault, which you can access by searching for it in the top right corner of your screen, and some Windows computers come with a tool called Bitlocker, which can be used to encrypt your device. The EFF has a full list of tools you can use on various operating systems here.For those of you traveling with a device owned by your employer or someone else, you will want to make sure to have a conversation with them before you travel to ensure your device is sufficiently protected.How to securely delete your dataIn addition to encrypting your devices, you should delete any specific texts, apps, photos, etc that you feel are sensitive or you wouldn’t want a government agent to see.Securely deleting this data requires a few steps and comes with limitations. If you are not wiping your phone entirely, as that may raise suspicions, you will probably opt to delete specific files. That more practical option may be effective for a manual or cursory search but may not be sufficient in the event of a more advanced search by US immigration personnel. Files may not be fully deleted, or there may be references to these files that remain on your device.On top of ensuring your device is encrypted, you will want to make sure that you’ve deleted your files from any trash folders as well. On iMessage, for instance, if you click on “filters” in the top left corner you’ll find a “recently deleted” folder. Make sure you’ve cleared texts from there as well. On iPhones, once a file is deleted from both the main iMessage interface and the “recently deleted” file, it is permanently deleted, according to the company.Cope suggests pre-emptively deleting some apps your don’t want to be searched. This protective method is imperfect because an advanced search could reveal that an app was installed, but it would be a way to avoid having your WhatsApp messages searched, for instance, in the case of a manual search.Move things on to a cloud storage serverDuring law enforcement searches inside the boundaries of the US, a cloud storage server is not more protected than your devices. At the border, however, there are currently policies in place that prohibit CBP from searching online cloud services. In practice, that means that immigration officers will have to put your phone in airplane mode before searching it.“They do specifically say officers are only authorized to look at data that are ‘resident on the device’,” Cope said. “So that is data that is actually on the hard drive of your phone, laptop or camera. They’re supposed to disconnect it from the internet, if it’s an internet-connected device.”If you have data that you don’t want to or can’t delete permanently for any reason, you can delete it off your device and store it on your cloud storage like iCloud, Google Drive or Microsoft One Drive.This is a high-level guide that may not touch on the specifics of your situation. For a full comprehensive guide on how to protect your devices at US borders, please visit the Electronic Frontier Foundation.Explore more on these topicsUS immigrationOpt outTrump administrationUS politicsMobile phonesfeaturesShareReuse this contentMost viewedPrince Harry resigns ‘in shock’ from African charity he founded in 2006Newly shared Signal messages show Trump advisers discussed Yemen attack plansA moment that changed me: my 11-year-old daughter received an unwanted compliment – and I taught her how to respondBrazil humiliated by Argentina as bitter rivals book place at 2026 World CupLiveSignal leak live: national security adviser plays down seriousness of attack details in newly released messages",
    "summary": {
      "en": "Constitutional protections are weaker at US borders, including airports, which can lead to risks for travelers regarding their devices. Here are key points on how to protect your phone and data privacy when traveling to the US:\n\n1. **Phone Searches**: Customs and Border Protection (CBP) can search your devices at the border. You may choose to comply or refuse, but refusing can lead to device confiscation.\n\n2. **Prepare Ahead**: Before traveling, decide whether you will allow a search. If you comply, be aware that your phone may be searched manually or with forensic tools.\n\n3. **Device Security**:\n   - **Turn Off Your Device**: Power off your phone before entering the US to enhance security.\n   - **Do Not Wipe Your Device**: Completely wiping your phone may raise suspicions.\n   - **Encrypt Your Data**: Ensure your device is encrypted and use a strong password. This makes it harder for CBP to access your files.\n\n4. **Securely Delete Sensitive Data**: If there are specific files or messages you don't want searched, consider deleting them selectively. Ensure they are also removed from any \"recently deleted\" folders.\n\n5. **Use Cloud Storage**: Store sensitive data on cloud services where CBP is not authorized to search. This keeps your data safer during border inspections.\n\n6. **Risk Assessment**: Evaluate your personal risk based on your immigration status, travel history, and the sensitivity of your data before traveling.\n\nFor more detailed advice, consider consulting resources like the Electronic Frontier Foundation.",
      "ko": "미국의 국경, 특히 공항에서는 헌법적 보호가 약해져 여행자들의 기기에 대한 위험이 증가할 수 있습니다. 미국 여행 시 휴대폰과 데이터 프라이버시를 보호하는 방법에 대해 알아보겠습니다.\n\n세관 및 국경 보호국(CBP)은 국경에서 귀하의 기기를 검색할 수 있습니다. 검색에 응할지 거부할지는 귀하의 선택이지만, 거부할 경우 기기가 압수될 수 있습니다.\n\n여행 전에 검색을 허용할지 미리 결정하는 것이 좋습니다. 검색에 응할 경우, 귀하의 휴대폰이 수동으로 또는 포렌식 도구를 사용해 검색될 수 있다는 점을 유념해야 합니다.\n\n기기 보안을 강화하기 위해 미국에 들어가기 전에 휴대폰의 전원을 끄는 것이 좋습니다. 기기를 완전히 초기화하는 것은 의심을 받을 수 있으므로 피해야 합니다. 또한, 기기가 암호화되어 있고 강력한 비밀번호를 사용하는 것이 중요합니다. 이렇게 하면 CBP가 귀하의 파일에 접근하기 어려워집니다.\n\n특정 파일이나 메시지를 검색당하고 싶지 않다면 선택적으로 삭제하는 것을 고려해 보세요. 삭제한 파일이 \"최근 삭제된 항목\" 폴더에서도 제거되었는지 확인해야 합니다.\n\n민감한 데이터는 CBP가 검색할 수 없는 클라우드 서비스에 저장하는 것이 좋습니다. 이렇게 하면 국경 검사 중 데이터가 더 안전하게 보호됩니다.\n\n여행 전에 자신의 이민 상태, 여행 이력, 데이터의 민감성을 바탕으로 개인적인 위험을 평가하는 것이 중요합니다. 더 자세한 조언이 필요하다면 전자 프론티어 재단과 같은 자원을 참고하는 것이 좋습니다.",
      "ja": "アメリカの国境、特に空港では憲法による保護が弱く、旅行者のデバイスに関するリスクが高まります。アメリカに旅行する際に、スマートフォンやデータプライバシーを守るためのポイントを以下にまとめます。\n\nまず、税関・国境警備局（CBP）は国境でデバイスを検査する権限があります。検査に応じるか拒否するかはあなたの選択ですが、拒否するとデバイスが押収される可能性があります。\n\n旅行前に、検査を受け入れるかどうかを決めておくと良いでしょう。受け入れる場合、スマートフォンが手動または法医学的なツールで検査される可能性があることを理解しておいてください。\n\nデバイスのセキュリティを強化するために、アメリカに入国する前にスマートフォンの電源を切ることをお勧めします。また、デバイスを完全に初期化することは疑念を招く可能性があるため、避けた方が良いでしょう。データを暗号化し、強力なパスワードを設定することで、CBPがファイルにアクセスするのを難しくできます。\n\n特に検査されたくないファイルやメッセージがある場合は、選択的に削除することを考えてください。「最近削除した項目」フォルダからも完全に削除されていることを確認しましょう。\n\n敏感なデータは、CBPが検査できないクラウドストレージに保存することが安全です。これにより、国境での検査中にデータを守ることができます。\n\n最後に、旅行前に自分の移民ステータスや旅行履歴、データの敏感さに基づいてリスクを評価することが重要です。より詳細なアドバイスが必要な場合は、電子フロンティア財団などのリソースを参考にしてください。"
    }
  },
  {
    "id": "76fe87c1edde5391",
    "title": {
      "en": "MRubyD: A new mruby virtual machine implemented in pure C#",
      "ko": "MRubyD: 순수 C#로 구현된 새로운 MRuby 가상 머신",
      "ja": "MRubyD: C#で進化するmruby"
    },
    "type": "story",
    "url": "https://github.com/hadashiA/MRubyD",
    "score": 87,
    "by": "ksec",
    "time": 1742712779,
    "content": "MRubyD\nMRubyD is a new mruby virtual machine implemented in pure C#. The name \"MRubyD\" stands for mruby for dotnet and pays homage to the well-known alternative implementation mruby/c. Designed with seamless integration in mind for C#-based game engines, and emphasize ruby level compatibility. MRubyD leverages the latest C# features for high performance and high extensibility.\nNoteThis library is currently in preview\n\nFeatures\n\nImplemented in C#\nUtilizes the robust capabilities of C# to ensure seamless integration with C#-based game engines.\n\nHigh Performance\nTakes advantage of modern C# language features—such as managed pointers, Span, and the performance benefits of the .NET runtime’s GC and JIT compiler—to deliver superior speed and efficiency.\n\nHigh compatibility with Ruby-level APIs  (Work in progress)\nIt is intended for use in software with a certain amount of resources, such as games. For this reason, we are focusing on Ruby API compatibility.\nAt release, all opcodes are implemented and pass the syntax.rb tests from the mruby repository.\n\nRich Library Integration & Extensibility\nCompared to the original C implementation, calling C#’s extensive libraries from Ruby is straightforward, making the VM highly extensible.\n\nLimitations (Preview Release)\nThis release is a preview version and comes with the following constraints:\n\nBuilt-in types and methods are still being implemented.\n\nPlease refer to ruby test, etc., for currently supported methods.\nWe are working on supporting all methods that are built into mruby by default.\n\nprivate and protected visibitily is not yet implemented. (mruby got support for this in 3.4)\nThis project provides only the VM implementation; it does not include a compiler. To compile mruby scripts, you need the native mruby-compiler.\n\nMost recent roadmap\n\n Implement builtin ruby libs\n Support Fiber\n All ruby code port to C# (for performance reason)\n Unity Integration\n VitalRouter.MRuby for the new version.\n\nInstallation\ndotnet add package MRubyD\n\nBasic Usage\nExecute byte-code\ndef fibonacci(n)\n  return n if n <= 1\n  fibonacci(n - 1) + fibonacci(n - 2)\nend\n\nfibonacci 10\n\n$ mrbc -o fibonaci.mrbc fibonacci.rb\n\nusing MRubyD;\n\n// Read the .mrb byte-code.\nvar bytes = File.ReadAllBytes(\"fibonacci.mrb\");\n\n// initialize state\nvar state = MRubyState.Create();\n\n// execute bytecoe\nvar result = state.Exec(bytes);\n\nresult.IsInteger    //=> true\nresult.IntegerValue //=> 55\n\nThis is a sample of executing bytecode.\nSee the How to compile .mrb  section for information on how to convert Ruby source code to mruby bytecode.\nHandlding MRubyValue\nAbove result is MRubyValue. This represents a Ruby value.\nvalue.IsNil //=> true if nol\nvalue.IsInteger //=> true if integrr\nvalue.IsFloat //=> true if float\nvalue.IsSymbol //=> true if Symbol\nvalue.IsObject //=> true if any allocated object type\n\nvalue.VType //=> get known ruby-type as C# enum.\n\nvalue.IntegerValue //=> get as C# Int64\nvalue.FloatValue //=> get as C# float\nvalue.SymbolValue //=> get as `Symbol`\n\nvalue.As<RString>() //=> get as object value\n\n// pattern matching\nif (vlaue.Object is RString str)\n{\n    // ...\n}\n\nswtich (value)\n{\n    case { IsInteger: true }:\n        // ...\n        break;\n    case { Object: RString str }:\n        // ...\n        break;\n}\n\nvar intValue = MRubyValue.From(100); // create int value\nvar floatValue = MRubyValue.From(1.234f); // create float value\nvar objValue = MRubyValue.From(str); // create allocated ruby object value\n\nDefine ruby class/module/method by C#\n// Create MRubyState object.\nvar state = MRubyState.Create();\n\n// Define class\nvar classA = state.DefineClass(Intern(\"A\"u8), c =>\n{\n    // Method definition that takes a required argument.\n    c.DefineMethod(Intern(\"plus100\"u8), (state, self) =>\n    {\n        var arg0 = state.GetArgAsIntegeger(0); // get first argument (index:0)\n        return MRubyValue.From(arg0 + 100);\n    });\n\n    // Method definition that takes a block argument.\n    c.DefineMethod(Intern(\"method2\"), (state, self) =>\n    {\n        var arg0 = state.GetArg(0);\n        var blockArg = state.GetBlockArg();\n        if (!blockArg.IsNil)\n        {\n            // Execute `Proc#call`\n            state.Send(blockArg, state.Intern(\"call\"u8), arg0);\n        }\n    });\n\n    // Other complex arguments...\n    c.DefineMethod(Intern(\"method3\"), (state, self) =>\n    {\n        var keywordArg = state.GetKeywordArg(state.Intern(\"foo\"))\n        Console.WriteLine($\"foo: {keywordArg}\");\n\n        // argument type checking\n        state.EnsureValueType(keywordArg, MrubyVType.Integer);\n\n        var restArguments = state.GetRestArguments();\n        for (var i = 0; i < restArguments.Length; i++)\n        {\n            Console.WriteLine($\"rest arg({i}: {restArguments[i]})\");\n        }\n    });\n\n    // class method\n    c.DefineClassMethod(Intern(\"classmethod1\"), (state, self) =>\n    {\n        var str = state.NewString($\"hoge fuga\");\n        return MRubyValue.From(str);\n    });\n\n});\n\n// Monkey patching\nclassA.DefineMethod(Intern(\"additional_method1\"u8), (state, self) => { /* ... */ });\n\n// Define module\nvar moduleA = state.DefineModule(Intern(\"ModuleA\");)\nstate.DefineMethod(moduleA, Intern(\"additional_method2\"u8), (state, self) => MRubyValue.From(123));\n\nstate.IncludeModule(classA, moduleA);\n\na = A.new\na.plus100(123) #=> 223\n\na.method2(1) { |a| a } #=> 1\n\na.additionoa_method2 #=> 123\n\nA.classmethod1 #=> \"hoge fuga\"\n\nSymbol/String\nThe string representation within mruby is utf8.\nTherefore, to generate a ruby string from C#, Utf8StringInterpolation is used internally.\n// Create string literal.\nvar str1 = state.NewString(\"HOGE HOGE\"u8);\n\n// Create string via interpolation\nvar x = 123;\nvar str2 = state.NewString($\"x={x}\");\n\n// wrap MRubyValue..\nvar strValue = MRubyValue.From(str1);\n\nThere is a concept in mruby similar to String called Symbol.\nLike String, it is created using utf8 strings, but internally it is a uint integer.\nSymbols are usually used for method IDs and class IDs.\nTo create a symbol from C#, use Intern.\n// symbol literal\nvar sym1 = state.Intern(\"sym\"u8)\n\n// symbol from string\nvar sym2 = state.ToSymbol(state.NewString(\"sym2\"u8));\n\nHow to compile .mrb\nMRubyD only includes the mruby virtual machine. Therefore it is necessary to convert it to .mrb bytecode before executing the .rb source.\nBasically, you need the native compiler provided by the mruby project.\n$ git clone git@github.com:mruby/mruby.git\n$ cd mruby\n$ rake\n$ ./build/host/bin/mrubc\n\nMRubyD.Compiler\nTo simplify compilation from C#, we also provide the MRubyD.Compiler package, which is a thin wrapper for the native compiler.\nNoteThis MRubyD.Compiler package is a thin wrapper for the native binary. Currently, builds for linux (x64/arm64), macOS (x64/arm64), and windows (x64) are provided.\n\ndotnet add package MRubyD.Compiler\n\nusing MRubyD.Compiler;\n\nvar source = \"\"\"\ndef a\n  1\nend\n\na\n\"\"\"u8;\n\nvar state = MRubyState.Create();\nvar compiler = MRubyCompiler.Create(state);\n\nvar irep = compiler.Compile(source);\n\nstate.Exec(irep); // => 1\n\nLICENSE\nMIT\nContact\n@hadahsiA",
    "summary": {
      "en": "**Summary of MRubyD**\n\nMRubyD is a new virtual machine for the mruby programming language, built entirely in C#. Its name reflects its purpose: to bring mruby to the .NET environment. It aims to integrate well with C# game engines while maintaining compatibility with Ruby APIs.\n\n**Key Features:**\n- **C# Implementation:** Designed for easy integration with C#-based game engines.\n- **High Performance:** Utilizes modern C# features for faster execution and efficiency.\n- **Ruby Compatibility:** Focuses on supporting Ruby APIs, with all opcodes implemented for basic functionality.\n- **Extensibility:** Allows easy access to C# libraries from Ruby, enhancing its flexibility.\n\n**Limitations:** \n- Currently in preview, meaning some built-in types and methods are still under development.\n- Does not yet support certain visibility features (private and protected).\n- Only provides the virtual machine; a separate compiler is needed for running Ruby scripts.\n\n**Installation and Usage:**\n- Install via `dotnet add package MRubyD`.\n- Example usage includes executing bytecode from a Ruby script and defining Ruby classes and methods in C#.\n\n**Roadmap:**\nFuture plans include implementing built-in Ruby libraries, supporting fiber, and enhancing integration with Unity.\n\n**Licensing:**\nMRubyD is licensed under the MIT license.\n\nFor more details, you can refer to the full documentation or contact the developer.",
      "ko": "MRubyD는 mruby 프로그래밍 언어를 위한 새로운 가상 머신으로, C#으로 완전히 개발되었습니다. 이 이름은 mruby를 .NET 환경으로 가져오는 목적을 반영합니다. MRubyD는 C# 게임 엔진과의 통합을 목표로 하면서도 Ruby API와의 호환성을 유지하고자 합니다.\n\n주요 특징으로는 C# 구현이 있어 C# 기반 게임 엔진과 쉽게 통합될 수 있도록 설계되었습니다. 또한 현대적인 C# 기능을 활용하여 빠른 실행과 효율성을 제공합니다. Ruby API 지원에 중점을 두고 있으며, 기본 기능을 위한 모든 연산 코드가 구현되어 있습니다. MRubyD는 Ruby에서 C# 라이브러리에 쉽게 접근할 수 있도록 하여 유연성을 높입니다.\n\n하지만 현재 미리보기 상태로, 일부 내장 타입과 메서드는 아직 개발 중입니다. 특정 가시성 기능인 private와 protected는 지원하지 않으며, Ruby 스크립트를 실행하기 위해서는 별도의 컴파일러가 필요합니다.\n\n설치는 `dotnet add package MRubyD` 명령어를 통해 가능합니다. 사용 예로는 Ruby 스크립트에서 바이트 코드를 실행하거나 C#에서 Ruby 클래스와 메서드를 정의하는 것이 포함됩니다.\n\n앞으로의 계획으로는 내장 Ruby 라이브러리 구현, fiber 지원, Unity와의 통합 강화 등이 있습니다. MRubyD는 MIT 라이선스 하에 배포됩니다. 더 자세한 내용은 전체 문서를 참조하거나 개발자에게 문의할 수 있습니다.",
      "ja": "MRubyDは、mrubyプログラミング言語のために完全にC#で構築された新しい仮想マシンです。この名前は、mrubyを.NET環境に持ち込むことを目的としていることを示しています。C#ベースのゲームエンジンとの統合を目指しつつ、RubyのAPIとの互換性も維持しています。\n\n主な特徴としては、C#での実装があり、C#ベースのゲームエンジンとの統合が容易です。また、最新のC#の機能を活用して、高速な実行と効率性を実現しています。RubyのAPIをサポートすることに重点を置き、基本的な機能のためにすべてのオペコードが実装されています。さらに、RubyからC#ライブラリに簡単にアクセスできるため、柔軟性が向上しています。\n\nただし、現在はプレビュー版であり、一部の組み込み型やメソッドはまだ開発中です。また、プライベートやプロテクテッドといった特定の可視性機能はまだサポートされていません。仮想マシンのみが提供されており、Rubyスクリプトを実行するためには別途コンパイラが必要です。\n\nインストールは「dotnet add package MRubyD」を使用します。使用例としては、Rubyスクリプトからのバイトコードを実行したり、C#でRubyのクラスやメソッドを定義したりすることが含まれます。\n\n今後の計画には、組み込みのRubyライブラリの実装やファイバーのサポート、Unityとの統合の強化が含まれています。\n\nMRubyDはMITライセンスの下でライセンスされています。詳細については、公式ドキュメントを参照するか、開発者にお問い合わせください。"
    }
  },
  {
    "id": "762d0ee62ba37bcc",
    "title": {
      "en": "Show HN: Generate docs from your public repos",
      "ko": "공개 레포로 문서 생성하기",
      "ja": "公開リポからドキュメント生成"
    },
    "type": "story",
    "url": "https://app.docs.dev/generate-docs-instantly",
    "score": 22,
    "by": "linktothenew",
    "time": 1742915158,
    "content": "Your docs AI assistantGenerate docs directly from your codebase.Your GitHub repository",
    "summary": {
      "en": "Your AI assistant helps you create documents straight from your code. It connects to your GitHub repository to generate these documents.",
      "ko": "당신의 AI 비서는 코드를 기반으로 문서를 작성하는 데 도움을 줍니다. 이 비서는 GitHub 저장소에 연결하여 문서를 생성합니다.",
      "ja": "あなたのAIアシスタントは、コードから直接ドキュメントを作成する手助けをします。GitHubのリポジトリに接続して、これらのドキュメントを生成します。"
    }
  },
  {
    "id": "69d49cc6504c4fff",
    "title": {
      "en": "Intel: A Bug and a Pro",
      "ko": "인텔: 버그와 프로",
      "ja": "インテル：バグとプロ"
    },
    "type": "story",
    "url": "https://www.abortretry.fail/p/intel-a-bug-and-a-pro",
    "score": 70,
    "by": "rbanffy",
    "time": 1742851213,
    "content": "Share this postAbort Retry FailIntel: a Bug and a ProCopy linkFacebookEmailNotesMoreDiscover more from Abort Retry FailIn Abort Retry Fail, I am attempting to chronicle the history of the computing industry. This is a goal that will likely not be completed within my lifetime.SubscribeBy subscribing,  I agree to Substack's Terms of Use, and acknowledge its Information Collection Notice and Privacy Policy.Already have an account? Sign inIntel: a Bug and a ProThe FDIV bug and release of the P6Feb 24, 202519Share this postAbort Retry FailIntel: a Bug and a ProCopy linkFacebookEmailNotesMore1ShareBy 1994, Intel had managed to capture about 75% of the microprocessor market for personal computers. The company had also found its way into automobiles, industrial controls, telecommunications equipment, and supercomputers. The Intel x86 architecture had propelled the company to these immense heights, and they’d established a cadence of releases in that CPU line of roughly four years. The investment that both individuals and companies had made in hardware and software for the architecture was measured in billions.While the Pentium had been announced on the 22nd of March in 1993, systems built around the Pentium were announced on the 17th of May in 1993, and volume shipments didn’t occur until later in the year. The Pentium’s 60MHz variant could deliver 100 million instructions per second with the Dhrystone 1.1 benchmark while the 66MHz variant bumped that to 112MIPS. These were the first x86 chips to be capable of this kind of performance, and they nearly doubled the performance of the original i486. This kind of performance nearly put Intel in competition with RISC-based UNIX workstation hardware, and Intel’s biggest software partner, Microsoft, supported those workstations with NT. A key difference, however, was that the Pentium’s price was around $900 while the MIPS R8000 was around $2500 and the Alpha 21064 was over $3000. Naturally, these were all far more reasonably priced when purchased in volume, but Intel was far better in terms of performance per dollar. For less than the cost of a high performance RISC CPU, a customer could purchase an entire Pentium-based PC that, while not as powerful, was capable of the same kinds of work. This is remarkable as PC manufacturers were running into the problems already solved by workstation makers: thermals, volatage variation, RFI, EMI. These kinds of considerations hadn’t been too big a hill to climb with an XT, but they were far more serious issues with a Pentium. They were serious enough that Intel had provided thermal models to system makers before they had provided the silicon.Early in 1994, Intel announced the Pentium P54C for Socket 5. These chips required a 3.3 volt power supply, could run at 75MHz, 90MHz, or 100MHz, and utilized an internal clock multiplier allowing them to operate at a higher frequency than the external buses. These chips bumped the transistor count to 3.3 million, and were built on a half micron BiCMOS process. These Pentiums also added support for use in multiprocessor systems which was the primary source of the increased transistor count. When adding a processor, a machine needs more circuitry for cache, memory, interrupts, and bus utilization.While most news for Intel was great, not all of it was. A few of the first generation Pentium processors were in the hands of Professor Thomas R. Nicely at Lynchburg College in Virginia where they were put to work researching reciprocals of twin prime numbers. On the 13th of June in 1994, Nicely noted that after adding three Pentium-based computers to his lab, he was getting inconsistent results in floating point divisions. He ruled out all causes other than hardware error on the 19th of October. Specifically, Nicely noted that 1 divided by 824633702441 was incorrect on three different Pentium systems while it was correct on multiple i486 and i386 systems. He then sent an email to Intel on the 24th documenting his discovery. Intel didn’t provide much information to him beyond stating that the issue was known. He then sent an email to several other people on the 30th. His email read:It appears that there is a bug in the floating point unit (numeric coprocessor) of many, and perhaps all, Pentium processors.In short, the Pentium FPU is returning erroneous values for certain division operations. For example, 1/824633702441.0 is calculated incorrectly (all digits beyond the eighth significant digit are in error). This can be verified in compiled code, an ordinary spreadsheet such as Quattro Pro or Excel, or even the Windows calculator (use the scientific mode), by computing (824633702441.0)*(1/824633702441.0), which should equal 1 exactly (within some extremely small rounding error; in general, coprocessor results should contain 19 significant decimal digits). However, the Pentiums tested return 0.999999996274709702 for this calculation. A similar erroneous value is obtained for x*(1/x) for most values of x in the interval 824633702418 <= x <= 824633702449, and throughout any interval obtained by multiplying or dividing the above interval by an integer power of 2 (there are yet other intervals which also produce division errors).The bug can also be observed by calculating 1/(1/x) for the above values of x. The Pentium FPU will fail to return the original x (in fact, it will often return a value exactly 3072 = 6*0x200 larger).The bug has been observed on all Pentiums I have tested or had tested to date, including a Dell P90, a Gateway P90, a Micron P60, an Insight P60, and a Packard-Bell P60. It has not been observed on any 486 or earlier system, even those with a PCI bus. If the FPU is locked out (not always possible), the error disappears; but then the Pentium becomes a “586SX”, and floating point must run in emulation, slowing down computations by a factor of roughly ten.I encountered erroneous results which were related to this bug as long ago as June, 1994, but it was not until 19 October 1994 that I felt I had eliminated all other likely sources of error (software logic, compiler, chipset, etc.). I contacted Intel Tech Support regarding this bug on Monday 24 October (call reference number 51270). The contact person later reported that the bug was observed on a 66-MHz system at Intel, but had no further information or explanation, other than the fact that no such bug had been previously reported or observed.Further information can be obtained by contacting me directly, and by downloading files from the [anonymous.nicely.pentium_bug] directory of the acavax.lynchburg.edu machine via anonymous ftp on Internet (password ANONYMOUS, user ID = Internet ID). These files include a documentation file, a DOS executable image demonstrating the bug, and the source code for the demonstration. The zip file uses PKZIP version 2.04g.I would be interested in hearing of test results from other Pentiums, and also from 486-DX4s and (if anybody has one yet) the AMD, Cyrix, and NexGen clones of the Pentium.You may use this information freely as long as you give me attribution by name and employer.This… was exactly the sort of thing folks at Intel would not have wanted to have happen. Andrew Schulman, author of Undocumented DOS and Undocumented Windows, was among the recipients of that email. At this time, Schulman didn’t own a Pentium, so he forwarded the email to Richard Smith of Phar Lap and asked him to test it. Smith and his company confirmed the bug, and Smith posted the email to a CompuServe forum. Within 24 hours, there were 10 more confirmations. This was called the FDIV bug (after the x86 assembly language mnemonic for floating point division), and it made headlines. On the 7th of November in 1994, the Electronic Engineering Times ran an article titled: Intel fixes a Pentium FPU glitch which read:To correct an anomaly that caused inaccurate results on some high-precision calculations, Intel Corp. last week confirmed that it had updated the floating-point unit (FPU) in the Pentium microprocessorThe company said that the glitch was discovered midyear and was fixed with a mask change in recent silicon. \"This was a very rare condition that happened once every 9 to 10 billion operand pairs,\" said Steve Smith, a Pentium engineering manager at Intel.A spot check last week indicated the problem is present in at least one recently made Pentium-based PC. Intel said it could not quantify how many such systems were in the field.Said an Intel spokesman: \"This doesn't even qualify as an errata. We fixed it in a subsequent stepping.\"Erroneous divisionThe issue came to light last week in a message, on Compuserve's \"Canopus\" forum, which was a reposting of a private e-mail communication from Lynchburg College (Lynchburg,Va.) mathematics professor Thomas Nicely. \"The Pentium floating-point unit is returning erroneous values for certain division operations,\" he wrote. \"For example, 1/824633702441 is calculated incorrectly (all digits beyond the eigth significant digit are in error). This can be verified...by computing (824633702441.0) X (1/824633702441.0), which should equal 1 exactly (within some exteremely small rounding error; in general, coprocessor results should contain 19 significant decimal digits). However, the Pentiums tested return 0.999999996274709702 for this calculation.\"\"The bug has been observed on all Pentiums I have tested or had tested to date, including a Dell P90, a Gateway P90, a Micron P60, an Insight P60 and a Packard-Bell P60. It has not been observed on any 486 or earlier system, even those with a PCI bus. If the floating-point unit is locked out (not always possible), the error disappears.\"Intel's Smith emphasized that the anomaly would not affect the average user. Speaking of Nicely, Smith said: \"He's the most exterme user. He spends round-the-clock time calculating reciprocals. What he observed after running this for months is an instance where we have eight decimal points correct, and the ninth not showing up correctly. So you get an error in the ninth decimal digit to the right of the mantissa. I think even if you're an engineer, you're not going to see this.\"Nicely said he pointed out the problem to Intel, because \"it has a major effect in mathematics, because we have to have absolute precision. I suspect that, to the majority of people, it will be irrelevant. But engineers may have a different outlook.\"A spot check conducted at EE Times last week tested out Nicely's expression on an AcerPower Minitower Pentium/60 machine, which was just received from Acer America. The result was 0.999999996247.Intel said it discovered the anomaly through its own random testing. The fix involved a mask change to the Pentium's floating-poing unit. Specifically, according to Intel's Smith, the correction entailed an update to the programmable-logic array (PLA) on the Pentium.\"This is related to the state machine in the floating-point unit. There are certain cases where, way out in the operation, we didn't handle the precision correctly,\" he said. \"It's an iterative calculation, and at each point, you have to go through a lookup process that says what your next approximation for the bits further out in the mantissa, [which equates to the digits] further to the right of the decimal point.\"Better resultsThe fix entailed adding terms, or additional gate-sequences, to the PLA. That corrected the erroneous results returned from the problematic lookup table accesses.Intel said there are no part-number designations or other markings on the updated microprocessors - which became available in the last few months - to differentiate them from the earlier anomalous parts. However, an Intel spokesman said, \"If customers are concerned, they can call and we'll replace\" any of the parts that contained the bug.CNN reported on the bug on the 22nd of November, and then on the 23rd of November in 1994, the New York Times ran an article titled: Flaw Undermines Accuracy of Pentium Chips, which read in part:The flaw appears in all Pentium chips now on the market, in certain types of division problems involving more than five significant digits, a mathematical term that can include numbers before and after a decimal point.Intel declined to say how many Pentium chips it made or sold, but Dataquest, a market research company in San Jose, Calif., estimated that in 1994 Intel would sell 5.5 million to 6 million Pentiums, roughly 10 percent of the number of personal computers sold worldwide.Intel said yesterday that it did not believe the chip needed to be recalled, asserting that the typical user would have but one chance in more than nine billion of encountering an inaccurate result as a consequence of the error, and thus there was no noticeable consequence to users of business or home computers. Indeed, the company said it was continuing to send computer makers Pentium chips built before the problem was detected.This was, most likely, the first widely publicized instance of a hardware error in a microprocessor. The publicity, however, didn’t get Intel to act. They would ship replacements only if a customer could prove to an Intel representative that he/she required accuracy beyond what his/her Pentium could provide. On the 12th of December, IBM announced that it was halting shipments of Pentium-based machines. While Intel had stated that an average user might encounter the bug once in 27,000 years, IBM found that a user would likely encounter this bug every few days. Intel quickly changed their plans announcing on the 19th that they’d replace all flawed Pentiums. This cost them $475 million (or roughly $1.018 billion in 2025 dollars).Ken Sherriff found the bug in silicon and provided an in-depth explanation for what exactly went wrong and how it got corrected if you’d like more detailed coverage of it.The year was far better for Intel in the supercomputer space with the i960 becoming the leading RISC chip in total number of chips sold. This little flake of silicon could be found in networking devices, laser printers, and the world’s most powerful supercomputer at the time built of two Intel Paragon XP/S 140s at Sandia National Laboratories.By the end of the year, Intel’s Tape Carrier Packaging (TCP) had made its way to market. Intel described TCP as offering reduced pitch, thin package profiles, and a small on-board footprint. They also stated: “Key package features include surface mount technology design, lead pitch of 0.25 mm, 48 mm tape format, polyimide-up for pick and place, and slide carrier handling. Shipped flat in slide carriers, the leads are designed to be formed into a ‘gull-wing’ configuration and reflowed onto the PCB by one of several methods.” What this meant was that the Pentium could be used in notebooks. The first of these was (as far as I could find) was the Toshiba T4900CT. This notebook featured an Intel Pentium clocked at 75MHz (3.3 volt, 16K cache), 10.4” SVGA TFT-LCD, 772MB HDD, 8MB of RAM (expandable to 40MB), 2x PCMCIA, VL-bus GPU, 3.5 inch 1.44MB floppy disk drive, and it ran Windows 3.11 for Workgroups. If you are aware of an early Pentium notebook, please let me know in the comments.Despite the FDIV bug and a healthy $3.55 billion spent on capital and R&D, Intel’s income for 1994 was $2.28 billion on revenues of $11.5 billion.With corrected Pentiums and the P54C out in the wild, 1995 was a great year for the company. With the launch of Windows 95 on the 24th of August, sales for the Pentium increased significantly with PC sales increasing by 25% globally to around 60 million. Microsoft’s success was lifting all boats in the PC markets, and it was doing so in a dramatic way. It’s support for the PCI bus didn’t hurt Intel either.Intel Pentium Pro die image, from IntelOn the 1st of November in 1995, Intel launched the Pentium Pro, and had Intel kept its original naming scheme, this would have been the i686. The original Pentium Pro was built of 5.5 million transistors on either a half micron or a 0.35 micron BiCMOS process. It shipped in a 387-pin CPGA (Socket 8), supported a clock speed of 150MHz to 200MHz, and could support single, dual, and quad processor configurations. While a 32bit CPU, the Pentium Pro had a 36bit address width and supported PAE which allowed it to address up to 64GB of RAM. It had an 8K L1 instruction cache, an 8K L1 data cache, and a 256K L2 on the low-end and up to 1MB L2 on the high-end. The L2 was on-package but not on-chip, and it had its own back-side bus. This design allowed the CPU to read memory and cache concurrently. TDP ranged from 29.2W to 44W depending upon the clock, bus speed (60MHz or 66MHz), and cache size.Intel Pentium Pro 200 in socket, image from computerbase.deThe Pentium Pro shared almost nothing with its predecessors beyond its name, manufacturer, and ISA. The lead designer was Fred Pollack who’d previously worked on the iAPX 432. Internally, the Pentium Pro was a superscalar, out of order, RISC chip with support for speculative execution and register renaming. On every cycle, up to 16bytes were fetched from the instruction cache and sent to decoders of which there were three. These decoders took x86 instructions and translated them into RISC micro-operations. Two of these were intended only for simple x86 instructions (simple defined here as instructions that are translated into a single RISC micro-operation in a single cycle) while the third could handle any instruction. The Pentium Pro heavily relied upon microcode and that microcode was upgradeable under either the BIOS or operating system control. Yet another deviation from earlier x86 chips was backward compatibility. Unlike earlier Intel x86 CPUs, the Pentium Pro, while capable of running 16bit code, didn’t emphasize this, and it was, indeed, slower than other x86 chips of that time at executing 16bit code. The cause of the slow down was that a read from a large register, say EAX, would stall until a write to a partial register, say AX, retired. This stall would then result in a pipeline flush. The Pentium Pro was meant to run fully 32bit software, and the ability to run software for earlier chips was meant to be a convenience. The Pentium Pro was specifically targetted at workstations and servers where one wouldn’t usually be running a standard word processor, spreadsheet, or video game. Those applications were the domain of the i386, i486, or original Pentium. Pentium Pro was a monster, image from Microprocessor Report, Vol9, Num15, 13th Nov 1995For those workstation and server users who wanted crazy performance more cheaply than a traditional UNIX on RISC system, the Pentium Pro delivered. When the chip shipped on the 2nd of November, pricing stood at $974 to $1325 (the top end SKU would ship slightly later at a price of $1989), and it was faster than all competitors at 32bit integer performance. While it lagged in floating point, the ability to combine multiple Pentiums Pro in a single system, allowed Intel to compete well despite that disadvantage. Truly, the Pentium Pro was remarkable. The slowest part, at 166MHz, delivered slightly more than double the integer performance of a 200MHz R4400 in SYSmark/NT. Obviously, when dealing with real-world applications, this could vary, but for many applications, the Pentium Pro did punch above its price. To put the pricing of full systems into perspective, Intergraph would launch the first quad-CPU Pentium Pro workstations in November of 1996. All of the machines in this lineup featured a graphics add-in card made by Intergraph (G76, G95, or Intense 3D). The cheapest was the TD-200 ranging from $1500 to $5000 depending upon the graphics card used. In that top of the line single-CPU model, the machine delivered roughly twice the graphical performance of an SGI O2 (according to Intergraph). Completing the line up from Intergraph were the TD-310, TD-410, and TD-610. These came with one, two, or four Pentiums Pro. These could be configured with up to 1GB of RAM, an Ultra SCSI hard disk, an ethernet controller, a Creative Labs Vibra 16c (integrated), up to ten expansion slots (PCI and ISA) in desk-side models, an 8x CD-ROM, a 3.5 inch floppy disk drive, dual-screen support, and Windows NT 4.0.Intergraph TD-310, image from intergraph manualThe Pentium Pro would not have anywhere near the market success of the Pentium, but that wasn’t its purpose. It was meant to break into the workstation and server markets; goals it accomplished. Additionally, the architecture of the Pentium Pro (P6) would server Intel quite well for more than a decade.Intel closed 1995 with $3.5 billion in income on $16.2 billion in revenues. Starting 1996 with the Pentium, Windows 95, and the explosion of the World Wide Web, Intel was benefiting from massive ecosystem growth. While the FDIV bug certainly got quite a bit of press, cost quite a bit of money, and was something Intel would surely rather have avoided, it didn’t hurt the company’s trajectory at all. Intel made it to number 5 on Fortune’s most admired companies list in 1996, and the company’s market value reached $111 billion. Intel closed 1996 with $5.157 billion in income on revenues of $20.847 billion, assets of $13.684 billion, and liabilities of $4.863 billion.I now have readers from many of the companies whose history I cover, and many of you were present for time periods I cover. A few of you are mentioned by name in my articles. All corrections to the record are welcome; feel free to leave a comment.Subscribe to Abort Retry FailBy Bradford Morgan WhiteIn Abort Retry Fail, I am attempting to chronicle the history of the computing industry. This is a goal that will likely not be completed within my lifetime.SubscribeBy subscribing,  I agree to Substack's Terms of Use, and acknowledge its Information Collection Notice and Privacy Policy.19 Likes∙1 Restack19Share this postAbort Retry FailIntel: a Bug and a ProCopy linkFacebookEmailNotesMore1Share",
    "summary": {
      "en": "The text discusses Intel's rise in the microprocessor market, focusing on the Pentium processor and the notable FDIV bug. \n\nKey points include:\n\n1. **Intel's Market Dominance (1994)**: By 1994, Intel held 75% of the microprocessor market and was involved in various industries, thanks to its x86 architecture.\n\n2. **Pentium Performance**: The Pentium, launched in 1993, significantly outperformed its predecessor, the i486, and offered competitive pricing compared to RISC workstation CPUs.\n\n3. **FDIV Bug Discovery**: In 1994, Professor Thomas R. Nicely discovered a bug in the Pentium's floating-point unit that caused inaccuracies in specific division calculations. He reported this issue to Intel, leading to widespread media coverage.\n\n4. **Intel's Response**: Initially, Intel downplayed the bug's impact, stating it was rare. However, after IBM halted shipments of Pentium-based machines due to the bug, Intel agreed to replace all affected chips, costing the company about $475 million.\n\n5. **Impact on Intel**: Despite the bug, Intel continued to grow, launching the Pentium Pro in 1995, which was designed for workstations and servers. The company experienced significant sales growth, driven by the launch of Windows 95 and the expanding PC market.\n\nOverall, while the FDIV bug was a significant issue, it did not derail Intel's success, and the company continued to thrive in the technology sector throughout the 1990s.",
      "ko": "1994년까지 인텔은 마이크로프로세서 시장에서 75%의 점유율을 차지하며 다양한 산업에 진출했습니다. 이는 인텔의 x86 아키텍처 덕분이었습니다. \n\n1993년에 출시된 펜티엄 프로세서는 이전 모델인 i486보다 성능이 크게 향상되었고, RISC 워크스테이션 CPU와 비교해도 경쟁력 있는 가격을 제공했습니다. \n\n1994년, 토마스 R. 나이슬리 교수는 펜티엄의 부동 소수점 유닛에서 특정 나눗셈 계산에서 부정확성을 초래하는 버그를 발견했습니다. 그는 이 문제를 인텔에 보고했고, 이 사건은 언론에 크게 보도되었습니다. \n\n처음에 인텔은 이 버그의 영향이 드물다고 주장하며 문제를 축소했습니다. 그러나 IBM이 펜티엄 기반 기계의 출하를 중단하자 인텔은 영향을 받은 모든 칩을 교체하기로 결정했고, 이로 인해 약 4억 7500만 달러의 비용이 발생했습니다. \n\n버그에도 불구하고 인텔은 계속 성장했습니다. 1995년에는 워크스테이션과 서버용으로 설계된 펜티엄 프로를 출시하며, 윈도우 95의 출시와 PC 시장의 확장에 힘입어 판매가 크게 증가했습니다. \n\nFDIV 버그는 중요한 문제였지만 인텔의 성공을 저해하지 않았고, 1990년대 내내 기술 분야에서 계속 번창했습니다.",
      "ja": "1994年までに、インテルはマイクロプロセッサ市場の75%を占めており、x86アーキテクチャのおかげでさまざまな産業に関与していました。1993年に発売されたペンティウムプロセッサは、前のi486を大きく上回る性能を持ち、RISCワークステーションのCPUと比較しても競争力のある価格を提供しました。\n\nしかし、1994年にトーマス・R・ナイセリー教授がペンティウムの浮動小数点ユニットにバグを発見しました。このバグは特定の割り算計算において不正確な結果を引き起こすもので、彼はこの問題をインテルに報告しました。この件はメディアで広く取り上げられました。\n\n当初、インテルはこのバグの影響を軽視し、発生は稀であると述べました。しかし、IBMがペンティウムを搭載した機械の出荷を停止した後、インテルは影響を受けたすべてのチップを交換することに同意し、その費用は約4億7500万ドルに達しました。\n\nこのバグにもかかわらず、インテルは成長を続け、1995年にはワークステーションやサーバー向けに設計されたペンティウムプロを発売しました。また、Windows 95の発売やPC市場の拡大により、売上は大きく伸びました。\n\nFDIVバグは重要な問題でしたが、インテルの成功を妨げることはなく、1990年代を通じて技術分野での成長を続けました。"
    }
  },
  {
    "id": "361dc226f099cf47",
    "title": {
      "en": "Rickover's Lessons",
      "ko": "릭오버의 교훈",
      "ja": "リコバーの教え"
    },
    "type": "story",
    "url": "https://www.chinatalk.media/p/rickovers-lessons-how-to-build-a",
    "score": 120,
    "by": "pepys",
    "time": 1742703526,
    "content": "Share this postChinaTalkRickover’s LessonsCopy linkFacebookEmailNotesMoreDiscover more from ChinaTalkDeep coverage of technology, China, and US policy. We feature original analysis alongside interviews with leading thinkers and policymakers.Over 51,000 subscribersSubscribeBy subscribing,  I agree to Substack's Terms of Use, and acknowledge its Information Collection Notice and Privacy Policy.Already have an account? Sign inRickover’s Lessons\"The status quo has no absolute sanctity\"Lily Ottinger and Charles YangMar 20, 202565Share this postChinaTalkRickover’s LessonsCopy linkFacebookEmailNotesMore1212ShareCharles Yang is the executive director for the Center for Industrial Strategy, a bipartisan think tank focused on industrial policy. Previously, he served as an AI and Supply Chain Policy Advisor at the Department of Energy and was an ML Engineer at an AI hardware startup in San Francisco. Today, he’s here to present some excerpts from his research into how Admiral Hyman Rickover built the nuclear navy.Strategic competition demands more than technological innovation — it requires building industrial power. The U.S. is realizing the damage done by decades of underinvestment in the nation’s industrial base, which now jeopardizes its ability to compete on the global stage. Today, the production capacity of Chinese shipyards is over 200 times that of US shipyards, and China has used its chokehold on critical mineral processing as leverage to retaliate against US sanctions.A new bipartisan consensus is emerging around the need for industrial policy — from the passage of the CHIPS and Science Act, to the recent bipartisan introduction of the SHIPS for America Act and the Critical Minerals for the Future Act.As Congress steps into this more active role, policymakers should learn from the successes of our past. Nearly 75 years ago, Admiral Hyman G. Rickover, “Father of the Nuclear Navy”, pioneered a bold program to develop and operationalize nuclear power in the Navy. Under his leadership, the U.S. government harnessed the power of the atom, building the world’s first nuclear-powered submarine and the world’s largest fleet of nuclear reactors for civilian power.Lessons From the PastRickover spent his entire career in the Navy and is still the longest-serving naval officer in US history. He spent the first 20 years of his career as an electrical engineer, where he honed a strong technical foundation and unique management style. In 1946, he was assigned a 1-year tour of duty at the Oak Ridge site of the Manhattan Project. Rickover immediately recognized the transformative potential of nuclear technology — he spent the rest of his career building the “Nuclear Navy,” which ensured US strategic dominance of the high seas for the rest of the 20th century.Within the span of 10 years, Rickover created an entire office dedicated to nuclear propulsion, and successfully launched the world’s first nuclear-powered submarine without cost overruns. He conclusively demonstrated the strategic importance of nuclear propulsion in a timeframe no one thought possible and helped the US beat the Soviets to nuclear propulsion for submarines by 3 years. His institutional legacy is the US Navy’s safe construction and operation of nuclear reactors.As the US gears up for another strategic competition, Rickover’s story can offer helpful lessons for aspiring technocrats. Oftentimes, industrial policy is framed in terms of legislation, but Rickover demonstrates that industrial policy is as much about policy as it is about strong leadership.USS Enterprise, the world’s first nuclear-powered aircraft carrier. Source.Talent, Training, and ManagementRickover spent an inordinate amount of time focused on interviewing personnel — he made the final hiring decision for every naval officer who applied to serve on a nuclear submarine until he retired. And he was an unorthodox interviewer, screening for high agency individuals who could think on their feet — literally! To test their composure, Rickover famously made candidates sit in a chair with the front two legs shortened as he loomed over them during questioning.The infamous “Rickover chair”One interview account:For one interviewee who said he liked hiking, Rickover asked him if he had ever hiked the nearby “Goat Mountain”. When he said he had not, Rickover told him to bring him proof he had climbed it by tomorrow morning and he would be hired. It turns out that Goat Mountain was the peak of a structure for mountain goats in a zoo. He went to the zoo, asked a tourist to take his picture, jumped into the enclosure, and climbed to the top. He’s hired the next day!But it didn’t end at the interview process — Rickover believed in continued technical training for his staff and in building out a talented workforce base for this new technology:While Rickover worked to staff up quickly in the short term, he also set out to build a deep bench and a long-term pipeline of talent. He required each officer and engineer he hired to submit a self-study plan demonstrating mastery of advanced texts in metallurgy, physics, and chemistry, along with field trips to AEC facilities, totaling 854 hours of study or 16 hours per week. He also worked with MIT to develop a survey course on nuclear physics and a master's degree in nuclear engineering, with a curriculum drawn up and agreed to by Rickover, starting in June of 1949. Rickover also worked with Oak Ridge National Lab to develop a 1-year curriculum in nuclear science and technology, a program christened “Oak Ridge School of Reactor Technology (ORSORT) with the first cohort starting in March 1950. Westinghouse, GE, utilities, naval and private shipyards, and Naval Reactors all sent students to ORSORT and the program started turning out ~100 graduates a year, providing another training center to develop a nuclear industry.1 Finally, Rickover had his engineers provide training lectures to a variety of audiences, ranging from senior officials in BuShips to junior technicians, as well as to explain shipboard problems and applications to scientists at Argonne, Oak Ridge, and Westinghouse/GE.He was also known for his unique style of management. Not only did he interview every naval officer in his office, he also maintained direct lines of communication with every nuclear sub commander and project officer on-site with contractors, giving him early awareness of every issue. The demanding oversight he extended over his technical staff under his command pushed them to have greater awareness of their own direct reports:Rickover was also an intensely demanding and scrutinizing manager. As most writing then was done on carbon copy paper, every night Rickover would collect the “pinks” of every piece of writing from his various teams i.e. the carbon copied half, and read over them at home, including drafts. When his officers protested as to how they should be expected to keep track of everything in their purview, including drafts reports from staff below them, Rickovers responded “It’s up to you to see that I don’t know more about what’s going on in your shop than you do”. By enforcing tight lines of supervision over his officers, Rickover ensured that he maintained full visibility into each team, including the project facilities at Knolls, Bettis, and the shipyards, allowing him to catch problems early on. It also enforced a culture of direct accountability and oversight across the organization.Rickover’s focus on hiring, training, and close project management represented his philosophical approach to how to build complex systems managed by humans.Near the end of his career, Rickover testified to Congress after the Three Mile Island Reactor accident. He spent the vast majority of his testimony talking not about regulatory reform, but about the lack of training and inadequate culture of responsibility among the operators.“Human experience shows that people, not organizations or management systems, get things done. For this reason, subordinates must be given authority and responsibility early in their careers…Complex jobs cannot be accomplished effectively with transients. A manager must make the work challenging and rewarding so that his people will remain with the organization for many years. This allows it to benefit fully from their knowledge, experience, and corporate memory.”~ Hyman Rickover, 1982Industrial State CapacityRickover’s scrutinizing style of management extended to the private companies he worked with. He pioneered the practice of project officers, who lived on-site at the projects and who would report directly to him any delays or unforeseen issues, so that Rickover could escalate immediately and ensure the project remained on track.Government contracting was, and still is today, a largely passive and administrative activity. While Rickover acknowledged that the government was the “customer” and the contractor was the one responsible for delivering, Rickover’s unique approach to program management was exercising tight oversight over the contractors. Rickover hired technical experts into his office and then sent them out as project officers to oversee the various contractor sites. There, the project officer was expected to be the active representative of the Naval Reactors Office, reporting directly to Rickover any issues with contractors and ensuring the contractor was on track to deliver the product as expected. In every sense, Rickover’s project officer was to be his eyes and ears on the ground. Rickover took great pains to ensure there was no customer capture, telling one of his project officers, “Don’t go to dinner with them. Your wives must not get friendly with their wives. You’re not even to let your dogs get friendly with their dogs…when you do that, you become one of them…you don’t represent me anymore”.Rickover’s success in scaling industrial technology was demonstrated early on with Zirconium production. In 1949, the world had only produced a shoebox worth of purified Zirconium, but the material showed promise as a fuel cladding material due to its durability under high temperatures without blocking the emitted neutrons needed to enable fission reactions. AEC opened up a simple contract for private companies to bid to produce Zirconium, but none of the companies were able to scale up production. Rickover took over production a year later, applied his practice of close project management with the (now defunct) Bureau of Mines, and only then passed it off to industry:But by 1949, when Rickover was looking to scale up promising fuel cladding material production, the AEC had already decided to run contracts through another AEC division. Unable to exert the centralized control over the contractors, the AEC manufacturers were slow to scale up a high-quality production process. In 1950, after a year of delay, Rickover finally received permission to have the Westinghouse Bettis site directly manufacture Zirconium metal and worked with the Bureau of Mines (BuMines) to purify the Zirconium. Under Rickover’s scrutiny, Bettis scaled a novel purification process to thousands of tons of production capacity. Rickover opened up contract bids for Zirconium only after having derisked this novel technology. When the Secretary of the Navy later asked Westinghouse how they managed to scale up this process, the response he got was “Rickover made us do it”.“The man in charge must concern himself with details. If he does not consider them important, neither will his subordinates.”~ Hyman Rickover, 1982Bureaucratic InnovationBuilding big things requires lots of people. Rickover was not only an exceptional manager of people and deeply technical, but his 20-year naval career before Oak Ridge taught him how to wrangle government bureaucracy — and discern which rules mattered and which didn’t. For example, Rickover was interviewing an officer who thought the monthly reports on the gasoline usage of his base’s motorboats were pointless and wasteful. Rickover told him to simply remove the tickler file that tracked the reports from the boss’s secretary file and to send over a note the next day alerting Rickover that the task had been completed. The interviewee did and was hired.SubscribeRickover’s bureaucratic skill is exemplified by his success in rallying the Navy behind the nuclear-powered submarine. He believed this was a feasible, near-term project, despite widely-held convictions to the contrary — including those of the Atomic Energy Commission (AEC). Even Robert Oppenheimer (who served as one of the first AEC commissioners) doubted nuclear propulsion early on.In light of initial resistance from the civilian AEC, Rickover formulated a unique bureaucratic innovation to position himself within two chains of command — one within the Navy and the other within the AEC.Rickover was also able to realize his bureaucratic innovation to occupy a spot on the org chart both at AEC and in the Navy BuShips, something he first formulated while at Oak Ridge. This way, if the AEC refused something, he could respond that “this is a priority for the Navy” and vice versa. Similar to how the Manhattan Project reduced risk by pursuing parallel technological approaches, Rickover would reduce his bureaucratic risk by pursuing parallel chains of command. This unique structure lives on to this day, with Naval Reactors shared between the semi-autonomous National Nuclear Safety Administration (NNSA) in the Department of Energy (DOE) and the Navy.Joint org chart for AEC and Navy nuclear reactor efforts“The status quo has no absolute sanctity under our form of government. It must constantly justify itself to the people in whom is vested ultimate sovereignty over this nation”~ Hyman RickoverRickover firmly believed that the right team and the right culture could build incredible industrial technologies at scale, even within the government. While discourse in Washington DC often focuses on regulations or money, Rickover’s life brings a uniquely human-centered view of industrial policy: one that recognizes the importance of state capacity, technical personnel, and most importantly, public leaders with the vision and drive to build technology.You can read the full story of Rickover and how he built the world’s first nuclear-powered submarine on Charles’s substack.Rough DraftsHow Hyman Rickover Built the Nuclear NavyThere is a common misconception that the United States stopped building nuclear reactors after the 1970s. But that is not the full story: the US Navy has consistently built at least one small nuclear reactor every year since the 1950s. The fact that the Navy has managed to safely design, build, and operate nuclear reactors for decades, despite the stagn…Read more22 days ago · 15 likes · 1 comment · Charles YangSubscribe to ChinaTalkHundreds of paid subscribersDeep coverage of technology, China, and US policy. We feature original analysis alongside interviews with leading thinkers and policymakers.SubscribeBy subscribing,  I agree to Substack's Terms of Use, and acknowledge its Information Collection Notice and Privacy Policy.65Share this postChinaTalkRickover’s LessonsCopy linkFacebookEmailNotesMore1212ShareA guest post byCharles YangPondering possible futuresSubscribe to Charles",
    "summary": {
      "en": "The article discusses the importance of industrial policy in the U.S., emphasizing lessons from Admiral Hyman Rickover, known as the \"Father of the Nuclear Navy.\" Rickover's approach to building the nuclear navy illustrates that strong leadership and effective management are crucial for technological advancement.\n\nKey points include:\n\n1. **Strategic Competition**: The U.S. faces challenges in global competition due to years of underinvestment in its industrial base, particularly in comparison to China's significant shipbuilding capacity.\n\n2. **Bipartisan Support for Industrial Policy**: Recent legislation like the CHIPS and Science Act reflects a growing consensus in Congress on the need for a robust industrial policy.\n\n3. **Rickover's Achievements**: He successfully led the development of the world’s first nuclear-powered submarine, demonstrating the strategic value of nuclear power in the Navy.\n\n4. **Focus on Talent and Training**: Rickover was meticulous in hiring, training, and managing personnel, ensuring they were highly skilled and accountable. He developed rigorous training programs and directly supervised his teams to maintain high standards.\n\n5. **Active Management Style**: He maintained close oversight of projects and contractors, ensuring they met expectations and addressing issues promptly.\n\n6. **Bureaucratic Innovation**: Rickover navigated government bureaucracy effectively, creating a dual command structure that allowed him to advocate for nuclear propulsion across different agencies.\n\n7. **Human-Centered Industrial Policy**: Rickover believed that successful industrial policy relies on capable personnel and visionary leaders who can drive technological progress.\n\nThe article concludes that Rickover's legacy offers valuable insights for modern policymakers as the U.S. seeks to strengthen its industrial capacity and compete globally.",
      "ko": "이 기사는 미국의 산업 정책의 중요성을 다루며, \"핵 해군의 아버지\"로 알려진 하이먼 리코버 제독의 교훈을 강조합니다. 리코버의 핵 해군 구축 방식은 강력한 리더십과 효과적인 관리가 기술 발전에 얼마나 중요한지를 보여줍니다.\n\n주요 내용으로는 미국이 글로벌 경쟁에서 직면한 도전이 있습니다. 특히 중국의 막대한 조선 능력과 비교할 때, 미국은 산업 기반에 대한 투자 부족으로 어려움을 겪고 있습니다. 최근 통과된 CHIPS 및 과학 법안은 강력한 산업 정책의 필요성에 대한 의회의 공감대를 반영하고 있습니다.\n\n리코버는 세계 최초의 핵 추진 잠수함 개발을 성공적으로 이끌며, 해군에서 핵 에너지의 전략적 가치를 입증했습니다. 그는 인재 채용과 교육, 관리에 매우 철저했으며, 인력이 높은 기술을 갖추고 책임감을 가지도록 보장했습니다. 그는 엄격한 교육 프로그램을 개발하고 팀을 직접 감독하여 높은 기준을 유지했습니다.\n\n리코버는 프로젝트와 계약자에 대한 밀접한 관리 스타일을 유지하며, 기대에 부응하도록 하고 문제를 신속하게 해결했습니다. 그는 정부의 관료적 절차를 효과적으로 헤쳐 나가며, 다양한 기관에서 핵 추진을 옹호할 수 있는 이중 지휘 구조를 만들었습니다.\n\n그는 성공적인 산업 정책이 유능한 인력과 비전 있는 리더에 의존한다고 믿었습니다. 리코버의 유산은 미국이 산업 역량을 강화하고 글로벌 경쟁에서 성공하기 위해 현대 정책 입안자들에게 귀중한 통찰을 제공합니다.",
      "ja": "この記事では、アメリカにおける産業政策の重要性について、核海軍の父と呼ばれるハイマン・リコバー提督からの教訓が強調されています。リコバーの核海軍の構築に対するアプローチは、技術の進歩には強力なリーダーシップと効果的な管理が不可欠であることを示しています。\n\nアメリカは、特に中国の大規模な造船能力と比較して、産業基盤への投資が不足しているため、グローバルな競争において課題に直面しています。最近のCHIPS法案や科学法案などの立法は、強固な産業政策の必要性について議会内での合意が高まっていることを反映しています。\n\nリコバーは、世界初の原子力潜水艦の開発を成功させ、海軍における原子力の戦略的価値を示しました。彼は人材の採用、訓練、管理に非常に厳格で、高度なスキルを持ち、責任感のある人材を育成しました。厳しい訓練プログラムを開発し、チームを直接監督することで高い基準を維持しました。\n\nリコバーはプロジェクトや契約者に対して密接な監視を行い、期待に応えるようにし、問題が発生した際には迅速に対処しました。彼は政府の官僚制度をうまく活用し、異なる機関で原子力推進を推進するための二重指揮構造を作り出しました。\n\nリコバーは、成功する産業政策は有能な人材と技術革新を推進できるビジョンを持ったリーダーに依存していると信じていました。リコバーの遺産は、アメリカが産業能力を強化し、国際的に競争するための貴重な洞察を現代の政策立案者に提供しています。"
    }
  },
  {
    "id": "2c6f01f2468a616d",
    "title": {
      "en": "Qwen2.5-VL-32B: Smarter and Lighter",
      "ko": "스마트하고 가벼운 Qwen2.5-VL-32B",
      "ja": "Qwen2.5-VL: 賢く軽く"
    },
    "type": "story",
    "url": "https://qwenlm.github.io/blog/qwen2.5-vl-32b/",
    "score": 537,
    "by": "tosh",
    "time": 1742841312,
    "content": "QWEN CHAT\nGITHUB\nHUGGING FACE\nMODELSCOPE\nDISCORDIntroduction#At the end of January this year, we launched the Qwen2.5-VL series of models, which received widespread attention and positive feedback from the community. Building on the Qwen2.5-VL series, we continued to optimize the model using reinforcement learning and open-sourced the new VL model with the beloved 32B parameter scale under the Apache 2.0 license — Qwen2.5-VL-32B-Instruct. Compared to the previously released Qwen2.5-VL series models, the features of this 32B VL model are as follows:Responses More Aligned with Human Preferences: Adjusted the output style to provide more detailed, better-formatted answers that align more closely with human preferences.Mathematical Reasoning: Significant improvement in the accuracy of solving complex mathematical problems.Fine-grained Image Understanding and Reasoning: Enhanced accuracy and detailed analysis in tasks such as image parsing, content recognition, and visual logic deduction.Performance#Extensive benchmarking against state-of-the-art (SoTA) models of comparable scale, Qwen2.5-VL-32B-Instruct has demonstrated superiority over baselines, e.g., Mistral-Small-3.1-24B and Gemma-3-27B-IT, even surpassing the larger Qwen2-VL-72B-Instruct. Notably, it achieves significant advantages in multimodal tasks such as MMMU, MMMU-Pro, and MathVista, which focus on complex, multi-step reasoning. On MM-MT-Bench, a benchmark emphasizing subjective user experience evaluation, Qwen2.5-VL-32B-Instruct outperforms its predecessor Qwen2-VL-72B-Instruct by a substantial margin.In addition to excelling in visual capabilities, Qwen2.5-VL-32B-Instruct has also achieved top-tier performance in pure text capabilities at the same scale.Demo Cases#Fine-grained Image Understanding and Reasoning (1/5)\nNextUserI am driving a large truck on this road, and it is now 12 o’clock. Can I reach a place 110 kilometers away before 13 o’clock?\nQwen2.5-VL-32BTo determine whether you can reach a place 110 kilometers away before 13:00, we need to analyze the information provided:Current Time: It is 12:00.Distance to Destination: 110 kilometers.Speed Limit for Trucks: The speed limit sign indicates that the maximum speed for trucks is 100 km/h.Step-by-Step Analysis:#1. Calculate the Required Travel Time#The formula to calculate travel time is:\nTime=DistanceSpeed\n\\text{Time} = \\frac{\\text{Distance}}{\\text{Speed}}\nTime=SpeedDistance\nGiven:Distance = 110 kmMaximum Speed = 100 km/hSubstitute the values:\nTime=110km100km/h=1.1hours\n\\text{Time} = \\frac{110 \\text{ km}}{100 \\text{ km/h}} = 1.1 \\text{ hours}\nTime=100km/h110km=1.1hours2. Convert Time to Hours and Minutes#1.1 hours is equivalent to:\n1hour+0.1×60minutes=1hour+6minutes=1hourand6minutes\n1 \\text{ hour} + 0.1 \\times 60 \\text{ minutes} = 1 \\text{ hour} + 6 \\text{ minutes} = 1 \\text{ hour and } 6 \\text{ minutes}\n1hour+0.1×60minutes=1hour+6minutes=1hourand6minutes3. Determine Arrival Time#If you start at 12:00 and it takes 1 hour and 6 minutes to travel 110 kilometers, your arrival time will be:\n12:00+1hourand6minutes=13:06\n12:00 + 1 \\text{ hour and } 6 \\text{ minutes} = 13:06\n12:00+1hourand6minutes=13:064. Compare with Target Time#You want to arrive before 13:00. However, based on the calculations, you will arrive at 13:06, which is after 13:00.Conclusion:#Given the speed limit of 100 km/h for trucks, it is not possible to reach a place 110 kilometers away before 13:00.Thus, the final answer is:\nNo\n\\boxed{\\text{No}}\nNoMathematical Reasoning (2/5)\nNextUserAs shown in the figure, the straight lines AB and CD intersect at point O, OD bisects ∠AOE, ∠BOC = 50.0, then ∠EOB = ()\nQwen2.5-VL-32BProblem Analysis#We are given the following information:Straight lines AB AB AB and CD CD CD intersect at point O O O.OD OD OD bisects ∠AOE \\angle AOE ∠AOE.∠BOC=50∘ \\angle BOC = 50^\\circ ∠BOC=50∘.We need to find ∠EOB \\angle EOB ∠EOB.Step-by-Step Solution#Step 1: Understand the given information and relationships#Since AB AB AB and CD CD CD are straight lines intersecting at O O O, the angles around point O O O sum up to 360∘ 360^\\circ 360∘.The vertically opposite angles are equal. Therefore:\n∠AOD=∠BOCand∠DOB=∠COA.\n\\angle AOD = \\angle BOC \\quad \\text{and} \\quad \\angle DOB = \\angle COA.\n∠AOD=∠BOCand∠DOB=∠COA.\nGiven ∠BOC=50∘ \\angle BOC = 50^\\circ ∠BOC=50∘, we have:\n∠AOD=50∘.\n\\angle AOD = 50^\\circ.\n∠AOD=50∘.Step 2: Use the angle bisector property#It is given that OD OD OD bisects ∠AOE \\angle AOE ∠AOE. This means:\n∠AOD=∠DOE.\n\\angle AOD = \\angle DOE.\n∠AOD=∠DOE.\nSince ∠AOD=50∘ \\angle AOD = 50^\\circ ∠AOD=50∘, we have:\n∠DOE=50∘.\n\\angle DOE = 50^\\circ.\n∠DOE=50∘.Step 3: Determine ∠AOE \\angle AOE ∠AOE#The angle ∠AOE \\angle AOE ∠AOE is the sum of ∠AOD \\angle AOD ∠AOD and ∠DOE \\angle DOE ∠DOE:\n∠AOE=∠AOD+∠DOE=50∘+50∘=100∘.\n\\angle AOE = \\angle AOD + \\angle DOE = 50^\\circ + 50^\\circ = 100^\\circ.\n∠AOE=∠AOD+∠DOE=50∘+50∘=100∘.Step 4: Use the straight line property#Since AB AB AB is a straight line, the angles on a straight line sum up to 180∘ 180^\\circ 180∘. Therefore:\n∠AOE+∠EOB=180∘.\n\\angle AOE + \\angle EOB = 180^\\circ.\n∠AOE+∠EOB=180∘.\nSubstituting ∠AOE=100∘ \\angle AOE = 100^\\circ ∠AOE=100∘, we get:\n100∘+∠EOB=180∘.\n100^\\circ + \\angle EOB = 180^\\circ.\n100∘+∠EOB=180∘.\nSolving for ∠EOB \\angle EOB ∠EOB:\n∠EOB=180∘−100∘=80∘.\n\\angle EOB = 180^\\circ - 100^\\circ = 80^\\circ.\n∠EOB=180∘−100∘=80∘.Final Answer#80\n\\boxed{80}\n80Mathematical Reasoning (3/5)\nNextUser侏罗纪蜘蛛网是一种非常有规律的蜘蛛网，如图，它是由无数个正方形环绕而成的，且最外边第一个正方形A_{1}B_{1}C_{1}D_{1}的面积为a_{1}=1，分别取正方形A_{1}B_{1}C_{1}D_{1}各边的三等分点A_{2}，B_{2}，C_{2}，D_{2}，作第二个正方形A_{2}B_{2}C_{2}D_{2}，且正方形A_{2}B_{2}C_{2}D_{2}的面积为a_{2}，\\ldots \\ldots ，依次类推，第n个正方形A_{n}B_{n}C_{n}D_{n}的面积为a_{n}. $求{a_{n}}的通项公式\nQwen2.5-VL-32B问题分析#我们需要找到第 n n n 个正方形的面积 an a_n an 的通项公式。已知：第一个正方形 A1B1C1D1 A_1B_1C_1D_1 A1B1C1D1 的面积为 a1=1 a_1 = 1 a1=1。每次取前一个正方形各边的三等分点，构造一个新的正方形。我们需要确定每次构造新正方形时，其面积与前一个正方形面积之间的关系。第一步：设第一个正方形的边长#设第一个正方形 A1B1C1D1 A_1B_1C_1D_1 A1B1C1D1 的边长为 s1 s_1 s1。由于其面积为 a1=1 a_1 = 1 a1=1，因此：\ns1=a1=1=1.\ns_1 = \\sqrt{a_1} = \\sqrt{1} = 1.\ns1=a1=1=1.第二步：构造第二个正方形#取 A1B1C1D1 A_1B_1C_1D_1 A1B1C1D1 各边的三等分点，得到新的正方形 A2B2C2D2 A_2B_2C_2D_2 A2B2C2D2。我们需要计算这个新正方形的边长。1. 确定新正方形的顶点坐标#假设第一个正方形 A1B1C1D1 A_1B_1C_1D_1 A1B1C1D1 的顶点坐标如下：A1=(0,1) A_1 = (0, 1) A1=(0,1),B1=(1,1) B_1 = (1, 1) B1=(1,1),C1=(1,0) C_1 = (1, 0) C1=(1,0),D1=(0,0) D_1 = (0, 0) D1=(0,0).取各边的三等分点：A2 A_2 A2 是 A1B1 A_1B_1 A1B1 的三等分点，坐标为 (13,1) \\left( \\frac{1}{3}, 1 \\right) (31,1),B2 B_2 B2 是 B1C1 B_1C_1 B1C1 的三等分点，坐标为 (1,23) \\left( 1, \\frac{2}{3} \\right) (1,32),C2 C_2 C2 是 C1D1 C_1D_1 C1D1 的三等分点，坐标为 (23,0) \\left( \\frac{2}{3}, 0 \\right) (32,0),D2 D_2 D2 是 D1A1 D_1A_1 D1A1 的三等分点，坐标为 (0,13) \\left( 0, \\frac{1}{3} \\right) (0,31).2. 计算新正方形的边长#新正方形 A2B2C2D2 A_2B_2C_2D_2 A2B2C2D2 的边长可以通过计算任意两点之间的距离得到。例如，计算 A2 A_2 A2 和 B2 B_2 B2 之间的距离：\nA2=(13,1),B2=(1,23).\nA_2 = \\left( \\frac{1}{3}, 1 \\right), \\quad B_2 = \\left( 1, \\frac{2}{3} \\right).\nA2=(31,1),B2=(1,32).\n两点间的距离公式为：\ns2=(x2−x1)2+(y2−y1)2.\ns_2 = \\sqrt{\\left( x_2 - x_1 \\right)^2 + \\left( y_2 - y_1 \\right)^2}.\ns2=(x2−x1)2+(y2−y1)2.\n代入坐标：\ns2=(1−13)2+(23−1)2=(23)2+(−13)2=49+19=59=53.\ns_2 = \\sqrt{\\left( 1 - \\frac{1}{3} \\right)^2 + \\left( \\frac{2}{3} - 1 \\right)^2} = \\sqrt{\\left( \\frac{2}{3} \\right)^2 + \\left( -\\frac{1}{3} \\right)^2} = \\sqrt{\\frac{4}{9} + \\frac{1}{9}} = \\sqrt{\\frac{5}{9}} = \\frac{\\sqrt{5}}{3}.\ns2=(1−31)2+(32−1)2=(32)2+(−31)2=94+91=95=35.3. 计算新正方形的面积#新正方形的面积 a2 a_2 a2 为：\na2=s22=(53)2=59.\na_2 = s_2^2 = \\left( \\frac{\\sqrt{5}}{3} \\right)^2 = \\frac{5}{9}.\na2=s22=(35)2=95.第三步：归纳规律#从上述计算可以看出：第一个正方形的边长为 s1=1 s_1 = 1 s1=1，面积为 a1=1 a_1 = 1 a1=1。第二个正方形的边长为 s2=53 s_2 = \\frac{\\sqrt{5}}{3} s2=35，面积为 a2=59 a_2 = \\frac{5}{9} a2=95。接下来，我们猜测每次构造新正方形时，边长和面积的变化规律。1. 边长变化规律#假设第 n n n 个正方形的边长为 sn s_n sn，则第 n+1 n+1 n+1 个正方形的边长 sn+1 s_{n+1} sn+1 可以通过相似三角形的性质得出。每次取三等分点构造的新正方形，其边长是前一个正方形边长的 53 \\frac{\\sqrt{5}}{3} 35 倍。因此：\nsn+1=53sn.\ns_{n+1} = \\frac{\\sqrt{5}}{3} s_n.\nsn+1=35sn.2. 面积变化规律#由于面积与边长的平方成正比，第 n+1 n+1 n+1 个正方形的面积 an+1 a_{n+1} an+1 为：\nan+1=sn+12=(53sn)2=(53)2an=59an.\na_{n+1} = s_{n+1}^2 = \\left( \\frac{\\sqrt{5}}{3} s_n \\right)^2 = \\left( \\frac{\\sqrt{5}}{3} \\right)^2 a_n = \\frac{5}{9} a_n.\nan+1=sn+12=(35sn)2=(35)2an=95an.这表明 {an} \\{a_n\\} {an} 是一个等比数列，首项为 a1=1 a_1 = 1 a1=1，公比为 59 \\frac{5}{9} 95。第四步：写出通项公式#等比数列的通项公式为：\nan=a1⋅qn−1,\na_n = a_1 \\cdot q^{n-1},\nan=a1⋅qn−1,\n其中 a1=1 a_1 = 1 a1=1，q=59 q = \\frac{5}{9} q=95。因此：\nan=1⋅(59)n−1=(59)n−1.\na_n = 1 \\cdot \\left( \\frac{5}{9} \\right)^{n-1} = \\left( \\frac{5}{9} \\right)^{n-1}.\nan=1⋅(95)n−1=(95)n−1.最终答案#(59)n−1\n\\boxed{\\left( \\frac{5}{9} \\right)^{n-1}}\n(95)n−1Mathematical Reasoning (4/5)\nNextUser如图，椭圆M:\\frac{y^2}{a^2}+\\frac{x^2}{b^2}=1(a>b>0)的两顶点为A(－2,0)，B(2,0)，离心率e=\\frac{\\sqrt{3}}{2}，过y轴上的点F(0,t)(|t|<4,t\neq 0)的直线l与椭圆交于C，D两点，并与x轴交于点P，直线AC与直线BD交于点Q. $当点P异于A，B两点时，设点P与点Q的横坐标分别为x_{P}，x_{Q}，存在常数\\lambda 使x_{P}\\cdot x_{Q}=\\lambda 成立，请求出\\lambda 的值.\nQwen2.5-VL题目分析#我们有一个椭圆 M:y2a2+x2b2=1 M: \\frac{y^2}{a^2} + \\frac{x^2}{b^2} = 1 M:a2y2+b2x2=1，其中 a>b>0 a > b > 0 a>b>0。已知椭圆的两顶点为 A(−2,0) A(-2, 0) A(−2,0) 和 B(2,0) B(2, 0) B(2,0)，离心率为 e=32 e = \\frac{\\sqrt{3}}{2} e=23。我们需要找到常数 λ \\lambda λ，使得点 P P P（直线 l l l 与 x x x-轴的交点）和点 Q Q Q（直线 AC AC AC 与直线 BD BD BD 的交点）的横坐标 xP x_P xP 和 xQ x_Q xQ 满足 xP⋅xQ=λ x_P \\cdot x_Q = \\lambda xP⋅xQ=λ。第一步：确定椭圆的参数#顶点信息：椭圆的顶点为 A(−2,0) A(-2, 0) A(−2,0) 和 B(2,0) B(2, 0) B(2,0)，说明椭圆的长轴在 x x x-轴上，且半长轴长度为 b=2 b = 2 b=2。因此，b=2 b = 2 b=2。离心率信息：离心率 e=32 e = \\frac{\\sqrt{3}}{2} e=23。离心率的公式为 e=ca e = \\frac{c}{a} e=ac，其中 c=a2−b2 c = \\sqrt{a^2 - b^2} c=a2−b2。代入 e=32 e = \\frac{\\sqrt{3}}{2} e=23，得到：\nca=32  ⟹  c=32a.\n\\frac{c}{a} = \\frac{\\sqrt{3}}{2} \\implies c = \\frac{\\sqrt{3}}{2} a.\nac=23⟹c=23a.又因为 c=a2−b2 c = \\sqrt{a^2 - b^2} c=a2−b2，代入 b=2 b = 2 b=2，得到：\na2−4=32a.\n\\sqrt{a^2 - 4} = \\frac{\\sqrt{3}}{2} a.\na2−4=23a.平方两边：\na2−4=34a2  ⟹  14a2=4  ⟹  a2=16  ⟹  a=4.\na^2 - 4 = \\frac{3}{4} a^2 \\implies \\frac{1}{4} a^2 = 4 \\implies a^2 = 16 \\implies a = 4.\na2−4=43a2⟹41a2=4⟹a2=16⟹a=4.因此，椭圆的方程为：\ny216+x24=1.\n\\frac{y^2}{16} + \\frac{x^2}{4} = 1.\n16y2+4x2=1.第二步：直线 l l l 的方程#直线 l l l 过点 F(0,t) F(0, t) F(0,t)，设其斜率为 k k k，则直线 l l l 的方程为：\ny=kx+t.\ny = kx + t.\ny=kx+t.第三步：直线 l l l 与椭圆的交点#将直线方程 y=kx+t y = kx + t y=kx+t 代入椭圆方程 y216+x24=1 \\frac{y^2}{16} + \\frac{x^2}{4} = 1 16y2+4x2=1，得到：\n(kx+t)216+x24=1.\n\\frac{(kx + t)^2}{16} + \\frac{x^2}{4} = 1.\n16(kx+t)2+4x2=1.\n整理得：\n(kx+t)2+4x2=16  ⟹  k2x2+2ktx+t2+4x2=16  ⟹  (k2+4)x2+2ktx+t2−16=0.\n(kx + t)^2 + 4x^2 = 16 \\implies k^2x^2 + 2ktx + t^2 + 4x^2 = 16 \\implies (k^2 + 4)x^2 + 2ktx + t^2 - 16 = 0.\n(kx+t)2+4x2=16⟹k2x2+2ktx+t2+4x2=16⟹(k2+4)x2+2ktx+t2−16=0.\n这是关于 x x x 的二次方程，设其两根为 x1 x_1 x1 和 x2 x_2 x2，则交点 C(x1,y1) C(x_1, y_1) C(x1,y1) 和 D(x2,y2) D(x_2, y_2) D(x2,y2) 的横坐标分别为 x1 x_1 x1 和 x2 x_2 x2。由韦达定理，有：\nx1+x2=−2ktk2+4,x1x2=t2−16k2+4.\nx_1 + x_2 = -\\frac{2kt}{k^2 + 4}, \\quad x_1 x_2 = \\frac{t^2 - 16}{k^2 + 4}.\nx1+x2=−k2+42kt,x1x2=k2+4t2−16.第四步：点 P P P 的横坐标#直线 l l l 与 x x x-轴的交点 P P P 的纵坐标为 0，代入直线方程 y=kx+t y = kx + t y=kx+t，得到：\n0=kxP+t  ⟹  xP=−tk.\n0 = kx_P + t \\implies x_P = -\\frac{t}{k}.\n0=kxP+t⟹xP=−kt.第五步：直线 AC AC AC 和 BD BD BD 的方程#直线 AC AC AC 的方程：点 A(−2,0) A(-2, 0) A(−2,0) 和点 C(x1,y1) C(x_1, y_1) C(x1,y1)，直线 AC AC AC 的斜率为：\ny1−0x1+2=y1x1+2.\n\\frac{y_1 - 0}{x_1 + 2} = \\frac{y_1}{x_1 + 2}.\nx1+2y1−0=x1+2y1.因此，直线 AC AC AC 的方程为：\ny=y1x1+2(x+2).\ny = \\frac{y_1}{x_1 + 2}(x + 2).\ny=x1+2y1(x+2).直线 BD BD BD 的方程：点 B(2,0) B(2, 0) B(2,0) 和点 D(x2,y2) D(x_2, y_2) D(x2,y2)，直线 BD BD BD 的斜率为：\ny2−0x2−2=y2x2−2.\n\\frac{y_2 - 0}{x_2 - 2} = \\frac{y_2}{x_2 - 2}.\nx2−2y2−0=x2−2y2.因此，直线 BD BD BD 的方程为：\ny=y2x2−2(x−2).\ny = \\frac{y_2}{x_2 - 2}(x - 2).\ny=x2−2y2(x−2).第六步：点 Q Q Q 的横坐标#点 Q Q Q 是直线 AC AC AC 和直线 BD BD BD 的交点，联立方程：\ny1x1+2(x+2)=y2x2−2(x−2).\n\\frac{y_1}{x_1 + 2}(x + 2) = \\frac{y_2}{x_2 - 2}(x - 2).\nx1+2y1(x+2)=x2−2y2(x−2).\n将 y1=kx1+t y_1 = kx_1 + t y1=kx1+t 和 y2=kx2+t y_2 = kx_2 + t y2=kx2+t 代入，得到：\nkx1+tx1+2(x+2)=kx2+tx2−2(x−2).\n\\frac{kx_1 + t}{x_1 + 2}(x + 2) = \\frac{kx_2 + t}{x_2 - 2}(x - 2).\nx1+2kx1+t(x+2)=x2−2kx2+t(x−2).\n交叉相乘得：\n(kx1+t)(x2−2)(x+2)=(kx2+t)(x1+2)(x−2).\n(kx_1 + t)(x_2 - 2)(x + 2) = (kx_2 + t)(x_1 + 2)(x - 2).\n(kx1+t)(x2−2)(x+2)=(kx2+t)(x1+2)(x−2).\n展开并整理，可以解出 xQ x_Q xQ。经过复杂但标准的代数运算，可以得到：\nxQ=4⋅x1x2−2(x1+x2)x1+x2−4.\nx_Q = 4 \\cdot \\frac{x_1 x_2 - 2(x_1 + x_2)}{x_1 + x_2 - 4}.\nxQ=4⋅x1+x2−4x1x2−2(x1+x2).\n将韦达定理的结果 x1+x2=−2ktk2+4 x_1 + x_2 = -\\frac{2kt}{k^2 + 4} x1+x2=−k2+42kt 和 x1x2=t2−16k2+4 x_1 x_2 = \\frac{t^2 - 16}{k^2 + 4} x1x2=k2+4t2−16 代入，化简后得到：\nxQ=−4tk.\nx_Q = -\\frac{4t}{k}.\nxQ=−k4t.第七步：计算 xP⋅xQ x_P \\cdot x_Q xP⋅xQ#点 P P P 的横坐标为 xP=−tk x_P = -\\frac{t}{k} xP=−kt，点 Q Q Q 的横坐标为 xQ=−4tk x_Q = -\\frac{4t}{k} xQ=−k4t。因此：\nxP⋅xQ=(−tk)(−4tk)=4t2k2.\nx_P \\cdot x_Q = \\left(-\\frac{t}{k}\\right) \\left(-\\frac{4t}{k}\\right) = \\frac{4t^2}{k^2}.\nxP⋅xQ=(−kt)(−k4t)=k24t2.\n注意到 k k k 和 t t t 的具体值不影响最终的乘积形式，且根据对称性和几何性质，可以确定 xP⋅xQ x_P \\cdot x_Q xP⋅xQ 为一个常数。通过进一步分析或直接利用椭圆的几何性质，可以得出：\nxP⋅xQ=4.\nx_P \\cdot x_Q = 4.\nxP⋅xQ=4.最终答案#4\n\\boxed{4}\n4Fine-grained Image Understanding (5/5)\nNextUser这是什么Qwen2.5-VL-32B这张图片展示的是一道中式火锅，具体来说是四川麻辣火锅。以下是一些关键特征：锅底：锅中装满了红色的辣椒和花椒，这是四川麻辣火锅的典型特征，通常会使用大量的干辣椒、花椒和其他香料来制作辣味浓郁的汤底。分隔设计：锅被分成多个小格，每个格子可以用来煮不同的食材，这样可以避免不同食材的味道相互影响，同时也能满足多人对不同口味的需求。周围配菜：可以看到一些切好的肉类（如牛肉片）、蔬菜和其他食材，这些都是火锅常见的涮菜。氛围感：整体画面呈现出一种热气腾腾、色彩鲜艳的感觉，符合火锅的热闹和美味的氛围。火锅简介：#四川麻辣火锅是中国火锅的一种，起源于四川省，以其独特的麻辣风味闻名。主要特点包括：使用大量辣椒和花椒，味道辛辣且麻。汤底通常由牛油或清油制成，加入各种香料熬制。配菜丰富多样，包括肉类、海鲜、蔬菜等，适合多人一起享用。这种火锅不仅是一种美食，也是一种社交方式，非常适合家庭聚会或朋友聚餐。User图中为什么是四川火锅Qwen2.5-VL-32B从图片中可以看出，这是一道典型的四川火锅，主要依据以下几个特征：1. 锅底的麻辣风格#图中的锅底颜色鲜艳，呈现出明显的红色，这是四川火锅的典型特征。四川火锅以“麻辣”著称，通常会使用大量的干辣椒、花椒等调料来制作辣味浓郁的汤底。红色的辣椒和花椒是四川火锅的灵魂，它们不仅赋予了火锅独特的风味，还体现了四川人对“麻”和“辣”的热爱。2. 分隔设计#锅被分成了多个小格，这种设计在四川火锅中非常常见。每个格子可以用来煮不同的食材，避免不同食材的味道相互影响，同时也能满足多人对不同口味的需求。这种设计也符合四川火锅的多样性和灵活性，适合多人一起享用。3. 配菜种类#周围可以看到一些切好的肉类（如牛肉片）和其他食材，这些都是四川火锅常见的涮菜。四川火锅的配菜种类丰富，包括肉类、海鲜、蔬菜等，能够满足不同人的口味需求。4. 氛围感#整体画面呈现出一种热气腾腾、色彩鲜艳的感觉，充满了火锅的热闹和美味氛围。四川火锅以其麻辣鲜香的特点，深受人们喜爱，尤其是在寒冷的季节或聚会时，更是不可或缺的美食。5. 地域文化#四川火锅是中国火锅的一种，起源于四川省，以其独特的麻辣风味闻名。四川人对辣椒和花椒有着深厚的情感，这也体现在他们的饮食文化中。四川火锅正是这种文化的体现。总结：#图中的锅底颜色鲜艳、麻辣十足，锅的设计分隔明确，周围配菜丰富多样，这些都与四川火锅的典型特征高度吻合。因此，可以确定这是一道四川火锅。Next Step#While Qwen2.5-VL-32B has focused on optimizing subjective experience and mathematical reasoning through reinforcement learning—operating within the paradigm of “fast thinking”. Our next research direction will prioritize long and effective reasoning processes to push the boundaries of visual models in tackling highly complex, multi-step visual reasoning tasks.Citation#If you find our model helpful, feel free to cite it:@article{Qwen2.5-VL,\n  title={Qwen2.5-VL Technical Report},\n  author={Bai, Shuai and Chen, Keqin and Liu, Xuejing and Wang, Jialin and Ge, Wenbin and Song, Sibo and Dang, Kai and Wang, Peng and Wang, Shijie and Tang, Jun and Zhong, Humen and Zhu, Yuanzhi and Yang, Mingkun and Li, Zhaohai and Wan, Jianqiang and Wang, Pengfei and Ding, Wei and Fu, Zheren and Xu, Yiheng and Ye, Jiabo and Zhang, Xi and Xie, Tianbao and Cheng, Zesen and Zhang, Hang and Yang, Zhibo and Xu, Haiyang and Lin, Junyang},\n  journal={arXiv preprint arXiv:2502.13923},\n  year={2025}\n}",
    "summary": {
      "en": "The Qwen2.5-VL series of models was launched in January and received positive feedback. The latest model, Qwen2.5-VL-32B-Instruct, has 32 billion parameters and is open-sourced under the Apache 2.0 license. Key improvements include:\n\n1. **Human-like Responses**: Produces more detailed and well-formatted answers.\n2. **Mathematical Reasoning**: Enhanced accuracy in solving complex math problems.\n3. **Image Understanding**: Better analysis and recognition in visual tasks.\n\nBenchmark tests show that Qwen2.5-VL-32B-Instruct outperforms similar models in various tasks, including multimodal reasoning and user experience evaluations.\n\nThe model excels in both visual and text tasks, showcasing significant improvements in performance.\n\nAdditionally, the model can analyze complex questions, such as travel time calculations and geometric reasoning, providing clear, step-by-step solutions.\n\nNext, the focus will shift towards enhancing long-term reasoning capabilities for more complex visual reasoning challenges.",
      "ko": "Qwen2.5-VL 시리즈 모델이 1월에 출시되어 긍정적인 반응을 얻었습니다. 최신 모델인 Qwen2.5-VL-32B-Instruct는 320억 개의 매개변수를 가지고 있으며, Apache 2.0 라이선스 하에 오픈 소스로 제공됩니다. 주요 개선 사항은 다음과 같습니다.\n\n첫째, 사람처럼 자연스러운 응답을 생성하여 더 자세하고 잘 정리된 답변을 제공합니다. 둘째, 수학적 추론 능력이 향상되어 복잡한 수학 문제를 해결하는 데 더 높은 정확도를 보입니다. 셋째, 이미지 이해 능력이 개선되어 시각적 작업에서 더 나은 분석과 인식을 할 수 있습니다.\n\n벤치마크 테스트 결과, Qwen2.5-VL-32B-Instruct는 다양한 작업에서 유사한 모델보다 우수한 성능을 보였으며, 다중 모드 추론과 사용자 경험 평가에서도 뛰어난 결과를 나타냈습니다.\n\n이 모델은 시각적 작업과 텍스트 작업 모두에서 뛰어난 성능을 발휘하며, 성능 개선이 두드러집니다. 또한, 복잡한 질문을 분석할 수 있어 여행 시간 계산이나 기하학적 추론과 같은 문제에 대해 명확하고 단계별로 해결책을 제시합니다.\n\n앞으로는 더 복잡한 시각적 추론 과제를 위한 장기적인 추론 능력 향상에 집중할 예정입니다.",
      "ja": "Qwen2.5-VLシリーズのモデルは1月に発表され、好評を得ています。最新モデルのQwen2.5-VL-32B-Instructは、320億のパラメータを持ち、Apache 2.0ライセンスのもとでオープンソースとして提供されています。主な改善点は以下の通りです。\n\nまず、人間のような応答が可能になり、より詳細で整った回答を生成します。次に、数学的推論の精度が向上し、複雑な数学問題の解決がより正確になりました。また、画像理解においても、視覚的なタスクの分析と認識が向上しています。\n\nベンチマークテストの結果、Qwen2.5-VL-32B-Instructは、マルチモーダル推論やユーザー体験評価を含むさまざまなタスクで、類似モデルを上回る性能を示しています。このモデルは視覚的なタスクとテキストタスクの両方で優れた成果を上げており、パフォーマンスの大幅な向上が見られます。\n\nさらに、このモデルは旅行時間の計算や幾何学的推論などの複雑な質問を分析し、明確で段階的な解決策を提供することができます。今後は、より複雑な視覚的推論の課題に対する長期的な推論能力の向上に焦点を当てていく予定です。"
    }
  },
  {
    "id": "a539958897f1f1fa",
    "title": {
      "en": "Supreme Court upholds Biden regulations on 'ghost gun' kits",
      "ko": "대법원, 바이든 '유령 총' 규제 유지",
      "ja": "バイデンの「ゴーストガン」規制維持"
    },
    "type": "story",
    "url": "https://www.nbcnews.com/politics/supreme-court/supreme-court-upholds-biden-regulations-ghost-gun-kits-rcna180991",
    "score": 9,
    "by": "ceejayoz",
    "time": 1742998563,
    "content": "Guns in AmericaSupreme Court upholds Biden regulations on 'ghost gun' kitsThe decision means that the federal government can regulate the easily obtainable gun parts in the same way as firearms purchased from specialist stores.[id=\"jwplayer-0\"].jw-error{background:#000;overflow:hidden;position:relative}[id=\"jwplayer-0\"] .jw-error-msg{top:50%;left:50%;position:absolute;transform:translate(-50%,-50%)}[id=\"jwplayer-0\"] .jw-error-text{text-align:start;color:#FFF;font:14px/1.35 Arial,Helvetica,sans-serif}This video file cannot be played.(ErrorCode:102630)Supreme Court upholds ghost gun restrictions02:21Get more newsLiveonMarch 26, 2025, 11:13 PM GMT+9/UpdatedMarch 26, 2025, 11:26 PM GMT+9By Lawrence HurleyWASHINGTON — The Supreme Court on Wednesday upheld a Biden administration effort to regulate “ghost gun” kits that allow people to easily obtain parts needed to assemble firearms from online sellers.The decision by a court that often backs gun rights resolves the legal dispute over whether the kits can be regulated the same way as other firearms. mps._execAd(\"boxinline\");The ruling was 7-2, with Justice Neil Gorsuch writing the majority opinion saying that the kits can be regulated under the federal Gun Control Act, saying the court had \"no trouble rejecting\" the arguments made by challengers.Issued by the federal Bureau of Alcohol, Tobacco, Firearms and Explosives (ATF), the regulation includes ghost guns within the definition of “firearm” as described in the long-standing federal law that regulates guns.The law \"embraces and thus permits ATF to regulate some weapon parts kits,\" Gorsuch wrote.He indicated that the ruling is limited, meaning that some products that require \"sufficient time, tools and expertise\" to create a gun would not necessarily be covered.mps._execAd(\"boxinline\",0,1,false);The court's three liberals joined four conservatives in the majority. Conservative Justices Clarence Thomas and Samuel Alito dissented.In backing the regulation, the court \"blesses the government's overreach based on a series of errors,\" Thomas wrote.The regulation has been in effect since August 2022 as litigation has made its way through the court system, with the Supreme Court in August 2023 refusing to put it on hold. Manufacturers and sellers have to obtain licenses, mark products with serial numbers, require background checks and maintain records.The Trump administration could seek to rescind the rule.RecommendedImmigrationImmigrationTrump's move to end an immigration program hits a powerful Republican base of votersCongressCongressTop Republicans say they're out of the loop as DOGE downsizes Social Security AdministrationThe Gun Control Act says the regulations apply to “any weapon ... which will or is designed to or may be readily be converted to expel a projectile by the action of an explosive.” It also covers the “frame or receiver of any such weapon.” The frame or receiver is the part of a firearm that houses other components, including the firing mechanism.The legal challenge was brought by Jennifer VanDerStok and Michael Andren, who own components they want to use to build guns. The plaintiffs also include gun rights groups and the makers and sellers of ghost guns.mps._execAd(\"boxinline\",0,2,false);Texas-based U.S. District Judge Reed O’Connor ruled in favor of the plaintiffs in 2023, with the New Orleans-based 5th U.S. Circuit Court of Appeals mostly upholding his ruling.The challengers argued that the ATF did not have the authority to unilaterally apply the Gun Control Act to the kits.Although the case concerns gun regulation, it did not involve legal questions relating to the right to bear arms under the Constitution’s Second Amendment.The court has regularly backed gun rights in other cases, including a recent ruling striking down a federal ban on accessories called bump stocks that allow semiautomatic rifles to fire more rapidly.The court has also expanded the individual right to bear arms, including in a major 2022 ruling, although in a more recent ruling it backtracked somewhat in upholding a federal law that bars people subject to domestic violence restraining orders from possessing firearms.Lawrence HurleyLawrence Hurley is a senior Supreme Court reporter for NBC News.",
    "summary": {
      "en": "The Supreme Court recently upheld regulations from the Biden administration on \"ghost gun\" kits, which are parts that can be easily assembled into firearms. This ruling allows the federal government to treat these kits like regular firearms under the Gun Control Act. The decision was made with a 7-2 vote, and Justice Neil Gorsuch wrote the majority opinion, stating that the regulation is valid and that the court dismissed the challengers' arguments. \n\nThe regulation requires manufacturers and sellers of ghost guns to obtain licenses, mark their products with serial numbers, conduct background checks, and keep records. The ruling does not apply to all gun parts, particularly those requiring significant time and expertise to assemble. \n\nSome conservative justices dissented, arguing that the government was overstepping its authority. The regulation has been in effect since August 2022, and legal challenges have been ongoing. This case did not directly address the Second Amendment right to bear arms, though the court has generally supported gun rights in other cases.",
      "ko": "대법원은 최근 바이든 행정부의 '유령 총기' 키트에 대한 규제를 지지하는 판결을 내렸습니다. 유령 총기 키트는 쉽게 조립하여 총기로 만들 수 있는 부품들입니다. 이번 판결로 연방 정부는 이러한 키트를 총기 규제법에 따라 일반 총기처럼 취급할 수 있게 되었습니다. 이 결정은 7대 2의 표결로 이루어졌으며, 닐 고서치 대법관이 다수 의견을 작성했습니다. 그는 이 규제가 유효하다고 밝히며, 반대 의견을 제기한 측의 주장을 기각했습니다.\n\n이 규제는 유령 총기를 제조하거나 판매하는 업체가 면허를 취득하고, 제품에 일련번호를 부여하며, 배경 조사를 실시하고 기록을 보관하도록 요구합니다. 그러나 이 판결은 모든 총기 부품에 적용되는 것은 아니며, 조립에 상당한 시간과 전문성이 필요한 부품들은 제외됩니다.\n\n일부 보수 성향의 대법관들은 정부가 권한을 초과하고 있다고 반대 의견을 제시했습니다. 이 규제는 2022년 8월부터 시행되고 있으며, 법적 도전이 계속되고 있습니다. 이번 사건은 총기 소지의 권리를 보장하는 수정헌법 제2조에 직접적으로 다루지 않았지만, 대법원은 다른 사건들에서 총기 권리를 일반적으로 지지해왔습니다.",
      "ja": "最近、最高裁判所はバイデン政権による「ゴーストガン」キットに関する規制を支持しました。ゴーストガンキットとは、簡単に組み立てて銃にできる部品のことです。この判決により、連邦政府はこれらのキットを銃規制法の下で通常の銃と同様に扱うことができるようになります。判決は7対2の票で決まり、ニール・ゴーサッチ判事が多数意見を執筆し、規制は有効であり、反対意見の主張は却下されたと述べました。\n\nこの規制は、ゴーストガンの製造者や販売者に対して、ライセンスの取得、製品へのシリアルナンバーの表示、バックグラウンドチェックの実施、記録の保持を求めています。ただし、この判決はすべての銃の部品に適用されるわけではなく、特に組み立てに多くの時間や専門知識を必要とする部品には適用されません。\n\n一部の保守派の判事は反対意見を表明し、政府が権限を越えていると主張しました。この規制は2022年8月から施行されており、法的な挑戦が続いています。このケースでは、武器を持つ権利を保障する第二修正について直接的に扱われてはいませんが、裁判所は他のケースでは一般的に銃の権利を支持しています。"
    }
  },
  {
    "id": "53444c1c7df643ad",
    "title": {
      "en": "We chose LangGraph to build our coding agent",
      "ko": "코딩 에이전트, 랭그래프 선택!",
      "ja": "LangGraphでコーディングエージェント構築！"
    },
    "type": "story",
    "url": "https://www.qodo.ai/blog/why-we-chose-langgraph-to-build-our-coding-agent/",
    "score": 80,
    "by": "jimminyx",
    "time": 1742881836,
    "content": "Why we chose LangGraph to build our coding agent\n\n\t\t\t\t\t\t\t\tTechnology\n\n\t\t\t\t\t\t\t\tSagi Medina\n\n\t\t\t\t\t\t\t\t\tMarch 21, 2025\n\n\t\t\t\t\t\t\t\t\t4 min\n\n\t\t\t\t\t\tTable of ContentsFlexibility to be opinionatedCoherent interfaceReusable components across workflowsState managementAreas for growth\n\n\t\t\t Join Our Discord\n\n\t\t\t\t\tWe’ve been building AI coding assistants at Qodo since the GPT-3 days. Our initial approach was highly structured with predefined flows for different coding tasks like test generation, code reviews, and improvements. This approach worked well with earlier generations of LLMs and with structured flows we were able to get real-world value from older models, despite all of their limitations.\nSince Claude Sonnet 3.5 was released 9 months ago, LLMs have become significantly more capable at general-purpose coding tasks. The new models opened up the possibility to build something more dynamic and flexible while still maintaining our standards for code quality. We wanted to move away from rigid workflows to an agent that could adapt to any kind of user request, while still reflecting our opinionated views on how AI can be best used for coding.\nInitially, we needed a framework that would let us quickly validate our ideas and from the few options that were available about 4 months ago, we settled on LangGraph for our initial proof of concept. We were pleasantly surprised to see that the framework has proven flexible and mature enough to carry us all the way to production.\nIn this post, I’ll explain why LangGraph was the right choice for us, and how it enabled us to build a coding assistant that balances flexibility with our opinionated approach to coding best practices.\nFlexibility to be opinionated\nOur key consideration was the ability to create opinionated workflows while maintaining adaptability. LangGraph takes a graph-based approach that gives you flexibility to build agents that land anywhere on the spectrum from completely open-ended — where you just give an LLM all available tools and let it run in a loop — to fully structured deterministic flows (like the ones we started with).\nAt its core, LangGraph lets you define a state machine for your agent. You create nodes that represent discrete steps in your workflow and edges that define the possible transitions between them. Each node can perform specific functions—gathering context, planning, generating code, or validating—while the graph structure determines how these functions connect.\nThe density of connections in the graph corresponds to how structured or flexible your agent is. A sparse graph with few connections corresponds with a more rigid, predictable flow where each step leads to exactly one next step. A dense graph with many interconnections gives the agent more freedom to choose its path.\nFuture, more capable models might work best with fully open-ended approaches. But even with the best current LLMs, you still get better results when you guide them through the problem. If you use LLMs directly for coding, you’ve probably already developed your own workflow — like breaking problems down, providing context strategically, guiding the model through complex reasoning, and backtracking or iterating when needed.\nThe nice thing about LangGraph’s flexibility is that we can easily recalibrate how structured our flows are when new, more powerful models are released.\nOur main flow follows a pattern that you might recognize: first, a context collection node gathers relevant information from the codebase (and external resources via MCP integration); next, a planning node breaks down the task into manageable steps; then an execution node generates the actual code; finally, a validation node checks the output against best practices and requirements. When validation fails, the agent loops back to execution with specific feedback rather than starting from scratch.\n\nCoherent interface\nWhen you’re building a complex system, a framework should simplify rather than complicate your work. LangGraph’s API does exactly that.\nHere’s how a simplified version of our main workflow looks when implemented with LangGraph:\nPlain textCopy to clipboardOpen code in new windowEnlighterJS 3 Syntax Highlighterfrom langgraph.graph import StateGraph, ENDworkflow = StateGraph(name=\"coding_assistant\")workflow.add_node(\"context_collector\", collect_relevant_context)workflow.add_node(\"task_planner\", create_execution_plan)workflow.add_node(\"task_executor\", execute_plan)workflow.add_node(\"validator\", validate_output)# Define flow between nodesworkflow.add_edge(\"context_collector\", \"task_planner\")workflow.add_edge(\"task_planner\", \"task_executor\")workflow.add_edge(\"task_executor\", \"validator\")# Conditional routing based on validation resultsworkflow.add_conditional_edges(    \"validator\",    should_revise,    {        True: \"task_executor\",  # Loop back if revision needed        False: END               # Complete if validation passes    })graph = workflow.compile()graph.invoke({\"user_input\": \"build me a game like levelsio\"})from langgraph.graph import StateGraph, END\n\nworkflow = StateGraph(name=\"coding_assistant\")\nworkflow.add_node(\"context_collector\", collect_relevant_context)\nworkflow.add_node(\"task_planner\", create_execution_plan)\nworkflow.add_node(\"task_executor\", execute_plan)\nworkflow.add_node(\"validator\", validate_output)\n\n# Define flow between nodes\nworkflow.add_edge(\"context_collector\", \"task_planner\")\nworkflow.add_edge(\"task_planner\", \"task_executor\")\nworkflow.add_edge(\"task_executor\", \"validator\")\n\n# Conditional routing based on validation results\nworkflow.add_conditional_edges(\n    \"validator\",\n    should_revise,\n    {\n        True: \"task_executor\",  # Loop back if revision needed\n        False: END               # Complete if validation passes\n    }\n)\n\ngraph = workflow.compile()\ngraph.invoke({\"user_input\": \"build me a game like levelsio\"})from langgraph.graph import StateGraph, END\n\nworkflow = StateGraph(name=\"coding_assistant\")\nworkflow.add_node(\"context_collector\", collect_relevant_context)\nworkflow.add_node(\"task_planner\", create_execution_plan)\nworkflow.add_node(\"task_executor\", execute_plan)\nworkflow.add_node(\"validator\", validate_output)\n\n# Define flow between nodes\nworkflow.add_edge(\"context_collector\", \"task_planner\")\nworkflow.add_edge(\"task_planner\", \"task_executor\")\nworkflow.add_edge(\"task_executor\", \"validator\")\n\n# Conditional routing based on validation results\nworkflow.add_conditional_edges(\n    \"validator\",\n    should_revise,\n    {\n        True: \"task_executor\",  # Loop back if revision needed\n        False: END               # Complete if validation passes\n    }\n)\n\ngraph = workflow.compile()\ngraph.invoke({\"user_input\": \"build me a game like levelsio\"})\n\nThis declarative approach makes the code almost self-documenting. The workflow definition directly mirrors our conceptual diagram, which makes it easy to reason about and modify.\nEach node function receives the current state and returns updates to that state. There’s no magic happening behind the scenes, just straightforward state transitions.\nLangChain gets a lot of flack for its overly complicated abstraction, but the team really cooked with the LangGraph interface. It adds just enough structure without getting in your way or forcing you to adopt a complicated mental model and puts your agent logic on full display rather than obscuring it behind abstractions.\nReusable components across workflows\nReusability is what separates valuable frameworks from disposable ones. The node-based architecture that LangGraph uses is great here.\nOur context collection node is a good example. It handles gathering relevant information from the codebase and it’s used in pretty much every flow. The same goes for our validation node, which checks code quality and runs tests. These components can slot into different graphs with minimal configuration.\nAs we build out more flows, the velocity payout is huge. We’re building specialized flows like TDD that have different structures but reuse many of the same nodes, just connected in a different configuration with a few specialized components added in.\n\nState management\nThe most satisfying part of adopting the right framework is when you get useful functionality out of the box. LangGraph’s built-in state management is a perfect example.\nAdding persistence to our agent took just a few lines of code:\nPlain textCopy to clipboardOpen code in new windowEnlighterJS 3 Syntax Highlighterfrom langgraph.graph import StateGraph, ENDfrom langgraph.checkpoint.postgres import PostgresSaverworkflow = StateGraph(name=\"coding_assistant\")......checkpointer = PostgresSaver.from_conn_string(    \"postgresql://user:password@localhost:5432/db\")checkpointer.setup()graph = workflow.compile(checkpointer=checkpointer)from langgraph.graph import StateGraph, END\nfrom langgraph.checkpoint.postgres import PostgresSaver\n\nworkflow = StateGraph(name=\"coding_assistant\")\n...\n...\n\ncheckpointer = PostgresSaver.from_conn_string(\n    \"postgresql://user:password@localhost:5432/db\"\n)\ncheckpointer.setup()\n\ngraph = workflow.compile(checkpointer=checkpointer)from langgraph.graph import StateGraph, END\nfrom langgraph.checkpoint.postgres import PostgresSaver\n\nworkflow = StateGraph(name=\"coding_assistant\")\n...\n...\n\ncheckpointer = PostgresSaver.from_conn_string(\n    \"postgresql://user:password@localhost:5432/db\"\n)\ncheckpointer.setup()\n\ngraph = workflow.compile(checkpointer=checkpointer)\n\nThat’s it. With this simple addition, our entire workflow state—including context collected, plans made, and code generated—persists to our postgres database without us building any custom infrastructure. There are also SQLite and in memory checkpointers that can be added just as easily.\nWhat’s really neat is that this doesn’t just enable basic persistence across sessions. It supports checkpoints and branch points so you can undo and replay changes.\nAreas for growth\nWhile LangGraph has been a great foundation for our agentic flows, it’s not without challenges. One pain point has been documentation. The framework is developing very quickly and the docs are sometimes incomplete or out of date. The maintainers are great and were super responsive on Slack (thanks Harrison and Nuno for all the help :)). Be prepared to potentially need to communicate directly with the project maintainers if you’re using the newer and more niche capabilities.\nTesting and mocking is a huge challenge when developing LLM driven systems that aren’t deterministic. Even relatively simple flows are extremely hard to reproduce. Our agent interacts extensively with the IDE, which is difficult to simulate in automated tests. We built a mock repository that simulates basic IDE operations, but it doesn’t perfectly replicate the real environment. This creates a gap between what we can test automatically and what happens in production.\nFor example, operations like “find all usages of this function” that depend on the IDE’s language server are particularly hard to mock. This forced us to rely more on manual testing than we’d prefer, which slowed down the iteration cycle.\nMature frameworks tend to provide robust infrastructure for mocking and testing. I’m hopeful that LangGraph will develop in these areas over time.\n\n\t\t\t\t\t\t\t\tSagi Medina\n\n\t\t\t\t\t\t\t\t\tMarch 21, 2025\n\n\t\t\t\t\t\t\t\t\t4 min\n\n\t\t\t\t\t\tStart to test, review and generate high quality code\n\n\t\t\tGet Started\n\n\t\t\t\t\t\t\tGet Qodo\n\n\t\t\t\t\t\t\t\t\t\tVS Code\n\n\t\t\t\t\t\t\t\t\t\tJetBrains\n\n\t\t\t\t\t\t\t\t\t\tGithub, Qodo Merge\n\n\t\t\t\t\t\t\tSubscribe to the newsletter\n\n\t\t\t\t\t\t\t\thbspt.forms.create({\n\t\t\t\t\t\t\t\t\tregion: \"eu1\",\n\t\t\t\t\t\t\t\t\tportalId: \"26816375\",\n\t\t\t\t\t\t\t\t\tformId: \"6233f5ed-8ded-40a7-94cf-8fe3631b4b56\",\n\t\t\t\t\t\t\t\t\tonFormReady: function($form) {\n\t\t\t\t\t\t\t\t\t\tdocument.querySelector('.hs-input[type=\"email\"]').value = '';\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t});\n\n\t\t\t\t\t\t\tShare\n\nMore from our blog\n\n\t\t\t\t\t\t\t\t\tCode Reviews\n\n\t\t\t\t\t\t\t\t\tNews & Updates\n\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t4 min\n\n\t\t\t\tQodo Merge 1.0: solving key challenges in AI-assisted code reviews\n\n\t\t\t\t\t\t\t\tElana Krasner\n\n\t\t\t\t\t\t\t\tJan 29, 2025\n\n\t\t\t\tRead more\n\n\t\t\t\t\t\t\t\t\tLearn\n\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t14 min\n\n\t\t\t\tCommon JavaScript Errors Explained and How to Fix Them\n\n\t\t\t\t\t\t\t\tDavid Parry\n\n\t\t\t\t\t\t\t\tMar 24, 2025\n\n\t\t\t\tRead more\n\n\t\t\t\t\t\t\t\t\tTesting\n\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t10 min\n\n\t\t\t\t10 Best Automated Unit Testing Tools for Java\n\n\t\t\t\t\t\t\t\tMarin Levrel\n\n\t\t\t\t\t\t\t\tMar 24, 2025\n\n\t\t\t\tRead more\n\n\t\t\tBrowse the blog",
    "summary": {
      "en": "**Summary of Why Qodo Chose LangGraph for Their Coding Agent**\n\nQodo has been developing AI coding assistants since the advent of GPT-3. Initially, they relied on structured workflows for specific coding tasks, which worked well with older models. However, the release of more advanced language models, like Claude Sonnet 3.5, allowed for more flexible and dynamic approaches.\n\nTo build a coding assistant that balances flexibility with their coding standards, Qodo chose LangGraph. This framework allows for both opinionated workflows and adaptability. LangGraph uses a graph-based structure where each node represents a step in the coding process, enabling different levels of structure from rigid to highly flexible.\n\n**Key Points:**\n\n1. **Flexibility**: LangGraph allows users to create workflows that can adapt as new models improve, making it easier to guide AI in coding tasks.\n\n2. **Coherent Interface**: The API is designed to simplify complex systems, making the code easier to understand and modify.\n\n3. **Reusability**: Components within LangGraph can be reused across different workflows, speeding up development.\n\n4. **State Management**: LangGraph offers built-in state management, allowing easy persistence of workflow states without additional infrastructure.\n\n5. **Areas for Growth**: Despite its advantages, LangGraph has challenges, including incomplete documentation and difficulties with testing LLM-driven systems due to their non-deterministic nature.\n\nOverall, LangGraph has proven to be a robust framework for Qodo's needs, supporting the development of a responsive and effective coding assistant.",
      "ko": "Qodo는 GPT-3의 등장 이후 AI 코딩 도우미를 개발해왔습니다. 초기에는 특정 코딩 작업을 위한 구조화된 워크플로우에 의존했으며, 이는 이전 모델들과 잘 맞았습니다. 그러나 Claude Sonnet 3.5와 같은 더 발전된 언어 모델의 출시로 인해 더 유연하고 동적인 접근 방식이 가능해졌습니다.\n\nQodo는 유연성과 코딩 기준의 균형을 맞춘 코딩 도우미를 만들기 위해 LangGraph를 선택했습니다. 이 프레임워크는 의견이 반영된 워크플로우와 적응성을 모두 지원합니다. LangGraph는 그래프 기반 구조를 사용하여 각 노드가 코딩 과정의 단계를 나타내며, 이를 통해 경직된 구조부터 매우 유연한 구조까지 다양한 수준의 구조를 제공합니다.\n\nLangGraph의 주요 장점 중 하나는 유연성입니다. 사용자는 새로운 모델이 개선됨에 따라 적응할 수 있는 워크플로우를 만들 수 있어 AI의 코딩 작업을 보다 쉽게 안내할 수 있습니다. 또한, API는 복잡한 시스템을 단순화하도록 설계되어 코드 이해와 수정이 용이합니다. LangGraph 내의 구성 요소는 다양한 워크플로우에서 재사용할 수 있어 개발 속도를 높이는 데 기여합니다.\n\n상태 관리 기능도 내장되어 있어 추가 인프라 없이 워크플로우 상태를 쉽게 유지할 수 있습니다. 그러나 LangGraph는 불완전한 문서화와 비결정론적 특성으로 인해 LLM 기반 시스템 테스트에 어려움이 있는 등 몇 가지 도전 과제가 있습니다.\n\n전반적으로 LangGraph는 Qodo의 요구에 부합하는 강력한 프레임워크로, 반응적이고 효과적인 코딩 도우미 개발을 지원하고 있습니다.",
      "ja": "Qodoは、GPT-3の登場以来、AIコーディングアシスタントの開発を進めてきました。最初は、特定のコーディングタスクに対して構造化されたワークフローに依存しており、古いモデルではうまく機能していました。しかし、Claude Sonnet 3.5のようなより高度な言語モデルの登場により、より柔軟でダイナミックなアプローチが可能になりました。\n\nQodoは、柔軟性とコーディング基準のバランスを取るためにLangGraphを選びました。このフレームワークは、意見を反映したワークフローと適応性の両方を提供します。LangGraphはグラフベースの構造を使用しており、各ノードがコーディングプロセスのステップを表しています。これにより、厳格な構造から非常に柔軟なものまで、さまざまなレベルの構造を実現できます。\n\nLangGraphの主な利点の一つは柔軟性です。新しいモデルが改善されるにつれて、ワークフローを適応させることができ、AIにコーディングタスクを指導するのが容易になります。また、APIは複雑なシステムを簡素化するように設計されており、コードの理解や修正がしやすくなっています。さらに、LangGraph内のコンポーネントは異なるワークフローで再利用できるため、開発のスピードが向上します。\n\n状態管理もLangGraphの特徴です。内蔵の状態管理機能により、追加のインフラなしでワークフローの状態を簡単に保持できます。しかし、LangGraphには成長の余地もあります。例えば、ドキュメントが不完全であったり、非決定的な性質を持つLLM（大規模言語モデル）駆動のシステムのテストが難しいという課題があります。\n\n全体として、LangGraphはQodoのニーズに応える堅牢なフレームワークであり、反応性が高く効果的なコーディングアシスタントの開発を支援しています。"
    }
  },
  {
    "id": "9982c542ad87fc14",
    "title": {
      "en": "Gemini 2.5 Pro reasons about task feasibility",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://everything.intellectronica.net/p/negotiating-with-the-machine",
    "score": 123,
    "by": "intellectronica",
    "time": 1742977287,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "848a62ac00a608da",
    "title": {
      "en": "RISC Architecture Really Did Change Everything",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://www.wired.com/story/angelina-jolie-was-right-about-risc-architecture/",
    "score": 31,
    "by": "ecliptik",
    "time": 1742956034,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "0916eacf2b59aebb",
    "title": {
      "en": "Don't Buy into Apple's Hype About AirPods Max Gaining Lossless Audio",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://www.macrumors.com/2025/03/24/airpods-max-lossless-audio-overhyped/",
    "score": 29,
    "by": "ksec",
    "time": 1742902674,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "0894f185902b17cb",
    "title": {
      "en": "Project Operation Whitecoat (2010)",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://scholarworks.lib.csusb.edu/cgi/viewcontent.cgi?article=1201&context=history-in-the-making",
    "score": 105,
    "by": "smegger001",
    "time": 1742834107,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "5a6b64c7bd1b498a",
    "title": {
      "en": "Supply Chain Attacks on Linux Distributions – Fedora Pagure",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://fenrisk.com/pagure",
    "score": 209,
    "by": "akyuu",
    "time": 1742414317,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "858184ddd148d376",
    "title": {
      "en": "Nōdo – Call Node.js from Ruby",
      "ko": "루비로 노드 호출하기",
      "ja": "ノード呼び出し"
    },
    "type": "story",
    "url": "https://github.com/mtgrosser/nodo",
    "score": 5,
    "by": "namiwang",
    "time": 1742955369,
    "content": "Nōdo – call Node.js from Ruby\nNodo provides a Ruby environment to interact with JavaScript running inside a Node process.\nノード means \"node\" in Japanese.\nWhy Nodo?\nNodo will dispatch all JS function calls to a single long-running Node process.\nJavaScript code is run in a namespaced environment, where you can access your initialized\nJS objects during sequential function calls without having to re-initialize them.\nIPC is done via unix sockets, greatly improving performance over classic process/eval solutions.\nInstallation\nIn your Gemfile:\ngem 'nodo'\n\nNode.js\nNodo requires a working installation of Node.js.\nIf the executable is located in your PATH, no configuration is required. Otherwise, the path to to binary can be set using:\nNodo.binary = '/usr/local/bin/node'\n\nUsage\nIn Nodo, you define JS functions as you would define Ruby methods:\nclass Foo < Nodo::Core\n\n  function :say_hi, <<~JS\n    (name) => {\n      return `Hello ${name}!`;\n    }\n  JS\n\nend\n\nfoo = Foo.new\nfoo.say_hi('Nodo')\n=> \"Hello Nodo!\"\n\nJS code can also be supplied using the code: keyword argument:\nfunction :hello, code: \"() => 'world'\"\n\nAsync functions\nNodo supports calling async functions from Ruby.\nThe Ruby call will happen synchronously, i.e. it will block until the JS\nfunction resolves:\nclass SyncFoo < Nodo::Core\n  function :do_something, <<~JS\n    async () => { return await asyncFunc(); }\n  JS\nend\n\nUsing npm modules\nInstall your modules to node_modules:\n$ yarn add uuid\n\nrequireing your dependencies will make the library available as a const with the same name:\nclass Bar < Nodo::Core\n  require :uuid\n\n  function :v4, <<~JS\n    () => {\n      return uuid.v4();\n    }\n  JS\nend\n\nbar = Bar.new\nbar.v4 => \"b305f5c4-db9a-4504-b0c3-4e097a5ec8b9\"\n\nimport is also supported for loading ESM packages:\nclass Bar < Nodo::Core\n  import :uuid\n\n  function :v4, <<~JS\n    () => {\n      return uuid.v4();\n    }\n  JS\nend\n\nbar = Bar.new\nbar.v4 => \"b305f5c4-db9a-4504-b0c3-4e097a5ec8b9\"\n\nAliasing requires\nIf the library name cannot be used as name of the constant, the const name\ncan be given using hash syntax:\nclass FooBar < Nodo::Core\n  require commonjs: '@rollup/plugin-commonjs'\nend\n\nDynamic ESM imports\nES modules can be imported dynamically using nodo.import():\nclass DynamicFoo < Nodo::Core\n  function :v4, <<~JS\n    async () => {\n      const uuid = await nodo.import('uuid');\n      return await uuid.v4()\n    }\n  JS\nend\n\nNote that the availability of dynamic imports depends on your Node version.\nDefining JS constants\nclass BarFoo < Nodo::Core\n  const :HELLO, \"World\"\nend\n\nExecute some custom JS during initialization\nclass BarFoo < Nodo::Core\n\n  script <<~JS\n    // custom JS to be executed during initialization\n    // things defined here can later be used inside functions\n    const bigThing = someLib.init();\n  JS\nend\n\nWith the above syntax, the script code will be generated during class definition\ntime. In order to have the code generated when the first instance is created, the\ncode can be defined inside a block:\nclass Foo < Nodo::Core\n  script do\n    <<~JS\n      var definitionTime = #{Time.now.to_json};\n    JS\n  end\nend\n\nNote that the script will still be executed only once, when the first instance\nof class is created.\nInheritance\nSubclasses will inherit functions, constants, dependencies and scripts from\ntheir superclasses, while only functions can be overwritten.\nclass Foo < Nodo::Core\n  function :foo, \"() => 'superclass'\"\nend\n\nclass SubFoo < Foo\n  function :bar, \"() => { return 'calling' + foo() }\"\nend\n\nclass SubSubFoo < SubFoo\n  function :foo, \"() => 'subsubclass'\"\nend\n\nFoo.new.foo => \"superclass\"\nSubFoo.new.bar => \"callingsuperclass\"\nSubSubFoo.new.bar => \"callingsubsubclass\"\n\nDeferred function definition\nBy default, the function code string literal is created when the class\nis defined. Therefore any string interpolation inside the code will take\nplace at definition time.\nIn order to defer the code generation until the first object instantiation,\nthe function code can be given inside a block:\nclass Deferred < Nodo::Core\n  function :now, <<~JS\n    () => { return #{Time.now.to_json}; }\n  JS\n\n  function :later do\n    <<~JS\n      () => { return #{Time.now.to_json}; }\n    JS\n  end\nend\n\ninstance = Deferred.new\nsleep 5\ninstance.now => \"2021-10-28 20:30:00 +0200\"\ninstance.later => \"2021-10-28 20:30:05 +0200\"\n\nThe block will be invoked when the first instance is created. As with deferred\nscripts, it will only be invoked once.\nLimiting function execution time\nThe default timeout for a single JS function call is 60 seconds and can be\nset globally:\nNodo.timeout = 5\n\nIf the execution of a single function call exceeds the timeout, Nodo::TimeoutError\nis raised.\nThe timeout can also be set on a per-function basis:\nclass Foo < Nodo::Core\n  function :sleep, timeout: 1, code: <<~'JS'\n    async (sec) => await new Promise(resolve => setTimeout(resolve, sec * 1000))\n  JS\nend\n\nFoo.new.sleep(2)\n=>  Nodo::TimeoutError raised\n\nSetting NODE_PATH\nBy default, ./node_modules is used as the NODE_PATH.\nTo set a custom path:\nNodo.modules_root = 'path/to/node_modules'\n\nAlso see: Clean your Rails root\nLogging\nBy default, JS errors will be logged to STDOUT.\nTo set a custom logger:\nNodo.logger = Logger.new('nodo.log')\n\nIn Rails applications, Rails.logger will automatically be set.\nDebugging\nTo get verbose debug output, set\nNodo.debug = true\n\nbefore instantiating any worker instances. The debug mode will be active during\nthe current process run.\nTo print a debug message from JS code:\nnodo.debug(\"Debug message\");\n\nEvaluation\nWhile Nodo is mainly function-based, it is possible to evaluate JS code in the\ncontext of the defined object.\nfoo = Foo.new.evaluate(\"3 + 5\")\n=> 8\n\nEvaluated code can access functions, required dependencies and constants:\nclass Foo < Nodo::Core\n  const :BAR, 'bar'\n  require :uuid\n  function :hello, code: '() => \"world\"'\nend\n\nfoo = Foo.new\n\nfoo.evaluate('BAR')\n=> \"bar\"\n\nfoo.evaluate('uuid.v4()')\n=> \"f258bef3-0d6f-4566-ad39-d8dec973ef6b\"\n\nfoo.evaluate('hello()')\n=> \"world\"\n\nVariables defined by evaluation are local to the current instance:\none = Foo.new\none.evaluate('a = 1')\ntwo = Foo.new\ntwo.evaluate('a = 2')\none.evaluate('a') => 1\ntwo.evaluate('a') => 2\n\n⚠️ Evaluation comes with the usual caveats:\n\nAvoid modifying any of your predefined identifiers. Remember that in JS,\nas in Ruby, constants are not necessarily constant.\nNever evaluate any code which includes un-checked user data. The Node.js process\nhas full read/write access to your filesystem! 💥\n\nClean your Rails root\nFor Rails applications, Nodo enables you to move node_modules, package.json and\nyarn.lock into your application's vendor folder by setting the NODE_PATH in\nan initializer:\n# config/initializers/nodo.rb\nNodo.modules_root = Rails.root.join('vendor', 'node_modules')\n\nThe rationale for this is NPM modules being external vendor dependencies, which\nshould not clutter the application root directory.\nWith this new default, all yarn operations should be done after cding to vendor.\nThis repo provides an adapted version\nof the yarn:install rake task which will automatically take care of the vendored module location.\nWorking with web mocking frameworks like WebMock\nNodo uses HTTP via UNIX sockets to connect to its Node process. This may lead to\nconflicts during tests when using WebMock or other tools which interfere with\nNet::HTTP. In order to work with WebMock, you need to enable its allow_localhost\noption:\nWebMock.disable_net_connect!(allow_localhost: true)",
    "summary": {
      "en": "**Summary of Nodo - Calling Node.js from Ruby**\n\nNodo is a tool that allows Ruby applications to call JavaScript functions running in a Node.js environment. It uses a long-running Node process to handle function calls efficiently.\n\n### Key Features:\n- **Namespace Environment**: JavaScript code runs in a controlled space, allowing access to initialized objects without re-initializing them.\n- **Performance**: Communicates using Unix sockets, which is faster than traditional methods.\n- **Installation**: Add `gem 'nodo'` to your Gemfile and ensure Node.js is installed.\n\n### Usage:\n- Define JavaScript functions in Ruby classes, similar to Ruby methods.\n- Supports synchronous and asynchronous function calls.\n- You can use npm modules by requiring them in your Ruby classes.\n\n### Example:\n```ruby\nclass Foo < Nodo::Core\n  function :say_hi, <<~JS\n    (name) => {\n      return `Hello ${name}!`;\n    }\n  JS\nend\n\nfoo = Foo.new\nfoo.say_hi('Nodo')  # => \"Hello Nodo!\"\n```\n\n### Additional Features:\n- **Dynamic Imports**: Load ES modules dynamically.\n- **Deferred Execution**: Generate function code at the time of object instantiation.\n- **Timeouts**: Set global or per-function timeouts for JS calls.\n- **Logging and Debugging**: Customize logging and enable debug mode for detailed output.\n\n### Evaluation:\nYou can evaluate JavaScript code within the context of a Ruby instance, accessing its methods and constants. However, be cautious with user-generated data to avoid security risks.\n\n### Rails Integration:\nFor Rails applications, you can configure Nodo to manage Node modules in a vendor folder, keeping the application root clean.\n\n### Testing Compatibility:\nWhen using testing tools like WebMock, configure it to allow local connections to avoid conflicts.\n\nIn summary, Nodo provides a seamless way to integrate JavaScript into Ruby applications, enhancing functionality while maintaining performance and security.",
      "ko": "Nodo는 루비 애플리케이션이 Node.js 환경에서 실행되는 자바스크립트 함수를 호출할 수 있도록 해주는 도구입니다. 이 도구는 장시간 실행되는 Node 프로세스를 사용하여 함수 호출을 효율적으로 처리합니다.\n\n주요 기능으로는 네임스페이스 환경이 있습니다. 자바스크립트 코드는 제어된 공간에서 실행되며, 초기화된 객체에 재초기화 없이 접근할 수 있습니다. 성능 면에서도 유닉스 소켓을 사용하여 전통적인 방법보다 빠른 통신을 제공합니다. 설치는 Gemfile에 `gem 'nodo'`를 추가하고 Node.js가 설치되어 있는지 확인하면 됩니다.\n\n사용 방법은 루비 클래스 내에서 자바스크립트 함수를 정의하는 것으로, 이는 루비 메서드와 유사합니다. 동기 및 비동기 함수 호출을 지원하며, 루비 클래스에서 npm 모듈을 요구하여 사용할 수 있습니다.\n\n예를 들어, 다음과 같이 클래스를 정의할 수 있습니다. \n\n```ruby\nclass Foo < Nodo::Core\n  function :say_hi, <<~JS\n    (name) => {\n      return `Hello ${name}!`;\n    }\n  JS\nend\n\nfoo = Foo.new\nfoo.say_hi('Nodo')  # => \"Hello Nodo!\"\n```\n\n추가 기능으로는 동적 임포트가 있어 ES 모듈을 동적으로 로드할 수 있습니다. 지연 실행 기능을 통해 객체 인스턴스화 시점에 함수 코드를 생성할 수 있으며, JS 호출에 대한 전역 또는 함수별 타임아웃을 설정할 수 있습니다. 또한, 로깅 및 디버깅 기능을 통해 상세한 출력을 위한 로깅을 사용자 정의하고 디버그 모드를 활성화할 수 있습니다.\n\n루비 인스턴스 내에서 자바스크립트 코드를 평가할 수 있으며, 해당 인스턴스의 메서드와 상수에 접근할 수 있습니다. 그러나 사용자 생성 데이터에 대해서는 보안 위험을 피하기 위해 주의해야 합니다.\n\nRails 애플리케이션의 경우, Nodo를 구성하여 Node 모듈을 벤더 폴더에서 관리할 수 있어 애플리케이션 루트를 깔끔하게 유지할 수 있습니다.\n\n테스트 도구인 WebMock을 사용할 때는 로컬 연결을 허용하도록 구성하여 충돌을 피해야 합니다.\n\n결론적으로, Nodo는 루비 애플리케이션에 자바스크립트를 매끄럽게 통합할 수 있는 방법을 제공하여 기능을 향상시키면서 성능과 보안을 유지합니다.",
      "ja": "Nodoは、RubyアプリケーションがNode.js環境で実行されているJavaScript関数を呼び出すためのツールです。長時間実行されるNodeプロセスを利用して、関数呼び出しを効率的に処理します。\n\nNodoの主な特徴には、名前空間環境があります。これにより、JavaScriptコードは制御された空間で実行され、初期化されたオブジェクトに再初期化せずにアクセスできます。また、Unixソケットを使用して通信するため、従来の方法よりも高速です。インストールは、Gemfileに「gem 'nodo'」を追加し、Node.jsがインストールされていることを確認するだけです。\n\n使用方法としては、Rubyクラス内でJavaScript関数を定義し、Rubyメソッドのように扱います。同期的および非同期的な関数呼び出しをサポートしており、Rubyクラス内でnpmモジュールを必要に応じて使用することも可能です。\n\n例えば、次のようにクラスを定義できます。\n\nclass Foo < Nodo::Core\n  function :say_hi, <<~JS\n    (name) => {\n      return `Hello ${name}!`;\n    }\n  JS\nend\n\nfoo = Foo.new\nfoo.say_hi('Nodo')  # => \"Hello Nodo!\"\n\n追加機能として、ESモジュールを動的に読み込むダイナミックインポートや、オブジェクトのインスタンス化時に関数コードを生成する遅延実行があります。さらに、JavaScript呼び出しに対してグローバルまたは関数ごとのタイムアウトを設定でき、詳細な出力のためにログのカスタマイズやデバッグモードを有効にすることもできます。\n\n評価機能もあり、Rubyインスタンスのコンテキスト内でJavaScriptコードを評価し、そのメソッドや定数にアクセスできます。ただし、ユーザー生成データには注意が必要で、セキュリティリスクを避けるための配慮が求められます。\n\nRailsアプリケーションでは、Nodoを設定してNodeモジュールをベンダーフォルダーで管理することができ、アプリケーションのルートをクリーンに保つことができます。\n\nテストツールとしてWebMockを使用する場合は、ローカル接続を許可するように設定し、競合を避ける必要があります。\n\nNodoは、RubyアプリケーションにJavaScriptをシームレスに統合する方法を提供し、機能性を向上させつつパフォーマンスとセキュリティを維持します。"
    }
  },
  {
    "id": "8049440cfd9b45fd",
    "title": {
      "en": "Three Hundred Years Later, a Tool from Isaac Newton Gets an Update",
      "ko": "300년 만의 뉴턴 도구 업데이트",
      "ja": "ニュートンの道具、300年ぶりの進化"
    },
    "type": "story",
    "url": "https://www.quantamagazine.org/three-hundred-years-later-a-tool-from-isaac-newton-gets-an-update-20250324/",
    "score": 151,
    "by": "rbanffy",
    "time": 1742854616,
    "content": "Quanta Homepage\n\n                                        Physics\n\n                                        Mathematics\n\n                                        Biology\n\n                                        Computer Science\n\n                                        Topics\n\n                                        Archive\n\n                                        Blog\n\n                                        Columns\n\n                                        Interviews\n\n                                        Podcasts\n\n                                        Puzzles\n\n                                        Multimedia\n\n                                        Videos\n\n                                        About Quanta\n\n                                    An editorially independent publication supported by the Simons Foundation.\n\n                                    Follow Quanta\n\n    Facebook\n\n        Youtube\n\n        Instagram\n\n    RSS\n\n                Newsletter\n\n                    Get the latest news delivered to your inbox.\n\n                            Email\n\n                        Subscribe\n\n                        Recent newsletters\n\n                                    Gift Store\n\n                                        Shop Quanta gear\n\nNewsletter\n\n                    Get the latest news delivered to your inbox.\n\n                            Email\n\n                        Subscribe\n\n                        Recent newsletters\n\nQuanta Homepage\n\n                                        Physics\n\n                                        Mathematics\n\n                                        Biology\n\n                                        Computer Science\n\n                                        Topics\n\n                                        Archive\n\n        Saved articles\n\n                    Saved Articles\n                                            Create a reading list by clicking the Read Later icon next to the articles you wish to save.\n\n                            See all saved articles\n\n        Login\n\n                    Log out\n\n                    Change password\n\n                                Search\n\nHome\n\n                Three Hundred Years Later, a Tool from Isaac Newton Gets an Update\n\n        Comment\n                3\n\n        Save Article\n\n                    Read Later\n\n                                                Share\n\n    Facebook\n\n                            Copied!\n\n    Copy link\n         (opens a new tab)\n\n    Email\n\n    Pocket\n\n    Reddit\n\n    Ycombinator\n\nalgorithms\n    Three Hundred Years Later, a Tool from Isaac Newton Gets an Update\n\n        By\n\n                Kevin Hartnett\n\nMarch 24, 2025\n\n            A simple, widely used mathematical technique can finally be applied to boundlessly complex problems.\n\n        Comment\n                3\n\n        Save Article\n\n                    Read Later\n\nalgorithms\n    Three Hundred Years Later, a Tool from Isaac Newton Gets an Update\n\n        By\n\n                Kevin Hartnett\n\nMarch 24, 2025\n\n            A simple, widely used mathematical technique can finally be applied to boundlessly complex problems.\n\n        Comment\n                3\n\n        Save Article\n\n                    Read Later\n\nMichele Sclafani for Quanta Magazine\n\nEvery day, researchers search for optimal solutions. They might want to figure out where to build a major airline hub. Or to determine how to maximize return while minimizing risk in an investment portfolio. Or to develop self-driving cars that can distinguish between traffic lights and stop signs.\nMathematically, these problems get translated into a search for the minimum values of functions. But in all these scenarios, the functions are too complicated to assess directly. Researchers have to approximate the minimal values instead.\nIt turns out that one of the best ways to do this is by using an algorithm that Isaac Newton developed over 300 years ago. This algorithm is fairly simple. It’s a little like searching, blindfolded, for the lowest point in an unfamiliar landscape. As you put one foot in front of the other, the only information you need is whether you’re going uphill or downhill, and whether the grade is increasing or decreasing. Using that information, you can get a good approximation of the minimum relatively quickly.\nAlthough enormously powerful — centuries later, Newton’s method is still crucial for solving present-day problems in logistics, finance, computer vision and even pure math — it also has a significant shortcoming. It doesn’t work well on all functions. So mathematicians have continued to study the technique, figuring out different ways to broaden its scope without sacrificing efficiency.\nLast summer, three researchers announced the latest improvement (opens a new tab) to Newton’s method. Amir Ali Ahmadi (opens a new tab) of Princeton University, along with his former students Abraar Chaudhry (opens a new tab) (now at the Georgia Institute of Technology) and Jeffrey Zhang (opens a new tab) (now at Yale University), extended Newton’s method to work efficiently on the broadest class of functions yet.\n“Newton’s method has 1,000 different applications in optimization,” Ahmadi said. “Potentially our algorithm can replace it.”\n\n                    In the 1680s, Isaac Newton developed an algorithm for finding optimal solutions. Three centuries later, mathematicians are still using and honing his method.\n\n    Godfrey Kneller/Public Domain\n\nA Centuries-Old Technique\nMathematical functions transform inputs into outputs. Often, the most important feature of a function is its minimum value — the combination of inputs that produces the smallest possible output.\nBut finding the minimum is hard. Functions can have dozens of variables raised to high powers, defying formulaic analysis; graphs of their solutions form high-dimensional landscapes that are impossible to explore from a bird’s-eye view. In those higher-dimensional landscapes, said Coralia Cartis (opens a new tab) of the University of Oxford, “We want to find a valley. Some are local valleys; others are the lowest point. You’re trying to find these things, and the question is: What info do you have to guide you to that?”\nIn the 1680s, Newton recognized that even when you’re dealing with a very complicated function, you’ll still always have access to at least two pieces of information to help you find its deepest valley. First, you can calculate the function’s so-called first derivative, or slope: the steepness of the function at a given point. Second, you can compute the rate at which the slope itself is changing (the function’s second derivative).\n\n                    Amir Ali Ahmadi sees optimization problems everywhere he looks.\n\n    Archives of the Mathematisches Forschungsinstitut Oberwolfach\n\nSay you’re trying to find the minimum of some complicated function. First, choose a point on the function that you think might be close to the true minimum. Compute the function’s first and second derivatives at that point. These derivatives can be used to construct a special quadratic equation — a parabola if your function lives in a 2D plane, and a cuplike shape called a paraboloid if your function is higher dimensional. This quadratic equation, which is called a Taylor approximation, roughly resembles your function at the point you chose.\nNow calculate the minimum of the quadratic equation instead of the original — something you can do easily, using a well-known formula. (That’s because quadratic equations are simple; it’s when equations get more complicated that calculating the minimum becomes prohibitive.) You’ll get a point. Then plug the coordinates of that point back into your original function, and you’ll get a new point on the function that is, hopefully, closer to its true minimum. Start the entire process again.\nNewton proved that if you keep on repeating this process, you’ll eventually home in on the minimum value of the original, more complicated function. The method doesn’t always work, especially if you start at a point that’s too far away from the true minimum. But for the most part, it does. And it has some desirable attributes.\n\n    Mark Belan/Quanta Magazine;Source:arxiv:2305.07512 (opens a new tab)\n\nOther iterative methods, like gradient descent — the algorithm used in today’s machine learning models — converge toward the true minimum at a linear rate. Newton’s method converges toward it much faster: at a “quadratic” rate. In other words, it can identify the minimum value in fewer iterations than gradient descent. (Each iteration of Newton’s method is more computationally expensive than an iteration of gradient descent, which is why researchers prefer gradient descent for certain applications, like training neural networks. But Newton’s method is still enormously efficient, making it useful in all sorts of contexts.)\nNewton could have written his method to converge toward the true minimum value even faster if, instead of taking just the first and second derivatives at each point, he had also taken, say, the third and fourth derivatives. That would have given him more complicated Taylor approximations, with exponents greater than 2. But the whole crux of his strategy was to transform a complicated function into a simpler one. These more complicated Taylor equations were more than Newton could handle mathematically.\n\n                    Jeffrey Zhang and his co-authors wiggled functions in just the right way, allowing them to broaden the scope of a powerful optimization technique.\n\n    Courtesy of Jeffrey Zhang\n\n“Newton did it for degree 2. He did that because nobody knew how to minimize higher-order polynomials,” Ahmadi said.\nIn the centuries since, mathematicians have worked to extend his method, to probe how much information they can squeeze out of more complicated Taylor approximations of their functions.\nIn the 19th century, for instance, the Russian mathematician Pafnuty Chebyshev proposed a version of Newton’s method that approximated functions with cubic equations (which have an exponent of 3). But his algorithm didn’t work when the original function involved multiple variables. Much more recently, in 2021, Yurii Nesterov (now at Corvinus University of Budapest) demonstrated how to approximate functions (opens a new tab) of any number of variables efficiently with cubic equations. But his method couldn’t be extended to approximate functions using quartic equations, quintics and so on without losing its efficiency. Nevertheless, the proof was a major breakthrough in the field.\nNow Ahmadi, Chaudhry and Zhang have taken Nesterov’s result another step further. Their algorithm works for any number of variables and arbitrarily many derivatives. Moreover, it remains efficient for all these cases — something that until now wasn’t possible.\nBut first, they had to find a way to make a hard math problem a lot easier.\nFinding Wiggle Room\nThere is no fast, general purpose method for finding the minima of functions raised to high exponents. That’s always been the main limitation of Newton’s method. But there are certain types of functions that have characteristics that make them easy to minimize. In the new work, Ahmadi, Chaudhry and Zhang prove that it’s always possible to find approximating equations that have these characteristics. They then show how to adapt these equations to run Newton’s method efficiently.\nWhat properties make an equation easy to minimize? Two things: The first is that the equation should be bowl-shaped, or “convex.” Rather than having many valleys, it has just one — meaning that when you try to minimize it, you don’t have to worry about mistaking an arbitrary valley for the lowest one.\n\n                    Abraar Chaudhry and two colleagues recently found a way to improve a centuries-old method for finding the minima of functions.\n\n    Camille Carpenter Henriquez\n\nThe second property is that the equation can be written as a sum of squares. For example, 5x2 + 16x + 13 can be written as the sum (x + 2)2 + (2x + 3)2. In recent years, mathematicians have developed techniques for minimizing equations with arbitrarily large exponents so long as they are both convex and a sum of squares. However, those techniques were of little help when it came to Newton’s method. Most of the time, the Taylor approximation you use won’t have these nice properties.\nBut Ahmadi, Chaudhry and Zhang figured out how to use a technique called semidefinite programming to wiggle the Taylor approximation just enough to make it both a sum of squares and convex, though not so much that it became unmoored from the original function it was supposed to resemble.\nThey essentially added a fudge factor to the Taylor expansion, turning it into an equation that had the two desired properties. “We can change the Taylor expansion a bit to make it simpler to minimize. Think of the Taylor expansion, but modified a little bit,” Ahmadi said. He and his colleagues then showed that, using this modified version of the Taylor expansion — which involved arbitrarily many derivatives — their algorithm would still converge on the true minimum of the original function. Moreover, the rate of convergence would scale with the number of derivatives used: Just as using two derivatives allowed Newton to approach the true minimum at a quadratic rate, using three derivatives enabled the researchers to approach it at a cubic rate, and so on.\nAhmadi, Chaudhry and Zhang had created a more powerful version of Newton’s method that could reach the true minimum value of a function in fewer iterations than previous techniques.\n\n                Related:\n\n                                    Surprising Limits Discovered in Quest for Optimal Solutions\n\n                                    Risky Giant Steps Can Solve Optimization Problems Faster\n\n                                    How We Can Make Sense of Chaos\n\nLike the original version of Newton’s method, each iteration of this new algorithm is still computationally more expensive than methods such as gradient descent. As a result, for the moment, the new work won’t change the way self-driving cars, machine learning algorithms or air traffic control systems work. The best bet in these cases is still gradient descent.\n“Many ideas in optimization take years before they are made fully practical,” said Jason Altschuler (opens a new tab) of the University of Pennsylvania. “But this seems like a fresh perspective.”\nIf, over time, the underlying computational technology needed to run Newton’s method becomes more efficient — making each iteration less computationally expensive — then the algorithm developed by Ahmadi, Chaudhry and Zhang could eventually surpass gradient descent for all sorts of applications, including machine learning.\n“Our algorithm right now is provably faster, in theory,” Ahmadi said. He’s hopeful, he added, that in 10 to 20 years, it will also be so in practice.\nCorrection:March 25, 2025\nThe graphic in this article has been updated.\n\nBy Kevin Hartnett\n                Contributing Writer\n\n                March 24, 2025\n\n                    View PDF/Print Mode\n\n                            algorithms\n\n                            applied math\n\n                            dynamical systems\n\n                            machine learning\n\n                            mathematics\n\n                    All topics\n\nShare this article\n\n    Facebook\n\n                            Copied!\n\n    Copy link\n         (opens a new tab)\n\n    Email\n\n    Pocket\n\n    Reddit\n\n    Ycombinator\n\n                    Newsletter\n\n                    Get Quanta Magazine delivered to your inbox\n\n                    Subscribe now\n\n                    Recent newsletters\n\n             (opens a new tab)\n\nThe Quanta Newsletter\n\n                    Get highlights of the most important news delivered to your email inbox\n\n                            Email\n\n                        Subscribe\n\n                        Recent newsletters\n                                             (opens a new tab)\n\nAlso in Mathematics\n\n                    ‘Once in a Century’ Proof Settles Math’s Kakeya Conjecture\n\n                geometry\n\n                    ‘Once in a Century’ Proof Settles Math’s Kakeya Conjecture\n\n        By\n\n                Joseph Howlett\n\n            March 14, 2025\n\n        Comment\n                2\n\n        Save Article\n\n                    Read Later\n\n                    Years After the Early Death of a Math Genius, Her Ideas Gain New Life\n\n                geometry\n\n                    Years After the Early Death of a Math Genius, Her Ideas Gain New Life\n\n        By\n\n                Joseph Howlett\n\n            March 3, 2025\n\n        Comment\n                3\n\n        Save Article\n\n                    Read Later\n\n                    After 20 Years, Math Couple Solves Major Group Theory Problem\n\n                group theory\n\n                    After 20 Years, Math Couple Solves Major Group Theory Problem\n\n        By\n\n                Leila Sloman\n\n            February 19, 2025\n\n        Comment\n                8\n\n        Save Article\n\n                    Read Later\n\nComment on this article\n\n                    Quanta Magazine moderates comments tofacilitate an informed, substantive, civil conversation. Abusive, profane, self-promotional, misleading, incoherent or off-topic comments will be rejected. Moderators are staffed during regular business hours (New York time) and can only accept comments written in English.\n\n        Show comments\n\nNext article\n                How Metabolism Can Shape Cells’ Destinies\n\nQuanta Homepage\n\n    Facebook\n\n        Youtube\n\n        Instagram\n\n                                        About Quanta\n\n                                        Archive\n\n                                        Contact Us\n\n                                        Terms & Conditions\n\n                                        Privacy Policy\n\n                        All Rights Reserved © 2025\n\n                    An editorially independent publication supported by the Simons Foundation.\n\n                        Simons Foundation\n\nQuanta Homepage\n\n    Facebook\n\n        Youtube\n\n        Instagram\n\nAbout Quanta\n\n                                        Archive\n\n                                        Contact Us\n\n                                        Terms & Conditions\n\n                                        Privacy Policy\n\nAll Rights Reserved © 2025\n\n                    An editorially independent publication supported by the Simons Foundation.\n\n                        Simons Foundation\n\nClose\n\n    Log in to Quanta\n\n            Use your social network\n\n                        Facebook                        Connect with Facebook\n\n                                                Connect with Google\n\n            or\n\n                    email\n\n                    password\n\n                    Remember me\n\n                        Forgot your password ?\n\n    Don't have an account yet?\n         Sign up\n\nClose\n\n        Forgot your password?\n        We’ll email you instructions to reset your password\n\n                email\n\nClose\n\n        Change your password\n        Enter your new password\n\n                Password\n\n                Retype new password\n\nClose\n\n        Sign Up\n\n                    First Name\n\n                    Last Name\n\n                    Email\n\n                    Password\n\n                    Retype Password\n\n            Creating an account means you accept Quanta Magazine's\n\n            Terms & Conditions and Privacy Policy",
    "summary": {
      "en": "**Summary:**\n\nQuanta Magazine, supported by the Simons Foundation, covers topics in physics, mathematics, biology, and computer science. Recently, an article highlighted a significant update to Isaac Newton's 300-year-old algorithm for finding optimal solutions in complex mathematical problems. \n\nResearchers, led by Amir Ali Ahmadi and his team, have improved Newton's method to work efficiently on a wider range of functions. Traditionally, Newton's method is used to find the minimum values of functions, which is crucial for various applications like logistics and finance. However, it has limitations, particularly with complex functions.\n\nThe new algorithm retains efficiency while allowing for the use of more derivatives, enabling faster convergence to minimum values. The researchers used a technique called semidefinite programming to modify the Taylor approximation of functions, making them easier to minimize. This advancement could potentially lead to practical applications in fields like machine learning in the future, although currently, simpler methods like gradient descent are still preferred.",
      "ko": "Quanta Magazine는 사이먼스 재단의 지원을 받아 물리학, 수학, 생물학, 컴퓨터 과학 등의 주제를 다룹니다. 최근 한 기사에서는 아이작 뉴턴의 300년 된 알고리즘이 개선되었다는 중요한 소식을 전했습니다. 이 알고리즘은 복잡한 수학 문제에서 최적의 해를 찾는 데 사용됩니다.\n\n아미르 알리 아흐마디와 그의 연구팀은 뉴턴의 방법을 개선하여 더 다양한 함수에서 효율적으로 작동하도록 만들었습니다. 전통적으로 뉴턴의 방법은 함수의 최소값을 찾는 데 사용되며, 이는 물류와 금융 등 여러 분야에서 매우 중요합니다. 그러나 이 방법은 복잡한 함수에 대해서는 한계가 있습니다.\n\n새로운 알고리즘은 효율성을 유지하면서 더 많은 도함수를 사용할 수 있게 하여 최소값에 더 빠르게 수렴할 수 있도록 합니다. 연구자들은 반정방형 프로그래밍이라는 기법을 사용하여 함수의 테일러 근사를 수정하였고, 이를 통해 최소화가 더 쉬워졌습니다. 이러한 발전은 미래에 머신러닝과 같은 분야에서 실용적인 응용으로 이어질 가능성이 있지만, 현재는 여전히 경량화된 방법인 경사 하강법이 선호되고 있습니다.",
      "ja": "クアンタ・マガジンは、サイモンズ財団の支援を受けて、物理学、数学、生物学、コンピュータ科学に関するトピックを扱っています。最近、アイザック・ニュートンの300年前のアルゴリズムに関する重要な更新が紹介されました。このアルゴリズムは、複雑な数学的問題における最適解を見つけるためのものです。\n\nアミール・アリ・アフマディ氏とその研究チームは、ニュートン法を改良し、より多様な関数に対して効率的に機能するようにしました。従来、ニュートン法は関数の最小値を見つけるために使用され、これは物流や金融などさまざまな分野で重要です。しかし、この方法には複雑な関数に対する限界があります。\n\n新しいアルゴリズムは、効率を保ちながら、より多くの導関数を使用できるようにし、最小値への収束を速めることができます。研究者たちは、セミデフィニットプログラミングという手法を用いて、関数のテイラー近似を修正し、最小化を容易にしました。この進展は、将来的に機械学習などの分野での実用的な応用につながる可能性がありますが、現時点では勾配降下法のようなよりシンプルな方法が依然として好まれています。"
    }
  },
  {
    "id": "9bf222cff8b15da3",
    "title": {
      "en": "'Brainrot' AI on Instagram Monetizing the Most Fucked Up Things You Can Imagine",
      "ko": "상상 초월 AI 수익화",
      "ja": "「狂気のAI収益化」"
    },
    "type": "story",
    "url": "https://www.404media.co/brainrot-ai-on-instagram-is-monetizing-the-most-fucked-up-things-you-can-imagine-and-lots-you-cant/",
    "score": 47,
    "by": "CharlesW",
    "time": 1742949659,
    "content": "This article contains potentially disturbing graphics and descriptions that are nonetheless viral on Instagram and other major platforms.\n\n404 Media is an independent website whose work is written, reported, and owned by human journalists and whose intended audience is real people, not AI scrapers, bots, or a search algorithm. Become a paid subscriber here for access to all of our articles ad-free and bonus content.\n\n    Subscribe\n\n      Join the newsletter to get the latest updates.\n\n            Success\n\n            Great! Check your inbox and click the link.\n\n            Error\n\n            Please enter a valid email address.\n\nThese are words I never thought I would type, and the people in my life who I have said them to have told me to immediately stop speaking. But here is how I would describe the type of AI generated reels that are popular on Instagram right now: Dora the Explorer feet mukbang; Peppa the Pig Skibidi toilet explosion; Steph Curry and LeBron James Ahegao Drakedom threesome; LeBron James and Diddy raping Steph Curry in prison; anthropomorphic fried egg strippers; iPhone case made of human skin; any number of sexualized Disney princesses doing anything you can imagine and lots of things you can’t; mermaids making out with fish; demon monster eating a woman’s head; face-swapped AI adult influencers with Down syndrome, and, unfortunately, this. Unfortunately, I swear to you that the screengrabs and videos I am including and linking to in this article are not the worst that I have seen on Instagram.Other “niches” that have become popular on Instagram and which have begun to regularly pop up on my feed are wildly racist AI videos of Black men whose faces are put on dogs or gorillas, Black men storming KFC restaurants and chasing after watermelon, George Floyd opening a “Fent-Donalds,” Martin Luther King Jr. in a tub of green sludge, Anne Frank as a zionist cyborg, etc. As I wrote last week, the strategy with these types of posts is to make a human linger on them long enough to say to themselves “what the fuck,” or to be so horrified as to comment “what the fuck,” or send it to a friend saying “what the fuck,” all of which are signals to the algorithm that it should boost this type of content but are decidedly not signals that the average person actually wants to see this type of thing. The type of content that I am seeing right now makes “Elsagate,” the YouTube scandal in which disturbing videos were targeted to kids and resulted in various YouTube reforms, look quaint.\n\n    This post is for paid members only\n    Become a paid member for unlimited ad-free access to articles, bonus podcast content, and more.\n    Subscribe\n\n    Sign up for free access to this post\n    Free members get access to posts like this one along with an email round-up of our week's stories.\n    Subscribe\n\n  Already have an account? Sign in",
    "summary": {
      "en": "The article discusses disturbing AI-generated content that is currently popular on Instagram. It describes various bizarre and inappropriate themes, including sexualized characters and racist portrayals. The author notes that this content often aims to provoke a strong reaction from viewers, which signals the algorithm to promote it further, even though most people find it unsettling. The writer compares this situation to the “Elsagate” scandal on YouTube, suggesting that today's content is even more extreme. The article emphasizes the troubling nature of these trends on social media.",
      "ko": "이 기사는 현재 인스타그램에서 인기 있는 불안한 AI 생성 콘텐츠에 대해 다룹니다. 성적 묘사나 인종 차별적인 표현 등 다양한 기괴하고 부적절한 주제를 설명합니다. 저자는 이러한 콘텐츠가 종종 시청자에게 강한 반응을 유도하려는 목적이 있으며, 이는 알고리즘이 이를 더 많이 추천하도록 만든다고 지적합니다. 대부분의 사람들은 이러한 콘텐츠가 불쾌하다고 느끼지만, 알고리즘은 이를 더욱 확산시킵니다. 작가는 이 상황을 유튜브의 \"엘사게이트\" 스캔들과 비교하며, 오늘날의 콘텐츠가 훨씬 더 극단적이라고 제안합니다. 이 기사는 소셜 미디어에서 이러한 트렌드가 가지는 문제의 심각성을 강조합니다.",
      "ja": "この記事では、現在Instagramで人気のある不気味なAI生成コンテンツについて取り上げています。性的なキャラクターや人種差別的な描写など、さまざまな奇妙で不適切なテーマが紹介されています。著者は、これらのコンテンツが視聴者から強い反応を引き出すことを目的としていることが多く、その結果、アルゴリズムがさらにそのコンテンツを推奨することになると指摘しています。多くの人々が不快に感じるにもかかわらずです。著者はこの状況をYouTubeの「エルサゲート」スキャンダルに例え、今日のコンテンツはさらに過激であると示唆しています。この記事は、ソーシャルメディアにおけるこれらのトレンドの問題点を強調しています。"
    }
  },
  {
    "id": "626ebd1b3c532545",
    "title": {
      "en": "Heavy chatbot usage is correlated with loneliness and reduced socialization",
      "ko": "챗봇과 외로움의 관계",
      "ja": "チャットボット孤独論"
    },
    "type": "story",
    "url": "https://www.platformer.news/openai-chatgpt-mental-health-well-being/",
    "score": 84,
    "by": "suvan",
    "time": 1742870942,
    "content": "OpenAI\n            How chatbots could spark the next big mental health crisis\n                New research from OpenAI shows that heavy chatbot usage is correlated with loneliness and reduced socialization. Will AI companies learn from social networks' mistakes?\n\n                    Casey Newton\n\n                        Mar 24, 2025\n                            — 10 min read\n\n            A chart illustrates that the longer people spend with ChatGPT, the likelier they are to report feelings of loneliness and other mental health risks. (MIT/OpenAI)\n\n    Join the clubThousands of top tech executives, journalists, academics and civil society workers read our reporting on — and analysis of — the day's biggest events at the intersection of technology and democracy.\n\n\tSubscribe\n\n\tGreat! Check your inbox and click the link.\n\tSorry, something went wrong. Please try again.\n\nThis is a column about AI. My boyfriend works at Anthropic, and I also co-host a podcast at the New York Times, which is suing OpenAI and Microsoft over allegations of copyright infringement. Seemy full ethics disclosure here.I.Few questions have generated as much discussion, and as few generally accepted conclusions, as how social networks like Instagram and TikTok affect our collective well-being. In 2023, the US Surgeon General issued an advisory which found that social networks can negatively affect the mental health of young people. Other studies have found that the introduction of social networks does not have any measurable effect on the population’s well-being.As that debate continues, lawmakers in dozens of states have passed laws that seek to restrict social media usage in the belief that it does pose serious risks. But the implementation of those laws has largely been stopped by the courts, which have blocked them on First Amendment grounds.While we await some sort of resolution, the next frontier of this debate is coming rapidly into view. Last year, the mother of a 14-year-old Florida boy sued chatbot maker Character.ai alleging that it was to blame for his suicide. (We spoke with her on this episode of Hard Fork.) And millions of Americans — both young people and adults — are entering into emotional and sexual relationships with chatbots.Over time, we should expect chatbots to become even more engaging than today’s social media feeds. They are personalized to their users; they have realistic human voices; and they are programmed to affirm and support their users in almost every case.\n\n\tSubscribe\n\n\tGreat! Check your inbox and click the link.\n\tSorry, something went wrong. Please try again.\n\nSo how will extended use of these bots affect their human users? And what should platforms do to mitigate the risks?II.These questions are at the center of two new studies published on Friday by researchers from the MIT Media Lab and OpenAI. And while further research is needed to support their conclusions, their findings are both consistent with earlier research about social media and a warning to platforms that are building chatbots optimized for engagement.In the first study, researchers collected and analyzed more than 4 million ChatGPT conversations from 4,076 people who had agreed to participate. They then surveyed participants about how those interactions had made them feel.In the second study, researchers recruited 981 people to participate in a four-week trial. Each person was asked to use ChatGPT for at least five minutes a day. At the end of the trial, participants filled out a survey about how they perceived ChatGPT, whether they felt lonely, whether they were socializing with people in the real world, and whether they perceived their use of the chatbot as problematic.The studies found that most users have a neutral relationship with ChatGPT, using it as a software tool like any other. But both studies also found a group of power users — those in the top 10 percent of time spent with ChatGPT — whose usage suggested more reason for concern.Heavy use of ChatGPT was correlated with increased loneliness, emotional dependence, and reduced social interaction, the studies found.“Generally, users who engage in personal conversations with chatbots tend to experience higher loneliness,” the researchers wrote. “Those who spend more time with chatbots tend to be even lonelier.”(Quick editorial aside: OpenAI deserves real credit for investing in this research and publishing it openly. This kind of self-skeptical investigation is exactly the sort of thing I have long advocated for companies like Meta to do more of; instead, in the wake of the Frances Haugen revelations, it has done far less of it.)Jason Phang, a researcher at OpenAI who worked on the studies, warned me that the findings would need to be replicated by other studies before they could be considered definitive. “These are correlations from a preliminary study, so we don't want to draw too strong conclusions here,” he said in an interview.Still, there is plenty in here that is worth discussing.Note that these studies aren’t suggesting that heavy ChatGPT usage directly causes loneliness. Rather, it suggests that lonely people are more likely to seek emotional bonds with bots — just as an earlier generation of research suggested that lonelier people spend more time on social media.That matters less for OpenAI, which has designed ChatGPT to present itself as more of a productivity tool than a boon companion. (Though that hasn’t stopped some people from falling in love with it, too.) But other developers — Character.ai, Replika, Nomi — are all intentionally courting users that seek more emotional connections. “Develop a passionate relationship,” read the copy on Nomi’s website. “Join the millions who already have met their AI soulmates,” touts Replika.Each of these apps offers paid monthly subscriptions; among the benefits offered are longer “memories” for chatbots to enable more realistic roleplay. Nomi and Replika sell additional benefits through in-app currencies that let you purchase AI “selfies,” cosmetic items, and additional chat features to enhance the fantasy.III.And for most people, all of that is probably fine. But the research from MIT and OpenAI suggests the danger here: that sufficiently compelling chatbots will pull people away from human connections, possibly making them feel lonelier and more dependent on the synthetic companion they must pay to maintain a connection with.“Right now, ChatGPT is very much geared as a knowledge worker and a tool for work,” Sandhini Agarwal, who works on AI policy at OpenAI and is one of the researchers on these studies, told me in an interview. “But as … we design more of these chatbots that are intended to be more like personal companions … I do think taking into account impacts on well-being will be really important. So this is trying to nudge the industry towards that direction.”What to do? Platforms should work to understand what early indicators or usage patterns might signal that someone is developing an unhealthy relationship with a chatbot. (Automated machine-learning classifiers, which OpenAI employed in this study, seem like a promising approach here.) They should also consider borrowing some features from social networks, including regular “nudges” when a user has been spending several hours a day inside their apps.“We don’t want for people to make a generalized claim like, ‘oh, chatbots are bad,’ or ‘chatbots are good,’” Pat Pataranutaporn, a researcher at MIT who worked on the studies, told me. “We try to show it really depends on the design and the interaction between people and chatbots. That’s the message that we want people to take away. Not all chatbots are made equal.”The researchers call this approach “socioaffective alignment”: designing bots that serve users’ needs without exploiting them.Meanwhile, lawmakers should warn platforms away from exploitative business models that seek to get lonely users hooked on their bots and then continually ratchet up the cost of maintaining that connection. It also seems likely that many of the state laws now aimed at young people and social networks will eventually be adapted to cover AI as well.For all the risks they might pose, I still think chatbots should be a net positive in many people’s lives. (Among the study’s other findings is that using ChatGPT in voice mode helped to reduce loneliness and emotional dependence on the chatbot, though it showed diminishing returns with heavier use.) Most people do not get enough emotional support, and putting a kind, wise, and trusted companion into everyone’s pocket could bring therapy-like benefits to billions of people.But to deliver those benefits, chatbot makers will have to acknowledge that their users’ mental health is now partially their responsibility. Social networks waited far too long to acknowledge that some meaningful percentage of their users have terrible outcomes from overusing them. It would be a true shame if the would-be inventors of superintelligence aren’t smart enough to do better this time around.SponsoredPower tools for pro software engineers.There are plenty of AI assistants out there to help you write code. Toy code. Hello-world code. Dare we say it:\"vibe code.\" Those tools are lots of fun andwe hope you use them. But when it's time to build something real, try Augment Code. Their AI assistant is built to handle huge, gnarly, production-grade codebases. The kind that real businesses have. The kind that real softwareengineers lose sleep over. We're not saying your code will never wake you up again. But if you have to be awake anyway, you might as well use an AI assistant that knows your dependencies, respects your team's coding standards, and lives in your favorite editors such as Vim, VSCode, JetBrains and more. That's Augment Code. Are you ready to move beyond the AI toys and build real software faster?Try Augment Code for freeGoverningThe Trump administration accidentally included the editor in chief of The Atlantic in its Signal group chat discussing war plans in Yemen. (Jeffrey Goldberg / The Atlantic)ByteDance’s biggest US investors are reportedly mulling over a deal with Oracle that would alloq them to acquire additional stakes in a TikTok US spinoff. (Financial Times)AI search startup Perplexity said it proposed a bid to acquire and transform TikTok. (Kylie Robison / The Verge)AI companies are aggressively lobbying for less state-level regulation since Trump’s election. It's all over their AI \"action\" plans. (Cecilia Kang / New York Times)Commerce secretary Howard Lutnick touted Elon Musk’s Starlink to federal officials overseeing a $42 billion rural broadband program. Your conflict of interest of the day. (Joe Miller and Alex Rogers / Financial Times)Starlink’s global expansion plans are hitting some regulatory roadblocks, as regulators consider whether Musk’s ties to Trump makes him a reliable partner. (Rafe Uddin and Stephen Morris / Financial Times)A look at how Musk’s promotion of conspiracy theories online have led to real consequences in government and policy. (Renée DiResta / The Atlantic)A look at Amazon's lawsuit against the Consumer Product Safety Commission, which claims the agency is unconstitutional. (Caroline O’Donovan / Washington Post)Health secretary Robert F. Kennedy Jr. praised phone restrictions in schools, citing health hazards linked to teen phone use. You will be surprised to learn that not all of these \"hazards\" are supported by scientific research. (Aria Bendix / NBC News)OpenAI’s Sora video generator amplifies sexist, racist and ableist stereotypes, this investigation found. (Reece Rogers and Victoria Turk / Wired)Pornographic content is increasingly appearing on Spotify’s top podcast charts despite the company’s ban on sexually explicit content. (Ashley Carman / Bloomberg)Meta’s new Community Notes fact-checking system isn’t doing enough to stop the spread of misinformation, these columnists write. (Dave Lee and Carolyn Silverman / Bloomberg)The 10 most popular “nudifying” apps saw their traffic jump by more than 600 percent, from 3 million in April 2023 to 23 million in April 2024. (Margi Murphy / Bloomberg)A look at AI timelines and the impending need for sooner-than-expected policy actions. A co-founder Anthropic suggests that if powerful AI is arriving next year or the year after, governments should take quick action. (Jack Clark / Import AIThe UK government is reportedly considering plans to reduce or abolish its digital services tax to avoid Trump’s trade tariffs. (Lucy White and Alex Wickham / Bloomberg)X suspended several accounts of opposition figures in Turkey as demonstrations in the country continue. (Eliza Gkritsi / Politico)An investigation into how a scammer network in Cambodia is laundering billions and exploiting victims using legitimate businesses. (Selam Gebrekidan and Joy Dong / New York Times)China has banned the use of facial recognition in private spaces like hotel rooms without consent. (Simon Sharwood / The Register)IndustryOpenAI and Meta are separately exploring partnerships with India’s Reliance Industries to expand AI offerings in the country. (Sri Muppidi and Amir Efrati / The Information)OpenAI is expanding its COO role and elevating two executives to the C-suite as Sam Altman focuses more on product. (Shirin Ghaffary / Bloomberg)An inside look at how Google scrambled for two years to catch up to OpenAI, through layoffs and the lowering of certain guardrails. (Paresh Dave and Arielle Pardes / Wired)Removing European news in search has little to no impact on ad revenue for Google, the company said. (Paul Liu / Google)Google is rolling out new AI features to Gemini Live, which lets it “see” a user’s screen or smartphone camera and answer questions about them in real-time. (Wes Davis / The Verge)Google accidentally deleted Google Maps Timeline data for some users and urged affected users to restore data from a backup. (Hadlee Simons / Android Authority)X was reportedly recently valued at $44 billion by investors, a dramatic reversal of fortune for the company after Musk’s takeover. (George Hammond, Tabby Kinder, Hannah Murphy and Eric Platt / Financial Times)X’s director of engineering, Haofei Wang, has reportedly left the company. (Kylie Robison / The Verge)Meta is testing a feature designed to help users write comments using AI. (Aisha Malik / TechCrunch)Korean chip startup FuriosaAI reportedly turned down an $800 million takeover bid from Meta. (Yoolim Lee and Riley Griffin / Bloomberg)Bluesky has made more money from sales of its T-shirt that CEO Jay Graber wore to SXSW to poke fun at Mark Zuckerberg than it has from selling custom domains. (Amanda Silberling / TechCrunch)Apple is testing adding cameras and visual intelligence features to its smartwatch line. (Mark Gurman / Bloomberg)Apple’s AirPods Max headphones will soon support lossless audio after losing it last year after it switched to a USB-C connector. (Chris Welch / The Verge)Microsoft launched six new AI agents for its Security Copilot, designed to assist overwhelmed security teams. (Tom Warren / The Verge)Yahoo is selling tech news site TechCrunch to Regent, a media investment firm. A grim development. (Sara Fischer / Axios)Ethereum’s on-chain activity dipped and the daily amount of ETH burned due to transaction fees hit an all-time low last week. (Zack Abrams / The Block)A profile of the Internet Archive, the nonprofit behind the Wayback Machine rushing to save web pages. (Emma Bowman / NPR)Showrunner Tony Gilroy said he will no longer publish television show Andor’s scripts to prevent it from being used in AI training. (Kylie Robison / The Verge)A review of Kagi, a search engine that this writer says offers a new vision for search for $10 a month. (David Pierce / The Verge)A look at how an AI’s treatment plan made from parsing thousands of old medicines saved a man’s life. (Kate Morgan / New York Times)A survey of 730 coders and developers on how they use AI chatbots at work. (Wired Staff / Wired)Those good postsFor more good posts every day, follow Casey’s Instagram stories.(Link)(Link)(Link)Talk to usSend us tips, comments, questions, and socioaffective alignment: casey@platformer.news.Sponsor a Newsletter",
    "summary": {
      "en": "OpenAI's recent research indicates that heavy use of chatbots like ChatGPT may lead to increased feelings of loneliness and reduced social interaction. The studies analyzed millions of chatbot conversations and found that while most users have a neutral relationship with these tools, a small group of heavy users reported significant mental health concerns, such as emotional dependency and loneliness. \n\nAs chatbots become more engaging and personalized, there are fears they could draw people away from real-life connections. The researchers emphasize the need for chatbot designers to consider the mental health impacts of their products. They suggest implementing features to detect unhealthy usage patterns and provide user nudges, similar to social media practices.\n\nThe findings highlight the responsibility of AI companies to prioritize user well-being, learning from the mistakes of social networks. While chatbots can offer valuable emotional support, their potential to negatively affect mental health must be acknowledged and addressed.",
      "ko": "OpenAI의 최근 연구에 따르면, ChatGPT와 같은 챗봇을 과도하게 사용하면 외로움이 증가하고 사회적 상호작용이 줄어들 수 있다고 합니다. 연구진은 수백만 건의 챗봇 대화를 분석한 결과, 대부분의 사용자가 챗봇과 중립적인 관계를 유지하는 반면, 소수의 과도한 사용자들은 감정적 의존과 외로움 같은 심각한 정신 건강 문제를 보고했다고 밝혔습니다.\n\n챗봇이 점점 더 매력적이고 개인화됨에 따라, 사람들이 실제 관계에서 멀어질 수 있다는 우려가 커지고 있습니다. 연구자들은 챗봇 설계자들이 제품의 정신 건강에 미치는 영향을 고려해야 한다고 강조합니다. 이들은 소셜 미디어에서 사용하는 방식처럼, 비정상적인 사용 패턴을 감지하고 사용자에게 경고하는 기능을 도입할 것을 제안합니다.\n\n이 연구 결과는 AI 기업들이 사용자 복지를 우선시해야 할 책임이 있음을 강조하며, 소셜 네트워크의 실수에서 교훈을 얻어야 한다고 말합니다. 챗봇이 소중한 정서적 지원을 제공할 수 있지만, 정신 건강에 부정적인 영향을 미칠 가능성도 인식하고 해결해야 한다는 점이 중요합니다.",
      "ja": "OpenAIの最近の研究によると、ChatGPTのようなチャットボットを多く利用することが、孤独感の増加や社会的な交流の減少につながる可能性があることが示されています。この研究では、数百万件のチャットボットの会話を分析し、ほとんどのユーザーがこれらのツールに対して中立的な関係を持っている一方で、一部のヘビーユーザーは感情的依存や孤独感などの深刻なメンタルヘルスの問題を報告しました。\n\nチャットボットがより魅力的で個別化されるにつれて、実際の人間関係から人々を引き離す懸念が高まっています。研究者たちは、チャットボットのデザイナーが自社製品のメンタルヘルスへの影響を考慮する必要があると強調しています。彼らは、健康的でない使用パターンを検出し、ユーザーに注意を促す機能を実装することを提案しています。これは、ソーシャルメディアの実践に似たアプローチです。\n\nこの研究結果は、AI企業がユーザーの幸福を優先する責任があることを浮き彫りにしています。ソーシャルネットワークの過去の失敗から学ぶ必要があります。チャットボットは貴重な感情的サポートを提供できる一方で、メンタルヘルスに悪影響を及ぼす可能性も認識し、対処することが重要です。"
    }
  },
  {
    "id": "20bb7511fe9936ea",
    "title": {
      "en": "Aircraft detection at planetary scale",
      "ko": "행성 규모 항공기 탐지",
      "ja": "惑星規模の航空機検出"
    },
    "type": "story",
    "url": "https://www.planet.com/pulse/aircraft-detection-at-planetary-scale/",
    "score": 95,
    "by": "jjwiseman",
    "time": 1742848821,
    "content": "HOMETechAircraft Detection at Planetary ScaleAdam Van EttenMarch 20, 2025•5 min readTechTechIntroductionOn a typical day, there are greater than 10,000 aircraft (commercial, private, and military) in flight at any given time. The precise departure (point A) and destination (point B) locations, as well as the timing of flight activity, provide critically important information for myriad industries. For instance, in the defense and intelligence sector, being able to identify how many aircraft were stationed at one foreign government’s airbase (point A) and how many are gone the next day may reveal insights as to why an allied government’s airbase (point B) just received a new fleet on their tarmac.On the commercial side, understanding how many aircraft landed in a city on a specific day can help predict economic trends and assess the impacts of world events - such as the quantity of aircraft present for large sporting or entertainment events. Satellite imagery is a powerful information source for this type of aircraft detection. Combine automated satellite scans of airfields with a global news reporting large language model, and you can start to get a feed of insights, linking the patterns of politics and economies with global air traffic.ScaleAircraft detection with satellite imagery is nothing new. In fact, aircraft detection on the tarmac is an archetypal use case for remote sensing machine learning. Until now, though, aircraft detection has been limited to a select number of airfields with sporadic coverage and cadence. Planet’s satellites, on the other hand, scan all of Earth’s landmass on a near-daily basis, so we are now able to mitigate those limitations, leveraging novel machine learning techniques with global PlanetScope coverage to drastically scale global aircraft detection.The need for greater scale in aircraft detection is difficult to overstate. More than one hundred thousand commercial and military flights take place each day, as planes transport people and cargo to nearly fifty thousand airports across the globe. Some sites collect and share publicly available data on this complex matrix of movement. But not every flight is recorded, and not every plane is public.Monitoring aircraft activity is vital for economic, defense, and intelligence purposes, but current methods rely on tedious and expensive processes, especially at scale. The rapid pace of geopolitical developments and sheer volume of data means that analyzing airfields manually is no longer feasible, especially in conflict/sensitive zones where aircraft movements aren’t publicly reported.Planet’s new Aircraft Detection Analytic Feed automates daily detection of aircraft by leveraging a machine learning model trained using PlanetScope and SkySat data. It precisely identifies aircraft ≥25 meters in length or wingspan across airfields globally. It represents the first attempt at global detection of large aircraft on a near-daily basis and offers a scalable solution for analysis at scale. This presents a massive and unprecedented opportunity for analysts with or without geospatial expertise. Historical daily counts of aircraft broken down by size and location enables pattern-of-life analyses to be conducted, highlighting when anomalous behavior is detected. This can indicate events taking place or even actions to come.Keep reading for more information and register for our upcoming webinar. Our ApproachOur Aircraft Detection service leverages a supervised object detection model, trained on PlanetScope imagery to detect aircraft at rest on an airfield/airport tarmac. Precise labeling of aircraft can be a challenging task in medium-resolution PlanetScope imagery, so we use high-resolution SkySat imagery collected within 3 minutes of a PlanetScope scene (see Figure 1). This approach enables us to label on high-resolution imagery, then apply those high fidelity labels to medium-resolution PlanetScope data. The vast majority of aircraft are static on a 3-minute timeframe, but around ~2% of aircraft move between the two collections, and we remove those labels in our quality control phase.Figure 1. SkySat aircraft labels are applied to concurrent PlanetScope imagery.With this approach, we collected over 800 concurrent (or “crossover”) image pairs for labeling. After significant experimentation with many different model architectures, we determined that aircraft <25m in length or wingspan are too small to be reliably detected in medium resolution imagery, so we elected to focus on aircraft this size or greater. Splitting the dataset into 85% training / 15% testing, we generated a training dataset consisting of ~15,000 labels, roughly evenly split between civilian and military types. This is by no means an enormous dataset, so expansion of the label corpus would likely yield a performance boost.Figure 2. Airfield locations in the labeled dataset.Figure 3. Observation dates, covering multiple years and every season. A concerted effort was made in 2023 to leverage SkySat capacity to capture data over airfields to ensure we had a healthy amount of data to leverage.We utilize a deep learning object detection model optimized for Planet’s medium resolution imagery, which runs at sufficient speed so that we are free to analyze as many airports and airstrips as desired. The model achieves an F1 score of 0.82 for aircraft detection on our globally distributed test set. Reported errors are at the 1σ level, computed via bootstrap resampling of the test set.High resolution SkySat imagery can be leveraged for more than just training data generation. Occasionally, additional scrutiny will be required to understand exactly what’s going on at a given airfield. An example is provided in Figure 3, which shows a consistent “missed” detection with our PlanetScope model. Yet closer inspection of this airfield with SkySat revealed that this apparent “miss” was in fact merely a painting on the tarmac. The ability to rapidly probe targeted areas much deeper with SkySat is a highly valuable complement to the ubiquitous daily coverage of PlanetScope.Figure 4. PlanetScope (left) detections showing a “missed” aircraft in the upper left. High-resolution SkySat imagery (right) illustrating that only paint exists at this location.Figure 5. Animation showing analysis of a large corpus of global detections.Next StepsOur solution extends significantly beyond the archetypal problem of counting aircraft on the tarmac. We track behavior at an approximately daily cadence by quantifying the fraction of aircraft that moved or remained static. Furthermore, interactive dashboards enable on-the-fly time series analysis, outlier categorization, and trend aggregation. We’ve integrated a global news LLM into this process to further enlighten our users. Detected outliers are subsequently probed for correlation to regional events. We’ll be demonstrating this capability in an upcoming Agile EO Webinar. Register here!Tags:#Aircraft DetectionContentsIntroductionScaleOur ApproachNext StepsShareReady to Get StartedConnect with a member of our Sales team. We'll help you find the right products and pricing for your needsContact SalesOther Articles You Might Like",
    "summary": {
      "en": "**Summary: Aircraft Detection at Planetary Scale**\n\nEvery day, over 10,000 aircraft are in the air, making tracking their movements crucial for various sectors, including defense and commercial industries. Understanding flight patterns can reveal important insights about geopolitical events and economic trends.\n\nTraditionally, detecting aircraft using satellite imagery has been limited and manual, but Planet's new Aircraft Detection Analytic Feed changes that. It uses advanced machine learning techniques and daily satellite scans to automatically identify large aircraft (≥25 meters) globally. This new system offers a scalable, efficient solution for monitoring aircraft activity, which is vital in many contexts, especially in sensitive areas.\n\nThe detection process combines medium-resolution PlanetScope imagery with high-resolution SkySat imagery to ensure accurate labeling of aircraft. The technology can help analysts recognize patterns and anomalies in aircraft behavior, providing significant insights without needing extensive expertise in geospatial data.\n\nNext steps for the project include enhancing the analysis capabilities with interactive dashboards and integrating global news data to better understand the context of detected events. A webinar will be held to showcase these advancements.",
      "ko": "매일 10,000대 이상의 항공기가 비행 중이며, 이들의 움직임을 추적하는 것은 방위 및 상업 산업 등 여러 분야에서 매우 중요합니다. 비행 패턴을 이해하면 지정학적 사건과 경제 동향에 대한 중요한 통찰을 얻을 수 있습니다.\n\n전통적으로 위성 이미지를 이용한 항공기 탐지는 제한적이고 수동적이었습니다. 그러나 Planet의 새로운 항공기 탐지 분석 피드는 이러한 방식을 변화시킵니다. 이 시스템은 고급 기계 학습 기술과 매일 실시되는 위성 스캔을 활용하여 전 세계적으로 대형 항공기(길이 25미터 이상)를 자동으로 식별합니다. 이 새로운 시스템은 항공기 활동을 모니터링하는 데 있어 확장 가능하고 효율적인 솔루션을 제공합니다. 이는 특히 민감한 지역에서 매우 중요합니다.\n\n탐지 과정은 중간 해상도의 PlanetScope 이미지와 고해상도의 SkySat 이미지를 결합하여 항공기를 정확하게 식별합니다. 이 기술은 분석가들이 항공기 행동의 패턴과 이상 징후를 인식하는 데 도움을 주며, 지리 공간 데이터에 대한 광범위한 전문 지식 없이도 중요한 통찰을 제공합니다.\n\n이 프로젝트의 다음 단계는 인터랙티브 대시보드를 통해 분석 능력을 강화하고, 탐지된 사건의 맥락을 이해하기 위해 전 세계 뉴스 데이터를 통합하는 것입니다. 이러한 발전을 선보이기 위한 웨비나도 개최될 예정입니다.",
      "ja": "毎日、1万機以上の航空機が空を飛んでおり、その動きを追跡することは、防衛や商業などさまざまな分野にとって重要です。飛行パターンを理解することで、地政学的な出来事や経済の動向についての重要な洞察が得られます。\n\n従来、衛星画像を使った航空機の検出は限られており、手動で行われていましたが、Planetの新しい航空機検出解析フィードがその状況を変えます。このシステムは、先進的な機械学習技術と日々の衛星スキャンを利用して、全世界で大型航空機（長さ25メートル以上）を自動的に特定します。この新しいシステムは、航空機の活動を監視するためのスケーラブルで効率的な解決策を提供し、特に敏感な地域では非常に重要です。\n\n検出プロセスでは、中解像度のPlanetScope画像と高解像度のSkySat画像を組み合わせて、航空機の正確なラベリングを行います。この技術により、アナリストは航空機の行動パターンや異常を認識しやすくなり、地理空間データに関する専門的な知識がなくても重要な洞察を得ることができます。\n\n今後のプロジェクトのステップとしては、インタラクティブなダッシュボードを用いて分析能力を向上させ、検出されたイベントの文脈をよりよく理解するために、世界のニュースデータを統合することが挙げられます。これらの進展を紹介するウェビナーも開催される予定です。"
    }
  },
  {
    "id": "781d9ca14c79dac7",
    "title": {
      "en": "Writing your own C++ standard library from scratch",
      "ko": "C++ 표준 라이브러리 만들기",
      "ja": "ゼロから作るC++ライブラリ"
    },
    "type": "story",
    "url": "https://nibblestew.blogspot.com/2025/03/writing-your-own-c-standard-library.html",
    "score": 144,
    "by": "JNRowe",
    "time": 1742890236,
    "content": "Nibble Stew\n\nA gathering of development thoughts of Jussi Pakkanen. Some of you may know him as the creator of the Meson build system. jpakkane at gmail dot com\n\nMonday, March 24, 2025\n\nWriting your own C++ standard library from scratch\n\nThe C++ standard library (also know as the STL) is, without a doubt, an astounding piece of work. Its scope, performance and incredible backwards compatibility have taken decades of work by many of the world's best programmers. My hat's off to all those people who have contributed to it.All of that is not to say that it is not without its problems. The biggest one being the absolutely abysmal compile times but unreadability, and certain unoptimalities caused by strict backwards compatibility are also at the top of the list. In fact, it could be argued that most of the things people really dislike about C++ are features of the STL rather than the language itself. Fortunately, using the STL is not mandatory. If you are crazy enough, you can disable it completely and build your own standard library in the best Bender style.One of the main advantages of being an unemployed-by-choice open source developer is that you can do all of that if you wish. There are no incompetent middle damagers hovering over your shoulder to ensure you are \"producing immediate customer value\" rather than \"wasting time on useless polishing that does not produce immediate customer value\".It's my time, and I'll waste it if I want to!What's in it?The biggest design questions of a standard library are scope and the \"feel\" of the API. Rather than spending time on design, we steal it. Thus, when in doubt, read the Python stdlib documentation and replicate it. Thus the name of the library is pystd.The test appTo keep the scope meaningful, we start by writing only enough of stdlib to build an app that reads a text file, validates it as UTF-8, splits the contents into words, counts how many time each word appears in the file and prints all words and how many times it appears sorted by decreasing count.This requires, at least:File handlingStringsUTF8 validationA hash mapA vectorSortingThe training wheels come offThe code is available in this Github repo for those who want to follow along at home.Disabling the STL is fairly easy (with Linux+GCC at least) and requires only these two Meson statements:add_global_arguments('-nostdinc++', language: 'cpp')\nadd_global_link_arguments('-nostdlib++', '-lsupc++', language: 'cpp')The supc++ library is (according to stackoverflow) a support library GCC needs to implement core language features. Now the stdlib is off and it is time to implement everything with sticks, stones and duct tape.The outcomeOnce you have implemented everything discussed above and auxiliary stuff like a hashing framework the main application looks like this.The end result is both Valgrind and Asan clean. There is one chunk of unreleased memory, but that comes from supc++. There is probably UB in the implementation. But it should be the good kind of UB that, if it would actually not work, would break the entire Linux userspace because everything depends on it working \"as expected\".All of this took fewer than 1000 lines of code in the library itself (including a regex implementation that is not actually used). For comparison merely including vector from the STL brings in 27 thousand lines of code.Comparison to an STL versionConverting this code to use the STL is fairly simple and only requires changing some types and fine tuning the API. The main difference is that the STL version does not validate that the input is UTF-8 as there is no builtin function for that. Now we can compare the two.Runtime for both is 0.001 to 0.002 seconds on the small test file I used. Pystd is not noticeably slower than the STL version, which is enough for our purposes. It almost certainly scales worse because there has been zero performance work on it.Compiling the pystd version with -O2 takes 0.3 seconds whereas the STL version takes 1.2 seconds. The measurements were done on a Ryzen 7 3700X processor.The executable's unstripped size is 349k for STL and 309k for pystd. The stripped sizes are 23k and 135k. Approximately 100 k of the pystd executable comes from supc++. In the STL version that probably comes dynamically from libstdc++(which, on this machine, takes 2.5 MB).Perfect ABI stabilityDesigning a standard library is exceedingly difficult because you can't ever really change it. Someone, somewhere, is depending on every misfeature in it so they can never be changed.Pystd has been designed to both support perfect ABI stability and make it possible to change it in arbitrary ways in the future. If you start from scratch this turned out to be fairly simple.The sample code above used the pystd namespace. It does not actually exist. Instead it is defined like this in the cpp file:#include <pystd2025.hpp>namespace pystd = pystd2025;In pystd all code is in a namespace with a year and is stored in a header file with the same year. The idea is, then, that every year you create a new release. This involves copying all stdlib header files to a file with the new year and regexping the namespace declarations to match. The old code is now frozen forever (except for bug fixes) whereas the new code can be changed at will because there arezero existing lines of code that depend on it.End users now have the choice of when to update their code to use newer pystd versions. Even better, if there is an old library that can not be updated, any of the old versions can be used in parallel. For example:pystd2030::SomeType foo;pystd2025::SomeType bar(foo.something(), foo.something_else());Thus if no code is ever updated, everything keeps working. If all code is updated at once, everything works. If only parts of the code are updated, things can still be made to work with some glue code. This puts the maintenance burden on the people whose projects can not be updated as opposed to every other developer in the world. This is as it should be, and also would motivate people with broken deps to spend some more effort to get them fixed.\n\nPosted by\n\nJussi\n\nat\n\n5:03 PM\n\nEmail ThisBlogThis!Share to XShare to FacebookShare to Pinterest\n\nNo comments:\n\nPost a Comment\n\n      BLOG_CMT_createIframe('https://www.blogger.com/rpc_relay.html');\n\nOlder Post\n\nHome\n\nSubscribe to:\nPost Comments (Atom)\n\nAbout Me\n\nJussi\n\nView my complete profile\n\nBlog Archive\n\n        ▼\n\n2025\n\n(5)\n\n        ▼\n\nMarch\n\n(1)\n\nWriting your own C++ standard library from scratch\n\n        ►\n\nFebruary\n\n(3)\n\n        ►\n\nJanuary\n\n(1)\n\n        ►\n\n2024\n\n(21)\n\n        ►\n\nDecember\n\n(4)\n\n        ►\n\nNovember\n\n(1)\n\n        ►\n\nOctober\n\n(2)\n\n        ►\n\nSeptember\n\n(1)\n\n        ►\n\nAugust\n\n(2)\n\n        ►\n\nJuly\n\n(1)\n\n        ►\n\nJune\n\n(1)\n\n        ►\n\nMay\n\n(1)\n\n        ►\n\nApril\n\n(3)\n\n        ►\n\nMarch\n\n(2)\n\n        ►\n\nFebruary\n\n(1)\n\n        ►\n\nJanuary\n\n(2)\n\n        ►\n\n2023\n\n(41)\n\n        ►\n\nDecember\n\n(5)\n\n        ►\n\nNovember\n\n(2)\n\n        ►\n\nOctober\n\n(2)\n\n        ►\n\nSeptember\n\n(3)\n\n        ►\n\nAugust\n\n(1)\n\n        ►\n\nJuly\n\n(3)\n\n        ►\n\nJune\n\n(4)\n\n        ►\n\nMay\n\n(4)\n\n        ►\n\nApril\n\n(4)\n\n        ►\n\nMarch\n\n(6)\n\n        ►\n\nFebruary\n\n(5)\n\n        ►\n\nJanuary\n\n(2)\n\n        ►\n\n2022\n\n(34)\n\n        ►\n\nDecember\n\n(4)\n\n        ►\n\nNovember\n\n(3)\n\n        ►\n\nOctober\n\n(2)\n\n        ►\n\nSeptember\n\n(4)\n\n        ►\n\nAugust\n\n(2)\n\n        ►\n\nJuly\n\n(3)\n\n        ►\n\nJune\n\n(2)\n\n        ►\n\nMay\n\n(2)\n\n        ►\n\nApril\n\n(4)\n\n        ►\n\nFebruary\n\n(5)\n\n        ►\n\nJanuary\n\n(3)\n\n        ►\n\n2021\n\n(29)\n\n        ►\n\nDecember\n\n(1)\n\n        ►\n\nNovember\n\n(1)\n\n        ►\n\nOctober\n\n(1)\n\n        ►\n\nSeptember\n\n(2)\n\n        ►\n\nAugust\n\n(1)\n\n        ►\n\nJuly\n\n(5)\n\n        ►\n\nJune\n\n(3)\n\n        ►\n\nMay\n\n(5)\n\n        ►\n\nApril\n\n(2)\n\n        ►\n\nMarch\n\n(4)\n\n        ►\n\nFebruary\n\n(3)\n\n        ►\n\nJanuary\n\n(1)\n\n        ►\n\n2020\n\n(42)\n\n        ►\n\nDecember\n\n(1)\n\n        ►\n\nNovember\n\n(5)\n\n        ►\n\nOctober\n\n(5)\n\n        ►\n\nSeptember\n\n(2)\n\n        ►\n\nAugust\n\n(4)\n\n        ►\n\nJuly\n\n(5)\n\n        ►\n\nJune\n\n(2)\n\n        ►\n\nMay\n\n(4)\n\n        ►\n\nApril\n\n(3)\n\n        ►\n\nMarch\n\n(4)\n\n        ►\n\nFebruary\n\n(5)\n\n        ►\n\nJanuary\n\n(2)\n\n        ►\n\n2019\n\n(27)\n\n        ►\n\nDecember\n\n(4)\n\n        ►\n\nNovember\n\n(3)\n\n        ►\n\nOctober\n\n(1)\n\n        ►\n\nSeptember\n\n(2)\n\n        ►\n\nAugust\n\n(3)\n\n        ►\n\nJuly\n\n(2)\n\n        ►\n\nJune\n\n(2)\n\n        ►\n\nMay\n\n(3)\n\n        ►\n\nApril\n\n(1)\n\n        ►\n\nFebruary\n\n(6)\n\n        ►\n\n2018\n\n(24)\n\n        ►\n\nNovember\n\n(4)\n\n        ►\n\nOctober\n\n(1)\n\n        ►\n\nSeptember\n\n(1)\n\n        ►\n\nAugust\n\n(3)\n\n        ►\n\nJuly\n\n(3)\n\n        ►\n\nJune\n\n(1)\n\n        ►\n\nApril\n\n(3)\n\n        ►\n\nMarch\n\n(4)\n\n        ►\n\nFebruary\n\n(4)\n\n        ►\n\n2017\n\n(35)\n\n        ►\n\nDecember\n\n(4)\n\n        ►\n\nNovember\n\n(1)\n\n        ►\n\nSeptember\n\n(1)\n\n        ►\n\nAugust\n\n(3)\n\n        ►\n\nJuly\n\n(3)\n\n        ►\n\nJune\n\n(3)\n\n        ►\n\nMay\n\n(5)\n\n        ►\n\nApril\n\n(4)\n\n        ►\n\nMarch\n\n(3)\n\n        ►\n\nFebruary\n\n(2)\n\n        ►\n\nJanuary\n\n(6)\n\n        ►\n\n2016\n\n(20)\n\n        ►\n\nDecember\n\n(4)\n\n        ►\n\nNovember\n\n(2)\n\n        ►\n\nOctober\n\n(1)\n\n        ►\n\nSeptember\n\n(2)\n\n        ►\n\nAugust\n\n(1)\n\n        ►\n\nJuly\n\n(1)\n\n        ►\n\nJune\n\n(2)\n\n        ►\n\nMay\n\n(2)\n\n        ►\n\nApril\n\n(4)\n\n        ►\n\nMarch\n\n(1)\n\n        ►\n\n2015\n\n(19)\n\n        ►\n\nDecember\n\n(2)\n\n        ►\n\nNovember\n\n(3)\n\n        ►\n\nOctober\n\n(3)\n\n        ►\n\nSeptember\n\n(2)\n\n        ►\n\nAugust\n\n(3)\n\n        ►\n\nJuly\n\n(5)\n\n        ►\n\nJune\n\n(1)\n\nSimple theme. Powered by Blogger.",
    "summary": {
      "en": "**Summary of \"Writing Your Own C++ Standard Library from Scratch\"**\n\nJussi Pakkanen, known for creating the Meson build system, discusses the possibility of creating a custom C++ standard library, highlighting the issues with the existing C++ standard library (STL), such as long compile times and readability problems. He suggests that developers can entirely disable the STL and build their own library, which he calls \"pystd\".\n\nThe goal of this project is to create a minimal library that can handle basic tasks like reading a text file, validating it as UTF-8, counting word occurrences, and sorting results. This involves implementing file handling, strings, UTF-8 validation, hash maps, vectors, and sorting functions.\n\nPakkanen shares his experience of disabling the STL using specific commands in Meson and notes that building the library required under 1000 lines of code, compared to the STL's vast size. He points out that while the performance of both versions is similar, the custom library compiles significantly faster.\n\nAn essential feature of pystd is its design for perfect ABI (Application Binary Interface) stability, allowing developers to update their code at their own pace without breaking existing functionality. Each year, a new version of the library can be released, maintaining older versions for compatibility.\n\nIn conclusion, by creating a custom C++ standard library, developers can avoid the drawbacks of the STL while maintaining flexibility and control over their code.",
      "ko": "유명한 Meson 빌드 시스템의 개발자인 유시 파카넨은 사용자 정의 C++ 표준 라이브러리를 만드는 가능성에 대해 이야기합니다. 그는 기존 C++ 표준 라이브러리(STL)의 문제점, 즉 긴 컴파일 시간과 가독성 문제를 강조합니다. 파카넨은 개발자들이 STL을 완전히 비활성화하고 자신만의 라이브러리인 \"pystd\"를 구축할 수 있다고 제안합니다.\n\n이 프로젝트의 목표는 텍스트 파일을 읽고, UTF-8로 유효성을 검사하며, 단어 발생 횟수를 세고, 결과를 정렬하는 등의 기본 작업을 처리할 수 있는 최소한의 라이브러리를 만드는 것입니다. 이를 위해 파일 처리, 문자열, UTF-8 유효성 검사, 해시 맵, 벡터 및 정렬 함수 등을 구현해야 합니다.\n\n파카넨은 Meson에서 특정 명령어를 사용하여 STL을 비활성화한 경험을 공유하며, 이 라이브러리를 구축하는 데 1000줄 이하의 코드가 필요했다고 언급합니다. 이는 STL의 방대한 크기에 비해 매우 적은 양입니다. 그는 두 버전의 성능이 비슷하지만, 사용자 정의 라이브러리가 훨씬 더 빠르게 컴파일된다고 지적합니다.\n\npystd의 중요한 특징 중 하나는 완벽한 ABI(응용 프로그램 이진 인터페이스) 안정성을 위해 설계되었다는 점입니다. 이를 통해 개발자들은 기존 기능을 손상시키지 않으면서 자신의 속도로 코드를 업데이트할 수 있습니다. 매년 새로운 버전의 라이브러리를 출시하면서도 이전 버전은 호환성을 위해 유지할 수 있습니다.\n\n결론적으로, 사용자 정의 C++ 표준 라이브러리를 만들면 개발자들은 STL의 단점을 피하면서 코드에 대한 유연성과 제어를 유지할 수 있습니다.",
      "ja": "Jussi Pakkanenは、Mesonビルドシステムの開発者として知られていますが、独自のC++標準ライブラリを作成する可能性について語っています。彼は、既存のC++標準ライブラリ（STL）の問題点、例えば長いコンパイル時間や可読性の低さを指摘しています。開発者はSTLを完全に無効にし、「pystd」と呼ばれる自分自身のライブラリを構築できると提案しています。\n\nこのプロジェクトの目的は、テキストファイルの読み込み、UTF-8としての検証、単語の出現回数のカウント、結果のソートなどの基本的なタスクを処理できる最小限のライブラリを作成することです。これには、ファイル処理、文字列、UTF-8の検証、ハッシュマップ、ベクター、ソート関数の実装が含まれます。\n\nPakkanenは、Mesonを使用してSTLを無効にするための特定のコマンドを使った経験を共有し、このライブラリの構築には1000行未満のコードが必要だったと述べています。これは、STLの膨大なサイズと比較して非常に少ない行数です。両方のバージョンのパフォーマンスは似ていますが、カスタムライブラリはコンパイルが大幅に速いことを指摘しています。\n\npystdの重要な特徴は、完璧なABI（アプリケーションバイナリインターフェース）安定性を考慮して設計されていることです。これにより、開発者は既存の機能を壊すことなく、自分のペースでコードを更新できます。毎年新しいバージョンのライブラリをリリースし、互換性のために古いバージョンを維持することが可能です。\n\n独自のC++標準ライブラリを作成することで、開発者はSTLの欠点を回避しつつ、コードに対する柔軟性と制御を維持できるということです。"
    }
  },
  {
    "id": "13d4eb798a832725",
    "title": {
      "en": "The Vatican's Latinist (2017)",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://newcriterion.com/article/the-vaticans-latinist/",
    "score": 142,
    "by": "bookofjoe",
    "time": 1742779791,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  }
]