[
  {
    "id": "981caf3cbe377770",
    "title": {
      "en": "We hacked Gemini's Python sandbox and leaked its source code (at least some)",
      "ko": "ì œë¯¸ë‹ˆ íŒŒì´ì¬ í•´í‚¹!",
      "ja": null
    },
    "type": "story",
    "url": "https://www.landh.tech/blog/20250327-we-hacked-gemini-source-code/",
    "score": 277,
    "by": "topsycatt",
    "time": 1743185578,
    "content": "<<Back to BlogWe hacked Googleâ€™s A.I Gemini and leaked its source code (at least some part)Mar 27, 2025RONI CARTA | LUPINgemini, llm, google, source code, leak, bug bounty, hackBack to Vegas, and This Time, We Brought Home the MVH Award !\nIn 2024 we released the blog post We Hacked Google A.I. for $50,000, where we traveled in 2023 to Las Vegas with Joseph \"rez0\" Thacker, Justin \"Rhynorater\" Gardner, and myself, Roni \"Lupin\" Carta, on a hacking journey that spanned from Las Vegas, Tokyo to France, all in pursuit of Gemini vulnerabilities during Google's LLM bugSWAT event. Well, we did it again â€¦\nThe world of Generative Artificial Intelligence (GenAI) and Large Language Models (LLMs) continues to be the Wild West of tech.  Since GPT burst onto the scene, the race to dominate the LLM landscape has only intensified, with tech giants like Meta, Microsoft, and Google racing to have the best model possible. But now there is also Anthropic, Mistral, Deepseek and more that are coming to the scene and impacting the industry at scale.\nAs companies rush to deploy AI assistants, classifiers, and a myriad of other LLM-powered tools, a critical question remains: are we building securely ?  As we highlighted last year, the rapid adoption sometimes feels like we forgot the fundamental security principles, opening the door to novel and familiar vulnerabilities alike.\nAI agents are rapidly emerging as the next game-changer in the world of artificial intelligence. These intelligent entities leverage advanced chains of thought reasoning, a process where the model generates a coherent sequence of internal reasoning steps to solve complex tasks. By documenting their thought processes, these agents not only enhance their decision-making capabilities but also provide transparency, allowing developers and researchers to understand and refine their performance. This dynamic combination of autonomous action and visible reasoning is paving the way for AI systems that are more adaptive, interpretable, and reliable. As we witness an increasing number of applications. from interactive assistants to sophisticated decision-support systems. The integration of chain-of-thought reasoning in AI agents is setting a new standard for what these models can achieve in real-world scenarios.\nGoogle, to their credit, are actively recognising this emerging frontier of AI security, and they started early on.  Their \"LLM bugSWAT\" events, held in vibrant locales like Las Vegas, are a testament to their commitment to proactive security red teaming.  These events challenge researchers worldwide to rigorously test their AI systems, seeking out the vulnerabilities that might otherwise slip through the cracks.\nAnd guess what ? We answered the call again in 2024 !  Justin and I returned to the bugSWAT event in Las Vegas, and this time, our efforts paid off in a big way.  Thanks to a brand new vulnerability in Gemini,  the one weâ€™re about to detail, we were incredibly honored to be awarded the Most Valuable Hacker (MVH) title at this year's Las Vegas bugSWAT !\n\nPicture taken with our MVH award and 2 awesome Googlers <3\nSo, prepare to dive deep once more.  This isn't just a repeat performance; it's a whole new vulnerability that we are about to show you ;)\nDiscovering the new Gemini\nThe Google team granted us early access to a preview of the next Gemini update, one that had several exciting new features. Along with this exclusive access, we received detailed documentation explaining these features and their intended functionalities. The goal was to fully explore and test these capabilities from an attackerâ€™s perspective.\nIt all started with a simple prompt. We asked Gemini:\nrun hello world in python3\n\nGemini provided the code, and the interface offered the enticing \"Run in Sandbox\" button. Intrigued, we started exploring.\n\nGemini's Python Playground â€“ A Secure Space... or Was It ?\nGemini at the time offered a Python Sandbox Interpreter. Think of it as a safe space where you can run Python code generated by the AI itself, or even your own custom scripts, right within the Gemini environment. This sandbox, powered by Google's Gvisor in a GRTE (Google Runtime Environment), is designed to be secure. The idea is you can experiment with code without risking any harm to the underlying system, a crucial feature for testing and development.\ngVisor is a user-space kernel developed by Google that acts as an intermediary between containerized applications and the host operating system. By intercepting system calls made by applications, it enforces strict security boundaries that reduce the risk of container escapes and limit potential damage from compromised processes. Rather than relying solely on traditional OS-level isolation, gVisor implements a minimal, tailored subset of kernel functionalities, thereby reducing the attack surface while still maintaining reasonable performance. This innovative approach enhances the security of container environments, making gVisor an essential tool for safely running and managing containerized workloads.\nAs security researchers and bug bounty hunters, we know that this gVisor sandbox is secured with multiple layers of defense and from what weâ€™ve seen no one managed to escape this sandbox. Actually a sandbox escape could award you a $100k bounty:\n\nWhile it might be possible to still escape it, this is a whole different set of challenges than what we were looking for.\nHowever, sandboxes are not always meant to be escaped since there are a lot of cases where there is stuff inside the sandbox itself that can help us leak data. This idea, shared with us by a Googler from the security team, was to be able to have shell access inside the Sandbox itself and try to find any piece of data that wasn't supposed to be accessible. The main problem was the following: This sandbox can only run a custom compiled Python binary.\nMapping the Territory\nThe first thing we saw is that it was also possible from the Front End to entirely rewrite the Python code and run our arbitrary version in the sandbox. Our first step was to understand the structure of this sandbox. We suspected there might be interesting files lurking around. Since we canâ€™t pop a shell, we checked which libraries were available in this custom compiled Python binary. We found out that os was present ! Great, we can then use it to map the filesystem.\nWe wrote the following Python Code:\nimport os\n\ndef get_size_formatted(size_in_bytes):\n    if size_in_bytes >= 1024 ** 3:\n        size = size_in_bytes / (1024 ** 3)\n        unit = \"Go\"\n    elif size_in_bytes >= 1024 ** 2:\n        size = size_in_bytes / (1024 ** 2)\n        unit = \"Mb\"\n    else:\n        size = size_in_bytes / 1024\n        unit = \"Ko\"\n    return f\"{size:.2f} {unit}\"\n\ndef lslR(path):\n    try:\n        # Determine if the path is a directory or a file\n        if os.path.isdir(path):\n            type_flag = 'd'\n            total_size = sum(os.path.getsize(os.path.join(path, f)) for f in os.listdir(path))\n        else:\n            type_flag = 'f'\n            total_size = os.path.getsize(path)\n\n        size_formatted = get_size_formatted(total_size)\n\n        # Check read and write permissions\n        read_flag = 'r' if os.access(path, os.R_OK) else '-'\n        write_flag = 'w' if os.access(path, os.W_OK) else '-'\n\n        # Print the type, permissions, size, and path\n        print(f\"{type_flag}{read_flag}{write_flag} - {size_formatted} - {path}\")\n\n        # If it's a directory, recursively print the contents\n        if type_flag == 'd':\n            for entry in os.listdir(path):\n                entry_path = os.path.join(path, entry)\n                lslR(entry_path)\n    except PermissionError:\n        print(f\"d-- - 0Ko - {path} (PermissionError: cannot access)\")\n    except Exception as e:\n        print(f\"--- - 0Ko - {path} (Error: {e})\")\n\nThe goal for this code was to have some kind of recursive listing of files and directories function to be able to see which files are present, their size and also their permissions.\nWeâ€™ve used the function to list the lslR(\"/usr\") directory.\n\nThis call identified a binary file located at /usr/bin/entry/entry_point. This sounds juicy !\n\nLeak the entry_point file\nOur next move was to extract this file, but with it being 579Mb in size, directly base64 encoding and printing it in the Front End wasn't an option, it caused the entire sandbox to hang until it eventually timed out.\nWe attempted to see if we could run TCP, HTTP, and DNS calls to exfiltrate information. Intriguingly, all our outbound connection attempts failed, the sandbox appeared completely isolated from the external network. This led to an interesting puzzle: if the sandbox is so tightly isolated that it cannot make external calls, how does it interface with Google services like Google Flights and others ? Well â€¦ we might be able to answer this later ;D\nSo we needed to exfiltrate this binary by printing in the console into chunks, for that we used the seek() function to walk through the binary file and retrieve the entire binary in chunks of 10 MB.\nimport os\nimport base64\n\ndef read_and_encode(file_path, kilobytes):\n    try:\n        # Calculate the number of bytes to read\n        num_bytes = kilobytes * 1024\n\n        # Open the file and read the specified number of bytes\n        with open(file_path, 'rb') as file:\n            file_content = file.read(num_bytes)\n\n        # Base64 encode the bytes\n        encoded_content = base64.b64encode(file_content)\n\n        # Print the encoded string\n        print(encoded_content.decode('utf-8'))\n\n    except FileNotFoundError:\n        print(f\"FileNotFoundError: {file_path} does not exist\")\n    except PermissionError:\n        print(f\"PermissionError: Cannot access {file_path}\")\n    except Exception as e:\n        print(f\"Error: {e}\")\n\nread_and_encode(\"/usr/bin/entry/entry_point\", 10000)\n\nWe then used Caido to catch the request in our proxy that would run the sandbox call and fetch the result and then send it into the Automate feature. The Automate feature allows you to send requests in bulk. This feature provides a flexible way to initiate bruteforce/fuzzing to rapidly modify certain parameters of requests using wordlists.\n\nNote from Lupin: In the article it seems like a straightforward path, but actually we took several hours to get to that point. It was 3 am we were hacking with Justin and I was sleeping on my keyboard while Justin was exfiltrating the binary using Caido.\n\nOnce we had all the base64 chunks, we reconstructed the entire file locally and we were ready to see its content.\nHow to read this file ?\nfile command ?\nRunning the file command on the binary revealed its identity as an binary: ELF 64-bit LSB shared object, x86-64, version 1 (SYSV), dynamically linked, interpreter /usr/grte/v5/lib64/ld-linux-x86-64.so.2 This  confirms that the file is a binary. Mmmmmh what can we do with this ?\nstrings command ?\nWhen we executed the strings command, the output was particularly intriguing due to multiple references to google3, Googleâ€™s internal repository. This pointed to the presence of internal data paths and code snippets that were never meant for external exposure, clearly indicating that the binary contains traces of Googleâ€™s proprietary software. But is there actually any security implication ?\nBinwalk FTW !\nThe real breakthrough came when using Binwalk. This tool managed to extract an entire file structure from within the binary, revealing a comprehensive sandbox layout. The extraction uncovered multiple directories and files, painting a detailed picture of the internal architecture and exposing components where our reaction upon what we found was like ... OMG.\nWait â€¦ is that internal Source Code ?\nWhen digging into the extract generated by our binwalk analysis, we unexpectedly found internal source code. The extraction revealed entire directories of proprietary Google source code. But is it sensitive ?\nGoogle3 Directory with Python Code\nIn the binwalk extracted directory we can find a google3 directory with the following files:\ntotal 2160\ndrwxr-xr-x   14 lupin  staff   448B Aug  7 06:17 .\ndrwxr-xr-x  231 lupin  staff   7.2K Aug  7 18:31 ..\n-r-xr-xr-x    1 lupin  staff   1.1M Jan  1  1980 __init__.py\ndrwxr-xr-x    5 lupin  staff   160B Aug  7 06:17 _solib__third_Uparty_Scrosstool_Sv18_Sstable_Ccc-compiler-k8-llvm\ndrwxr-xr-x    4 lupin  staff   128B Aug  7 06:17 assistant\ndrwxr-xr-x    4 lupin  staff   128B Aug  7 06:17 base\ndrwxr-xr-x    5 lupin  staff   160B Aug  7 06:17 devtools\ndrwxr-xr-x    4 lupin  staff   128B Aug  7 06:17 file\ndrwxr-xr-x    4 lupin  staff   128B Aug  7 06:17 google\ndrwxr-xr-x    4 lupin  staff   128B Aug  7 06:17 net\ndrwxr-xr-x    9 lupin  staff   288B Aug  7 06:17 pyglib\ndrwxr-xr-x    4 lupin  staff   128B Aug  7 06:17 testing\ndrwxr-xr-x    9 lupin  staff   288B Aug  7 06:17 third_party\ndrwxr-xr-x    4 lupin  staff   128B Aug  7 06:17 util\n\nIn the assistant directory, internal Gemini code related to RPC calls (used for handling requests via tools like YouTube, Google Flights, Google Maps, etc.) was also discovered. The directory structure is as follows:\n.\nâ”œâ”€â”€ __init__.py\nâ””â”€â”€ boq\n    â”œâ”€â”€ __init__.py\n    â””â”€â”€ lamda\n        â”œâ”€â”€ __init__.py\n        â””â”€â”€ execution_box\n            â”œâ”€â”€ __init__.py\n            â”œâ”€â”€ images\n            â”‚   â”œâ”€â”€ __init__.py\n            â”‚   â”œâ”€â”€ blaze_compatibility_hack.py\n            â”‚   â”œâ”€â”€ charts_json_writer.py\n            â”‚   â”œâ”€â”€ format_exception.py\n            â”‚   â”œâ”€â”€ library_overrides.py\n            â”‚   â”œâ”€â”€ matplotlib_post_processor.py\n            â”‚   â”œâ”€â”€ py_interpreter.py\n            â”‚   â”œâ”€â”€ py_interpreter_main.py\n            â”‚   â””â”€â”€ vegalite_post_processor.py\n            â”œâ”€â”€ sandbox_interface\n            â”‚   â”œâ”€â”€ __init__.py\n            â”‚   â”œâ”€â”€ async_sandbox_rpc.py\n            â”‚   â”œâ”€â”€ sandbox_rpc.py\n            â”‚   â”œâ”€â”€ sandbox_rpc_pb2.pyc\n            â”‚   â””â”€â”€ tool_use\n            â”‚       â”œâ”€â”€ __init__.py\n            â”‚       â”œâ”€â”€ metaprogramming.py\n            â”‚       â””â”€â”€ runtime.py\n            â””â”€â”€ tool_use\n                â”œâ”€â”€ __init__.py\n                â””â”€â”€ planning_immersive_lib.py\n\n8 directories, 22 files\n\nA Closer Look at the Python Code\nInside the file google3/assistant/boq/lamda/execution_box/images/py_interpreter.py, a snippet of code reveals:\n# String for attempted script dump detection:\n  snippet = (  # pylint: disable=unused-variable\n      \"3AVp#dzcQj$U?uLOj+Gl]GlY<+Z8DnKh\"  # pylint: disable=unused-variable\n  )\n\nThis snippet appears to serve as a safeguard against unauthorized script dumping, underscoring that the code was never intended for public exposure.\n\nAfter a thorough review, the inclusion of what appeared to be internal Google3 code was, in fact, a deliberate choiceâ€¦ Too bad x)\nThe Python code, despite its anti-dumping mechanism that might initially indicate restricted access, had been explicitly approved for public exposure by the Google Security Team well before launch. Although these measures were originally designed to prevent unintended printing, they were retained because â€¦ why not ?\nBut we didnâ€™t leave this sandbox alone, we knew we were close to something huge ! ;D\nDigging the main logic of the Sandbox\nWhile digging deeper into the Python code, we noticed that, as expected, this sandbox was communicating with external Google servers to perform activities such as fetch data from Google Flights or other Google services.\nThis was implemented via a python class (google3.assistant.boq.lamda.execution_box.sandbox_interface) which exposed various functions like _set_reader_and_writer  that could be called.\ndef _set_reader_and_writer(\n    reader_handle: io.BufferedReader | None,\n    writer_handle: io.BufferedWriter | None,\n) -> None:\n  \"\"\"Sets the reader and writer handles for rpcs.\n\n  Should be called before running any user code that might\n  import async_sandbox_rpc\n\n  Args:\n    reader_handle: the handle through which to receive incoming RpcResponses. If\n      None will default to legacy behavior (/dev/fd/3)\n    writer_handle: the handle through which to receive incoming RpcRequests. If.\n      None will default to legacy behavior (/dev/fd/4)\n  \"\"\"\n  with _INIT_LOCK:\n    global _READER_HANDLE\n    global _WRITER_HANDLE\n    _READER_HANDLE, _WRITER_HANDLE = reader_handle, writer_handle\n\ndef run_tool(\n    name: str, operation_id: str, parameters: str\n) -> sandbox_rpc_pb2.RunToolResponse:\n  \"\"\"Runs a tool with the given name and id, passing in parameters.\n\n  Args:\n    name: The name of the tool.\n    operation_id: The name of the operation to perform.\n    parameters: The parameters to pass to the tool.\n\n  Returns:\n    A RunToolResponse containing the response from the tool.\n  \"\"\"\n  result = make_rpc(\n      sandbox_rpc_pb2.RpcRequest(\n          run_tool_request=sandbox_rpc_pb2.RunToolRequest(\n              name=name, operation_id=operation_id, parameters=parameters\n          )\n      )\n  )\n\n  if result and result.HasField(\"run_tool_response\"):\n    return result.run_tool_response\n  else:\n    return sandbox_rpc_pb2.RunToolResponse(response=\"\")\n\nWe would provide various pieces of data to these functions, they would serialize the data into the protobuf compatible format, and then call out over RPC by writing to a local file descriptor 5. The response could then be read by reading from local file descriptor 7. By utilizing the protos that were found in the massive binary, we were able to craft messages to and from this RPC server, and call these Google tools directly.\nHowever, we noticed something interesting, not every sandboxes would have the same set of Google services available. It would depend if the sandbox was spawned by the Front End to be able to run Python source code, or by the Google Agent. What do we mean by that ?\nReAct Research paper !\nBefore explaining the next part, we need to explain that Googleâ€™s team showed us the following research paper that Gemini is based of:\n\nREACT: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS\n\nThis paper introduces a novel approach (at the time) where language models alternate between generating reasoning traces and executing specific actions, effectively merging thought and behavior in an interleaved manner. In practice, this means that as the model reasons through a problem, creating a transparent trail of thought that helps it plan, track, and adjust its actions, it simultaneously interacts with external sources to gather additional data when needed. This dynamic interplay not only boosts the modelâ€™s performance by mitigating common issues like hallucination and error propagation but also makes its decision-making process more interpretable and controllable for human operators.\nBy integrating both internal reasoning and external knowledge, ReAct offers a flexible and general framework that excels across a variety of tasks, ranging from question answering and fact verification to text-based games and web navigation. In essence, ReAct leverages the combined strengths of reasoning and acting to create more robust, human-aligned, and versatile language models.\n\nOk, but why do we need to understand this ? Well, if we follow the logic of this paper, basically Gemini can prompt itself several times in order to refine the commands and have a proper chain of thoughts.\nIf a user asks â€œWhat is the earliest flight between Toronto and New York ?â€, Gemini would have roughly a chain of thought like:\n\nThe user is asking me to search the earliest flight between Toronto and New York\n\nCreating a plan like:\n\nI need to run a Python code that will connect to Google Flights tool\nThe code needs to find all flights from today to next week from YYZ airport to JFK airport\nThe code needs to sort by date the flights and take the first item\n\nOnce the plan done, it would generate the code with the available Tools that the Agent has\n\nOnce the code generated, it would spawn a sandbox with the right privileges (eg: having access to the Google Flights tool through the file descriptor)\n\nRun the code, process the output\n\nMakes a response to the user\n\nSo our theory was the following:\n\nWhat if we could do a secondary prompt injection in the planning section of Gemini in order to have access to a more privileged sandbox ?\n\nWith the help of the Google Security Team, we tested this idea and observed that, depending on factors like the generation seed and temperature (all the usual probabilistic LLM nuances), we could occasionally access what appeared to be a more privileged sandbox.\nBy â€œmore privileged sandbox,â€ we mean one that can access the extensions through two new file descriptors. These file descriptors are always present but arenâ€™t always actively listening, when the agent calls the sandbox, they monitor for any calls to the extensions (Google services) so that we can interact with the API, whereas if accessed through the Python interpreter, those extensions remain inaccessible.\nThis led us to believe that there was a real opportunity for a P0 vulnerability: there was a specific message handler that might allow a file read on Googleâ€™s internal infrastructure, and we were hopeful that the sandbox with the tool extension could initiate an RPC call to this specific tool. Given the probabilistic nature of the attack, which made it difficult to reproduce consistently, we have Google Security Team assess this situation. Ultimately, their review revealed that the suspicious message handler was not available via RPC and could only be called externally.\n\nEven though our tests were limited, the core idea still has some real potential if we push it further. Running code in the sandbox context isnâ€™t meant to give extra powers, it's treated as untrusted, with safety checks outside the sandbox and every tool call being filtered. But being able to run code does offer some neat benefits:\n\nReliability: Once you can run code, you can trigger actions more consistently.\n\nChaining/Complexity: Controlling multiple tools or fine-tuning parameters via plain text is tough; code execution could let you build more complex chains, even if safety measures are still in place.\n\nTool Output Poisoning: You might be able to manipulate a toolâ€™s output more effectively.\n\nLeaks: There could be other hidden parts of the environment that, if exposed, might offer extra advantages.\n\nThis shows that our idea still holds promise for further escalation. And that â€œleaksâ€ potential, we wanted to see if we could at least confirm this one theory â€¦\nWe found our leak ;D\nWhile digging deeper, we uncovered several ways to leak proto files. In case you're not familiar, proto files (short for Protocol Buffer files) are like the blueprints of data, defining how messages are structured and how information is exchanged between different parts of the system. At first glance, they might seem harmless, but leaking these files can give a pretty detailed peek into Googleâ€™s internal architecture.\nExposing classification.proto\nIt turns out that by running a command like:\nstrings entry_point > stringsoutput.txt\n\nand then searching for â€œDogfoodâ€ in the resulting file, we managed to retrieve snippets of the internal protos. Parts of the extracted content included the metadata description of extremely sensitive protos. It didnâ€™t contain user data by itself but those files are internal categories Google uses to classify user data.\nFor legal reasons we canâ€™t show the result of this command x)\n\nWhy search for the string â€œDogfoodâ€ specifically ? At Google, \"dogfood\" refers to the practice of using pre-release versions of the company's own products and prototypes internally to test and refine them before a public launch. It allows devs to test the deployment and potential issues in these products, before going to production.\nMoreover, there was the following exposed file, privacy/data_governance/attributes/proto/classification.proto, which details how data is classified within Google. Although the file includes references to associated documentation, those documents remain highly confidential and should not be publicly accessible.\n\nNote from Lupin again: This was found the next day of our all-nighter where we exfiltrated the binary file. We were in a suite in an Hotel Room booked by Google, and we were working with the security team to understand what we had found the previous night. This time Justin was the one who slept on the couch hahaha ! This bug was really time consuming but so fun ! ğŸ˜€\n\nExposing Internal Security Proto Definitions\nThe same output also reveals numerous internal proto files that should have remained hidden. Running:\ncat stringsoutput.txt| grep '\\.proto' | grep 'security'\n\nlists several sensitive files, including:\nsecurity/thinmint/proto/core/thinmint_core.proto\nsecurity/thinmint/proto/thinmint.proto\nsecurity/credentials/proto/authenticator.proto\nsecurity/data_access/proto/standard_dat_scope.proto\nsecurity/loas/l2/proto/credstype.proto\nsecurity/credentials/proto/end_user_credentials.proto\nsecurity/loas/l2/proto/usertype.proto\nsecurity/credentials/proto/iam_request_attributes.proto\nsecurity/util/proto/permission.proto\nsecurity/loas/l2/proto/common.proto\nops/security/sst/signalserver/proto/ss_data.proto\nsecurity/credentials/proto/data_access_token_scope.proto\nsecurity/loas/l2/proto/identity_types.proto\nsecurity/credentials/proto/principal.proto\nsecurity/loas/l2/proto/instance.proto\nsecurity/credentials/proto/justification.proto\n\nWhen looking in the binary strings for security/credentials/proto/authenticator.proto confirms that its data is indeed exposed.\nWhy were those protos there?\nAs we said previously, the Google Security Team thoroughly reviewed everything in the sandbox and gave a green light for public disclosure. However, the build pipeline for compiling the sandbox binary included an automated step that adds security proto files to a binary whenever it detects that the binary might need them to enforce internal rules.\nIn this particular case, that step wasnâ€™t necessary, resulting in the unintended inclusion of highly confidential internal protos in the wild !\nAs bug bounty hunters, it's essential to deeply understand the business rules that govern a companyâ€™s operations. We reported these proto leaks because we know that Google treats them as highly confidential information that should never be exposed. The more we understand the inner workings and priorities of our target, the better we are at identifying and flaging those subtle bugs that might otherwise slip under the radar. This deep knowledge not only helps us pinpoint vulnerabilities but also ensures our reports are aligned with the critical security concerns of the organization.\nConclusion\nBefore we wrap things up, itâ€™s worth mentioning how vital it is to test these cutting-edge A.I. systems before they go live. With so many interconnections and cool features, like even a simple sandbox that can access different extensions, thereâ€™s always the potential for unexpected surprises. Weâ€™ve seen firsthand that when all these parts work together, even a small oversight can open up new avenues for issues. So, thorough testing isnâ€™t just a best practice; itâ€™s the only way to make sure everything stays secure and functions as intended.\nAt the end of the day, what made this whole experience so memorable was the pure fun of the ride. Cracking vulnerabilities, exploring hidden code, and pushing the limits of Gemini's sandbox was as much about the challenge as it was about the excitement of the hunt. The people weâ€™ve met at the bugSWAT event in Las Vegas were all awesome. The shared laughs over unexpected twists, and the thrill of outsmarting complex systems turned this technical journey into an adventure weâ€™ll never forget. Itâ€™s moments like these, where serious hacking meets good times, that remind us why we do what we do.\nFinally, a huge shout-out to all the other winners and participants who made bugSWAT 2024 such a blast. We want to congratulate Sreeram & Sivanesh for their killer teamwork, Alessandro for coming so close to that top spot, and En for making it onto the podium. It was an absolute thrill meeting so many amazing hackers and security pros, your energy and passion made this event unforgettable. We canâ€™t wait to see everyone again at the next bugSWAT, and until then, keep hacking and having fun !\nAnd of course, thanks to the Google Security team ! As always you rock â¤ï¸<<Back to Blog",
    "summary": {
      "en": "In March 2025, a group of hackers, including Roni Carta, Justin Gardner, and Joseph Thacker, successfully discovered and leaked parts of Google's A.I. model, Gemini, during a bug-hunting event in Las Vegas. Their journey highlighted the rapid advancements and security challenges in Generative Artificial Intelligence (GenAI) and Large Language Models (LLMs), as tech companies compete to improve their AI offerings.\n\nGoogle has been proactive in addressing security by hosting events like \"LLM bugSWAT,\" where researchers identify vulnerabilities in AI systems. At the 2024 event, Roni and Justin earned the Most Valuable Hacker (MVH) title for uncovering a new vulnerability in Gemini.\n\nThey explored Gemini's secure Python Sandbox, designed to allow safe code execution. However, they discovered ways to access the internal file system and exfiltrate sensitive data by manipulating the sandbox environment. This led to finding internal Google source code and proto files, which define the structure of data exchange within Google's systems.\n\nThe hackers reported their findings to Google, emphasizing the importance of thorough testing in AI systems to prevent potential vulnerabilities. Their experience at bugSWAT was not only about hacking but also about building connections within the cybersecurity community. They look forward to future events and continued collaboration with security professionals.",
      "ko": "2025ë…„ 3ì›”, í•´ì»¤ ê·¸ë£¹ì´ ë¼ìŠ¤ë² ê°€ìŠ¤ì—ì„œ ì—´ë¦° ë²„ê·¸ í—ŒíŒ… í–‰ì‚¬ì—ì„œ êµ¬ê¸€ì˜ ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì¸ ì œë¯¸ë‹ˆì˜ ì¼ë¶€ë¥¼ ë°œê²¬í•˜ê³  ìœ ì¶œí•˜ëŠ” ë° ì„±ê³µí–ˆìŠµë‹ˆë‹¤. ì´ ê·¸ë£¹ì—ëŠ” ë¡œë‹ˆ ì¹´ë¥´íƒ€, ì €ìŠ¤í‹´ ê°€ë“œë„ˆ, ì¡°ì…‰ íƒœì»¤ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì´ë“¤ì˜ ì—¬ì •ì€ ìƒì„±ì  ì¸ê³µì§€ëŠ¥(GenAI)ê³¼ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì—ì„œì˜ ë¹ ë¥¸ ë°œì „ê³¼ ë³´ì•ˆ ë¬¸ì œë¥¼ ê°•ì¡°í•˜ë©°, ê¸°ìˆ  ê¸°ì—…ë“¤ì´ AI ì œí’ˆì„ ê°œì„ í•˜ê¸° ìœ„í•´ ê²½ìŸí•˜ê³  ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.\n\nêµ¬ê¸€ì€ \"LLM bugSWAT\"ì™€ ê°™ì€ í–‰ì‚¬ë¥¼ ê°œìµœí•˜ì—¬ AI ì‹œìŠ¤í…œì˜ ì·¨ì•½ì ì„ ì‹ë³„í•˜ëŠ” ì—°êµ¬ìë“¤ì„ ì§€ì›í•˜ë©° ë³´ì•ˆ ë¬¸ì œì— ì ê·¹ì ìœ¼ë¡œ ëŒ€ì‘í•˜ê³  ìˆìŠµë‹ˆë‹¤. 2024ë…„ í–‰ì‚¬ì—ì„œ ë¡œë‹ˆì™€ ì €ìŠ¤í‹´ì€ ì œë¯¸ë‹ˆì—ì„œ ìƒˆë¡œìš´ ì·¨ì•½ì ì„ ë°œê²¬í•˜ì—¬ ê°€ì¥ ê°€ì¹˜ ìˆëŠ” í•´ì»¤(MVH)ë¡œ ì„ ì •ë˜ì—ˆìŠµë‹ˆë‹¤.\n\nê·¸ë“¤ì€ ì•ˆì „í•œ ì½”ë“œ ì‹¤í–‰ì„ ìœ„í•´ ì„¤ê³„ëœ ì œë¯¸ë‹ˆì˜ ë³´ì•ˆ íŒŒì´ì¬ ìƒŒë“œë°•ìŠ¤ë¥¼ íƒìƒ‰í–ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ìƒŒë“œë°•ìŠ¤ í™˜ê²½ì„ ì¡°ì‘í•˜ì—¬ ë‚´ë¶€ íŒŒì¼ ì‹œìŠ¤í…œì— ì ‘ê·¼í•˜ê³  ë¯¼ê°í•œ ë°ì´í„°ë¥¼ ìœ ì¶œí•  ìˆ˜ ìˆëŠ” ë°©ë²•ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ì´ ê³¼ì •ì—ì„œ êµ¬ê¸€ì˜ ë‚´ë¶€ ì†ŒìŠ¤ ì½”ë“œì™€ ë°ì´í„° êµí™˜ êµ¬ì¡°ë¥¼ ì •ì˜í•˜ëŠ” í”„ë¡œí†  íŒŒì¼ì„ ì°¾ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.\n\ní•´ì»¤ë“¤ì€ êµ¬ê¸€ì— ì´ findingsë¥¼ ë³´ê³ í•˜ë©° AI ì‹œìŠ¤í…œì—ì„œ ì ì¬ì ì¸ ì·¨ì•½ì ì„ ë°©ì§€í•˜ê¸° ìœ„í•´ ì² ì €í•œ í…ŒìŠ¤íŠ¸ì˜ ì¤‘ìš”ì„±ì„ ê°•ì¡°í–ˆìŠµë‹ˆë‹¤. bugSWATì—ì„œì˜ ê²½í—˜ì€ ë‹¨ìˆœí•œ í•´í‚¹ì„ ë„˜ì–´ ì‚¬ì´ë²„ ë³´ì•ˆ ì»¤ë®¤ë‹ˆí‹° ë‚´ì—ì„œì˜ ì—°ê²°ì„ êµ¬ì¶•í•˜ëŠ” ë°ì—ë„ í° ì˜ë¯¸ê°€ ìˆì—ˆìŠµë‹ˆë‹¤. ê·¸ë“¤ì€ ì•ìœ¼ë¡œì˜ í–‰ì‚¬ì™€ ë³´ì•ˆ ì „ë¬¸ê°€ë“¤ê³¼ì˜ ì§€ì†ì ì¸ í˜‘ì—…ì„ ê¸°ëŒ€í•˜ê³  ìˆìŠµë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "861c898eec47ed74",
    "title": {
      "en": "There's a psychological burden of digital life even heavier than distraction",
      "ko": "ë””ì§€í„¸ ì‚¶ì˜ ì‹¬ë¦¬ì  ì§",
      "ja": null
    },
    "type": "story",
    "url": "https://www.chrbutler.com/digital-echoes-and-unquiet-minds",
    "score": 34,
    "by": "delaugust",
    "time": 1743193772,
    "content": "Digital Echoes and Unquiet Minds\n\nThereâ€™s a psychological burden of digital life even heavier than distraction.\n\nWhen the iPhone was first introduced in 2007, the notion of an â€œeverything deviceâ€ was universally celebrated. A single object that could serve as phone, camera, music player, web browser, and so much more promised unprecedented convenience and connectivity. It was, quite literally, the dream of the nineties. But the better part of twenty years later, weâ€™ve gained enough perspective to recognize that this revolutionary vision came with costs we did not anticipate.\n\nDistraction, of course, is the one we can all relate to first. An everything device has the problem of being useful nearly all the time, and when in use, all consuming. When you use it to do one thing, it pushes you toward others. In order to avoid this, you must disable functions. Thatâ€™s an interesting turn of events, isnâ€™t it? We have made a thing that does more than we need, more often than we desire. Because system-wide, duplicative notifications are enabled by default, the best thing you could say about the deviceâ€™s design is that it lacks a point of view toward a prioritization of what it does. The worst thing you could say is that it is distracting by design.\n\n(I find it fascinating how many people â€“myself includedâ€‰â€”â€‰attempt to reduce the features of their smartphone to the point of replicating a â€œdumbphoneâ€ experience in order to save ourselves from distraction, but donâ€™t actually go so far as to use a lesser-featured phone because a few key features are just too good to give up. A dumbphone is less distracting, but a nightmare for text messaging and a lousy camera. It turns out I donâ€™t want a phone at all, but a camera that textsâ€‰â€”â€‰and ideally one smaller than anything on the market now. I know Iâ€™m not alone, and yet this product will not be made. )\n\nThis kind of distraction is direct distraction. Itâ€™s the kind we are increasingly aware of, and as its accumulating stress puts pressure on our inner and outer lives, we can combat it with various choices and optimizations. But there is another kind of distraction that is less direct, though just as cumulative and, I believe, just as toxic. Iâ€™ve come to think of it as the â€œdigital echo.â€\n\nOn a smartphone, every single thing it is used to do generates information that goes elsewhere. The vast majority of this is unseenâ€‰â€”â€‰though not unfeltâ€‰â€”â€‰by us. Everyone knows that there is no privacy within a digital device, nor within its â€œlisteningâ€ range. We are all aware that as much information as smartphone provides to us, exponentially more is generated for someone elseâ€‰â€”â€‰someone watching, listening, measuring, and monetizing. The â€œdigital echoâ€ is more than just the awareness of this; it is the cognitive burden of knowing that our actions generate data elsewhere. The echo exists whenever we use connected technology, creating a subtle but persistent awareness that what we do isnâ€™t just our own. A device like a smartphone has always generated a â€œdigital echoâ€, but many others are as well.\n\nComparing two different motor vehicles illustrates this well. In a car like a Tesla, which we might think of as a â€œsmartcarâ€ since itâ€™s a computer you can drive, every function produces a digital signal. Adjusting the air conditioning, making a turn, opening a doorâ€‰â€”â€‰the car knows and records it all, transmitting this information to distant servers. By contrast, my 15-year-old Honda performs all of its functions without creating these digital echoes. The operations remain private, existing only in the moment they occur. In our increasingly digital world, I have begun to feel the SCIF-like isolation of the cabin of my car, and I like it.\n\n(The â€œsmartcarâ€, of course, wonâ€™t remain simply a computer you can drive. The pinnacle â€œsmartcarâ€ drives itself. The self-driving car represents perhaps the most acute expression of how digital culture values attention and convenience above all else, especially control and ownership. As a passenger of a self-driving car, you surrender control over the vehicleâ€™s operation in exchange for the â€œfreedomâ€ to direct your attention elsewhere, most likely to some digital signal either on your own device or on screens within the vehicle. I can see the value in this; driving can be boring and most times I am behind the wheel Iâ€™d rather be doing something else. But currently, truly autonomous vehicles are service-enabling products like Waymo, meaning we also relinquish ownership. The benefits of that also seem obvious: no insurance premiums, no maintenance costs. But not every advantage is worth its cost. The economics of self-driving cars are not clear-cut. Thereâ€™s a real debate to be had about\nattention, convenience, and ownership that I hope will play out before we have no choice but to be a passenger in someone elseâ€™s machine.)\n\nWhen I find myself looking for new ways to throttle my smartphoneâ€™s functions, or when I sit in the untapped isolation of my car, I often wonder about the costs of the â€œdigital echo.â€ What is the psychological cost of knowing that your actions arenâ€™t just your own, but create information that can be observed and analyzed by others? As more aspects of our lives generate digital echoes, they force an ambient awareness of being perpetually witnessed rather than simply existing.\n\nThis transforms even solitary activities into implicit social interactions. It forces us to maintain awareness of our â€œobserved selfâ€ alongside our â€œexperiencing self,â€ creating a kind of persistent self-consciousness. We become performers in our own lives rather than merely participants.\n\nI think this growing awareness contributes to a growing interest in returning to single-focus devices and analog technologies. Record players and film cameras arenâ€™t experiencing resurgence merely from nostalgia, but because they offer fundamentally different relationships with mediaâ€‰â€”â€‰relationships characterized by intention, presence, and focus.\n\nIn my own life, this recognition has led to deliberate choices about which technologies to embrace and which to avoid. Here are three off the top of my head:\n\nReplacing streaming services with owned media formats (CDs, Blu-rays) that remain accessible on my terms, not subject to platform changes or content disappearance\n\nPreferring printed books while using dedicated e-readers for digital textsâ€‰â€”â€‰in this case, accepting certain digital echoes when the benefits (in particular, access to otherwise unavailable material) outweigh the costs\n\nRejecting smart home devices entirely, recognizing that their convenience rarely justifies the added complexity and surveillance they introduce\n\nYouâ€™ve probably made similarly-motivated decisions, perhaps in other areas of your life or in relation to other things entirely. What matters, I think, is that these choices arenâ€™t about rejecting technology but about creating spaces for more intentional engagement. They represent a search for balance in a world that increasingly defaults to maximum connectivity.\n\nI had a conversation recently with a friend who mused, â€œWhat are these the early days of?â€ What a wonderful question that is; we are, I hope, always living in the early days of something. Perhaps now, weâ€™re witnessing the beginning of a new phase in our relationship with technology. The initial wave of digital transformation prioritized connecting everything possible; the next wave may be more discriminating about what should be connected and whatâ€™s better left direct and immediate. I hope to see operating systems truly designed around focus rather than multitasking, interfaces that respect attention rather than constantly competing for it, and devices that serve discrete purposes exceptionally well instead of performing multiple functions adequately.\n\nThe digital echoes of our actions will likely continue to multiply, but we can choose which echoes weâ€™re willing to generate and which activities deserve to remain ephemeralâ€‰â€”â€‰to exist only in the moment they occur and then in the memories of those present. What looks like revision or retreat may be the next wave of innovation, borne out of having learned the lessons of the last few decades and desiring better for the next.\n\n        Written by Christopher Butler on March 28, 2025\n\n        Tagged\n        Essays\n\n      Â© Christopher Butler. All rights reserved.\n      Now\n      About this Website\n      Newsletter\n      RSS",
    "summary": {
      "en": "**Summary of \"Digital Echoes and Unquiet Minds\"**\n\nThe rise of smartphones, starting with the iPhone in 2007, has brought significant convenience but also unexpected psychological burdens. One major issue is distraction; smartphones are designed to keep users engaged, often leading to attempts to limit their features. Many people try to replicate a simpler phone experience without fully giving up the benefits of smartphones.\n\nBeyond distraction, there's a deeper issue called the \"digital echo,\" which refers to the constant awareness that our actions on digital devices generate data that is collected and monitored by others. This knowledge creates a feeling of being perpetually observed, which can make even solitary activities feel social and lead to self-consciousness.\n\nThe author notes a growing interest in simpler, analog technologies, such as record players and film cameras, as they encourage more intentional engagement with media. The article discusses personal choices to limit digital echoes, like preferring physical media over streaming and avoiding smart home devices due to their surveillance aspects.\n\nUltimately, the author hopes for a future where technology prioritizes focus and intentionality rather than constant connectivity, suggesting that the next phase of digital innovation will involve a more careful selection of what should be connected.",
      "ko": "ìŠ¤ë§ˆíŠ¸í°ì˜ ë“±ì¥ì€ 2007ë…„ ì•„ì´í°ì„ ì‹œì‘ìœ¼ë¡œ í° í¸ë¦¬í•¨ì„ ê°€ì ¸ì™”ì§€ë§Œ, ì˜ˆìƒì¹˜ ëª»í•œ ì‹¬ë¦¬ì  ë¶€ë‹´ë„ ì•ˆê²¼ìŠµë‹ˆë‹¤. ê°€ì¥ í° ë¬¸ì œ ì¤‘ í•˜ë‚˜ëŠ” ì£¼ì˜ ì‚°ë§Œì…ë‹ˆë‹¤. ìŠ¤ë§ˆíŠ¸í°ì€ ì‚¬ìš©ìë¥¼ ê³„ì† ëŒì–´ë“¤ì´ë„ë¡ ì„¤ê³„ë˜ì–´ ìˆì–´, ë§ì€ ì‚¬ëŒë“¤ì´ ê¸°ëŠ¥ì„ ì œí•œí•˜ë ¤ê³  ì‹œë„í•©ë‹ˆë‹¤. ë§ì€ ì´ë“¤ì´ ìŠ¤ë§ˆíŠ¸í°ì˜ ì¥ì ì„ ì™„ì „íˆ í¬ê¸°í•˜ì§€ ì•Šìœ¼ë©´ì„œë„ ë” ê°„ë‹¨í•œ ì „í™” ê²½í—˜ì„ ì¶”êµ¬í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n\nì£¼ì˜ ì‚°ë§Œì„ ë„˜ì–´ì„œ, 'ë””ì§€í„¸ ì—ì½”'ë¼ëŠ” ë” ê¹Šì€ ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ìš°ë¦¬ê°€ ë””ì§€í„¸ ê¸°ê¸°ì—ì„œ í•˜ëŠ” í–‰ë™ì´ ë°ì´í„°ë¡œ ìƒì„±ë˜ì–´ ë‹¤ë¥¸ ì‚¬ëŒì— ì˜í•´ ìˆ˜ì§‘ë˜ê³  ê°ì‹œëœë‹¤ëŠ” ì§€ì†ì ì¸ ì¸ì‹ì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ì¸ì‹ì€ ëŠì„ì—†ì´ ê´€ì°°ë‹¹í•˜ëŠ” ëŠë‚Œì„ ì£¼ì–´, í˜¼ì í•˜ëŠ” í™œë™ì¡°ì°¨ë„ ì‚¬íšŒì ì¸ ëŠë‚Œì„ ì£¼ê³  ìì˜ì‹ì„ ìœ ë°œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nì €ìëŠ” ë ˆì½”ë“œ í”Œë ˆì´ì–´ë‚˜ í•„ë¦„ ì¹´ë©”ë¼ì™€ ê°™ì€ ë” ê°„ë‹¨í•œ ì•„ë‚ ë¡œê·¸ ê¸°ìˆ ì— ëŒ€í•œ ê´€ì‹¬ì´ ì»¤ì§€ê³  ìˆë‹¤ê³  ì–¸ê¸‰í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ê¸°ìˆ ì€ ë¯¸ë””ì–´ì™€ì˜ ë” ì˜ë„ì ì¸ ìƒí˜¸ì‘ìš©ì„ ì´‰ì§„í•©ë‹ˆë‹¤. ì´ ê¸€ì—ì„œëŠ” ìŠ¤íŠ¸ë¦¬ë° ëŒ€ì‹  ë¬¼ë¦¬ì ì¸ ë¯¸ë””ì–´ë¥¼ ì„ í˜¸í•˜ê±°ë‚˜ ê°ì‹œ ì¸¡ë©´ ë•Œë¬¸ì— ìŠ¤ë§ˆíŠ¸ í™ˆ ê¸°ê¸°ë¥¼ í”¼í•˜ëŠ” ë“± ë””ì§€í„¸ ì—ì½”ë¥¼ ì œí•œí•˜ê¸° ìœ„í•œ ê°œì¸ì ì¸ ì„ íƒì— ëŒ€í•´ ë…¼ì˜í•©ë‹ˆë‹¤.\n\nê²°êµ­ ì €ìëŠ” ê¸°ìˆ ì´ ëŠì„ì—†ëŠ” ì—°ê²°ë³´ë‹¤ëŠ” ì§‘ì¤‘ê³¼ ì˜ë„ì„±ì„ ìš°ì„ ì‹œí•˜ëŠ” ë¯¸ë˜ë¥¼ í¬ë§í•©ë‹ˆë‹¤. ë‹¤ìŒ ë””ì§€í„¸ í˜ì‹ ì˜ ë‹¨ê³„ëŠ” ë¬´ì—‡ì„ ì—°ê²°í• ì§€ì— ëŒ€í•œ ë” ì‹ ì¤‘í•œ ì„ íƒì„ í¬í•¨í•  ê²ƒì´ë¼ê³  ì œì•ˆí•©ë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "f068670bb2ee81fe",
    "title": {
      "en": "Xee: A Modern XPath and XSLT Engine in Rust",
      "ko": "ì—‘ìŠ¤ì´: ëŸ¬ìŠ¤íŠ¸ë¡œ ë§Œë“  í˜„ëŒ€ì  XPath/XSLT ì—”ì§„",
      "ja": null
    },
    "type": "story",
    "url": "https://blog.startifact.com/posts/xee/",
    "score": 229,
    "by": "robin_reala",
    "time": 1743144498,
    "content": "Xee: A Modern XPath and XSLT Engine in Rust\n\n        By Martijn Faassenâ€¢2025-03-27â€¢Tags:xml,rust,xpath,lxml\n\n            For the last two years I've been working on a programming language\nimplementation in Rust named Xee. Xee stands for \"XML Execution Engine\" and\nit supports modern versions of XPath and XSLT. Those are programming languages,\nand yes, that's XML stuff.\nNow hold on. Your brain might shut down when I talk about XML. I totally get\nthat XML may not be your cup of tea. But I'm also going to be talking about a\nstrange different world of technology where everything is specified, and the\nimplementation of a programming language using Rust, so I hope you still decide\nto read on if those topics could interest you.\nAnd if XML does happen to be your cup of tea, I think you should be excited\nabout Xee, as I think it can help secure a better future for XML technologies.\nHere's the Xee repository.\nThere are two highlights: a command-line tool\nxee\nthat lets you do XPath queries, and a Rust library\nxee-xpath to issue XPath\nqueries from Rust.\n\nGenesis\nIn 2023 I was asked by Paligo, my amazing and generous\nclient, whether I wanted to implement a modern version of XPath and XSLT in\nRust. I felt extremely nervous for a week. Then I told them that this was a big\nproject. I told them that I could do it and I was excited to do it, but it was\ngoing to be a lot of work.\nAnd although I was right to be very intimidated by the scope, I still\nunderestimated the effort at the time.\nBut Xee has come a long way nonetheless! I'm going to take you along on its\njourney if you're willing to follow.\n\nWhat is Xee?\nXee is a programming language implementation. It implements two core XML\nprogramming languages: XPath and,\npartially at the time of writing, XSLT.\nXPath is an XML query language, and XSLT is a language that uses XPath as its\nexpression language which lets you transform XML documents into other\ndocuments. Xee implements modern versions of these specifications, rather\nthan the versions released in 1999.\nXee implements these languages in the Rust programming language. This brings\nmodern XML technology not just to Rust. Rust is a systems programming language\nand is good at integration with other programming languages. So Xee can bring\nits capabilities to other programming languages as well, from PHP to Python.\nI've already experimented with PHP\nbindings.\nSince Xee is written in Rust, it should also be possible to compile the Xee\ninterpreter to WASM and run this stuff in the browser.\nI'll continue to talk about how Xee is implemented later, but first we'll take\na break and share some XML history.\n\nXML history\nLet's talk a bit about XML. XML emerged in the late 90s, and though it may be\ndifficult to believe now, for a while in the early part of the 2000s, XML was a\ncool technology everyone wanted to use. There was much excitement in the form\nof industry activity and many computer science papers were also published.\nTo illustrate how big this was, last year I was at the RustNL conference and I\nspoke to two separate speakers who mentioned they had worked on an XSLT\nengine1 in the past. One of them was Niko\nMatsakis, Rust core developer.\nSo me being a young and hip developer back then 2, I was doing cool XML\nstuff too. My biggest accomplishment in the XML space was the creation of\nlxml, the XML library for Python. I started that project in\nlate 2004. Early on Stefan Behnel\njoined the project and he has competently maintained it ever since - it would\nnot have been as successful without him.\nWhile XML technology isn't cool anymore today, it's still everywhere. The core\nlanguage web browsers use is not XML but its close cousin HTML. Embedded in\nHTML are true XML-based languages, such as SVG and MathML. Even though JSON and\nother languages took a large chunk out of it, XML is still used to store and\ntransmit a lot of data, and it's extensively used for documents as well, in\nformats such as docbook and JATS. XML is now niche technology, but it's a\nbigger niche than you might think, and it's not going to go away any time soon.\nIn my own career, I became less and less involved with XML over time, though\nI'd still run into it on a regular basis. It's both amusing and useful that\nwhenever I talk to a potential client that uses Python, they're already using\nlxml somewhere.\nA few years ago I entered back into the XML world. And here I am, that\nrelatively rare bird who knows a fancy modern programming language like Rust,\nand is at the same time very familiar with XML.\n\nXPath and XSLT are programming languages\nSo XPath and XSLT are both programming languages.\nXPath is a query language for XML. Given an XML document, let's say something\nlike HTML, you can query it with expressions like: /html/body//p to get all\np elements inside the body element of the outer html element. XPath in\nits modern incarnation is a functional programming language with a type system,\nvariables, function definition, conditionals, loops and so on.\nXSLT is a transformation language for XML. It describes, using templates and a\nfunctional approach, how to transform an XML document of one type into another.\nYou can for instance use it to transform docbook XML, which describes\ndocuments, into HTML. It builds on XPath - XPath expressions are the expression\nlanguage of XSLT. XSLT itself also supports programming constructs like\nvariables, loops, conditionals, functions and the like, in a partial\nduplication of XPath.\n\nState of the XML open source stack\nSo if you want to use these programming languages and you use an open source\nstack, where do you go?\nThe Java world has good modern XPath and XSLT support. XPath and XSLT are\nimplemented by Saxon, which has been around for a long time. Saxon is available\non .NET as well. There are also PHP and Python bindings via a rather complex C\nto Java bridge, and Saxon offers a JavaScript reimplemention of its runtime as\nwell. Besides its open source offerings, Saxon also has closed-source\nprofessional/enterprise editions which provide more features. Besides Saxon,\nthere are also open source XQuery3 implementations in Java.\nBut if you step out of the Java world and its periphery, and if you look in\nyour average open source stack or Linux distribution for an XPath or XSLT\nimplementation you don't find Saxon or these XQuery databases; you find\nlibxml2 and libxslt.\nlibxml2 and libxslt are C libraries for handling XML. This amalgam of\nlibraries supports parsing XML, querying it using XPath, transforming it using\nXSLT and more. libxml2 is everywhere - in your Linux distribution and in\nMacOS. People don't just use it from C code - for Python for instance I built\nlxml on top.\nThese libraries were originally created by Daniel\nVeillard. I remember speaking to him once, many years\nago. We came from different worlds - he was thinking about writing fast\nprocessor-cache friendly code in C, whereas I was interested in an easy to use\nAPI in Python. I was impressed he had implemented all these specifications -\nlxml was merely piggybacking on that hard work.\nBut libxml2 is stuck in the past - it implements XPath, but only XPath 1.0,\nand similarly libxslt implements XSLT 1.0 only. These are specifications from\n1999. The XPath 2 specification was released in 2007, and we're currently\nactually at XPath 3.1, released in 2017. Similarly XSLT 2.0 was released in\n2007 and XSLT 3.0, the current version, in 2017.\nMy hope is that Xee can be a more modern alternative to libxml2 and libxslt\nthat finds its home in the open source world. For XPath and XSLT to be thriving\nstandards they need multiple implementations, in multiple programming\nlanguages, by multiple parties.\nAnd personally I feel like I have come full circle - finally, in these latter\ndays of XML, I am where Daniel Veillard had gone ages before with libxml2. I\nfind myself implementing the same stuff, not in C, but still in a systems\nprogramming language, Rust.\n\nSpecification culture\nI was at XML Prague, an XML conference, last year,\nand I noticed something interesting about XML culture. It is still very\nstandards focused. This was a very prevalent attitude in the web development\nworld in the early 2000s, but I think that although standards are still\nconsidered important today, they're less culturally prominent.\nThe XML culture is different: stuff needs to be specified. If it's not in a\nspecification it's not fully real. This makes the XML community move more\nslowly than the rest of the software community. I was somewhat bemused to hear\ntalk in 2024 about updating the RESTXQ spec, an XQuery based web framework\nstandard, first discussed in 2012, to make use of language features like\nhashmaps and arrays, now that they had been finally added to XPath/XQuery in\n2017.\nThese XML specifications go deep, they build on each other, they are solid. If\nyou value solid foundations that will stand the test of time, the XML world has\ngot your back.\n\nImplementing a programming language\nYou might be bored with XML by now so before I return to the discussion of\nspecifications, I will talk a bit about the architecture of Xee.\nXee follows various familiar patterns in the implementation of programming\nlanguages. I based part of its architecture on the excellent book Crafting\nInterpreters.\nIn Xee, XPath gets lexed into tokens, then parsed into an abstract syntax tree\n(AST). The AST is then transformed into an intermediate representation (IR)\nthat represents the expression in a more compact way. This IR is then compiled\ninto bytecode - a simple assembly-language like stack machine, similar to the\none that underlies many programming languages such as Python and Java. The Xee\ninterpreter can then execute the bytecode.\nThis translation at present is straightforward; while I've prepared the IR to\nsupport optimization passes such as constant folding and the like, this doesn't\nhappen yet.4\nXSLT, though unfinished, is built on the same architecture as the XPath engine.\nThere's a frontend that transforms XSLT XML into an XSLT AST, and then this is\ntransformed into the same IR as the one used for XPath. It uses the same\nbytecode intepreter. So, only the XSLT frontend is different, everything else\nis the same. This made it easy to implement a whole bunch of XSLT features as I\nhad already implemented them for XPath.\nImplementing programming languages is fun!\n\nSpecifications, again\nXPath and XSLT are programming languages that are fully specified. You can\nreally implement them from the specification. On the one hand this makes life a\nlot easier - the goals are clear as it's clearly specified how things are\nsupposed to work. There's a vast conformance test suite available as well. On\nthe other hand this means an endless treadmill; I can't just stop when I think\nit looks good enough when there's more specification left to implement.\nXPath 3.1 has grown a lot bigger than XPath 1.0; it became a full-fledged\nprogramming language, with a much larger standard library. XSLT 3.0 has also\nevolved a lot since XSLT 1.0. Specifications keep building on each other, and\nadd more features in new updates, until implementing them becomes a daunting\ntask. I sometimes I wish I was implementing XPath 1.0 and XSLT 1.0, like Daniel\nVeillard back in the day.\nLet me give you a quick tour of various specifications so you can understand\nsomething about the magnitude of the task of implementing them.\nThe grammar and behavior of the XPath language is laid out in the W3C\nspecification XML Xpath Language (XPath)\n3.1. This refers to another specification,\nXQuery and XPath Data Model 3.1\nwhich describes how XPath views XML data - what properties of XML data exist.\nIt also builds on another specification XPath and XQuery Functions and\nOperators 3.1, which not only\ndescribes the behavior of XPath operators such as +, - and *, but also\ndefines its standard library of functions.\nXPath has a type system, and its types are described by W3C XML Schema\nDefinition Language (XSD) 1.1: Part 1:\nStructures and W3C XML Schema\nDefinition Language (XSD) 1.1 Part 2:\nDatatypes. This defines atomic types\n(which Xee implements) but also lets you define new types and use types from an\nXML schema, which Xee doesn't implement at present. These specifications also\ndescribe how XPath is to parse and format strings of atomic types, such as the\nformat of decimals and dates.\nOh, and that XPath functions and operators specification? Some of the functions\nuse regular expressions. The specification defines XPath regular expressions as\nan extension of the regular expressions system defined in the XML schema\nspecification. And all of that builds on the unicode specification but that's\nanother country. So I ended up implementing a regex\nengine too.\nOver to XSLT. There's XSL Transformations (XSLT) Version\n3.0 which defines the XSLT programming\nlanguage. It builds on all the specifications that went before, and also builds\non XSLT and XQuery Serialization\n3.0, which describes\noptions for how to serialize XML and various other things.\nOf course all of this builds on the XML specification itself, Extensive Markup\nLanguage (XML) 1.0 (Fifth Edition), extended with\nnamespaces, in Namespaces in XML 1.0.\nThen there are a few stray specifications that are also relevant like XML\nBase and\nxml:id. But those are small ones.\nOnce I counted up the page count5 of just the XPath and XSLT\nspecifications along with the most relevant XML Schema spec (part 2), and that\nsubset is over 1800 pages.\nI probably forgot a few specifications, because after a while they start coming\nout of my ears, but this should give you an impression.\n\nXee status\nWhat I'm most proud of is the XPath 3.1 implementation in Xee. The XPath core\nlanguage and most of its standard library have been implemented. There are gaps\nin the standard library implementation still - some formatting functions are\nparticularly huge, for instance, but overall it's pretty complete.\nThere's an XPath 3.1 conformance test suite, and of the 21859 tests, 20130\ntests are passing at the time of writing. Most of the failing tests have to do\nwith the implementation of missing standard library functionality.\nIncidentally, this test suite runs those 20130 tests in 13 seconds on my\nmachine. Computers are fast.\nMeanwhile Xee also provides a solid basis for XSLT, reusing a lot of the XPath\ninfrastructure. While a lot of XSLT works, much remains to be done and I'm\nhoping to find people who want to help contribute!\n\nA call for contributors\nSo now I will call for this rare bird: someone who read all this, saw all those\nXML specifications, knows a bit of Rust, likes implementing programming\nlanguages and thought: cool! I want to help!\n\nDo you like the challenge of implementing some functionality, small or large,\naccording to spec? Xee has plenty of tasks for you.\n\nAre you interested in programming language implementation? Perhaps do cool\nprogramming language optimization work? For a programming language that has\nan existing user base already? Xee has the foundations.\n\nDo you like to think about query optimization problems? Care about using\nsuccinct data structures? (not\nintegrated into Xee proper yet). We have plenty of what should interest you.\n\nDo you care about the future of XML and want to ensure a modern open source\nimplementation is available outside of the Java world?\n\nThe Xee project could use your help and is ready for it. Small and large\ncontributions are possible and welcome!\n2\nI'm still hip. I say so. Even though I do XML stuff.\n\n1\nNot the same XSLT engine. Different ones!\n\n3\nXQuery is a superset of XPath.\n\n4\nSo you're interested in working on programming language\noptimization you've come to the right place!\n\n5\nI printed each specification HTML page to PDF to see how many pages\nthey were.\n\n                â†Prev\n                Looking for new challenges!\n\n  Comments\n  You can use your Mastodon account to reply to this post. Learn how\n  this is implemented here.\n\n  Reply\n  Load comments\n\n    Reply to this post\n\n      With an account on the Fediverse or Mastodon, you can respond to this\n      post. Since Mastodon is decentralized, you can use your existing account\n      hosted by another Mastodon server or compatible platform if you don't\n      have an account on this one.\n\n    Copy and paste this URL into the search field of your favorite Fediverse app or the web interface of your Mastodon server.\n\n      Copy\n      Close\n\n  You need JavaScript to view the comments.\n\n    const dialog = document.querySelector('dialog');\n\n    document.getElementById('replyButton').addEventListener('click', () => {\n       dialog.showModal();\n      });\n\n    document.getElementById('copyButton').addEventListener('click', () => {\n      navigator.clipboard.writeText(\"https://fosstodon.org/@faassen/114235009789423262\");\n    });\n\n    document.getElementById('cancelButton').addEventListener('click', () => {\n      dialog.close();\n    });\n\n    dialog.addEventListener('keydown', e => {\n      if (e.key === 'Escape') dialog.close();\n    });\n\n    function escapeHtml(unsafe) {\n      return unsafe\n            .replace(/&/g, \"&amp;\")\n            .replace(/</g, \"&lt;\")\n            .replace(/>/g, \"&gt;\")\n            .replace(/\"/g, \"&quot;\")\n            .replace(/'/g, \"&#039;\");\n    }\n\n    // render date as YYYY-MM-DD HH:MM, not using the browser's locale\n    function renderDate(date) {\n        return date.getFullYear() + \"-\" + (date.getMonth() + 1).toString().padStart(2, '0') + \"-\" + date.getDate().toString().padStart(2, '0') + \" \" + date.getHours().toString().padStart(2, '0') + \":\" + date.getMinutes().toString().padStart(2, '0');\n    }\n\n    document.getElementById(\"load-comment\").addEventListener(\"click\", function() {\n        document.getElementById(\"load-comment\").innerHTML = \"Loading\";\n        fetch('https://fosstodon.org/api/v1/statuses/114235009789423262/context')\n          .then(function(response) {\n            return response.json();\n          })\n          .then(function(data) {\n            if(data['descendants'] &&\n               Array.isArray(data['descendants']) &&\n              data['descendants'].length > 0) {\n                document.getElementById('mastodon-comments-list').innerHTML = \"\";\n                data['descendants'].forEach(function(reply) {\n                  reply.account.display_name = escapeHtml(reply.account.display_name);\n                  reply.account.reply_class = reply.in_reply_to_id == \"114235009789423262\" ? \"reply-original\" : \"reply-child\";\n                  reply.created_date = new Date(reply.created_at);\n                  reply.account.emojis.forEach(emoji => {\n                    reply.account.display_name = reply.account.display_name.replace(`:${emoji.shortcode}:`,\n                      `<img src=\"${escapeHtml(emoji.static_url)}\" alt=\"Emoji ${emoji.shortcode}\" height=\"20\" width=\"20\" />`);\n                  });\n                  mastodonComment =\n                    `\n<div class=\"mastodon-wrapper\">\n  <div class=\"comment-level ${reply.account.reply_class}\"><svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 512 512\">\n    <path fill=\"currentColor\" stroke=\"currentColor\" d=\"m 307,477.17986 c -11.5,-5.1 -19,-16.6 -19,-29.2 v -64 H 176 C 78.8,383.97986 -4.6936293e-8,305.17986 -4.6936293e-8,207.97986 -4.6936293e-8,94.679854 81.5,44.079854 100.2,33.879854 c 2.5,-1.4 5.3,-1.9 8.1,-1.9 10.9,0 19.7,8.9 19.7,19.7 0,7.5 -4.3,14.4 -9.8,19.5 -9.4,8.8 -22.2,26.4 -22.2,56.700006 0,53 43,96 96,96 h 96 v -64 c 0,-12.6 7.4,-24.1 19,-29.2 11.6,-5.1 25,-3 34.4,5.4 l 160,144 c 6.7,6.2 10.6,14.8 10.6,23.9 0,9.1 -3.9,17.7 -10.6,23.8 l -160,144 c -9.4,8.5 -22.9,10.6 -34.4,5.4 z\" />\n  </svg></div>\n  <div class=\"mastodon-comment\">\n    <div class=\"comment\">\n      <div class=\"comment-avatar\"><img src=\"${escapeHtml(reply.account.avatar_static)}\" alt=\"\"></div>\n      <div class=\"comment-author\">\n        <div class=\"comment-author-name\"><a href=\"${reply.account.url}\" rel=\"nofollow\">${reply.account.display_name}</a></div>\n        <div class=\"comment-author-reply\"><a href=\"${reply.account.url}\" rel=\"nofollow\">${escapeHtml(reply.account.acct)}</a></div>\n      </div>\n      <div class=\"meta\">${renderDate(reply.created_date)}</div>\n    </div>\n    <div class=\"comment-content\">${reply.content}</div>\n  </div>\n</div>\n`;\n                  document.getElementById('mastodon-comments-list').appendChild(DOMPurify.sanitize(mastodonComment, {'RETURN_DOM_FRAGMENT': true}));\n                });\n            } else {\n              document.getElementById('mastodon-comments-list').innerHTML = \"<p>No comments found</p>\";\n            }\n          });\n        });",
    "summary": {
      "en": "### Summary of \"Xee: A Modern XPath and XSLT Engine in Rust\"\n\nXee is a programming language implementation created by Martijn Faassen, designed to support modern versions of XPath and XSLT using Rust. XPath is a query language for XML, while XSLT is used for transforming XML documents. Xee aims to modernize these technologies and provide better integration with various programming languages.\n\n**Key Points:**\n\n1. **Project Background**: Faassen was approached by Paligo to create Xee, which he found daunting but exciting. His goal is to provide a modern implementation of XML technologies.\n\n2. **Implementation and Features**: Xee consists of a command-line tool for XPath queries and a Rust library for XPath integration. It can potentially be compiled to run in web browsers using WebAssembly (WASM).\n\n3. **XML's Evolution**: Although XML was once very popular in the early 2000s, its usage has declined, but it remains important for many applications and data formats.\n\n4. **XPath and XSLT**: Both are considered programming languages, with XPath allowing queries on XML data and XSLT enabling document transformations. Xee implements modern versions of these languages.\n\n5. **Challenges in Implementation**: The existing libraries for XML, like libxml2 and libxslt, are outdated, only supporting older versions of XPath and XSLT. Xee aims to fill this gap with a modern alternative.\n\n6. **Standards and Specifications**: The XML community is heavily focused on standards, which can slow down development. Xee is designed according to these specifications, making it a robust solution.\n\n7. **Development Status**: Xee has a functioning implementation of XPath 3.1, with many features already complete. The project invites contributions from others interested in programming languages and XML technologies.\n\n8. **Call for Contributors**: Faassen encourages those knowledgeable in Rust and interested in XML to join the project and help enhance its functionality.\n\nOverall, Xee represents an effort to revitalize XML technologies by providing a modern, open-source implementation in Rust.",
      "ko": "XeeëŠ” Martijn Faassenì´ ë§Œë“  í”„ë¡œê·¸ë˜ë° ì–¸ì–´ êµ¬í˜„ì²´ë¡œ, Rustë¥¼ ì‚¬ìš©í•˜ì—¬ í˜„ëŒ€ì ì¸ XPathì™€ XSLTë¥¼ ì§€ì›í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. XPathëŠ” XMLì„ ìœ„í•œ ì¿¼ë¦¬ ì–¸ì–´ì´ë©°, XSLTëŠ” XML ë¬¸ì„œë¥¼ ë³€í™˜í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤. XeeëŠ” ì´ëŸ¬í•œ ê¸°ìˆ ì„ í˜„ëŒ€í™”í•˜ê³  ë‹¤ì–‘í•œ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì™€ì˜ í†µí•©ì„ ê°œì„ í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n\nFaassenì€ Paligoì˜ ìš”ì²­ìœ¼ë¡œ Xeeë¥¼ ë§Œë“¤ê²Œ ë˜ì—ˆê³ , ì´ ì‘ì—…ì´ ì–´ë µì§€ë§Œ í¥ë¯¸ë¡­ë‹¤ê³  ëŠê¼ˆìŠµë‹ˆë‹¤. ê·¸ì˜ ëª©í‘œëŠ” XML ê¸°ìˆ ì˜ í˜„ëŒ€ì ì¸ êµ¬í˜„ì„ ì œê³µí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. XeeëŠ” XPath ì¿¼ë¦¬ë¥¼ ìœ„í•œ ëª…ë ¹ì¤„ ë„êµ¬ì™€ XPath í†µí•©ì„ ìœ„í•œ Rust ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì´ ë„êµ¬ëŠ” WebAssembly(WASM)ë¥¼ ì‚¬ìš©í•˜ì—¬ ì›¹ ë¸Œë¼ìš°ì €ì—ì„œ ì‹¤í–‰ë  ìˆ˜ ìˆë„ë¡ ì»´íŒŒì¼ë  ê°€ëŠ¥ì„±ë„ ìˆìŠµë‹ˆë‹¤.\n\nXMLì€ 2000ë…„ëŒ€ ì´ˆë°˜ì— ë§¤ìš° ì¸ê¸°ê°€ ìˆì—ˆì§€ë§Œ, í˜„ì¬ ì‚¬ìš©ëŸ‰ì€ ì¤„ì–´ë“¤ì—ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¼ì—ë„ ë¶ˆêµ¬í•˜ê³  ë§ì€ ì• í”Œë¦¬ì¼€ì´ì…˜ê³¼ ë°ì´í„° í˜•ì‹ì—ì„œ ì—¬ì „íˆ ì¤‘ìš”í•œ ì—­í• ì„ í•˜ê³  ìˆìŠµë‹ˆë‹¤. XPathì™€ XSLTëŠ” ëª¨ë‘ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ë¡œ ê°„ì£¼ë˜ë©°, XPathëŠ” XML ë°ì´í„°ì— ëŒ€í•œ ì¿¼ë¦¬ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•˜ê³ , XSLTëŠ” ë¬¸ì„œ ë³€í™˜ì„ ì§€ì›í•©ë‹ˆë‹¤. XeeëŠ” ì´ëŸ¬í•œ ì–¸ì–´ì˜ í˜„ëŒ€ì ì¸ ë²„ì „ì„ êµ¬í˜„í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n\nê¸°ì¡´ì˜ XML ë¼ì´ë¸ŒëŸ¬ë¦¬ì¸ libxml2ì™€ libxsltëŠ” êµ¬ì‹ìœ¼ë¡œ, ì˜¤ë˜ëœ ë²„ì „ì˜ XPathì™€ XSLTë§Œ ì§€ì›í•©ë‹ˆë‹¤. XeeëŠ” ì´ëŸ¬í•œ ê³µë°±ì„ ë©”ìš°ê¸° ìœ„í•´ í˜„ëŒ€ì ì¸ ëŒ€ì•ˆì„ ì œê³µí•˜ê³ ì í•©ë‹ˆë‹¤. XML ì»¤ë®¤ë‹ˆí‹°ëŠ” í‘œì¤€ì— ë§ì€ ì¤‘ì ì„ ë‘ê³  ìˆì–´ ê°œë°œ ì†ë„ë¥¼ ëŠ¦ì¶œ ìˆ˜ ìˆìŠµë‹ˆë‹¤. XeeëŠ” ì´ëŸ¬í•œ ì‚¬ì–‘ì— ë”°ë¼ ì„¤ê³„ë˜ì–´ ê°•ë ¥í•œ ì†”ë£¨ì…˜ì´ ë©ë‹ˆë‹¤.\n\ní˜„ì¬ XeeëŠ” XPath 3.1ì˜ ê¸°ëŠ¥ì ì¸ êµ¬í˜„ì„ ê°€ì§€ê³  ìˆìœ¼ë©°, ë§ì€ ê¸°ëŠ¥ì´ ì´ë¯¸ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì´ í”„ë¡œì íŠ¸ëŠ” í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì™€ XML ê¸°ìˆ ì— ê´€ì‹¬ì´ ìˆëŠ” ì‚¬ëŒë“¤ì˜ ê¸°ì—¬ë¥¼ í™˜ì˜í•©ë‹ˆë‹¤. Faassenì€ Rustì— ëŒ€í•œ ì§€ì‹ì´ ìˆê³  XMLì— ê´€ì‹¬ì´ ìˆëŠ” ì‚¬ëŒë“¤ì´ í”„ë¡œì íŠ¸ì— ì°¸ì—¬í•˜ì—¬ ê¸°ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ë° ë„ì›€ì„ ì£¼ê¸°ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.\n\nXeeëŠ” Rustì—ì„œ í˜„ëŒ€ì ì´ê³  ì˜¤í”ˆ ì†ŒìŠ¤ êµ¬í˜„ì„ ì œê³µí•¨ìœ¼ë¡œì¨ XML ê¸°ìˆ ì„ ì¬í™œì„±í™”í•˜ë ¤ëŠ” ë…¸ë ¥ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "551e20eaab8852f1",
    "title": {
      "en": "How Kerala got rich",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://aeon.co/essays/how-did-kerala-go-from-poor-to-prosperous-among-indias-states",
    "score": 256,
    "by": "lordleft",
    "time": 1743179264,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "f9d177a202e349e0",
    "title": {
      "en": "Show HN: Hexi â€“ Modern header-only network binary serialisation for C++",
      "ko": "í—¥ì‹œ: C++ë¥¼ ìœ„í•œ í˜„ëŒ€ì  ë„¤íŠ¸ì›Œí¬ ì§ë ¬í™”",
      "ja": null
    },
    "type": "story",
    "url": "https://github.com/EmberEmu/Hexi",
    "score": 59,
    "by": "Chaosvex",
    "time": 1743183462,
    "content": "Hexi is a lightweight, header-only C++23 library for safely handling binary data from arbitrary sources (but primarily network data). It sits somewhere between manually memcpying bytes from network buffers and full-blown serialisation libraries.\nThe design goals are ease of use, safety when dealing with untrusted data, a reasonable level of flexibility, and keeping overhead to a minimum.\nWhat Hexi doesn't offer: versioning, conversion between different formats, handling of text-based formats, unloading the dishwasher.\n\nIncorporating Hexi into your project is simple! The easiest way is to simply copy hexi.h from single_include into your own project. If you'd rather only include what you use, you can add include to your include paths or incorporate it into your own CMake project with target_link_library. To build the unit tests, run CMake with ENABLE_TESTING.\nHere's what some libraries might call a very simple motivating example:\n#include <hexi.h>\n#include <array>\n#include <vector>\n#include <cstddef>\n\nstruct UserPacket {\n    uint64_t user_id;\n    uint64_t timestamp;\n    std::array<uint8_t, 16> ipv6;\n};\n\nauto deserialise(std::span<const char> network_buffer) {\n    hexi::buffer_adaptor adaptor(network_buffer); // wrap the buffer\n    hexi::binary_stream stream(adaptor);          // create a binary stream\n\n    // deserialise!\n    UserPacket packet;\n    stream >> packet;\n    return packet;\n}\n\nauto serialise(const UserPacket& packet) {\n    std::vector<uint8_t> buffer;\n    hexi::buffer_adaptor adaptor(buffer); // wrap the buffer\n    hexi::binary_stream stream(adaptor);  // create a binary stream\n\n    // serialise!\n    stream << packet;\n    return buffer;\n}\n\nBy default, Hexi will try to serialise basic structures such as our UserPacket if they meet requirements for being safe to directly copy the bytes. Now, for reasons of portability, it's not recommended that you do things this way unless you're positive that the data layout is identical on the system that wrote the data. Not to worry, this is easily solved. Plus, we didn't do any error handling. All in good time.\n\nThe two classes you'll primarily deal with are buffer_adaptor and binary_stream.\nbinary_stream takes a container as its argument and is used to do the reading and writing. It doesn't know much about the details of the underlying container.\nTo support containers that weren't written to be used with Hexi, buffer_adaptor is used as a wrapper that binary_stream can interface with. As with binary_stream, it also provides read and write operations but at a lower level.\nbuffer_adaptor can wrap any contiguous container or view that provides data and size member functions and optionally resize() for write support. From the standard library, that means the following can be used out of the box:\n\n std::array\n std::span\n std::string_view\n std::string\n std::vector\n\nPlenty of non-standard library containers will work out of the box, too, as long as they provide a vaguely similar API.\nThe container's value type must be a byte type (e.g. char, std::byte, uint8_t). std::as_bytes can be used as a workaround if this poses a problem.\n\nHexi supports custom containers, including non-contiguous containers. In fact, there's a non-contiguous container included in the library. You simply need to provide a few functions such as read and size to allow the binary_stream class to be able to use it.\nstatic_buffer.h provides a simple example of a custom container that can be used directly with binary_stream.\n\nAs mentioned, Hexi is intended to be safe to use even when dealing with untrusted data. An example might be network messages that have been manipulated to try to trick your code into reading out of bounds.\nbinary_stream performs bounds checking to ensure that it will never read more data than the buffer has available and optionally allows you to specify an upper bound on the amount of data to read. This can be useful when you have multiple messages in a buffer and want to limit the deserialisation from potentially eating into the next.\nbuffer_t buffer;\n// ... read data\nhexi::binary_stream stream(buffer, 32); // will never read more than 32 bytes\n\nThe default error handling mechanism is exceptions. Upon encountering a problem with reading data, an exception derived from hexi::exception will be thrown. These are:\n\nhexi::buffer_underrun - attempt to read out of bounds\nhexi::stream_read_limit - attempt to read more than the imposed limit\n\nExceptions from binary_stream can be disabled by specifying no_throw as a template argument, as shown:\nhexi::binary_stream<buf_type, hexi::no_throw> stream(...);\n\nWhile this prevents binary_stream itself from throwing, it does not prevent propagation of exceptions from lower levels. For example, a wrapped std::vector could still throw std::bad_alloc if allocation fails when writing to it.\nRegardless of the error handling mechanism you use, the state of a binary_stream can be checked as follows:\nhexi::binary_stream<buf_type, hexi::no_throw> stream(...);\n// ... assume an error happens\n\n// simplest way to check whether any errors have occurred\nif (!stream) {\n    // handle error\n}\n\n// or we can get the state\nif (auto state = stream.state(); state != hexi::stream_state::ok) {\n    // handle error\n}\n\nIn the first example, reading our UserPacket would only work as expected if the program that wrote the data laid everything out in the same way as our own program.\nThis might not be the case for reasons of architecture differences, compiler flags, etc.\nHere's the same example but doing it portably.\n#include <hexi.h>\n#include <span>\n#include <string>\n#include <vector>\n#include <cstddef>\n#include <cstdint>\n\nstruct UserPacket {\n    uint64_t user_id;\n    std::string username;\n    uint64_t timestamp;\n    uint8_t has_optional_field;\n    uint32_t optional_field;  // pretend this is big endian in the protocol\n\n    // deserialise\n    auto& operator>>(auto& stream) {\n        stream >> user_id >> username >> timestamp >> has_optional_field;\n\n        if (has_optional_field) {\n            stream >> optional_field;\n            hexi::endian::big_to_native_inplace(optional_field);\n        }\n\n        // we can manually trigger an error if something went wrong\n        // stream.set_error_state();\n        return stream;\n    }\n\n    // serialise\n    auto& operator<<(auto& stream) const {\n        stream << user_id << username << timestamp << has_optional_field;\n\n        if (has_optional_field) {\n            stream << hexi::endian::native_to_big(optional_field);\n        }\n\n        return stream;\n    }\n};\n\n// pretend we're reading network data\nvoid read() {\n    std::vector<char> buffer;\n    const auto bytes_read = socket.read(buffer);\n\n    // ... logic for determing packet type, etc\n\n    bool result {};\n\n    switch (packet_type) {\n        case packet_type::user_packet:\n            result = handle_user_packet(buffer);\n            break;\n    }\n\n    // ... handle result\n}\n\nauto handle_user_packet(std::span<const char> buffer) {\n    hexi::buffer_adaptor adaptor(buffer);\n    hexi::binary_stream stream(adaptor);\n\n    UserPacket packet;\n    stream >> packet;\n\n    if (stream) {\n        // ... do something with the packet\n        return true;\n    } else {\n        return false;\n    }\n}\n\nBecause binary_stream is a template, it's easiest to allow the compiler to perform type deduction magic.\nIf you want the function bodies to be in a source file, it's recommended that you provide your own using alias for your binary_stream type.\nThe alternative is to use the polymorphic equivalents, pmc::buffer_adaptor and pmc::binary_stream, which allow you to change the underlying buffer type at runtime but at the cost of virtual call overhead and lacking some functionality that doesn't mesh well with polymorphism.\nHow you structure your code is up to you, this is just one way of doing it.\n\nWhen using binary_stream, strings are always treated as null-terminated. Writing a char*, std::string_view or std::string will always write a terminating byte to the stream. If you require otherwise, use one of the put functions.\nLikewise, reading to std::string assumes the buffer contains a null-terminator. If it does not, an empty string will be returned. If you know the length of the string or need to support a custom terminating/sentinel value, use get() and find_first_of().\n\nHere's a very quick rundown on some of the included extras.\n\nhexi::file_buffer\n\nFor dealing with binary files. Simples.\n\nhexi::static_buffer\n\nFixed-size networking buffer for when you know the upper bound on the amount of data you'll need to send or receive in one go. Essentially a wrapper around std::array but with added state tracking. Handy if you need to deserialise in multiple steps (read packet header, dispatch, read packet body).\n\nhexi::dynamic_buffer\n\nResizeable buffer for when you want to deal with occasional large read/writes without having to allocate the space up front. Internally, it adds additional allocations to accomodate extra data rather than requesting a larger allocation and copying data as std::vector would. It reuses allocated blocks where possible and has support for Asio (Boost or standalone). Effectively, it's a linked list buffer.\n\nhexi::tls_block_allocator\n\nAllows many instances of dynamic_buffer to share a larger pool of pre-allocated memory, with each thread having its own pool. This is useful when you have many network sockets to handle and want to avoid the general purpose allocator. The caveat is that a deallocation must be made by the same thread that made the allocation, thus limiting access to the buffer to a single thread (with some exceptions).\n\nhexi::endian\n\nProvides functionality for handling endianness of integral types.\n\nWe're at the end of the overview, but there's more to discover if you decide to give Hexi a shot. Here's a selection of tasty morsels:\n\nbinary_stream allows you to perform write seeking within the stream, when the underlying buffer supports it. This is nice if, for example, you need to update a message header with information that you might not know until the rest of the message has been written; checksums, sizes, etc.\nbinary_stream provides overloaded put and get member functions, which allow for fine-grained control, such as reading/writing a specific number of bytes.\nbinary_stream allows for writing to std::string_view and std::span with view() and span() as long as the underlying container is contiguous. This allows you to create views into the buffer's data, providing a fast, zero-copy way to read strings and arrays from the stream. If you do this, you should avoid writing to the same buffer while holding views to the data.\nbuffer_adaptor provides a template option, space_optimise. This is enabled by default and allows it to avoid resizing containers in cases where all data has been read by the stream. Disabling it allows for preserving data even after having been read. This option is only relevant in scenarios where a single buffer is being both written to and read from.\nbuffer_adaptor provides find_first_of, making it easy to find a specific sentinel value within your buffer.\n\nTo learn more, check out the examples in docs/examples!",
    "summary": {
      "en": "Hexi is a lightweight C++23 library designed for safely managing binary data, especially from network sources. It aims to be simple to use, secure against untrusted data, flexible, and efficient. However, it does not include features like versioning, format conversion, or text format handling.\n\nTo use Hexi, you can simply copy the header file into your project or include it in your build system. The main components are `buffer_adaptor` and `binary_stream`, which facilitate reading and writing binary data. Hexi can work with standard containers like `std::array`, `std::vector`, and `std::string`, as well as custom containers as long as they follow a similar API.\n\nHexi ensures safety by performing bounds checks to prevent reading beyond the available data. It uses exceptions for error handling, which can be customized or disabled if needed. The library also includes features for handling endianness and offers various buffer types like fixed-size, dynamic, and file buffers.\n\nKey features include:\n- Easy serialization and deserialization of structures.\n- Bounds checking to prevent data overflows.\n- Support for both standard and custom containers.\n- Handling of endianness for different data formats.\n\nFor a complete understanding and examples, users are encouraged to explore the documentation and examples provided by Hexi.",
      "ko": "HexiëŠ” ì´ì§„ ë°ì´í„°ë¥¼ ì•ˆì „í•˜ê²Œ ê´€ë¦¬í•˜ê¸° ìœ„í•´ ì„¤ê³„ëœ ê²½ëŸ‰ C++23 ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤. ì£¼ë¡œ ë„¤íŠ¸ì›Œí¬ ì†ŒìŠ¤ì—ì„œ ì˜¤ëŠ” ë°ì´í„°ë¥¼ ë‹¤ë£¨ëŠ” ë° ì´ˆì ì„ ë§ì¶”ê³  ìˆìœ¼ë©°, ì‚¬ìš©ì´ ê°„í¸í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ì—†ëŠ” ë°ì´í„°ì— ëŒ€í•´ ì•ˆì „í•˜ë©° ìœ ì—°í•˜ê³  íš¨ìœ¨ì ì…ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ë²„ì „ ê´€ë¦¬, í˜•ì‹ ë³€í™˜, í…ìŠ¤íŠ¸ í˜•ì‹ ì²˜ë¦¬ì™€ ê°™ì€ ê¸°ëŠ¥ì€ í¬í•¨ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.\n\nHexië¥¼ ì‚¬ìš©í•˜ë ¤ë©´ í—¤ë” íŒŒì¼ì„ í”„ë¡œì íŠ¸ì— ë³µì‚¬í•˜ê±°ë‚˜ ë¹Œë“œ ì‹œìŠ¤í…œì— í¬í•¨ì‹œí‚¤ë©´ ë©ë‹ˆë‹¤. ì£¼ìš” êµ¬ì„± ìš”ì†ŒëŠ” `buffer_adaptor`ì™€ `binary_stream`ìœ¼ë¡œ, ì´ë“¤ì€ ì´ì§„ ë°ì´í„°ë¥¼ ì½ê³  ì“°ëŠ” ë° ë„ì›€ì„ ì¤ë‹ˆë‹¤. HexiëŠ” `std::array`, `std::vector`, `std::string`ê³¼ ê°™ì€ í‘œì¤€ ì»¨í…Œì´ë„ˆëŠ” ë¬¼ë¡ , ìœ ì‚¬í•œ APIë¥¼ ë”°ë¥´ëŠ” ì‚¬ìš©ì ì •ì˜ ì»¨í…Œì´ë„ˆì™€ë„ í•¨ê»˜ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nHexiëŠ” ë°ì´í„°ì˜ ê²½ê³„ë¥¼ ì²´í¬í•˜ì—¬ ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ë¥¼ ë„˜ì–´ ì½ëŠ” ê²ƒì„ ë°©ì§€í•¨ìœ¼ë¡œì¨ ì•ˆì „ì„±ì„ ë³´ì¥í•©ë‹ˆë‹¤. ì˜¤ë¥˜ ì²˜ë¦¬ë¥¼ ìœ„í•´ ì˜ˆì™¸ë¥¼ ì‚¬ìš©í•˜ë©°, í•„ìš”ì— ë”°ë¼ ì´ë¥¼ ì‚¬ìš©ì ì •ì˜í•˜ê±°ë‚˜ ë¹„í™œì„±í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, ì—”ë””ì•ˆ ì²˜ë¦¬ ê¸°ëŠ¥ì„ í¬í•¨í•˜ê³  ìˆìœ¼ë©°, ê³ ì • í¬ê¸°, ë™ì , íŒŒì¼ ë²„í¼ì™€ ê°™ì€ ë‹¤ì–‘í•œ ë²„í¼ ìœ í˜•ì„ ì œê³µí•©ë‹ˆë‹¤.\n\nì£¼ìš” ê¸°ëŠ¥ìœ¼ë¡œëŠ” êµ¬ì¡°ì²´ì˜ ì§ë ¬í™” ë° ì—­ì§ë ¬í™”ê°€ ìš©ì´í•˜ê³ , ë°ì´í„° ì˜¤ë²„í”Œë¡œìš°ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•œ ê²½ê³„ ì²´í¬, í‘œì¤€ ë° ì‚¬ìš©ì ì •ì˜ ì»¨í…Œì´ë„ˆ ì§€ì›, ë‹¤ì–‘í•œ ë°ì´í„° í˜•ì‹ì— ëŒ€í•œ ì—”ë””ì•ˆ ì²˜ë¦¬ ë“±ì´ ìˆìŠµë‹ˆë‹¤.\n\nì™„ì „í•œ ì´í•´ì™€ ì˜ˆì œë¥¼ ìœ„í•´ ì‚¬ìš©ìëŠ” Hexiì—ì„œ ì œê³µí•˜ëŠ” ë¬¸ì„œì™€ ì˜ˆì œë¥¼ ì‚´í´ë³´ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "74fec543d154070c",
    "title": {
      "en": "Decomposing a Factorial into Large Factors",
      "ko": "íŒ©í† ë¦¬ì–¼ì˜ ëŒ€ìˆ˜ ë¶„í•´",
      "ja": null
    },
    "type": "story",
    "url": "https://terrytao.wordpress.com/2025/03/26/decomposing-a-factorial-into-large-factors/",
    "score": 93,
    "by": "surprisetalk",
    "time": 1743173754,
    "content": "Decomposing a factorial into largefactors\n\t\t26 March, 2025 in math.NT, paper | Tags: Erdos, factorial function, factorisation | by Terence Tao\n\nIâ€™ve just uploaded to the arXiv the paper â€œDecomposing a factorial into large factorsâ€œ. This paper studies the quantity , defined as the largest quantity such that it is possible to factorize  into  factors , each of which is at least . The first few values of this sequence are\n (OEIS A034258). For instance, we have , because on the one hand we can factor\n but on the other hand it is not possible to factorize  into nine factors, each of which is  or higher.\n\nThis quantity  was introduced by ErdÃ¶s, who asked for upper and lower bounds on ; informally, this asks how equitably one can split up  into  factors. When factoring an arbitrary number, this is essentially a variant of the notorious knapsack problem (after taking logarithms), but one can hope that the specific structure of the factorial  can make this particular knapsack-type problem more tractable. Since\n for any putative factorization, we obtain an upper bound\n thanks to the Stirling approximation. At one point, ErdÃ¶s, Selfridge, and Straus claimed that this upper bound was asymptotically sharp, in the sense that\n as ; informally, this means we can split  into  factors that are (mostly) approximately the same size, when  is large. However, as reported in this later paper, ErdÃ¶s â€œbelieved that Straus had written up our proofâ€¦ Unfortunately Straus suddenly died and no trace was ever found of his notes. Furthermore, we never could reconstruct our proof, so our assertion now can be called only a conjectureâ€.\n\nSome further exploration of  was conducted by Guy and Selfridge. There is a simple construction that gives the lower bound\n that comes from starting with the standard factorization  and transferring some powers of  from the later part of the sequence to the earlier part to rebalance the terms somewhat. More precisely, if one removes one power of two from the even numbers between  and , and one additional power of two from the multiples of four between  to , this frees up  powers of two that one can then distribute amongst the numbers up to  to bring them all up to at least  in size. A more complicated procedure involving transferring both powers of  and  then gives the improvement . At this point, however, things got more complicated, and the following conjectures were made by Guy and Selfridge:\n\n  (i) Is  for all ?  (ii) Is  for all ? (At , this conjecture barely fails: .)  (iii) Is  for all ?\n\nIn this note we establish the bounds\n as , where  is the explicit constant\n In particular this recovers the lost result (2). An upper bound of the shape\n for some  was previously conjectured by ErdÃ¶s and Graham (ErdÃ¶s problem #391). We conjecture that the upper bound in (3) is sharp, thus\n which is consistent with the above conjectures (i), (ii), (iii) of Guy and Selfridge, although numerically the convergence is somewhat slow.\n\nThe upper bound argument for (3) is simple enough that it could also be modified to establish the first conjecture (i) of Guy and Selfridge; in principle, (ii) and (iii) are now also reducible to a finite computation, but unfortunately the implied constants in the lower bound of (3) are too weak to make this directly feasible. However, it may be possible to now crowdsource the verification of (ii) and (iii) by supplying a suitable set of factorizations to cover medium sized , combined with some effective version of the lower bound argument that can establish  for all  past a certain threshold. The value  singled out by Guy and Selfridge appears to be quite a suitable test case: the constructions I tried fell just a little short of the conjectured threshold of , but it seems barely within reach that a sufficiently efficient rearrangement of factors can work here.\n\nWe now describe the proof of the upper and lower bound in (3). To improve upon the trivial upper bound (1), one can use the large prime factors of . Indeed, every prime  between  and  divides  at least once (and the ones between  and  divide it twice), and any factor  that contains such a factor therefore has to be significantly larger than the benchmark value of . This observation already readily leads to some upper bound of the shape (4) for some ; if one also uses the primes  that are slightly less than  (noting that any multiple of  that exceeds , must in fact exceed ) is what leads to the precise constant .\n\nFor previous lower bound constructions, one started with the initial factorization  and then tried to â€œimproveâ€ this factorization by moving around some of the prime factors. For the lower bound in (3), we start instead with an approximate factorization roughly of the shape\n where  is the target lower bound (so, slightly smaller than ), and  is a moderately sized natural number parameter (we will take , although there is significant flexibility here). If we denote the right-hand side here by , then  is basically a product of  numbers of size at least . It is not literally equal to ; however, an easy application of Legendreâ€™s formula shows that for odd small primes ,  and  have almost exactly the same number of factors of . On the other hand, as  is odd,  contains no factors of , while  contains about  such factors. The prime factorizations of  and  differ somewhat at large primes, but  has slightly more such prime factors as  (about  such factors, in fact). By some careful applications of the prime number theorem, one can tweak some of the large primes appearing in  to make the prime factorization of  and  agree almost exactly, except that  is missing most of the powers of  in , while having some additional large prime factors beyond those contained in  to compensate. With a suitable choice of threshold , one can then replace these excess large prime factors with powers of two to obtain a factorization of  into  terms that are all at least , giving the lower bound.\n\nThe general approach of first locating some approximate factorization of  (where the approximation is in the â€œadelicâ€ sense of having not just approximately the right magnitude, but also approximately the right number of factors of  for various primes ), and then moving factors around to get an exact factorization of , looks promising for also resolving the conjectures (ii), (iii) mentioned above. For instance, I was numerically able to verify that  by the following procedure:\n\n  Start with the approximate factorization of ,  by . Thus  is the product of  odd numbers, each of which is at least .  Call an odd prime -heavy if it divides  more often than , and -heavy if it divides  more often than . It turns out that there are  more -heavy primes than -heavy primes (counting multiplicity). On the other hand,  contains  powers of , while  has none. This represents the (multi-)set of primes one has to redistribute in order to convert a factorization of  to a factorization of .  Using a greedy algorithm, one can match a -heavy prime  to each -heavy prime  (counting multiplicity) in such a way that  for a small  (in most cases one can make , and often one also has ). If we then replace  in the factorization of  by  for each -heavy prime , this increases  (and does not decrease any of the  factors of ), while eliminating all the -heavy primes. With a somewhat crude matching algorithm, I was able to do this using  of the  powers of  dividing , leaving  powers remaining at my disposal. (I donâ€™t claim that this is the most efficient matching, in terms of powers of two required, but it sufficed.)  There are still  -heavy primes left over in the factorization of (the modified version of) . Replacing each of these primes with , and then distributing the remaining  powers of two arbitrarily, this obtains a factorization of  into  terms, each of which are at least .\n\nHowever, I was not able to adjust parameters to reach  in this manner. Perhaps some readers here who are adept with computers can come up with a more efficient construction to get closer to this bound? If one can find a way to reach this bound, most likely it can be adapted to then resolve conjectures (ii) and (iii) above after some additional numerical effort.\n\nShare this:PrintEmailMoreTwitterFacebookRedditPinterestLike Loading...\n\nRecent Comments\n\t\t\t\t\tAnonymous on The blue-eyed islanders puzzleâ€¦Anonymous on The blue-eyed islanders puzzleâ€¦Anonymous on The blue-eyed islanders puzzleâ€¦Anonymous on Decomposing a factorial into lâ€¦Anonymous on Cosmic Distance Ladder videosâ€¦Anonymous on Analysis IAnonymous on Analysis ITerence Tao on Analysis IAnonymous on Analysis Ifrobitzblog on Decomposing a factorial into lâ€¦Anonymous on Analysis IAnonymous on Analysis IAnonymous on Analysis ITerence Tao on Decomposing a factorial into lâ€¦Terence Tao on Decomposing a factorial into lâ€¦\n\nTop PostsDecomposing a factorial into large factorsThe three-dimensional Kakeya conjecture, after Wang and ZahlCareer adviceCosmic Distance Ladder videos with Grant Sanderson (3blue1brown): commentary and correctionsAnalysis IBooksOn writingWork hardDoes one have to be a genius to do maths?AboutArchives\n\n\t\t\t\t\tMarch 2025(1)\n\tFebruary 2025(3)\n\tJanuary 2025(1)\n\tDecember 2024(3)\n\tNovember 2024(4)\n\tOctober 2024(1)\n\tSeptember 2024(4)\n\tAugust 2024(3)\n\tJuly 2024(3)\n\tJune 2024(1)\n\tMay 2024(1)\n\tApril 2024(5)\n\tMarch 2024(1)\n\tDecember 2023(2)\n\tNovember 2023(2)\n\tOctober 2023(1)\n\tSeptember 2023(3)\n\tAugust 2023(3)\n\tJune 2023(8)\n\tMay 2023(1)\n\tApril 2023(1)\n\tMarch 2023(2)\n\tFebruary 2023(1)\n\tJanuary 2023(2)\n\tDecember 2022(3)\n\tNovember 2022(3)\n\tOctober 2022(3)\n\tSeptember 2022(1)\n\tJuly 2022(3)\n\tJune 2022(1)\n\tMay 2022(2)\n\tApril 2022(2)\n\tMarch 2022(5)\n\tFebruary 2022(3)\n\tJanuary 2022(1)\n\tDecember 2021(2)\n\tNovember 2021(2)\n\tOctober 2021(1)\n\tSeptember 2021(2)\n\tAugust 2021(1)\n\tJuly 2021(3)\n\tJune 2021(1)\n\tMay 2021(2)\n\tFebruary 2021(6)\n\tJanuary 2021(2)\n\tDecember 2020(4)\n\tNovember 2020(2)\n\tOctober 2020(4)\n\tSeptember 2020(5)\n\tAugust 2020(2)\n\tJuly 2020(2)\n\tJune 2020(1)\n\tMay 2020(2)\n\tApril 2020(3)\n\tMarch 2020(9)\n\tFebruary 2020(1)\n\tJanuary 2020(3)\n\tDecember 2019(4)\n\tNovember 2019(2)\n\tSeptember 2019(2)\n\tAugust 2019(3)\n\tJuly 2019(2)\n\tJune 2019(4)\n\tMay 2019(6)\n\tApril 2019(4)\n\tMarch 2019(2)\n\tFebruary 2019(5)\n\tJanuary 2019(1)\n\tDecember 2018(6)\n\tNovember 2018(2)\n\tOctober 2018(2)\n\tSeptember 2018(5)\n\tAugust 2018(3)\n\tJuly 2018(3)\n\tJune 2018(1)\n\tMay 2018(4)\n\tApril 2018(4)\n\tMarch 2018(5)\n\tFebruary 2018(4)\n\tJanuary 2018(5)\n\tDecember 2017(5)\n\tNovember 2017(3)\n\tOctober 2017(4)\n\tSeptember 2017(4)\n\tAugust 2017(5)\n\tJuly 2017(5)\n\tJune 2017(1)\n\tMay 2017(3)\n\tApril 2017(2)\n\tMarch 2017(3)\n\tFebruary 2017(1)\n\tJanuary 2017(2)\n\tDecember 2016(2)\n\tNovember 2016(2)\n\tOctober 2016(5)\n\tSeptember 2016(4)\n\tAugust 2016(4)\n\tJuly 2016(1)\n\tJune 2016(3)\n\tMay 2016(5)\n\tApril 2016(2)\n\tMarch 2016(6)\n\tFebruary 2016(2)\n\tJanuary 2016(1)\n\tDecember 2015(4)\n\tNovember 2015(6)\n\tOctober 2015(5)\n\tSeptember 2015(5)\n\tAugust 2015(4)\n\tJuly 2015(7)\n\tJune 2015(1)\n\tMay 2015(5)\n\tApril 2015(4)\n\tMarch 2015(3)\n\tFebruary 2015(4)\n\tJanuary 2015(4)\n\tDecember 2014(6)\n\tNovember 2014(5)\n\tOctober 2014(4)\n\tSeptember 2014(3)\n\tAugust 2014(4)\n\tJuly 2014(5)\n\tJune 2014(5)\n\tMay 2014(5)\n\tApril 2014(2)\n\tMarch 2014(4)\n\tFebruary 2014(5)\n\tJanuary 2014(4)\n\tDecember 2013(4)\n\tNovember 2013(5)\n\tOctober 2013(4)\n\tSeptember 2013(5)\n\tAugust 2013(1)\n\tJuly 2013(7)\n\tJune 2013(12)\n\tMay 2013(4)\n\tApril 2013(2)\n\tMarch 2013(2)\n\tFebruary 2013(6)\n\tJanuary 2013(1)\n\tDecember 2012(4)\n\tNovember 2012(7)\n\tOctober 2012(6)\n\tSeptember 2012(4)\n\tAugust 2012(3)\n\tJuly 2012(4)\n\tJune 2012(3)\n\tMay 2012(3)\n\tApril 2012(4)\n\tMarch 2012(5)\n\tFebruary 2012(5)\n\tJanuary 2012(4)\n\tDecember 2011(8)\n\tNovember 2011(8)\n\tOctober 2011(7)\n\tSeptember 2011(6)\n\tAugust 2011(8)\n\tJuly 2011(9)\n\tJune 2011(8)\n\tMay 2011(11)\n\tApril 2011(3)\n\tMarch 2011(10)\n\tFebruary 2011(3)\n\tJanuary 2011(5)\n\tDecember 2010(5)\n\tNovember 2010(6)\n\tOctober 2010(9)\n\tSeptember 2010(9)\n\tAugust 2010(3)\n\tJuly 2010(4)\n\tJune 2010(8)\n\tMay 2010(8)\n\tApril 2010(8)\n\tMarch 2010(8)\n\tFebruary 2010(10)\n\tJanuary 2010(12)\n\tDecember 2009(11)\n\tNovember 2009(8)\n\tOctober 2009(15)\n\tSeptember 2009(6)\n\tAugust 2009(13)\n\tJuly 2009(10)\n\tJune 2009(11)\n\tMay 2009(9)\n\tApril 2009(11)\n\tMarch 2009(14)\n\tFebruary 2009(13)\n\tJanuary 2009(18)\n\tDecember 2008(8)\n\tNovember 2008(9)\n\tOctober 2008(10)\n\tSeptember 2008(5)\n\tAugust 2008(6)\n\tJuly 2008(7)\n\tJune 2008(8)\n\tMay 2008(11)\n\tApril 2008(12)\n\tMarch 2008(12)\n\tFebruary 2008(13)\n\tJanuary 2008(17)\n\tDecember 2007(10)\n\tNovember 2007(9)\n\tOctober 2007(9)\n\tSeptember 2007(7)\n\tAugust 2007(9)\n\tJuly 2007(9)\n\tJune 2007(6)\n\tMay 2007(10)\n\tApril 2007(11)\n\tMarch 2007(9)\n\tFebruary 2007(4)\n\n\t\t\tCategories\n\n\t\t\t\t\texpository (315)\n\n\ttricks (13)\n\n\tguest blog (10)\n\n\tMathematics (885)\n\n\tmath.AC (8)\n\n\tmath.AG (42)\n\n\tmath.AP (114)\n\n\tmath.AT (17)\n\n\tmath.CA (188)\n\n\tmath.CO (197)\n\n\tmath.CT (9)\n\n\tmath.CV (37)\n\n\tmath.DG (37)\n\n\tmath.DS (89)\n\n\tmath.FA (24)\n\n\tmath.GM (14)\n\n\tmath.GN (21)\n\n\tmath.GR (88)\n\n\tmath.GT (16)\n\n\tmath.HO (13)\n\n\tmath.IT (13)\n\n\tmath.LO (53)\n\n\tmath.MG (47)\n\n\tmath.MP (31)\n\n\tmath.NA (24)\n\n\tmath.NT (199)\n\n\tmath.OA (22)\n\n\tmath.PR (109)\n\n\tmath.QA (6)\n\n\tmath.RA (47)\n\n\tmath.RT (21)\n\n\tmath.SG (4)\n\n\tmath.SP (48)\n\n\tmath.ST (11)\n\n\tnon-technical (195)\n\n\tadmin (46)\n\n\tadvertising (66)\n\n\tdiversions (7)\n\n\tmedia (14)\n\n\tjournals (3)\n\n\tobituary (15)\n\n\topinion (36)\n\n\tpaper (253)\n\n\tbook (20)\n\n\tCompanion (13)\n\n\tupdate (23)\n\n\tquestion (127)\n\n\tpolymath (86)\n\n\ttalk (68)\n\n\tDLS (20)\n\n\tteaching (188)\n\n\t245A â€“ Real analysis (11)\n\n\t245B â€“ Real analysis (21)\n\n\t245C â€“ Real analysis (6)\n\n\t246A â€“ complex analysis (11)\n\n\t246B â€“ complex analysis (5)\n\n\t246C â€“ complex analysis (5)\n\n\t247B â€“ Classical Fourier Analysis (5)\n\n\t254A â€“ analytic prime number theory (19)\n\n\t254A â€“ ergodic theory (18)\n\n\t254A â€“ Hilbert's fifth problem (12)\n\n\t254A â€“ Incompressible fluid equations (5)\n\n\t254A â€“ random matrices (14)\n\n\t254B â€“ expansion in groups (8)\n\n\t254B â€“ Higher order Fourier analysis (9)\n\n\t255B â€“ incompressible Euler equations (2)\n\n\t275A â€“ probability theory (6)\n\n\t285G â€“ poincare conjecture (20)\n\n\tLogic reading seminar (8)\n\n\tThe sciences (1)\n\n\ttravel (26)\n\n\t\t\tadditive combinatorics\napproximate groups\narithmetic progressions\nBen Green\nCauchy-Schwarz\nCayley graphs\ncentral limit theorem\nChowla conjecture\ncompressed sensing\ncorrespondence principle\ndistributions\ndivisor function\neigenvalues\nElias Stein\nEmmanuel Breuillard\nentropy\nequidistribution\nergodic theory\nEuler equations\nexponential sums\nfinite fields\nFourier transform\nFreiman's theorem\nGowers uniformity norm\nGowers uniformity norms\ngraph theory\nGromov's theorem\nGUE\nHilbert's fifth problem\nincompressible Euler equations\ninverse conjecture\nJoni Teravainen\nKaisa Matomaki\nKakeya conjecture\nLie algebras\nLie groups\nLiouville function\nLittlewood-Offord problem\nMaksym Radziwill\nMobius function\nmultiplicative functions\nNavier-Stokes equations\nnilpotent groups\nnilsequences\nnonstandard analysis\nparity problem\nPaul Erdos\npolitics\npolymath1\npolymath8\nPolymath15\npolynomial method\npolynomials\nprime gaps\nprime numbers\nprime number theorem\nrandom matrices\nrandomness\nRatner's theorem\nregularity lemma\nRicci flow\nRiemann zeta function\nSchrodinger equation\nShannon entropy\nsieve theory\nstructure\nSzemeredi's theorem\nTamar Ziegler\ntiling\nUCLA\nultrafilters\nuniversality\nVan Vu\nwave maps\nYitang Zhang The Polymath BlogPolymath projects 2021A sort of Polymath on a famous MathOverflow problemTen Years of PolymathUpdates and PicturesPolymath proposal: finding simpler unit distance graphs of chromatic number 5A new polymath proposal (related to the Riemann Hypothesis) over Taoâ€™s blogSpontaneous Polymath 14 â€“ A success!Polymath 13 â€“ a success!Non-transitive Dice over Gowersâ€™s BlogRotaâ€™s Basis Conjecture: Polymath 12, post 3\n\n\t\t\t13 comments\n\t\t\tComments feed for this article\n\n\t\t\t26 March, 2025 at 8:27 pm\n\t\t\tAnonymous\n\n\t\t\t\t\t\tthere is an open brace for href\n[Corrected, thanks â€“ T.]\n\n\t\t\t\tReply\n\n\t\t\t26 March, 2025 at 11:04 pm\n\t\t\tSamuel Bonaya Buya\n\n\t\t\t\t\t\tIn my opinion the paper is a significant contribution by Tao on the understanding of the prime number theorem\n\n\t\t\t\tReply\n\n\t\t\t27 March, 2025 at 4:02 am\n\t\t\tAntoine Deleforge\n\n\t\t\t\t\t\tLooking at the first few numbers in the OEIS sequence, it looks like t(n+1) â€“ t(n) is always zero or one. Is there any reason for this to be true?\n\n\t\t\t\tReply\n\n\t\t\t27 March, 2025 at 6:39 am\n\t\t\tTerence Tao\n\n\t\t\t\t\t\tNo; in fact, in Guyâ€™s article on this problem, he notes that there is a jump of  from  to  (though he does not provide enough preceding values to extend the sequence in the OEIS).  In that article he also notes that Erdos conjectures that the gaps can in fact be arbitrarily large, though I see no way to attack this question even heuristically (as the extremizers for this problem may be neither structured nor (pseudo)random, but exhibit some very strange intermediate behavior).\nIn the image below, I display the upper bound on  (the pink dots) in the intermediate range  coming from Lemma 2.1 of my paper (there is no plot for  in this image as I do not have data in this range).  [Incidentally there is a slight typo in that lemma, which I will correct in the next revision: the term  should instead be .]  There is considerable fluctuation here (due to the corresponding fluctuation in the primes), which is also reflected in the related plot in Figure 2 of the paper.  Of course, fluctuation in the upper bound for  does not imply fluctuation in the true value of , but it is perhaps evidence in that direction.\n\nAnd below is a comparison of the upper bound against the true value of  in the range :\n\n\t\t\t\tReply\n\n\t\t\t27 March, 2025 at 4:14 am\n\t\t\tIvan\n\n\t\t\t\t\t\tYou may want to enclose the comma in curly brackets when it is used as a thousands separator so that  does not generate extra space after it, e.g.,  instead of  (p. 3 of the paper).\n[Thanks, this will be done in the next revision of the ms -T]\n\n\t\t\t\tReply\n\n\t\t\t27 March, 2025 at 5:18 am\n\t\t\tAntoine Deleforge\n\n\t\t\t\t\t\tI donâ€™t immediately see the connection to the knapsack problem. If we pick the non-dividable items to be the logs of the prime factors of N!, then the problem amounts to distributing *all* of these items into N knapsacks, such that each knapsack contains *at least* a value of t(N). This is quite different from the original knapsack problem where the goal is rather to select a *subset* of items, and maximize the value while remaining *below* the knapsack capacity. Is there a deeper or more natural connection that I am missing? Can further progress on this Erdos problem be expected to eventually yield insights on the knapsack problem, or is the relation between the two too distant for that to happen?\n\n\t\t\t\tReply\n\n\t\t\t27 March, 2025 at 6:53 am\n\t\t\tTerence Tao\n\n\t\t\t\t\t\tItâ€™s more accurate to say that the factorial problem is a *variant* of the knapsack problem; most directly, it corresponds to a knapsack problem with negative item sizes (and negative capacity in the backpack), which of course is not physically realistic (or intuitive), but it is possible that some of the knapsack algorithms that work for positive sizes and capacities can carry over to this new context with suitable modification.  (For instance, I would guess that the problem of solving this sort of factoring problem for a general input number (rather than a factorial) is NP-complete, by some modification of the proof of NP-completeness of the knapsack problem.)\nNote by the way that to solve the factorization problem, it suffices to distribute some subset of the log-primes into the knapsacks rather than all of them, since one can just add in the remaining log-primes arbitrarily to finish the job.\n\n\t\t\t\tReply\n\n\t\t\t27 March, 2025 at 7:08 am\n\t\t\tducduc2710\n\n\t\t\t\t\t\tThat technique I think can be used to limit prime gaps.\n\n\t\t\t\tReply\n\n\t\t\t27 March, 2025 at 7:21 am\n\t\t\tAnonymous\n\n\t\t\t\t\t\tSmall typo: â€œmultiples of four between3/4 to Nâ€ It should be 3/4N to N.\n\n[Corrected, thanks -T.]\n\n\t\t\t\tReply\n\n\t\t\t27 March, 2025 at 11:35 am\n\t\t\tTerence Tao\n\n\t\t\t\t\t\tIâ€™m posting (with permission) some computational work by Andrew Sutherland, who implemented a greedy approach working through the prime factors  of  inreverse order (with multiplicity), constucting integers of the form  with  chosen to be minimal subject to the constraint that it can be constructed from the divisors of  that still remain. For instance when , it is able to factor  into  numbers greater than or equal to , verifying the Guy-Selfridge conjecture at this value. The code (in Maple) is at https://math.mit.edu/~drew/GuySelfridge.m . An earlier (less efficient) factorization with these parameters can be found at https://math.mit.edu/~drew/ES300000.txt .\nAndrew writes, â€ It only takes about a few seconds on a fast machine so I was able to run it on all  in  and noticed that while it typically succeeds on , it still fails to prove  in  cases in , including  as large as . But it succeeds on every  in , so if the conjecture is true, it is still true if you replace  with  (probably this can be lowered a lot further, the greedy approach is not optimal).\nI then tested the threshold  on all  from  to . It failed only for â€œ.\nWith this data, one can now reduce conjecture (ii) to conjecture (iii) provided one can construct suitable factorizations of  to resolve the three remaining cases  (one also has to retest the range  but this should be straightforward, since there is now enough room that one should be able to sample this range quite sparsely, e.g., test the threshold  for  a multiple of ). But the range  seems a bit more delicate, as the most direct greedy algorithm sometimes fails.\nAndrew adds, â€œI think itâ€™s possible that one might be able to turn this algorithm into an asymptotic bound. For sufficiently large prime divisors  of , you can just take  because  will be small and there are plenty of powers of small primes initially available (and you can quantify this), and even if you focus just on the integers the algorithm constructs before it hits the first cofactor it cannot minimize you should get some constant factor of  that might be bigger than .â€\n\n\t\t\t\tReply\n\n\t\t\t27 March, 2025 at 12:18 pm\n\t\t\tTerence Tao\n\n\t\t\t\t\t\tAndrew has kindly shared with me the lower bounds for  for  given by this approach, and I have incorporated them into my previous plot here, showing the current upper (pink) and lower (blue) bounds on :\n\nNote the verification of the conjecture  in this range for .  The data also replicates Guyâ€™s reported values , and suggests that the jumps in  are indeed rather irregular. (The text file for the data can be found here.)\n\n\t\t\t\tReply\n\n\t\t\t27 March, 2025 at 2:35 pm\n\t\t\tfrobitzblog\n\n\t\t\t\t\t\tWith a bit of fiddling by hand I was able to improve the factorizations for N=182,200,207, so now (ii) is confirmed up to 100,000.  You can find the factorizations here, here, and here.\n\n\t\t\t\tReply\n\n\t\t\t28 March, 2025 at 8:12 am\n\t\t\tAnonymous\n\n\t\t\t\t\t\tShould inequality (4) have t(N)/N on the left-hand side (as opposed to just t(N))?\n[Corrected, thanks â€“ T.]\n\n\t\t\t\tReply\n\n\t\tLeave a comment Cancel reply\n\n\t\t\tÎ”document.getElementById( \"ak_js_1\" ).setAttribute( \"value\", ( new Date() ).getTime() );",
    "summary": {
      "en": "The paper \"Decomposing a Factorial into Large Factors\" by Terence Tao, discusses how to divide a factorial into several factors that are all at least a certain size. This topic builds on work started by mathematician Paul ErdÃ¶s, who was interested in finding upper and lower limits for this factorization.\n\nKey points include:\n\n1. **Definition**: The paper defines a quantity related to how well a factorial can be split into factors of a minimum size. The goal is to find the largest number of factors that can be used while ensuring each factor meets the size requirement.\n\n2. **Historical Context**: ErdÃ¶s had previously conjectured about the bounds of this quantity but did not fully prove it due to the loss of notes from collaborator John Straus.\n\n3. **Recent Findings**: Tao establishes new bounds for this quantity and recovers some previously lost results. He also suggests that the problem resembles a variant of the knapsack problem, where items (or factors) must be optimally selected to meet certain criteria.\n\n4. **Conjectures**: Tao discusses several conjectures related to the bounds and invites further computational exploration to resolve them. He provides methods for approximating the factorization and suggests a potential crowd-sourced approach to verify certain conjectures.\n\n5. **Methodology**: The paper details how to improve factorization by manipulating prime factors and redistributing them to achieve the required minimum size for all factors.\n\nOverall, the paper contributes to understanding how to effectively decompose factorials, a topic with connections to number theory and combinatorial optimization.",
      "ko": "í…Œë ŒìŠ¤ íƒ€ì˜¤ì˜ ë…¼ë¬¸ \"íŒ©í† ë¦¬ì–¼ì„ í° ì¸ìˆ˜ë¡œ ë¶„í•´í•˜ê¸°\"ëŠ” íŒ©í† ë¦¬ì–¼ì„ ìµœì†Œí•œì˜ í¬ê¸°ë¥¼ ê°€ì§„ ì—¬ëŸ¬ ì¸ìˆ˜ë¡œ ë‚˜ëˆ„ëŠ” ë°©ë²•ì— ëŒ€í•´ ë‹¤ë£¹ë‹ˆë‹¤. ì´ ì£¼ì œëŠ” ìˆ˜í•™ì í´ ì—ë¥´ë˜ì‹œê°€ ì‹œì‘í•œ ì—°êµ¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ë©°, ê·¸ëŠ” ì´ëŸ¬í•œ ì¸ìˆ˜ ë¶„í•´ì˜ ìƒí•œê³¼ í•˜í•œì„ ì°¾ëŠ” ë° ê´€ì‹¬ì´ ìˆì—ˆìŠµë‹ˆë‹¤.\n\në…¼ë¬¸ì˜ ì£¼ìš” ë‚´ìš©ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. ì²«ì§¸, íŒ©í† ë¦¬ì–¼ì„ ìµœì†Œ í¬ê¸°ì˜ ì¸ìˆ˜ë¡œ ì–¼ë§ˆë‚˜ ì˜ ë‚˜ëˆŒ ìˆ˜ ìˆëŠ”ì§€ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì–‘ì„ ì •ì˜í•©ë‹ˆë‹¤. ëª©í‘œëŠ” ê° ì¸ìˆ˜ê°€ í¬ê¸° ìš”ê±´ì„ ì¶©ì¡±í•˜ë©´ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ìµœëŒ€ ì¸ìˆ˜ì˜ ìˆ˜ë¥¼ ì°¾ëŠ” ê²ƒì…ë‹ˆë‹¤. \n\në‘˜ì§¸, ì—ë¥´ë˜ì‹œëŠ” ì´ ì–‘ì˜ ê²½ê³„ì— ëŒ€í•´ ì´ì „ì— ì¶”ì¸¡í–ˆì§€ë§Œ, ë™ë£Œì¸ ì¡´ ìŠ¤íŠ¸ë¼ìš°ìŠ¤ì˜ ë…¸íŠ¸ë¥¼ ìƒì–´ë²„ë ¤ ì™„ì „í•œ ì¦ëª…ì„ í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. \n\nì…‹ì§¸, íƒ€ì˜¤ëŠ” ì´ ì–‘ì— ëŒ€í•œ ìƒˆë¡œìš´ ê²½ê³„ë¥¼ ì„¤ì •í•˜ê³  ì´ì „ì— ìƒì–´ë²„ë¦° ê²°ê³¼ë¥¼ íšŒë³µí•©ë‹ˆë‹¤. ê·¸ëŠ” ì´ ë¬¸ì œê°€ íŠ¹ì • ê¸°ì¤€ì„ ì¶©ì¡±í•˜ê¸° ìœ„í•´ ì•„ì´í…œ(ë˜ëŠ” ì¸ìˆ˜)ì„ ìµœì ìœ¼ë¡œ ì„ íƒí•´ì•¼ í•˜ëŠ” ë°°ë‚­ ë¬¸ì œì˜ ë³€í˜•ê³¼ ìœ ì‚¬í•˜ë‹¤ê³  ì œì•ˆí•©ë‹ˆë‹¤. \n\në„·ì§¸, íƒ€ì˜¤ëŠ” ê²½ê³„ì™€ ê´€ë ¨ëœ ì—¬ëŸ¬ ì¶”ì¸¡ì„ ë…¼ì˜í•˜ë©°, ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ ì¶”ê°€ì ì¸ ê³„ì‚° íƒìƒ‰ì„ ê¶Œì¥í•©ë‹ˆë‹¤. ê·¸ëŠ” ì¸ìˆ˜ ë¶„í•´ë¥¼ ê·¼ì‚¬í•˜ëŠ” ë°©ë²•ì„ ì œê³µí•˜ê³ , íŠ¹ì • ì¶”ì¸¡ì„ ê²€ì¦í•˜ê¸° ìœ„í•œ ì ì¬ì ì¸ í¬ë¼ìš°ë“œì†Œì‹± ì ‘ê·¼ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. \n\në§ˆì§€ë§‰ìœ¼ë¡œ, ë…¼ë¬¸ì€ ì†Œì¸ìˆ˜ë¥¼ ì¡°ì‘í•˜ê³  ì¬ë¶„ë°°í•˜ì—¬ ëª¨ë“  ì¸ìˆ˜ê°€ ìš”êµ¬ë˜ëŠ” ìµœì†Œ í¬ê¸°ë¥¼ ë‹¬ì„±í•˜ë„ë¡ ì¸ìˆ˜ ë¶„í•´ë¥¼ ê°œì„ í•˜ëŠ” ë°©ë²•ì„ ìì„¸íˆ ì„¤ëª…í•©ë‹ˆë‹¤. ì „ë°˜ì ìœ¼ë¡œ ì´ ë…¼ë¬¸ì€ ìˆ«ì ì´ë¡ ê³¼ ì¡°í•© ìµœì í™”ì™€ ê´€ë ¨ëœ íŒ©í† ë¦¬ì–¼ ë¶„í•´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì´í•´í•˜ëŠ” ë° ê¸°ì—¬í•©ë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "725d856e594facb9",
    "title": {
      "en": "Finley (YC W21) Is Hiring a Technical Implementations Specialist",
      "ko": null,
      "ja": null
    },
    "type": "job",
    "url": "https://ats.rippling.com/finley-technologies/jobs",
    "score": 1,
    "by": "festinalente",
    "time": 1743195709,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "143a7a518678cbf9",
    "title": {
      "en": "The Art of DJing: Avalon Emerson (2019)",
      "ko": "DJingì˜ ë¯¸í•™: ì•„ë°œë¡  ì—ë¨¸ìŠ¨",
      "ja": null
    },
    "type": "story",
    "url": "https://it.ra.co/features/3392",
    "score": 39,
    "by": "easyThrowaway",
    "time": 1743189734,
    "content": "#feature {\n\n    }\n\n    #feature a {\n\n    }\n\n    #feature .quote {\n\n    }\n\n      One of the most creative DJs in the game unpacks her methods for Elissa Stolman.\n\nWe're celebrating ten years of The Art of DJing. Get stuck into more of the series here.\n\nAbout a week before our scheduled date for this interview, Avalon Emerson seemed over it. \"I'm not a vibeman,\" she told me, contrasting her technical acumen with the unlearnable, abstract magic other DJs apparently possess. She was concerned that this feature would break down her workflow into digestible info nuggets that most people could and have figured out and that anyone can replicate. As a result she'd come off too clinical, her talents less impressive than those of the DJs she calls \"vibemen.\"\n\nBut never in my life have I met someone who vibes more intensely than Avalon Emerson. Her vibes have the capacity to exalt and to destroy. How did she not realize that she is a total vibewoman?\n\nSure, some have probably discovered any given facet of her organizational methodology. Others use many of the same rekordbox and CDJ functions. But they didn't create the mind palace that is Emerson's approach to DJing. I visualize her way of obtaining, organizing, editing, playing, mixing and archiving music as a Fordist factory designed like a panopticon. Although the individual tasks are simple, their integration into a logical whole is remarkable. It's a less romantic vision of what makes her a great DJ, but it's no less impressive.\n\nEmerson's approach to hacking DJ technology's underused possibilities seems like an application of her knowledge of computer programming. It's probably her nerdinessâ€”visual, intellectual and musicalâ€”that distinguishes her most obviously from the vibemen of DJ world. Vibemen preside over ecstatic dance floors, sweating and grimacing while they blend the old-fashioned way. Emerson leans in close to the screen with her fingers on the dial and squints through Navigator glasses, piloting the CDJ with the practiced ease of someone who types very quickly.\n\nThe whole tech whiz thing is ultimately a tool that allows her to devote most of her CPU to determining what to play and when, enchanting a crowd, making people danceâ€”in short, delivering the kind of ecstatic communal experience that elevates playing songs to the art of DJing. Her entire process of organising and playing music is engineered to help her find and transition to the next song as quickly possible, which is key for someone who jumps between genres and tempos as often as Emerson does. Any given set might include shades of hi-NRG and New Beat, booming breakbeats or aquatic house rollers, but they always bear her pop sensibility. Many of the edits she plays occasionally appear as free downloads on her personal website under the banner of Cybernedits.\n\nEmerson has taught me a lot of things about DJing and production. One of her most salient lessons was one she demonstrates more often than she articulates: a technological and rational approach doesn't eliminate an artist's creative jujuâ€”one can enhance the other. Anyone can learn Emerson's tricks, but the rest is up to you.\n\nLet's start with how you developed your current style of mixing. You don't usually bring records to gigs anymore, but you used to. When and why did you phase out vinyl? How long of a process was that?\n\nTo be honest, like a lot of other new DJs, I felt like if I didn't walk into the club with vinyl then I was somehow or perceived to be \"less\" of a DJ. So I felt pressured to do so. But it's annoying to carry records around, and more importantly, you can do more interesting things on CDJs. I also edit a lot of stuff, and those edits obviously only exist as digital files.\n\nDid you learn to DJ on vinyl?\n\nNot really. I used iTunes the first time I played music for people in a party scenario when I was like, 19.\n\nWas there ever a period where you played only or mostly vinyl?\n\nNo. I played CDs for a long time in San Francisco because USB CDJs didn't exist for the majority of the time that I lived there. Some bars had a Serato box, but I didn't buy one. Back then, whenever I encountered CDJs, they were usually these crazy wedding CDJs that are like, rack-mount units with CD trays that pop out like old desktop computers. The options were either vinyl, Serato or those CDJs, and no one used CDJs until the CDJ 1000s started popping up. I've made edits and produced music for longer than I've been a DJ, so I've always wanted to incorporate my original material. That's the main reason I've never been a vinyl-only DJ.\n\nWhen did you decide that people who judged others negatively for not using vinyl were wrong?\n\nWhen I started getting feedback that I was a good DJ. I was better than a lot of people who were playing only vinyl anyways.\n\nYou don't play vinyl anymore, but you do have a vinyl collection here at your house. Why do you still buy records?\n\nBecause that's still usually the most straightforward way to get a high-quality version of a track, and with old stuff it's often the only way. Buying and ripping is a massive part of being a DJ nowadays. Do I carry it in a Rimowa everywhere? No. But I still buy and rip constantly. I use a belt-drive turntable to rip records because the timing is more constant and they apparently transfer less noise to the needle. It's more of a hi-fi turntable. The signal goes through a Urei Soundcraft 1620 mixer, which has nice vinyl preamps in it and just sounds nice. That goes into my Soundcraft sound card, and then I record that in Ableton. Then I edit, EQ, decrackle, and remaster and normalize it.\n\nWhen I first moved to Berlin, I didn't have a good set-up for ripping, so sometimes I brought a few records to gigs because I didn't have the track digitally or because I just wanted to play vinyl. But I stopped using vinyl at all as I started to prioritize archiving my sets. I save the history of my gigs so that I can look back over four years and see exactly what I played in the order I played it. You can't do that with vinyl.\n\nWhy do you find it helpful to archive your sets?\n\nI don't do it so that I can get better, I do it mostly for personal archival reasons. I want to know what I played in Panorama Bar in July 2015. I think it's cool to be able to look back and see that. Compared to making music and releasing it on a record, DJing a party is inherently ephemeral. The medium requires the context of the space and time to be relevant as an artform. So any type of archival stuff like recording my sets, which I do as much as I can, is really important to me, but it's kinda a personal thing.\n\nWhat equipment do you bring to gigs, and how do you use each piece?\n\nMy rider says: no vinyl; three or four CDJs, at least 2000 Mark I, Mark II if available; an Allen & Heath Xone 92 or 96. I like how effect routing works on the Allen & Heath. At the top of the section about mixers is something that says, if there's a nice rotary mixer available in the clubâ€”some clubs secretly do have a nice rotaryâ€”I'd like to use it. I DJ a lot, so playing on nice hi-fi rotaries every once in a while can break it up a little bit and make it interesting and fun for me. I bring USBsâ€”well, right now I use super high-speed SD cards made for photographers and videographers. I need ones with high write speeds because I have a billion different intelligent playlists, and it'll take Rekordbox much longer to write the music onto a drive with a run-of-the-mill, cheap USB drive. And if you have something with a slow read-speed paired with an older CDJ, that's when you start getting \"Cannot read\" or buffering errors. I also bring headphones and pedals.\n\nTell me about the pedals. What do you use the pedals for?\n\nI used to bring an isolator and sometimes I bring two pedals, but usually I just bring one. Sometimes it's a delay, sometimes it's a reverb. I've tried different ones and switch them out when I get sick of them. If I'm using a rotary mixer, I usually don't use the pedals because most of themâ€”except for some E&S DJR 400sâ€”don't have an effect loop or it's not routed as a send/return. Most of the time when I use a pedal, I route it as a send/return through the Xone 92 rather than as an insert effect, which is a fundamentally different way of doing effects. It's like in Ableton: if you a drop a reverb directly onto the track, it's different than if you send the track's dry signal to a return, which is the way you do it on an Allen & Heath. I have the pedal plugged into a return on the mixer and have the fader all the way up with the signal 100 percent wet. That means when I chop something in, I send the track's dry signal to the effect return using the knobs above the gain, and that delay or reverb will remain in the mix even if I take the dry signal out.\n\nIf I want to mix out in a dramatic way, I can increase the wet signal from the outgoing track as it's fading out or coming to a point where I want to chop it out. I increase the effect on channel one until there's a snare roll or something and time that with some big, meaty change in the incoming track. I increase the effect wetness on channel one, and then drop out the dry signal of channel one by pulling down the fader. Instead of just having a silent void immediately following that cut, there's a nice little reverb or delay tail, and that passes the baton in a more musical way to track two.\n\nWhat kind of reverbs and delay pedals do you use?\n\nI use a bunch of different kinds. The Strymon blueSky Reverb is kind of a techno bro one, but it's nice. I also have a TC Electronic Hall Of Fame 2, a Teil1 Keinedelay and an Eventide Space, and a really cheap little Mooer Ana Echo, which is a little too gnarly for me, and it's in mono. Once I played with it at De School, and it self-oscillated in a very loud way. I was kind of embarrassed.\n\nThat's the same way you learned to do things on a CDJ, right? By trying things at a gig you haven't done beforeâ€”and sometimes that doesn't go your way.\n\nYeah, for sure. Of course. All the time. If you're not going to try something because you might be embarrassed by it, then you should just quit trying anything in life, because you're gonna fail at it sometimes, too.\n\nWhat CDJ functions do you use the most often?\n\nI loop stuff. I use the track tag and parameter filters, and I use hot cues to break up a track's linear structure.\n\nHow much preparation does that entail in rekordbox?\n\nIt's easier to set hot cues if you do it ahead of time, but you can do it on the fly, and I do that sometimes. You have to set auto-loops in advance, so that once the playhead reaches the timecode you set, it'll automatically start looping there. Say there's a really chill part of a track before it goes into a hectic part with vocals and horns and all kinds of stuff, and you'd rather mix out before that happensâ€”you can do that. Also, any notes have to be set in advance. A note that says \"vocals\" or \"hit C to skip breakdown\" helps me do some of my \"live editing\" and gives me flexibility and breathing room when it comes to how I play certain songs. The other functions I use most are beat jump, which makes the playhead skip a certain amount of beats ahead or backwards. I also use slip mode a bit, which lets you scratch or loop or do a goofy vinyl break without losing your place in the song.\n\nYou've mentioned chopping tracks in, mixing out in dramatic ways and rearranging tracks using hot cues. How would you describe your approach to mixing records? You're not trying to make long, seamless blends that are phrased well within the limitations of a track's given arrangement, which is often how people mix with vinyl.\n\nI do a lot of cutting and quick mixes. I often layer two eight-bar loops on top of one another, and then I'll let one of the loops go so that the song can build while still maintaining some elements from the previous song until the main part comes in and I want the other one to get out of the way. It's about timing, bottling up energy from tracks and having them stack on top of one another and telling a storyâ€”not always in the DJ Harvey-style, vibeman journey way. I think of my \"storytelling\" more like putting a few words together into a clause, and that clause forms a sentence, then I string together sentences to say something in a passage. It's not just about playing songs that have similar-sounding elements in them or that would have been tagged as the same genre in rekordbox. It's hard to quantify.\n\nNow you're talking about structuring sets, not the way you transition between tracks.\n\nYeah. I could probably loop all of my sets into a few different categories. The first is short festival sets that last an hour or two. Then there are four-hour headlining slots at a club, not on a stage. The last category is long sets, like eight hours closing Panorama Bar. Especially during festival sets, I don't really have a lot of room for indecision in the booth. I don't want to be in a position where I'm like, \"Hmm, maybe I'll go in this direction,\" or, \"Hmm, which one should I start with for this new direction idea that I have?\" Also, to be totally honest, it feels pretty pointless to try and \"read\" a crowd of a few thousand people. So for those I have a playlist that's usually twice as long as the set's duration, and it's sorted roughly in the order I'd want to play it. In general I want to start with a pretty intro that's not really a dance music thingâ€”like, if you look at my set from MUTEK a few months ago, I played a North Sea Dialect song before going into something that was still deep but more banging, so there was a contrast between the beatless intro and something that hit harder.\n\nDo you usually have an opening track in mind before you start playing?\n\nYeah, pretty much every time. I want the DJ playing before me to be able to finish as loudly or as dramatically or flashy as they want. Then everyone claps, and it's kind of a reset. When two bands play one after the other, they don't try to groove into the previous band's track. It's kind of annoying when people try to mix in from my last track. It's like, \"Hey, chill. You'll have your moment. It's OK, eager beaver.\" So even if the DJ before me plays a tool, I let it run out, we all clap, and then I start.\n\nOK, so at MUTEK you wanted to start with something beatless to reset the vibe and then contrast that with something more hard-hitting.\n\nI think for that one I was playing two hours, which for the festival's biggest stage is kind of long. So I didn't have to immediately start with the crazy vibes. I played some stuff that's more sparse and drummy and that had some more angular rhythms in it. I'm doing a shitty job at describing this.\n\nNo, you're doing fine. You're just doubting yourself because you're starting to use more \"vibeman\" talk rather than technical language to describe what you're talking about right now, but that's OK. I think you tend to downplay how much of your style is vibeman-relatedâ€”we can get into that later.\n\nThat's true. OK. So yeah, after an intro you can really go hard and go kinda fast. But there's no need to rush into a crazy vibe. If you look at it like a graph of energy over time, you don't just wanna be at the top all the time. People get tired. So after I gave them the hardness and excitement of big-room rave, I did long blends for 15 or 20 minutes. There are times when I want to just stitch things together to build a monolithic, washing-over-you vibe by layering drummy acapellas and tooly tracks. It's about building pressure and using energy in a dynamic way instead of just going, \"Here's a song, here's a song.\"\n\nYou mentioned earlier that you think about a rough structure for the set in advance and organize that in rekordbox. Can you explain a little more about how you use rekordbox?\n\nI laid out some basic stuff in The Hour last year, but my process is a little more sophisticated now, so I'm going to explain it again. I've set it up for two situations to do with how I choose each next track: browse versus search. Browse is when I don't know what the next song will be, so I want to have my library set up in a way that facilitates me browsing and picking the next song. Search is what I do when I know what song I want to play next and I need my library set up to help me find it as fast as possible. Sometimes I turn into a big illiterate baby up there and I know what song I want to play, but I can't remember the name of the song or the artist that made it.\n\nIt's easier to recognize or recall a song based on the color of the record's label or something like that. That's another reason people like playing vinyl.\n\nTotally. That's something I do appreciate about vinyl. A 12-inch record is a big, human-sized visual cue that you can hold. I'm often in the situation where I can't come up with the artist name or the track nameâ€”I just know that it had blue cover art and that I played it in Leeds last weekend. Because I have the history of all my gigs archived, I can go back and find it through those playlists. Since I've been DJing professionally for several years, I split those up; Berghain has its own folder, then I have ones for countries or regions. If I had every gig just sorted in reverse chronological order, I'd have to scroll back through months of gigs to get to my last one in Leeds. This way I can just go \"UK > Leeds > Wire September 18.\" The most recent gigs are at the top. I still can't believe I'm doing an interview about this and that this is what I do.\n\nThen I have my intelligent playlists. The gigs playlists are all manual drag-and-drop, but the intelligent ones are made automatically via tags or other attributes that I've set. I have tags like \"techno,\" \"club,\" \"breaks,\" \"acid,\" \"trancey,\" \"wavey,\" \"drummy,\" \"drone\" and some others. And then I have tags for functions, which are more to do with energy or situations that I would play them in. Those function tags are: \"deep,\" \"glue,\" \"dreamy,\" \"poppy,\" \"sunny,\" then the \"tools\" header, which indicates more functional things, like a stem of one of my own songs, an acapella, a beat or an ambient track. My last category of tag is \"Played At,\" which I only uses for places that I play kind of often: Panorama Bar and De School. Since people go there regularly, I don't want to repeat myself too much from set to set, and this allows me to see what I've played there in the past.\n\nAlright, then I better not hear 100 Hz's \"Whisper\" the next time you play Panorama Bar.\n\nYou love that song, and I only played it twice there. I import the history from my USB after I play. After a set, I highlight all the tracks in that playlist and attach the \"Played At Panorama Bar\" tag to it. Rekordbox writes a list of all the tags in the comments section of the file itself. That means that it'll show my \"Played At Panorama Bar\" tag no matter how I navigate to the track on the CDJ, so I can decide if I want to play it again.\n\nWhat goes into that decision? How do you determine when to retire a track or whether to repeat it?\n\nI'm struggling with that right now. Due to the size of my library I can only use 256-gig USBs, which is pretty big. Say I lose my USB and I have to go buy one at the airport or whatever; the 256-gig ones are often not available. That's why I'd like to keep my library under 128 gigs and why I should delete stuff that I don't use. But that would disrupt the archive I've made of all my gigs since 2015.\n\nAnd even if I don't play a certain song anymore, maybe there are songs that I played two years ago and haven't played since, so it's time to bring it back. This is one of my more complex playlists: \"Goodies from two years ago.\" The conditions are: the date the file was added to rekordbox is in the last 36 months but not in the last 24 months; the DJ play count is over two, meaning that I've played it a few times, but it's less than 12, so it's not one of my all-time classic bangers like one of my songs. I play those a lot because I feel like people come to hear me DJ because they like my productions. This Goodies playlist uses data I've been tracking for the last few years to pick songs that I like and that were legit parts of my sets from a specific timeâ€”two years agoâ€”so that I can go back and find stuff I might have forgotten about. I have it for one year ago and then this year, too.\n\nMost of my intelligent playlists listen for combinations of all the tags that I ascribe to a single song, because one song usually has many tags attached to it. That makes importing new songs and categorizing them easy, because when I add a new song, the only thing I have to do is listen to it and semantically define it. I don't have to remember all the playlists that I have and then decide which one goes in where. The other benefit is that rekordbox writes the tags I ascribe to it in the comment field of the AIFF file. So even if I'm scrolling by a brand new song and I'm not super familiar with it, I can look and say, \"Well, the last time I heard it in rekordbox, I ascribed a 'breaks' tag, a 'deep' tag, an 'acid' tag and a 'techno' tag.\" That jogs my memory about what a song sounds like.\n\nThen I have special little playlists of songs that are good for ending a set and an intelligent playlist that searches for my name, so I can find all of my own productions, demos, remixes or Cybernedits.\n\nSince pretty much everything's tagged, I can basically create intelligent playlists on the fly by editing the track filter on the CDJs themselves rather than ahead of time in rekordbox. I've personally never seen someone use the tag filter screen beforeâ€”it's hard to even find an image of it on Google, even though it's a really cool feature. I use it all the time during long sets. I can say I want something that is within six beats per minute of 130, I want things that are tagged \"techno\" and \"breaks\" and \"wave.\" And then boom: the CDJ filters all of my songs to these 18 tracks that satisfy those requirements.\n\nAnother really useful thing is to have auto-playlists for things that I added in the last week, two weeks, four weeks and eight weeks. If I'm in a rush then I can just dump things in there, and I don't have to add them to any playlists or tag them at all and I can still access them quickly.\n\nWhy did you decide to develop this extremely organized method?\n\nLike, why did I decide to get crazy about it? I don't know...\n\nYes you do.\n\nBecause it's \"the best way of organizing your shit\"? It was already there, and I just discovered it.\n\nI guess I'm trying to lead you to articulate one of my own assumptions or observations about you, like all good interviewers do.\n\nIs the observation that I shouldn't be a DJ?\n\nGirlâ€¦ no. I think it's related to what you've brought up about not being a \"vibeman\" or, \"I can't believe I'm talking about this because it's so silly that it's my job to have developed this elaborate analytical method to organize it\"â€”\n\nDo you think it's that elaborate?\n\nIt's pretty elaborate. I mean, just describe how a track goes from being a Dropbox promo that someone sent you to being a part of your set.\n\nWell, first of all, thank you for sending me a Dropbox link, because I can just add it to my Dropbox remotely. I have a folder on my computer that's in my Dropbox folder called \"DJ Music Inbox,\" which is one place where I dump everything so that I can dedicate time to sit down and listen to and tag promos or rips or whatever. I don't put it on my desktop; I don't put it in my Downloads folderâ€”don't do that. If someone sends me a bunch of music and I don't have time to go through it now but I will laterâ€”that's in my DJ Music Inbox on Dropbox.\n\nI don't use WAVs because they don't support metadata. Anyone reading this: please don't send WAVs. Send AIFFs because they're still lossless but you can have metadata on them. If it's a WAV, I use XLD to convert the file. It's a nice program because if you have a photo in the same directory, it will automatically attach it as album art. I try to attach artwork as much as possible, even if it's just a press photo, so that I can connect a color visual.\n\nAfter I drag something onto the XLD icon, it automatically moves it into the DJ Music Library folder, which is also on Dropbox. Anything that's in rekordbox is in here. I do that so that it's easy and straightforward to backup or restore a rekordbox library, because I have two computers that share the same rekordbox library. I look at rekordbox on my desktop studio computer and also on my laptop when I'm on the road, and I want to be able to have the same library on both computers. So if I'm done working on the studio computer, I back up the rekordbox library, export the library fileâ€”which isn't the music itself, but rather a 400-ish MG zip fileâ€”and restore it on my laptop from that data.\n\nOnce the actual AIFF file is in DJ Music Library, then I just highlight it and drag it into the Collection in Rekordbox. At that point I go through and tag each file or song. When I tag them, they automatically fly into the intelligent playlists that are looking for combinations of tags.\n\nSee? Simple as that [laughs]. Back to my previous question: Why did you decide to develop this specific, detailed and elaborate process for organizing your music and workflow?\n\nI'm obsessed with optimization and I think there can always be a better way to do something. Humans are really good at some things, and computers are really good at other things. I would like to use the computer for what it is good at, so that it frees up the human side of me. I'm kind of parroting a programmer mantra, which is that humans aren't good at remembering things but computers are. Humans are good at the vibeman stuff. I want to let the computer do as many rote memory tasks, like looping something when it gets to a certain part, as possible. Beat-matching is not one of the things that it's good at, by the way. There's all kinds of groove and swing and stuff, and unless you're playing techno and trance all the time, you have to hear what's going on in order to mix. I'm actually gonna come out and say that I have definitely used the sync function on CDJsâ€”but it's for a really specific purpose, and that's the only way that it's useful.\n\nWhat's the specific circumstance?\n\nWhen I have two or three CDJs going at the same time and all three of the faders are up 100 percent and I want to drastically change the BPM. Say I have two songs with beats and an acapella, and I want to go from 140 BPM down to 116. I put two of them on sync and move one, and they all follow. People act like the Sync button makes the CDJ magically listen to the song and figure out how to beat-match for them. What it actually does is just change the beat of the slave track to the master track, one for one. So if I move the tempo fader on the master track, then anything that has Sync on it will change by the same number of BPM.\n\nThat's related to what you said at the start about vinyl; that there are certain conventions about what makes someone a \"good\" or \"authentic\" or \"serious\" DJ, and that you don't subscribe to them.\n\nThe Sync button is a good example. Once you realize what it actually is or does, what's revealed is that people who parrot \"rules\" about not using Sync are scared and have imposter syndrome themselves, and they're afraid of other people thinking that they're not \"real\" DJs. Maybe those people don't go from 116 to 140 BPM that often anyway.\n\nBefore we did this interview, you were sort of crusty about the idea that you might demystify your craft by showing how much of what you do are tasks that could be repeated by any human. What you've referred to as the \"vibeman\" approach is harder to quantify. You can't break it down in a didactic way. The nature of the vibeman is kind of mystical and you either have it or you don't.\n\nWell, hold on. Part of my anxiety about giving only really technical answers in this interview is that I don't want to seem like aâ€¦ I feel like a salesman for Pioneer or a rekordbox instructor. That's why I would also like to talk about ripping and editing, because that's a huge part of what I do. Like, if it's some New Beat proto-techno thing from 1988, maybe the EQ of the song is kind of fucked up and it needs some more low end or something. I throw it through one of my remastering chains in Ableton.\n\nGive us a rundown of what's in the mastering chain.\n\nI have a decrackler at the beginning, an EQ to cut out the very lowest sub frequencies, then other more musical EQs to cut or boost others. Then I have various aural exciters and compressors. I have Ableton utilities along the chain to raise or lower the gain, and at the end I have a loudness maximizer. I do this with everything I rip. Some digital files need it too, like if someone sends me a premaster.\n\nTell me about the editing process.\n\nSometimes I tweak the arrangement a little, but I usually do that kind of thing in rekordbox using hot cues nowadays. It's faster and more flexible.\n\nWhy is that an important part of your process?\n\nSometimes I see a potential in a song and how it would live in my DJ sets, and I have to edit it a bit so that it gets there. I'm not really a tooly genre DJ. I play all kinds of things and sometimes I hear something like a weird pop song from the '80s, and I can edit it so that it can feel more right on the dance floor.\n\nWhat percentage of stuff you playâ€”\n\nâ€”is fucked with in any way? Like anything that I've even looped or hit a hot cue on? A lot. Pretty much all of them. Over 90 percent.\n\nCan I bring you back to big-picture stuff now? I think you put it very nicely when you were saying that you're trying to let the computer do what it is does best so that you can do what humans do best. Before, you were overstating how much of what you do is just using rekordbox and computers in a clever way. Do you think that even if someone knew all of Avalon's secrets and methods, they still wouldn't play like you do?\n\nOf course. I sometimes literally rip apart a song so that even if you have the record, what I play is actually not the thing that you have. Maybe originally there's a little bongo intro and then the kick comes in and then the synth and then the bassline, but sometimes that doesn't happen when I play that song. Breaking the linearity of a track is a pretty baseline, low-level deconstruction that I do on the reg. The goal is to be able to play these things like an instrument. That's what makes this fun for me.\n\nUsing CDJs in that way undermines 20th-century conventions that people made to justify the artistic merit of electronic music to those who thought it wasn't \"proper\" or \"real\" music, and that DJing was a cheap, easy hobby rather than an artform.\n\nSome people still say, \"You're just playing other people's music.\" They have a hard time understanding why I get paid for just playing other people's music. Most people just don't pay for music anymore, but they still want to have that participatory communal experience of going somewhere to hear music with others, just like they did hundreds of years ago. I pay the door charge to participate in music; I want to listen to it with my friends and party. I don't care where the music comes from, but I do care if it's more interesting and varied, and that preference of the crowds nowadays seems to favor DJs with 200 GBs of music with them, rather than live performers or producers who play all of their own music for an hour. I don't knowâ€”it's not fair, but what is in the current system?\n\nThat's why I think it's important for DJs to share and shout about the music that they're playing from people, especially when it comes from contemporary producers who could still benefit from a river of pennies flowing to them from selling AIFFs on the internet.\n\nHave you been thinking about that a lot recently?\n\nI guess so. I hope that's something that I can devote more time to in the futureâ€”something that isn't DJing. After I learn to do all the lifehack CDJ tricks.",
    "summary": {
      "en": "Avalon Emerson, a creative DJ, discusses her unique approach to DJing in an interview with Elissa Stolman. She distinguishes herself from other DJs, whom she refers to as \"vibemen,\" by emphasizing her technical skills and organizational methods. Emerson's workflow blends creativity with efficiency, enabling her to quickly find and mix songs across various genres while maintaining an engaging atmosphere for her audience.\n\nShe transitioned from vinyl to digital formats, favoring CDJs and digital files for their versatility and convenience. Despite not playing vinyl anymore, she still buys records for high-quality tracks and enjoys the process of ripping and editing them to fit her style. Emerson meticulously archives her sets to track her musical journey and avoid repeating herself at venues.\n\nHer DJ setup includes multiple CDJs, a high-quality mixer, USB drives, and pedals for effects. Emerson employs various techniques like looping, hot cues, and creative transitions to craft dynamic mixes that tell a story rather than following traditional long blends. She organizes her music in a detailed manner using software like Rekordbox, allowing her to easily categorize and access tracks based on tags and playlists.\n\nEmerson believes that technical skills enhance artistic expression rather than diminish it. She emphasizes the importance of using technology to streamline her workflow, allowing her to focus on the emotional experience of her audience. Ultimately, she conveys that even if someone learns her techniques, they won't replicate her unique style, which combines her personal touch with her technical expertise.",
      "ko": "ì•„ë°œë¡  ì—ë¨¸ìŠ¨ì€ ì—˜ë¦¬ì‚¬ ìŠ¤í†¨ë¨¼ê³¼ì˜ ì¸í„°ë·°ì—ì„œ ê·¸ë…€ë§Œì˜ ë…íŠ¹í•œ DJ ìŠ¤íƒ€ì¼ì— ëŒ€í•´ ì´ì•¼ê¸°í–ˆìŠµë‹ˆë‹¤. ê·¸ë…€ëŠ” ìì‹ ì„ \"ë°”ì´ë¸Œë§¨\"ì´ë¼ê³  ë¶€ë¥´ëŠ” ë‹¤ë¥¸ DJë“¤ê³¼ ì°¨ë³„í™”í•˜ê¸° ìœ„í•´ ê¸°ìˆ ì ì¸ ëŠ¥ë ¥ê³¼ ì¡°ì§ì ì¸ ë°©ë²•ì„ ê°•ì¡°í•©ë‹ˆë‹¤. ì—ë¨¸ìŠ¨ì˜ ì‘ì—… ë°©ì‹ì€ ì°½ì˜ì„±ê³¼ íš¨ìœ¨ì„±ì„ ê²°í•©í•˜ì—¬ ë‹¤ì–‘í•œ ì¥ë¥´ì˜ ê³¡ì„ ë¹ ë¥´ê²Œ ì°¾ì•„ ë¯¹ìŠ¤í•˜ë©´ì„œë„ ê´€ê°ì—ê²Œ ë§¤ë ¥ì ì¸ ë¶„ìœ„ê¸°ë¥¼ ìœ ì§€í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.\n\nê·¸ë…€ëŠ” ë°”ì´ë‹ì—ì„œ ë””ì§€í„¸ í¬ë§·ìœ¼ë¡œ ì „í™˜í–ˆìœ¼ë©°, CDJì™€ ë””ì§€í„¸ íŒŒì¼ì˜ ë‹¤ì¬ë‹¤ëŠ¥í•¨ê³¼ í¸ë¦¬í•¨ì„ ì„ í˜¸í•©ë‹ˆë‹¤. ë¹„ë¡ ë” ì´ìƒ ë°”ì´ë‹ì„ ì—°ì£¼í•˜ì§€ ì•Šì§€ë§Œ, ê³ í’ˆì§ˆ íŠ¸ë™ì„ ìœ„í•´ ì—¬ì „íˆ ë ˆì½”ë“œë¥¼ êµ¬ë§¤í•˜ê³ , ì´ë¥¼ ìì‹ ì˜ ìŠ¤íƒ€ì¼ì— ë§ê²Œ í¸ì§‘í•˜ëŠ” ê³¼ì •ì„ ì¦ê¹ë‹ˆë‹¤. ì—ë¨¸ìŠ¨ì€ ìì‹ ì˜ ì„¸íŠ¸ë¥¼ ì„¸ì‹¬í•˜ê²Œ ì•„ì¹´ì´ë¸Œí•˜ì—¬ ìŒì•… ì—¬ì •ì„ ê¸°ë¡í•˜ê³ , ê³µì—°ì¥ì—ì„œ ê°™ì€ ê³¡ì„ ë°˜ë³µí•˜ì§€ ì•Šë„ë¡ í•©ë‹ˆë‹¤.\n\nê·¸ë…€ì˜ DJ ì¥ë¹„ì—ëŠ” ì—¬ëŸ¬ ê°œì˜ CDJ, ê³ í’ˆì§ˆ ë¯¹ì„œ, USB ë“œë¼ì´ë¸Œ, íš¨ê³¼ë¥¼ ìœ„í•œ í˜ë‹¬ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì—ë¨¸ìŠ¨ì€ ë£¨í•‘, í•« í, ì°½ì˜ì ì¸ ì „í™˜ê³¼ ê°™ì€ ë‹¤ì–‘í•œ ê¸°ìˆ ì„ ì‚¬ìš©í•˜ì—¬ ì „í†µì ì¸ ê¸´ ë¯¹ìŠ¤ ëŒ€ì‹  ì´ì•¼ê¸°ë¥¼ ì „ë‹¬í•˜ëŠ” ì—­ë™ì ì¸ ë¯¹ìŠ¤ë¥¼ ë§Œë“­ë‹ˆë‹¤. ê·¸ë…€ëŠ” ë ˆì½”ë“œë°•ìŠ¤ì™€ ê°™ì€ ì†Œí”„íŠ¸ì›¨ì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ ìŒì•…ì„ ì„¸ë¶€ì ìœ¼ë¡œ ì •ë¦¬í•˜ë©°, íƒœê·¸ì™€ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ì— ë”°ë¼ ê³¡ì„ ì‰½ê²Œ ë¶„ë¥˜í•˜ê³  ì ‘ê·¼í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.\n\nì—ë¨¸ìŠ¨ì€ ê¸°ìˆ ì ì¸ ëŠ¥ë ¥ì´ ì˜ˆìˆ ì  í‘œí˜„ì„ ì €í•´í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ì˜¤íˆë ¤ í–¥ìƒì‹œí‚¨ë‹¤ê³  ë¯¿ìŠµë‹ˆë‹¤. ê·¸ë…€ëŠ” ê¸°ìˆ ì„ í™œìš©í•˜ì—¬ ì‘ì—… íë¦„ì„ ê°„ì†Œí™”í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë‹¤ê³  ê°•ì¡°í•˜ë©°, ì´ë¥¼ í†µí•´ ê´€ê°ì˜ ê°ì •ì  ê²½í—˜ì— ì§‘ì¤‘í•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤. ê²°êµ­, ê·¸ë…€ëŠ” ëˆ„êµ°ê°€ ìì‹ ì˜ ê¸°ìˆ ì„ ë°°ìš´ë‹¤ê³  í•´ë„, ê°œì¸ì ì¸ í„°ì¹˜ì™€ ê¸°ìˆ ì  ì „ë¬¸ì„±ì´ ê²°í•©ëœ ê·¸ë…€ë§Œì˜ ë…íŠ¹í•œ ìŠ¤íƒ€ì¼ì„ ì¬í˜„í•  ìˆ˜ëŠ” ì—†ë‹¤ê³  ì „í•©ë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "bd620a437d6eb2ae",
    "title": {
      "en": "Superhyperbola",
      "ko": "ìŠˆí¼í•˜ì´í¼ë³¼ë¼",
      "ja": null
    },
    "type": "story",
    "url": "https://www.johndcook.com/blog/2025/03/27/superhyperbola/",
    "score": 28,
    "by": "jihadjihad",
    "time": 1743186321,
    "content": "Superhyperbola\n\n\t\t\tPosted on 27 March 2025 by John\n\n\t\tAn ellipse has equation\n\nand a hyperbola has equation\n\nSimilarly the superellipse has equation\n\nand the superhyperbola\n\nWhen p = 2, the absolute value signs are unnecessary and the superellipse and superhyperbola reduce to the ellipse and hyperbola respectively.\nIncreasingp makes the superellipse more like a rectangle. But unlike a rectangle with rounded corners, the change in curvature is continuous.\n\nIncreasingp makes the superhyperbola more blunt at the vertices.\n\nMarketing\nThe superellipse is a fairly well known variation on an ellipse. Even if youâ€™re not familiar the term, youâ€™ve probably seen the shape. I give a couple examples here. The superhyperbola is the obvious analog of a superellipse, but the term is far less common. Iâ€™d never hear the term until yesterday.\nItâ€™s not clear why the superellipse would be common and the superhyperbola obscure, but hereâ€™s some speculation. First of all, the superellipse had an advocate, Piet Hein. If the superhyperbola has an advocate, heâ€™s not a very effective advocate.\nThe name is also off-putting: juxtaposing super andhyper sounds silly. The etymology makes sense, even if it sounds funny. Piet Hein used the prefixsuperâ€“ to refer to increasing the exponent from the usual value of 2. Its unfortunate thathyperbola begins with a root that is similar tosuper.\nRelated posts\n\nApple design, squircles, and curvature\nSquircle corner radius\nSupereggs\n\n\t\t\t\tCategories : MathBookmark the permalink",
    "summary": {
      "en": "**Summary of Superhyperbola Post**\n\nThe post discusses mathematical shapes known as superellipses and superhyperbolas. \n\n- **Ellipses and Hyperbolas**: An ellipse and a hyperbola have specific mathematical equations. Superellipses and superhyperbolas are variations that change based on a parameter, \\( p \\).\n- **Shape Changes**: As \\( p \\) increases, the superellipse starts to resemble a rectangle, while the superhyperbola becomes blunter at its points.\n- **Recognition**: The superellipse is well-known, partly due to the advocacy of Piet Hein. In contrast, the superhyperbola is less recognized, and the term may sound off-putting to some.\n- **Terminology**: The prefix \"super-\" indicates an increase in the exponent from 2, which is the standard for ellipses and hyperbolas.\n\nOverall, the post highlights the differences and lesser-known status of the superhyperbola compared to the superellipse.",
      "ko": "ì´ ê¸€ì—ì„œëŠ” ìˆ˜í•™ì  ë„í˜•ì¸ ìŠˆí¼íƒ€ì›ê³¼ ìŠˆí¼ìŒê³¡ì„ ì— ëŒ€í•´ ì„¤ëª…í•©ë‹ˆë‹¤. íƒ€ì›ê³¼ ìŒê³¡ì„ ì€ ê°ê° íŠ¹ì •í•œ ìˆ˜í•™ì  ë°©ì •ì‹ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ìŠˆí¼íƒ€ì›ê³¼ ìŠˆí¼ìŒê³¡ì„ ì€ ë§¤ê°œë³€ìˆ˜ \\( p \\)ì— ë”°ë¼ ë³€í˜•ëœ í˜•íƒœì…ë‹ˆë‹¤. \n\n\\( p \\)ì˜ ê°’ì´ ì¦ê°€í•¨ì— ë”°ë¼ ìŠˆí¼íƒ€ì›ì€ ì§ì‚¬ê°í˜•ì— ê°€ê¹Œì›Œì§€ê³ , ìŠˆí¼ìŒê³¡ì„ ì€ ê·¸ ê¼­ì§“ì ì´ ë” ë‘¥ê¸€ì–´ì§€ëŠ” íŠ¹ì§•ì´ ìˆìŠµë‹ˆë‹¤. ìŠˆí¼íƒ€ì›ì€ í”¼ì—íŠ¸ í•˜ì¸(Piet Hein)ì˜ ì§€ì§€ ë•ë¶„ì— ì˜ ì•Œë ¤ì ¸ ìˆì§€ë§Œ, ìŠˆí¼ìŒê³¡ì„ ì€ ìƒëŒ€ì ìœ¼ë¡œ ëœ ì•Œë ¤ì ¸ ìˆìœ¼ë©°, ì´ ìš©ì–´ê°€ ì¼ë¶€ ì‚¬ëŒë“¤ì—ê²ŒëŠ” ìƒì†Œí•˜ê²Œ ë“¤ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n\n\"ìŠˆí¼-\"ë¼ëŠ” ì ‘ë‘ì‚¬ëŠ” íƒ€ì›ê³¼ ìŒê³¡ì„ ì˜ í‘œì¤€ ì§€ìˆ˜ì¸ 2ì—ì„œ ì¦ê°€í–ˆìŒì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ì „ë°˜ì ìœ¼ë¡œ ì´ ê¸€ì€ ìŠˆí¼íƒ€ì›ì´ ë” ì˜ ì•Œë ¤ì ¸ ìˆëŠ” ë°˜ë©´, ìŠˆí¼ìŒê³¡ì„ ì€ ìƒëŒ€ì ìœ¼ë¡œ ëœ ì•Œë ¤ì ¸ ìˆë‹¤ëŠ” ì ì„ ê°•ì¡°í•˜ê³  ìˆìŠµë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "7edca9dd2a61648d",
    "title": {
      "en": "How to Write Blog Posts that Developers Read",
      "ko": "ê°œë°œìê°€ ì½ëŠ” ë¸”ë¡œê·¸ ì“°ê¸°",
      "ja": null
    },
    "type": "story",
    "url": "https://refactoringenglish.com/chapters/write-blog-posts-developers-read/",
    "score": 245,
    "by": "rbanffy",
    "time": 1743159679,
    "content": "How to Write Blog Posts that Developers Readby Michael Lynch, published\nMarch 27, 2025if(window.location.pathname===\"/chapters/nine-years-of-blogging/\"){const e=\"What I Learned from Nine Years of Blogging\";document.title=e,document.querySelector(\"h1\").textContent=e}I recently spoke to a developer who tried blogging but gave up because nobody was reading his posts. I checked out his blog, and it was immediately obvious why he didnâ€™t have any readers.The developer had interesting insights, but he made so many mistakes in presenting his ideas that he was driving everyone away. The tragedy was that these errors were easy to fix. Once you learn to recognize them, they feel obvious, but some bloggers make these mistakes for years.I know because Iâ€™m one of them.Iâ€™ve been blogging about software development for nine years. My best posts have reached 300k+ readers, but many of them flopped, especially in my first few years.Over time, Iâ€™ve learned techniques that help some blog posts succeed and the pitfalls that cause others to languish in obscurity.Why listen to me?Get to the pointThink one degree biggerPlan the route to your readersShow more picturesAccommodate skimmersWhy listen to me?ğŸ”—Iâ€™m going to say a bunch of gloaty things to establish credibility, but it feels gross, so letâ€™s just get it out of the way:Iâ€™ve written a software blog for nine years, and it attracts 300k-500k unique readers per year.My posts have reached the front page of Hacker News over 30 times, many of them reaching the #1 spot.According to a ranking system I made up, I have the 48th most popular personal blog on Hacker News.I launched a successful indie business by writing a popular blog post about my product.My articles frequently appear on reddit and Lobsters.My software blog receives 300k-500k unique readers per year.I donâ€™t claim to be the worldâ€™s best software blogger, but Iâ€™ve had enough success and experience to share some useful lessons.Get to the pointğŸ”—The biggest mistake software bloggers make is meandering.Often, the author has some valuable insight to share, but they squander their first seven paragraphs on the history of functional programming and a trip they took to Bell Labs in 1973. By the time they get to the part thatâ€™s actually interesting, everyone has long since closed the browser tab.Internet attention spans are short. If you dawdle before making your point, the reader will seek out one of the literally billions of other articles they could be reading instead.So, how do you convince the reader to stay and continue reading your blog post?When the reader arrives, theyâ€™re trying to answer two questions as quickly as possible:Did the author write this article for someone like me?How will I benefit from reading it?Give yourself the title plus your first three sentences to answer both questions. If you find yourself in paragraph two and you havenâ€™t answered either question, youâ€™re in trouble.To show the reader youâ€™re writing for them, mention topics they care about, and use terminology they recognize. If you throw out jargon or unfamiliar concepts, the reader assumes the article isnâ€™t meant for them and clicks away.Your introduction should also make it clear to the reader how the article will benefit them. There are many possible benefits you can offer:A technique the reader can apply in their work or personal life.A clear explanation of a concept that impacts the readerâ€™s work or personal life.An insight that gives the reader a better understanding of a particular technology or industry.An interesting story that resonates with the reader.Example: â€œif got, want: A Simple Way to Write Better Go Testsâ€ğŸ”—I recently wrote an article about improving tests when using the Go programming language.Hereâ€™s the title and first paragraph:if got, want: A Simple Way to Write Better Go TestsThereâ€™s an excellent Go testing pattern that too few people know. I can teach it to you in 30 seconds.This article immediately answers the two questions:Did the author write the article for someone like me?The article is for Go developers.Whatâ€™s the benefit of reading it?Youâ€™ll learn a new testing technique in 30 seconds.Think one degree biggerğŸ”—When you write an article, you hopefully have a type of reader in mind. For example, if you wrote an article called â€œDebugging Memory Leaks in Java,â€ you probably assumed that the reader is an intermediate to advanced Java developer.Most software bloggers never think to ask, â€œIs there a wider audience for this topic?â€For example, â€œintermediate to advanced Java developersâ€ are a subset of â€œJava developers,â€ who are a subset of â€œprogrammers,â€ who are a subset of â€œpeople who read blog posts.â€If you wrote an article for intermediate and advanced Java developers, how much would have to change for the article to appeal to Java developers of any experience level?Often, the change is just an extra sentence or two early in the article to introduce a concept or replace jargon with more accessible terms.Jeff: Sony has a futuristic sci-fi movie theyâ€™re looking to make.Nick: Cigarettes in space?Jeff: Itâ€™s the final frontier, Nick.Nick: But wouldnâ€™t they blow up in an all-oxygen environment?Jeff: Probably. But itâ€™s an easy fix. One line of dialogue. â€œThank God we invented theâ€¦ you know, whatever device.â€Thank You for Smoking (2005)The set of all Java developers is about 10x larger than the set of intermediate and advanced Java developers. That means small tweaks can expand the reach of your article by an order of magnitude.Obviously, you canâ€™t broaden every article, and you canâ€™t keep broadening your audience forever. No matter how well you explain background concepts, your tax accountant will never read an article about memory leaks in Java. The point isnâ€™t to write articles that appeal to every possible reader but to notice opportunities to reach a larger audience.Example: â€œHow I Stole Your Siacoinâ€ğŸ”—One of my earliest successes in blogging was an article called â€œHow I Stole Your Siacoin.â€ It was about a time I stole a reddit userâ€™s cryptocurrency (for noble reasons, I promise).Initially, I thought the story would resonate with the few hundred people who followed a niche cryptocurrency called Siacoin. As I was editing the article, I realized that you didnâ€™t have to know anything about Siacoin to understand my story. I revised it slightly so it would make sense to cryptocurrency enthusiasts who had never heard of Siacoin.Then, I realized I could even explain this story to people who knew nothing about cryptocurrency. I adjusted the terminology to use regular-person terms like â€œwalletâ€ and â€œpassphraseâ€ and avoided crypto-specific terms like â€œblockchainâ€ or â€œMerkle tree.â€The article was my first ever hit. It became the most popular story of all time not only on the /r/siacoin subreddit but also on the larger /r/cryptocurrency subreddit. It reached the front page of Hacker News, even though readers there are generally hostile to cryptocurrency-focused stories.â€œHow I Stole Your Siacoinâ€ only needed a few tweaks to be enjoyable for people who didnâ€™t know anything about cryptocurrency.Plan the route to your readersğŸ”—Suppose you wrote the greatest beginnerâ€™s tutorial imaginable for the Python programming language. Both your five-year-old nephew and 80-year-old dentist blazed through it with ease and delight. Everyone who reads your tutorial goes on to become a Python core contributor.Bad news: nobody will ever read your Python tutorial.â€œLies!â€ you shout. â€œThousands of developers learn Python every year. Why wouldnâ€™t my objectively awesome tutorial become popular?â€Well, think it through. What happens after you hit publish? How does anyone find your article?Youâ€™re probably thinking: Google.Yes, your friend Google will index your tutorial and use its secret Google magic to identify your articleâ€™s superior quality. Before you know it, your tutorial will be the top result for python tutorial.Except that canâ€™t happen because there are so many Python tutorials out there already on sites that Google prefers over yours. Youâ€™ll never even make it to the first page of results.Itâ€™s nearly impossible for a new blog post to rank well in Google for the search term python tutorial.Okay, so youâ€™ll submit your Python tutorial to reddit. The /r/python subreddit has over 1.3 million subscribers. If even 5% of them read your article, thatâ€™s a huge audience:The /r/python subreddit has over 1.3 million subscribers.Whoops! /r/python only accepts text posts, not external links, so you canâ€™t post your tutorial there.The /r/python subreddit disables the option to submit external links.Fine, then youâ€™ll submit it to Hacker News. They accept anything and let their members decide whatâ€™s interesting. Surely, theyâ€™ll recognize the quality of your work!Nope, it will flop there, too. Hacker News doesnâ€™t like tutorials, especially for mainstream technologies like Python.You can try sharing your tutorial by tweeting it, skeeting it, or tooting it, but unless you already have a massive following on social media, that wonâ€™t reach a critical mass either.So, whatâ€™s the answer? How do you get people to read your amazing Python tutorial?The answer is that you donâ€™t write a beginnerâ€™s Python tutorial.You need a realistic path to your readersğŸ”—If you want people to read your blog, choose topics that have a clear path to your readers. Before you begin writing, think through how readers will find your post.Questions to ask when considering an article topicIs it realistic for readers to find you via Google search?Are there already 500 articles about the same topic from more established websites?What keywords would your target reader search? Try searching those keywords, and see whether there are already relevant results from well-known domains.If youâ€™re going to submit it to a link aggregator like Hacker News or Lobsters, how often do posts like yours succeed there?If youâ€™re going to share it on a subreddit or niche forum, does it have any chance there?Does the forum accept links to blog posts?The bigger the community, the stricter the rules tend to be about external links and self-promotion.Do blog posts like yours ever succeed there?Is the community still active?The best plan is to give your post multiple chances to succeed. If youâ€™re betting everything on Google bubbling your post to the top, it could take months or years for you to find out if you succeeded. If youâ€™re relying on Hacker News or reddit to tell you whether your article is worth reading, theyâ€™re going to break your heart a lot.Example: â€œUsing Zig to Unit Test a C Applicationâ€ğŸ”—In 2023, I wrote an article called â€œUsing Zig to Unit Test a C Application.â€ It was about using a new low-level language called Zig to write tests for legacy C code.Before I wrote the article, I knew that there were several places where I could share it. By luck, they all worked out:Hacker News is extremely friendly to Zig content, so my article reached the #7 spot on the front page.Lobsters is extremely friendly to Zig content, so my article was one of the top links of the day.Google bubbled my article to the top result for the keywords zig unit testing c.Itâ€™s actually even a top result for just zig unit testing because there arenâ€™t many articles about the topic.The /r/Zig subreddit accepts links to blog posts, even if theyâ€™re self-promotion, so my post reached the top spot in that subreddit.Ziggit is a niche forum thatâ€™s welcoming to Zig-related articles, so my post received 1,000 views from Ziggit.Show more picturesğŸ”—The biggest bang-for-your-buck change you can make to a blog post is adding pictures.If your article features long stretches of text, think about whether thereâ€™s any photo, screenshot, graph, or diagram that could make the post more visually interesting.If youâ€™re talking about a program with a graphical interface, show screenshots.If youâ€™re talking about an improvement in metrics like app performance or active users, show graphs.If youâ€™re writing about your server getting overloaded, show a screenshot of what that looked like in your dashboard or email alerts.If youâ€™re explaining a difficult concept, draw a diagram.I hire illustrators for most of my posts (including this one). I typically pay $50-100 per illustration. For simple diagrams like the nested circle sketches above, I use Excalidraw, which is free and open-source.You can also use free stock photos and AI-generated images, as theyâ€™re better than nothing, but theyâ€™re worse than anything else, including terrible MS Paint drawings.Even a terrible MS Paint drawing is more interesting than an AI-generated image.Accommodate skimmersğŸ”—Many readers skim an article first to decide if itâ€™s worth reading. Dazzle those readers during the skim.If the reader only saw your headings and images, would it pique their interest?The worst thing for a skimmer to see is a wall of text: long paragraphs with no images or headings to break them up. Just text, text, text all the way down.Tool: Read like a skimmerğŸ”—Hereâ€™s a JavaScript bookmarklet that you can use to see what your article looks like with just headings and images.Skimmify pageDrag the link to your browser bookmark bar, and then click it to see what your article looks like to skimmers.Example: Boring structure vs. interesting structureğŸ”—I wrote my article, â€œEnd-to-End Testing Web Apps: The Painless Way,â€ in 2019, before I thought about structure.If you skim the article, does it make you want to read the full version?\nYour browser does not support the video tag.Probably not. The headings donâ€™t reveal much about the content, and the visuals are confusing.Consider my more recent article, â€œI Regret My $46k Website Redesign.â€\nYour browser does not support the video tag.If you skim that article, you still see the bones of a good story, and there are interesting visual elements to draw the reader in.One of those articles barely attracted any readers, and the other became one of the most popular articles I ever published, attracting 150k unique readers in its first week. Can you guess which is which?.campaign-progress{background-color:#fdfffa;padding:1rem;border-radius:6px;text-align:center;border:1px solid #dae8c6;width:90%;max-width:500px;margin-left:auto;margin-right:auto}.goal-amount{font-weight:500;margin-bottom:1rem}.countdown{color:#555;font-size:1.1em}.progress{height:40px}.progress-bar{font-size:1.1em;line-height:40px}Pre-order the bookThis is an excerpt from my upcoming book,\nRefactoring English: Effective Writing for Software Developers.$4,776 raised of $5,000\ngoal96%Time left to meet goal: 3 days, 0 hours, 2 minutesWant to fund this so I can write the full book? Pre-order the book on\nKickstarter to support the book.Pre-Order Nowconst currentAmount=4776,goalAmount=5e3;function updateFundingInfo(){document.getElementById(\"current-amount\").textContent=currentAmount.toLocaleString(),document.getElementById(\"goal-amount\").textContent=goalAmount.toLocaleString();const t=Math.round(currentAmount/goalAmount*100),e=document.getElementById(\"progress-bar\");e.style.width=t+\"%\",e.textContent=t+\"%\",e.setAttribute(\"aria-valuenow\",currentAmount)}function updateCountdown(){const t=new Date(\"2025-03-31T23:59:00-04:00\"),n=new Date,e=t-n;if(e<=0){document.getElementById(\"countdown\").textContent=\"Campaign ended\";return}const s=Math.floor(e/(1e3*60*60*24)),o=Math.floor(e%(1e3*60*60*24)/(1e3*60*60)),i=Math.floor(e%(1e3*60*60)/(1e3*60));document.getElementById(\"countdown\").textContent=`${s} days, ${o} hours, ${i} minutes`}updateFundingInfo(),updateCountdown()In the nine years I've been blogging about software development, some of my posts have hit 300k+ readers, while others flopped, especially early on. I'm sharing all the lessons I learned the hard way about how to write popular blog posts for developers. https://t.co/a5cLF4MXfFâ€” Michael Lynch (@deliberatecoder) March 27, 2025â€œNot Quite How Developers Readâ€ illustration by Piotr Letachowicz. Steve Jobs illustration by Loraine Yow.",
    "summary": {
      "en": "Michael Lynch shares tips for writing blog posts that attract developers based on his nine years of blogging experience. He emphasizes that many bloggers make common mistakes that turn readers away, but these errors are often easy to fix. Here are the key points:\n\n1. **Get to the Point**: Capture the reader's interest quickly. Answer the questions \"Is this for me?\" and \"What's the benefit?\" within the first few sentences.\n\n2. **Think Bigger**: Consider whether your topic can appeal to a wider audience. Small adjustments can make your article relevant to more readers.\n\n3. **Plan for Visibility**: Before writing, think about how readers will find your post. Research existing content, keywords, and appropriate platforms for sharing.\n\n4. **Use Visuals**: Incorporate images, diagrams, or screenshots to make your post more engaging and visually appealing.\n\n5. **Accommodate Skimmers**: Many readers skim articles first. Make sure your headings and images draw attention, and avoid long blocks of text.\n\nBy applying these techniques, bloggers can improve the chances of their posts being read and appreciated by developers.",
      "ko": "ë§ˆì´í´ ë¦°ì¹˜ëŠ” ê°œë°œìë“¤ì„ ëŒì–´ë“¤ì´ëŠ” ë¸”ë¡œê·¸ ê¸€ ì‘ì„± íŒì„ ì•„í™‰ ë…„ì˜ ë¸”ë¡œê¹… ê²½í—˜ì„ ë°”íƒ•ìœ¼ë¡œ ê³µìœ í•©ë‹ˆë‹¤. ê·¸ëŠ” ë§ì€ ë¸”ë¡œê±°ë“¤ì´ ë…ìë¥¼ ë©€ì–´ì§€ê²Œ í•˜ëŠ” ì¼ë°˜ì ì¸ ì‹¤ìˆ˜ë¥¼ ì €ì§€ë¥´ì§€ë§Œ, ì´ëŸ¬í•œ ì˜¤ë¥˜ëŠ” ëŒ€ê°œ ì‰½ê²Œ ìˆ˜ì •í•  ìˆ˜ ìˆë‹¤ê³  ê°•ì¡°í•©ë‹ˆë‹¤. ì£¼ìš” í¬ì¸íŠ¸ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n\nì²«ì§¸, ë…ìì˜ ê´€ì‹¬ì„ ë¹ ë¥´ê²Œ ëŒì–´ì•¼ í•©ë‹ˆë‹¤. ê¸€ì˜ ì²« ëª‡ ë¬¸ì¥ ì•ˆì— \"ì´ ê¸€ì´ ë‚˜ì—ê²Œ í•„ìš”í•œê°€?\"ì™€ \"ë¬´ìŠ¨ ì´ì ì´ ìˆëŠ”ê°€?\"ë¼ëŠ” ì§ˆë¬¸ì— ë‹µí•´ì•¼ í•©ë‹ˆë‹¤.\n\në‘˜ì§¸, ë” ë„“ì€ ì‹œê°ì„ ê°€ì ¸ì•¼ í•©ë‹ˆë‹¤. ìì‹ ì˜ ì£¼ì œê°€ ë” ë§ì€ ë…ìì—ê²Œ ì–´í•„í•  ìˆ˜ ìˆëŠ”ì§€ ê³ ë ¤í•´ ë³´ì„¸ìš”. ì‘ì€ ì¡°ì •ë§Œìœ¼ë¡œë„ ê¸€ì´ ë” ë§ì€ ì‚¬ëŒë“¤ì—ê²Œ ê´€ë ¨ì„±ì„ ê°€ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nì…‹ì§¸, ê°€ì‹œì„±ì„ ê³„íší•´ì•¼ í•©ë‹ˆë‹¤. ê¸€ì„ ì“°ê¸° ì „ì— ë…ìë“¤ì´ ì–´ë–»ê²Œ ìì‹ ì˜ í¬ìŠ¤íŠ¸ë¥¼ ì°¾ì„ì§€ë¥¼ ìƒê°í•´ ë³´ì„¸ìš”. ê¸°ì¡´ ì½˜í…ì¸ , í‚¤ì›Œë“œ, ê³µìœ í•  ì ì ˆí•œ í”Œë«í¼ì— ëŒ€í•´ ì¡°ì‚¬í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.\n\në„·ì§¸, ì‹œê° ìë£Œë¥¼ í™œìš©í•˜ì„¸ìš”. ì´ë¯¸ì§€, ë„í‘œ, ìŠ¤í¬ë¦°ìƒ· ë“±ì„ í¬í•¨ì‹œì¼œ ê¸€ì„ ë” ë§¤ë ¥ì ì´ê³  ì‹œê°ì ìœ¼ë¡œ í¥ë¯¸ë¡­ê²Œ ë§Œë“œì„¸ìš”.\n\në§ˆì§€ë§‰ìœ¼ë¡œ, ìŠ¤í‚¤ë¨¸ë¥¼ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤. ë§ì€ ë…ìë“¤ì´ ë¨¼ì € ê¸°ì‚¬ë¥¼ í›‘ì–´ë´…ë‹ˆë‹¤. ì œëª©ê³¼ ì´ë¯¸ì§€ë¥¼ ëˆˆì— ë„ê²Œ í•˜ê³ , ê¸´ ë¬¸ë‹¨ì€ í”¼í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.\n\nì´ëŸ¬í•œ ê¸°ë²•ì„ ì ìš©í•˜ë©´ ë¸”ë¡œê±°ë“¤ì€ ìì‹ ì˜ ê¸€ì´ ê°œë°œìë“¤ì—ê²Œ ì½íˆê³  ì¸ì •ë°›ì„ ê°€ëŠ¥ì„±ì„ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "bd81f570e9c669f3",
    "title": {
      "en": "Swiftly 1.0",
      "ko": "ìŠ¤ìœ„í”„íŠ¸ 1.0",
      "ja": null
    },
    "type": "story",
    "url": "https://swift.org/blog/introducing-swiftly_10/",
    "score": 34,
    "by": "todsacerdoti",
    "time": 1743193761,
    "content": "Introducing swiftly 1.0\n\n    March 28, 2025\n\n              Chris McGee\n\n  Today weâ€™re delighted to introduce the first stable release of swiftly, a Swift version manager that takes the pain out of installing, managing and updating your Swift toolchain.\n\nThe latest version of Swift is bundled with Xcode for writing apps for Apple platforms. But perhaps you want to install Swift on a different platform like Linux, or use a different version of the toolchain for building services or command line tools. Downloading, extracting and installing a trusted build of Swift along with the relevant dependencies for your operating system can require quite a few manual and error-prone steps.\n\nswiftly has been around for some years as a community-supported tool for Swift developers using Linux. With this release, weâ€™re officially supporting it as part of the core Swift toolchain, including hosting it as part of the Swift GitHub organization. Weâ€™ve also added macOS support to make it easier to install Swift separately from Xcode.\n\nIntroducing swiftly\n\nswiftly is the best tool to install the standalone toolchain, providing commands to install Swift on a new system, update to the latest stable version, and experiment or test with nightly snapshots or older versions. It also makes it easy to switch effortlessly between multiple installed toolchains. You can even add a file to your project repository so swiftly will use the same toolchain version for all members of your development team.\n\nNaturally, swiftly itself is written in Swift, and is able to update itself to the latest version.\n\nQuick tour\n\nLetâ€™s take a look at some of the features of swiftly!\n\nTo get started, visit swift.org/install and install it.\n\nswiftly will provide directions after installation if there are any system packages, or shell commands needed for smooth operation of the new toolchain.\n\nThe latest Swift toolchain is installed as the default, so you can immediately use it to start a new project. For example:\n\n$ swift package init\n\nThe swiftly use command selects the default toolchain for Swift commands (e.g. swift test, swift build):\n\n$ swiftly use 6.0.3\n$ swift --version\n--\nApple Swift version 6.0.3 (swiftlang-6.0.3.1.2 clang-1600.0.28.6)\nTarget: arm64-apple-macosx15.0\n\nAt a later point, if thereâ€™s a new release of Swift you can install it alongside the existing toolchain with the latest command:\n\n$ swiftly install latest\n\nPre-release of versions of Swift are available, including nightly â€œsnapshotâ€ toolchains. They can be easily listed using swiftly:\n\n$ swiftly list-available main-snapshot\n--\nAvailable main development snapshot toolchains\n----------------------------------------------\nmain-snapshot-2025-03-25\n...\n\nOnce youâ€™ve identified a snapshot toolchain, it can be installed using its name:\n\n$ swiftly install main-snapshot-2025-03-25\n--\nInstalling main-snapshot-2025-03-25\n\nAnother way to temporarily use a specific version of Swift is to use the special â€˜+â€™ selector. With this syntax, you donâ€™t need to first switch to a different toolchain:\n\n$ swiftly run lldb +main-snapshot-2025-03-25\n--\n(lldb) _\n\nIf youâ€™re building a SwiftPM project in a team setting and want to enforce a common version of the Swift toolchain on all contributors, simply create a .swift-version file in the root of your project folder with the desired version (e.g. â€œ6.0.3â€).\n\nAs swiftly is updated with new features and bug fixes, you can run swiftly self-update to check and install new releases.\n\nHow swiftly works\n\nBy writing swiftly in Swift, weâ€™re able to take advantage of the languageâ€™s features, support, and ecosystem of related projects. Swift comes with standard library features for working with the filesystem in its Foundation module. For network operations Async HTTP Client is there to work the HTTP requests. And to retrieve the latest Swift release, swiftly uses the Swift OpenAPI plugin to generate the code to interact with the swift.org  website. Lastly, it takes advantage of Swiftâ€™s interoperability with C to use the existing libarchive library to work with archives. swiftly uses libarchive to extract the toolchains downloaded from the Swift website and the integration is simple.\n\nIt can be challenging to build shell programs that work well across multiple platforms with minimal system dependencies; this motivated us to switch swiftly away from using a shell program to install it and become a self-installing binary application. swiftly has access to excellent argument parsing capabilities, beautiful --help screens, and the full standard library.\n\nThe only remaining problem was being able to deliver the operating system and processor architecture specific binary to the users system with simplicity. The swift.org website helps with operating system detection, but it cannot reliably detect the Linux distribution. Luckily, there is the Swift Static Linux SDK that makes binaries that work with a wide range of distributions. The processor architecture can be determined on most unixes using uname -m . The result of all of this is the simplicity of a copy and paste from the website to your terminal and get started with Swift.\n\nInstalling Swift, swiftly\n\nMoving forward, swiftly will become the default way to install Swift outside of Xcode. The initial version supports macOS and a variety of Linux distributions, including Ubuntu, Debian, Fedora, Red Hat Enterprise Linux and Amazon Linux.\n\nThe swiftly documentation provides further information about using swiftly in a CI/CD environment, as well as setting proxy servers and custom install locations for enterprise environments. swiftly is an open source project, and so you can raise new issues or contribute pull requests at its GitHub repository. You can also ask questions or discuss swiftly on the Swift Forums.\n\nSpecial thanks to Patrick Freed for creating swiftly, contributing it to the Swift organization, and his continued contributions to this valuable tool. The community is what makes Swift amazing!\n\n      Written by\n\n              Chris McGee\n\n            Chris McGee is on the team at Apple working on Swift Package Manager, and Swiftly.\n\n      How Swift's server support powers Things Cloud",
    "summary": {
      "en": "**Summary of Swiftly 1.0 Release**\n\nOn March 28, 2025, Chris McGee announced the first stable release of Swiftly, a Swift version manager designed to simplify the installation, management, and updating of Swift toolchains. \n\n**Key Features:**\n- **Cross-Platform Support:** Swiftly allows users to install Swift on various platforms, including Linux and macOS, separately from Xcode.\n- **Easy Toolchain Management:** Users can install a new Swift version, update to the latest stable version, and switch between different toolchains easily. It also supports nightly snapshots and older versions.\n- **Team Collaboration:** Developers can create a `.swift-version` file in their project to ensure all team members use the same toolchain version.\n- **Self-Updating:** Swiftly can update itself to the latest version.\n\n**Installation and Usage:**\n- To get started, users can visit swift.org/install. Swiftly will guide them through any necessary package installations.\n- The toolchain can be set as the default for immediate project use, and users can easily install new or specific versions with simple commands.\n\n**Technical Aspects:**\n- Swiftly is built in Swift and utilizes various Swift features for filesystem management and HTTP requests. It simplifies installation by being a self-installing binary, making it easier to use across different platforms.\n\n**Future Directions:**\n- Swiftly is intended to be the primary method for installing Swift outside of Xcode, supporting various Linux distributions and macOS. More documentation is available for advanced use cases in CI/CD environments.\n\n**Community Contribution:**\n- The project is open-source, encouraging contributions and discussions within the Swift community. Special acknowledgment goes to Patrick Freed for his contributions to Swiftly. \n\nFor more information, users can explore the Swiftly documentation and engage with the community on Swift Forums.",
      "ko": "2025ë…„ 3ì›” 28ì¼, í¬ë¦¬ìŠ¤ ë§¥ê¸°(Chris McGee)ëŠ” Swift íˆ´ì²´ì¸ ì„¤ì¹˜, ê´€ë¦¬ ë° ì—…ë°ì´íŠ¸ë¥¼ ê°„ì†Œí™”í•˜ê¸° ìœ„í•´ ì„¤ê³„ëœ Swift ë²„ì „ ê´€ë¦¬ ë„êµ¬ì¸ Swiftlyì˜ ì²« ë²ˆì§¸ ì•ˆì • ë²„ì „ì„ ë°œí‘œí–ˆìŠµë‹ˆë‹¤.\n\nSwiftlyì˜ ì£¼ìš” ê¸°ëŠ¥ìœ¼ë¡œëŠ” ë‹¤ì–‘í•œ í”Œë«í¼ì—ì„œ Swiftë¥¼ ì„¤ì¹˜í•  ìˆ˜ ìˆëŠ” í¬ë¡œìŠ¤ í”Œë«í¼ ì§€ì›ì´ ìˆìŠµë‹ˆë‹¤. ì‚¬ìš©ìëŠ” Xcodeì™€ëŠ” ë³„ê°œë¡œ ë¦¬ëˆ…ìŠ¤ì™€ macOSì—ì„œ Swiftë¥¼ ì„¤ì¹˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, ì‚¬ìš©ìëŠ” ìƒˆë¡œìš´ Swift ë²„ì „ì„ ì„¤ì¹˜í•˜ê³  ìµœì‹  ì•ˆì • ë²„ì „ìœ¼ë¡œ ì—…ë°ì´íŠ¸í•˜ë©°, ë‹¤ì–‘í•œ íˆ´ì²´ì¸ ê°„ì— ì‰½ê²Œ ì „í™˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì•¼ê°„ ìŠ¤ëƒ…ìƒ·ê³¼ ì´ì „ ë²„ì „ë„ ì§€ì›í•©ë‹ˆë‹¤. ê°œë°œìë“¤ì€ í”„ë¡œì íŠ¸ì— `.swift-version` íŒŒì¼ì„ ìƒì„±í•˜ì—¬ íŒ€ì› ëª¨ë‘ê°€ ë™ì¼í•œ íˆ´ì²´ì¸ ë²„ì „ì„ ì‚¬ìš©í•˜ë„ë¡ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. SwiftlyëŠ” ìŠ¤ìŠ¤ë¡œ ìµœì‹  ë²„ì „ìœ¼ë¡œ ì—…ë°ì´íŠ¸í•  ìˆ˜ ìˆëŠ” ê¸°ëŠ¥ë„ ê°–ì¶”ê³  ìˆìŠµë‹ˆë‹¤.\n\nì‚¬ìš©ìëŠ” swift.org/installì„ ë°©ë¬¸í•˜ì—¬ Swiftlyë¥¼ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. SwiftlyëŠ” í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜ë¥¼ ì•ˆë‚´í•©ë‹ˆë‹¤. íˆ´ì²´ì¸ì€ ì¦‰ì‹œ í”„ë¡œì íŠ¸ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •í•  ìˆ˜ ìˆìœ¼ë©°, ì‚¬ìš©ìëŠ” ê°„ë‹¨í•œ ëª…ë ¹ì–´ë¡œ ìƒˆë¡œìš´ ë²„ì „ì´ë‚˜ íŠ¹ì • ë²„ì „ì„ ì‰½ê²Œ ì„¤ì¹˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nSwiftlyëŠ” Swiftë¡œ êµ¬ì¶•ë˜ì—ˆìœ¼ë©°, íŒŒì¼ ì‹œìŠ¤í…œ ê´€ë¦¬ì™€ HTTP ìš”ì²­ì„ ìœ„í•œ ë‹¤ì–‘í•œ Swift ê¸°ëŠ¥ì„ í™œìš©í•©ë‹ˆë‹¤. ìê°€ ì„¤ì¹˜í˜• ë°”ì´ë„ˆë¦¬ë¡œ ì„¤ê³„ë˜ì–´ ìˆì–´ ì—¬ëŸ¬ í”Œë«í¼ì—ì„œ ì‚¬ìš©í•˜ê¸° ì‰½ìŠµë‹ˆë‹¤.\n\nSwiftlyëŠ” Xcode ì™¸ë¶€ì—ì„œ Swiftë¥¼ ì„¤ì¹˜í•˜ëŠ” ì£¼ìš” ë°©ë²•ìœ¼ë¡œ ì‚¬ìš©ë  ì˜ˆì •ì´ë©°, ë‹¤ì–‘í•œ ë¦¬ëˆ…ìŠ¤ ë°°í¬íŒê³¼ macOSë¥¼ ì§€ì›í•©ë‹ˆë‹¤. CI/CD í™˜ê²½ì—ì„œì˜ ê³ ê¸‰ ì‚¬ìš© ì‚¬ë¡€ì— ëŒ€í•œ ë¬¸ì„œë„ ì¶”ê°€ë¡œ ì œê³µë©ë‹ˆë‹¤.\n\nì´ í”„ë¡œì íŠ¸ëŠ” ì˜¤í”ˆ ì†ŒìŠ¤ì´ë©°, Swift ì»¤ë®¤ë‹ˆí‹° ë‚´ì—ì„œ ê¸°ì—¬ì™€ ë…¼ì˜ë¥¼ ì¥ë ¤í•©ë‹ˆë‹¤. íŠ¹íˆ íŒ¨íŠ¸ë¦­ í”„ë¦¬ë“œ(Patrick Freed)ì˜ ê¸°ì—¬ì— ê°ì‚¬ì˜ ëœ»ì„ ì „í•©ë‹ˆë‹¤. ë” ë§ì€ ì •ë³´ëŠ” Swiftly ë¬¸ì„œë¥¼ í†µí•´ í™•ì¸í•  ìˆ˜ ìˆìœ¼ë©°, Swift í¬ëŸ¼ì—ì„œ ì»¤ë®¤ë‹ˆí‹°ì™€ ì†Œí†µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "81b904731d3c64d7",
    "title": {
      "en": "The Real Book (2021)",
      "ko": "ì§„ì§œ ì±… (2021)",
      "ja": null
    },
    "type": "story",
    "url": "https://99percentinvisible.org/episode/the-real-book/",
    "score": 61,
    "by": "Tomte",
    "time": 1743179950,
    "content": "Episode 438\nThe Real Book\n\n    PlayPause\n  Click to enlarge image\n\n                    History\n\n      Category\n      History\n\n      Date\n      04.06.21\n\n    Producer\n    99pi\n\n            Add to QueueRemove from QueueDownloadTranscript\n\n                      Share on Facebook\n\n                      Share on Twitter\n\n                      Leave a Comment\n\n                Since the mid-1970s, almost every jazz musician has owned a copy of the same book. It has a peach-colored cover, a chunky, 1970s-style logo, and a black plastic binding. Itâ€™s delightfully homemade-lookingâ€”like it was printed by a bunch of teenagers at a Kinkos. And inside is the sheet music for hundreds of common jazz tunesâ€”also known as jazz â€œstandardsâ€â€”all meticulously notated by hand. Itâ€™s called the Real Book.\n\nBut if you were going to music school in the 1970s, you couldnâ€™t just buy a copy of the Real Book at the campus bookstore. Because the Real Bookâ€¦ was illegal. The worldâ€™s most popular collection of jazz music was a totally unlicensed publication. It was a self-published book created without permission from music publishers or songwriters. It was duplicated at photocopy shops and sold on street corners, out of the trunks of cars, and under the table at music stores where people used secret code words to make the exchange. The full story of how the Real Book came to be this bootleg bible of jazz is a complicated one. Itâ€™s a story about what happens when an insurgent, improvisational art form like jazz gets codified and becomes something that you can learn from a book.\nThe History of Fake Books\nBarry Kernfeld\n is a musicologist who has written a lot about the history of jazz and music piracy. Kernfeld says that long before the Real Book ever came out, jazz musicians were relying on collections of music they called fake books. Kernfeld says that the story of the first fake book began in the 1940s. â€œA man named George Goodwin in New York City, involved in radio in the early 1940s, was getting a little frustrated with all the intricacies of tracking licensing. And so he invented this thing that he called the Tune-Dex,â€ explains Kernfeld.\nTuneDex card via Georgia State University Library\nThe Tune-Dex was an index card catalog designed for radio station employees to keep track of the songs they were playing on air. On one side the cards had information about a particular song, such as the composer, the publisher, and anything that one would need to know for payment rights. On the other side of the card were a few lines of bite-sized sheet musicâ€”just the songâ€™s melody, lyrics, and chords so that radio station employees could glance at it and quickly recall the song. This abbreviated musical notation also made the cards useful to another group of people: working jazz musicians.\n\nAs a Black art form, jazz had developed out of a mix of other Black music traditions including spirituals and the blues. By the 1940s, a lot of â€œjazzâ€ was popular dance music, and many jazz musicians were making their money playing live gigs in small clubs and bars. The standard jazz repertoire was mostly well-known pop songs from Broadway, or New Yorkâ€™s songwriting factory: â€œTin Pan Alley.â€\n\nJazz musicians would riff and freestyle over these songs. The art of improvisation has always been a key art form of jazz music. But what made the average gigging trumpeter or sax player truly valuable was their ability to play any one of hundreds of songs right there on the spot.\nTo be prepared for any request, musicians would bring stacks and stacks of sheet music to every gig. But lugging around a giant pile of paper could be really cumbersomeâ€”this is where the Tune-Dex came in. Someone figured out that you could gather together a bunch of Tune-Dex cards, print copies of them on sheets of paper, add a table of contents and a simple binding, and then sell the finished product directly to musicians in the form of a book. They called them â€œfake booksâ€ because they helped musicians fake their way through unfamiliar songs. These first fake books were cheaper than regular sheet music, and a lot more organized. They became an essential tool for this entire class of working musicians.\n\nBootleggers\n\nMusicians loved these new fake books, but the music publishers hated them. They wanted musicians to buy legal sheet music, and so the publishing companies started cracking down on fake book bootleggers. That, of course, didnâ€™t stop the bootleggers and by the 1950s, there were countless illegal fake books in existence, which were being used in nightclubs all across the country.\n\nAs helpful as fake books were, they had a lot of problems. They were notoriously illegible and confusingly laid out. The other big problem with these fake books at this point was that the music inside felt really out of date. The fake books hadnâ€™t changed since the mid-40s, but jazz had. Disillusioned by commercial jazz that appealed to mainstream white audiences, a new generation of Black musicians took jazz improvisation to a new level. They experimented with more angular harmonies, technically demanding melodies and blindingly fast tempos. Their new style was called bebop.\n\nBebop was just the beginning. Over several decades, jazz exploded into this constellation of different styles. Meanwhile, the economics of jazz shifted too. There were fewer clubs, smaller paychecks, and more university jazz programs with steady teaching gigs. The ivory tower, not the nightclub, increasingly became a place for young musicians to learn, and for established musicians to earn a living. And if youâ€™re going to jazz school, you need jazz books.\nBerklee College of Music. Photo by Cryptic C62\nThe fake books at the time hadnâ€™t kept up with the music. They still contained the same old-fashioned collection of standards with the same old-fashioned collection of chord changes. If a young jazz musician wanted to try and play like Charles Mingus or Sonny Rollins, they werenâ€™t going to learn from a book. That isâ€¦ until two college kids invented the Real Book.\n\nThe Two Guys\n\nIn the mid-70s, Steve Swallow began teaching at Bostonâ€™s Berklee College of Music, an elite private music school that boasted one of the first jazz performance programs in the country. Swallow had only been teaching at Berklee for a few months when two students approached him about a secret project. â€œI keep referring them to them as â€˜the two guys who wrote the book,â€™ becauseâ€¦they swore me to secrecy. They made me agree that I would not divulge their names,â€ explains Swallow. The â€œtwo guysâ€ wanted to make a new fake book, one that actually catered to the needs of contemporary jazz musicians and reflected the current state of jazz. And they needed Swallowâ€™s help.\n\nFrom the very beginning, the students envisioned the Real Book as a cooler and more contemporary fake book than the stodgy, outdated ones theyâ€™d grown up with. They wanted it to include new songs from jazz fusion artists like Herbie Hancock, and free jazz pioneers like Ornette Coleman who were pushing the boundaries of the genre. They also wanted to include the old jazz standards from Broadway and Tin Pan Alley, but they wanted to update those classics with alternate chord changes that reflected the way modern musicians, like Miles Davis, were actually playing them.\n\nModern jazz musicians had altered a lot of classic standards over the years, with new harmonies and more complex chord changes. And to capture these new sounds, the students spent hours listening to recordings and transcribing what they heard, as best they could. It was a huge undertaking because most of these chord changes had never actually been written down. They werenâ€™t necessarily thinking about it like this at the time, but the students were effectively establishing a new set of standardized harmonies for a handful of classic songs.\n\nThe music wasnâ€™t the only part of their new fake book that the students wanted to improve. They also wanted to fix the aesthetic problems with the old fake books, and make something that was nice to look at and easy to read. One of â€œthe two guysâ€ notated all of the music by hand in this very distinctive and expressive script. He also designed and silk-screened the logo on the front cover: â€œThe Real Book,â€ written in chunky, SchoolHouse Rock-style block letters.\n\nBy the summer of 1975, the book was done, and the students took it to local photocopying shops where they cranked out hundreds of copies to sell directly to other students and a few local businesses near Berklee. Overnight, almost everyone had to have one. As the Real Bookâ€™s notoriety grew, so did the demand. The two students hadnâ€™t printed enough copies to keep up, but it turns out, they didnâ€™t need to. Not long after they created a few hundred copies of the book, bootleg versions began popping up all over the world. The Real Book had taken on a life of its own, and the students ironically found themselves in the same position as the music publishers and songwriters theyâ€™d originally cut out of the process, as they watched unlicensed copies of their work get duplicated and sold. After they released the first edition of the Real Book, the students put out two more editions to correct mistakes, and then their work was done. But the Real Book lived on, copied over and over again by new generations of bootleggers. And as the number of students in elite conservatory jazz programs continued to swell over the next few decades, the Real Book, with its modern repertoire, reharmonized standards, and beautiful handwriting, became the de-facto textbook for this new legion of jazz students. The unofficial official handbook of jazz.\n\nThe Real Real Book\n\nJust like with old fake books, the success of the Real Book was a major problem for music publishers. Some companies released their own fake books, but they never managed to compete with the Real Book. The popularity of the Real Book meant that lots of people werenâ€™t getting paid for their work. But in the mid-2000s, music executive Jeff Schroedl and the publisher Hal Leonard decided, if you canâ€™t beat â€™em, join â€™em. They went through the Real Book page by page, secured the rights to almost every song, and published a completely legal version. You donâ€™t need to buy the Real Book out of the back of someoneâ€™s car anymore. Itâ€™s available at your local music shop. They even wanted the same handwriting. Hal Leonard actually hired a copyist to mimic the old Real Bookâ€™s iconic script and turn it into a digital font, which means a digital copy of a physical copy of one anonymous Berklee studentâ€™s handwriting from the mid-70s will continue to live on for as long as new editions of the book are published.\nThe Hal Leonard version of the Real Book\nWhen Hal Leonard finally published the legal version of the Real Book in 2004, it was great news if you were a composer with a song in there. Youâ€™d finally be getting royalties from the sale of the most popular jazz fake book of all time. But that didnâ€™t totally solve the intellectual property problems with the Real Book. While the legalization of the Real Book did resolve most of its flagrant copyright violations, it didnâ€™t clear up authorship disputes that go back to the early days of jazz. Many jazz songs arise out of collective tinkering and improvising in jam sessions. Itâ€™s sometimes quite hard to say who exactly wrote a given song, and power dynamics often impacted whose name actually got listed as an official songwriter. And so there are likely many musicians whose names will never appear on the songs they helped write, even if those songs appear in the legal Real Book.\n\nUseful Tool, or Reductive Cheat Sheet?\n\nEven if we put the intellectual property questions aside for a second, fake books like the Real Book still have plenty of critics. Nicholas Payton is a musician and record label owner, and he compares the Real Book to a study guide or a cheat sheetâ€”a way to distill this complicated art form into a manageable packet of digestible information. To Payton, jazz isnâ€™t just information to be learned. Itâ€™s a way of thinking and a form of expression. And itâ€™s fundamentally a Black cultural phenomenon that canâ€™t be taken out of its historical context. Payton says that reading books like the Real Book, even going to music school, can really only get you so far. If you want to learn to play, at some point youâ€™re going to have to immerse yourself in the culture of the music. For Payton (and many musicians) learning directly from elders, in person, is a crucial part of what it means to really know the art form.\nThereâ€™s also the question of codification, and whether itâ€™s useful to have one songbook filled with definitive versions of all these jazz tunes. Carolyn Wilkins has taught ensembles at Berklee College of Music, and she says that the chords that are written down in the Real Book sometimes get treated like the right way to play a particular song. But even though jazz has all of these â€œstandards,â€ theyâ€™re not supposed to be played in one standard way. As you listen to different recordings of the same song by different jazz artists, it becomes obvious that thereâ€™s no one right way to play it. Wilkins says that the Real Book does have its place in jazz education. Over her years at Berklee, sheâ€™s seen how it can be a useful starting place as a tool to bring young jazz musicians together. The key, she says, is to treat the Real Book as a starting place. From there you need to go out and explore all the other ways people have played a particular song. â€œAnd then ultimately you must find your own way.â€\n\n        Enjoy 99pi? Subscribe to the podcast!\n        iTunes RSS Feed\n\n        Get the latest from 99pi each week in your inbox\n\n            Email Address\n\n              Yes Please! By submitting this form, you acknowledge that you have read the Terms of Use and Privacy Policy, that you understand them, and that you agree to be bound by them.  If you do not agree to be bound by the Terms of Use and Privacy Policy, you may not use the 99% Invisible website and services.\n\n        Enjoy 99pi? Subscribe to the podcast!\n        Subscribe Subscribe\n\n  Credits\n\n      Production\n      Reporter Mikel McCavana spoke with Jeff Leonard, musician and music educator at Berklee College of Music, Boston University, New England Conservatory; Steve Swallow, musician and composer; Barry Kernfeld, musicologist and author; Jeff Schroedl, Executive Vice President at Hal Leonard; Nicholas Payton; Musician, owner of Paytone Records, and creator of the Black American Music (BAM) movement; Carolyn Wilkins, musician and professor at Berklee College of Music; Gerald Horne, author and Moores Professor of History and African American Studies at the University of Houston.\nThis episode was edited by Emmett FitzGerald.",
    "summary": {
      "en": "**Episode 438: The Real Book - Summary**\n\nSince the 1970s, nearly every jazz musician has owned a book called the Real Book, which has a peach cover and contains hand-written sheet music for many jazz standards. However, this book was initially illegal, as it was self-published without permission from music publishers or songwriters and was sold covertly.\n\nThe origin of the Real Book is linked to earlier \"fake books,\" which emerged in the 1940s to help musicians play popular songs without carrying large amounts of sheet music. These fake books faced backlash from publishers who wanted to sell legal sheet music.\n\nThe Real Book was created in the mid-70s by two students at Berklee College of Music who wanted a modern collection that included contemporary jazz tunes and updated chord changes. They produced copies to sell to fellow students, but soon bootleg versions appeared worldwide, leading to a surge in demand.\n\nIn the mid-2000s, Hal Leonard published a legal version of the Real Book, ensuring composers received royalties, but some intellectual property issues remained unresolved, particularly regarding authorship of jazz songs.\n\nWhile the Real Book is a useful tool for learning jazz, critics argue it oversimplifies the genre. Musicians like Nicholas Payton emphasize that jazz is more than just notes on a page; it's about cultural immersion and personal expression. Others, like Carolyn Wilkins, see the Real Book as a helpful starting point but stress the importance of exploring diverse interpretations of jazz music.",
      "ko": "1970ë…„ëŒ€ ì´í›„ ê±°ì˜ ëª¨ë“  ì¬ì¦ˆ ìŒì•…ê°€ë“¤ì€ ë³µìˆ­ì•„ìƒ‰ í‘œì§€ë¥¼ ê°€ì§„ 'ë¦¬ì–¼ ë¶'ì´ë¼ëŠ” ì±…ì„ ì†Œìœ í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ ì±…ì—ëŠ” ë§ì€ ì¬ì¦ˆ ìŠ¤íƒ ë‹¤ë“œì˜ ì†ìœ¼ë¡œ ì“´ ì•…ë³´ê°€ ë‹´ê²¨ ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ ì±…ì€ ì²˜ìŒì—ëŠ” ë¶ˆë²•ì´ì—ˆìŠµë‹ˆë‹¤. ìŒì•… ì¶œíŒì‚¬ë‚˜ ì‘ê³¡ê°€ì˜ í—ˆê°€ ì—†ì´ ìê°€ ì¶œíŒë˜ì–´ ë¹„ë°€ë¦¬ì— íŒë§¤ë˜ì—ˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.\n\në¦¬ì–¼ ë¶ì˜ ê¸°ì›ì€ 1940ë…„ëŒ€ì— ë“±ì¥í•œ 'ê°€ì§œ ë¶'ê³¼ ê´€ë ¨ì´ ìˆìŠµë‹ˆë‹¤. ì´ ê°€ì§œ ë¶ì€ ìŒì•…ê°€ë“¤ì´ ë§ì€ ì•…ë³´ë¥¼ ê°€ì§€ê³  ë‹¤ë‹ˆì§€ ì•Šê³ ë„ ì¸ê¸° ê³¡ì„ ì—°ì£¼í•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ê¸° ìœ„í•´ ë§Œë“¤ì–´ì¡ŒìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì¶œíŒì‚¬ë“¤ì€ ë²•ì ì¸ ì•…ë³´ë¥¼ íŒë§¤í•˜ê³  ì‹¶ì–´ í–ˆê¸° ë•Œë¬¸ì— ê°€ì§œ ë¶ì— ëŒ€í•œ ë°˜ë°œì´ ìˆì—ˆìŠµë‹ˆë‹¤.\n\në¦¬ì–¼ ë¶ì€ 1970ë…„ëŒ€ ì¤‘ë°˜, í˜„ëŒ€ì ì¸ ì¬ì¦ˆ ê³¡ê³¼ ì—…ë°ì´íŠ¸ëœ ì½”ë“œ ë³€í™”ë¥¼ í¬í•¨í•œ ì»¬ë ‰ì…˜ì„ ì›í–ˆë˜ ë²„í´ë¦¬ ìŒì•… ëŒ€í•™ì˜ ë‘ í•™ìƒì— ì˜í•´ ë§Œë“¤ì–´ì¡ŒìŠµë‹ˆë‹¤. ê·¸ë“¤ì€ ë™ë£Œ í•™ìƒë“¤ì—ê²Œ íŒë§¤í•˜ê¸° ìœ„í•´ ë³µì‚¬ë³¸ì„ ì œì‘í–ˆì§€ë§Œ, ê³§ ì „ ì„¸ê³„ì—ì„œ ë¶ˆë²• ë³µì œí’ˆì´ ë“±ì¥í•˜ë©´ì„œ ìˆ˜ìš”ê°€ ê¸‰ì¦í–ˆìŠµë‹ˆë‹¤.\n\n2000ë…„ëŒ€ ì¤‘ë°˜, í•  ë ˆë„ˆë“œê°€ ë¦¬ì–¼ ë¶ì˜ í•©ë²•ì ì¸ ë²„ì „ì„ ì¶œíŒí•˜ì—¬ ì‘ê³¡ê°€ë“¤ì´ ë¡œì—´í‹°ë¥¼ ë°›ì„ ìˆ˜ ìˆë„ë¡ í–ˆì§€ë§Œ, ì¬ì¦ˆ ê³¡ì˜ ì €ì‘ê¶Œ ë¬¸ì œëŠ” ì—¬ì „íˆ í•´ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n\në¦¬ì–¼ ë¶ì€ ì¬ì¦ˆë¥¼ ë°°ìš°ëŠ” ë° ìœ ìš©í•œ ë„êµ¬ì´ì§€ë§Œ, ë¹„í‰ê°€ë“¤ì€ ì´ ì±…ì´ ì¥ë¥´ë¥¼ ì§€ë‚˜ì¹˜ê²Œ ë‹¨ìˆœí™”í•œë‹¤ê³  ì£¼ì¥í•©ë‹ˆë‹¤. ë‹ˆì½œë¼ìŠ¤ í˜ì´íŠ¼ê³¼ ê°™ì€ ìŒì•…ê°€ëŠ” ì¬ì¦ˆê°€ ë‹¨ìˆœíˆ ì•…ë³´ì— ì íŒ ìŒí‘œ ì´ìƒì˜ ê²ƒì´ë¼ê³  ê°•ì¡°í•˜ë©°, ë¬¸í™”ì  ëª°ì…ê³¼ ê°œì¸ì  í‘œí˜„ì´ ì¤‘ìš”í•˜ë‹¤ê³  ë§í•©ë‹ˆë‹¤. ìºë¡¤ë¦° ìœŒí‚¨ìŠ¤ì™€ ê°™ì€ ë‹¤ë¥¸ ì´ë“¤ì€ ë¦¬ì–¼ ë¶ì´ ìœ ìš©í•œ ì¶œë°œì ì´ ë  ìˆ˜ ìˆì§€ë§Œ, ì¬ì¦ˆ ìŒì•…ì˜ ë‹¤ì–‘í•œ í•´ì„ì„ íƒêµ¬í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë‹¤ê³  ê°•ì¡°í•©ë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "f5d064ce994c8f87",
    "title": {
      "en": "xAI has acquired X, xAI now valued at $80 billion",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://twitter.com/elonmusk/status/1905731750275510312",
    "score": 46,
    "by": "rvz",
    "time": 1743197022,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "bb49980e2d39f614",
    "title": {
      "en": "SignalBotOne â€“ Notification Webhooks for Signal",
      "ko": "ì‹œê·¸ë„ë´‡ ì•Œë¦¼",
      "ja": null
    },
    "type": "story",
    "url": "https://signalbot.one/",
    "score": 36,
    "by": "danslo",
    "time": 1743181616,
    "content": "Add a Webhook to Your Signal ChatReceive messages on Signal via a simple API.Perfect for notifications and alerts.Try it! Learn More â†’$ curl -d 'ğŸš€ Houthi alert' https://signalbot.one/api/...9:41SignalBotğŸš€ Houthi alert9:41\n\nGet startedReceive Signal messages in two steps1Message @BotMaster.1000And get an instant webhook URL2Receive NotificationsGet real-time alerts and notifications, via DM or in a Signal group.SignalBotğŸš¨ Alert: Server CPU usage at 92%SignalBotâœ… Deployment successful: v2.1.3\n\nFrequently Asked QuestionsEverything you need to know about SignalBotHow secure is SignalBot?SignalBot uses strong security measures and does not store messages or metadata. However, it is not recommended to use the API to send passwords or war plans. If you want to notify a group, it's the safest to create a dedicated group chat for SignalBot notifications.Who's behind this?SignalBot was made by gwillem and is free to use. Like it? Buy me a coffee â¤ï¸ Can I customize the notification format?Right now, only plain text and emojis are supported. Markdown support is on the way.What integrations are available?SignalBot offers a generic webhook API that can be used with curl or any programming language. It can be used to message you or a group you have invited SignalBot to. If you require specific integrations, do reach out!",
    "summary": {
      "en": "### Summary: Adding a Webhook to Your Signal Chat\n\nYou can receive messages on Signal easily using a simple API, which is great for notifications and alerts. Here's how to get started:\n\n1. **Get a Webhook URL**: Message @BotMaster to receive your webhook URL.\n2. **Receive Notifications**: Get real-time alerts via direct message or in a Signal group.\n\n**Examples of Notifications**:\n- Server CPU usage alert\n- Successful deployment notifications\n\n### Frequently Asked Questions\n\n- **Security**: SignalBot is secure and doesnâ€™t store messages or metadata. Avoid sending sensitive information like passwords.\n- **Creator**: SignalBot is developed by gwillem and is free to use.\n- **Customization**: Currently, notifications can only be plain text and emojis, with Markdown support coming soon.\n- **Integrations**: SignalBot has a generic webhook API that works with various programming languages. Reach out for specific integration needs.",
      "ko": "ì‹ í˜¸ ì±„íŒ…ì— ì›¹í›„í¬ë¥¼ ì¶”ê°€í•˜ëŠ” ë°©ë²•ì€ ê°„ë‹¨í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ì•Œë¦¼ê³¼ ê²½ê³ ë¥¼ ì‰½ê²Œ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‹œì‘í•˜ëŠ” ë°©ë²•ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n\në¨¼ì € ì›¹í›„í¬ URLì„ ë°›ì•„ì•¼ í•©ë‹ˆë‹¤. @BotMasterì—ê²Œ ë©”ì‹œì§€ë¥¼ ë³´ë‚´ë©´ ì›¹í›„í¬ URLì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´í›„ì—ëŠ” ì§ì ‘ ë©”ì‹œì§€ë‚˜ ì‹ í˜¸ ê·¸ë£¹ì„ í†µí•´ ì‹¤ì‹œê°„ ì•Œë¦¼ì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nì•Œë¦¼ì˜ ì˜ˆë¡œëŠ” ì„œë²„ CPU ì‚¬ìš©ëŸ‰ ê²½ê³ ë‚˜ ì„±ê³µì ì¸ ë°°í¬ ì•Œë¦¼ì´ ìˆìŠµë‹ˆë‹¤.\n\nìì£¼ ë¬»ëŠ” ì§ˆë¬¸ì— ëŒ€í•´ ì„¤ëª…í•˜ê² ìŠµë‹ˆë‹¤. ë³´ì•ˆ ì¸¡ë©´ì—ì„œ SignalBotì€ ì•ˆì „í•˜ë©° ë©”ì‹œì§€ë‚˜ ë©”íƒ€ë°ì´í„°ë¥¼ ì €ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë¹„ë°€ë²ˆí˜¸ì™€ ê°™ì€ ë¯¼ê°í•œ ì •ë³´ëŠ” ë³´ë‚´ì§€ ì•ŠëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. SignalBotì€ gwillemì´ ê°œë°œí•˜ì˜€ìœ¼ë©° ë¬´ë£Œë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í˜„ì¬ ì•Œë¦¼ì€ ì¼ë°˜ í…ìŠ¤íŠ¸ì™€ ì´ëª¨ì§€ë¡œë§Œ ì œê³µë˜ë©°, ê³§ ë§ˆí¬ë‹¤ìš´ ì§€ì›ì´ ì¶”ê°€ë  ì˜ˆì •ì…ë‹ˆë‹¤. SignalBotì€ ë‹¤ì–‘í•œ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì™€ í˜¸í™˜ë˜ëŠ” ì¼ë°˜ ì›¹í›„í¬ APIë¥¼ ì œê³µí•˜ë¯€ë¡œ, íŠ¹ì • í†µí•© í•„ìš”ê°€ ìˆì„ ê²½ìš° ë¬¸ì˜í•´ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "a77b776dfe11cf48",
    "title": {
      "en": "A cretaceous fly trap? Remarkable abdominal modification in a fossil wasp",
      "ko": "ê³µë£¡ ì‹œëŒ€ íŒŒë¦¬ ë«? í™”ì„ ë²Œì˜ ë†€ë¼ìš´ ë³€í™”",
      "ja": null
    },
    "type": "story",
    "url": "https://bmcbiol.biomedcentral.com/articles/10.1186/s12915-025-02190-2",
    "score": 16,
    "by": "gnabgib",
    "time": 1743188100,
    "content": "Research\n\n            Open access\n\n                            Published: 27 March 2025\n\n                        A cretaceous fly trap? remarkable abdominal modification in a fossil wasp\n                        Qiong Wu1, Lars Vilhelmsen2, Xiaoqin Li1, De Zhuo3, Dong Ren1 & â€¦Taiping Gao1Show authors\n\n    BMC Biology\n\n                            volume23, Articlenumber:81 (2025)\n            Cite this article\n\n                        1589 Accesses\n\n                            509 Altmetric\n\n                    Metrics details\n\n                    AbstractBackgroundCarnivorous insects have evolved a range of prey and host capture mechanisms. However, insect predation strategies in the fossil record remain poorly understood.ResultsHere, we describe â€ Sirenobethylus charybdis n. gen. & sp., based on sixteen adult female wasps in Kachin amber from the mid-Cretaceous, 99 Mya (million years ago), and place it in Chrysidoidea: â€ Sirenobethylidae n. fam. The fossils display unique morphological modifications on the tip of the abdomen consisting of three flaps from the modified abdominal sternum 6 and tergum and sternum 7; the lower flap formed from sternum 6 is preserved in different positions relative to the other flaps in different specimens, indicating that they form some sort of grasping apparatus. Nothing similar is known from any other insect; the rounded abdominal apparatus, combined with the setae along the edges, is reminiscent of a Venus flytrap. Phylogenetic analysis suggests that the new family is a separate lineage close to the base of Chrysidoidea.Conclusionsâ€ Sirenobethylus probably was a koinobiont parasitoid wasp; the abdominal grasping apparatus may have been used to temporarily immobilize the host during oviposition. The new fossils suggest that Chrysidoidea displayed a wider range of parasitoid strategies in the mid-Cretaceous than they do today.\n\n                    BackgroundInsects are the most diverse group of animals on the planet, with more than 1 million described species and probably several times more undescribed; recent estimates suggest approximately 5.5 million species in total [1, 2]. Their highly adaptable exoskeleton has allowed them to radiate and colonize a wide range of habitats and develop highly efficient and innovative solutions to a range of challenges posed by their surroundings [3, 4]. Among other mechanisms, carnivorous insects have evolved a range of prey capture mechanisms [5, 6]: the forelegs of praying mantises (Mantodea) and mantis flies (Neuroptera: Mantispidae) [7]; the capture basket formed by the spiny legs of adult dragonflies (Odonata); the prehensile labial â€˜maskâ€™ employed by dragonfly nymphs [8]; the modified fore legs of female dryinid wasps (Hymenoptera: Dryinidae) for immobilizing hosts temporarily [9]; the hair-trigger mandibles of trap-jaw ants (Formicidae: Odontomachus) [10]; the fore and midlegs of heel-walkers (Mantophasmatodea) for swooping on prey [11]; the large hind tarsal claws of hangingflies (Mecoptera: Bittacidae) for grasping prey [12].The fossil insect fauna from the Cretaceous (Albian â€“ Cenomanian; 99 Mya) Kachin amber provide unique insights into insect evolution [13, 14]; in addition to confirming the ancestry of features observed in modern organisms, it displays occasional examples of ancient morphologies without obvious modern parallels. With regard to potential prey capture mechanisms, the most prominent example so far might be the remarkable mandibles of the â€˜saber-toothâ€™ haidomyrmecine ants [7, 15]. In the present paper, we describe an even more bizarre possible host capture/immobilization mechanism in the abdomen of a chrysidoid wasp. The rounded abdominal apparatus, combined with the setae along the edges, is reminiscent of a Venus flytrap (Droseraceae: Dionaea muscipula), a carnivorous plant using two opposing specialized leaves to capture insect prey [16].ResultsSystematic paleontologyOrder Hymenoptera Linnaeus, 1758.Infraorder Aculeata Latreille, 1802.Superfamily Chrysidoidea Latreille, 1802.Family â€ Sirenobethylidae Wu, Vilhelmsen & Gao fam. nov.ZooBank LSID: urn:lsid:zoobank.org:act:EAEC75B2-83B0-4C0E-A4F8-4F18DA024D15.Type genus. â€ Sirenobethylus Wu, Vilhelmsen & Gao gen. nov.Diagnosis. Head hypognathous, with medial line on vertex. Antenna with nine flagellomeres, antennal sockets simple, close to posterior margin of clypeus; clypeus projecting and acute in lateral view, slightly convex; mandibles with four apical teeth along truncate apical margin; occipital carina distinct, complete. Propleuron not exposed in dorsal view; prosternum small, diamond-shaped, exposed; notauli present. Female macropterous. Second abdominal (first metasomal) segment in dorsal view with angular anterolateral corners; tergum 7 longer than wide, distinctly narrower than other terga; sternum 6 wider than other sterna, laterally expanded distally, paddle-shaped, projecting posteriorly, posterior margin concave, with a dozen very long, slender setae; many thick spines on dorsal surface of sternum 6. Sternum 7 with median part accommodating ovipositor shaft dorsally and two lateral parts curving outwards before approaching median part distally; median and lateral parts of sternum 7 separated by weakly sclerotized areas. Sting sheaths on either side of the sting, apparently shorter than sting.Included genus. â€ Sirenobethylus Wu, Vilhelmsen & Gao gen. nov.Genus â€ Sirenobethylus Wu, Vilhelmsen & Gao gen. nov.ZooBank LSID: urn:lsid:zoobank.org:act:B3548EEB-BF75-4CA3-8E63-23C1B399A47C.Type species. â€ Sirenobethylus charybdis Wu, Vilhelmsen & Gao sp. nov.Etymology. The new generic name is a combination of the Greek â€˜sireno-â€™ meaning â€˜female humanlike beings with alluring voices in Greek mythologyâ€™, and â€˜bethylusâ€™, from the nominal genus of Bethylidae. â€˜Sireno-â€™ is also a reference to Mammalia: Sirenia, as the â€˜tailâ€™ of the wasp in ventral view resembles that of a manatee. The gender is masculine.â€ Sirenobethylus charybdis Wu, Vilhelmsen & Gao sp. nov. (Figs. 1â€“3).Fig.1â€ Sirenobethylus charybdis sp. nov., holotype (specimen CNU-HYM-MA2015124) female. A Dorsal view as preserved. B The tip of abdomen and ovipositor in ventral view, showing trigger hairs (black arrows). C The tip of abdomen and ovipositor in lateral view, showing trigger hairs (black arrows), ovipositor (orange arrow) and groove on the sternum 7 (blue arrow). D Habitus reconstruction. Scale bars: A 0.5mm; B 0.3mm; C 0.2mm. Abbreviations: S6 sternum 6; T7 tergum 7; S7 sternum 7Full size imageZooBank LSID: urn:lsid:zoobank.org:act:75AEB71E-2DCD-4CBA-9EB9-5DEE7CFD0465.Etymology. The epithet refers to Charybdis, the sea monster in Greek mythology who alternately swallowed and disgorged copious amounts seawater three times a day.Diagnosis. As for the genus.Materials. Holotype. Female, CNU-HYM-MA-2015124.Locality and horizon. The amber specimen was collected from Kachin (Hukawng Valley) of northern Myanmar, which is dated at 98.79â€‰Â±â€‰0.62 Mya [17, 18].Description. See Additional file 1: Figs. S1â€“S16, Dataset S1 [19,20,21,22,23,24,25,26,27], Additional file 2: Table S1.DiscussionPhylogenetic position of â€ Sirenobethylus gen. nov.We describe a new genus â€ Sirenobethylus, from mid-Cretaceous Kachin amber, based on sixteen specimens. The new genus is readily attributed to the Aculeata by its concealed posterior abdominal segments and ovipositor apparatus [28]. â€ Sirenobethylus has 9 flagellomeres and forewing with 8 closed cells, which is different from Vespoidea sensu lato [29] and Apoidea (antenna with 10 flagellomeres in female and forewing usually has 10 or 9 closed cells) [30, 31]. Therefore, â€ Sirenobethylus probably belongs to Chrysidoidea. We retrieve this superfamily as monophyletic (Fig.4, Additional file 1: Dataset S2) [32], unlike some recent molecular studies [33].All â€ Sirenobethylus specimens examined are macropterous females; given the unique diagnostic traits in, e.g., wing venation, and the somewhat isolated phylogenetic position of the new taxon (Fig.4), it is not possible to associate these females with any males known from Kachin amber. They have the forewing venation similar to â€ Chrysopsenellidae, including a long pterostigma, a closed subdiscal cell, and vein 2m-cu absent (Fig.1A and D). Therefore, the new genus is much more similar to â€ Chrysopsenellidae than extant groups. However, â€ Sirenobethylus has comparatively complete hind wing venation, including two closed cells also exhibited by â€ Plumalexiidae and Plumariidae, but different from other groups of Chrysidoidea [34]. All these features suggest that â€ Sirenobethylus could be a stem group of Chrysidoidea, which is consistent with our phylogenetic analyses (Fig.4, Additional file 3: Table S2). Furthermore, â€ Sirenobethylus has a unique combination of diagnostic characters within Chrysidoidea. For these reasons, we place â€ Sirenobethylus charybdis gen. & sp. n. in its own family, the â€ Sirenobethylidae.Possibly function of the abdominal apparatusThe abdominal apparatus of â€ Sirenobethylus, including the sixth sternum and the seventh tergum and sternum, form three superimposed horizontal flaps, modified into a complex composite structure. The composite structure is round and resembles that of the Venus flytrap (Droseraceae: Dionaea muscipula), the carnivorous plant that captures insects between its leaves [16]. The upper flap (tergum 7) is elongate and tongue-shaped; the middle flap (sternum 7) extends laterally far beyond the dorsal flap and is extensively membranous. The lower flap (sternum 6) is expanded distally and laterally, forming a paddle-shaped structure (Fig.1B); the thick spines on the dorsal part of the lower flap are elongate and scattered in the middle, but shorter and more densely placed along the edges (Additional file 4: Video S1). Furthermore, micro-CT (micro computed tomography) reconstruction shows two apodemes on the anterolateral corners of the lower flap, just inside the constriction where the sternum 6 meets the posterior margin of sternum 5 (Additional file 5: Video S2). The posterior margin of the lower flap has a dozen very long, slender setae extending from it. The tip of the abdomen often has numerous setae in the extant Aculeata, but they are not as long [35, 36]. The eighth tergum of â€ Sirenobethylus is hidden beneath the upper flap and the sting and is shorter than the upper flap (Fig.2D). The sting of â€ Sirenobethylus extends through a groove on the dorsal side of the middle flap, below the upper flap; the sting sheaths are situated on either side of the sting, and are apparently shorter than the sting (Fig.1C). Among the existing Aculeata with stings, most have sheaths that are about as long as the sting itself [28].Fig.2Photographs and micro-CT reconstructions (volume renderings) of â€ Sirenobethylus charybdis sp. nov., paratype (specimen CNU-HYM-MA2015119) female. A Dorsal view as preserved. B Micro-CT reconstruction of the tip of abdomen in dorsal view, showing sternum 6, sternum 7 lateral bar, sternum 7 median bar and the contact point between the two, ovipositor (white arrows). C Micro-CT reconstruction of sternum 3 with transverse line. D Micro-CT reconstruction of the interior abdomen in lateral view; blue area indicates extent of tergum 8, green area indicates sternum 6. Scale bars: A 0.5mm; Bâ€“D 0.2mm. Abbreviations: S6 sternum 6; S7 sternum 7; T8 tergum 8Full size imageThe abdominal apparatus of â€ Sirenobethylus is unlike anything previously reported from any extant wasp or indeed any insect known to us [5, 37]. From the morphology and the different states of position of the lower flap preserved in different specimens, it seems evident that the apparatus had some grasping function. We consider two different possible usages for the apparatus: 1) It may have had a function during mating, restraining the male. Due to the lack of male fossil evidence, we cannot determine the role of the apparatus in the mating process. Indeed, it would be unique for insect females to restrain the males during mating, rather than the other way around. We consider this an unlikely function of the abdominal apparatus. 2) It might have served to restrain a host temporarily during oviposition. We consider this to be the most likely function of the abdominal apparatus and will elaborate on this in the following.The fortuitous preservation of the flaps in different relative positions in various specimens of â€ Sirenobethylus, i.e., â€˜openâ€™ with the lower flap depressed relative to the middle and dorsal flaps (Figs. 3Fâ€“H, Additional file 1: Figs. S2, S10, S13) versus â€˜closedâ€™ with the ventral flap closely appressed to the middle and dorsal flaps (Figs. 1C, 2D, 3E, Additional file 1: Figs. S4, S5, S7, S9, S11, S14, S16) indicates that together they form a grasping apparatus. The very elongate hairs along the posterior margin of the ventral flap (Figs. 1D, 3C and D) might have served as â€˜trigger hairsâ€™ forewarning the parasitoid of an approaching host and perhaps indicating the host's position based on the number of hairs that the host touches [38]. The setae on the lower flap are long and sparse in the middle, and short and dense along the edges and presumably flexible (Fig.2D); the extensive membranous areas on the middle flap (Fig.2B) appear relatively soft. We speculate that the coarse setal brush inside the ventral flap and the extensive membranous areas on the middle flap might have served to cushion the host during oviposition rather than crushing it, indicating that the host may not have been permanently incapacitated during the procedure and that â€ Sirenobethylus might have been a koinobiont parasitoid rather than a predator [27]. For these reasons, we suggest that the abdominal apparatus could have served to temporarily grasp and immobilize the host during oviposition. In addition, the sting of â€ Sirenobethylus is situated in a groove on the dorsal side of the middle flap, and among the sixteen specimens, six specimens have stings preserved with grooves directed downward, which would allow the â€ Sirenobethylus to easily sting the captured host (Figs. 1C, 3Eâ€“G, Additional file 1: Figs. S5F, S8G, S10D, S11D, S12H, S16E).Fig.3Photographs of â€ Sirenobethylus charybdis sp. nov. females. (A, B) Lateral view of specimens CNU-HYM-MA2015132 and CNU-HYM-MA2015125. (C, D) Dorsal view of specimens CNU-HYM-MA2015129 and CNU-HYM-MA2015122, showing trigger hair (black arrows). (Eâ€“H) Abdominal terminal in posterior view of specimens CNU-HYM-MA2015132, CNU-HYM-MA2015125, CNU-HYM-MA2015129, CNU-HYM-MA2015122, showing ovipositor (orange arrows), respectively, with upperâ€‰+â€‰middle and lower flap in different relative positions (e.g., E: closed; H: fully open). Scale bars: Aâ€“D 0.5mm; Eâ€“H 0.2mmFull size imageBased on the reconstruction from micro-CT data (Fig.2, Additional file 4: Video S1, Additional file 5: Video S2), the lower flap rotates around the point where sternum 6 is overlapped ventrally by sternum 5. Adductor muscles inserting on the lower side of the anterolateral apodemes would raise the lower flap towards the middle flap, closing the apparatus, whereas abductor muscles inserting on the upper part of the apodemes would depress the lower flap away from the middle flap. For quick operation, especially when closing the apparatus to grasp the host, the muscles would have to be of substantial size. We speculate that the abductors and adductors might have arisen from tergum 3 and sternum 3, respectively; these are the largest sclerites in the abdomen and each have a transverse line on their anterior part that might indicate the attachment sites of the muscles.The extant Chrysidoidea sensu lato [27, 30] display a range of life histories: parasitoids of wood-living beetle larvae (Scolebythidae), parasitoids of beetle or Lepidoptera larvae (Bethylidae), parasitoids of sawfly cocoons (Chrysididae: Cleptinae), egg-parasitoids of stick insects (Chrysididae: Amiseginae and Loboscelidinae), kleptoparasitoids in nests of solitary bees or wasps (Chrysididae: Chrysidinae), parasitoids of nymphs of webspinners/embiopterans (Sclerogibbidae) or parasitoids of nymphs of Auchenorrhyncha (Dryinidae, Embolemidae) [27]. Given this diversity and the lack of information from a number of chrysidoid families, including the extant Plumariidae, it is not possible to infer potential hosts for â€ Sirenobethylus by mapping lifestyles on the phylogeny, although most of the aforementioned groups have also been reported from Kachin amber [39].The females of some Dryinidae have developed a host restraining apparatus on the forelegs [40]; they use their chelate fore tarsi to immobilize their elusive hosts (leafhoppers, treehoppers and planthoppers) during oviposition. These dryinid females are often wingless, have large eyes and elongate legs, and pursue their hosts actively prior to oviposition [9]. In contrast, â€ Sirenobethylus was probably not able to pursue hosts over longer distances given the position of the putative capture apparatus at the posterior end of the body and its overall habitus compared to dryinid females (smaller eyes, shorter legs). However, the elaborate grasping apparatus indicates that â€ Sirenobethylus was indeed targeting highly mobile prey, and the hosts might have been homopteran hoppers (like for dryinids) or small winged insects, like flies, the elongate trigger hairs perhaps eliciting a short posterior lunge if a potential target came within range. We imagine it would have waited with the apparatus open, ready to pounce as soon as a potential host activated the capture response. Our findings suggest that Chrysidoidea displayed a wider range of parasitoid strategies in the mid-Cretaceous than they do today.ConclusionsWe report new mid-Cretaceous fossils of Chrysidoidea, suggesting that â€ Sirenobethylidae is a separate lineage close to the base of Chrysidoidea based on phylogenetic analysis. Based on our detailed analyses of the morphology of the specimens at our disposal, we infer that â€ Sirenobethylus was probably a koinobiont parasitoid wasp, the unique grasping mechanism at the tip of the abdomen possibly being used for temporary host capture. Our new findings indicate that by the mid-Cretaceous, some early Chrysidoidea had evolved unique parasitoid strategies.MethodsMaterial availabilityAll specimens were collected from Noije Bum hill, about 18km southwest of Tanai Village in the Hukawng Valley, northern Myanmar (26Â° 21â€² 33.41\" N, 96Â° 43â€² 11.88\" E) [17, 18]. All amber specimens are stored in the Key Lab of Insect Evolution and Environmental Changes, College of Life Sciences, Capital Normal University (CNUB; Dong Ren, Curator), Beijing, China. Extant specimens examined are stored in the Natural History Museum of Denmark, University of Copenhagen, Copenhagen, Denmark. The wing venation nomenclature is based on Rasnitsyn (1980) [41].No datasets were generated or analysed during the current study.Optical microscopy, photographyThe specimens studied were examined and photographed using a Leica M205A stereomicroscope equipped with a Leica DFC425 camera and LAS software. The amber specimens were examined under a Leica M205C stereomicroscope. Figure1 of the holotype specimen, Fig.4 of habitus images of extant specimens and Additional file 1: Fig. S7C and D were taken with a BKâ€‰+â€‰Imaging System from Visionary Digital equipped with a Canon EOS 7D camera. The other images of the amber specimens were taken with a Nikon SMZ 25 microscope with an attached Nikon DS-Ri2 digital camera system or a Nikon ECLIPSE Ni microscope with an attached Nikon DS-Ri2 digital camera system.Fig.4Bayesian phylogenetic tree based on morphological characters. The large black dots show the age of the Kachin amber species; the branch nodes of this phylogenetic tree are not time-calibrated, the geological time scale refers only to the fossil taxa. The numbers on the branch nodes are posterior probabilities. Green branches: Chrysidoidea; blue branches: Vespoidea; orange branches: Apoidea. Families with habitus images associated indicated in purple: â€ Sirenobethylus charybdis (Sirenobethylidae), Chrysis ignita (Chrysididae), Pristocera depressa (Bethylidae), Embolemus ruddii (Embolemidae), Rhopalomutilla carinaticeps (Mutillidae), Polistes nimpha (Vespidae), Scolia quadripunctata (Scoliidae), Formica rufa (Formicidae)Full size imageMicro-CT scanningThe paratype CNU-HYM-MA2015119 was scanned at the micro-CT laboratory of YKLP (Yunnan Key Laboratory for Paleobiology) with an X-ray microscope (3D-XRM), Zeiss Xradia 520 versa. Scanning parameters are as follows: beam strength: 60kV/5w, filter: no, resolution: 1.94Î¼m, exposure time: 5s, number of TIFF images: 1718. Volume rendering and 3D reconstruction were performed using the open-source software Drishti 2.4 [42]. The 3D-reconstruction models of the abdomen of the specimen are displayed in Fig.2, and the original scan data has been deposited in Dryad (Wu et al., 2025; https://doi.org/https://doi.org/10.5061/dryad.4b8gthtq9).Phylogenetic analysisOur phylogenetic analyses included one species of non-aculeate wasp (Trigonalidae: Taeniogonalos gundlachii) as outgroup/root, 19 species of Chrysidoidea (7 fossil, 12 extant), 19 species of Vespoidea (19 extant), and four species of Apoidea (4 extant) as ingroups to clarify the phylogenetic position of the new fossil taxon (see Additional file 3: Table S2). We scored 57 morphological characters (see Additional file 1: Dataset S3) [43,44,45,46,47,48,49,50].Bayesian analyses were performed in MrBayes version 3.2.7 [51]. Only variable characters were coded, and non-applicable morphological characters were treated as missing data. Equal transition probabilities between the states and among-character rate variation were assumed, allowing the different characters to evolve at different rates. Bayesian phylogenetic analysis used the Mk model, were conducted with four independent runs. Convergence was assessed by the average standard deviation of split frequencies (ASDSFâ€‰<â€‰0.01), and the potential scale reduction factor (PSRFâ€‰<â€‰1.005). After 20 million generations, the topology converged with an ASDSFâ€‰<â€‰0.004, and PSRF valuesâ€‰<â€‰1.001. 50% of the generations were then discarded as burn-in. The posterior probabilities were plotted as relative branch support in the final tree (allcompat. tre) using FigTree v.1.4.3 [52]. The halfcompat. tree can be found in the Additional file 1: Fig. S17.\n                    Data availability\n\n              All data generated or analysed during this study are included in this article and its supplementary information files. The sixteen Kachin amber specimens (CNU-HYM-MA2015118 â€“CNU-HYM-MA2015133) reported in this study were purchased by Mr. Fangyuan Xia in April, 2015 and donated to the Key Laboratory of Insect Evolution and Environmental Changes, College of Life Sciences, Capital Normal University in May, 2016. They are deposited in the â€œFossil Insect Collectionâ€ of the Key Laboratory of Insect Evolution and Environmental Changes, College of Life Sciences, Capital Normal University, Beijing, China. Correspondence and requests for materials should be addressed to Dr. Dong Ren, rendong@mail.cnu.edu.cn or Dr. Taiping Gao, tpgao@cnu.edu.cn.\n              Nomenclatural acts established herein are registered in ZooBank (www.zoobank.org) following the requirements of the International Code of Zoological Nomenclature and listed under LSID: urn:lsid:zoobank.org:pub:33EF6F52-752D-4283-BF54-150854595F34. The original photo data of the CT scans were deposited on Dryad (https://doi.org/https://doi.org/10.5061/dryad.4b8gthtq9).\n            AbbreviationsCT:\n                    Computed tomography\n                  Mya:\n                    Million years ago\n                  S2, S3, S4, S5, S6 and S7:\n                    Sternum 2, 3, 4, 5, 6 and 7\n                  T2, T3, T4, T5, T6, T7 and T8:\n                    Tergum 2, 3, 4, 5, 6, 7 and 8\n                  1st:\n                    First\n                  6th:\n                    Sixth\n                  7th:\n                    Seventh\n                  ReferencesStork NE. How many species of insects and other terrestrial arthropods are there on Earth? Annu Rev Entomol. 2018;63:31â€“45.Article\n    CAS\n    PubMed\n\n                    Google Scholar\n                Eggleton P. The state of the worldâ€™s insects. Annu Rev Env Resour. 2020;45:61â€“82.Article\n\n                    Google Scholar\n                Tihelka E, Cai CY, Giacomelli M, Lozano-Fernandez J, Rota-Stabelli O, Huang DY, et al. The evolution of insect biodiversity. Curr Biol. 2021;31:1299â€“311.Article\n\n                    Google Scholar\n                Wang B, Xu CP, Jarzembowski EA. Ecological radiations of insects in the Mesozoic. Trends Ecol Evol. 2022;37:529â€“40.Article\n    PubMed\n\n                    Google Scholar\n                Grimaldi DA, Engel MS. Evolution of the insects. New York: Cambridge University Press; 2005.\n                    Google Scholar\n                van de Kamp T, MikÃ³ I, Staniczek AH, Eggs B, Bajerlein D, FaragÃ³ T, et al. Evolution of flexible biting in hyperdiverse parasitoid wasps. P Roy Soc B-Biol Sci. 2022;289:20212086.\n                    Google Scholar\n                Lai DH, Chen PC, Li SM, Xiang XZ, Ou HH, Kang NY, et al. The associated evolution of raptorial foreleg and mantispid diversification during 200 million years. Natl Sci Rev. 2023;10:nwad278.Corbet PS. Dragonflies: Behaviour and Ecology of Odonata. New York: Cornell University Press; 1999.\n                    Google Scholar\n                Virla EG, Moya-Raygoza G, Guglielmino A. A review of the biology of the pincer wasps (Hymenoptera: Dryinidae). Austral Entomol. 2023;62:274â€“99.Article\n\n                    Google Scholar\n                Gronenberg W, Tautz J, HÃ¶lldobler B. Fast trap jaws and giant neurons in the ant Odontomachus. Science. 1993;262:561â€“3.Article\n    CAS\n    PubMed\n\n                    Google Scholar\n                Zompro O, Adis J, Weitschat W. A review of the order Mantophasmatodea (Insecta). Zool Anz. 2002;241:269â€“79.Article\n\n                    Google Scholar\n                Setty LR. Biology and morphology of some North American Bittacidae (Order Mecoptera). Am Midl Nat. 1940;23:257â€“353.Article\n\n                    Google Scholar\n                Grimaldi DA, Engel MS, Nascimbene PC. Fossiliferous Cretaceous amber from Myanmar (Burma): its rediscovery, biotic diversity, and paleontological significance. Am Mus Novit. 2002;3361:1â€“71.Article\n\n                    Google Scholar\n                Ross AJ. Complete checklist of Burmese (Myanmar) amber taxa 2023. Mesozoic. 2024;1:21â€“57.Article\n\n                    Google Scholar\n                Barden P, Perrichot V, Wang B. Specialized predation drives aberrant morphological integration and diversity in the earliest ants. Curr Biol. 2020;30:3818â€“24.Article\n    CAS\n    PubMed\n\n                    Google Scholar\n                Durak GM, Speck T, Poppinga S. Shapeshifting in the Venus flytrap (Dionaea muscipula): Morphological and biomechanical adaptations and the potential costs of a failed hunting cycle. Front Plant Sci. 2022;2:970320.Article\n\n                    Google Scholar\n                Cruickshank RD, Ko K. Geology of an amber locality in the Hukawng Valley, northern Myanmar. J Asian Earth Sci. 2003;21:441â€“55.Article\n\n                    Google Scholar\n                Shi GH, Grimaldi DA, Harlow GE, Wang J, Wang J, Yang MC, et al. Age constraint on Burmese amber based on U-Pb dating of zircons. Cretaceous Res. 2012;37:155â€“63.Article\n\n                    Google Scholar\n                Brothers DJ. A new Late Cretaceous family of Hymenoptera, and phylogeny of the Plumariidae and Chrysidoidea (Aculeata). Zookeys. 2011;130:515â€“42.Article\n\n                    Google Scholar\n                Evans HE. Discovery of the female Plumarius (Hymenoptera, Plumariidae). Psyche-J Entomol. 1967;73:229â€“37.Article\n\n                    Google Scholar\n                Brothers DJ. The first female Plumariidae (Hymenoptera: Chrysidea) from Southern Africa. XVII International Congress of Entomology, Hamburg, Abstracts. 1984;26.Engel MS, Grimaldi DA. Cretaceous Scolebythidae and phylogeny of the family (Hymenoptera: Chrysidoidea). Am Mus Novit. 2007;3568:1â€“16.Article\n\n                    Google Scholar\n                Lepeco A, Melo GAR. Revisiting the phylogeny of the scolebythid wasps (Hymenoptera: Aculeata) through Bayesian model evaluation and parsimony, with description of a new fossil family of Chrysidoidea. Zool J Linn Soc-Lond. 2024;201:57â€“85.Article\n\n                    Google Scholar\n                Melo GAR, Lucena DAA. â€ Chrysobythidae, a new family of chrysidoid wasps from Cretaceous Burmese amber (Hymenoptera, Aculeata). Hist Biol. 2020;32:1143â€“55.Article\n\n                    Google Scholar\n                Engel MS, Grimaldi DA. The first Cretaceous sclerogibbid wasp (Hymenoptera: Sclerogibbidae). Am Mus Novit. 2006;3515:1â€“7.Article\n\n                    Google Scholar\n                Bohart RM, Kimsey LS. A synopsis of the Chrysididae in America North of Mexico. Mem Amer Ent Inst. 1982;33:1â€“266.\n                    Google Scholar\n                Finnamore AT, Brothers DJ. Superfamily Chrysidoidea. In: Goulet H, Huber JT, editors. Hymenoptera of the World: an identification guide to families. Ottawa: Agriculture Canada; 1993. p. 130â€“60.\n                    Google Scholar\n                Kumpanenko A, Gladun D, Vilhelmsen L. Functional morphology and evolution of the sting sheaths in Aculeata (Hymenoptera). Arthropod Syst Phylo. 2019;77:325â€“38.\n                    Google Scholar\n                Brothers DJ, Finnamore AT. Superfamily Vespoidea. In: Goulet H, Huber JT, editors. Hymenoptera of the World: an identification guide to families. Ottawa: Agriculture Canada; 1993. p. 161â€“278.\n                    Google Scholar\n                Sharkey MJ. Phylogeny and classification of Hymenoptera. Zootaxa. 2007;1668:521â€“48.Article\n\n                    Google Scholar\n                Finnamore AT, Michener CD. Superfamily Apoidea. In: Goulet H, Huber JT, editors. Hymenoptera of the World: an identification guide to families. Ottawa: Agriculture Canada; 1993. p. 279â€“357.\n                    Google Scholar\n                Blaimer BB, Santos BF, Cruaud A, Gates MW, Kula RR, MikÃ³ I, et al. Key innovations and the diversification of Hymenoptera. Nat Commun. 2023;14:1212.Article\n    CAS\n    PubMed\n    PubMed Central\n\n                    Google Scholar\n                Zhang YM, Bossert S, Spasojevic T. Evolving perspectives in Hymenoptera systematics: bridging fossils and genomes across time. Syst Entomol. 2025;50:1â€“31.Article\n\n                    Google Scholar\n                Rasnitsyn AP, Brothers DJ. The first plumalexiid wasp (Hymenoptera: Chrysidoidea, Plumalexiidae) from the mid-Cretaceous Burmese amber. Cretaceous Res. 2020;115:104568.Article\n\n                    Google Scholar\n                Kochetkov DN, Loktionov VM. New and little known species of spider wasps (Hymenoptera: Pompilidae) from the Russian Far East. Far East Entomol. 2019;382:1â€“9.Article\n\n                    Google Scholar\n                Tu BB, Lelej AS, Chen XX. Review of the genus Cystomutilla AndrÃ©, 1896 (Hymenoptera: Mutillidae: Sphaeropthalminae: Sphaeropthalmini), with description of the new genus Hemutilla gen. nov. and four new species from China. Zootaxa. 2014;3889:71â€“91.Grimaldi DA. The Complete Insect: Anatomy, Physiology, Evolution, and Ecology. Princeton: Princeton University Press; 2023.Book\n\n                    Google Scholar\n                Escalante-Perez M, Scherzer S, Al-Rasheid KA, Dottinger C, Neher E, Hedrich R. Mechano-stimulation triggers turgor changes associated with trap closure in the Darwin plant Dionaea muscipula. Mol Plant. 2014;7:744â€“6.Article\n    CAS\n    PubMed\n\n                    Google Scholar\n                Ross AJ. Supplement to the Burmese (Myanmar) amber checklist and bibliography, 2024. Palaeoentomology. 2025;8:12â€“28.Article\n\n                    Google Scholar\n                Ponomarenko NG. Family Dryinidae (Dryinids). In: Medvedev GS, editor. Keys to the Insects of the European Part of the USSR. Moscow: Publications House Nauka; 1978. p. 16â€“27.\n                    Google Scholar\n                Rasnitsyn AP. Origin and Evolution of Hymenoptera. Trudy Paleontologicheskogo Instituta. 1980;174:1â€“192 ([In Russian]).\n                    Google Scholar\n                Limaye A. Drishti: a volume exploration and presentation tool. Proceedings of the SPIE. 2012;8506. https://doi.org/10.1117/12.935640.Brothers DJ. Phylogeny and classification of the aculeate Hymenoptera, with special reference to Mutillidae. Kans Univ Sci Bull. 1975;50:483â€“648.\n                    Google Scholar\n                Brothers DJ, Carpenter JM. Phylogeny of Aculeata: Chrysidoidea and Vespoidea (Hymenoptera). J Hymenopt Res. 1993;2:227â€“304.\n                    Google Scholar\n                Perrard A, Grimaldi DA, Carpenter JM. Early lineages of Vespidae (Hymenoptera) in Cretaceous amber. Syst Entomol. 2017;42:379â€“86.Article\n\n                    Google Scholar\n                Wu Q, Yang HR, Shih CK, Ren D, Zhao YY, Gao TP. Vespids from the mid-Cretaceous with club-shaped antennae provide new evidence about the intrafamiliar relationships of Vespidae. Zool J Linn Soc-Lond. 2020;193:217â€“29.Article\n\n                    Google Scholar\n                Vilhelmsen L. Head capsule characters in the Hymenoptera and their phylogenetic implications. ZooKeys. 2011;130:343â€“61.Article\n\n                    Google Scholar\n                Mason WRM. Key to superfamilies of HYMENOPTERA. In: Goulet H, Huber JT, editors. Hymenoptera of the World: an identification guide to families. Ottawa: Agriculture Canada; 1993. p. 65â€“100.\n                    Google Scholar\n                Lucena DAA, Melo GAR. Chrysidid wasps (Hymenoptera: Chrysididae) from Cretaceous Burmese amber: phylogenetic affinities and classification. Cretaceous Res. 2018;89:279â€“91.Article\n\n                    Google Scholar\n                Lucena DAA, Almeida EAB. Morphology and Bayesian tip-dating recover deep Cretaceous-age divergences among major chrysidid lineages (Hymenoptera: Chrysididae). Zool J Linn Soc-Lond. 2022;194:36â€“79.Article\n\n                    Google Scholar\n                Ronquist F, Teslenko M, Van Der Mark P, Ayres DL, Darling A, HÃ¶hna S, et al. MrBayes 3.2: Efficient bayesian phylogenetic inference and model choice across a large model space. Syst Biol. 2012;61:539â€“42.Rambaut A. FigTree. Computer software and documentation distributed by the author; 2013. http://tree.bio.ed.ac.uk/software/figtree/. Accessed March 1, 2025.Download referencesAcknowledgementsWe thank the editorial board of BMC Biology, and in particular Dr. Caitlyn Cardetti. We thank three anonymous reviewers for their valuable comments on this manuscript. We appreciate Ms. Xiaoran Zuo for the habitus reconstruction pictures and thanks Dr. Zhipeng Zhao for his help in discussion and the early CT construction of the specimens.FundingThis project was supported by a grant from the National Natural Science Foundation of China (Nos. 32470468, 32270467, 32020103006). The Support Project of High-level Teachers in Beijing Municipal Universities in the Period of 14th Fiveâ€“year Plan (No. BPHR20220114).Author informationAuthors and AffiliationsCollege of Life Sciences, Capital Normal University, Beijing, 100048, ChinaQiong Wu,Xiaoqin Li,Dong Ren&Taiping GaoNatural History Museum of Denmark, SCIENCE, University of Copenhagen, Universitetsparken 15, 2100, Copenhagen, DenmarkLars VilhelmsenBeijing Xiachong Amber Museum, 9 Shuanghe Middle Road, Beijing, 100023, ChinaDe ZhuoAuthorsQiong WuView author publicationsYou can also search for this author inPubMedGoogle ScholarLars VilhelmsenView author publicationsYou can also search for this author inPubMedGoogle ScholarXiaoqin LiView author publicationsYou can also search for this author inPubMedGoogle ScholarDe ZhuoView author publicationsYou can also search for this author inPubMedGoogle ScholarDong RenView author publicationsYou can also search for this author inPubMedGoogle ScholarTaiping GaoView author publicationsYou can also search for this author inPubMedGoogle ScholarContributionsTPG conceived and designed the experiments. QW, LV, XQL, DZ, DR, and TPG performed the analyses and experiments. QW prepared photographs and line drawings. QW, LV, and TPG wrote the manuscript. All authors read and approved the final manuscript.Corresponding authorCorrespondence to\n                Taiping Gao.Ethics declarations\n\n                Ethics approval and consent to participate\n                Not applicable.\n\n                Consent for publication\n                Not applicable.\n\n                Competing interests\n                The authors declare no competing interests.\n\n            Additional informationPublisherâ€™s NoteSpringer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.Supplementary Information12915_2025_2190_MOESM1_ESM.docAdditional file 1:Figures S1â€“S17, Dataset S1â€“S3. Fig. S1 Photographs of â€ Sirenobethyluscharybdis sp. nov., holotypefemale. Fig. S2 Photographs of â€ Sirenobethyluscharybdis sp. nov., paratypefemale. Fig. S3 Photographs of â€ Sirenobethyluscharybdis sp. nov., paratypefemale. Fig. S4 Photographs of â€ Sirenobethyluscharybdis sp. nov., paratypefemale. Fig. S5 Photographs of â€ Sirenobethyluscharybdis sp. nov., paratypefemale. Fig. S6 Photographs of â€ Sirenobethyluscharybdis sp. nov., paratypefemale. Fig. S7 Photographs of â€ Sirenobethyluscharybdis sp. nov., paratypefemale. Fig. S8 Photographs of â€ Sirenobethyluscharybdis sp. nov., paratypefemale. Fig. S9 Photographs of â€ Sirenobethyluscharybdis sp. nov., paratypefemale. Fig. S10 Photographs of â€ Sirenobethyluscharybdis sp. nov., paratypefemale. Fig. S11 Photographs of â€ Sirenobethyluscharybdis sp. nov., paratypefemale. Fig. S12 Photographs of â€ Sirenobethyluscharybdis sp. nov., paratypefemale. Fig. S13 Photographs of â€ Sirenobethyluscharybdis sp. nov., paratypefemale. Fig. S14 Photographs of â€ Sirenobethyluscharybdis sp. nov., paratypefemale. Fig. S15 Photographs of â€ Sirenobethyluscharybdis sp. nov., paratypefemale. Fig. S16 Photographs of â€ Sirenobethyluscharybdis sp. nov., paratypefemale. Fig. S17 Halfcompat tree based on morphological characters in Bayesian analyses. Dataset S1. Systematic paleontology. Dataset S2. Phylogenetic analysis. Dataset S3. Morphological characters list.Additional file 2:Table S1. Body structure measurements of all specimens.Additional file 3:Table S2. The character-state matrix.Additional file 4:Video S1. CT scan of the lateral of the abdomen.Additional file 5:Video S2. CT scan of the dorsal of the abdomen.Rights and permissions\n                Open Access  This article is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License, which permits any non-commercial use, sharing, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if you modified the licensed material. You do not have permission under this licence to share adapted material derived from this article or parts of it. The images or other third party material in this article are included in the articleâ€™s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the articleâ€™s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by-nc-nd/4.0/.\n              Reprints and permissionsAbout this articleCite this articleWu, Q., Vilhelmsen, L., Li, X. et al. A cretaceous fly trap? remarkable abdominal modification in a fossil wasp.\n                    BMC Biol 23, 81 (2025). https://doi.org/10.1186/s12915-025-02190-2Download citationReceived: 04 December 2024Accepted: 08 March 2025Published: 27 March 2025DOI: https://doi.org/10.1186/s12915-025-02190-2Share this articleAnyone you share the following link with will be able to read this content:Get shareable linkSorry, a shareable link is not currently available for this article.Copy to clipboard\n                            Provided by the Springer Nature SharedIt content-sharing initiative\n                        KeywordsSirenobethylidaeChrysidoideaMorphologyGrasping apparatusPhylogeny",
    "summary": {
      "en": "**Summary:**\n\nA new genus of fossil wasp named **Sirenobethylus charybdis** has been discovered in mid-Cretaceous amber from Myanmar, dating back 99 million years. This wasp exhibits unique modifications at the tip of its abdomen, which feature three flaps that may function as a grasping mechanism, resembling a Venus flytrap. This adaptation is thought to help the wasp temporarily immobilize its hosts during oviposition (laying eggs). \n\nThe findings suggest that the family **Sirenobethylidae**, to which this wasp belongs, represents an early branch of the **Chrysidoidea** superfamily, indicating a broader range of parasitoid strategies in Cretaceous insects compared to those observed today. The study highlights the diversity of insect predation methods and provides insights into the evolution of wasp morphology and behavior. \n\nOverall, **Sirenobethylus** is believed to have been a koinobiont parasitoid, using its specialized abdomen to capture and hold hosts for laying eggs. This discovery contributes to our understanding of insect evolution and the ecological roles of ancient wasps.",
      "ko": "ë¯¸ì–€ë§ˆì˜ ì¤‘ìƒëŒ€ í¬ë ˆíƒ€ê¸°ì—ì„œ ë°œê²¬ëœ 9,900ë§Œ ë…„ ëœ í˜¸ë°•ì—ì„œ ìƒˆë¡œìš´ í™”ì„ ë§ë²Œ ì†ì¸ **Sirenobethylus charybdis**ê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ ë§ë²Œì€ ë³µë¶€ ëë¶€ë¶„ì— ë…íŠ¹í•œ êµ¬ì¡°ë¥¼ ê°€ì§€ê³  ìˆìœ¼ë©°, ì„¸ ê°œì˜ í”Œë©ì´ ìˆì–´ ì´ë¥¼ í†µí•´ ë¬¼ì²´ë¥¼ ì¡ëŠ” ê¸°ëŠ¥ì„ í•  ìˆ˜ ìˆì„ ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤. ì´ êµ¬ì¡°ëŠ” ì‹ì¶©ì‹ë¬¼ì¸ ë¹„ë„ˆìŠ¤ í”Œë¼ì´íŠ¸ë©ê³¼ ìœ ì‚¬í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ì ì‘ì€ ë§ë²Œì´ ì•Œì„ ë‚³ì„ ë•Œ ìˆ™ì£¼ë¥¼ ì¼ì‹œì ìœ¼ë¡œ immobilizeí•˜ëŠ” ë° ë„ì›€ì´ ë˜ëŠ” ê²ƒìœ¼ë¡œ ìƒê°ë©ë‹ˆë‹¤.\n\nì´ ì—°êµ¬ ê²°ê³¼ëŠ” ì´ ë§ë²Œì´ ì†í•œ **Sirenobethylidae** ê°€ì¡±ì´ **Chrysidoidea** ì´ˆê³¼ì¡±ì˜ ì´ˆê¸° ë¶„ê¸°ë¥¼ ë‚˜íƒ€ë‚´ë©°, í¬ë ˆíƒ€ê¸° ê³¤ì¶©ì—ì„œ í˜„ì¬ ê´€ì°°ë˜ëŠ” ê²ƒë³´ë‹¤ ë” ë‹¤ì–‘í•œ ê¸°ìƒ ì „ëµì´ ì¡´ì¬í–ˆìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” ê³¤ì¶©ì˜ í¬ì‹ ë°©ë²•ì˜ ë‹¤ì–‘ì„±ì„ ê°•ì¡°í•˜ê³ , ë§ë²Œì˜ í˜•íƒœì™€ í–‰ë™ì˜ ì§„í™”ì— ëŒ€í•œ í†µì°°ì„ ì œê³µí•©ë‹ˆë‹¤.\n\nì „ë°˜ì ìœ¼ë¡œ **Sirenobethylus**ëŠ” ìˆ™ì£¼ë¥¼ ì¡ì•„ ì•Œì„ ë‚³ê¸° ìœ„í•´ íŠ¹ìˆ˜í•œ ë³µë¶€ë¥¼ ì‚¬ìš©í•˜ëŠ” ì½”ì´ë…¸ë¹„ì˜¨íŠ¸ ê¸°ìƒì¶©ìœ¼ë¡œ ì—¬ê²¨ì§‘ë‹ˆë‹¤. ì´ ë°œê²¬ì€ ê³¤ì¶© ì§„í™”ì™€ ê³ ëŒ€ ë§ë²Œì˜ ìƒíƒœì  ì—­í• ì— ëŒ€í•œ ì´í•´ë¥¼ ë†’ì´ëŠ” ë° ê¸°ì—¬í•©ë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "a5bb7b71df5c21ed",
    "title": {
      "en": "Cross-Platform P2P Wi-Fi: How the EU Killed AWDL",
      "ko": "EUê°€ AWDLë¥¼ ì£½ì˜€ë‹¤: í¬ë¡œìŠ¤ í”Œë«í¼ P2P Wi-Fi",
      "ja": null
    },
    "type": "story",
    "url": "https://www.ditto.com/blog/cross-platform-p2p-wi-fi-how-the-eu-killed-awdl",
    "score": 158,
    "by": "stusmall",
    "time": 1743167584,
    "content": "Published OnMarch 28, 2025March 28, 2025Cross-Platform P2P Wi-Fi: How the EU Killed AWDLThis post investigates how we got from Wi-Fi Direct to AWDL to Wi-Fi Aware, what makes Wi-Fi Aware technically superior, and why this shift unlocks true cross-platform peer-to-peer connectivity for developers.Adam FishFounder and CEO\n\npre {\n\t\t--theme--background: var(--core--100);\n    --theme--border: var(--swatch--light-faded);\n    --theme--border-fill: var(--core--100);\n    --theme--text: var(--core--800);\n    --theme--text-secondary: var(--core--400);\n\t\t--pre-text-main: var(--theme--text);\n    --pre-text-comment: color-mix(in srgb, var(--theme--text) 40%, transparent);\n    --pre-text-string: hsl(95, 38%, 62%);\n    --pre-text-keyword: hsl(286, 60%, 67%);\n    --pre-text-number: color-mix(in srgb, var(--theme--text) 60%, transparent);\n    --pre-text-attribute: color-mix(in srgb, var(--theme--text) 60%, transparent);\n    font-family: var(--eyebrow--font-family);\n    font-size: var(--text-main--font-size);\n    line-height: 1.5;\n    font-weight: var(--eyebrow--font-weight);\n    letter-spacing: var(--eyebrow--letter-spacing);\n    margin: 3em 0 !important;\n}\n\npre:has(code.hljs), pre {\n    overflow: clip;\n    padding: 0.75em !important;\n    background-color: var(--theme--background) !important;\n    white-space: pre-wrap;\n    color: var(--pre-text-main);\n}\n\npre code.hljs, pre code {\n    display: block;\n    overflow: auto;\n    height: 100%;\n    font-size: .875em;\n    font-family: var(--eyebrow--font-family);\n    font-weight: var(--eyebrow--font-weight);\n    letter-spacing: var(--eyebrow--letter-spacing);\n    padding: 0.875em;\n    color: var(--pre-text-main) !important;\n}\n\npre code::selection,\npre code span::selection {\n  background: color-mix(in srgb, var(--theme--text) 10%, transparent);\n}\n\npre code::-webkit-scrollbar {\n  width: 4px;\n  height: 4px;\n}\n\npre code::-webkit-scrollbar-corner {\n  background: rgba(0,0,0,0);\n  display: none;\n}\n\npre code::-webkit-scrollbar-track {\n  background: transparent;\n  padding: 2px;\n}\n\npre code::-webkit-scrollbar-thumb {\n  background-color: color-mix(in srgb, var(--theme--text) 25%, transparent);\n  border-radius: 999px;\n}\n\npre code::-webkit-scrollbar-thumb:hover {\n  background-color: color-mix(in srgb, var(--theme--text) 25%, transparent)\n}\n\n.hljs {\n    background: transparent;\n    color: var(--pre-text-main);\n}\n\n.hljs-ln-n {\n\topacity: 0.4;\n  font-family: var(--eyebrow--font-family);\n  font-weight: var(--eyebrow--font-weight);\n}\n\n.hljs-comment,\n.hljs-quote {\n    color: var(--pre-text-comment);\n    font-family: var(--eyebrow--font-family);\n    font-weight: var(--eyebrow--font-weight);\n}\n\n.hljs-deletion,\n.hljs-name,\n.hljs-regexp,\n.hljs-selector-class,\n.hljs-selector-id,\n.hljs-tag,\n.hljs-template-variable,\n.hljs-variable {\n    color: #ffa07a;\n    font-family: var(--eyebrow--font-family);\n    font-weight: var(--eyebrow--font-weight);\n}\n\n.hljs-built_in,\n.hljs-link,\n.hljs-literal,\n.hljs-meta,\n.hljs-number,\n.hljs-params,\n.hljs-type {\n    color: var(--pre-text-number);\n    font-family: var(--eyebrow--font-family);\n    font-weight: var(--eyebrow--font-weight);\n}\n\n.hljs-attribute {\n    color: var(--pre-text-attribute);\n    font-family: var(--eyebrow--font-family);\n    font-weight: var(--eyebrow--font-weight);\n}\n\n.hljs-addition,\n.hljs-bullet,\n.hljs-string,\n.hljs-symbol {\n    color: var(--pre-text-string);\n}\n\n.hljs-section,\n.hljs-title {\n    color: #F37243;\n    font-family: var(--eyebrow--font-family);\n    font-weight: var(--eyebrow--font-weight);\n}\n\n.hljs-keyword,\n.hljs-selector-tag {\n    color: var(--pre-text-keyword);\n    font-family: var(--eyebrow--font-family);\n    font-weight: var(--eyebrow--font-weight);\n}\n\n.hljs-emphasis {\n    font-style: italic\n}\n\n.hljs-strong {\n    font-weight: 700;\n    font-family: var(--eyebrow--font-family);\n}\n\n@media screen and (-ms-high-contrast:active) {\n\n    .hljs-addition,\n    .hljs-attribute,\n    .hljs-built_in,\n    .hljs-bullet,\n    .hljs-comment,\n    .hljs-link,\n    .hljs-literal,\n    .hljs-meta,\n    .hljs-number,\n    .hljs-params,\n    .hljs-quote,\n    .hljs-string,\n    .hljs-symbol,\n    .hljs-type {\n        color: highlight\n    }\n\n    .hljs-keyword,\n    .hljs-selector-tag {\n        font-weight: 700\n    }\n}\nTL;DR: Under pressure from the EUâ€™s Digital Markets Act (DMA), Apple is being forced to ditch its proprietary peer-to-peer Wi-Fi protocol â€“ Apple Wireless Direct Link (AWDL) â€“ in favor of the industry-standard Wi-Fi Aware, also known as Neighbor Awareness Networking (NAN). A quietly published EU interoperability roadmap mandates Apple support Wi-Fi Aware 4.0 in iOS 19 and v5.0,1 thereafter, essentially forcing AWDL into retirement. This post investigates how we got here (from Wi-Fi Direct to AWDL to Wi-Fi Aware), what makes Wi-Fi Aware technically superior, and why this shift unlocks true cross-platform peer-to-peer connectivity for developers.EU Forces Appleâ€™s Hand on Peer-to-Peer Wi-FiIn a little-publicized mandate, the European Commission explicitly requires Apple to implement the Wi-Fi Allianceâ€™s Wi-Fi Aware standard as part of DMA interoperability measures. The official DMA roadmap states:â€œApple shall implement the measures for Wi-Fi Aware 4.0 in the next major iOS release, i.e. iOS 19, at the latest, and for Wi-Fi Aware 5.0 in the next iOS release at the latest nine months following the introduction of the Wi-Fi Aware 5.0 specificationâ€In plain terms, by the time iOS 19 ships, iPhones must support Wi-Fi Aware v4.0, and Apple must roll out v5.0 support soon after the Wi-Fi Alliance finalizes that spec.Crucially, this decision was not a voluntary announcement by Apple â€“ it was imposed by regulators. Apple has kept quiet about these changes publicly, likely because they involve opening up formerly closed-off tech. The DMA enforcement timeline was highlighted in an EU Q&A site and legal annex, not an Apple press release.7 The European Commissionâ€™s language makes it clear this is about enabling third-party devices and apps to use high-bandwidth peer-to-peer (P2P) Wi-Fi features equal to Appleâ€™s own, rather than Apple benevolently adopting a new standard. In fact, the EU order compels Apple to deprecate AWDL and ensure third-party solutions using Wi-Fi Aware are just as effective as Appleâ€™s internal protocols. In short, the EU gave Apple no choice: embrace Wi-Fi Aware or face penalties.What does this mean? Essentially, Appleâ€™s hidden sauce for fast device-to-device communication â€“ AWDL â€“ is being forced into retirement. And with that, for the first time, iPhones and Androids will speak a common language for local wireless networking. Letâ€™s unpack how we got here, and why itâ€™s a big deal for developers.From Wi-Fi Direct to AWDL to Wi-Fi Aware: A Brief HistoryTo understand the significance, we need a quick history of ad-hoc Wi-Fi protocols:Wi-Fi Ad-hoc (IBSS mode): Early 802.11 allowed devices to connect directly in a peer-to-peer â€œad-hocâ€ network (IBSS), but it had limitations (no always-on discovery, no power-saving coordination, weak security). It never gained widespread use.Wi-Fi Direct: The Wi-Fi Allianceâ€™s first big attempt at standard P2P. Wi-Fi Direct (circa 2010) allows devices to form a direct link without an AP, designating one device as a group owner (soft AP) for security and IP allocation. It improved on ad-hoc mode (supporting WPA2, dynamic group formation), but had drawbacks â€“ e.g. limited service discovery capabilities and difficulty staying connected to infrastructure Wi-Fi concurrently.Apple Wireless Direct Link (AWDL): Around 2014, Apple developed AWDL as a proprietary, high-performance P2P Wi-Fi protocol for its ecosystem. According to Appleâ€™s patent on AWDL (US20180083858A1) and reverse-engineering by researchers, AWDL was designed to address Wi-Fi Directâ€™s concerns and succeeded ad-hoc IBSS mode.8 Apple deployed AWDL in over a billion devices (every modern iPhone, iPad, Mac) to power AirDrop, AirPlay peer connections, GameKit, Apple Watch unlock, and more.8,9 Notably, AWDL can coexist with regular Wi-Fi by rapidly hopping channels â€“ an iPhone can be on an AP and seamlessly switch to AWDL channel windows to talk to a peer.9 This gave AWDL low latency and high throughput without dropping your internet connection.Neighbor Awareness Networking (NAN / Wi-Fi Aware): As it turns out, Apple didnâ€™t keep all of AWDL to itself â€“ it contributed to the Wi-Fi Alliance, which adopted AWDLâ€™s approach as the basis for the NAN standard (branded â€œWi-Fi Awareâ€) around 2015.8 Wi-Fi Aware is essentially the industry-standard cousin of AWDL, enabling devices to discover each other and communicate directly with Wi-Fi speeds, in a power-efficient way, regardless of vendor. Android added platform support for Wi-Fi Aware in Oreo (8.0) and later,10 but Apple until now stuck with its in-house AWDL stack which can be used by developers but isn't an open standard.In summary, AWDL was Appleâ€™s competitive edge â€“ a proprietary P2P stack that outperformed legacy Wi-Fi Direct and only worked on Apple devices. If an app needed cross-platform local connectivity, it couldnâ€™t use AWDL (Apple provides no raw AWDL API). Developers resorted to Wi-Fi Direct, or Wi-Fi Aware on Android vs. Appleâ€™s AWDL on iOS, with no interoperability. This fragmentation is exactly what the EUâ€™s DMA targeted.The DMA order effectively forces Apple to drop AWDL and align with Wi-Fi Aware. The Commission explicitly says Apple mustâ€œimplement Wi-Fi Aware in iOS devices in accordance with the Wi-Fi Aware specificationâ€ and â€œcontinue toâ€¦improve the Wi-Fi Aware standardâ€¦ Apple shall not prevent AWDL from becoming part of the Wi-Fi Aware standardâ€,even urging Apple to allocate memory for concurrent P2P on older devices in a non-discriminatory way until AWDL is fully deprecated.The writing is on the wall: AWDL as a private protocol is done for.Inside AWDL: Appleâ€™s Once-Secret Peer-to-Peer ProtocolAWDL is worth a closer look, because it shows what Apple achieved and what will now be opened up via Wi-Fi Aware. How does AWDL work? In short, it creates a continuously syncing ad-hoc network on the fly among nearby Apple devices:Availability Windows & Channel Hopping: Each AWDL-enabled device periodically advertises Availability Windows (AWs) â€“ tiny time slices when itâ€™s available on a specific Wi-Fi channel for peer-to-peer communication.8 An elected master node (chosen via a priority scheme) coordinates these windows across devices. Outside of these AWs, devices can rejoin normal Wi-Fi (e.g. your home routerâ€™s channel) or sleep their radio to save power.8 This scheduling is what allows, let's say, your Mac to be on Wi-Fi for internet most of the time, but briefly switch to channel 6 to AirDrop a file from your iPhone, then switch back â€“ all without manual intervention.Integration with BLE: AWDL doesnâ€™t work in isolation â€“ it integrates with Bluetooth Low Energy for discovery. For example, AirDrop uses BLE advertisements to initially discover nearby devices (showing them in the UI), then quickly forms an AWDL connection for the actual high-speed file transfer. This combo gives the best of both: BLEâ€™s low-power device discovery and AWDLâ€™s high-throughput data channel.11,12Performance: AWDL leverages the full Wi-Fi PHY, so it can hit hundreds of Mbps throughput and sub-second latencies that BLE or classic Bluetooth canâ€™t touch. It also supports robust security (authenticated pairing, encryption) as used in AirDrop/AirPlay. One clever feature: because AWDL devices coordinate their availability, one device can even sustain multiple P2P links concurrently (e.g. an iPhone streaming to a HomePod via AWDL while also AirDropping to a Mac) â€“ something spelled out in the EU requirements.Closed Nature: Despite its capabilities, AWDL has been closed off to third-party developers and other OSes. Appleâ€™s APIs like MultipeerConnectivity framework ride on AWDL under the hood for Apple-to-Apple connections, but there was no way for an Android device or a Windows laptop to speak AWDL. It was an Apple-only club. Researchers at TU Darmstadtâ€™s Secure Mobile Networking Lab had to reverse-engineer AWDL (publishing an open Linux implementation called OWL) to document its inner workings.13 They demonstrated that AWDL indeed is an IEEE 802.11-based ad-hoc protocol with Apple-specific extensions, tightly integrated with Appleâ€™s ecosystem.14 Bottom line: AWDL gave Apple a technical edge but at the cost of interoperability â€“ a classic â€œwalled gardenâ€ approach.Itâ€™s this walled garden that the EU is breaking down. The mandate that â€œApple shall make Wi-Fi Aware available to third partiesâ€ means Apple must expose new iOS APIs for P2P connectivity that are standard-based. And since Android (and even some IoT devices) already support Wi-Fi Aware, weâ€™re headed for a world where an iPhone and an Android phone can find and connect to each other directly via Wi-Fi, no access point, no cloud, no hacks â€“ a scenario that AWDL alone never allowed.Wi-Fi Aware 4.0: The New Cross-Platform StandardSo what exactly is Wi-Fi Aware (a.k.a. NAN), and why is version 4.0 a game-changer? At a high level, Wi-Fi Aware offers the same kind of capabilities as AWDL, but as an open standard for any vendor. It lets devices discover each other and exchange data directly via Wi-Fi, without needing a router or cell service. Think of it as Wi-Fiâ€™s answer to Bluetooth discovery but with Wi-Fi speed and range. Some key technical features of Wi-Fi Aware (especially in the latest v4.0 spec) include:Continuous, Efficient Discovery: Devices form a Wi-Fi Aware group and synchronize wake-up times to transmit Discovery Beacons. Like AWDLâ€™s AWs, Wi-Fi Aware defines Discovery Windows where devices are active to find peers, then can sleep outside those windows to save power. This allows always-on background discovery with minimal battery impact.15 The latest spec enhances this with an â€œInstant Communicationâ€ mode â€“ a device can temporarily accelerate discovery (e.g. switch to a channel and beacon rapidly) when triggered by an external event like a BLE advertisement or NFC tap, to achieve very fast discovery and connection setup.16 In practice, that means an app can use BLE to wake up Wi-Fi (advertising a service via BLE then negotiating a NAN link), combining the energy efficiency of BLE with the speed of Wi-Fi â€“ just as Appleâ€™s AirDrop has done privately. Wi-Fi Aware v4.0 explicitly added standardized BLE co-operation: â€œLatest enhancements to Wi-Fi Aware offer discovery by Bluetooth LE, which triggers a formal Wi-Fi Aware session by waking the Wi-Fi radio.â€10High Throughput Data & Range: Once devices discover each other, Wi-Fi Aware supports establishing a direct Wi-Fi data path. This can be an IP connection or a native transport, and it leverages Wi-Fiâ€™s high data rates (including Wi-Fi 5/6/6E speeds on 5 GHz or 6 GHz bands). In fact, the Wi-Fi Alliance notes that Wi-Fi Aware data connections use â€œhigh performance data rates and security, leveraging cutting-edge Wi-Fi technologies, including Wi-Fi 6, Wi-Fi 6E, and WPA3.â€ 10 Compared to Bluetooth or BLE, the throughput and range are vastly superior â€“ Wi-Fi Aware can work at typical Wi-Fi ranges (tens of meters, even over 100m in open air) and deliver tens or hundreds of Mbps. By contrast, BLE might get 100+ meters but on the order of 0.1 Mbps in real-world throughput. Wi-Fi Aware will close that gap by giving cross-platform apps both long range and high speed.Lower Latency & Instant Communication: Version 4.0 of the spec introduced refinements for latency-critical applications. The aforementioned Instant Communication mode lets devices expedite the discovery handshake â€“ important for use cases like AR gaming or urgent data sync where waiting a few seconds for a discovery window might be too slow. In Instant mode, a device (say, an AR headset) triggered via BLE could immediately switch to a predetermined channel and begin a quick service discovery exchange with a peer, rather than strictly waiting on the periodic timetable.16 The spec shows this can cut discovery latency dramatically (Figure 73 in the spec illustrates an accelerated discovery).16 From a developerâ€™s perspective, Wi-Fi Aware can feel nearly instantaneous in establishing a link when properly used.Accurate Ranging: Perhaps one of the most exciting features for version 4 and beyond is built-in distance measurement between devices. Wi-Fi Aware includes a ranging protocol (based on Fine Timing Measurement, FTM) that lets one device get the distance to another with sub-meter accuracy.15 This is similar to how Apple devices can use UWB or Bluetooth RTT for ranging, but now via Wi-Fi. The devices exchange precise timing signals to calculate distance (and even do so as part of discovery â€“ a NAN discovery packet can include a request to measure range). The specâ€™s NAN Ranging section defines how devices negotiate a ranging session and obtain a distance estimate before or during data exchange.16 Enhanced ranging could unlock things like peer-to-peer localization (for example, an app can find not just who is nearby but also roughly how far or even what direction).Security and Privacy: Wi-Fi Aware has baked-in solutions for secure communication and privacy. It supports device pairing (establishing trust and keys) and encrypted data paths with mutual authentication.15 It also provides privacy features like randomized identifiers that rotate, so devices arenâ€™t broadcasting a fixed MAC or identity constantly.10 This addresses the concern that always-on discovery could be used to track devices â€“ Aware can randomize its â€œNAN IDsâ€ and only reveal a stable identity when a trusted handshake occurs. The EU mandate will require Apple to expose the same security levels to third-party developers as it uses for its own devices, meaning things like AirDropâ€™s peer authentication should extend to third-party Aware sessions.In essence, Wi-Fi Aware 4.0 is AWDL on steroids and open to all. It took the concepts Apple pioneered (timeslot synchronization, dual Wi-Fi/BLE use, etc.) and formalized them into a cross-vendor standard, adding improvements along the way. No longer limited to Apple devices, any Wi-Fi Aware certified device can join the discovery clusters and connect. With iOS 19, an iPhone will become just another Wi-Fi Aware node â€“ able to discover and connect to Android phones, PCs, IoT gadgets, etc., directly via Wi-Fi.AWDL vs. Wi-Fi Aware vs. BLE: Feature ComparisonHow does Appleâ€™s AWDL, the upcoming Wi-Fi Aware, and good old Bluetooth Low Energy stack up? The table below summarizes the key differences and capabilities of these peer-to-peer wireless technologies:\n.table_component {\n    overflow: auto;\n    width: 100%;\n}\n\n.table_component table {\n    border: 1px solid #dededf;\n    height: 100%;\n    width: 100%;\n    table-layout: fixed;\n    border-collapse: collapse;\n    border-spacing: 1px;\n    text-align: left;\n}\n\n.table_component caption {\n    caption-side: top;\n    text-align: left;\n}\n\n.table_component th {\n    border: 1px solid #dededf;\n    background-color: #eceff1;\n    color: #000000;\n    padding: 5px;\n}\n\n.table_component td {\n    border: 1px solid #dededf;\n    background-color: #ffffff;\n    color: #000000;\n    padding: 5px;\n}\n\n            Feature\n            Apple AWDL (Proprietary)\n            Wi-Fi Aware 4.0 (2022 Spec)\n            Bluetooth LE (5.x)\n\n            Standardization\n\n                Apple-defined (private protocol)\n\n                Wi-Fi Alliance NAN standard\n\n                Bluetooth SIG standard\n\n            Topology\n\n                Mesh networking. Multiple devices in a cluster. One acts as a time sync master.\n\n                Decentralized cluster (no fixed master). Typically one-to-one data links, but multiple links supported.\n\n                Point-to-point or star (one-to-many, each connection 1:1). No native mesh routing.\n\n                Discovery Mechanism\n\n                AWDL frames (Wi-Fi beacons), BLE-assisted initial discovery (e.g., AirDrop).\n\n                Publish/Subscribe discovery with NAN frames. Supports out-of-band BLE wake-up for power saving.\n\n            BLE Advertising channels, low-power continuous advertising, and scanning.\n\n                Initial Connection Latency\n\n                Very fast (<1s) using BLE assist (AirDrop). Quick AWDL link setup.\n\n                Fast (<1s typical) discovery, tens of ms connection setup after discovery.\n\n                Fast discovery (~0.5â€“1s). Connection establishment latency (50â€“100 ms).\n\n                Data Throughput\n\n                High â€“ 160â€“320 Mbps real-world (AirDrop). Wi-Fi 5/6 speeds.\n\n                High â€“ 100+ Mbps real-world on Wi-Fi 5 hardware, 250+ Mbps possible on Wi-Fi 6.\n\n                Low â€“ Max ~1.36 Mbps app throughput (BLE 5), typically 0.2â€“0.5 MB/s.\n\n            Range\n\n                ~50â€“100m typical Wi-Fi range. 100m+ line-of-sight.\n\n                ~50â€“100m typical Wi-Fi range, similar to AWDL.\n\n                Up to 100â€“200m typical; max ~1km line of sight with BLE 5 long-range (coded PHY).\n\n                Concurrent Internet\n\n                Yes â€“ simultaneous infrastructure Wi-Fi and P2P via channel hopping.\n\n            Yes â€“ NAN discovery windows are scheduled around AP connectivity. Coexistence supported.\n\n                Yes â€“ BLE separate from Wi-Fi, runs in parallel.\n\n                Notable Features\n\n                Proprietary; Powers AirDrop/AirPlay; Mesh with master; No direct public API (apps use Multipeer Connectivity).\n\n                Open standard; Flexible discovery; Instant messaging; Built-in secure data path setup; Android API since 2017.\n\n                Universally supported; Extremely energy-efficient; Background presence detection; Limited data rate. Often combined with Wi-Fi for bulk transfer.\n\n(Note: Above ranges and throughput are based on Dittoâ€™s real-world tests and specification data. Bluetooth 5's theoretical 4x range increase can reach ~400m line-of-sight, typical usable range 100â€“200m indoors. Wi-Fi range varies significantly with the environment.)As the table shows, Wi-Fi Aware (NAN) and AWDL are closely matched in capabilities â€“ no surprise, given their kinship. Both vastly outperform Bluetooth LE for high-bandwidth applications, though BLE remains invaluable for ultra-low-power needs and simple proximity detection. The sweet spot that AWDL and Aware occupy is: fast, local data exchange (from tens of megabits up to hundreds) over distances of a room or building floor, without requiring any network infrastructure. This is why forcing Apple to support Wi-Fi Aware is so pivotal â€“ it means an iPhone and an Android phone sitting next to each other can finally establish a fast, direct Wi-Fi link without an access point, something that was previously impossible (because the iPhone would only speak AWDL, and the Android only Wi-Fi Aware/Wi-Fi Direct). In effect, the EU is unifying the tableâ€™s middle column (â€œWi-Fi Awareâ€) across the industry, and pushing the proprietary AWDL column toward obsolescence.A Glimpse of Wi-Fi Aware 5.0 â€“ Whatâ€™s Next?The EU is already looking ahead to Wi-Fi Aware 5.0, mandating Apple support it when available. While v5.0 is still in the works, we can speculate based on industry trends and draft discussions:Better Interoperability & Backwards Compatibility: Each iteration of Aware aims to bring improvements while remaining backward compatible. v5.0 will likely fine-tune the interaction between different versions (e.g. allowing a v5 device to gracefully communicate with a v4 device at a slightly reduced feature set).Multi-Band and Wi-Fi 7 Enhancements: With Wi-Fi 7 (802.11be) emerging, v5.0 could incorporate support for Multi-Link Operation (MLO) â€“ allowing Aware devices to use multiple bands or channels simultaneously for P2P, increasing reliability and throughput. It might also embrace new PHY capabilities like 320 MHz channels in 6 GHz or even integration of the 60 GHz band for ultra-high throughput at short range. Imagine a future Aware where two devices use 6 GHz for discovery and 60 GHz for a quick gigabit data burst.Improved Ranging and Location: Wi-Fi Aware might leverage Wi-Fi 7â€™s improved location features or even integrate with UWB. v5.0 could offer finer distance measurement or angle-of-arrival info by coordinating multiple antennas, which would interest AR/VR use cases and precise indoor positioning.Extended Mesh Networking: Currently, Aware focuses on finding peers and setting up links; v5.0 might add more mesh networking primitives â€“ e.g., forwarding data through intermediate nodes or coordinating groups of devices more intelligently. This could turn clusters of phones into true mesh networks for group connectivity without infrastructure.Security Upgrades: Each version updates security. v5.0 will likely address any weaknesses found in v4, perhaps adding quantum-resistant encryption for pairing or tighter integration with device identity frameworks. Given Appleâ€™s emphasis on privacy, expect them to push for features that allow secure sharing of connection metadata with third parties without exposing user data.Weâ€™ll know for sure once the Wi-Fi Alliance releases the Wi-Fi Aware 5.0 spec, but the direction is clear: faster, farther, and more seamless peer-to-peer connectivity. And importantly, Apple will be on board from day one (not years late as it was with previous standards).Wi-Fi Aware in Action: Android Kotlin ExampleTo illustrate how developers can use Wi-Fi Aware, letâ€™s look at a simplified real-world example on Android. Below is Kotlin code demonstrating a device publishing a service and handling a message from a subscriber. (Androidâ€™s Wi-Fi Aware API is available from API level 26; one must have location and â€œNearby Wi-Fi Devicesâ€ permissions, and the device must support Aware.)val wifiAwareMgr = context.getSystemService(Context.WIFI_AWARE_SERVICE) as WifiAwareManager\n\nif (!wifiAwareMgr.isAvailable) {\n    Log.e(\"WiFiAwareDemo\", \"Wi-Fi Aware not available on this device.\")\n    return\n}\n\n// Attach to the Wi-Fi Aware service\nwifiAwareMgr.attach(object : AttachCallback() {\n    override fun onAttached(session: WifiAwareSession) {\n        // Once attached, we can publish or subscribe\n        val publishConfig = PublishConfig.Builder()\n            .setServiceName(\"com.example.p2pchat\")    // Name of our service\n            .build()\n\n        session.publish(publishConfig, object : DiscoverySessionCallback() {\n            override fun onPublishStarted(pubSession: PublishDiscoverySession) {\n                Log.i(\"WiFiAwareDemo\", \"Service published, ready for subscribers.\")\n            }\n\n            override fun onMessageReceived(\n                session: DiscoverySession,\n                peerHandle: PeerHandle,\n                message: ByteArray\n            ) {\n                val msgStr = String(message, Charsets.UTF_8)\n                Log.i(\"WiFiAwareDemo\", \"Received message from subscriber: $msgStr\")\n                // Here we could respond or establish a data path if needed\n            }\n        }, null)\n    }\n\n    override fun onAttachFailed() {\n        Log.e(\"WiFiAwareDemo\", \"Failed to attach to Wi-Fi Aware session.\")\n    }\n}, null)\nIn this code, the app attaches to the Wi-Fi Aware service, then publishes a service named \"com.example.p2pchat\". When a peer subscribes and sends us a message (for example, â€œHello from subscriberâ€), it arrives in onMessageReceived. A subscriber device would perform complementary steps: calling session.subscribe(...) with the same service name and implementing onServiceDiscovered to detect the publisher, then possibly using subscribeSession.sendMessage(peer, ...) to send that â€œHello.â€ At that point, either side could then use WifiAwareSession.createNetworkSpecifier() to set up an actual data path (network interface) for larger communication.The key takeaway is that Wi-Fi Aware makes peer discovery and messaging a first-class citizen in the API, abstracting away the low-level Wi-Fi fiddling. The app developer just provides a service name and gets callbacks when peers appear or messages arrive.(Note: The above is a minimal example. In a real app, youâ€™d handle permissions, check for support via PackageManager.FEATURE_WIFI_AWARE, and probably use the new NEARBY_WIFI_DEVICES permission on Android 13+. Also, establishing a full data path would involve requesting a Network from ConnectivityManager with a network specifier from the Aware session.)Immediately after Google announced Wi-Fi Aware in Android, we at Ditto realized its potential for seamless peer-to-peer sync. As shown above, you can certainly roll your own discovery and data exchange with Aware. However, not every developer will want to manage these details or deal with corner cases of connectivity. Thatâ€™s why Dittoâ€™s real-time sync SDK is integrating Wi-Fi Aware support out-of-the-box.Our upcoming releases will automatically use Wi-Fi Aware in iOS under the hood for nearby devices, enabling peer-to-peer database synchronization and binary file sharing between iOS and Android with zero configuration. In practical terms, if you build your app with Ditto, two devices in proximity will be able to find each other and sync data directly (bypassing cloud or LAN) using the fastest available transport â€“ now including Wi-Fi Aware alongside Bluetooth, AWDL, LAN, etc.Cross-platform, edge-first applications (collaborative apps, offline-first data stores, local IoT networks) will significantly benefit from this, as devices will form a local mesh that syncs instantly and reliably, even if the internet is down. Dittoâ€™s approach has always been to multiplex multiple transports (Wi-Fi infrastructure, P2P, BLE, etc.) for robustness; adding NAN support supercharges the bandwidth available for nearby sync sessions.A concrete example: Consider an app for first responders that shares maps and live sensor data among a team in the field. With Wi-Fi Aware, an Android tablet, an iPhone, and a specialized helmet device could all auto-discover each other and form a mesh to sync mission data in real-time without any network. Previously, if the iPhone had an app using AWDL, it couldnâ€™t directly connect to the Android tabletâ€™s Wi-Fi Aware session â€“ they were incompatible silos. Now, theyâ€™ll speak one language, making such scenarios truly feasible.Bigger Picture: The Dawn of True Cross-Platform Mesh NetworkingAppleâ€™s reluctant adoption of Wi-Fi Aware marks a pivot point for device connectivity. For years, weâ€™ve seen a split: Appleâ€™s ecosystem â€œJust Worksâ€ within itself (thanks to AWDL, AirDrop, etc.), while other platforms muddled along with standards that never quite matched the seamlessness or performance. That left cross-platform interactions hamstrung â€“ the experience of sharing something between an iPhone and an Android was far from instant or easy.With iOS supporting Wi-Fi Aware, weâ€™re essentially witnessing AWDL go open. The proprietary tech that powered some of Appleâ€™s most magical features will now be available in an interoperable way to any developer. The implications are significant:End of the Proprietary P2P Divide: No more need for parallel implementations. Developers wonâ€™t have to build one system using MultipeerConnectivity for iOS-to-iOS and another using Wi-Fi Aware or Wi-Fi Direct for Android-to-Android. They can use Wi-Fi Aware universally for nearby networking. This reduces development complexity and encourages building features that work on all devices, not just within one brand.Cross-Platform AirDrop and Beyond: We will likely see apps (or OS-level features) that enable AirDrop-like functionality between iOS and Android. Googleâ€™s Nearby Share and Samsungâ€™s Quick Share could potentially become interoperable with Appleâ€™s implementation now that the underlying protocol is shared. The user experience barrier between ecosystems could start to blur in local sharing scenarios.Mesh and Edge Computing Potential: If many devices can seamlessly form ad-hoc networks, this enables new paradigms in edge computing. Clusters of phones could share workload or content directly. For example, at a conference, a presenterâ€™s laptop could broadcast slides via Wi-Fi Aware to all audience phones without internet. Or a fleet of drones could coordinate via Aware when out of range of a base station. The offline mesh becomes a first-class citizen.Competitive Innovation: The EUâ€™s push here also sets a precedent â€“ even giants like Apple must conform to interoperability on critical features. This may drive Apple (and others) to innovate on top of the standards rather than via proprietary lock-in. We might see Apple contribute more actively to Wi-Fi Awareâ€™s future improvements (as required by the DMA) to ensure it meets their needs for things like AR/VR data streams. That collaboration could yield better tech for everyone, faster.One canâ€™t ignore the irony that the Wi-Fi Aware standard is effectively a child of AWDL. Now the child comes back to replace its parent. From a technical perspective, this is a win for engineering elegance â€“ itâ€™s always cleaner to have one agreed-upon protocol rather than parallel ones. From a developer perspective, itâ€™s a huge win for interoperability and user reach.Apple will undoubtedly ensure that the transition doesnâ€™t degrade the experience for Apple-to-Apple interactions; the DMA even mandates that third-party access be â€œequally effectiveâ€ as Appleâ€™s own solutions. That means as developers, we should expect the new iOS 19 Wi-Fi Aware APIs to give us essentially what AWDL gave Appleâ€™s apps. Itâ€™s like being handed the keys to a supercar that was previously locked in Appleâ€™s garage.ConclusionThe EUâ€™s crackdown on Appleâ€™s closed ecosystems is catalyzing a long-awaited unification in short-range wireless technology. By compelling Apple to adopt Wi-Fi Aware, the Digital Markets Act is effectively forcing the end of AWDL as an exclusive domain. For developers and users, this is exciting news: soon your apps will be able to use high-speed peer-to-peer Wi-Fi on iPhones and have it talk to other platforms seamlessly. Weâ€™ll likely see an explosion of innovative uses for local connectivity â€“ from truly universal AirDrop alternatives to cross-platform local multiplayer games, ad-hoc collaborative editing, IoT device commissioning, and beyond â€“ no specialized hardware or router required.At a technical level, AWDL will be remembered as an ahead-of-its-time solution that proved what was possible, and Wi-Fi Aware ensures those capabilities are broadly available as an industry standard. With Wi-Fi Aware 4.0 on the cusp of ubiquity (and 5.0 on the horizon), we are entering a new era of frictionless sharing and syncing among devices in physical proximity. Itâ€™s a win for interoperability and a win for innovation in peer-to-peer networking. The walls around AWDL are coming down â€“ and the implications for edge computing and offline experiences are profound.â€Sources:[1] European Commission â€“ DMA Decisions on Apple Interoperability (Q&A) â€“ High-bandwidth P2P Wi-Fi (Wi-Fi Aware 4.0 in iOS 19, Wi-Fi Aware 5.0 next). (2025) (Interoperability - European Commission)[2] The Apple Wiki â€“ Apple Wireless Direct Link (AWDL) â€“ Proprietary mesh protocol introduced in iOS 7 (2014) for AirDrop/Continuity. (Apple Wireless Direct Link - The Apple Wiki) (Apple Wireless Direct Link - The Apple Wiki)[3] ZDNet â€“ Appleâ€™s AWDL protocol plagued by flawsâ€¦ â€“ Research note: â€œNAN (Wi-Fi Aware) is a new standard supported by Android which draws on AWDLâ€™s design.â€ (Nov 2019) (Apple's AWDL protocol plagued by flaws that enable tracking and MitM attacks | ZDNET)[4] Android AOSP Documentation â€“ Wi-Fi Aware feature (Neighbor Awareness Networking) â€“ Added in Android 8.0; supports discovery, connection, and ranging (added in Android 9). (Wi-Fi Aware | Android Open Source Project)[5] Nordic Semiconductor â€“ Bluetooth Range Compared â€“ Bluetooth 5 LE offers up to ~400 m range (4Ã— vs BLE4), 2 Mbps PHY, ~1.36 Mbps application throughput. (Things You Should Know About Bluetooth Range)[6] Computerworld â€“ Coming soon: Faster, longer-range Bluetooth 5 â€“ â€œIn clear line of sight, Bluetooth 5 range could stretch to 400 meters,â€ (2016)[7] BGR -- iOS 19 Features Coming to EU -- Details new features for EU iPhones including high-bandwidth P2P Wi-Fi, sideloading, and alternative app stores (March 2025) (8 Exclusive iOS 19 Features Coming to EU iPhone Users)[8] Open Wireless Link Wiki - What is Apple Wireless Direct Link (AWDL) -- Appleâ€™s patent on AWDL (US201800838) and origins as a successor to Wi-FI IBSS (Wiki | Open Wireless Link)[9] CyberHoot â€“ Apple Wireless Direct Link (AWDL) â€“ Apple deployed AWDL in over billion devices to power AirDrop, AirPlay peer Connections, and more (2002) (Apple Wireless Direct Link (AWDL) - CyberHoot)[10] Wi-Fi Alliance â€“ Wifi Aware â€“ Android added platform support for Wi-Fi Aware in Oreo (8.0) and later (Wi-Fi Aware | Wi-Fi Alliance)[11] Usenix Association â€“ A billion Open Interfaces for Eve and Mallory: MitM, DoS, and Tracking ATtacks on iOS and macOS Through Apple Wireless Direct Link â€“ AWDL integrates with Bluetooth Low Energy (A Billion Open Interfaces for Eve and Mallory: MitM, DoS ... - USENIX)[12] Octet Stream â€“ Building Cross Platform Offline - First Apps with Bluetooth Low Energy - Integration with Bluetooth Low Energy (May 2024) (Building Cross-Platform Offline-First Apps with Bluetooth Low Energy).[13] Open Wireless Link â€“ Code â€“ Linux Implementation called OWL (Code | Open Wireless Link)[14] Secure Mobile Networking Lab (SEEMOO) -- Apple Wireless Direct Link (AWDL) and Secure Device Communications â€“ AWDL is a based ad-hoc protocol with Apple-specific extensions integrated into Appleâ€™s ecosystem (Matthias Hollick â€“ Secure Mobile Networking Lab)[15] WiFi Alliance â€“ Wi-Fi CERTIFIED Wi-Fi Aware Technology Overview â€“ Wi-Fi Aware always-on background discovery with power efficiency (2002) (Wi-Fi CERTIFIED Wi-Fi Awareâ„¢ Technology Overview (2022) | Wi-Fi Alliance)[16] WiF Alliance â€“ Wi-Fi Aware Specification v4.0 â€“ Detailed Specification for Wi-Fi Aware technology (2022) (Wi-Fi Aware Specification v4.0.pdfâ€SUBSCRIBEGet posts straight in your inboxSubscribe to updates and we'll send you occasional emails with posts that we think you'll like.\n  hbspt.forms.create({\n    portalId: \"4836182\",\n    formId: \"b8668664-695d-40ab-a974-db7a6522dbea\",\n    region: \"na1\"\n  });\nEmail*utm_sourceutm_mediumutm_campaignutm_termutm_content\n\nRead moreView All ArticlesView All ArticlesView All ArticlesProductMarch 19, 2025Introducing Ditto 4.10: More Power, More Control, and New Platform SupportbySkyler JokielOur latest Ditto 4.10 SDK release brings significant improvements, giving developers more flexibility, better performance, and support for new platforms. March 12, 2025Ditto Lands $82M to Pioneer the Edge-Native RevolutionbyRyan RatnerThe future of computing isnâ€™t in the cloud - itâ€™s at the edge. And with this latest funding round, weâ€™re poised to make Ditto the new standard for edge development.\n\nul.footer_links_wrap>li.footer_links_item { transition: opacity 400ms ease, transform 400ms ease; }\nul.footer_links_wrap:has(li.footer_links_item:hover)>li.footer_links_item:not(:hover) { opacity: 0.5; }\nul.footer_links_wrap:has(li.footer_links_item:hover)>li.footer_links_item:hover { transform: translateX(0.5em); }\nResilient Edge Device ConnectivityServers and Cloud, OptionalStart for freeStart for freeStart for freeSchedule a DemoSchedule a DemoSchedule a DemoÂ© 2025 DittoLive IncorporatedAll rights reserved.CompanyPlatformAbout UsOur CustomersPricingCareersResourcesBlogDEMOAPPSIn The NewsPress ReleasesMake a ReportSocialsLinkedinGithubTwitter / XLegalTerms of ServicePrivacy PolicyCookie PolicyDPA",
    "summary": {
      "en": "The European Union (EU) is requiring Apple to replace its proprietary peer-to-peer Wi-Fi protocol, Apple Wireless Direct Link (AWDL), with the industry-standard Wi-Fi Aware, also known as Neighbor Awareness Networking (NAN). This change is mandated by the EU's Digital Markets Act (DMA), which aims to improve interoperability among devices. \n\nKey points include:\n\n1. **Forced Transition**: Apple must implement Wi-Fi Aware 4.0 in iOS 19 and follow up with Wi-Fi Aware 5.0 shortly after its release. This transition is not voluntary but a regulatory requirement.\n\n2. **Significance of Wi-Fi Aware**: Wi-Fi Aware allows devices from different manufacturers to discover and communicate directly without needing a router or internet connection, enhancing cross-platform connectivity.\n\n3. **History of Wi-Fi Protocols**:\n   - **Wi-Fi Direct**: An earlier standard that allowed devices to connect directly but had limitations.\n   - **AWDL**: Developed by Apple for its devices, providing high performance but lacking cross-platform functionality.\n   - **Wi-Fi Aware**: An open standard based on concepts from AWDL, enabling better interoperability and power efficiency.\n\n4. **Advantages of Wi-Fi Aware**:\n   - Continuous and efficient device discovery.\n   - High data throughput and range.\n   - Lower latency and instant communication capabilities.\n   - Built-in security features.\n\n5. **Impact on Developers**: The shift to Wi-Fi Aware will simplify development for cross-platform applications, allowing for easier implementation of features like peer-to-peer file sharing, similar to Appleâ€™s AirDrop, across both iOS and Android devices.\n\n6. **Future Innovations**: The EU's mandate may lead to more advancements in peer-to-peer networking, including potential improvements in future versions of Wi-Fi Aware.\n\nOverall, this change represents a significant step towards unifying device connectivity standards, enabling better collaboration and communication between different platforms.",
      "ko": "ìœ ëŸ½ì—°í•©(EU)ì€ ì• í”Œì—ê²Œ ìì‚¬ì˜ ë…ì ì ì¸ í”¼ì–´ íˆ¬ í”¼ì–´ Wi-Fi í”„ë¡œí† ì½œì¸ ì• í”Œ ë¬´ì„  ì§ì ‘ ë§í¬(AWDL)ë¥¼ ì—…ê³„ í‘œì¤€ì¸ Wi-Fi Aware, ì¦‰ ì´ì›ƒ ì¸ì‹ ë„¤íŠ¸ì›Œí‚¹(NAN)ìœ¼ë¡œ êµì²´í•  ê²ƒì„ ìš”êµ¬í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ ë³€í™”ëŠ” EUì˜ ë””ì§€í„¸ ì‹œì¥ë²•(DMA)ì— ì˜í•´ ì˜ë¬´í™”ë˜ì—ˆìœ¼ë©°, ì´ëŠ” ê¸°ê¸° ê°„ì˜ ìƒí˜¸ ìš´ìš©ì„±ì„ ê°œì„ í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n\nì• í”Œì€ iOS 19ì—ì„œ Wi-Fi Aware 4.0ì„ êµ¬í˜„í•´ì•¼ í•˜ë©°, ê·¸ í›„ ê³§ë°”ë¡œ Wi-Fi Aware 5.0ìœ¼ë¡œ ì—…ë°ì´íŠ¸í•´ì•¼ í•©ë‹ˆë‹¤. ì´ ì „í™˜ì€ ìë°œì ì¸ ê²ƒì´ ì•„ë‹ˆë¼ ê·œì œ ìš”êµ¬ì‚¬í•­ì…ë‹ˆë‹¤.\n\nWi-Fi AwareëŠ” ì„œë¡œ ë‹¤ë¥¸ ì œì¡°ì‚¬ì˜ ê¸°ê¸°ê°€ ë¼ìš°í„°ë‚˜ ì¸í„°ë„· ì—°ê²° ì—†ì´ ì§ì ‘ ë°œê²¬í•˜ê³  í†µì‹ í•  ìˆ˜ ìˆê²Œ í•´ì£¼ì–´, í”Œë«í¼ ê°„ ì—°ê²°ì„±ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ì´ì „ì˜ Wi-Fi DirectëŠ” ê¸°ê¸°ê°€ ì§ì ‘ ì—°ê²°ë  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” í‘œì¤€ì´ì—ˆì§€ë§Œ í•œê³„ê°€ ìˆì—ˆìŠµë‹ˆë‹¤. AWDLì€ ì• í”Œì´ ìì‚¬ ê¸°ê¸°ë¥¼ ìœ„í•´ ê°œë°œí•œ ê²ƒìœ¼ë¡œ ë†’ì€ ì„±ëŠ¥ì„ ì œê³µí•˜ì§€ë§Œ, í”Œë«í¼ ê°„ ê¸°ëŠ¥ì´ ë¶€ì¡±í–ˆìŠµë‹ˆë‹¤. Wi-Fi AwareëŠ” AWDLì˜ ê°œë…ì„ ë°”íƒ•ìœ¼ë¡œ í•œ ê°œë°©í˜• í‘œì¤€ìœ¼ë¡œ, ë” ë‚˜ì€ ìƒí˜¸ ìš´ìš©ì„±ê³¼ ì „ë ¥ íš¨ìœ¨ì„±ì„ ì œê³µí•©ë‹ˆë‹¤.\n\nWi-Fi Awareì˜ ì¥ì ìœ¼ë¡œëŠ” ì§€ì†ì ì´ê³  íš¨ìœ¨ì ì¸ ê¸°ê¸° ë°œê²¬, ë†’ì€ ë°ì´í„° ì „ì†¡ ì†ë„ì™€ ë²”ìœ„, ë‚®ì€ ì§€ì—° ì‹œê°„ ë° ì¦‰ê°ì ì¸ í†µì‹  ê¸°ëŠ¥, ë‚´ì¥ëœ ë³´ì•ˆ ê¸°ëŠ¥ì´ ìˆìŠµë‹ˆë‹¤. Wi-Fi Awareë¡œì˜ ì „í™˜ì€ í¬ë¡œìŠ¤ í”Œë«í¼ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì„ ê°„ì†Œí™”í•˜ì—¬, ì• í”Œì˜ ì—ì–´ë“œë¡­ê³¼ ìœ ì‚¬í•œ í”¼ì–´ íˆ¬ í”¼ì–´ íŒŒì¼ ê³µìœ  ê¸°ëŠ¥ì„ iOSì™€ ì•ˆë“œë¡œì´ë“œ ê¸°ê¸° ëª¨ë‘ì—ì„œ ì‰½ê²Œ êµ¬í˜„í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.\n\nEUì˜ ìš”êµ¬ëŠ” í”¼ì–´ íˆ¬ í”¼ì–´ ë„¤íŠ¸ì›Œí‚¹ì˜ ë°œì „ì„ ì´ëŒì–´ë‚¼ ìˆ˜ ìˆìœ¼ë©°, í–¥í›„ Wi-Fi Awareì˜ ê°œì„  ê°€ëŠ¥ì„±ë„ ì—´ì–´ì¤ë‹ˆë‹¤. ì´ëŸ¬í•œ ë³€í™”ëŠ” ê¸°ê¸° ì—°ê²° í‘œì¤€ì„ í†µí•©í•˜ëŠ” ì¤‘ìš”í•œ ë‹¨ê³„ë¡œ, ì„œë¡œ ë‹¤ë¥¸ í”Œë«í¼ ê°„ì˜ í˜‘ì—…ê³¼ í†µì‹ ì„ ë”ìš± ì›í™œí•˜ê²Œ í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "7265932f6ff4bdeb",
    "title": {
      "en": "Optimizing Matrix Multiplication on RDNA3",
      "ko": "RDNA3 í–‰ë ¬ ê³±ì…ˆ ìµœì í™”",
      "ja": null
    },
    "type": "story",
    "url": "https://seb-v.github.io/optimization/update/2025/01/20/Fast-GPU-Matrix-multiplication.html",
    "score": 18,
    "by": "skidrow",
    "time": 1742896521,
    "content": "Introduction\n\nHi everyone !\n\nIn this post, I will share with you all the steps to write an optimized FP32 matrix multiplication on AMD RDNA3 GPU outperforming rocBLAS by 60%. I will cover some basics and explain all the optimizations I have implemented. This will be done in a iterative way in 8 differents Kernels.\n\n  Figure 1: sneak peek of the performance results\n\nI primary intended to work on this to deepen my understanding of RDNA3 and try out HIP and I felt like I needed to share what I learned doing this :).\n\nFew things I like to say before we start :\n\n  All the information I used comes from the publicly available ISA guide1\n  I donâ€™t intend to re-implement or replace rocBLAS\n  I only focused on 4096x4096 matrices single precision (FP32) matrix multiplication for the sake of simplicity.\n  All my tests were done on Windows 11 with a AMD Radeon 7900 XTX.\n\nThat being said, letâ€™s start !\n\nProblem statement\n\nThere is a lot of research happening on the way to improve the performance of matrix multiplication nowadays. Being a core algorithm in ML applications, any FLOPS we can exploit is golden.\n\nBefore proceeding, letâ€™s recall the basics of matrix multiplication. Given two matrices:\n\n  A of size M,K\n  B of size K,N\n\nTheir product, C, is computed as follows:\n\nCij=âˆ‘k=0Kâˆ’1Aikâ‹…Bkj\n\niâˆˆ[0,Mâˆ’1]\njâˆˆ[0,Nâˆ’1]\n\nwhere C is the resulting matrix of size M,N.\n\nFor each output value of matrix C, we compute the dot product between the rows of matrix A and the columns of matrix B.\n\n  Figure 2: example for the first element of C\n\nIn terms of complexity, we have O(n3) computational complexity and O(n2) memory accesses.\nIf we donâ€™t think about architectural details, this is clearly a compute bound problem and our goal will be to be compute bound on the GPU.\n\nLetâ€™s say we manage to write the best implementation possible for the 7900 XTX. How fast could it run ? To answer this questions we need to look a bit at RDNA3 architecture.\n\nRDNA3 GPUs are made of arrays of WorkGroup Processors (WGP). Every WGP are split into 2 Compute Units (CUs), themself split into 2 SIMDs. A SIMD handles the work of multiple threads organized in waves (or warps for CUDA folks) and has a set of components to do some work (like arithmetic operations). For Floating point operations, there are two 32 way VALU units.\n\n  Figure 3: simplified representation of WGPs\n\n  Figure 4: simplified representation of a single SIMD\n\nWe can compute our theoritical floating point operation per second with this formula:\n\nFLOPS=freqâˆ—nbSIMDâˆ—flopsPerSIMD\n\nEvery SIMD can issue 2 Floating points intructions per cycle (one on each vALU unit). If we use FMA instructions (Fused Multiply Add), each SIMD can issue 32âˆ—2âˆ—2=128 floating point operations per cycle.\nThe 7900 XTX has 48 WGPs, thatâ€™s 48âˆ—2âˆ—2=192 SIMDs.\n\nFLOPS=2500âˆ—106âˆ—192âˆ—128FLOP/s\n\nFLOPS=61.44TFLOP/s\n\nOur theoritical VRAM bandwidth is given by :\n\nBW=rateâˆ—busWidth/8\n\nThe 7900 XTX uses GDDR6 with a 384-bit bus running at 20 Gbps.\n\nBW=20âˆ—384/8=960GB/s\n\nIf we go back to our 4096x4096 matrix multiplication, we essentially need to do 2âˆ—4096âˆ—4096âˆ—4096 operations.\nWith a 61 TFLops implementation, it would take roughly 2.23 ms to do the work and the bandwidth required to sustain this rate would be 4096âˆ—4096âˆ—4âˆ—3/2.23âˆ—10âˆ’3=90.2GB/s.\n\nOf course, these are oversimplified calculations as they totally ignore memory hierarchy but we see that the available bandwidth is sufficiently high so that we can increase the amount of data we read to be closer to compute bound.\n\nKernel 1: naive implementation\n\nLetâ€™s start with a naive implementation like this :\n\n__global__ void kernel1_naive(const float *A, const float *B, float *C, int M, int K, int N, float alpha, float beta)\n{\n    int row = blockIdx.y * blockDim.y + threadIdx.y;\n    int col = blockIdx.x * blockDim.x + threadIdx.x;\n    if (row < M && col < N)\n    {\n        float acc_c = 0.0f;\n        for (int k = 0; k < K; ++k)\n        {\n            acc_c += A[row * K + k] * B[k * N + col];\n        }\n        C[row * N + col] = alpha * acc_c + beta * C[row * N + col];\n    }\n}\n\nYou will notice I am doing  C=alphaâˆ—Aâˆ—B+betaâˆ—C instead of C=Aâˆ—B here. This is because it makes easier to compare with libraries like rocBLAS where matrix multiplications is provided by SGEMM functions (Single-Precision General Matrix Multiply).\n\nWe launch 4096x4096 threads with a blocksize of 16x16 and each thread compute the inner dot product described before.\n\nThe performance for this kernel is 136 ms (1010.60 GFlops/s). I know, thatâ€™s pretty bad and far off our 61 TFLops target.\n\nKernel 0: rocBLAS reference implementation\n\nNow that we have seen possibly the worst implementation in terms of performance, letâ€™s look at the official rocBLAS implementation.\n\n    const int M = N;\n    const int K = N;\n    CHECK_ROCBLAS_STATUS(rocblas_sgemm(\n        handle,\n        rocblas_operation_none, // Transpose option for A\n        rocblas_operation_none, // Transpose option for B\n        M,                      // Number of rows in A and C\n        N,                      // Number of columns in B and C\n        K,                      // Number of columns in A and rows in B\n        &alpha,                 // alpha\n        d_a,                    // Matrix A on the device\n        M,                      // Leading dimension of A\n        d_b,                    // Matrix B on the device\n        K,                      // Leading dimension of B\n        &beta,                  // beta\n        d_c,                    // Matrix C on the device\n        M                       // Leading dimension of C\n        ));\n\nAs discussed before, I used rocblas_sgemm function with alpha and beta set to 1.02\n\nThe performance for this kernel is 4.49 ms (30547 GFLOPs/s). This is clearly much better than our kernel 1 but still far from our theoritical 61.4 TFlops/s.\n\nBy inspecting the ISA in RGP3, I couldnâ€™t find any dual issue instructions in the kernel (only v_fmac_f32_e32)4\n\n  Figure 5: extract of rocBLAS ISA code\n\nThis is very surprising as this essentially means one of the VALU unit is sitting there doing nothing.\n\nConsidering this, the VALU utilization of this kernel is pretty impressive and almost 100 %. However, itâ€™s really surprising we canâ€™t exploit these dual issue instructions properly. Iâ€™ll come to that later.\n\nKernel 2: LDS Tiling\n\nThe main issue with our naive kernel is that our inner loop directly accesses global memory. This is inefficient because fetching data from global memory has a high latency, typically on the order of hundreds of cycles. Since each memory read is followed by minimal computation (just one multiplication and one addition), the GPU struggles to hide this latency, even with a large number of concurrent threads. Moreover, the algorithm repeatedly reads the same rows and columns from global memory across different threads, leading to redundant memory accesses and further exacerbating the performance bottleneck.\n\nA solution to this problem is to load the data once into faster local memory and then iterate efficiently over it with all the threads. On RDNA3, we have the Local Data Store (LDS), a high-speed, low-latency memory accessible by all threads within a workgroup.\n\n  Figure 6: simplified representation of the memory hierarchy\n\nSince the LDS has a much smaller capacity than global memory, we need to use tiling to divide our problem into smaller sub-matrix multiplications. One way to facilitate this is to restructure the computation by moving the inner loopâ€™s dot product to the outer loop. The key idea is to cache a column of matrix A and a row of matrix B, then perform the computation across the entire tile. This approach is more cache-efficient and significantly reduces memory access latency.\n\nThe pseudo code for our kernel 1 is :\n\nfor i from 0 to M - 1:                  # Loop over rows of A\n    for j from 0 to N - 1:              # Loop over columns of B\n        sum = 0\n        for k from 0 to K - 1:          # Loop over columns of A / rows of B\n            sum += A[i][k] * B[k][j]\n        end for\n        C[i][j] = sum\n    end for\nend for\n\nIf we move the dot product to the outer loop, we have this :\n\nfor k from 0 to K - 1:                  # Outer loop over the shared dimension\n    for i from 0 to M - 1:              # Loop over rows of A\n        for j from 0 to N - 1:          # Loop over columns of B\n            C[i][j] += A[i][k] * B[k][j]\n        end for\n    end for\nend for\n\nTiling in this form is straightforward: each workgroup operates on a tile and follows these steps: (BK is the batch size, ie number of rows/columns we load to the LDS)\n\nInit c to 0\nWhile kId is less than N:\n  # Load A and B to Tile As and Bs\n  Load BK columns A to As\n  Load BK rows to Bs\n  Syncthreads\n  # Accumulate results using LDS\n  for k from 0 to BK\n    c += As[threadIdx.y][k] * Bs[k][threadIdx.x]\n  Syncthreads\n  Increment kId by BK\nend for\nc[row][col]=c\n\nIf we choose a tile size of 32x32 and BK=32, our new kernel looks like this:\n\n#define TILE_SIZE 32\n__global__ void kernel2_lds(const float *A, const float *B, float *C, int N)\n{\n    __shared__ float As[TILE_SIZE][TILE_SIZE];\n    __shared__ float Bs[TILE_SIZE][TILE_SIZE];\n\n    int row = blockIdx.y * TILE_SIZE + threadIdx.y;\n    int col = blockIdx.x * TILE_SIZE + threadIdx.x;\n\n    float sum = 0.0f;\n\n    for (int t = 0; t < N; t += TILE_SIZE)\n    {\n        Bs[threadIdx.y][threadIdx.x] = B[N * (threadIdx.y + t) + col];\n        As[threadIdx.y][threadIdx.x] = A[N * row + t + threadIdx.x];\n\n        __syncthreads();\n\n        for (int k = 0; k < TILE_SIZE; k++)\n        {\n            sum += As[threadIdx.y][k] * Bs[k][threadIdx.x];\n        }\n\n        __syncthreads();\n    }\n\n    if (row < N && col < N)\n    {\n        C[row * N + col] = sum;\n    }\n}\n\n__syncthreads(); is required here to ensure that all threads in the workgroup can see the data loaded into the LDS and to synchronize before any updates are made to the data.\n\nWe also ensure that the contents of both matrices A and B are loaded into the LDS by rows rather than columns to avoid uncoalesced memory accesses.\nIndeed, if we were to read by columns, each thread in a wave would access a non-contiguous memory region, result",
    "summary": {
      "en": "In this post, the author explains how to optimize FP32 matrix multiplication on an AMD RDNA3 GPU, specifically achieving a performance improvement over the rocBLAS library by 60%. The focus is on 4096x4096 matrices, using an AMD Radeon 7900 XTX, and involves eight different kernel implementations.\n\n**Key Points:**\n\n1. **Matrix Multiplication Basics**: The product of two matrices A (size MxK) and B (size KxN) results in matrix C (size MxN). The computation involves calculating the dot product of rows in A and columns in B.\n\n2. **Performance Goals**: The goal is to optimize the implementation to be compute-bound on the GPU, taking advantage of the RDNA3 architecture.\n\n3. **Theoretical Performance**: The author calculates the theoretical performance to be about 61.44 TFLOPS and the bandwidth required to sustain this performance is around 90.2 GB/s.\n\n4. **Naive Implementation**: A basic kernel implementation shows poor performance (136 ms, 1010.60 GFLOPS/s). The rocBLAS implementation performs better (4.49 ms, 30547 GFLOPS/s) but still falls short of the theoretical maximum.\n\n5. **Optimization Strategy**: The primary issue with the naive implementation is inefficient global memory access. The author proposes using Local Data Store (LDS) tiling, which uses faster local memory to reduce latency and improve performance.\n\n6. **Tiling Implementation**: The new approach involves loading data into tiles and performing computations on these tiles to minimize memory accesses. The author provides a pseudo code example and a specific implementation for the optimized kernel using LDS.\n\nOverall, the post highlights the importance of optimizing memory access patterns and utilizing GPU architecture features to enhance matrix multiplication performance.",
      "ko": "ì´ ê¸€ì—ì„œëŠ” AMD RDNA3 GPUì—ì„œ FP32 í–‰ë ¬ ê³±ì…ˆì„ ìµœì í™”í•˜ëŠ” ë°©ë²•ì„ ì„¤ëª…í•˜ë©°, rocBLAS ë¼ì´ë¸ŒëŸ¬ë¦¬ë³´ë‹¤ 60% í–¥ìƒëœ ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ëŠ” ë°©ë²•ì„ ë‹¤ë£¹ë‹ˆë‹¤. ì£¼ë¡œ 4096x4096 í¬ê¸°ì˜ í–‰ë ¬ì„ ì‚¬ìš©í•˜ë©°, AMD Radeon 7900 XTXë¥¼ í™œìš©í•˜ê³ , ì—¬ëŸ ê°€ì§€ì˜ ì„œë¡œ ë‹¤ë¥¸ ì»¤ë„ êµ¬í˜„ì„ í¬í•¨í•©ë‹ˆë‹¤.\n\ní–‰ë ¬ ê³±ì…ˆì˜ ê¸°ë³¸ ì›ë¦¬ëŠ” ë‘ ê°œì˜ í–‰ë ¬ A(í¬ê¸° MxK)ì™€ B(í¬ê¸° KxN)ë¥¼ ê³±í•˜ì—¬ í–‰ë ¬ C(í¬ê¸° MxN)ë¥¼ ìƒì„±í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì´ ê³¼ì •ì—ì„œëŠ” Aì˜ í–‰ê³¼ Bì˜ ì—´ ê°„ì˜ ë‚´ì ì„ ê³„ì‚°í•©ë‹ˆë‹¤.\n\nì„±ëŠ¥ ëª©í‘œëŠ” GPUì—ì„œ ê³„ì‚° ì¤‘ì‹¬ìœ¼ë¡œ ìµœì í™”í•˜ì—¬ RDNA3 ì•„í‚¤í…ì²˜ì˜ ì´ì ì„ ìµœëŒ€í•œ í™œìš©í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì €ìëŠ” ì´ë¡ ì ì¸ ì„±ëŠ¥ì„ ì•½ 61.44 TFLOPSë¡œ ê³„ì‚°í•˜ë©°, ì´ ì„±ëŠ¥ì„ ìœ ì§€í•˜ê¸° ìœ„í•´ í•„ìš”í•œ ëŒ€ì—­í­ì€ ì•½ 90.2 GB/së¼ê³  ì„¤ëª…í•©ë‹ˆë‹¤.\n\nê¸°ë³¸ì ì¸ ì»¤ë„ êµ¬í˜„ì€ ì„±ëŠ¥ì´ ì¢‹ì§€ ì•Šì•„ 136ms, 1010.60 GFLOPS/sì˜ ê²°ê³¼ë¥¼ ë³´ì…ë‹ˆë‹¤. rocBLAS êµ¬í˜„ì€ ë” ë‚˜ì€ ì„±ëŠ¥ì¸ 4.49ms, 30547 GFLOPS/së¥¼ ê¸°ë¡í•˜ì§€ë§Œ ì—¬ì „íˆ ì´ë¡ ì ì¸ ìµœëŒ€ ì„±ëŠ¥ì—ëŠ” ë¯¸ì¹˜ì§€ ëª»í•©ë‹ˆë‹¤.\n\nìµœì í™” ì „ëµì˜ ì£¼ìš” ë¬¸ì œëŠ” ë¹„íš¨ìœ¨ì ì¸ ì „ì—­ ë©”ëª¨ë¦¬ ì ‘ê·¼ì…ë‹ˆë‹¤. ì €ìëŠ” ì§€ì—° ì‹œê°„ì„ ì¤„ì´ê³  ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ Local Data Store(LDS) íƒ€ì¼ë§ì„ ì‚¬ìš©í•  ê²ƒì„ ì œì•ˆí•©ë‹ˆë‹¤. ì´ ìƒˆë¡œìš´ ì ‘ê·¼ ë°©ì‹ì€ ë°ì´í„°ë¥¼ íƒ€ì¼ì— ë¡œë“œí•˜ê³  ì´ íƒ€ì¼ì—ì„œ ê³„ì‚°ì„ ìˆ˜í–‰í•˜ì—¬ ë©”ëª¨ë¦¬ ì ‘ê·¼ì„ ìµœì†Œí™”í•©ë‹ˆë‹¤. ì €ìëŠ” ìµœì í™”ëœ ì»¤ë„ì„ ìœ„í•œ LDS ì‚¬ìš©ì˜ êµ¬ì²´ì ì¸ êµ¬í˜„ê³¼ ì˜ì‚¬ ì½”ë“œë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n\nì´ ê¸€ì€ ë©”ëª¨ë¦¬ ì ‘ê·¼ íŒ¨í„´ì„ ìµœì í™”í•˜ê³  GPU ì•„í‚¤í…ì²˜ì˜ ê¸°ëŠ¥ì„ í™œìš©í•˜ì—¬ í–‰ë ¬ ê³±ì…ˆ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ê²ƒì˜ ì¤‘ìš”ì„±ì„ ê°•ì¡°í•©ë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "4080a392bd1c945c",
    "title": {
      "en": "Building Statically Linked Go Executables with CGO and Zig",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://calabro.io/zig-cgo",
    "score": 81,
    "by": "todsacerdoti",
    "time": 1743171067,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "541246337a07996d",
    "title": {
      "en": "Architecture Patterns with Python",
      "ko": "íŒŒì´ì¬ ì•„í‚¤í…ì²˜ íŒ¨í„´",
      "ja": null
    },
    "type": "story",
    "url": "https://www.cosmicpython.com/book/preface.html",
    "score": 398,
    "by": "asicsp",
    "time": 1743141447,
    "content": "Preface\n\nYou may be wondering who we are and why we wrote this book.\n\nAt the end of Harryâ€™s last book,\nTest-Driven Development with Python (Oâ€™Reilly),\nhe found himself asking a bunch of questions about architecture, such as,\nWhatâ€™s the best way of structuring your application so that itâ€™s easy to test?\nMore specifically, so that your core business logic is covered by unit tests,\nand so that you minimize the number of integration and end-to-end tests you need?\nHe made vague references to \"Hexagonal Architecture\" and \"Ports and Adapters\"\nand \"Functional Core, Imperative Shell,\" but if he was honest, heâ€™d have to\nadmit that these werenâ€™t things he really understood or had done in practice.\n\nAnd then he was lucky enough to run into Bob, who has the answers to all these\nquestions.\n\nBob ended up as a software architect because nobody else on his team was\ndoing it. He turned out to be pretty bad at it, but he was lucky enough to run\ninto Ian Cooper, who taught him new ways of writing and thinking about code.\n\nManaging Complexity, Solving Business Problems\n\nWe both work for MADE.com, a European ecommerce company that sells furniture\nonline; there, we apply the techniques in this book to build distributed systems\nthat model real-world business problems. Our example domain is the first system\nBob built for MADE, and this book is an attempt to write down all the stuff we\nhave to teach new programmers when they join one of our teams.\n\nMADE.com operates a global supply chain of freight partners and manufacturers.\nTo keep costs low, we try to optimize the delivery of stock to our\nwarehouses so that we donâ€™t have unsold goods lying around the place.\n\nIdeally, the sofa that you want to buy will arrive in port on the very day\nthat you decide to buy it, and weâ€™ll ship it straight to your house without\never storing it. Getting the timing right is a tricky balancing act when goods take\nthree months to arrive by container ship. Along the way, things get broken or water\ndamaged, storms cause unexpected delays, logistics partners mishandle goods,\npaperwork goes missing, customers change their minds and amend their orders,\nand so on.\n\nWe solve those problems by building intelligent software representing the\nkinds of operations taking place in the real world so that we can automate as\nmuch of the business as possible.\n\nWhy Python?\n\nIf youâ€™re reading this book, we probably donâ€™t need to convince you that Python\nis great, so the real question is \"Why does the Python community need a book\nlike this?\" The answer is about Pythonâ€™s popularity and maturity: although Python is\nprobably the worldâ€™s fastest-growing programming language and is nearing the top\nof the absolute popularity tables, itâ€™s only just starting to take on the kinds\nof problems that the C# and Java world has been working on for years.\nStartups become real businesses; web apps and scripted automations are becoming\n(whisper it) enterprise software.\n\nIn the Python world, we often quote the Zen of Python:\n\"There should be oneâ€”and preferably only oneâ€”obvious way to do it.\"[1]\nUnfortunately, as project size grows, the most obvious way of doing things\nisnâ€™t always the way that helps you manage complexity and evolving\nrequirements.\n\nNone of the techniques and patterns we discuss in this book are\nnew, but they are mostly new to the Python world. And this book isnâ€™t\na replacement for the classics in the field such as Eric Evansâ€™s\nDomain-Driven Design\nor Martin Fowlerâ€™s Patterns of\nEnterprise Application Architecture (both published by Addison-Wesley Professional)â€”which we often refer to and\nencourage you to go and read.\n\nBut all the classic code examples in the literature do tend to be written in\nJava or C++/#, and if youâ€™re a Python person and havenâ€™t used either of\nthose languages in a long time (or indeed ever), those code listings can be\nquiteâ€¦trying. Thereâ€™s a reason the latest edition of that other classic text, Fowlerâ€™s\nRefactoring (Addison-Wesley Professional), is in JavaScript.\n\nTDD, DDD, and Event-Driven Architecture\n\nIn order of notoriety, we know of three tools for managing complexity:\n\nTest-driven development (TDD) helps us to build code that is correct\nand enables us to refactor or add new features, without fear of regression.\nBut it can be hard to get the best out of our tests: How do we make sure\nthat they run as fast as possible? That we get as much coverage and feedback\nfrom fast, dependency-free unit tests and have the minimum number of slower,\nflaky end-to-end tests?\n\nDomain-driven design (DDD) asks us to focus our efforts on building a good\nmodel of the business domain, but how do we make sure that our models arenâ€™t\nencumbered with infrastructure concerns and donâ€™t become hard to change?\n\nLoosely coupled (micro)services integrated via messages (sometimes called\nreactive microservices) are a well-established answer to managing complexity\nacross multiple applications or business domains. But itâ€™s not always\nobvious how to make them fit with the established tools of\nthe Python worldâ€”Flask, Django, Celery, and so on.\n\nNote\n\nDonâ€™t be put off if youâ€™re not working with (or interested in) microservices.\n    The vast majority of the patterns we discuss,\n    including much of the event-driven architecture material,\n    is absolutely applicable in a monolithic architecture.\n\nOur aim with this book is to introduce several classic architectural patterns\nand show how they support TDD, DDD, and event-driven services.  We hope\nit will serve as a reference for implementing them in a Pythonic way, and that\npeople can use it as a first step toward further research  in this field.\n\nWho Should Read This Book\n\nHere are a few things we assume about you, dear reader:\n\nYouâ€™ve been close to some reasonably complex Python applications.\n\nYouâ€™ve seen some of the pain that comes with trying to manage\nthat complexity.\n\nYou donâ€™t necessarily know anything about DDD or any of the\nclassic application architecture patterns.\n\nWe structure our explorations of architectural patterns around an example app,\nbuilding it up chapter by chapter. We use TDD at\nwork, so we tend to show listings of tests first, followed by implementation.\nIf youâ€™re not used to working test-first, it may feel a little strange at\nthe beginning, but we hope youâ€™ll soon get used to seeing code \"being used\"\n(i.e., from the outside) before you see how itâ€™s built on the inside.\n\nWe use some specific Python frameworks and technologies, including Flask,\nSQLAlchemy, and pytest, as well as Docker and Redis. If youâ€™re already\nfamiliar with them, that wonâ€™t hurt, but we donâ€™t think itâ€™s required.  One of\nour main aims with this book is to build an architecture for which specific\ntechnology choices become minor implementation details.\n\nA Brief Overview of What Youâ€™ll Learn\n\nThe book is divided into two parts; hereâ€™s a look at the topics weâ€™ll cover\nand the chapters they live in.\n\n#part1\n\nDomain modeling and DDD (Chapters 1, 2 and 7)\n\nAt some level, everyone has learned the lesson that complex business\nproblems need to be reflected in code, in the form of a model of the domain.\nBut why does it always seem to be so hard to do without getting tangled\nup with infrastructure concerns, our web frameworks, or whatever else?\nIn the first chapter we give a broad overview of domain modeling and DDD, and we\nshow how to get started with a model that has no external dependencies, and\nfast unit tests. Later we return to DDD patterns to discuss how to choose\nthe right aggregate, and how this choice relates to questions of data\nintegrity.\n\nRepository, Service Layer, and Unit of Work patterns (Chapters 2, 4, and 5)\n\nIn these three chapters we present three closely related and\nmutually reinforcing patterns that support our ambition to keep\nthe model free of extraneous dependencies.  We build a layer of\nabstraction around persistent storage, and we build a service\nlayer to define the entrypoints to our system and capture the\nprimary use cases. We show how this layer makes it easy to build\nthin entrypoints to our system, whether itâ€™s a Flask API or a CLI.\n\nSome thoughts on testing and abstractions (Chapter 3 and 5)\n\nAfter presenting the first abstraction (the Repository pattern), we take the\nopportunity for a general discussion of how to choose abstractions, and\nwhat their role is in choosing how our software is coupled together. After\nwe introduce the Service Layer pattern, we talk a bit about achieving a test pyramid\nand writing unit tests at the highest possible level of abstraction.\n\n#part2\n\nEvent-driven architecture (Chapters 8-11)\n\nWe introduce three more mutually reinforcing patterns:\nthe Domain Events, Message Bus, and Handler patterns.\nDomain events are a vehicle for capturing the idea that\nsome interactions with a system are triggers for others.\nWe use  a message bus to allow actions to trigger events\nand call appropriate handlers.\nWe move on to discuss how events can be used as a pattern\nfor integration between services in a microservices architecture.\nFinally, we distinguish between commands and events.\nOur application is now fundamentally a message-processing system.\n\nCommand-query responsibility segregation ([chapter_12_cqrs])\n\nWe present an example of command-query responsibility segregation,\nwith and without events.\n\nDependency injection ([chapter_13_dependency_injection])\n\nWe tidy up our explicit and implicit dependencies and implement a\nsimple dependency injection framework.\n\nAdditional Content\n\nHow do I get there from here? ([epilogue_1_how_to_get_there_from_here])\n\nImplementing architectural patterns always looks easy when you show a simple\nexample, starting from scratch, but many of you will probably be wondering how\nto apply these principles to existing software. Weâ€™ll provide a\nfew pointers in the epilogue and some links to further reading.\n\nExample Code and Coding Along\n\nYouâ€™re reading a book, but youâ€™ll probably agree with us when we say that\nthe best way to learn about code is to code.  We learned most of what we know\nfrom pairing with people, writing code with them, and learning by doing, and\nweâ€™d like to re-create that experience as much as possible for you in this book.\n\nAs a result, weâ€™ve structured the book around a single example project\n(although we do sometimes throw in other examples). Weâ€™ll build up this project as the chapters progress, as if youâ€™ve paired with us and\nweâ€™re explaining what weâ€™re doing and why at each step.\n\nBut to really get to grips with these patterns, you need to mess about with the\ncode and get a feel for how it works. Youâ€™ll find all the code on\nGitHub; each chapter has its own branch. You can find a list of the branches on GitHub as well.\n\nHere are three ways you might code along with the book:\n\nStart your own repo and try to build up the app as we do, following the\nexamples from listings in the book, and occasionally looking to our repo\nfor hints. A word of warning, however: if youâ€™ve read Harryâ€™s previous book\nand coded along with that, youâ€™ll find that this book requires you to figure out more on\nyour own; you may need to lean pretty heavily on the working versions on GitHub.\n\nTry to apply each pattern, chapter by chapter, to your own (preferably\nsmall/toy) project, and see if you can make it work for your use case.  This\nis high risk/high reward (and high effort besides!). It may take quite some\nwork to get things working for the specifics of your project, but on the other\nhand, youâ€™re likely to learn the most.\n\nFor less effort, in each chapter we outline an \"Exercise for the Reader,\"\nand point you to a GitHub location where you can download some partially finished\ncode for the chapter with a few missing parts to write yourself.\n\nParticularly if youâ€™re intending to apply some of these patterns in your own\nprojects, working through a simple example is a great way to\nsafely practice.\n\nTip\n\nAt the very least, do a git checkout of the code from our repo as you\n    read each chapter. Being able to jump in and see the code in the context of\n    an actual working app will help answer a lot of questions as you go, and\n    makes everything more real. Youâ€™ll find instructions for how to do that\n    at the beginning of each chapter.\n\nLicense\n\nThe code (and the online version of the book) is licensed under a Creative\nCommons CC BY-NC-ND license, which means you are free to copy and share it with\nanyone you like, for non-commercial purposes, as long as you give attribution.\nIf you want to re-use any of the content from this book and you have any\nworries about the license, contact Oâ€™Reilly at permissions@oreilly.com.\n\nThe print edition is licensed differently; please see the copyright page.\n\nConventions Used in This Book\n\nThe following typographical conventions are used in this book:\n\nItalic\n\nIndicates new terms, URLs, email addresses, filenames, and file extensions.\n\nConstant width\n\nUsed for program listings, as well as within paragraphs to refer to program elements such as variable or function names, databases, data types, environment variables, statements, and keywords.\n\nConstant width bold\n\nShows commands or other text that should be typed literally by the user.\n\nConstant width italic\n\nShows text that should be replaced with user-supplied values or by values determined by context.\n\nTip\n\nThis element signifies a tip or suggestion.\n\nNote\n\nThis element signifies a general note.\n\nWarning\n\nThis element indicates a warning or caution.\n\nOâ€™Reilly Online Learning\n\nNote\n\nFor more than 40 years, Oâ€™Reilly Media has provided technology and business training, knowledge, and insight to help companies succeed.\n\nOur unique network of experts and innovators share their knowledge and expertise through books, articles, conferences, and our online learning platform. Oâ€™Reillyâ€™s online learning platform gives you on-demand access to live training courses, in-depth learning paths, interactive coding environments, and a vast collection of text and video from Oâ€™Reilly and 200+ other publishers. For more information, please visit http://oreilly.com.\n\nHow to Contact Oâ€™Reilly\n\nPlease address comments and questions concerning this book to the publisher:\n\n  Oâ€™Reilly Media, Inc.\n  1005 Gravenstein Highway North\n  Sebastopol, CA 95472\n  800-998-9938 (in the United States or Canada)\n  707-829-0515 (international or local)\n  707-829-0104 (fax)\n\nWe have a web page for this book, where we list errata, examples, and any additional information. You can access this page at https://oreil.ly/architecture-patterns-python.\n\nEmail bookquestions@oreilly.com to comment or ask technical questions about this book.\n\nFor more information about our books, courses, conferences, and news, see our website at http://www.oreilly.com.\n\nFind us on Facebook: http://facebook.com/oreilly\n\nFollow us on Twitter: http://twitter.com/oreillymedia\n\nWatch us on YouTube: http://www.youtube.com/oreillymedia\n\nAcknowledgments\n\nTo our tech reviewers, David Seddon, Ed Jung, and Hynek Schlawack: we absolutely\ndo not deserve you. You are all incredibly dedicated, conscientious, and\nrigorous. Each one of you is immensely smart, and your different points of\nview were both useful and complementary to each other. Thank you from the\nbottom of our hearts.\n\nGigantic thanks also to all our readers so far for their comments and\nsuggestions:\nIan Cooper, Abdullah Ariff, Jonathan Meier, Gil GonÃ§alves, Matthieu Choplin,\nBen Judson, James Gregory, Åukasz Lechowicz, Clinton Roy, Vitorino AraÃºjo,\nSusan Goodbody, Josh Harwood, Daniel Butler, Liu Haibin, Jimmy Davies, Ignacio\nVergara Kausel, Gaia Canestrani, Renne Rocha, pedroabi, Ashia Zawaduk, Jostein\nLeira, Brandon Rhodes, Jazeps Basko, simkimsia, Adrien Brunet, Sergey Nosko,\nDmitry Bychkov,\nand many more; our apologies if we missed you on this list.\n\nSuper-mega-thanks to our editor Corbin Collins for his gentle chivvying, and\nfor being a tireless advocate of the reader. Similarly-superlative thanks to\nthe production staff, Katherine Tozer, Sharon Wilkey, Ellen Troutman-Zaig, and\nRebecca Demarest, for your dedication, professionalism, and attention to\ndetail. This book is immeasurably improved thanks to you.\n\nAny errors remaining in the book are our own, naturally.\n\n  << Previous - Appendix E: Validation\n  Next - Introduction >>",
    "summary": {
      "en": "**Summary:**\n\nThis book explores key architectural patterns for building complex applications in Python, focusing on effective software design and testing strategies. Written by Harry and Bob, it stems from Harry's questions about structuring applications for better testability after his previous work on Test-Driven Development (TDD) with Python. Bob, an experienced software architect, shares insights learned from Ian Cooper on managing complexity in software.\n\nThe authors work at MADE.com, an online furniture retailer, where they apply these techniques to create intelligent systems for optimizing logistics and delivery. They aim to teach new programmers the essential skills needed for such projects.\n\nThe book emphasizes the growing need for robust architectural patterns in Python as it evolves into more complex applications, similar to those in C# and Java. It covers TDD, Domain-Driven Design (DDD), and event-driven architecture, introducing classic patterns and how they can be applied in a Pythonic way.\n\nReaders are expected to have experience with complex Python applications but donâ€™t need prior knowledge of DDD or architectural patterns. The book builds a single example project throughout its chapters, encouraging readers to engage with the code actively through exercises and GitHub resources.\n\nKey areas covered include:\n- Domain modeling and DDD principles.\n- Repository, Service Layer, and Unit of Work patterns.\n- Event-driven architecture and message processing.\n- Command-query responsibility segregation and dependency injection.\n\nOverall, this book serves as a reference for implementing architectural patterns in Python and encourages further exploration of software design principles.",
      "ko": "ì´ ì±…ì€ ë³µì¡í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ êµ¬ì¶•í•˜ê¸° ìœ„í•œ ì£¼ìš” ì•„í‚¤í…ì²˜ íŒ¨í„´ì„ íƒêµ¬í•˜ë©°, íš¨ê³¼ì ì¸ ì†Œí”„íŠ¸ì›¨ì–´ ì„¤ê³„ì™€ í…ŒìŠ¤íŠ¸ ì „ëµì— ì¤‘ì ì„ ë‘¡ë‹ˆë‹¤. í•´ë¦¬ì™€ ë°¥ì´ ì €ìë¡œ ì°¸ì—¬í–ˆìœ¼ë©°, ì´ ì±…ì€ í•´ë¦¬ê°€ íŒŒì´ì¬ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ ì£¼ë„ ê°œë°œ(TDD)ì„ ì§„í–‰í•œ í›„ ì• í”Œë¦¬ì¼€ì´ì…˜ êµ¬ì¡°ì— ëŒ€í•œ ì§ˆë¬¸ì—ì„œ ì¶œë°œí–ˆìŠµë‹ˆë‹¤. ê²½í—˜ì´ í’ë¶€í•œ ì†Œí”„íŠ¸ì›¨ì–´ ì•„í‚¤í…íŠ¸ì¸ ë°¥ì€ ì†Œí”„íŠ¸ì›¨ì–´ì˜ ë³µì¡ì„±ì„ ê´€ë¦¬í•˜ëŠ” ë°©ë²•ì— ëŒ€í•œ ì´ì•ˆ ì¿ í¼ì˜ í†µì°°ì„ ê³µìœ í•©ë‹ˆë‹¤.\n\nì €ìë“¤ì€ ì˜¨ë¼ì¸ ê°€êµ¬ ì†Œë§¤ì—…ì²´ì¸ MADE.comì—ì„œ ì¼í•˜ë©°, ì´ëŸ¬í•œ ê¸°ìˆ ì„ í™œìš©í•´ ë¬¼ë¥˜ì™€ ë°°ì†¡ì„ ìµœì í™”í•˜ëŠ” ì§€ëŠ¥í˜• ì‹œìŠ¤í…œì„ ë§Œë“­ë‹ˆë‹¤. ì´ë“¤ì€ ìƒˆë¡œìš´ í”„ë¡œê·¸ë˜ë¨¸ë“¤ì—ê²Œ ì´ëŸ¬í•œ í”„ë¡œì íŠ¸ì— í•„ìš”í•œ í•„ìˆ˜ ê¸°ìˆ ì„ ê°€ë¥´ì¹˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n\nì±…ì€ íŒŒì´ì¬ì´ C#ê³¼ ìë°”ì™€ ê°™ì€ ë³µì¡í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ìœ¼ë¡œ ë°œì „í•¨ì— ë”°ë¼ ê°•ë ¥í•œ ì•„í‚¤í…ì²˜ íŒ¨í„´ì˜ í•„ìš”ì„±ì´ ì»¤ì§€ê³  ìˆìŒì„ ê°•ì¡°í•©ë‹ˆë‹¤. TDD, ë„ë©”ì¸ ì£¼ë„ ì„¤ê³„(DDD), ì´ë²¤íŠ¸ ê¸°ë°˜ ì•„í‚¤í…ì²˜ë¥¼ ë‹¤ë£¨ë©°, ê³ ì „ì ì¸ íŒ¨í„´ê³¼ ì´ë¥¼ íŒŒì´ì¬ ë°©ì‹ìœ¼ë¡œ ì ìš©í•˜ëŠ” ë°©ë²•ì„ ì†Œê°œí•©ë‹ˆë‹¤.\n\në…ìëŠ” ë³µì¡í•œ íŒŒì´ì¬ ì• í”Œë¦¬ì¼€ì´ì…˜ì— ëŒ€í•œ ê²½í—˜ì´ ìˆì–´ì•¼ í•˜ì§€ë§Œ, DDDë‚˜ ì•„í‚¤í…ì²˜ íŒ¨í„´ì— ëŒ€í•œ ì‚¬ì „ ì§€ì‹ì€ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì´ ì±…ì€ ê° ì¥ì—ì„œ í•˜ë‚˜ì˜ ì˜ˆì œ í”„ë¡œì íŠ¸ë¥¼ êµ¬ì¶•í•˜ë©°, ë…ìê°€ ì½”ë“œì— ì ê·¹ì ìœ¼ë¡œ ì°¸ì—¬í•˜ë„ë¡ ìœ ë„í•˜ëŠ” ì—°ìŠµ ë¬¸ì œì™€ GitHub ë¦¬ì†ŒìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n\nì£¼ìš” ë‚´ìš©ìœ¼ë¡œëŠ” ë„ë©”ì¸ ëª¨ë¸ë§ê³¼ DDD ì›ì¹™, ë¦¬í¬ì§€í† ë¦¬, ì„œë¹„ìŠ¤ ë ˆì´ì–´, ìœ ë‹› ì˜¤ë¸Œ ì›Œí¬ íŒ¨í„´, ì´ë²¤íŠ¸ ê¸°ë°˜ ì•„í‚¤í…ì²˜ì™€ ë©”ì‹œì§€ ì²˜ë¦¬, ëª…ë ¹-ì¿¼ë¦¬ ì±…ì„ ë¶„ë¦¬ ë° ì˜ì¡´ì„± ì£¼ì…ì´ í¬í•¨ë©ë‹ˆë‹¤.\n\nì „ë°˜ì ìœ¼ë¡œ ì´ ì±…ì€ íŒŒì´ì¬ì—ì„œ ì•„í‚¤í…ì²˜ íŒ¨í„´ì„ êµ¬í˜„í•˜ê¸° ìœ„í•œ ì°¸ê³ ì„œ ì—­í• ì„ í•˜ë©°, ì†Œí”„íŠ¸ì›¨ì–´ ì„¤ê³„ ì›ì¹™ì— ëŒ€í•œ ì¶”ê°€ íƒêµ¬ë¥¼ ì¥ë ¤í•©ë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "9ceda24309032b3b",
    "title": {
      "en": "The Biology of B-Movie Monsters (2003)",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://fathom.lib.uchicago.edu/2/21701757/",
    "score": 48,
    "by": "cainxinth",
    "time": 1743169241,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "4eb49c6d920d4f18",
    "title": {
      "en": "Getting hit by lightning is good for some tropical trees",
      "ko": "ë²ˆê°œê°€ ë‚˜ë¬´ë¥¼ ì‚´ë¦°ë‹¤",
      "ja": null
    },
    "type": "story",
    "url": "https://www.caryinstitute.org/news-insights/press-release/getting-hit-lightning-good-some-tropical-trees",
    "score": 116,
    "by": "sohkamyung",
    "time": 1743169978,
    "content": "Share:\n\n                            March 26, 2025\n\n          Biodiversity,\n\n          Climate Change,\n\n          Conservation,\n\n          Tropical Forests,\n\n          Lightning\n\n          Getting zapped with millions of volts of electricity may not sound like a healthy activity, but for some trees, it is. A new study, published in New Phytologist, reports that some tropical tree species are not only able to tolerate lightning strikes, but benefit from them. The trees may have even evolved to act as lightning rods.The research was led by Evan Gora, a forest ecologist at Cary Institute of Ecosystem Studies. Gora studies how lightning impacts biodiversity and carbon storage in Panamaâ€™s tropical forests.Lightning kills hundreds of millions of trees per year. But in 2015, while working in Panama, Gora and his colleagues came across a Dipteryx oleifera tree that had survived a strike with little damage â€” even though the jolt had been strong enough to blast a parasitic vine out of its crown and kill more than a dozen neighboring trees. â€œSeeing that there are trees that get struck by lightning and theyâ€™re fine was just mind blowing,â€ Gora recalled. Over time, the team encountered other D. oleifera trees thriving after getting hit, so they decided to take a closer look.Also known as the eboe, choibÃ¡, tonka bean or almendro, Dipteryx oleifera is native to Honduras, Nicaragua, Costa Rica, Panama, Colombia, and Ecuador. Its hard wood is used in construction, and it produces almond-flavored seeds that are edible and sold in local markets. A keystone species of Panamanian forests, D. oleifera fruits and seeds are a crucial food source for rainforest mammals such as agouti during the dry season.Scientists had previously suspected that some trees evolved to tolerate lightning, but evidence to back it up was lacking. In 2022, Gora and colleagues demonstrated for the first time that trees differ in their ability to survive getting hit by lightning. Their new paper, published Wednesday, is the first to show that trees can actually benefit from these electric jolts.Using a unique lightning location system, the team tracked the outcomes of 93 trees that had been struck by lightning in Barro Colorado Nature Monument in central Panama. For two to six years after the strike, the team measured tree survival rates, crown and trunk condition, number of parasitic vines or lianas, and neighboring tree mortality. The study included nine directly struck D. oleifera trees, and compared them with 84 other trees that had been struck.All nine D. oleifera trees survived direct lightning strikes with only minor damages. In contrast, directly struck trees of other species were badly damaged, losing 5.7 times more leaves from their crowns, and 64% died within two years.When each D. oleifera tree was zapped, an average of 9.2 neighboring trees were killed as the electricity traveled between adjoining vines and touching branches, or jumped across small gaps between trees. Lightning strikes also decreased D. oleifera's parasitic liana infestations by 78%, further reducing competition for light and nutrients.A Dipteryx oleifera tree just after being struck by lightning in 2019 (left) versus two years later (right). The tree survived the strike with minimal damage, and benefited from having its parasitic vines and competing neighbors removed by the strike. Photos: Evan GoraThese patterns also bore out across the broader population. The team found that D. oleifera trees in general tend to have fewer lianas. Analyzing trends in tree death over the past 40 years, the researchers found that the trees neighboring D. oleifera trees were 48% more prone to die than other trees in the forest, likely because of lightning.Using drones, Gora and colleagues created 3D models of canopy height, which showed that D. oleifera trees tend to be about four meters taller than their nearest neighbors, likely because lightning killed their taller neighbors, giving them an advantage in competing for light and space.â€œThese data provide the first evidence that some trees benefit from being struck by lightning,â€ the authors write. Or, as Gora puts it, â€œIt's better off for a Dipteryx oleifera tree to be struck than not.â€Because of all these benefits, the team thinks D. oleifera trees may be specially adapted to attract lightning. With their distinctive height and unusually wide crowns, they may be up to 68% more likely to get electrocuted than other trees with average height and crowns, according to the teamâ€™s calculations.Lightning strikes open up gaps around Dipteryx oleifera trees, giving them more space to spread out and collect light. Photo: Evan GoraEstimates suggest individual Dipteryx oleifera trees are directly hit by lightning every 56 years, on average. And since the trees can live for hundreds or possibly more than a thousand years, they are expected to survive these blasts many times throughout their lives. During the study, one of the D. oleifera trees was struck twice in just five years.The remarkable ability to survive lightning strikes and benefit from the removal of lianas and competitors gives D. oleifera trees a major advantage over other trees. According to the scientists' calculations, lightning tolerance boosts the speciesâ€™ ability to produce offspring by 14 times.Next, the team aims to investigate what electrical or structural traits allow these trees to survive lightning strikes. They would also like to explore whether other species show lightning tolerance, to better understand how common this phenomenon is.What is clear is that lightning plays an underappreciated role in tree competition. And with lightning on the rise in many regions due to climate change, its influence may increase, potentially favoring lightning-tolerant species like Dipteryx oleifera. Understanding lightning and its role in shaping the forests may be important for predicting changes in biodiversity and carbon storage, and for informing tropical reforestation efforts.Study co-authors include: Helene Muller-Landau and Pablo NarvÃ¡ez of the Smithsonian Tropical Research Institute; KC Cushman of Oak Ridge National Laboratory; Jeannine Richards of Florida Gulf Coast University; Phillip Bitzer and Jeffrey Burchfield of the University of Alabama in Huntsville; and Stephen Yanoviak of the University of Louisville.New Phytologist is a leading international journal focusing on high quality, original research across the broad spectrum of plant sciences, from intracellular processes through to global environmental change. The journal is owned by the New Phytologist Foundation, a not-for-profit organisation dedicated to the promotion of plant science.FundingThis work was supported by grants from the National Science Foundation (DEB-1354060, DEB-1655346, and DEB-2213246 to SPY, DEB-1354510, DEB-1655554, and DEB-2213247 to PMB, and DEB-2213245, DEB-2241507, and GRF-2015188266 to EMG), the National Geographic Society (9703-15 to EMG), and a Smithsonian Tropical Research Institute Tupper Postdoctoral Fellowship to EMG. KCC was supported as part of the Next Generation Ecosystem Experiments-Tropics, funded by the U.S. Department of Energy, Office of Science, Office of Biological and Environmental Research.\n\n        Share:",
    "summary": {
      "en": "A recent study has found that certain tropical trees, specifically the Dipteryx oleifera, can not only survive lightning strikes but may actually benefit from them. Led by forest ecologist Evan Gora, the research showed that these trees can act like lightning rods, experiencing minimal damage while helping to eliminate competition from nearby plants.\n\nThe study tracked 93 trees struck by lightning in Panama and discovered that while D. oleifera trees survived with minor damage, other species suffered significant loss, with many dying shortly after being struck. The strikes reduced the number of parasitic vines on D. oleifera trees, allowing them to grow better and compete for resources more effectively.\n\nThe researchers suggest that D. oleifera trees may have evolved to attract lightning due to their height and wide crowns. On average, these trees are struck by lightning every 56 years and can live for hundreds of years, benefiting from multiple strikes throughout their lifespan.\n\nThe findings highlight the important role that lightning plays in forest dynamics and could influence biodiversity and carbon storage, especially as climate change increases lightning frequency. Future research will explore what traits allow these trees to survive lightning and whether other species have similar adaptations.",
      "ko": "ìµœê·¼ ì—°êµ¬ì— ë”°ë¥´ë©´ íŠ¹ì • ì—´ëŒ€ ë‚˜ë¬´, íŠ¹íˆ ë””í”„í…Œë¦­ìŠ¤ ì˜¬ë ˆì´í˜ë¼(Dipteryx oleifera)ëŠ” ë²ˆê°œì— ë§ì•„ë„ ìƒì¡´í•  ìˆ˜ ìˆì„ ë¿ë§Œ ì•„ë‹ˆë¼ ì˜¤íˆë ¤ ì´ë“ì„ ë³¼ ìˆ˜ ìˆë‹¤ëŠ” ì‚¬ì‹¤ì´ ë°í˜€ì¡ŒìŠµë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” ì‚°ë¦¼ ìƒíƒœí•™ì ì—ë°˜ ê³ ë¼(Evan Gora)ê°€ ì´ëŒì—ˆìœ¼ë©°, ì´ ë‚˜ë¬´ë“¤ì´ ë²ˆê°œë¥¼ ìœ ë„í•˜ëŠ” ì—­í• ì„ í•˜ë©° ìµœì†Œí•œì˜ í”¼í•´ë¥¼ ì…ëŠ” ë™ì‹œì— ì£¼ë³€ ì‹ë¬¼ê³¼ì˜ ê²½ìŸì„ ì¤„ì´ëŠ” ë° ë„ì›€ì„ ì¤€ë‹¤ëŠ” ê²°ê³¼ë¥¼ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤.\n\nì—°êµ¬íŒ€ì€ íŒŒë‚˜ë§ˆì—ì„œ ë²ˆê°œì— ë§ì€ 93ê·¸ë£¨ì˜ ë‚˜ë¬´ë¥¼ ì¶”ì í•˜ì˜€ê³ , D. oleifera ë‚˜ë¬´ëŠ” ê²½ë¯¸í•œ í”¼í•´ë¥¼ ì…ê³  ìƒì¡´í•œ ë°˜ë©´, ë‹¤ë¥¸ ì¢…ë“¤ì€ ìƒë‹¹í•œ í”¼í•´ë¥¼ ì…ê³  ë§ì€ ë‚˜ë¬´ê°€ ë²ˆê°œì— ë§ì€ ì§í›„ ì‚¬ë§í•˜ëŠ” ê²ƒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ë²ˆê°œëŠ” D. oleifera ë‚˜ë¬´ì— ìˆëŠ” ê¸°ìƒ ë©êµ´ì˜ ìˆ˜ë¥¼ ì¤„ì—¬ì£¼ì–´ ì´ ë‚˜ë¬´ë“¤ì´ ë” ì˜ ìë¼ê³  ìì› ê²½ìŸì—ì„œ ìœ ë¦¬í•œ ìœ„ì¹˜ë¥¼ ì°¨ì§€í•  ìˆ˜ ìˆë„ë¡ í–ˆìŠµë‹ˆë‹¤.\n\nì—°êµ¬ìë“¤ì€ D. oleifera ë‚˜ë¬´ê°€ ê·¸ ë†’ì´ì™€ ë„“ì€ ê°€ì§€ ë•ë¶„ì— ë²ˆê°œë¥¼ ëŒì–´ë‹¹ê¸°ëŠ” ë°©í–¥ìœ¼ë¡œ ì§„í™”í–ˆì„ ê°€ëŠ¥ì„±ì´ ìˆë‹¤ê³  ì œì•ˆí•©ë‹ˆë‹¤. í‰ê· ì ìœ¼ë¡œ ì´ ë‚˜ë¬´ë“¤ì€ 56ë…„ë§ˆë‹¤ ë²ˆê°œì— ë§ìœ¼ë©°, ìˆ˜ë°± ë…„ì„ ì‚´ ìˆ˜ ìˆì–´ ìƒì•  ë™ì•ˆ ì—¬ëŸ¬ ë²ˆì˜ ë²ˆê°œë¥¼ ê²½í—˜í•˜ë©° ì´ë“ì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nì´ ì—°êµ¬ ê²°ê³¼ëŠ” ë²ˆê°œê°€ ìˆ²ì˜ ìƒíƒœê³„ì—ì„œ ì¤‘ìš”í•œ ì—­í• ì„ í•œë‹¤ëŠ” ì ì„ ê°•ì¡°í•˜ë©°, ê¸°í›„ ë³€í™”ë¡œ ì¸í•´ ë²ˆê°œê°€ ë” ìì£¼ ë°œìƒí•¨ì— ë”°ë¼ ìƒë¬¼ ë‹¤ì–‘ì„±ê³¼ íƒ„ì†Œ ì €ì¥ì— ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í–¥í›„ ì—°êµ¬ì—ì„œëŠ” ì´ëŸ¬í•œ ë‚˜ë¬´ë“¤ì´ ë²ˆê°œë¥¼ ê²¬ë”œ ìˆ˜ ìˆëŠ” íŠ¹ì„±ì´ ë¬´ì—‡ì¸ì§€, ê·¸ë¦¬ê³  ë‹¤ë¥¸ ì¢…ë“¤ë„ ë¹„ìŠ·í•œ ì ì‘ì„ ê°€ì§€ê³  ìˆëŠ”ì§€ì— ëŒ€í•´ íƒêµ¬í•  ì˜ˆì •ì…ë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "5ea5b028361048ce",
    "title": {
      "en": "Disk I/O bottlenecks in GitHub Actions",
      "ko": "ê¹ƒí—ˆë¸Œ ì•¡ì…˜ì˜ ë””ìŠ¤í¬ ë³‘ëª©",
      "ja": null
    },
    "type": "story",
    "url": "https://depot.dev/blog/uncovering-disk-io-bottlenecks-github-actions-ci",
    "score": 82,
    "by": "jacobwg",
    "time": 1743175356,
    "content": "When your CI pipelines are slow, you can only optimize so much. Bottlenecks in CPU, Network, Memory, and Disk I/O can all contribute to slow CI pipelines. Let's take a look at how disk I/O can be a bottleneck in GitHub Actions.",
    "summary": {
      "en": "Slow CI pipelines can only be improved to a certain extent. Issues with CPU, Network, Memory, and Disk I/O can all cause delays. This summary focuses on how Disk I/O can slow down workflows in GitHub Actions.",
      "ko": "ëŠë¦° CI íŒŒì´í”„ë¼ì¸ì€ ì–´ëŠ ì •ë„ê¹Œì§€ ê°œì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. CPU, ë„¤íŠ¸ì›Œí¬, ë©”ëª¨ë¦¬, ë””ìŠ¤í¬ I/Oì™€ ê°™ì€ ë¬¸ì œë“¤ì´ ëª¨ë‘ ì§€ì—°ì„ ì´ˆë˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ìš”ì•½ì—ì„œëŠ” ë””ìŠ¤í¬ I/Oê°€ GitHub Actionsì˜ ì‘ì—… íë¦„ì„ ì–´ë–»ê²Œ ëŠë¦¬ê²Œ í•  ìˆ˜ ìˆëŠ”ì§€ì— ëŒ€í•´ ì„¤ëª…í•©ë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "fe85c9fb8a23bd2d",
    "title": {
      "en": "MilliForth-6502: The smallest Forth real programming language for 6502",
      "ko": "ë°€ë¦¬í¬ìŠ¤ 6502: ì´ˆì†Œí˜• í¬ìŠ¤ í”„ë¡œê·¸ë˜ë° ì–¸ì–´",
      "ja": null
    },
    "type": "story",
    "url": "https://github.com/agsb/milliForth-6502",
    "score": 89,
    "by": "rbanffy",
    "time": 1743159880,
    "content": "A milliForth for 6502\n\"A Forth in 328 bytes â€” the smallest real programming\nlanguage ever, as of yet.\"\nThe milliForth1 is a review of sectorForth2,\nand smaller than sector Lisp3\nThe miniForth4 is another Forth to use in a boot sector\nof less than 512 bytes.\nBytes?\nYes, bytes. But those are for a x86 16-bit CPU.\nHow minimal could be it for a classic 6502 8-bit CPU ?\nTwo essentially different CPUs, a 16-bit x86 based on complex\nregisters and opcodes, and a 8-bit 6502 using page zero\nas common registers and page one as hardware stack.\nInner Interpreter\nThe FIG-Forth (1980) for 6502 uses Indirect Thread Code (ITC)\nas inner interpreter.\nThe miniForth, sectorforth and milliForth use Direct Thread Code (DTC)\nThis Forth for 6502, will be was done using two models:\nwith classic Direct Thread Code (DTC)\nand\nwith Minimal Thread Code (MTC)\n\n(later we will compare both, but DTC will win for less size)\nThis project is also used to verify standart Direct Thread Code against\nvariations of Minimum Thread Code.\nMinimal Thread Code\nis an alternative model for inner interpreter, where\nthe dictionary is organized with the primitives words grouped together\nbefore the compound words, defining a \"tipping point\", from where could\ndecide if the reference of a word will be to executed or be pushed into\nreturn stack. PS. MTC is a reduced form of TachyonForth inner interpreter.\nCoding for 6502\nFocus in size not performance.\nThe compilation wqas done with ca65 V2.19 - Git 7979f8a41.\nThe emulation of 6502 CPU was done with run6502\nThe way at 6502 is use a page zero and lots of lda/sta bytes.\nBoth DTC and MTC runs with my_hello_world.FORTH, with these numbers.\nMTC, Instructions: 35796948, Cycles: 148802145, SIZE: 582\n\nDTC, Instructions: 35211469, Cycles: 148450585, SIZE: 596\n\ncompiling my_hello_world.FORTH, overhead MTC / DTC\n\nInstructions:    1.66%\n\nCycles:          0.24%\n\n(*) Thanks to wise changes from peterferrie !\nChanges:\n\nas Forth-19945: FALSE is $0000 and TRUE is $FFFF ;\n\nall tib (80 bytes), pic (16 cells), data (36 cells) and\nreturn (36 cells) stacks are in page $200 ;\n\ntib and pic grows forward, stacks grows backwards ;\n\nonly immediate flag used as $80, no more flags ;\n\nno line editor, no backspace, no cancel line, no low ASCII verify ;\n\nno stacks overflow or underflow checks ;\n\nRemarks:\n\n6502 is a byte processor, no need 'pad' at end of even names ;\nhardware stack (page $100) not used as forth stack, free for use ;\nuses 32 bytes of page zero ;\nno multiuser, no multitask, no faster ;\nonly update latest at end of word definition ;\nredefine a word does not change previous uses ;\nstacks moves like the hardware stack ;\nwords must be between spaces, before and after ever ;\nbetter use 7-bit ASCII characters ;\napprouch as ANSI X3.215-19945\n\nNotes\nLook up at Notes6 for more.\n24/08/2024\nmerge of dtc and mtc code into a flagged sector-6502.s file\n16/08/2024:\nboth models DTC and MTC, works with my_hello_world.FORTH;\n11/08/2024:\nreturn to direct thread code;\n11/06/2024:\nadapt for minimal thread indirect code;\n24/01/2024:\nwrite using standart direct thread code;\n14/11/2023\ncode for 6502 sized to 624 bytes,\nno ascii-7, no key, no emit, no 2/, many errors\nCoding\nThis version includes:\nprimitives:\n    s@    return the address of user structure\n    +     adds two values at top of data stack\n    nand  logic not and the two values at top of data stack\n    @     fetch a value of cell wich address at top of data stack\n    !     store a value into a cell wich address at top of data stack\n    0#    test if top of data stack is not zero\n\n    :     starts compilng a new word\n    ;     stops compiling a new word\n    exit  ends a word\n\n    key   get a char from default terminal (system dependent)\n    emit  put a char into default terminal (system dependent)\n\ninternals:\n    spush, spull, rpull, rpush, (stack code)\n    copyfrom, copyinto, (heap code)\n    incr, decr, add, etc (register mimics)\n    cold, warm, quit, token, skip, scan, getline, (boot and terminal)\n    parse, find, compile, execute, (outer interpreter)\n\n    unnest, next, nest, (dtc inner)\n    unnest, next, nest, pick, jump, (mtc inner)\n\n    ps. next is not the FOR NEXT loop\n\nexternals:\n    getch, putch, byes (depends on system, used minimal for emulator )\n\nextensions: (selectable)\n    2/      shift right one bit\n    exec    jump to address at top of spt\n    :$      jump to (ipt)\n    ;$      jump to next\n\nextras:    (selectable)\n    bye     ends the Forth, return to system\n    abort   restart the Forth\n    .S      list cells in data stack\n    .R      list cells in return stack\n    .       show cell at top of data stack\n    words   extended list the words in dictionary\n    dump    list contents of dictionary in binary\n\nA my_hello_world.FORTH alternate version with dictionary for use;\n\nThe sp@ and rp@ are now derived from s@ in the my_hello_world.FORTH\n\nMemory\n    $000    page zero       ; cpu reserved\n    $100    hardware stack  ; cpu reserved\n    $200    TIB             ; terminal input buffer, 80 bytes\n    $298*   data stack      ; data stack, 36 cells, backwards\n    $2E0*   return stack    ; return stack, 36 cells, backwards\n    $2E0    PIC             ; reserved for scratch, 16 cells\n    $300    _main_          ; start of Forth\n    $???    _ends_          ; end of code and primitives of Forth\n    $???    _init_          ; start of compound dictionary\n\n    _init_ is the page (MSB) of _ends_ + 1\n\nStacks\n\" When heap moves forward, move the stack backward \"\nPush is 'store and decrease'. Pull is 'increas and fetch'.\nA common memory model organization of Forth:\n   tib->...<-spt, user forth dictionary, here->pad...<-rpt,\n\nthen backward stacks allow to use the slack space ...\nThis 6502 Forth memory model is blocked in pages of 256 bytes:\n   page0, page1, page2, core ... forth dictionary ...here...\n\nat page2, without 'rush over'\n   |tib 40 cells> <spt 36 cells| <rpt 36 cells|pic 16 cells> | .\n\nLanguage\n\"SectorFORTH was an extensive guide throughout the process of\nimplementing milliFORTH, and milliFORTH's design actually converged\non sectorFORTH unintentionally in a few areas. That said, the language\nimplemented is intentionally very similar, being the 'minimal FORTH'.\"\nFor Forth language primer see\nStarting Forth\nFor Forth from inside howto see\nJonasForth\nUse\n** 16/08/2024 DTC and MTC models operational, using lib6502 for emulation and tests **\nA crude small script for compile with ca65 is included.\n; for make it\nsh mk a sector-6502\n\n; for clear it\nsh mk x sector-6502\n\nthe size is take from main: to ends: using the sector-6502.lbl file\nNote\nthe originals files are edited for lines with less than 80 bytes\nthe bf.FORTH and hello_world.FORTH are from original milliForth1\nthe my_hello_world.FORTH is adapted for miiliforth-6502\nReferences\nFootnotes\n\nThe original milliForth: https://github.com/fuzzballcat/milliForth â†© â†©2\n\nThe inspirational sectorForth: https://github.com/cesarblum/sectorforth/ â†©\n\nMind-blowing sectorLISP: https://justine.lol/sectorlisp2/, https://github.com/jart/sectorlisp â†©\n\nThe miniforth: https://github.com/meithecatte/miniforth â†©\n\nForth standart ANSI X3.215-1994: http://www.forth.org/svfig/Win32Forth/DPANS94.txt â†© â†©2\n\nNotes and Times: https://github.com/agsb/milliForth-6502/blob/main/Notes.md â†©",
    "summary": {
      "en": "**Summary of milliForth for 6502**\n\nmilliForth is a very compact version of the Forth programming language, measuring just 328 bytes, making it one of the smallest programming languages available. It is specifically designed for the 8-bit 6502 CPU, contrasting with other Forth versions that target 16-bit CPUs like x86.\n\nKey features of milliForth include:\n\n- **Interpreter Types**: It employs two models for its inner interpreter: Direct Thread Code (DTC) and Minimal Thread Code (MTC). DTC is preferred for its smaller size.\n- **Focus on Size**: The coding prioritizes size over performance, using tools like ca65 for compilation.\n- **Memory Management**: The design utilizes specific memory pages for various functions, including storage for input and output buffers, data stacks, and a return stack.\n- **Primitives and Internals**: It includes basic operations (like addition and fetching values), stack management, and functions to handle the terminal and compilation.\n- **Language Design**: milliForth aims to maintain simplicity and efficiency, drawing inspiration from sectorForth while ensuring it remains minimal.\n\nThis project also serves as a testbed for comparing DTC and MTC, with both models successfully running a sample program. The coding practices and design choices reflect an emphasis on fitting within the constraints of the 6502 architecture. \n\nFor more details, additional resources and references are provided, including links to the original milliForth and similar projects.",
      "ko": "milliForthëŠ” Forth í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì˜ ë§¤ìš° ê°„ê²°í•œ ë²„ì „ìœ¼ë¡œ, í¬ê¸°ê°€ ë‹¨ 328ë°”ì´íŠ¸ì— ë¶ˆê³¼í•´ ê°€ì¥ ì‘ì€ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ ì¤‘ í•˜ë‚˜ë¡œ í‰ê°€ë°›ê³  ìˆìŠµë‹ˆë‹¤. ì´ ì–¸ì–´ëŠ” 8ë¹„íŠ¸ 6502 CPUë¥¼ ìœ„í•´ íŠ¹ë³„íˆ ì„¤ê³„ë˜ì—ˆìœ¼ë©°, x86ê³¼ ê°™ì€ 16ë¹„íŠ¸ CPUë¥¼ ëŒ€ìƒìœ¼ë¡œ í•˜ëŠ” ë‹¤ë¥¸ Forth ë²„ì „ê³¼ëŠ” ì°¨ë³„í™”ë©ë‹ˆë‹¤.\n\nmilliForthì˜ ì£¼ìš” íŠ¹ì§• ì¤‘ í•˜ë‚˜ëŠ” ë‘ ê°€ì§€ ë‚´ë¶€ ì¸í„°í”„ë¦¬í„° ëª¨ë¸ì¸ ì§ì ‘ ìŠ¤ë ˆë“œ ì½”ë“œ(Direct Thread Code, DTC)ì™€ ìµœì†Œ ìŠ¤ë ˆë“œ ì½”ë“œ(Minimal Thread Code, MTC)ë¥¼ ì‚¬ìš©í•œë‹¤ëŠ” ì ì…ë‹ˆë‹¤. DTCëŠ” í¬ê¸°ê°€ ì‘ì•„ ì„ í˜¸ë©ë‹ˆë‹¤. ë˜í•œ, ì½”ë“œëŠ” ì„±ëŠ¥ë³´ë‹¤ í¬ê¸°ë¥¼ ìš°ì„ ì‹œí•˜ë©°, ca65ì™€ ê°™ì€ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì»´íŒŒì¼í•©ë‹ˆë‹¤.\n\në©”ëª¨ë¦¬ ê´€ë¦¬ ì¸¡ë©´ì—ì„œëŠ” ë‹¤ì–‘í•œ ê¸°ëŠ¥ì„ ìœ„í•´ íŠ¹ì • ë©”ëª¨ë¦¬ í˜ì´ì§€ë¥¼ í™œìš©í•©ë‹ˆë‹¤. ì—¬ê¸°ì—ëŠ” ì…ë ¥ ë° ì¶œë ¥ ë²„í¼, ë°ì´í„° ìŠ¤íƒ, ë°˜í™˜ ìŠ¤íƒì„ ìœ„í•œ ì €ì¥ ê³µê°„ì´ í¬í•¨ë©ë‹ˆë‹¤. ê¸°ë³¸ì ì¸ ì—°ì‚°(ì˜ˆ: ë§ì…ˆ ë° ê°’ ê°€ì ¸ì˜¤ê¸°), ìŠ¤íƒ ê´€ë¦¬, í„°ë¯¸ë„ ë° ì»´íŒŒì¼ì„ ì²˜ë¦¬í•˜ëŠ” ê¸°ëŠ¥ë„ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n\nmilliForthëŠ” ê°„ê²°í•¨ê³¼ íš¨ìœ¨ì„±ì„ ìœ ì§€í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•˜ë©°, sectorForthì—ì„œ ì˜ê°ì„ ë°›ì•„ ìµœì†Œí•œì˜ í˜•íƒœë¥¼ ìœ ì§€í•˜ê³ ì í•©ë‹ˆë‹¤. ì´ í”„ë¡œì íŠ¸ëŠ” DTCì™€ MTCë¥¼ ë¹„êµí•˜ê¸° ìœ„í•œ í…ŒìŠ¤íŠ¸ë² ë“œ ì—­í• ë„ í•˜ë©°, ë‘ ëª¨ë¸ ëª¨ë‘ ìƒ˜í”Œ í”„ë¡œê·¸ë¨ì„ ì„±ê³µì ìœ¼ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì½”ë”© ê´€í–‰ê³¼ ì„¤ê³„ ì„ íƒì€ 6502 ì•„í‚¤í…ì²˜ì˜ ì œì•½ì— ë§ì¶”ëŠ” ë° ì¤‘ì ì„ ë‘ê³  ìˆìŠµë‹ˆë‹¤.\n\në” ë§ì€ ì •ë³´ì™€ ìë£ŒëŠ” ì›ë³¸ milliForth ë° ìœ ì‚¬í•œ í”„ë¡œì íŠ¸ì— ëŒ€í•œ ë§í¬ë¥¼ í¬í•¨í•˜ì—¬ ì œê³µë©ë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "a8137c3c4854deab",
    "title": {
      "en": "Building a modern durable execution engine from first principles",
      "ko": "í˜„ëŒ€ì  ì‹¤í–‰ ì—”ì§„ êµ¬ì¶•í•˜ê¸°",
      "ja": null
    },
    "type": "story",
    "url": "https://restate.dev/blog/building-a-modern-durable-execution-engine-from-first-principles/",
    "score": 38,
    "by": "whoiskatrin",
    "time": 1743083504,
    "content": "Building a modern Durable Execution Engine from First PrinciplesHow Restate works, Part 2Posted February 20, 2025 by Stephan Ewen, Ahmed Farghal, and Till Rohrmannâ€20min readWe dive into the architecture details of Restate, a Durable Execution engine we built from the ground up. Restate requires no database/log or other system, but implements a full stack that competes with the best logs in terms of durability and operations.This is the second article in our series on building a durable execution system from first principles. The first blog post in this series, Every System is a Log, looks at this from the application side, and shows how a unified log architecture results in a tremendous simplification of distributed coordination logic. This post discusses the details of how we built the log-based runtime for that paradigm.Modelling locking and database updates through an application log,taken from Every System is a LogTo build this runtime, we asked ourselves, what such a system would look like when designed from first principles? We built a precursor to this with Stateful Functions, and from all the lessons learned there, we arrived at a design with a self-contained complete stack, centered around a command log and event-processor, shipping as a single Rust binary. To get an idea of the user experience we arrived at, check the videos in the announcement post.This stands somewhat in contrast to the common wisdom â€œdonâ€™t build a new stateful system, just use Postgresâ€. But we saw a clear case to build a new stack, for multiple reasons: First, the interactions and access patterns are different enough from existing systems that we can offer both better performance and operational behavior, similar to why message queues exist, even though you can queue with a SQL table. Second, the architecture of event logs has made significant advancements in recent years, but the advanced implementations are exclusive to proprietary stacks and managed offerings - the open source logs and queues still follow architectures from the on-prem era. Third, we saw how a converged stack lets us provide a much better end-to-end developer experience, from first experiments on your laptop to multi-region production deployments.Recap: Server and Services #A Restate application stack consists of two components: Restate Server, which sits at a similar place in your stack as a message broker, and the application services, which are durable functions/handlers containing the application logic. The server receives invocation events, persists them, and pushes them to the services, similar to an event broker. The services run the code that corresponds to RPC- or event-handlers, workflows, activities, or actors. Services may run as processes, containers, or even serverless functions.But Restate doesnâ€™t just push invocations, it maintains a bidirectional connection with the executing service handler and lets the code perform durable actions as part of the invocation, including journaling steps, sending events to other handlers, accessing/modifying state, creating persistent futures (callbacks) and timers. The services use a thin SDK library which communicates the actions to the server - somewhat comparable to a KafkaConsumer or JDBC client, but more high-level. See Restateâ€™s examples for sample code and details.The server handles all coordination and durability for the invocation life cycle, journals, embedded K/V state, and manages failover, leader-election, and fencing. The serverâ€™s view on an invocation and its journal is the ground truth; the services follow the serverâ€™s view and function executions may be cancelled/reset/retried as needed.That approach makes the services completely stateless and simple to operate. They scale rapidly and run on serverless infrastructure like AWS Lambda, Cloudflare workers, etc.This characteristic also lets us build those SDKs in many languages fairly easily, including TypeScript, Java, Kotlin, Python, Go, and Rust.Clusters, Object Stores, and the Latency Gap #A distributed Restate deployment is a cluster of nodes that are connected to each other. Invocations and events can be sent to any node, and all nodes participate in the storage of events and dispatching of invocations to services/functions. Restate is active/active from a cluster-perspective, but has leader/follower roles at the granularity of individual partitions, similar to systems like Kafka or TiKV.Restate stores data using two mechanisms: New events (invocations, journal entries, state updates, â€¦) are persisted in an embedded replicated log (called Bifrost). From there, events move to state indexes in RocksDB, which are periodically snapshotted to an object store. So at any point in time, the majority of the data is durable in the object store (the nodes maintain a copy as cache) while a smaller part of the data is durable in the log replicated across the nodes.This is a form of storage tiering, though not the classical tiering like in modern logs. It is more similar to a database management system, where the write-ahead-log (WAL) would be replicated across nodes, while the table data files and indexes would be persisted on S3 (and cached on the nodes).Object store + latency gap #Architectures that keep most- or all - of their data on object stores have become popular for many reasons: Object stores are unbeatable in terms of combined scalability, durability, and cost (AWS S3 cites eleven 9s of durability, stores more than 100 trillion objects, and is cheaper than persistent disks). Plus, the storage exists disaggregated from compute nodes, making the nodes stateless (or owning little state), which is highly desirable for efficient operations.Object stores are also available in most on-prem setups weâ€™ve encountered. It was natural for us to design Restate such that object storage would be the primary durability for the majority of the data.The reason why Restate has additionally a replication layer that persists new events (rather than writing events straight to object storage) is to provide low latency. Pure object store approaches have latencies that average around 100ms to make data durable, with tail latencies being a multiple of that. While that is feasible for analytical systems (e.g., Apache Flink) and data pipelines (like WarpStream), such latencies can quickly become prohibitive for many applications.Restateâ€™s replication bridges the latency gap between the requirements of fast durable functions and the capabilities of object storage.Navigating the cloud latency-cost-disk triad #The setup described above is what we ship first, in Restate 1.2: a fast log replicated between Restate server nodes. However, Restate uses virtual log abstraction, to easily support other log implementations as well, without having to build a full consensus machinery each time. This is a defining feature of Restateâ€™s runtime implementation that weâ€™ll dive deeper into in the next article in this series. We are currently using that mechanism to build object-store support in the log as well, which is a powerful feature for bringing the amount of data persistent on nodes to very small amounts, even zero.There is no single best configuration for that setup - only a spectrum of trade-offs to pick from. In his Materialized View newsletter, Chris Riccomini describes it as a CAP-theorem-like choice:In our context (durable execution runtime), durability must be a given, but we have the additional dimension of how much replicated data is kept on the nodes. Restateâ€™s triad thus is: latency-cost-disk.â• Low latency, â• low cost, â–some data on disks: Quorum replication to nodes with async batch writes to S3.The nodes provide fast durability through replication and keep the data for anything between a few 100ms and minutes, before moving the events to object storage. Restate 1.2 can be seen as a variant with a long flush interval.â• Low latency, â– high cost, â• no data on disks: Quorum replication directly to S3 Express One Zone.Restateâ€™s replication mechanism deals only with ordering, quorum, and repairs upon loss of a zone, but doesnâ€™t keep data on the nodes (except caches).â– High latency, â• low cost, â• no data on disks: Synchronous batch writes to S3.Restateâ€™s replication mechanism isnâ€™t used.Naturally, there are nuances: direct replication has an even lower latency than S3 Express 1Z quorums. Synchronous batch writes to S3 can be cheaper than anything else, because that approach may avoid cross AZ bandwidth cost. Disks still exist as caches in all configurations. And there is the option of using quorum replication to S3 Express 1Z in different regions, to support multi-region deployments without relying on disks. But it shows that there is the spectrum of options, with which we aim to enable developers to use Restate in diverse setups across cloud and on-prem, while maintaining a simple dependency: just an object store.Restate 1.2 ships with all the virtual log infrastructure, and a low-latency replicated log implementation. We are currently working on the other configurations - if you are interested in being an early tester or design partner, please reach out to us.As a final thought, being able to adjust to different trade-offs also helps Restate and its users adapt to changing cloud pricing models. To quote another prolific dist. sys. writer:Partitioned Scale out #Restate follows the partitioned scale-out model: A cluster has a set of partitions, each with a log partition and an event processor instance. Partitions operate independently and allow the system to scale both across cores and nodes.Everything related to an invocation happens within a single partition: invocation, idempotency & deduplication, journal entries, state, promises/futures, avoiding the need to synchronize and coordinate with any other shards. The target partition for an invocation is determined by hashing the virtual object key, workflow ID, or idempotency key, if applicable - otherwise, the partition is freely chosen.In some cases, a function execution produces an event for another partition, for example RPC events or completions. In that case, events are still written to the local partition, and the server has an out-of-band exactly-once event shuffler to move events to the right target partition.The partitions are not exposed to applications (though you see them when using restatectl) - only keys are directly addressable (virtual object id, workflow id, idempotency key), to allow changing the number of partitions without losing consistency.From here on, we look only at what happens inside a single partition.Event Log and Processor #The work that Restate Server does inside one partition happens in two components: the distributed durable log (called Bifrost) and the processors. The log is the fast primary durability for events (e.g., make invocations, add journal entry, update state, create durable promise, â€¦), the processor acts on events (e.g., invokes handlers) and materializes their state. Log and processor are co-partitioned, meaning a partition processor connects to one log partition. They are independent, but frequently co-located in the same process.Compared to databases, you can think of Bifrost as the transaction WAL, and the processor as the query engine and table storage. Compared to stream processing, you can think of Restateâ€™s log as Kafka and the processor as a stream processing application (like KStreams or Flink).Log and processor form a tight loop: the processor continuously tails the log, and acts on the events (e.g., making invocation). That may produce more events (journal entries, state updates, â€¦), which are written to the log and again processed by the processor.Letâ€™s go through an example to illustrate this:A client invokes service handler processPayment with idempotency key K through Restate. The ingress enqueues the invocation to the log partition, as determined by hashing K.The leader Processor for the partition receives that event and checks its local idempotency key state. K is not contained there for processPayment. The processor atomically adds K to the state and transitions the invocation to running, then builds a connection to the target service endpoint, and pushes the invoke journal entry.The service streams back a step result event (ctx.run({...})) and the processor enqueues that journal entry event in the log. Being persistent in the log is the point when â€œthe step happenedâ€, meaning from there on it will always be recovered.When the processor receives the event from the log (that means no other processor has taken over leadership in the meantime) then it adds the event to the invocationâ€™s journal state and sends an ack to the service.Similar steps happen when the service sends a state update, a timer, an RPC event, or creates a durable promise. Events get always added to the log first, and once they are received by the processor they are acted upon (e.g., added to journal, routed as invocation to other service, etc.)Once the invocation completes, the Processor adds the result event to the log. Upon receiving that event, it sets the invocation state as complete and sends the result back to the client.When the function execution fails (e.g., crash, loss of connection, user-defined error), the processor dispatches a new invocation, attaching the full journal events from this invocation so far. To avoid split brain scenarios between services, the processor tracks invocation execution attempts (retries) and rejects events sent from an invocation if a newer attempt has started. This can be tracked with simple in-memory state, because invocations are sticky to partitions, and partitions have strong leaders.State storage #The processor stores all its non-transient state in an embedded RocksDB instance. Operations on that embedded store are very fast, but the state is lost when the node is lost. However, all state of the processor is deterministically derived from the durable log and can always be rebuilt from the log during recovery. To avoid arbitrarily long re-build phases, the RocksDB database is periodically snapshotted to the object store and the log is trimmed to the point of the snapshot. Processors can be restored by fetching the latest snapshot and attaching to the log at the event sequence number when the snapshot was taken.The implementation of the partition processor is a tight event loop in Rustâ€™s Tokio runtime. Partition Processors operate independently from each other and access exclusively local data structures (in memory, RocksDB, streams to ongoing invocations). The partition-local handling of invocations is easy in a log-first design, and would be much harder to achieve if we built this on a general purpose database.That property makes the design also both simple and fast: Committing an event (e.g., step / activity) means appending the event to the log (obtaining a write quorum). As soon as that happens, the event is pushed from the log leader in-memory to the attached processor and ack-ed to the handler/workflow. This takes a single network roundtrip for a replication quorum, and no distributed reads. The durability of RocksDB happens completely asynchronously in the background.Leaders and Followers #Both log and processors have one leader and optional followers. In the case of the log, followers increase durability for events through additional copies. In the case of processors, followers are hot standbys that have a copy of the state (deterministically derived from the log) and can quickly take over upon failure. Only the processor leader actually dispatches invocations for functions and workflows to the services, and only the leader writes snapshots to object store.High-level architecture and request flow.Control Plane, Data Plane, External Consensus #So far, everything we looked at was the data plane of the system: The log and the partition processor.Everything is coordinated by a control plane, which is responsible for failure detection, failover coordination, and re-configuration. The control plane stores metadata for the cluster (like configurations) and runs the cluster controller that handles partition placement and leader election.Control Plane and Data PlaneBecause Restate has one control plane for both log and processors, it can co-coordinate both, for example ensuring that the leader processor is always co-located with the log partition leader, to reduce network hops and optimize reading from local memory caches. In contrast, if we were to build this transparently on an external log like Kafka, this co-location would be harder to achieve. The benefits of this joint control plane show in many parts of the system and are one of the reasons Restate is simpler to set up, scale, and operate.Besides managing re-configurations and failover, the control plane also provides the external consensus for the data plane, allowing the data plane to operate more efficiently and with simpler properties than full consensus. Weâ€™ll go into the details of Restateâ€™s log implementation in the next blog post - for now, a useful high-level way to think about this is that the control plane moves the data plane from one steady configuration to another, whenever the previous configuration is no longer functional (a failure happened) or desired (e.g., re-balancing). This blog post from Jack Vanlightly gives a nice introduction to that concept.\nThe Control Plane reconfigures the Data Plane (Figure from â€œAn Introduction to Virtual Consensus in Delos â€œby Jack Vanlightly)Another benefit of this design is that it allows Restate to use a simpler/slower implementation of consensus on the control plane, because it is rarely invoked. Restate abstracts its consensus to just an atomic compare-and-swap (CAS) metadata operation, which the built-in metadata store backs with an implementation of the RAFT consensus algorithm. But this can be easily extended to plug in different storage systems, as long as they support atomic CAS.Failover & Reconfiguration #Though the control plane jointly coordinates log and processor reconfiguration, each has their own mechanisms to ensure consistency.A segmented log (Figure from â€œAn Introduction to Virtual Consensus in Delos â€œby Jack Vanlightly)Bifrostâ€™s (the logâ€™s) mechanism is based on a mix of Delos (Virtual Consensus) and LogDevice. From a high-level, bifrost is segmented and failover or reconfiguration seals the active segment and creates a new segment, possibly with a new leader and a different set of nodes that store replicas. To the outside and the partition processors, everything looks like a single contiguous log.When a partition processor fails, the control plane selects a new leader for that partition.The failover procedure relies on the external consensus provided by the control plane: New leaders obtain the next epoch in a strictly monotonous sequence (so newer leaders have higher epochs). The new leader appends a message to the log to signal their epoch is now active, and then simply starts appending events from its operations. The old leader (who might still be following the log) will receive that epoch bump message and step down at that exact point - it will keep materializing state (as a follower) but not dispatch invocations any more. The old leader also aborts ongoing function executions and lets the new leader recover those.Leader handover via messages in the logAny messages carrying lower epochs than the latest epoch-bumping message will be ignored, which filters messages that the old leader might have still been appending to the log before it found out that it was superseded by another leader. If the old leader was attempting to commit a journal entry, but the message was appended after the epoch-bump message, that commit cannot happen: The new leader will (or might have already) recover the process without that journal entry and execute and commit that step. This mechanism ensures that any step / activity result is committed exactly once. No split brain view is possible.This mechanism also automatically resolves concurrent competition for leadership - the highest epoch will win, and late events are consistently ignored.Converged Single Binary #Restate is architected as a set of individual components that communicate with each other and make no assumptions about the whereabouts of their peers. A Restate binary can run every component or a subset of them; a set of components is described by a role.The default configuration is the converged mode, where every binary runs every role. In that case, you get a distributed architecture in a single binary. You can start more instances of the binary to form clusters. This mode is easy to use and efficient, because it also lets different components communicate efficiently through in-memory channels and caches whenever possible (e.g., log to processor).The roles and components of RestateHowever, you can of course also run it as a disaggregated setup, where different sets of nodes run different roles. That lets you separate control plane from data plane and pick your best trade-offs in terms of cost/durability/availability for metadata and data. For example:Deploy three nodes with the admin role across three different regions, ensure application and consensus metadata are disaster proof.Deploy six nodes with the Log-Server role across three availability zones, making sure data is replicated to tolerate zone outages.Deploy Ingress and Worker roles in one availability zone to strictly co-locate them with zone-local services.Restateâ€™s architecture gives you a great developer experience from the start (launching a single binary on your laptop) all the way to sophisticated distributed deployments (disaggregated distributed setups).Some Performance Numbers #How fast can a system like this be? The answer is, we donâ€™t really know, we have plenty more optimization we can do. Our main focus for this release was durability, resilience, and operational tooling.But even before any deep performance optimization, the system already pushes some pretty cool numbers, both latency- and throughput wise. Below are numbers from Restate 1.2. We measure the throughput / latency of the server against mock functions and activities, to put maximum stress on the server.Latency #Restate aims to keep latencies low, despite giving strong guarantees on durability (replication) and consistency (strong consensus on locking keys, workflow ids, etc.).Below are the numbers for durable functions with an increasing number of intermediate durable steps, running on a 3-way replicated cluster. Under low load, things are generally fast and a single step has a median latency of 3ms. Under high load, steps still have a median latency of 10ms after the initial workflow setup. Tail latencies under low load are a bit higher than we like (possibly caused by some Tokio / RocksDB issues) and we believe we can get these down in the future.LoadIntermediate StepsLatencyp50p90p99Low (10 concurrent clients)05ms34ms54ms315ms42ms69ms931ms57ms93ms2761ms106ms155msHigh (1200 concurrent clients)028ms41ms58ms358ms76ms98ms9116ms138ms163ms27283ms320ms356msOne thing you can observe here is that Restate is built to make durable steps cheap. An initial function or workflow invocation needs to check whether the workflow ID, idempotency key, or object key already exists and whether it is under execution. But once an invocation has been made, adding steps is just the equivalent of a conditional append to the log.Throughput #We ran a workflow of 9 intermediate durable steps (totalling 11 actions, including invoke/result), using 1200 concurrent clients to submit workflows.Restate pushes 94,286 actions (steps) per second, equalling 8,571 full workflows each second. The system maintains a p50 of 116.36ms and a p99 of 163.33ms for the full workflow! The p50 per step is 10ms.The experiment ran on AWS c6id.8xlarge nodes, which are admittedly beefy, but also deliver a throughput that most companies will not ever reach or exceed in their transactional load. And, if they exceed that, Restate still scales to more nodes through more partitions.Up next: a fast, flexible, state-of-the-art log #We mentioned that we built our own implementation of a distributed replicated log (called Bifrost), because we didnâ€™t find any of the existing logs suitable in terms of latency (single roundtrip, quorum replication with external consensus), durability (active-active with flexible quorums), flexibility (segmented log that can be dynamically reconfigured).The next post in this series will dig into all the nitty gritty details of how we built that log. This log itself is a marvel of engineering and one of the reasons Restate is as powerful as it is. If you are into distributed systems, you will enjoy that one for sure!Try it out! #We hope you find this work as exciting as we do. If you want to try this out, the quickstart, helps to get you to your first demo app (and give us a star on GitHub).To get right into the distributed fun, check this guide to running a cluster locally.Let us know what you think or ask questions in our community on Discord or Slack and get more deep content like this from us on X, LinkedIn, Bluesky, or via email.Restate is also available as a fully managed cloud service, if all you want is to use it and let us operate it.restate\nrelease\narchitecture\ndeployment",
    "summary": {
      "en": "**Summary of \"Building a Modern Durable Execution Engine from First Principles: How Restate Works\"**\n\nThis article, written by Stephan Ewen, Ahmed Farghal, and Till Rohrmann, is the second in a series about Restate, a new Durable Execution Engine. Unlike traditional systems, Restate does not rely on external databases or logs and aims to provide high durability and operational efficiency.\n\n**Key Points:**\n\n1. **Unified Log Architecture**: Restate simplifies distributed coordination by using a log-based runtime, improving performance compared to existing systems like Postgres.\n\n2. **System Structure**:\n   - **Restate Server**: Acts like a message broker, receiving events and dispatching them to application services.\n   - **Application Services**: Durable functions that execute application logic, manage events, and maintain state.\n\n3. **Bidirectional Communication**: The server maintains a connection with services, allowing them to perform durable actions like journaling and state modification.\n\n4. **Data Storage**: Restate uses an embedded log for new events and stores data in RocksDB, which is periodically backed up to an object store for durability.\n\n5. **Latency Management**: To address the latency of object storage, Restate implements a replication layer that ensures low-latency operations.\n\n6. **Partitioned Scale-Out Model**: The system scales by using partitions, each with its own log and event processor, which operate independently to handle invocations.\n\n7. **Control Plane and Data Plane**: A control plane coordinates the overall system, managing failures and configurations, while the data plane handles logs and event processing.\n\n8. **Performance**: Early tests show promising low latencies (around 3ms to 10ms) and high throughput (over 94,000 actions per second), even under heavy load.\n\n9. **Future Improvements**: The next article will focus on the development of Restate's log implementation, called Bifrost, which aims to enhance performance and flexibility.\n\nOverall, Restate is designed to provide a better developer experience and operational efficiency for building durable execution systems. It's available as a managed cloud service, making it accessible for various users.",
      "ko": "ì´ ê¸€ì€ Stephan Ewen, Ahmed Farghal, ê·¸ë¦¬ê³  Till Rohrmannì´ ì‘ì„±í•œ Restateë¼ëŠ” ìƒˆë¡œìš´ ë‚´êµ¬ì„± ì‹¤í–‰ ì—”ì§„ì— ê´€í•œ ë‘ ë²ˆì§¸ ê¸°ì‚¬ì…ë‹ˆë‹¤. RestateëŠ” ì „í†µì ì¸ ì‹œìŠ¤í…œê³¼ ë‹¬ë¦¬ ì™¸ë¶€ ë°ì´í„°ë² ì´ìŠ¤ë‚˜ ë¡œê·¸ì— ì˜ì¡´í•˜ì§€ ì•Šìœ¼ë©°, ë†’ì€ ë‚´êµ¬ì„±ê³¼ ìš´ì˜ íš¨ìœ¨ì„±ì„ ëª©í‘œë¡œ í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n\nRestateì˜ ì£¼ìš” íŠ¹ì§• ì¤‘ í•˜ë‚˜ëŠ” í†µí•© ë¡œê·¸ ì•„í‚¤í…ì²˜ì…ë‹ˆë‹¤. ì´ ì•„í‚¤í…ì²˜ëŠ” ë¡œê·¸ ê¸°ë°˜ì˜ ëŸ°íƒ€ì„ì„ ì‚¬ìš©í•˜ì—¬ ë¶„ì‚° ì¡°ì •ì„ ë‹¨ìˆœí™”í•˜ê³ , ê¸°ì¡´ ì‹œìŠ¤í…œì¸ Postgresì— ë¹„í•´ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. Restate ì„œë²„ëŠ” ë©”ì‹œì§€ ë¸Œë¡œì»¤ì²˜ëŸ¼ ì‘ë™í•˜ì—¬ ì´ë²¤íŠ¸ë¥¼ ìˆ˜ì‹ í•˜ê³  ì• í”Œë¦¬ì¼€ì´ì…˜ ì„œë¹„ìŠ¤ì— ì „ë‹¬í•©ë‹ˆë‹¤. ì• í”Œë¦¬ì¼€ì´ì…˜ ì„œë¹„ìŠ¤ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡œì§ì„ ì‹¤í–‰í•˜ê³ , ì´ë²¤íŠ¸ë¥¼ ê´€ë¦¬í•˜ë©°, ìƒíƒœë¥¼ ìœ ì§€í•˜ëŠ” ë‚´êµ¬ì„± ìˆëŠ” ê¸°ëŠ¥ì…ë‹ˆë‹¤.\n\nì„œë²„ëŠ” ì„œë¹„ìŠ¤ì™€ì˜ ì—°ê²°ì„ ìœ ì§€í•˜ì—¬ ì €ë„ë§ì´ë‚˜ ìƒíƒœ ìˆ˜ì •ê³¼ ê°™ì€ ë‚´êµ¬ì„± ìˆëŠ” ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤. RestateëŠ” ìƒˆë¡œìš´ ì´ë²¤íŠ¸ë¥¼ ìœ„í•œ ë‚´ì¥ ë¡œê·¸ë¥¼ ì‚¬ìš©í•˜ê³ , ë°ì´í„°ë¥¼ RocksDBì— ì €ì¥í•©ë‹ˆë‹¤. ì´ ë°ì´í„°ëŠ” ì£¼ê¸°ì ìœ¼ë¡œ ê°ì²´ ì €ì¥ì†Œì— ë°±ì—…ë˜ì–´ ë‚´êµ¬ì„±ì„ ë³´ì¥í•©ë‹ˆë‹¤. ê°ì²´ ì €ì¥ì†Œì˜ ì§€ì—° ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ RestateëŠ” ë‚®ì€ ì§€ì—° ì‹œê°„ì„ ë³´ì¥í•˜ëŠ” ë³µì œ ê³„ì¸µì„ êµ¬í˜„í–ˆìŠµë‹ˆë‹¤.\n\nì‹œìŠ¤í…œì€ íŒŒí‹°ì…˜ì„ ì‚¬ìš©í•˜ì—¬ í™•ì¥ë˜ë©°, ê° íŒŒí‹°ì…˜ì€ ë…ë¦½ì ìœ¼ë¡œ ì‘ë™í•˜ëŠ” ë¡œê·¸ì™€ ì´ë²¤íŠ¸ í”„ë¡œì„¸ì„œë¥¼ ê°€ì§€ê³  ìˆì–´ í˜¸ì¶œì„ ì²˜ë¦¬í•©ë‹ˆë‹¤. ì œì–´ í‰ë©´ì€ ì „ì²´ ì‹œìŠ¤í…œì„ ì¡°ì •í•˜ë©°, ì‹¤íŒ¨ì™€ êµ¬ì„±ì„ ê´€ë¦¬í•˜ê³ , ë°ì´í„° í‰ë©´ì€ ë¡œê·¸ì™€ ì´ë²¤íŠ¸ ì²˜ë¦¬ë¥¼ ë‹´ë‹¹í•©ë‹ˆë‹¤. ì´ˆê¸° í…ŒìŠ¤íŠ¸ ê²°ê³¼, RestateëŠ” ë†’ì€ ë¶€í•˜ì—ì„œë„ ì•½ 3msì—ì„œ 10msì˜ ë‚®ì€ ì§€ì—° ì‹œê°„ê³¼ ì´ˆë‹¹ 94,000ê±´ ì´ìƒì˜ ë†’ì€ ì²˜ë¦¬ëŸ‰ì„ ë³´ì—¬ì£¼ê³  ìˆìŠµë‹ˆë‹¤.\n\nì•ìœ¼ë¡œì˜ ê°œì„  ì‚¬í•­ìœ¼ë¡œëŠ” Restateì˜ ë¡œê·¸ êµ¬í˜„ì¸ Bifrostì˜ ê°œë°œì— ì´ˆì ì„ ë§ì¶˜ ë‹¤ìŒ ê¸°ì‚¬ê°€ ì˜ˆì •ë˜ì–´ ìˆìœ¼ë©°, ì´ëŠ” ì„±ëŠ¥ê³¼ ìœ ì—°ì„±ì„ í–¥ìƒì‹œí‚¤ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì „ë°˜ì ìœ¼ë¡œ RestateëŠ” ë‚´êµ¬ì„± ìˆëŠ” ì‹¤í–‰ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ëŠ” ë° ìˆì–´ ë” ë‚˜ì€ ê°œë°œì ê²½í—˜ê³¼ ìš´ì˜ íš¨ìœ¨ì„±ì„ ì œê³µí•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ ì„œë¹„ìŠ¤ëŠ” ê´€ë¦¬í˜• í´ë¼ìš°ë“œ ì„œë¹„ìŠ¤ë¡œ ì œê³µë˜ì–´ ë‹¤ì–‘í•œ ì‚¬ìš©ìë“¤ì´ ì ‘ê·¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "0d3dbde9a74eb778",
    "title": {
      "en": "Ask HN: can Wireless-CarPlay dongles steal your data?",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": null,
    "score": 7,
    "by": "concerned_citi",
    "time": 1742905228,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "327ccb524a039975",
    "title": {
      "en": "Show HN: Cursor IDE now remembers your coding prefs using MCP",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": null,
    "score": 70,
    "by": "roseway4",
    "time": 1743173099,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "c1c0ec42735e15d9",
    "title": {
      "en": "Framework 13 AMD Setup with FreeBSD",
      "ko": "í”„ë ˆì„ì›Œí¬ 13 AMDì™€ FreeBSD",
      "ja": null
    },
    "type": "story",
    "url": "https://euroquis.nl/freebsd/2025/03/16/framework.html",
    "score": 33,
    "by": "hggh",
    "time": 1742909640,
    "content": "Framework 13 AMD Setup with FreeBSD\n\n      Mar 16, 2025\n      â€¢ adridg\n\n    The FreeBSD Foundation exists to support the\nFreeBSD community and the FreeBSD project. Some of its projects are\naimed at improving the experience of FreeBSD on specific hardware.\nThere is an ongoing, and expanding, laptop experience project.\nTo expand that project further, the foundation has provided Framework\nlaptops to a bunch of developers working on the FreeBSD laptop and desktop\nexperience. Iâ€™m one of those developers, and here are some initial notes on the process.\nThe notes assume experience with FreeBSD.\n\n  Some disclaimers up front: the FreeBSD foundation is a lot like KDE e.V.,\nwhich supports the KDE community and project. I wear a board hat for KDE e.V.,\nbut on the FreeBSD side Iâ€™m â€œjust a ports developerâ€. Of course, the ports\nI try to work on are the KDE ones, so thereâ€™s a happy synergy here.\n\n  An anonymous donor sponsored these machines. While I am part of the\nFreeBSD donations@ team, I was not involved in the overall decision-making\naround this donation.\n\nThe machine I got is a Framework 13 with an AMD 7000 series CPU.\nThatâ€™s not the very-very latest one, which has a Ryzen 300 series in it,\nbut it is at least 3 CPU generations newer than any other machine I have.\nFor me in particular of interest is that it has\nthe same GPU series, AMD Polaris 12,  as my FreeBSD 14-STABLE desktop machine, so I can\nshare experimentation with graphics drivers between them.\n\nI picked the 2.8K display with rounded corners, because thatâ€™s potentially\nan interesting edge-case for the KDE Plasma 6 desktop; if thereâ€™s any\nfunny-stuff needed for those corners, then we need to know about it.\n\nLetâ€™s Get Physical\n\nAlthough itâ€™s completely irrelevant for the long-term use of the laptop,\nIâ€™ve got to hand it to the Framework folks: the packaging is really nice.\nRecyclable cardboard, well-laid-out, understandable boxes. I donâ€™t often\nget a â€œhuh, thatâ€™s cleverâ€ reaction when unpacking consumer electronics.\n\nThereâ€™s a screwdriver included, cunningly hidden beneath\nthe do-it-yourself-installation memory modules. Thatâ€™s clever.\n\nWhen it comes to putting the machine together, the installation guide with videos is both\ncomprehensive and easy-to-follow. â€œPut DDR5 SO-DIMM modules in corresponding socketsâ€\nand â€œinsert NVMe into socketâ€ is straightforward, I do that all the time when (re)building desktop machines.\n\nThe bezel, on the other hand â€¦\n\nThe bezel around the screen is just a thin bit of plastic. I got a red one,\nbecause FreeBSD (there is no KDE Blue option). It is essential to\nplace it correctly, with all the screen-cables nicely aligned. I did not,\nand just clicked the bezel in place, pushed down on it and then closed the laptop,\nâ€œper the instructionsâ€. Except the bezel stuck out about 2mm, and on re-opening the\nlaptop, it just about tore the bezel in half.\n\nAfter 20 tricky minutes I could get the laptop open again and removed the bezel,\nrepaired it, and tried again. I donâ€™t really have a suggestion to improve the\nbezel installation except â€œtry very carefully to close the laptop a bit, re-open,\nclose a bit further, re-open, â€¦â€ until itâ€™s clear that the lid closes properly.\nTake some time to (re)route the cables to the screen so that they are as flat\nas possible.\n\nAccessories\n\nThe little modules for the Framework laptop are pretty nifty. Iâ€™m already\nthinking I should have gotten an additional USB-C one. I selected one unusual module,\nRJ-45 wired ethernet, because my experience with FreeBSD and WiFi is\nnot a good one. However, thatâ€™s what this whole laptop project is for.\nThe FreeBSD Foundation has already funded work on laptop WiFi,\nso itâ€™s probably over-cautiousness on my part.\n\nWith all the physical bits in place, the big questionâ€¦\n\nWill it run Doom?\n\n  Framework 13 AMD DIY build with FreeBSD 14.2 boot screen. It sure looks like it could be Doom.\n\nOf course. Donâ€™t be silly.\n\nWill it run FreeBSD?\n\nYes, but that takes a little bit of effort. Download a FreeBSD 14.2 image\nand write it to a USB stick on some other machine. Leave it on your desk for now.\n\nBoot the Framework laptop for the first time and let it do memory training and whatnot.\nDo not connect any devices and let it complain that thereâ€™s nothing to boot.\n\nReboot, still with nothing attached, and spam F2 during boot. You have to\ndo this to get to the EFI shell / system configuration before it tries\nto boot anything. Disable secure boot. Linuxes have a signed GRUB shim\nnowadays, or other bits and pieces so they work with secure boot.\nFreeBSD 14.2 does not, yet.\n\nNow insert the USB stick, reboot, and go through the installer process.\nItâ€™s a text installer (still, as I still havenâ€™t built FreeBSD support in Calamares)\nand gets you to a working system in about 5 minutes. Having the wired ethernet\nhelps avoid any trouble here.\n\nReboot after installation and you can get a text console. All that\ntechnology for a late-80s user experience.\n\nWill it run X11?\n\nYes, but the 14.2-RELEASE Errata point\nout that DRM kernel modules do not work if you grab the pre-built ones.\nThis was true on March 12th 2025, so:\n\n  Run pkg to install the package manager (initially it is a stub)\n  Run pkg install git to install git (this pulls in a surprising amount of other stuff)\n  Get the system sources (with git)\n  Rebuild the world and install it\n  Get the ports tree (with git)\n  Build graphics/drm-61-kmod from ports (just make ; make install, and the port itself is a real quick build)\n  Build graphics/gpu-firmware-amd-kmod from ports, remember FLAVOR=polaris12 for the GPU in this laptop (otherwise the default flavor is built)\n\nAfter that, enable the amdgpu module in rc.conf, or load it by hand.\nAny old X11 stuff will do, but I suggest installing x11/kde and x11/sddm.\n\nWill it run KDE Plasma 6 Wayland?\n\nHahaha. No. But yes.\n\nKDE Plasma 6 on Wayland in general works. But on this specific machine,\nwith this specific grapics card, Plasma starts, all the processes\nof a KDE Plasma desktop are running, and the screen displays a single\nwhite text-cursor in the upper-left corner.\n\nItâ€™s not this-specific-machine, either, since I have a desktop\nwith Intel CPU and an AMD RX550 video card that behaves the same.\n\nLast time I dug into KWin internals in an attempt to figure this out\nI ended up with â€œsome part of the OpenGL stack is lyingâ€ and then\ngave up. Now with a fresh laptop that just cries out for a modern\ndesktop, Iâ€™m going to try again.",
    "summary": {
      "en": "**Summary of Framework 13 AMD Setup with FreeBSD**\n\nThe FreeBSD Foundation supports the FreeBSD community and is currently enhancing the FreeBSD experience on laptops, including Framework laptops provided to developers. The author received a Framework 13 laptop with an AMD 7000 series CPU, which is useful for testing graphics drivers due to its similar GPU to their desktop machine.\n\nThe laptop's packaging was praised for its clever design, but the installation of the screen bezel was tricky, requiring careful alignment to avoid damage.\n\nThe author chose a wired ethernet module instead of WiFi, due to past issues with FreeBSD and WiFi. They confirmed that FreeBSD 14.2 can be installed on the laptop, but it requires disabling secure boot and using a USB stick for installation.\n\nAfter installation, the system boots into a basic text console. While X11 works after some setup, running KDE Plasma 6 on Wayland does not function properly on this machine, displaying only a text cursor. The author plans to investigate this further.",
      "ko": "FreeBSD ì¬ë‹¨ì€ FreeBSD ì»¤ë®¤ë‹ˆí‹°ë¥¼ ì§€ì›í•˜ë©°, í˜„ì¬ ê°œë°œìì—ê²Œ ì œê³µë˜ëŠ” Framework ë…¸íŠ¸ë¶ì„ í¬í•¨í•´ ë…¸íŠ¸ë¶ì—ì„œ FreeBSD ê²½í—˜ì„ í–¥ìƒì‹œí‚¤ê³  ìˆìŠµë‹ˆë‹¤. í•„ìëŠ” AMD 7000 ì‹œë¦¬ì¦ˆ CPUê°€ ì¥ì°©ëœ Framework 13 ë…¸íŠ¸ë¶ì„ ë°›ì•˜ìœ¼ë©°, ì´ ë…¸íŠ¸ë¶ì€ ë°ìŠ¤í¬íƒ‘ ê¸°ê³„ì™€ ìœ ì‚¬í•œ GPU ë•ë¶„ì— ê·¸ë˜í”½ ë“œë¼ì´ë²„ í…ŒìŠ¤íŠ¸ì— ìœ ìš©í•©ë‹ˆë‹¤.\n\në…¸íŠ¸ë¶ì˜ í¬ì¥ì€ ë…ì°½ì ì¸ ë””ìì¸ìœ¼ë¡œ í˜¸í‰ì„ ë°›ì•˜ì§€ë§Œ, í™”ë©´ ë² ì ¤ ì„¤ì¹˜ëŠ” ê¹Œë‹¤ë¡œì›Œì„œ ì†ìƒì„ í”¼í•˜ê¸° ìœ„í•´ ì‹ ì¤‘í•œ ì •ë ¬ì´ í•„ìš”í–ˆìŠµë‹ˆë‹¤. í•„ìëŠ” ê³¼ê±° FreeBSDì™€ WiFi ê´€ë ¨ ë¬¸ì œë¡œ ì¸í•´ ìœ ì„  ì´ë”ë„· ëª¨ë“ˆì„ ì„ íƒí–ˆìŠµë‹ˆë‹¤. FreeBSD 14.2ê°€ ì´ ë…¸íŠ¸ë¶ì— ì„¤ì¹˜ë  ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì„ í™•ì¸í–ˆì§€ë§Œ, ì„¤ì¹˜ë¥¼ ìœ„í•´ì„œëŠ” ë³´ì•ˆ ë¶€íŒ…ì„ ë¹„í™œì„±í™”í•˜ê³  USB ìŠ¤í‹±ì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.\n\nì„¤ì¹˜ í›„ ì‹œìŠ¤í…œì€ ê¸°ë³¸ í…ìŠ¤íŠ¸ ì½˜ì†”ë¡œ ë¶€íŒ…ë©ë‹ˆë‹¤. X11ì€ ì•½ê°„ì˜ ì„¤ì • í›„ ì‘ë™í•˜ì§€ë§Œ, Waylandì—ì„œ KDE Plasma 6ì„ ì‹¤í–‰í•˜ë©´ ì œëŒ€ë¡œ ì‘ë™í•˜ì§€ ì•Šê³  í…ìŠ¤íŠ¸ ì»¤ì„œë§Œ í‘œì‹œë©ë‹ˆë‹¤. í•„ìëŠ” ì´ ë¬¸ì œë¥¼ ë” ì¡°ì‚¬í•  ê³„íšì…ë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "44e224563abf2956",
    "title": {
      "en": "I asked police to send me their public surveillance footage of my car",
      "ko": "ë‚´ ì°¨ CCTV ìš”ì²­!",
      "ja": null
    },
    "type": "story",
    "url": "https://cardinalnews.org/2025/03/28/i-drove-300-miles-in-rural-virginia-then-asked-police-to-send-me-their-public-surveillance-footage-of-my-car-heres-what-i-learned/",
    "score": 449,
    "by": "bookofjoe",
    "time": 1743164046,
    "content": "<iframe title=\"Everlit Audio Player\" src=\"https://everlit.audio/embeds/artl_eQjyeH7pmVP?client=wp&amp;client_version=1.10.5\" width=\"100%\" height=\"130px\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen=\"\"></iframe>Two police officers walked into a doughnut shop.\n\nItâ€™s not the opening line of a joke; itâ€™s what I saw as I was working on an early draft of this story in March at the Staunton Dunkinâ€™, about a quarter mile from where my vehicle was captured on a Flock camera in January and February coming back from my trips to Cardinalâ€™s Roanoke office.\n\nTheir eyes may have strayed to the racks of Boston creme, lemon-filled and coconut-covered doughnuts as they strode to the counter with purpose, but they were here for something else.\n\nSurveillance footage.\n\nwindow.zone_load_1502249140 = function(z, d) { if (!d.count) document.getElementById('zone_load_1502249140').style.display = 'none'; };\n\n\t\t\t\tDon't miss another story! Sign up for Cardinalâ€™s free daily newsletter.\n\nDelivered to your inbox every day at 5 a.m.\n\n\t\t\t\t\t\tSign up\n\n\t\tThe research for State of Surveillance showed that you canâ€™t drive anywhere without going through a town, city or county thatâ€™s using public surveillance of some kind, mostly license plate reading cameras. I wondered how often I might be captured on camera just driving around to meet my reporters. Would the data over time display patterns that would make my behavior predictable to anyone looking at it?\n\nSo I took a daylong drive across Cardinal Country and asked 15 law enforcement agencies, using Freedom of Information Act requests, to provide me with the Flock LPR footage of my vehicle. My journey took me over 300 miles through slices of the communities those agencies serve, including the nearly 50 cameras they employ. And this journey may take me to one more place: an April Foolâ€™s Day hearing in a courtroom in Roanoke. There, a judge will be asked to rule on a motion to declare the footage of the public to be beyond the reach of the public.\n\nBut while Roanoke and Botetourt and two other police agencies denied my request for that footage, nine agencies complied and searched their data for signs of me passing through.\n\nHereâ€™s what I found.\n\nCheck out our podcast episode on Jeffâ€™s surveillance investigation.\n\n   Watch    February 13, 2025, I left Staunton around 7:30 in the morning to head toward Roanoke. Richmond Avenue, on the outskirts of the city, is probably the way most people make their way out of town to interstates 64 and 81. Itâ€™s a significant crossroad of the regionâ€™s major east-west and north-south highways.\n\nStaunton maintains at least one of its six Flock cameras on a local intersection just shy of the cluster of on- and off-ramps. It makes surveillance-sense to position cameras to see whoâ€™s coming in and whoâ€™s leaving your town at such a singular crossroad.\n\nI was not captured by a Flock camera there, though.\n\nAs part of its services, Flock advises police on where to place its tech. The top priority appears to be places of entry and exit around the community, notably near the main highways. Itâ€™s possible that Staunton doesnâ€™t have a camera taking pictures of who is leaving town; itâ€™s also possible my vehicleâ€™s plate was blocked by heavy morning traffic and so no photo could be taken.\n\nIt was a cold morning, but truckers and car drivers were behaving on the morning commute. Staying on I-81, I passed through Augusta, Rockbridge and Botetourt counties, which between them have at least eight Flock cameras. I didnâ€™t think any would be pointed at the main highway because currently Flock canâ€™t place its cameras on state property.\n\nNinety uneventful minutes later, I pulled into Roanoke to go to the Cardinal office and visit my Roanoke members of our own Cardinal team â€” which, in an unintentional irony in this story, we refer to as The Flock.\n\nI got into town just after 9:15 a.m. I know that because a Roanoke Police Department Flock camera captured my car traveling southbound down Williamson Road near the Salem Avenue intersection at 9:16:09 a.m. (That photo, as well as another, were provided by the Staunton police, as part of their arrangement to access other agenciesâ€™ data in their Flock searches.)\n\nYou can see from the image below exactly what Flock technology captures: a decent shot of the back of any vehicle that passes, a readable image of the license plate.\n\nPart of Flockâ€™s proprietary tech determines the make and model of the vehicle and also notes if there are bumper stickers, bike racks, any other unique markings that would help identify that vehicle. That generates a â€œvehicle fingerprintâ€ for every car or truck, which none of the agencies I FOIAâ€™d would provide me. That fingerprint could prove helpful in the case where a witness or other camera captured some non-license-plate information about a vehicle, like specific bumper stickers or a roof rack.\n\nI parked my car on Church Avenue, walked to the office and logged in to our morning news meeting. Some of our reporters were there in person; others began popping up on the screen from their beats in Danville, Martinsville and Bristol. We talked about our dayâ€™s work. Afterward, I drove around town just to see if Iâ€™d be picked up in a residential area. I started in Gainsboro. Snow covered the ground around the homes on Gilmer Avenue. I did not notice any cameras.\n\nI crossed town to Marshall Avenue and a neighborhood within a few blocks of the YMCA, and then on to another neighborhood sitting next to Interstate 581, which reaches across the town like a tight belt of loud traffic. Looking between homes, I saw the Roanoke Star, perched over trees frosted with ice not yet melted.\n\nEach of these neighborhoods had different backstories and histories you could see in the architecture of their homes, in the cars that parked on their streets. One thing they had in common on that cold morning: They were all very quiet. And I did not see any surveillance cameras.\n\nLater, I received no images of my car in those places. Flock can be used to monitor public space in suspected high-crime areas, which has earned it the wrath of rights organizations including the ACLU. Because Roanoke has only five cameras, according to contracts we received from the city, itâ€™s my guess they are not yet focusing on specific populations or neighborhoods.\n\nAfter those brief stops, I left town mid-morning. I canâ€™t tell you exactly when, and Iâ€™ll tell you why thatâ€™s relevant.\n\nWhen I eventually received data from the Staunton Police about my trip, I noticed that Flock cameras had photographed my vehicle in similar locations within both Staunton and Roanoke at similar times on another day, January 29. If you asked me today if I knew whether I had made a trip to the Roanoke office on Jan. 29, I would hesitate before I could answer. I would have to check my calendar and emails to be able to say that I was there, with certainty.\n\nBut the police would have known, if they wanted to, without asking for any kind of warrant or court order.\n\nCheck out the other stories in this ongoing series.\n\n\t\t\t\t\t\tCity of Roanoke, Botetourt County sheriff go to court over FOIA request\n\n\t\t\t\t\t\tState of Surveillance: Everyoneâ€™s watching\n\n\t\t\tFranklin County does have four Flock cameras, but my vehicleâ€™s image was not captured by any of them. Until I came into town, I was staying on routes 220 and 57.\n\nU.S. 220 was a misty spectacle on Feb. 13. Ice made trees sag. Thick limbs and branches crashed under the weight, closing the right lane of the highway in some places. Snow covered shaded places around buildings, but the roads were mostly clear, and traffic moved along. Nearing noon, milder temps had caused fog to rise up from the hollers. As I drove south past Boones Mill and Trump Town USA, I knew I would not trigger that townâ€™s lone operational Flock camera. Itâ€™s set up to catch northbound traffic.\n\nI entered Martinsville via Fayette Street. Martinsville has dozens of Flock cameras, 48 according to the contracts Cardinal News gathered, so I expected to be picked up multiple times. However, my vehicle was detected only once.\n\nEven the police chief, Rob Fincher, was surprised. He was open to running the test again, but I wasnâ€™t trying for statistical accuracy; I wanted this to be a record of a single day. There are lots of things that can get in the way of taking a clear picture, including glare and shadow and other things (cars in this case) getting between your camera and your subject. Some of those things may have been at play on that particular day.\n\nA Martinsville Flock camera did spot my vehicle at 12:11 p.m. eastbound on the way into town from its perch near the corner of West Church Street and South Memorial Boulevard.\n\nTwenty-two minutes later I was spreading cream cheese on a bagel and coffee at the Ground Floor. (I know the time because I took my own photo, not because of a surveillance camera timestamp.)\n\nThe place was bustling. On most tables stood a little rubbery Jesus toy. On one wall hangs a long roll of brown paper where people casually write their prayers. I was reminded that some people believe youâ€™re being watched 24/7 by a higher power, though Iâ€™d argue thereâ€™s likely a pretty high trust factor about how that surveillance might be utilized. I touched base with our Martinsville reporter Dean-Paul Stephens, and then headed for Danville.\n\n* * *\n\nSpeaking of trust and ethics: two weeks later, Lt. Greg Jones called me at the Roanoke office. The Amherst County Sheriffâ€™s Office had a question about my request for data about my vehicle.\n\nâ€œYou werenâ€™t trying to spy on a cheating wife or something like that, were you?â€ he asked.\n\nI assured him that I wasnâ€™t. As Cardinal Executive Director Luanne Rife points out in her column on Sunshine Week, public agencies donâ€™t have to agree with why youâ€™re asking for their public information. The idea is that it belongs to you already. They are under legal obligation to provide it to you.\n\nNot to say this question didnâ€™t cause some thought and conversation in the newsroom. Public surveillance data like this could indeed be used to stalk an ex; it could also be used by a person suspicious their ex is stalking them to see if their exâ€™s vehicle actually could be found on the same roads as theirs and at the same times, which could then be used to secure a protective order or even open a criminal investigation. It could be used by private investigators to find bail jumpers and missing persons. Now imagine all those requests coming in to the local police agencyâ€¦\n\nThe only reason it hadnâ€™t happened yet was because people really didnâ€™t know they could do that. Suddenly the cops could be in the position to find themselves spending hours looking up public surveillance for citizens with all sorts of reasons to utilize the data.\n\nSo was this a foolâ€™s errand I was on? I didnâ€™t think so. The police in over 80 of our local communities had chosen to start photographing citizens in their vehicles in public and sharing this with other agencies in our region and beyond, even out of state. I wasnâ€™t the one running over 500 searches a month on its citizens, as the Roanoke police were doing. And who knows who they were running those searches on, and why?\n\n* * *\n\nBy the time I reached Danville, the weather was almost warm. The sun was out and glancing through the empty trees along Craghead Street and in through the plate glass windows of Links Coffee House.\n\nI found out after requesting data from Danville that while they did have a contract with Flock, they had not yet installed the Flock cameras, according to Matt Bell, the cityâ€™s PR specialist.\n\nThe coffee was good. The casual conversation surveillance was rich with interesting dialogues. But I had miles to go. It was just before 2 p.m. Time to get moving again.\n\n* * *\n\nTraffic in Lynchburg was heavy around 3:30 p.m. as I drove north along U.S. 29 Business. I figured there might be at least some of Lynchburgâ€™s Flock cameras along the very busy Business 29, also known in that area as Wards Road.\n\nJust south of Liberty University, a Flock camera picked up my car near Wards Ferry Road. Lynchburg has at least a dozen Flock cameras, according to contracts we got from them during our reporting for our first State of Surveillance story. I figured one might be on this stretch of road.\n\nBy this point in the afternoon, the novelty of the day was wearing off. I got back on main route 29 and headed north.\n\nAlong the rest of the way, I passed through Amherst County, which has four Flock cameras; Nelson County, which has none; and Augusta County, with two cameras. Since I stuck to the main roads, U. S. 29 and then I-64, the chances of running into a camera were low. If Iâ€™d pulled off onto a main county road, things might have been different.\n\nIn March, Amherst would conduct a search and be unable to find my vehicle. Same with Augusta County.\n\nAt 4:59 p.m., I exited the highway onto Richmond Avenue in Staunton. This time a Flock camera spotted my vehicle and got a clear picture. I went home and ordered pizza.\n\nWhich brings me back to the cops in the coffee shop, a few weeks later.\n\n* * *\n\nAs I mentioned, the two police officers were not interested in doughnuts, or even coffee. They asked to speak to the manager. The counter person explained that the manager was at the other store across town. They asked if they could speak to that person on the phone.\n\nIt was then I noticed that a person who had come in with them was part of this conversation.\n\nFrom what I could gather, because I didnâ€™t pull out my press badge and start asking questions, the young woman with them had been in some kind of incident; and that the police had determined that maybe some of the video footage that Dunkin takes of its drive-through may have caught the other car as it passed on the road beyond; or maybe the offending vehicle had come through the drive-through.\n\nIn a few minutes, the officers and the woman were guided behind the counter to review footage.\n\nThis scene somehow made me feel optimistic about how weâ€™re already using such technology. It still operates under the notion that not all data belongs to the police. They have to ask, or convince a judge to give them a court order.\n\nYet just glancing at the footage I have included in this story, itâ€™s also a little creepy to see how as few as four to six pictures, properly time- and date-stamped, can establish patterns that could enable someone to know with some likelihood how they could intercept me on my way to work one morning.\n\nThere are two differences between police use of other visual data (like a storeâ€™s security video) and Flockâ€™s gathering of public footage (such as my car). In that first case, thereâ€™s a crime involved. And the privately captured video is granted to police voluntarily and for a good reason. Itâ€™s not theirs to take and examine at their leisure.\n\nPublic-facing LRP cameras like Flockâ€™s, on the other hand, capture vast amounts of data unrelated to any criminal activity. And thereâ€™s zero oversight outside of the law enforcement community.This goes back to the idea that footage taken of me in public, non-investigative in nature, can be considered investigative and not subject to a public information request, and concerns me.\n\nThe idea that a law enforcement agency will claim the images that we see in this story are â€œinvestigativeâ€ in nature â€” and need to be protected from me â€” tells me that they are worried about something else. What is it?\n\nItâ€™s a paradigm shift where we go from having an expectation of privacy even in public spaces to its inverse. Not only do we not have a right to privacy in public; we donâ€™t even have a right to see ourselves as the government and police might see us â€” a set of still moments in place and time from which they, not us, can decide what our story is.\n\nWe want to know what you think! Tell us what you think about surveillance or share your experiences here.\n\n\t\t\t\tEnjoying our free stories?\n\nDonate today to help Cardinal News remain free for everyone.\n\n\t\t\t\tOne-time\n\n\t\t\t\tMonthly\n\n\t\t\t\tAnnually\n\n\t\t\tOne-time\n\n\t\t\t\t\t\t\t\t\t\t\t\t\t$150\n\n\t\t\t\t\t\t\t\t\t\t\t\t\t$200\n\n\t\t\t\t\t\t\t\t\t\t\t\t\t$500\n\n\t\t\t\t\t\t\t\t\t\t\t\tOther\n\n\t\t\t\t\t\t\t\t\t\t\t\tDonation amount\n\n\t\t\t\t\t\t\t\t\t\t\t\t\t$\n\n\t\t\tMonthly\n\n\t\t\t\t\t\t\t\t\t\t\t\t\t$15\n\n\t\t\t\t\t\t\t\t\t\t\t\t\t$20\n\n\t\t\t\t\t\t\t\t\t\t\t\t\t$50\n\n\t\t\t\t\t\t\t\t\t\t\t\tOther\n\n\t\t\t\t\t\t\t\t\t\t\t\tDonation amount\t\t\t\t\t\t\t\t\t\t\t\tper month\n\n\t\t\t\t\t\t\t\t\t\t\t\t\t$\n\n\t\t\tAnnually\n\n\t\t\t\t\t\t\t\t\t\t\t\t\t$150\n\n\t\t\t\t\t\t\t\t\t\t\t\t\t$200\n\n\t\t\t\t\t\t\t\t\t\t\t\t\t$500\n\n\t\t\t\t\t\t\t\t\t\t\t\tOther\n\n\t\t\t\t\t\t\t\t\t\t\t\tDonation amount\t\t\t\t\t\t\t\t\t\t\t\tper year\n\n\t\t\t\t\t\t\t\t\t\t\t\t\t$\n\n\t\t\tThanks for joining our flock!\n\n\t\t\tDonate Now\n\n\tRelated stories\n\n\t\tTagged: Redbird Stories,State of Surveillance",
    "summary": {
      "en": "The text describes a personal investigation into the use of surveillance technology, specifically license plate reading (LPR) cameras, in public spaces. The author, while working on a story, noticed police officers entering a doughnut shop to review surveillance footage. This prompted him to explore how often he might be captured on camera during his travels for work.\n\nHe took a daylong trip across various counties, requesting footage from 15 law enforcement agencies through Freedom of Information Act requests. His journey revealed that while some agencies denied his requests, many complied and provided data about his vehicle. He noted the locations and times where his car was captured on camera, emphasizing how surveillance can reveal patterns of behavior.\n\nThe author reflected on the implications of such technology, indicating it could be used to track individuals without their knowledge. He expressed concerns about privacy, as public surveillance data can be accessed by police without a warrant, raising questions about oversight and individual rights. Ultimately, the investigation highlighted a shift in expectations of privacy in public spaces, suggesting that people may no longer have the right to view how they are monitored by the government.",
      "ko": "ì´ ê¸€ì€ ê³µê³µ ì¥ì†Œì—ì„œ ê°ì‹œ ê¸°ìˆ , íŠ¹íˆ ë²ˆí˜¸íŒ ì¸ì‹ ì¹´ë©”ë¼ì˜ ì‚¬ìš©ì— ëŒ€í•œ ê°œì¸ì ì¸ ì¡°ì‚¬ë¥¼ ë‹¤ë£¨ê³  ìˆë‹¤. ì €ìëŠ” ì´ì•¼ê¸°ë¥¼ ì‘ì—…í•˜ë˜ ì¤‘ ê²½ì°°ê´€ë“¤ì´ ë„ë„› ê°€ê²Œì— ë“¤ì–´ê°€ ê°ì‹œ ì˜ìƒì„ ê²€í† í•˜ëŠ” ëª¨ìŠµì„ ëª©ê²©í–ˆë‹¤. ì´ ê²½í—˜ì€ ê·¸ê°€ ì—…ë¬´ë¡œ ì´ë™í•˜ëŠ” ë™ì•ˆ ì–¼ë§ˆë‚˜ ìì£¼ ì¹´ë©”ë¼ì— í¬ì°©ë  ìˆ˜ ìˆëŠ”ì§€ë¥¼ íƒêµ¬í•˜ê²Œ ë§Œë“¤ì—ˆë‹¤.\n\nì €ìëŠ” í•˜ë£¨ ë™ì•ˆ ì—¬ëŸ¬ ì¹´ìš´í‹°ë¥¼ ì—¬í–‰í•˜ë©° ì •ë³´ê³µê°œë²•ì— ë”°ë¼ 15ê°œ ë²• ì§‘í–‰ ê¸°ê´€ì— ì˜ìƒì„ ìš”ì²­í–ˆë‹¤. ê·¸ì˜ ì—¬ì •ì—ì„œ ì¼ë¶€ ê¸°ê´€ì€ ìš”ì²­ì„ ê±°ë¶€í–ˆì§€ë§Œ, ë§ì€ ê¸°ê´€ì´ í˜‘ì¡°í•˜ì—¬ ê·¸ì˜ ì°¨ëŸ‰ì— ëŒ€í•œ ë°ì´í„°ë¥¼ ì œê³µí–ˆë‹¤. ê·¸ëŠ” ìì‹ ì˜ ì°¨ê°€ ì¹´ë©”ë¼ì— í¬ì°©ëœ ì¥ì†Œì™€ ì‹œê°„ì„ ê¸°ë¡í•˜ë©°, ê°ì‹œê°€ í–‰ë™ íŒ¨í„´ì„ ë“œëŸ¬ë‚¼ ìˆ˜ ìˆìŒì„ ê°•ì¡°í–ˆë‹¤.\n\nì €ìëŠ” ì´ëŸ¬í•œ ê¸°ìˆ ì˜ í•¨ì˜ì— ëŒ€í•´ ê³ ë¯¼í•˜ë©°, ê°œì¸ì´ ëª¨ë¥´ëŠ” ì‚¬ì´ì— ì¶”ì ë  ìˆ˜ ìˆë‹¤ëŠ” ì ì„ ì§€ì í–ˆë‹¤. ê·¸ëŠ” ê³µê³µ ê°ì‹œ ë°ì´í„°ê°€ ê²½ì°°ì— ì˜í•´ ì˜ì¥ ì—†ì´ ì ‘ê·¼ë  ìˆ˜ ìˆë‹¤ëŠ” ì ì—ì„œ ì‚¬ìƒí™œì— ëŒ€í•œ ìš°ë ¤ë¥¼ í‘œëª…í•˜ë©°, ê°ë…ê³¼ ê°œì¸ì˜ ê¶Œë¦¬ì— ëŒ€í•œ ì§ˆë¬¸ì„ ì œê¸°í–ˆë‹¤. ê²°êµ­, ì´ ì¡°ì‚¬ëŠ” ê³µê³µ ì¥ì†Œì—ì„œì˜ ì‚¬ìƒí™œ ê¸°ëŒ€ì¹˜ì˜ ë³€í™”ë¥¼ ê°•ì¡°í•˜ë©°, ì‚¬ëŒë“¤ì´ ì •ë¶€ì— ì˜í•´ ì–´ë–»ê²Œ ê°ì‹œë˜ëŠ”ì§€ë¥¼ ì•Œ ê¶Œë¦¬ê°€ ë” ì´ìƒ ì—†ì„ì§€ë„ ëª¨ë¥¸ë‹¤ëŠ” ì ì„ ì‹œì‚¬í–ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "957629cb9498aa3f",
    "title": {
      "en": "Japanese scientists create new plastic that dissolves in saltwater overnight",
      "ko": "ë°”ë‹¤ì—ì„œ ì‚¬ë¼ì§€ëŠ” í”Œë¼ìŠ¤í‹±",
      "ja": null
    },
    "type": "story",
    "url": "https://newatlas.com/materials/plastic-dissolves-ocean-overnight-no-microplastics/",
    "score": 138,
    "by": "bentobean",
    "time": 1743170950,
    "content": "Materials\n\n        New plastic dissolves in the ocean overnight, leaving no microplastics\n\nByMichael Irving\n\n        March 27, 2025\n\n    Facebook\n\n    Twitter\n\n    Flipboard\n\n    LinkedIn\n\n    Reddit\n\n        New plastic dissolves in the ocean overnight, leaving no microplastics\n\n            A sample sheet of the new biodegradable plasticRIKEN\n\n            View 2 Images\n\n                1/2\n\n            A sample sheet of the new biodegradable plasticRIKEN\n\n                2/2\n\n            An artist's impression of the new plastic, showing the strong bonds above the water and how they break down when submerged in saltwaterRIKEN\n\n        Plastics are durable and strong, which is great while theyâ€™re being used but frustrating when they end up in the environment. Scientists at RIKEN in Japan have developed a new type of plastic thatâ€™s just as stable in everyday use but dissolves quickly in saltwater, leaving behind safe compounds.The benefit of plastics is that theyâ€™re made with strong covalent bonds that hold their molecules together, meaning they take a lot of energy to break. This is why theyâ€™re so sturdy, long-lasting and perfect for everything from packaging to toys.But those same strong bonds become a problem after the useful life of a plastic product is over. That cup you used once and threw away will sit in landfill for decades, even centuries, before it fully breaks down. And when it does, it forms microplastic pieces that are turning up in all corners of the natural world, including our own bodies, where they wreak havoc on our health in ways weâ€™re only just beginning to understand.RIKEN researchers have now developed a new type of plastic that can work just as well as the regular stuff when itâ€™s needed, and break down readily into safe compounds when itâ€™s not. Itâ€™s made of what are known as supramolecular polymers, which have reversible bonds that function like sticky notes that can be attached, removed and reattached, according to the team.The team wanted to make a specific type of supramolecular polymer that would be strong enough for the usual uses of plastic, but could also be made to break down quickly when required, under mild conditions and leaving only non-toxic compounds.After screening a range of molecules, the researchers identified a particular combination that seemed to have the right properties â€“ sodium hexametaphosphate, which is a common food additive, and monomers based on guanidinium ions, which are used in fertilizers. When these two compounds are mixed together in water, they form a viscous material that can be dried to form plastics.A reaction between the two ingredients forms â€œsalt bridgesâ€ between the molecules that make the material strong and flexible, like conventional plastic. However, when theyâ€™re soaked in saltwater, the electrolytes unlock those bonds, and the material dissolves.\n\n        An artist's impression of the new plastic, showing the strong bonds above the water and how they break down when submerged in saltwaterRIKEN\n\n        In practice, the team found that the material was just as strong as normal plastic during use, and was non-flammable, colorless and transparent. Immersed in saltwater though, the plastic completely dissolved in about eight and a half hours.Thereâ€™s one major hurdle with any degradable plastic material of course: what if it comes into contact with the catalyst for its destruction before you want it to? A plastic cup is no good if certain liquids can dissolve it, after all.In this case, the team found that applying hydrophobic coatings prevented any early breaking down of the material. When you eventually want to dispose of it, a simple scratch on the surface was enough to let the saltwater back in, allowing the material to dissolve just as quickly as the non-coated sheets.While some biodegradable plastics can still leave behind harmful microplastics, this material breaks down into nitrogen and phosphorus, which are useful nutrients for plants and microbes. That said, too much of these can be disruptive to the environment as well, so the team suggests the best process might be to do the bulk of the recycling in specialized plants, where the resulting elements can be retrieved for future use.But if some of it does end up in the ocean, it will be far less harmful, and possibly even beneficial, compared to current plastic waste.A paper describing the research was published in the journal Science.Source: RIKEN",
    "summary": {
      "en": "Scientists at RIKEN in Japan have created a new type of plastic that dissolves in saltwater overnight without leaving harmful microplastics. This biodegradable plastic is made from supramolecular polymers, which have reversible bonds that allow them to be strong during use but break down easily when submerged in saltwater.\n\nThe new plastic is created by mixing sodium hexametaphosphate, a common food additive, with guanidinium ion-based monomers found in fertilizers. This combination forms a flexible and strong material that dissolves in about eight and a half hours in saltwater, breaking down into safe compounds like nitrogen and phosphorus, which can benefit plants and microbes.\n\nTo prevent the plastic from dissolving prematurely, researchers have developed hydrophobic coatings. This means the plastic can be used safely without breaking down until it is intentionally scratched to allow saltwater in for disposal.\n\nOverall, this new biodegradable plastic is a promising alternative to traditional plastics, as it poses less risk to the environment and can potentially be beneficial if it ends up in the ocean.",
      "ko": "ì¼ë³¸ RIKENì˜ ê³¼í•™ìë“¤ì´ ì†Œê¸ˆë¬¼ì— í•˜ë£»ë°¤ ë§Œì— ë…¹ì•„ë²„ë¦¬ëŠ” ìƒˆë¡œìš´ ì¢…ë¥˜ì˜ í”Œë¼ìŠ¤í‹±ì„ ê°œë°œí–ˆìŠµë‹ˆë‹¤. ì´ í”Œë¼ìŠ¤í‹±ì€ í•´ë¡œìš´ ë¯¸ì„¸í”Œë¼ìŠ¤í‹±ì„ ë‚¨ê¸°ì§€ ì•ŠëŠ” ìƒë¶„í•´ì„± ì†Œì¬ë¡œ, ì¬ì¡°í•© ê°€ëŠ¥í•œ ê²°í•©ì„ ê°€ì§„ ì´ˆë¶„ì í´ë¦¬ë¨¸ë¡œ ë§Œë“¤ì–´ì¡ŒìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ê²°í•© ë•ë¶„ì— ì‚¬ìš© ì¤‘ì—ëŠ” ê°•í•œ ì„±ì§ˆì„ ìœ ì§€í•˜ì§€ë§Œ, ì†Œê¸ˆë¬¼ì— ì ê¸°ë©´ ì‰½ê²Œ ë¶„í•´ë©ë‹ˆë‹¤.\n\nìƒˆë¡œìš´ í”Œë¼ìŠ¤í‹±ì€ ì¼ë°˜ì ì¸ ì‹í’ˆ ì²¨ê°€ë¬¼ì¸ í—¥ì‚¬ë©”íƒ€ì¸ì‚° ë‚˜íŠ¸ë¥¨ê³¼ ë¹„ë£Œì—ì„œ ë°œê²¬ë˜ëŠ” êµ¬ì•„ë‹ˆë””ëŠ„ ì´ì˜¨ ê¸°ë°˜ì˜ ë‹¨ëŸ‰ì²´ë¥¼ í˜¼í•©í•˜ì—¬ ë§Œë“¤ì–´ì§‘ë‹ˆë‹¤. ì´ ì¡°í•©ì€ ìœ ì—°í•˜ê³  ê°•í•œ ì¬ë£Œë¥¼ í˜•ì„±í•˜ë©°, ì†Œê¸ˆë¬¼ì—ì„œ ì•½ 8ì‹œê°„ ë°˜ ë§Œì— ë…¹ì•„ ì•ˆì „í•œ í™”í•©ë¬¼ì¸ ì§ˆì†Œì™€ ì¸ìœ¼ë¡œ ë¶„í•´ë©ë‹ˆë‹¤. ì´ í™”í•©ë¬¼ì€ ì‹ë¬¼ê³¼ ë¯¸ìƒë¬¼ì— ìœ ìµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\ní”Œë¼ìŠ¤í‹±ì´ ì¡°ê¸°ì— ë…¹ì§€ ì•Šë„ë¡ í•˜ê¸° ìœ„í•´ ì—°êµ¬ìë“¤ì€ ì†Œìˆ˜ì„± ì½”íŒ…ì„ ê°œë°œí–ˆìŠµë‹ˆë‹¤. ì´ ì½”íŒ… ë•ë¶„ì— í”Œë¼ìŠ¤í‹±ì€ ê³ ì˜ë¡œ ê¸ì–´ ì†Œê¸ˆë¬¼ì´ ë“¤ì–´ê°€ë„ë¡ í•˜ì§€ ì•ŠëŠ” í•œ ì•ˆì „í•˜ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nì „ë°˜ì ìœ¼ë¡œ ì´ ìƒˆë¡œìš´ ìƒë¶„í•´ì„± í”Œë¼ìŠ¤í‹±ì€ ì „í†µì ì¸ í”Œë¼ìŠ¤í‹±ì— ë¹„í•´ í™˜ê²½ì— ë¯¸ì¹˜ëŠ” ìœ„í—˜ì´ ì ê³ , ë°”ë‹¤ì— ë²„ë ¤ì¡Œì„ ë•Œë„ ìœ ìµí•  ìˆ˜ ìˆëŠ” ê°€ëŠ¥ì„±ì„ ì§€ë‹Œ ìœ ë§í•œ ëŒ€ì•ˆì…ë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "fba455c66aeef148",
    "title": {
      "en": "Apple needs a Snow Sequoia",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://reviews.ofb.biz/safari/article/1300.html",
    "score": 909,
    "by": "trbutler",
    "time": 1743114765,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "2c99611a163fcd4a",
    "title": {
      "en": "TV is watching you â€“ Companies inventing new ways to make money off your data",
      "ko": "TVê°€ ì§€ì¼œë³¸ë‹¤: ë°ì´í„°ë¡œ ëˆ ë²„ëŠ” ê¸°ì—…ë“¤",
      "ja": null
    },
    "type": "story",
    "url": "https://www.vox.com/technology/405879/roku-amazon-netflix-moana-disney",
    "score": 8,
    "by": "rmason",
    "time": 1743194265,
    "content": "TechnologyYour TV is watching youRoku, Amazon, and practically every company in the streaming business are inventing new ways to make money off your data.by  Adam Clark EstesMar 27, 2025, 7:30 PM GMT+9FacebookLinkGetty Images; Paige Vickers/VoxAdam Clark Estes is a senior technology correspondent at Vox and author of the User Friendly newsletter. Heâ€™s spent 15 years covering the intersection of technology, culture, and politics at places like The Atlantic, Gizmodo, and Vice.Roku City, the oddly alluring cityscape screen saver, scrolls across millions of idle TVs every day. Recently, an island paradise appeared in the picture. In the foreground, a floating billboard invited me to subscribe to Disney+ and watch Moana 2 at the press of a button on my remote. The convenience, I donâ€™t mind about the new era of ad-supported everything. The wiretapping, I do.Ads are obviously not new on TV. As long as weâ€™ve been watching shows on glowing boxes, weâ€™ve been watching commercials that provide the economic engine for the entire entertainment factory to operate. While streaming platforms offered a reprieve for a few years by charging monthly fees for commercial-free content, itâ€™s now practically impossible to watch TV without seeing some sort of marketing. Whatâ€™s happening more under the radar is that your TV is collecting data about you and your watching habits â€” sometimes by directly monitoring whatâ€™s on your screen â€” and serving you personalized ads on your TV or elsewhere.The screen that you once loved for private, uninterrupted Netflix-watching has become a big billboard that also spies on you.User FriendlyA weekly dispatch to make sure tech is working for you, instead of overwhelming you. From senior technology correspondent Adam Clark Estes.Email (required)Sign UpBy submitting your email, you agree to our Terms and Privacy Notice. This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply.This isnâ€™t just a Roku problem, although the company found itself in hot water when some users were recently required to watch a video ad â€” a Moana 2 trailer â€” before they could access their TVâ€™s home screen at all. Roku says this is just a test, but the fact that itâ€™s similar to a feature Amazon rolled out over a year ago on Prime Video suggests that ads are generally getting more brazen on streaming platforms. How you feel about it depends a lot on your mindset and feelings about privacy. Your TV wants your dataThe TV business traditionally included three distinct entities. Thereâ€™s the hardware, namely the TV itself; the entertainment, like movies and shows; and the ads, usually just commercials that interrupt your movies and shows. In the streaming era, tech companies want to control all three, a setup also known as vertical integration. If, say, Roku makes the TV, supplies the content, and sells the ads, then it stands to control the experience, set the rates, and make the most money. Thatâ€™s business!Roku has done this very well. Although it was founded in 2002, Roku broke into the market in 2008 after Netflix invested $6 million in the company to make a set-top box that enabled any TV to stream Netflix content. It was literally called the Netflix Player by Roku. Over the course of the next 15 years, Roku would grow its hardware business to include streaming sticks, which are basically just smaller set-top-boxes; wireless soundbars, speakers, and subwoofers; and after licensing its operating system to third-party TV makers, its own affordable, Roku-branded smart TVs. RelatedThe Wild West of streaming TV is here and itâ€™s freeWhile most people think of Roku as a hardware company, it actually transitioned into becoming an advertising company almost a decade ago. In the early days, you might see a banner ad on your home screen or a tile telling you to watch Game of Thrones on HBO Go. But after firing up a more serious ad business in 2016, Roku started selling targeted ads on the Roku Channel, a free, ad-supported TV (FAST) service across its devices in 2017. Roku even started making its own content, including a biopic of Weird Al Yankovic. Your TV is collecting data about you and your watching habits â€” sometimes by directly monitoring whatâ€™s on your screen â€” and serving you personalized ads on your TV or elsewhere.Things really ramped up when Roku started acquiring ad-tech companies, including Nielsenâ€™s Advanced Video Advertising business in 2021. This helped Roku gain new insights into its audience in order to target ads better and ultimately charge more money for those ads. At the end of 2024, Roku reported annual ad revenues of $3.5 billion, which accounted for 85 percent of its total revenue â€” far higher than its hardware business. Roku also has 90 million users â€” millions more than Apple TV+ â€” who have become a gold mine of data, not just about what they watch on TV but also who they are and what they like. Today, itâ€™s better to think of Roku not just as an advertising company or the folks who make cheap TVs and streaming sticks, but also as a data company with millions of detailed profiles.The magical world of Moana 2 made an appearance in Roku City when the movie hit streaming in March 2025. RokuRegarding the Moana 2 controversy, Roku said in a statement that the companyâ€™s growth â€œhas and will always require continuous testing and innovation across design, navigation, content, and our first-rate advertising products.â€ The statement also said, â€œOur recent test is just the latest example, as we explore new ways to showcase brands and programming while still providing a delightful and simple user experience.â€The shift toward ad-supported everything has been happening across the TV landscape. People buy new TVs less frequently these days, so TV makers want to make money off the TVs theyâ€™ve already sold. Samsung has Samsung Ads, LG has LG Ad Solutions, Vizio has Vizio Ads, and so on and so forth. Tech companies, notably Amazon and Google, have gotten into the mix too, not only making software and hardware for TVs but also leveraging the massive amount of data they have on their users to sell ads on their TV platforms. These companies also sell data to advertisers and data brokers, all in the interest of knowing as much about you as possible in the interest of targeting you more effectively. It could even be used to train AI.The wealth of Rokuâ€™s first-party data could be a gold mine for Amazon or Google, according to Laura Martin, an analyst at the investment bank Needham and Company. â€œRoku is the perfect size with a really strategic fit,â€ Martin told me, referring to a possible Amazon purchase. She added that Rokuâ€™s data could also be a boon for any company with AI ambitions, including OpenAI. â€œIf I was a large language model, this is data I would absolutely want to own.â€The streaming industry has faced a reckoning in recent years too: After years of prioritizing growth over all else, companies like Netflix and Disney finally had to start making money. Thatâ€™s resulted in those companies charging more, bundling services, and introducing cheaper ad-supported tiers. For better or worse, ads are the future of the TV business, just as they were its past. â€œFor consumers, itâ€™s definitely a complicated ecosystem,â€ said Jon Giegengack, founder of Hub Entertainment Research. Giegengack argues, though, that this ecosystem is ultimately better for consumers. In effect, thereâ€™s a streaming option that works for any budget, and ads fill in the gaps.RelatedThe streaming boom is overBut not everyone is thrilled to be bombarded by ads and to have their data passively harvested. More ads also means less attention paid to the content you want to watch and more to the ads these companies want you to see. Nevertheless, the trade-off is worth it to a lot of Americans. Some 43 percent of all streaming subscriptions in the United States were ad-supported by the end of last year, according to the market data firm Antenna. Even if you pay for an ad-free tier, youâ€™re contributing to the ad ecosystem by giving up your data to whatever streaming platforms you use and even the company that makes your TV.Is it possible to escape the ads? Breaking free from this ad prison is tough. Most TVs on the market today come with a technology called automatic content recognition (ACR) built in. This is basically Shazam for TV â€” Shazam itself helped popularize the tech â€” and gives smart TV platforms the ability to monitor what youâ€™re watching by either taking screenshots or capturing audio snippets while youâ€™re watching. (This happens at the signal level, not from actual microphone recordings from the TV.) Advertisers and TV companies use ACR tech to collect data about your habits that are otherwise hard to track, like if you watch live TV with an antenna. They use that data to build out a profile of you in order to better target ads. ACR also works with devices, like gaming consoles, that you plug into your TV through HDMI cables. Yash Vekaria, a PhD candidate at UC Davis, called the HDMI spying â€œthe most egregious thing we foundâ€ in his research for a paper published last year on how ACR technology works. And I have to admit that I had not heard of ACR until I came across Vekariaâ€™s research.â€œThey havenâ€™t kept it secret, but thereâ€™s no awareness about it,â€ Vekaria told me. â€œSo if people donâ€™t know, they will not question it.â€One surprising thingItâ€™s very difficult to watch streaming TV and avoid ads altogether these days. One, perhaps surprising option? Your local library. An app called Kanopy taps into the collections of local libraries across the country and has tons of great classic movies, documentaries, and indie films. Itâ€™s also free and ad-free â€” all you need is a library card.While ACR is popular across platforms, Roku is especially excited about the technology. Many of the companies that Roku has acquired in recent years have been working on ACR, and a Roku-owned company won an Emmy in 2023 for its work on the technology. Roku has also said that, because its share of the TV operating system market is 40 percent, the scale of its data collection capabilities is â€œunparalleled.â€ Unfortunately, you donâ€™t have much of a choice when it comes to ACR on your TV. You probably enabled the technology when you first set up your TV and accepted its privacy policy. If you refuse to do this, a lot of the functions on your TV wonâ€™t work. You can also accept the policy and then disable ACR on your TVâ€™s settings, but that could disable certain features too. In 2017, Vizio settled a class-action lawsuit for tracking users by default. If you want to turn off this tracking technology, hereâ€™s a good guide from Consumer Reports that explains how for most types of smart TVs.To be honest, after learning about all this in the past week or so, I havenâ€™t done anything revolutionary. I can actually buy into the idea that more relevant ads provide a better experience. I donâ€™t need to see ads for a dozen different eczema treatments while Iâ€™m watching YouTube TV, because I donâ€™t have eczema. Iâ€™m okay learning about a new toy for young kids, because I have a young kid. (Advertising to kids â€” or even letting your kids watch YouTube â€” is an entirely different matter.) So Iâ€™ve agreed to all the privacy policies and am enjoying my streaming content as the industry intended.But it does bug me, just on principle, that I have to let a tech company wiretap my TV in order to enjoy all of the deviceâ€™s features. If youâ€™re set on an ad-free TV experience, your best bet is to buy an old dumb TV off eBay and never connect it to a Roku, Amazon, or Google device. You can buy an antenna for network television, and a DVD player for movies. There are worse Y2K trends to resurrect than being completely offline for a few precious leisure hours.A version of this story was also published in the User Friendly newsletter. Sign up here so you donâ€™t miss the next one!See More: AmazonAmazon Prime VideoBig TechBusiness & FinanceCultureDisneyDisney PlusEven BetterLifeMediaMoneyNetflixStreamingTechnologyTVMost PopularKavanaugh and Barrett appear likely to break with the Supreme Courtâ€™s MAGA wingHow worried should legal immigrants be about Trumpâ€™s deportations?Your TV is watching youA marine biologist discovered something incredible in a beer bottle on the seafloorHow Trump wants to make one of the most dangerous jobs in America even worseToday, ExplainedUnderstand the world with a daily explainer plus the most compelling stories of the day, compiled by news editor Sean Collins.Email (required)Sign UpBy submitting your email, you agree to our Terms and Privacy Notice. This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply.Advertiser Content FromThis is the title for the native ad",
    "summary": {
      "en": "Streaming companies like Roku and Amazon are increasingly using viewer data to enhance their advertising strategies. While traditional TV has always included ads, streaming services initially offered ad-free experiences. However, many now incorporate ads, and TVs are collecting data on viewing habits to serve personalized advertisements.\n\nRoku, originally known for its hardware, has shifted towards becoming an advertising and data company, generating a significant portion of its revenue from ads. This shift is part of a broader trend in the industry where tech companies aim to control all aspects of the TV experienceâ€”from hardware to content to advertising. Many TVs now include technology that monitors what you watch, which raises privacy concerns.\n\nAs a result, ads are becoming more prevalent, with many viewers opting for ad-supported subscriptions. Despite some consumers being uncomfortable with data collection, others appreciate the targeted advertising. Alternatives, like free library streaming services, exist for those wanting to avoid ads altogether. Overall, the TV landscape is evolving, and viewers have to navigate a complex ecosystem where privacy and advertising intersect.",
      "ko": "Rokuì™€ ì•„ë§ˆì¡´ ê°™ì€ ìŠ¤íŠ¸ë¦¬ë° íšŒì‚¬ë“¤ì´ ì‹œì²­ì ë°ì´í„°ë¥¼ í™œìš©í•´ ê´‘ê³  ì „ëµì„ ê°•í™”í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì „í†µì ì¸ TVëŠ” í•­ìƒ ê´‘ê³ ë¥¼ í¬í•¨í•´ì™”ì§€ë§Œ, ìŠ¤íŠ¸ë¦¬ë° ì„œë¹„ìŠ¤ëŠ” ì²˜ìŒì—ëŠ” ê´‘ê³  ì—†ëŠ” ê²½í—˜ì„ ì œê³µí–ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ì œ ë§ì€ ì„œë¹„ìŠ¤ê°€ ê´‘ê³ ë¥¼ í¬í•¨í•˜ê³  ìˆìœ¼ë©°, TVëŠ” ì‹œì²­ ìŠµê´€ì— ëŒ€í•œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•´ ê°œì¸ ë§ì¶¤í˜• ê´‘ê³ ë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n\nRokuëŠ” ì›ë˜ í•˜ë“œì›¨ì–´ë¡œ ì•Œë ¤ì¡Œì§€ë§Œ, ì´ì œëŠ” ê´‘ê³ ì™€ ë°ì´í„° íšŒì‚¬ë¡œ ì „í™˜í•˜ê³  ìˆìœ¼ë©°, ê´‘ê³ ì—ì„œ ìƒë‹¹í•œ ìˆ˜ìµì„ ì˜¬ë¦¬ê³  ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ë³€í™”ëŠ” ê¸°ìˆ  íšŒì‚¬ë“¤ì´ TV ê²½í—˜ì˜ ëª¨ë“  ì¸¡ë©´, ì¦‰ í•˜ë“œì›¨ì–´, ì½˜í…ì¸ , ê´‘ê³ ë¥¼ í†µì œí•˜ë ¤ëŠ” ì‚°ì—…ì˜ ë„“ì€ íë¦„ì˜ ì¼í™˜ì…ë‹ˆë‹¤. í˜„ì¬ ë§ì€ TVëŠ” ì‹œì²­í•˜ëŠ” ë‚´ìš©ì„ ëª¨ë‹ˆí„°ë§í•˜ëŠ” ê¸°ìˆ ì„ í¬í•¨í•˜ê³  ìˆì–´ ê°œì¸ ì •ë³´ ë³´í˜¸ì— ëŒ€í•œ ìš°ë ¤ë¥¼ ë¶ˆëŸ¬ì¼ìœ¼í‚¤ê³  ìˆìŠµë‹ˆë‹¤.\n\nê·¸ ê²°ê³¼, ê´‘ê³ ê°€ ì ì  ë” ë§ì´ ë“±ì¥í•˜ê³  ìˆìœ¼ë©°, ë§ì€ ì‹œì²­ìë“¤ì´ ê´‘ê³  ì§€ì› êµ¬ë…ì„ ì„ íƒí•˜ê³  ìˆìŠµë‹ˆë‹¤. ì¼ë¶€ ì†Œë¹„ìë“¤ì€ ë°ì´í„° ìˆ˜ì§‘ì— ë¶ˆí¸í•¨ì„ ëŠë¼ì§€ë§Œ, ë‹¤ë¥¸ ì´ë“¤ì€ íƒ€ê²Ÿ ê´‘ê³ ë¥¼ ê¸ì •ì ìœ¼ë¡œ í‰ê°€í•©ë‹ˆë‹¤. ê´‘ê³ ë¥¼ ì™„ì „íˆ í”¼í•˜ê³  ì‹¶ì€ ì‚¬ëŒë“¤ì„ ìœ„í•´ ë¬´ë£Œ ìŠ¤íŠ¸ë¦¬ë° ì„œë¹„ìŠ¤ì™€ ê°™ì€ ëŒ€ì•ˆë„ ì¡´ì¬í•©ë‹ˆë‹¤. ì „ë°˜ì ìœ¼ë¡œ TV í™˜ê²½ì€ ë³€í™”í•˜ê³  ìˆìœ¼ë©°, ì‹œì²­ìë“¤ì€ ê°œì¸ ì •ë³´ ë³´í˜¸ì™€ ê´‘ê³ ê°€ ì–½íŒ ë³µì¡í•œ ìƒíƒœê³„ë¥¼ í—¤ì³ ë‚˜ê°€ì•¼ í•©ë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "b55976a927b034b2",
    "title": {
      "en": "The Biology of a Large Language Model",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://transformer-circuits.pub/2025/attribution-graphs/biology.html",
    "score": 96,
    "by": "frozenseven",
    "time": 1743171508,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "c8926decaaaf557b",
    "title": {
      "en": "Entropy Attacks",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://blog.cr.yp.to/20140205-entropy.html",
    "score": 79,
    "by": "todsacerdoti",
    "time": 1742905238,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "c21af1bea42bc001",
    "title": {
      "en": "MoirÃ© Than Meets the Eye: Uncovering the Quantum Potential of Phasons",
      "ko": "ëª¨ì´ë ˆì˜ ë¹„ë°€: íŒŒì†ì˜ ì–‘ì ì ì¬ë ¥",
      "ja": null
    },
    "type": "story",
    "url": "https://newscenter.lbl.gov/2025/03/24/moire-than-meets-the-eye/",
    "score": 17,
    "by": "gnabgib",
    "time": 1742834975,
    "content": "Key Takeaways\n\nResearchers have discovered that phasons, low-temperature quasiparticles found in crystal lattices, enable interlayer excitons to move at very low temperatures, when motion should stop.\nIn addition to contributing to foundational materials science knowledge, this discovery could help improve the stability of quantum technologies, such as using excitons as qubits.\nThe Molecular Foundryâ€™s Imaging and Manipulation of Nanostructures facility enabled the research.\n\nA moirÃ© pattern appears when you stack and rotate two copies of an image with regularly repeating shapes, turning simple patterns of squares or triangles into a groovy wave pattern that moves across the combined image in an optical delight.\nSimilarly, stacking single layers of sub-nanometer-thick semiconductor materials known as transition metal dichalcogenides (TMDs) can generate a moirÃ© potential, and novel electronic and optoelectronic properties may emerge between the layers.\nA moirÃ© potential is a â€œseascapeâ€ of potential energy with regularly repeating peaks and valleys. They were previously thought to be stationary. But a team of researchers at the Molecular Foundry at Lawrence Berkeley National Laboratory (Berkeley Lab) has uncovered something unusual about the moirÃ© potentials that emerge when TMDs are stacked: they are constantly moving, even at low temperatures.\nTheir discovery contributes to foundational knowledge in materials science. It also holds promise for advancing the stability of quantum technologies, as controlling moirÃ© potentials could help mitigate decoherence in qubits and sensors. Decoherence occurs when interference causes the quantum state and its information to be lost. The researchers published their findings in ACS Nano. The research is part of broader efforts at Berkeley Lab to advance quantum information systems by working across the quantum research ecosystem, from theory to application, to fabricate and test quantum-based devices and develop software and algorithms.\nResearch was led by Antonio Rossi, a former postdoctoral scholar under Molecular Foundry staff scientist Alex Weber-Bargioni. Rossi came back to Berkeley Lab to collaborate with Molecular Foundry staff scientist Archana Raja and make use of the tools in the Foundryâ€™s Imaging and Manipulation of Nanostructures facility.\nUnexpected Mobility in the MoirÃ© Seascape\nRajaâ€™s lab focuses on characterizing 2D materials using ultrafast lasers and optical spectroscopy at temperatures below -150Â°C. Exciting the layered TMD samples with a green pulsed laser energizes electrons and causes them to jump from their ground state to an excited one. Excited electrons leave behind a â€˜holeâ€™ with a positive charge, resulting in an electron-hole pair or exciton.\nExcitons are known to form within single-layered materials. However, excitons in the stacked two-layer system separate; electrons move into the tungsten disulfide layer, and positively charged holes get left behind in the tungsten diselenide layer. In the materials community, these special layer-jumping excitons are known as â€œinterlayer excitonsâ€ or IXs.\nâ€œYou would expect the moirÃ© valleys to act as traps,â€ Rossi said. â€œSo once the exciton is in there, itâ€™s basically trapped. Itâ€™s like sitting (in a valley), and all you can see is the mountains around you. Youâ€™re not moving.â€\nHowever, the team noticed that IXs explored the moirÃ©â€™s seascape despite being trapped within it. â€œIt takes very little energy to make this moirÃ© potential move, so the moirÃ© is moving around exactly like a stormy sea,â€ explained Rossi.\nâ€œWe showed that even at very cold temperatures, energy, and information are not as localized as you might expect. This happens because of a special â€˜mechanical propertyâ€™ of the MoirÃ© pattern,â€ said Raja. â€œThere are different ways to transport energy and information at different temperatures. This is a new way to do that.â€\nCollaborator Jonas Zipfel, a postdoctoral researcher in Rajaâ€™s group, worked with Rossi to automate their measurements to better understand the excitonsâ€™ motion. â€œJonasâ€™ work made it so we could seamlessly collect luminescence spectra, image, and lifetime (data), all of which enabled us to extract the diffusivity (movement) of the excitons,â€ said Raja.\nTo enable the observation of excitons in motion, Johannes Lischner and Indrajit Maity from Imperial College London used simulations to obtain snapshots of the moirÃ© potential â€œseascape.â€ They wanted to see how it behaved at different times.\nBy working with theorists Lischner and Maity, the research team arrived at the only logical explanation for their observations: the moirÃ© potential itself must be moving.\nCatching a Low-Temperature Quasiparticle in Motion\nThe researchers have proposed that a low-temperature quasiparticle called a phason enables the IX to move even while itâ€™s trapped. A quasiparticle is a quantum of energy within a crystal lattice; it has momentum and position and generally behaves like a particle. Phasons are quasiparticles thought to be naturally present in the moirÃ© potential.\nâ€œYou have the (interlayer) exciton surfing the moirÃ© and moving around,â€ Rossi stated. He believes the phason mediates the movement in the same way a surfboard allows a surfer to catch waves. â€œItâ€™s kind of carrying the exciton, in a way.â€\nRossi and team found the motion of the interlayer excitons within the moirÃ© potential to be angle and temperature-dependent. Their movement is at a maximum when TMD layers are parallel (when the molecules of the stacked layers align in the same direction).\nUnexpectedly, as the system temperature approaches zero, the motion of the interlayer excitons tapers gradually to a number that is slightly higher than zero, rather than coming to a complete halt. And while the number is small, itâ€™s significant.\nRossi explained, â€œIt was a surprise to find that this movement happens even at really low temperatures when everything is supposed to be frozen.â€\nHis next steps include investigating the superconductivity in twisted bilayer graphene that may arise from phason quasiparticles. Rossi is currently doing research for the Center of Nanotechnology Innovation at NEST, Institute of Technology Italy.\nRaja is interested in exploring different semiconductor and moirÃ© systems. Sheâ€™s also intrigued by the possibility of imaging phasons directly. She said, â€œOur evidence here is through the diffusion of the (interlayer) exciton, but we havenâ€™t necessarily caught the phason red-handed, yet.â€\nThe Molecular Foundry is a DOE Office of Science user facility at Berkeley Lab.\nThe work was supported, in part, by the DOE Office of Science.\n###\nLawrence Berkeley National Laboratory (Berkeley Lab) is committed to groundbreaking research focused on discovery science and solutions for abundant and reliable energy supplies. The labâ€™s expertise spans materials, chemistry, physics, biology, earth and environmental science, mathematics, and computing. Researchers from around the world rely on the labâ€™s world-class scientific facilities for their own pioneering research. Founded in 1931 on the belief that the biggest problems are best addressed by teams, Berkeley Lab and its scientists have been recognized with 16 Nobel Prizes. Berkeley Lab is a multiprogram national laboratory managed by the University of California for the U.S. Department of Energyâ€™s Office of Science.\nDOEâ€™s Office of Science is the single largest supporter of basic research in the physical sciences in the United States, and is working to address some of the most pressing challenges of our time. For more information, please visit energy.gov/science.\n\n        Tags:\n\n                  Materials\n                  Quantum",
    "summary": {
      "en": "**Summary:**\n\nResearchers have found that phasons, which are quasiparticles in crystal lattices, allow interlayer excitons to move even at very low temperatures, where movement usually stops. This discovery enhances our understanding of materials science and may improve the stability of quantum technologies, such as qubits.\n\nThe study, conducted at the Molecular Foundry, involved stacking thin semiconductor layers called transition metal dichalcogenides (TMDs). When these layers are stacked, they create a moving moirÃ© potential, which was previously thought to be stationary. This potential plays a key role in the movement of excitons, which are pairs of electrons and holes created when light interacts with these materials.\n\nThe researchers observed that excitons could move within the moirÃ© potential, which behaves like a dynamic seascape. They discovered that the excitonsâ€™ mobility is influenced by temperature and the alignment of the layers. Surprisingly, even close to absolute zero, the excitons still exhibit some movement instead of completely freezing.\n\nThis research opens new avenues for exploring other semiconductor systems and understanding the role of phasons in materials. The findings contribute to the broader goal of advancing quantum information systems.",
      "ko": "ì—°êµ¬ìë“¤ì€ ê²°ì • ê²©ìì—ì„œ ë°œìƒí•˜ëŠ” ì¤€ì…ìì¸ íŒŒì†(phason)ì´ ë§¤ìš° ë‚®ì€ ì˜¨ë„ì—ì„œë„ ì¸µê°„ ì—‘ì‹œí†¤ì´ ì›€ì§ì¼ ìˆ˜ ìˆë„ë¡ í•œë‹¤ëŠ” ì‚¬ì‹¤ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œ ì´ëŸ¬í•œ ì˜¨ë„ì—ì„œëŠ” ë¬¼ì§ˆì˜ ì›€ì§ì„ì´ ë©ˆì¶”ê²Œ ë˜ëŠ”ë°, ì´ ë°œê²¬ì€ ì¬ë£Œ ê³¼í•™ì— ëŒ€í•œ ì´í•´ë¥¼ ë†’ì´ê³  íë¹„íŠ¸ì™€ ê°™ì€ ì–‘ì ê¸°ìˆ ì˜ ì•ˆì •ì„±ì„ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆëŠ” ê°€ëŠ¥ì„±ì„ ì œì‹œí•©ë‹ˆë‹¤.\n\nì´ ì—°êµ¬ëŠ” ë¶„ì ì—°êµ¬ì†Œì—ì„œ ì§„í–‰ë˜ì—ˆìœ¼ë©°, ì „ì´ ê¸ˆì† ë‹¤ì¹¼ì½”ê²í™”ë¬¼(TMD)ì´ë¼ê³  ë¶ˆë¦¬ëŠ” ì–‡ì€ ë°˜ë„ì²´ ì¸µì„ ìŒ“ëŠ” ë°©ì‹ìœ¼ë¡œ ì´ë£¨ì–´ì¡ŒìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ì¸µë“¤ì´ ìŒ“ì´ë©´ ì •ì§€í•´ ìˆë‹¤ê³  ì—¬ê²¨ì¡Œë˜ ì›€ì§ì´ëŠ” ëª¨ì•„ë ˆ ì ì¬ë ¥ì´ í˜•ì„±ë©ë‹ˆë‹¤. ì´ ì ì¬ë ¥ì€ ë¹›ì´ ì´ëŸ¬í•œ ë¬¼ì§ˆê³¼ ìƒí˜¸ì‘ìš©í•  ë•Œ ìƒì„±ë˜ëŠ” ì „ìì™€ ì •ê³µì˜ ìŒì¸ ì—‘ì‹œí†¤ì˜ ì´ë™ì— ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤.\n\nì—°êµ¬ìë“¤ì€ ì—‘ì‹œí†¤ì´ ë§ˆì¹˜ ë™ì ì¸ ë°”ë‹¤ í’ê²½ì²˜ëŸ¼ í–‰ë™í•˜ëŠ” ëª¨ì•„ë ˆ ì ì¬ë ¥ ë‚´ì—ì„œ ì´ë™í•  ìˆ˜ ìˆìŒì„ ê´€ì°°í–ˆìŠµë‹ˆë‹¤. ê·¸ë“¤ì€ ì—‘ì‹œí†¤ì˜ ì´ë™ì„±ì´ ì˜¨ë„ì™€ ì¸µì˜ ì •ë ¬ì— ì˜í•´ ì˜í–¥ì„ ë°›ëŠ”ë‹¤ëŠ” ê²ƒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ë†€ëê²Œë„ ì ˆëŒ€ ì˜ë„ì— ê°€ê¹Œìš´ ì˜¨ë„ì—ì„œë„ ì—‘ì‹œí†¤ì€ ì™„ì „íˆ ì–¼ì–´ë¶™ì§€ ì•Šê³  ì¼ë¶€ ì›€ì§ì„ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.\n\nì´ ì—°êµ¬ëŠ” ë‹¤ë¥¸ ë°˜ë„ì²´ ì‹œìŠ¤í…œì„ íƒìƒ‰í•˜ê³  ì¬ë£Œì—ì„œ íŒŒì†ì˜ ì—­í• ì„ ì´í•´í•˜ëŠ” ìƒˆë¡œìš´ ê¸¸ì„ ì—´ì–´ì¤ë‹ˆë‹¤. ì´ëŸ¬í•œ ë°œê²¬ì€ ì–‘ì ì •ë³´ ì‹œìŠ¤í…œì„ ë°œì „ì‹œí‚¤ë ¤ëŠ” ë” ë„“ì€ ëª©í‘œì— ê¸°ì—¬í•©ë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "83b73cf6b28b436f",
    "title": {
      "en": "Are Levi's from Amazon different from Levi's from Levi's?",
      "ko": "ì•„ë§ˆì¡´ ë¦¬ë°”ì´ìŠ¤, ì§„ì§œì¸ê°€?",
      "ja": null
    },
    "type": "story",
    "url": "https://nymag.com/strategist/article/levis-amazon-jeans-testing.html",
    "score": 120,
    "by": "randycupertino",
    "time": 1743164306,
    "content": "strategist investigates\n\n                Mar. 26, 2025\n\n          Are Leviâ€™s From Amazon Different From Leviâ€™s From Leviâ€™s?\n\n            By\n        Erin Schwartz,\n          a Strategist writer covering dÃ©cor, gardening, and garment care.\n          They previously worked as an editor at Garage magazine.\n\n                Photo-Illustration: The Strategist; Photos: Retailers\n\n        Welcome to Jeans Month on the Strategist, where weâ€™re obsessively vetting denim â€” from trying on every pair at the Gap to asking dozens of stylish people about their favorite fits. For more, head to ourJeans Month hub.\n\n  The Strategist recently received a mysterious tip â€” the tipster had bought a pair of Leviâ€™s jeans from Amazon that felt notably different from (and worse than) a pair that came directly from Leviâ€™s. Iâ€™ve heard versions of the same theory over the years â€” not just for Leviâ€™s and Amazon but from buyers of brand-name tank tops, mattresses, and T-shirts who were convinced that what theyâ€™d gotten from a cheaper retailer was lower quality than the version sold elsewhere under the same name.\n\n  As the Strategistâ€™s resident materials expert, I was on the case. I acquired two pairs each of our most-recommended jeans(womenâ€™s Wedgies and Ribcages and the classic menâ€™s 501s) â€” one pair ordered from Amazon, one pair sent by Leviâ€™s for each style. I was careful to match up the same washes to prevent differences in distressing or fabric treatment from skewing the results. Still, I was skeptical. It didnâ€™t make sense: Why would Leviâ€™s maintain separate supply chains for different retailers? I pulled the jeans out of their plastic packaging expecting them to be indistinguishable. They were not.\n\n    The denim looked slightly different.\n\n        {\n          \"@id\": \"#articleSchema\",\n          \"image\": {\n            \"@context\": \"http://schema.org\",\n            \"@type\": \"ImageObject\",\n            \"creditText\": \"Author\",\n            \"caption\": \"The color difference between non-Amazon Ribcage denim (above) and Amazon Ribcage denim (below).\",\n            \"contentUrl\": \"https://pyxis.nymag.com/v1/imgs/3c8/745/c5dbd00a5d3b4fb447d8e2637774ae245b-IMG-4783.2x.rvertical.w570.jpg\",\n            \"width\": \"1140\",\n            \"height\": \"1426\"\n          }\n        }\n\n      The color difference between non-Amazon Ribcage denim (above) and Amazon Ribcage denim (below).\n      Photo: Author\n\n  The first thing I noticed: The washes looked different. The most pronounced were the Ribcage jeans in a medium blue called â€œJazz Popâ€ â€” the pair from Amazon had a smoother handfeel and more even color, while the non-Amazon pair felt bumpier with small flecks of higher-contrast fading, an effect I associate with acid washing. The Wedgies from Amazon had a bumpier feel as well, and the 501s from Amazon were a hint darker, closer to indigo than medium blue.\n\n    I brought the jeans to a testing lab.\n\n  To figure out whether these aesthetic variations made for differences in quality, I took all the jeans to the testing lab of F.I.T.â€™s Textile Development and Marketing Department. The pairs were mixed and relabeled to obscure which one came from which retailer; lab assistant Cesar Saavedra stamped and snipped out samples, which were then weighed, pipetted with bleach, and clamped into a blue metal machine that exerted hundreds of pounds of force to rip the denim against the grain before releasing with a pneumatic hiss.\n\n  Based on the results, â€œthe denim in each of these six pairs is different,â€ said Margaret Bishop, an adjunct professor in the department. â€œItâ€™s all strong. Youâ€™re not getting a cheap product.â€ But in a blind test, none of the jeans was identical.\n\n    One pair of non-Amazon Leviâ€™s was lighter weight.\n\n  Back at the office, I reconciled my data with my denim scraps to interpret the results. There were some outliers â€” most of the denim weighed 13 to 14 ounces per square yard except for a pair of non-Amazon 501s, which was 30 percent lighter than its analogue. A pair of non-Amazon Ribcages was significantly less resistant to tearing. But for the most part, one source didnâ€™t significantly outperform the other. In fact, the jeans from Amazon did slightly better on average, but with a six-jean sample size, take that with a grain of salt. The aesthetic differences also didnâ€™t correlate to the jeansâ€™ strength. Bishop attributed the bumpier handfeel of a couple of the pairs to the level of twist in the yarn, but it didnâ€™t make them weaker. (A colorfastness test confirmed the two Jazz Pop Ribcages were dyed differently.)\n\n    Ultimately, the Amazon Leviâ€™s werenâ€™t worse quality.\n\n  It seemed the tipster was half right. The tests confirmed a lot of variability between two pairs of the same jeans â€” you could buy the same style from Amazon and Leviâ€™s and feel a difference. But it didnâ€™t add up to gaps in quality; there was no indication that the Leviâ€™s from Amazon were worse.\n\n        {\n          \"@id\": \"#articleSchema\",\n          \"image\": {\n            \"@context\": \"http://schema.org\",\n            \"@type\": \"ImageObject\",\n            \"creditText\": \"Author\",\n            \"caption\": \"A denim sample undergoes a tensile strength test at FIT.\",\n            \"contentUrl\": \"https://pyxis.nymag.com/v1/imgs/6a3/8a6/c5d2ea1b06dc41ddfdb0fd140e4b5a581e-IMG-4762.2x.rvertical.w570.jpg\",\n            \"width\": \"1140\",\n            \"height\": \"1426\"\n          }\n        }\n\n      A denim sample undergoes a tensile strength test at FIT.\n      Photo: Author\n\n  Leviâ€™s sources its fabric from dozens of mills across the world, from luxury supplierCandianiin Italy to sites in India, Bangladesh, Mexico, and Turkey. The six pairs I tested were manufactured in three places: Cambodia, Macau, and Mexico. The companyâ€™s supply chain is vast, and to some extent, it makes sense that jeans made to the same specifications from different mills, dye facilities, and factories would result in different products. ï»¿\n\n  This is especially true for washes and distressing, a notoriously fiddly process. â€œWash houses get a formula â€” a recipe, if you will â€” of how the denim is supposed to be washed. You might have different machinery, you might have slightly different chemicals,â€ says Maxine BÃ©dat, author of the jeans study Unraveled. Some distressing â€” whiskering, fraying â€” is done by hand. Just as â€œeverybody making a recipe doesnâ€™t come out with the same pie,â€ small differences in production will add up to different-looking jeans.\n\n  â€œThe bigger the brand and the more channels in which itâ€™s sold, the more diverse quality and fabric youâ€™re going to see,â€ says Angela Velasquez, the executive editor of SJ Denim. If you want to minimize variation between pairs of jeans, she says to look for a â€œsmaller, niche brand,â€ which is more likely to have a tighter supply chain and thus fewer differences in fabric and fit between pairs.\n\n  Do you have to worry about this if youâ€™re just looking for a good pair of jeans? Not necessarily. According to BÃ©dat, the way to get the most out of your denim is to â€œreally spend time thinking about what actually works and fits,â€ which will probably involve going into a store in person. But Iâ€™ve found no evidence of a plot to offload worse denim onto Amazon. â€œI truthfully think the only consumers that really care about all the nitty-gritty and will know what any of this means are the true denim heads,â€ says Velasquez. And theyâ€™re getting their denim from Kaihara.\n\n      The denim I tested\n\n      (Buy from either retailer.)\n\n                Leviâ€™s Wedgie High Waist Straight Leg Jeans - Christina\n\n    $98\n\n      $98\n\n at Amazon\n\n      $98\n\n at Levi's\n\n    @media screen and (max-width: 1179.9px) {\n      .page-header .disclaimer-text_revenue,\n      .section-header .disclaimer-text_revenue\n       {\n        display: block;\n      }\n    }\n    @media screen and (min-width: 1180px) {\n      .tertiary .disclaimer-text_revenue {\n        display: block;\n      }\n    }\n\n   {\"@context\":\"http://schema.org\",\"@type\":\"Product\",\"name\":\"Levi's Wedgie High Waist Straight Leg Jeans - Christina\",\"image\":\"https://pyxis.nymag.com/v1/imgs/ca8/149/75eaef417998204d44776340cc31f102e8.jpg\",\"gtin12\":\"196524418497\",\"brand\":{\"@type\":\"Brand\",\"name\":\"Levi's\"},\"offers\":[{\"@type\":\"Offer\",\"price\":98,\"priceCurrency\":\"USD\",\"url\":\"https://www.amazon.com/dp/B0B192W56J?tag=thestrategistsite-20&ascsubtag=__st0328aam__cm8opcv6700000igxq9l2pmnp__260260________________\"},{\"@type\":\"Offer\",\"price\":98,\"priceCurrency\":\"USD\",\"url\":\"https://click.linksynergy.com/deeplink?id=OHlcvPYhHQM&mid=53220&murl=https%3A%2F%2Fwww.levi.com%2FUS%2Fen_US%2Fclothing%2Fwomen%2Fjeans%2Fstraight%2Fwedgie-straight-fit-womens-jeans%2Fp%2F349640178&u1=[st0328aam][cm8opcv6700000igxq9l2pmnp][219367][][][][][][][][]\"}],\"offerCount\":2}\n\n        @media screen and (min-width: 768px) {\n          .product-grid .product-grid-item .price-detail-secondary {\n            height: 16px;\n          }\n        }\n\n                Leviâ€™s Ribcage Straight Ankle Jeans - Jazz Pop\n\n    $56\n\n    $98\n\n      now\n      43% off\n\n      $56\n\n at Amazon\n\n      $98\n\n at Levi's\n\n    @media screen and (max-width: 1179.9px) {\n      .page-header .disclaimer-text_revenue,\n      .section-header .disclaimer-text_revenue\n       {\n        display: block;\n      }\n    }\n    @media screen and (min-width: 1180px) {\n      .tertiary .disclaimer-text_revenue {\n        display: block;\n      }\n    }\n\n   {\"@context\":\"http://schema.org\",\"@type\":\"Product\",\"name\":\"Levi's Ribcage Straight Ankle Jeans - Jazz Pop\",\"image\":\"https://pyxis.nymag.com/v1/imgs/c5d/565/990fa24584cddb5d26b353b56cb35958d8-jazz-pop.jpg\",\"gtin12\":\"195901201240\",\"brand\":{\"@type\":\"Brand\",\"name\":\"Levi's\"},\"offers\":[{\"@type\":\"Offer\",\"price\":56,\"priceCurrency\":\"USD\",\"url\":\"https://www.amazon.com/dp/B096T4BCRQ?tag=thestrategistsite-20&ascsubtag=__st0328aam__cm8opcv6700000igxq9l2pmnp__260264________________\"},{\"@type\":\"Offer\",\"price\":98,\"priceCurrency\":\"USD\",\"url\":\"https://click.linksynergy.com/deeplink?id=OHlcvPYhHQM&mid=53220&murl=https%3A%2F%2Fwww.levi.com%2FUS%2Fen_US%2Fclothing%2Fwomen%2Fjeans%2Fstraight%2Fribcage-straight-ankle-womens-jeans%2Fp%2F726930117&u1=[st0328aam][cm8opcv6700000igxq9l2pmnp][259945][][][][][][][][]\"}],\"offerCount\":2}\n\n        @media screen and (min-width: 768px) {\n          .product-grid .product-grid-item .price-detail-secondary {\n            height: 16px;\n          }\n        }\n\n                Leviâ€™s 501 Original Fit Menâ€™s Jeans - Medium Stonewash\n\n    $49\n\n    $80\n\n      now\n      38% off\n\n      $49\n\n at Amazon\n\n      $56\n\n at Levi's\n\n    @media screen and (max-width: 1179.9px) {\n      .page-header .disclaimer-text_revenue,\n      .section-header .disclaimer-text_revenue\n       {\n        display: block;\n      }\n    }\n    @media screen and (min-width: 1180px) {\n      .tertiary .disclaimer-text_revenue {\n        display: block;\n      }\n    }\n\n   {\"@context\":\"http://schema.org\",\"@type\":\"Product\",\"name\":\"Leviâ€™s 501 Original Fit Menâ€™s Jeans - Medium Stonewash\",\"image\":\"https://pyxis.nymag.com/v1/imgs/798/d78/a1800f62761f0df777b47ba75ae582e349-stonewash.png\",\"brand\":{\"@type\":\"Brand\",\"name\":\"Leviâ€™s\"},\"offers\":[{\"@type\":\"Offer\",\"price\":49.29,\"priceCurrency\":\"USD\",\"url\":\"https://www.amazon.com/dp/B0018OOWRE?tag=thestrategistsite-20&ascsubtag=__st0328aam__cm8opcv6700000igxq9l2pmnp__260269________________\"},{\"@type\":\"Offer\",\"price\":55.65,\"priceCurrency\":\"USD\",\"url\":\"https://click.linksynergy.com/deeplink?id=OHlcvPYhHQM&mid=53220&murl=https%3A%2F%2Fwww.levi.com%2FUS%2Fen_US%2Fclothing%2Fmen%2Fjeans%2Fstraight%2F501-original-fit-mens-jeans%2Fp%2F005010193&u1=[st0328aam][cm8opcv6700000igxq9l2pmnp][260268][][][][][][][][]\"}],\"offerCount\":2}\n\n          get the strategist newsletter\n          Actually good deals, smart shopping advice, and exclusive discounts.\n\n            Email\n\n          This site is protected by reCAPTCHA and the Google\n          Privacy Policy and\n          Terms of Service apply.\n\n        Vox Media, LLC Terms and Privacy Notice\n        By submitting your email, you agree to our Terms and Privacy Notice and to receive email correspondence from us.\n\n    More From The Strategist\n\n              Whatâ€™s the Difference Between a Pair of $30 Jeans and $300 Jeans?\n\n              I Spent 3 Hours at the Jellycat Diner\n\n              What Jennifer Aniston Canâ€™t Live Without\n\n              The State of the Status Hand Soap\n\n  The Strategistis designed to surfaceuseful, expert recommendations for things to buy across the vast e-commerce landscape. Every product is independently selected by our team of editors, whomyou can read abouthere. We update links when possible, but note that deals can expire and all prices are subject to change.\n\n    Tags:\n\n            the strategist\n\n            jeans month\n\n            fashion\n\n            unisex apparel\n\n            strategist investigates\n\n            strategist most popular\n\n          More\n\n        Show\n\n    Leave a Comment\n\n      Are Leviâ€™s From Amazon Different From Leviâ€™s From Leviâ€™s?\n\n    const freeLayoutsInstances = [\n      'ecom-article',\n      'ecom-products',\n      'non-monetizable'\n    ];\n    const paywalledLayoutsInstances = ['paywalled-article'];\n    const layoutInstance = document.querySelector('html').getAttribute('data-layout-uri').split('/instances/')[1].replace('@published', '');\n    const siteSlug = 'strategist';\n    const keywords = [\"the strategist\",\"jeans month\",\"fashion\",\"unisex apparel\",\"strategist investigates\",\"strategist most popular\"]; // This is set by handlebars in the server.\n    const featureTypes = window._nymPermutive?.article?.featureTypes;\n    const freeConditions = {\n      isStrategist: !paywalledLayoutsInstances.includes(layoutInstance) && siteSlug === 'strategist',\n      isFreeLayout: freeLayoutsInstances.includes(layoutInstance),\n      hasExcludePaywallTags: /paywall exclude/i.test(keywords.join(',')),\n      isEcomm: featureTypes && featureTypes.includes('ecomm')\n    };\n    const structuredData = {\n      '@context': 'http://schema.org',\n      '@id': '#articleSchema',\n      hasPart: {\n        '@type': 'WebPageElement',\n        cssSelector: '.article-content',\n        isAccessibleForFree: false\n      },\n      isAccessibleForFree: false\n    };\n    for (const condition of Object.keys(freeConditions)) {\n      if (!freeConditions[condition]) continue;\n      structuredData.isAccessibleForFree = true;\n      structuredData.hasPart.isAccessibleForFree = true\n      break;\n    }\n    const ldJsonScript = document.createElement('script');\n    ldJsonScript.type = \"application/ld+json\";\n    ldJsonScript.innerHTML = JSON.stringify(structuredData);\n    document.head.appendChild(ldJsonScript);",
    "summary": {
      "en": "**Summary: Are Leviâ€™s From Amazon Different From Leviâ€™s From Leviâ€™s?**\n\nIn a recent exploration during \"Jeans Month,\" the Strategist investigated whether Levi's jeans purchased from Amazon are of lower quality than those bought directly from Levi's. After receiving a tip about quality differences, the author tested pairs of popular Levi's styles from both retailers. \n\nKey findings included:\n- The jeans from Amazon and Levi's had noticeable aesthetic differences, such as variations in color and texture, but these did not indicate a significant difference in quality.\n- Testing at a lab showed that while the denim from both sources varied, most pairs performed similarly in terms of strength and durability.\n- Levi's sources fabric from various global mills, which can lead to differences in production quality and appearance.\n\nUltimately, the assessment indicated that while there might be some differences between Levi's jeans from different retailers, the quality of jeans from Amazon is not necessarily worse than those from Levi's own store. \n\nFor those looking for jeans, the focus should be on fit and style rather than solely on the retailer.",
      "ko": "ìµœê·¼ \"ì²­ë°”ì§€ì˜ ë‹¬\"ì„ ë§ì•„, ì „ëµê°€ë“¤ì€ ì•„ë§ˆì¡´ì—ì„œ êµ¬ë§¤í•œ ë¦¬ë°”ì´ìŠ¤ ì²­ë°”ì§€ê°€ ë¦¬ë°”ì´ìŠ¤ ë§¤ì¥ì—ì„œ ì§ì ‘ êµ¬ë§¤í•œ ê²ƒë³´ë‹¤ í’ˆì§ˆì´ ë‚®ì€ì§€ ì¡°ì‚¬í–ˆìŠµë‹ˆë‹¤. í’ˆì§ˆ ì°¨ì´ì— ëŒ€í•œ ì œë³´ë¥¼ ë°›ì€ ì €ìëŠ” ë‘ íŒë§¤ì²˜ì—ì„œ ì¸ê¸° ìˆëŠ” ë¦¬ë°”ì´ìŠ¤ ìŠ¤íƒ€ì¼ì˜ ì²­ë°”ì§€ë¥¼ í…ŒìŠ¤íŠ¸í–ˆìŠµë‹ˆë‹¤.\n\nì£¼ìš” ë°œê²¬ ì‚¬í•­ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. ì•„ë§ˆì¡´ê³¼ ë¦¬ë°”ì´ìŠ¤ì—ì„œ íŒë§¤í•˜ëŠ” ì²­ë°”ì§€ëŠ” ìƒ‰ìƒê³¼ ì§ˆê°ì—ì„œ ëˆˆì— ë„ëŠ” ì°¨ì´ê°€ ìˆì—ˆì§€ë§Œ, ì´ëŠ” í’ˆì§ˆì˜ í° ì°¨ì´ë¥¼ ë‚˜íƒ€ë‚´ì§€ëŠ” ì•Šì•˜ìŠµë‹ˆë‹¤. ì‹¤í—˜ì‹¤ í…ŒìŠ¤íŠ¸ ê²°ê³¼, ë‘ ì¶œì²˜ì˜ ë°ë‹˜ì€ ë‹¤ì†Œ ì°¨ì´ê°€ ìˆì—ˆì§€ë§Œ, ëŒ€ë¶€ë¶„ì˜ ì²­ë°”ì§€ëŠ” ê°•ë„ì™€ ë‚´êµ¬ì„± ë©´ì—ì„œ ë¹„ìŠ·í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤. ë¦¬ë°”ì´ìŠ¤ëŠ” ë‹¤ì–‘í•œ ê¸€ë¡œë²Œ ì œì§ì†Œì—ì„œ ì›ë‹¨ì„ ì¡°ë‹¬í•˜ê¸° ë•Œë¬¸ì— ìƒì‚° í’ˆì§ˆê³¼ ì™¸ê´€ì— ì°¨ì´ê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nê²°êµ­, í‰ê°€ ê²°ê³¼ì— ë”°ë¥´ë©´ ì„œë¡œ ë‹¤ë¥¸ íŒë§¤ì²˜ì—ì„œ êµ¬ë§¤í•œ ë¦¬ë°”ì´ìŠ¤ ì²­ë°”ì§€ ì‚¬ì´ì— ì•½ê°„ì˜ ì°¨ì´ê°€ ìˆì„ ìˆ˜ ìˆì§€ë§Œ, ì•„ë§ˆì¡´ì—ì„œ êµ¬ë§¤í•œ ì²­ë°”ì§€ê°€ ë¦¬ë°”ì´ìŠ¤ ë§¤ì¥ì—ì„œ êµ¬ë§¤í•œ ê²ƒë³´ë‹¤ ë°˜ë“œì‹œ í’ˆì§ˆì´ ë–¨ì–´ì§€ëŠ” ê²ƒì€ ì•„ë‹™ë‹ˆë‹¤. ì²­ë°”ì§€ë¥¼ ì°¾ëŠ” ì†Œë¹„ìë“¤ì€ íŒë§¤ì²˜ë³´ë‹¤ëŠ” í•ê³¼ ìŠ¤íƒ€ì¼ì— ë” ì§‘ì¤‘í•´ì•¼ í•©ë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "d91c6896e5ca9717",
    "title": {
      "en": "FDIC says banks can engage in crypto activities without prior approval",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://www.reuters.com/business/finance/fdic-says-banks-can-engage-crypto-activities-without-prior-approval-2025-03-28/",
    "score": 6,
    "by": "speckx",
    "time": 1743194880,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "a243f5c5e6b75df5",
    "title": {
      "en": "Europe's Battle for Tech Sovereignty: Why OpenStack Matters [video]",
      "ko": "ìœ ëŸ½ì˜ ê¸°ìˆ  ì£¼ê¶Œ ì „ìŸ: ì˜¤í”ˆìŠ¤íƒì˜ ì¤‘ìš”ì„±",
      "ja": null
    },
    "type": "story",
    "url": "https://vpetersson.com/podcast/S02E06.html",
    "score": 7,
    "by": "mvip",
    "time": 1743191518,
    "content": "{\n  \"@context\": \"https://schema.org\",\n  \"@type\": [\"VideoObject\", \"PodcastEpisode\"],\n  \"name\": \"Europe's Battle for Tech Sovereignty: Why OpenStack Matters\",\n  \"description\": \"In this timely conversation with Johan Christenson, founder of Cleura and board member of OpenInfra (overseeing Kata Containers and OpenStack), we dive into Europe's growing urgency around digital sovereignty and what it will actually take to build a competitive, homegrown cloud ecosystem. Johan, a long-time advocate for open source infrastructure, pulls back the curtain on why progress has been so slow and where things can shift.\\n\",\n  \"uploadDate\": \"2025-03-28T00:00:00+00:00\",\n  \"duration\": \"PT72M\",\n  \"thumbnailUrl\": \"https://i.ytimg.com/vi/yq_AWq24-IM/default.jpg\",\n  \"embedUrl\": \"https://www.youtube.com/embed/yq_AWq24-IM\",\n  \"contentUrl\": \"https://www.youtube.com/watch?v=yq_AWq24-IM\",\n  \"url\": \"https://vpetersson.com/podcast/S02E06.html\",\n  \"mainEntityOfPage\": \"https://vpetersson.com/podcast/S02E06.html\",\n  \"inLanguage\": \"en\",\n  \"isFamilyFriendly\": true,\n\n  \"actors\": [\n\n    {\n      \"@type\": \"Person\",\n      \"name\": \"Johan Christenson\"\n    }\n\n  ],\n\n  \"author\": {\n    \"@type\": \"Person\",\n    \"name\": \"Viktor Petersson\",\n    \"url\": \"https://vpetersson.com\"\n  },\n  \"publisher\": {\n    \"@type\": \"Organization\",\n    \"name\": \"Nerding Out with Viktor\",\n    \"url\": \"https://vpetersson.com/podcast/\"\n  },\n  \"partOfSeries\": {\n    \"@type\": \"PodcastSeries\",\n    \"name\": \"Nerding Out with Viktor\",\n    \"url\": \"https://vpetersson.com/podcast/\",\n    \"inLanguage\": \"en\",\n    \"isAccessibleForFree\": true,\n    \"seasonNumber\": 2\n  },\n  \"episodeNumber\": 6,\n  \"seasonNumber\": 2,\n  \"sameAs\": [\n    \"https://open.spotify.com/episode/39sf97LkWGRZthwNNRuLup?si=1xtPNO_DRTixQ9_YmzAtUA\"\n    ,\"https://podcasts.apple.com/gb/podcast/europes-battle-for-tech-sovereignty-why-openstack-matters/id1722663295?i=1000701181516\"\n    ,\"https://music.amazon.co.uk/podcasts/c8e79c21-2dde-4597-b9fb-257ecbc2bf29/episodes/e0a97010-b929-4484-bd64-2e72cb91f6ab/nerding-out-with-viktor-europe's-battle-for-tech-sovereignty-why-openstack-matters\"\n  ]\n}\n\n{\n  \"@context\": \"https://schema.org\",\n  \"@type\": \"BreadcrumbList\",\n  \"itemListElement\": [\n    {\n      \"@type\": \"ListItem\",\n      \"position\": 1,\n      \"name\": \"Home\",\n      \"item\": \"https://vpetersson.com\"\n    },\n    {\n      \"@type\": \"ListItem\",\n      \"position\": 2,\n      \"name\": \"Podcast\",\n      \"item\": \"https://vpetersson.com/podcast/\"\n    },\n    {\n      \"@type\": \"ListItem\",\n      \"position\": 3,\n      \"name\": \"Europe's Battle for Tech Sovereignty: Why OpenStack Matters\",\n      \"item\": \"https://vpetersson.com/podcast/S02E06.html\"\n    }\n  ]\n}\n\n  Podcast\n\n        Join Viktor, a proud nerd and seasoned entrepreneur, whose academic journey at Santa Clara University in Silicon Valley sparked a career marked by innovation and foresight. From his college days, Viktor embarked on an entrepreneurial path, beginning with YippieMove, a groundbreaking email migration service, and continuing with a series of bootstrapped ventures.\n\n        Links\n\n        Follow Me\n\n            Follow Me\n\n            Join Viktor, a proud nerd and seasoned entrepreneur, whose academic journey at Santa Clara University in Silicon Valley sparked a career marked by innovation and foresight. From his college days, Viktor embarked on an entrepreneurial path, beginning with YippieMove, a groundbreaking email migration service, and continuing with a series of bootstrapped ventures.\n\n      Europe's Battle for Tech Sovereignty: Why OpenStack Matters\n\n        Play On\n\n        28 MAR â€¢ 2025\n\n          1 hour 12 mins\n\n  Share:\n\n        In this timely conversation with Johan Christenson, founder of Cleura and board member of OpenInfra (overseeing Kata Containers and OpenStack), we dive into Europeâ€™s growing urgency around digital sovereignty and what it will actually take to build a competitive, homegrown cloud ecosystem. Johan, a long-time advocate for open source infrastructure, pulls back the curtain on why progress has been so slow and where things can shift.\n\nWe kick off by looking at Europeâ€™s deep dependence on U.S. cloud providers, and the real-world risks that come with it. From pricing power and data availability to political influence and tech autonomy, Johan explains how this imbalance affects everything from government policy to startup growth.\n\nA major part of our conversation breaks down the key blockers that have kept Europe stuck:\n\n  Procurement systems that favor incumbents over local innovation\n  Long-standing vendor lock-in across schools, agencies, and enterprises\n  A steady brain drain of top talent to non-European tech companies\n  Innovation programs that reward optics over sustainable outcomes\n  The sheer complexity of building a scalable, fully independent cloud stack\n\nJohan explains the uphill battle smaller providers face when going up against hyperscalers â€” not just on price, but on the range and depth of services they offer. He draws a sharp contrast between basic infrastructure and the fully integrated ecosystems that dominate the market.\n\nWe explore his experience building on OpenStack, including:\n\n  Why his company committed early to open infrastructure\n  Lessons from over a decade of contributing to and operating at scale\n  How complexity, resilience, and governance affect platform choices\n  Why internal capability-building matters more than plug-and-play simplicity\n\nFrom there, we expand into bigger-picture ideas: how European vendors could collaborate more effectively, the role of technical standards in shaping markets, and how cloud-native tools like Kubernetes, if used thoughtfully, might help smaller players compete.\n\nThe episode wraps with a sharp take on Europeâ€™s regulatory landscape. Johan argues that the problem isnâ€™t a lack of rules, but the lack of enforcement. He walks through how the disconnect between policy ambitions and operational reality slows down even the most well-intentioned builders.\n\nIf youâ€™re thinking seriously about digital independence, infrastructure sovereignty, or Europeâ€™s place in the global tech stack, this conversation is both a clear-eyed reality check and a grounded look at where change could come from.\n\nFor more on this topic, check out these related articles (in Swedish):\n\n  Ge Sverige ett digitalt beredskapslyft\n  Europa behÃ¶ver ett digitalt airbusprojekt\n\n            Transcript\n\n              Show/Hide Transcript\n\n                      [00:00]\n                      Viktor Petersson\n\n                    Welcome back to another episode of Nerding out with Viktor.\n\n                      [00:03]\n                      Viktor Petersson\n\n                    Today I'm joined by Johan Christenson.\n\n                      [00:05]\n                      Viktor Petersson\n\n                    Welcome, Johan.\n\n                      [00:06]\n                      Johan Christenson\n\n                    Thank you very much.\n\n                      [00:08]\n                      Viktor Petersson\n\n                    Johan.\n\n                      [00:09]\n                      Viktor Petersson\n\n                    You are in the epicenter of this whole new push that we see as of lately with Europe standing up against America when it comes to tech.\n\n                      [00:18]\n                      Viktor Petersson\n\n                    And we've known each other for quite a while.\n\n                      [00:21]\n                      Viktor Petersson\n\n                    And you've been doing a company called.\n\n                      [00:23]\n                      Viktor Petersson\n\n                    Well, used to be called City Networks and now called Cloud Plura.\n\n                      [00:26]\n                      Viktor Petersson\n\n                    Is that correct?\n\n                      [00:27]\n                      Viktor Petersson\n\n                    That's a correct pronunciation of your.\n\n                      [00:29]\n                      Viktor Petersson\n\n                    Yeah, that's right.\n\n                      [00:30]\n                      Viktor Petersson\n\n                    Amazing.\n\n                      [00:31]\n                      Viktor Petersson\n\n                    So maybe recap for the audience.\n\n                      [00:34]\n                      Viktor Petersson\n\n                    What is this whole push that we're seeing from the European cloud space in general?\n\n                      [00:40]\n                      Johan Christenson\n\n                    Well, I think that the push has actually been ongoing for quite some time, but we have not necessarily succeeded quite well with that.\n\n                      [00:47]\n                      Viktor Petersson\n\n                    Fair enough.\n\n                      [00:48]\n                      Johan Christenson\n\n                    But of course, with all the things that are going on in the world today, I think that people are waking up to a different world that are actually.\n\n                      [00:55]\n                      Johan Christenson\n\n                    It's a little bit scary sometimes, right?\n\n                      [00:57]\n                      Johan Christenson\n\n                    There's a lot of vulnerability in society.\n\n                      [01:00]\n                      Johan Christenson\n\n                    Our competitiveness is going down and so forth.\n\n                      [01:02]\n                      Johan Christenson\n\n                    So there is a push, I think, for a lot of different things in that sort of call for independence or not necessarily push against anybody, but more to make sure that there's balance in society that, you know, if things really go bad, we actually can do certain things that maybe we're too dependent on a few players to actually do today.\n\n                      [01:24]\n                      Viktor Petersson\n\n                    Absolutely.\n\n                      [01:25]\n                      Viktor Petersson\n\n                    I mean, yeah, this comes down to like European 70 essentially when it comes to tech.\n\n                      [01:30]\n                      Viktor Petersson\n\n                    And if we do look at almost any company in European ecosystem, they're largely built to your point.\n\n                      [01:37]\n                      Viktor Petersson\n\n                    You had an article in one of the big Swedish newspapers lately about this dependency, right.\n\n                      [01:41]\n                      Viktor Petersson\n\n                    About if these big clouds were to whatever block the European tech sector or economic sector in general, we would be completely doomed.\n\n                      [01:52]\n                      Viktor Petersson\n\n                    Right.\n\n                      [01:52]\n                      Viktor Petersson\n\n                    So maybe speak a bit more like how you see that and how that's what we do about this really.\n\n                      [02:00]\n                      Johan Christenson\n\n                    Well, I mean, you know, there is.\n\n                      [02:02]\n                      Johan Christenson\n\n                    If you.\n\n                      [02:02]\n                      Johan Christenson\n\n                    If you take that first bullet, right.\n\n                      [02:04]\n                      Johan Christenson\n\n                    There's a vulnerability that we built in over many years.\n\n                      [02:08]\n                      Johan Christenson\n\n                    You know, it's been a culture here in Europe that we buy American, you know, used to be you never been fired for buying IBM, you know, many years ago.\n\n                      [02:17]\n                      Johan Christenson\n\n                    And that's kind of changed over to different companies today.\n\n                      [02:20]\n                      Viktor Petersson\n\n                    Yeah.\n\n                      [02:21]\n                      Johan Christenson\n\n                    And that has gone so far today that there are true vulnerabilities.\n\n                      [02:26]\n                      Johan Christenson\n\n                    Some pieces we're building in ourselves.\n\n                      [02:28]\n                      Johan Christenson\n\n                    Like we have apps in Scandinavia that if an app doesn't work, you can't access half of your things and it almost takes down a society.\n\n                      [02:37]\n                      Johan Christenson\n\n                    But then of course, what's maybe more concerning is the underlying infrastructure of those things.\n\n                      [02:42]\n                      Johan Christenson\n\n                    It's kind of like easily put.\n\n                      [02:43]\n                      Johan Christenson\n\n                    You can say Europe needs to be able to build its own railways or its own roads.\n\n                      [02:48]\n                      Johan Christenson\n\n                    We take that for granted.\n\n                      [02:50]\n                      Johan Christenson\n\n                    But for some reason, you know, we're so comfortable, you know, just outsourcing everything else when it comes to it and as we know it today is of course, the foundation for pretty much everything we do.\n\n                      [03:01]\n                      Johan Christenson\n\n                    Whether it's, you know, us doing this thing now or if you build furniture or stuff that you don't associate with it's still a super foundational part.\n\n                      [03:13]\n                      Johan Christenson\n\n                    And then if you don't have that, I think over time we've started to realize that it's not just the vulnerability aspect in the sense that if somebody hits the off switch or something just happens to it, you know, we're super vulnerable as a society.\n\n                      [03:29]\n                      Johan Christenson\n\n                    Many times we talk about, you know, food, for example.\n\n                      [03:33]\n                      Johan Christenson\n\n                    We need to make sure that we can, you know, produce all the food.\n\n                      [03:35]\n                      Johan Christenson\n\n                    But very few people think about the carrots for the carrots actually get to the table.\n\n                      [03:40]\n                      Johan Christenson\n\n                    There's so many processes, supply chains, and it is everywhere in that.\n\n                      [03:44]\n                      Johan Christenson\n\n                    Right.\n\n                      [03:44]\n                      Johan Christenson\n\n                    So you have that aspect of the vulnerability, and that is just immense, I would say.\n\n                      [03:50]\n                      Johan Christenson\n\n                    And today, of course, in our society, you know, a car, you know, can you stop the car?\n\n                      [03:56]\n                      Johan Christenson\n\n                    Can you make the car go fast?\n\n                      [03:58]\n                      Johan Christenson\n\n                    You know, there's so many of these things that come up once societies become more like, or I should say rather that we've had war next to us and we feel more insecure with allies that used to be very reliable, so to speak, and we might have the feeling that they're not so reliable and there's so much of that vulnerability that goes around.\n\n                      [04:16]\n                      Johan Christenson\n\n                    And you can go on and on about that.\n\n                      [04:18]\n                      Johan Christenson\n\n                    But then longer term for us, of course, is the competitiveness, right?\n\n                      [04:21]\n                      Johan Christenson\n\n                    I mean, if you don't.\n\n                      [04:24]\n                      Johan Christenson\n\n                    If you don't have people that actually know the underlying infrastructure and how you build that, but rather just innovate on top of somebody else's innovation, you become completely dependent on that as well.\n\n                      [04:37]\n                      Johan Christenson\n\n                    And of course, you also lose.\n\n                      [04:39]\n                      Johan Christenson\n\n                    You lose, know, that talent that could actually create that underlying, you know, infrastructure, whether it's a road, a railway, or in this case, it, infrastructure, you need those kind of talents for you to be, you know, competitive in the higher layer, so to speak, of it.\n\n                      [04:56]\n                      Johan Christenson\n\n                    So there's various aspects of this that I think we're waking up today",
    "summary": {
      "en": "The podcast episode titled \"Europe's Battle for Tech Sovereignty: Why OpenStack Matters\" features Johan Christenson, founder of Cleura and board member of OpenInfra. In this discussion, they explore the urgent need for Europe to achieve digital sovereignty and establish a competitive local cloud ecosystem.\n\nKey points include:\n\n- **Dependence on U.S. Providers**: Europe relies heavily on American cloud services, posing risks to data availability, pricing, and political influence.\n- **Barriers to Progress**: Several obstacles hinder Europe's tech growth, such as procurement systems favoring established companies, vendor lock-in, talent migration to non-European firms, and complex infrastructure challenges.\n- **Building on OpenStack**: Johan shares insights from his experience with OpenStack, emphasizing the importance of open-source infrastructure and internal capability development.\n- **Collaboration and Standards**: The conversation highlights the need for European vendors to work together and the role of technical standards in market development.\n- **Regulatory Landscape**: Johan points out that while Europe has regulations, enforcement is often lacking, slowing progress.\n\nThe episode serves as a reality check on Europeâ€™s tech independence and discusses potential pathways for improvement. It emphasizes the importance of building local capabilities to avoid over-reliance on external providers.",
      "ko": "\"ìœ ëŸ½ì˜ ê¸°ìˆ  ì£¼ê¶Œì„ ìœ„í•œ ì „íˆ¬: ì˜¤í”ˆìŠ¤íƒì˜ ì¤‘ìš”ì„±\"ì´ë¼ëŠ” ì œëª©ì˜ íŒŸìºìŠ¤íŠ¸ ì—í”¼ì†Œë“œì—ì„œëŠ” í´ë ˆìš°ë¼ì˜ ì°½ë¦½ìì´ì ì˜¤í”ˆì¸í”„ë¼ ì´ì‚¬ì¸ ìš”í•œ í¬ë¦¬ìŠ¤í…ìŠ¨ì´ ì¶œì—°í•©ë‹ˆë‹¤. ì´ ëŒ€í™”ì—ì„œëŠ” ìœ ëŸ½ì´ ë””ì§€í„¸ ì£¼ê¶Œì„ ë‹¬ì„±í•˜ê³  ê²½ìŸë ¥ ìˆëŠ” ì§€ì—­ í´ë¼ìš°ë“œ ìƒíƒœê³„ë¥¼ êµ¬ì¶•í•´ì•¼ í•˜ëŠ” ê¸´ê¸‰í•œ í•„ìš”ì„±ì— ëŒ€í•´ ë…¼ì˜í•©ë‹ˆë‹¤.\n\nì£¼ìš” ë‚´ìš©ìœ¼ë¡œëŠ” ìœ ëŸ½ì´ ë¯¸êµ­ í´ë¼ìš°ë“œ ì„œë¹„ìŠ¤ì— í¬ê²Œ ì˜ì¡´í•˜ê³  ìˆë‹¤ëŠ” ì ì´ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ë°ì´í„° ê°€ìš©ì„±, ê°€ê²©, ì •ì¹˜ì  ì˜í–¥ë ¥ì— ìœ„í—˜ì„ ì´ˆë˜í•©ë‹ˆë‹¤. ë˜í•œ, ìœ ëŸ½ì˜ ê¸°ìˆ  ì„±ì¥ì„ ì €í•´í•˜ëŠ” ì—¬ëŸ¬ ì¥ì• ë¬¼ë„ ì–¸ê¸‰ë©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ê¸°ì¡´ ê¸°ì—…ì— ìœ ë¦¬í•œ ì¡°ë‹¬ ì‹œìŠ¤í…œ, ê³µê¸‰ì—…ì²´ ì¢…ì†, ìœ ëŸ½ ì™¸ ê¸°ì—…ìœ¼ë¡œì˜ ì¸ì¬ ìœ ì¶œ, ë³µì¡í•œ ì¸í”„ë¼ ë¬¸ì œ ë“±ì´ ìˆìŠµë‹ˆë‹¤.\n\nìš”í•œì€ ì˜¤í”ˆìŠ¤íƒì— ëŒ€í•œ ìì‹ ì˜ ê²½í—˜ì„ ë°”íƒ•ìœ¼ë¡œ ì˜¤í”ˆ ì†ŒìŠ¤ ì¸í”„ë¼ì˜ ì¤‘ìš”ì„±ê³¼ ë‚´ë¶€ ì—­ëŸ‰ ê°œë°œì˜ í•„ìš”ì„±ì„ ê°•ì¡°í•©ë‹ˆë‹¤. ëŒ€í™”ì—ì„œëŠ” ìœ ëŸ½ì˜ ê³µê¸‰ì—…ì²´ë“¤ì´ í˜‘ë ¥í•´ì•¼ í•˜ë©°, ì‹œì¥ ë°œì „ì„ ìœ„í•œ ê¸°ìˆ  í‘œì¤€ì˜ ì—­í• ë„ ì¤‘ìš”í•˜ë‹¤ëŠ” ì ì´ ê°•ì¡°ë©ë‹ˆë‹¤. ìš”í•œì€ ìœ ëŸ½ì— ê·œì œê°€ ìˆì§€ë§Œ, ì‹¤ì œ ì§‘í–‰ì´ ë¶€ì¡±í•´ ì§„í–‰ì´ ë”ë””ë‹¤ëŠ” ì ë„ ì§€ì í•©ë‹ˆë‹¤.\n\nì´ ì—í”¼ì†Œë“œëŠ” ìœ ëŸ½ì˜ ê¸°ìˆ  ë…ë¦½ì„±ì— ëŒ€í•œ í˜„ì‹¤ì ì¸ ì ê²€ì„ ì œê³µí•˜ë©°, ê°œì„ ì„ ìœ„í•œ ì ì¬ì ì¸ ê²½ë¡œì— ëŒ€í•´ ë…¼ì˜í•©ë‹ˆë‹¤. ì™¸ë¶€ ê³µê¸‰ì—…ì²´ì— ëŒ€í•œ ê³¼ë„í•œ ì˜ì¡´ì„ í”¼í•˜ê¸° ìœ„í•´ ì§€ì—­ ì—­ëŸ‰ì„ êµ¬ì¶•í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë‹¤ëŠ” ì ì„ ê°•ì¡°í•©ë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "e1174069efe65757",
    "title": {
      "en": "Giant, fungus-like organism may be a completely unknown branch of life",
      "ko": "ê±°ëŒ€ ê· ë¥˜, ë¯¸ì§€ì˜ ìƒëª…ì²´?",
      "ja": null
    },
    "type": "story",
    "url": "https://www.livescience.com/animals/giant-fungus-like-organism-may-be-a-completely-unknown-branch-of-life",
    "score": 274,
    "by": "wglb",
    "time": 1743117328,
    "content": "Animals\n\nGiant, fungus-like organism may be a completely unknown branch of life\n\nNews\n\nBy\nJess Thomson\n\npublished\nyesterday\n\nAn ancient and enormous organism called Prototaxites, initially found to be a type of fungus, may actually be an unknown branch of life, researchers say.\n\nComments\n( 0 )\n()\n\nWhen you purchase through links on our site, we may earn an affiliate commission. Hereâ€™s how it works.\n\nwindow.vanilla.infiniteArticlesData = [];\n\nA painting of what Prototaxites may have looked like, 400 million years ago.\n(Image credit: Painting by Mary Parrish, National Museum of Natural History.)\n\nA bizarre ancient life-form, considered to be the first giant organism to live on land, may belong to a totally unknown branch of the tree of life, scientists say.These organisms, named Prototaxites, lived around 420 million to 375 million years ago during the Devonian period and resembled branchless, cylindrical tree trunks. These organisms would have been massive, with some species growing up to 26 feet (8 meters) tall and 3 feet (1 meter) wide.Since the first Prototaxites fossil was discovered in 1843, scientists haven't been sure whether they were a plant, fungus or even a type of algae. However, chemical analyses of Prototaxites fossils in 2007 suggested they were likely a giant ancient fungus.Now, according to a paper published March 17 on the preprint server bioRxiv, Prototaxites might not have been a humongous fungus after all â€” rather, it may have been an entirely different and previously unknown life-form. The study has not yet been peer-reviewed.All life on Earth is classified within three domains â€” bacteria, archaea and eukarya â€” with eukarya containing all multicellular organisms within the four kingdoms of fungi, animals, plants and protists. Bacteria and archaea contain only single-celled organisms.Previous chemical analysis of Prototaxites fossils indicated that they likely fed off decaying organisms, just like many fungi do today, rather than making their food from carbon dioxide in the air like plants.However, according to this new research, Prototaxites may actually have been part of a totally different kingdom of life, separate from fungi, plants, animals and protists.\n    window.sliceComponents = window.sliceComponents || {};\n\n    externalsScriptLoaded.then(() => {\n        window.reliablePageLoad.then(() => {\n            var componentContainer = document.querySelector(\"#slice-container-newsletterForm-articleInbodyContent-TT23hGQ7XJtsjBD4MeoeD7\");\n\n            if (componentContainer) {\n                var data = {\"layout\":\"inbodyContent\",\"header\":\"Sign up for the Live Science daily newsletter now\",\"tagline\":\"Get the world\\u2019s most fascinating discoveries delivered straight to your inbox.\",\"formFooterText\":\"By submitting your information you agree to the <a href=\\\"https:\\/\\/futureplc.com\\/terms-conditions\\/\\\" target=\\\"_blank\\\">Terms & Conditions<\\/a> and <a href=\\\"https:\\/\\/futureplc.com\\/privacy-policy\\/\\\" target=\\\"_blank\\\">Privacy Policy<\\/a> and are aged 16 or over.\",\"successMessage\":{\"body\":\"Thank you for signing up. You will receive a confirmation email shortly.\"},\"failureMessage\":\"There was a problem. Please refresh the page and try again.\",\"method\":\"POST\",\"inputs\":[{\"type\":\"hidden\",\"name\":\"NAME\"},{\"type\":\"email\",\"name\":\"MAIL\",\"placeholder\":\"Your Email Address\",\"required\":true},{\"type\":\"hidden\",\"name\":\"NEWSLETTER_CODE\",\"value\":\"XLS-D\"},{\"type\":\"hidden\",\"name\":\"LANG\",\"value\":\"EN\"},{\"type\":\"hidden\",\"name\":\"SOURCE\",\"value\":\"60\"},{\"type\":\"hidden\",\"name\":\"COUNTRY\"},{\"type\":\"checkbox\",\"name\":\"CONTACT_OTHER_BRANDS\",\"label\":{\"text\":\"Contact me with news and offers from other Future brands\"}},{\"type\":\"checkbox\",\"name\":\"CONTACT_PARTNERS\",\"label\":{\"text\":\"Receive email from us on behalf of our trusted partners or sponsors\"}},{\"type\":\"submit\",\"value\":\"Sign me up\",\"required\":true}],\"endpoint\":\"https:\\/\\/newsletter-subscribe.futureplc.com\\/v2\\/submission\\/submit\",\"analytics\":[{\"analyticsType\":\"widgetViewed\"}],\"ariaLabels\":{}};\n\n                var triggerHydrate = function() {\n                    window.sliceComponents.newsletterForm.hydrate(data, componentContainer);\n                }\n\n                if (window.lazyObserveElement) {\n                    window.lazyObserveElement(componentContainer, triggerHydrate);\n                } else {\n                    triggerHydrate();\n                }\n            }\n        }).catch(err => console.error('%c FTE ','background: #9306F9; color: #ffffff','Hydration Script has failed for newsletterForm-articleInbodyContent-TT23hGQ7XJtsjBD4MeoeD7 Slice', err));\n    }).catch(err => console.error('%c FTE ','background: #9306F9; color: #ffffff','Externals script failed to load', err));\nSign up for the Live Science daily newsletter nowGet the worldâ€™s most fascinating discoveries delivered straight to your inbox.Contact me with news and offers from other Future brandsReceive email from us on behalf of our trusted partners or sponsorsBy submitting your information you agree to the Terms & Conditions and Privacy Policy and are aged 16 or over.The researchers studied the fossilized remains of one Prototaxites species named Prototaxites taiti, found preserved in the Rhynie chert, a sedimentary deposit of exceptionally well-preserved fossils of early land plants and animals in Scotland. This species was much smaller than many other species of Prototaxites, only growing up to a few inches tall, but it is still the largest Prototaxites specimen found in this region.Upon examining the internal structure of the fossilized Prototaxites, the researchers found that its interior was made up of a series of tubes, similar to those within a fungus. But these tubes branched off and reconnected in ways very unlike those seen in modern fungi.\"We report that Prototaxites taiti was the largest organism in the Rhynie ecosystem and its anatomy was fundamentally distinct from all known extant or extinct fungi,\" the researchers wrote in the paper. \"We therefore conclude that Prototaxites was not a fungus, and instead propose it is best assigned to a now entirely extinct terrestrial lineage.\"True fungi from the same period have also been preserved in the Rhynie chert, enabling the researchers to chemically compare them to Prototaxites. In addition to their unique structural characteristics, the team found that the Prototaxites fossils left completely different chemical signatures to the fungi fossils, indicating that the Prototaxites did not contain chitin, a major building block of fungal cell walls and a hallmark of the fungal kingdom. The Prototaxites fossils instead appeared to contain chemicals similar to lignin, which is found in the wood and bark of plants.\"We conclude that the morphology and molecular fingerprint of P. taiti is clearly distinct from that of the fungi and other organism preserved alongside it in the Rhynie chert, and we suggest that it is best considered a member of a previously undescribed, entirely extinct group of eukaryotes,\" the researchers wrote.Kevin Boyce, a professor at Stanford University, led the 2007 study that posited Prototaxites is a giant fungus and was not involved in this new research. However, he told the New Scientist that he agreed with the study's findings.RELATED STORIESâ€”Scientists discover new 15 million-year old fish with last meal fossilized inside its stomachâ€”30,000-year-old fossilized vulture feathers 'nothing like what we usually see' preserved in volcanic ashâ€”Iguanas sailed one-fifth of the way around the world on rafts 34 million years ago\"Given the phylogenetic information we have now, there is no good place to put Prototaxites in the fungal phylogeny,\" Boyce said. \"So maybe it is a fungus, but whether a fungus or something else entirely, it represents a novel experiment with complex multicellularity that is now extinct and does not share a multicellular common ancestor with anything alive today.\"More research into Prototaxites fossils needs to be done to determine if they were fungi or a completely different type of life, and what caused them to go extinct millions of years ago.\"The conclusion that it is a completely unknown eukaryote certainly creates an air of mystery and intrigue around it â€” probably not likely to be solved until more fossils are discovered or new analytical techniques developed,\" Brett Summerell, a plant pathologist and fungi expert at the Botanic Gardens of Sydney, Australia, who not involved in this new study, told the New Scientist.\n\nJess ThomsonSocial Links NavigationLive Science ContributorJess Thomson is a freelance journalist. She previously worked as a science reporter for Newsweek, and has also written for publications including VICE, The Guardian, The Cut, and Inverse. Jess holds a Biological Sciences degree from the University of Oxford, where she specialised in animal behavior and ecology.\n\nYou must confirm your public display name before commenting\nPlease logout and then login again, you will then be prompted to enter your display name.\n\nLogout\n\nMore about animals\n\nFish in the Mariana Trench all have the same, unique mutations\n\n4 snow leopards spotted together on remote Pakistan mountain in rare footage\n\nLatest\n\nScientists uncover 'inside-out, legless, headless wonder' that lived long before the dinosaurs\n\nSee more latest\n\nMost Popular\n\nScientists uncover 'inside-out, legless, headless wonder' that lived long before the dinosaurs\n\nHuge steam plume rises from Alaska's Mount Spurr as volcano edges closer to eruption\n\nFish in the Mariana Trench all have the same, unique mutations\n\nStaring at the March 29 solar eclipse can cause eye damage in seconds â€” and you wonâ€™t even feel it happening\n\n'Woolly devil' flowers in Texas desert are the 1st new plant genus discovered in a US national park in almost 50 years\n\nFlat, razor-thin telescope lens could change the game in deep space imaging â€” and production could start soon\n\nEclipse map: What will tomorrow's solar eclipse look like from your state?\n\n4 snow leopards spotted together on remote Pakistan mountain in rare footage\n\nJames Webb telescope zooms in on bizarre 'Einstein ring' caused by bending of the universe\n\nHow to watch tomorrow's solar eclipse from anywhere on Earth\n\nfunction loadTaboola()\n{\nvar script = window.document.createElement('script');\nscript.async = 1;\nscript.src = '//cdn.taboola.com/libtrc/futureplc-network/loader.js';\nvar insertLocation = window.document.getElementsByTagName('script')[0];\ninsertLocation.parentNode.insertBefore(script, insertLocation);\n}\nfunction taboolaInit(){\nwindow._taboola = window._taboola || [];\nwindow._taboola.push({article: 'auto'});\n(window.Promise\n? window.Promise.all([window.reliablePageLoad, window.reliableConsentGiven])\n: window.reliableConsentGiven\n).then(function () {\nvar delay = 0;\nwindow.setTimeout(loadTaboola, delay)\n});\n};\ntaboolaInit();\n\nwindow._taboola = window._taboola || [];\nvar screenWidth = window.screen.width;\nfunction taboola_is_device(device) {\nif ((! device) || device === null || (typeof device) === 'undefined') return true\nif (device === 'amp') return false\nif (device === 'desktop' && screenWidth >= 700) return true\nif (device === 'mobile' && screenWidth < 700) return true\nreturn false\n}\n\n(function(){\nvar suitableDevice = taboola_is_device(\"desktop\");\nvar suitablePlacement = !(\"Mid Article\".includes('Mid Article') && \"\") &&\n!(\"Mid Article\".includes('Mid Article') && window.FUTR && window.FUTR.Kiosq && window.FUTR.Kiosq.hasBarrier);\nif (suitableDevice && suitablePlacement) {\nwindow._taboola.push({\nmode: \"thumbnails-a-mid\",\ncontainer: \"desktop-taboola-mid-article\",\nplacement: \"Mid Article\",\ntarget_type: \"mix\",\n});\n}\n})();\n\n(function(){\nvar suitableDevice = taboola_is_device(\"mobile\");\nvar suitablePlacement = !(\"Mid Article\".includes('Mid Article') && \"\") &&\n!(\"Mid Article\".includes('Mid Article') && window.FUTR && window.FUTR.Kiosq && window.FUTR.Kiosq.hasBarrier);\nif (suitableDevice && suitablePlacement) {\nwindow._taboola.push({\nmode: \"thumbnails-a-mid\",\ncontainer: \"mobile-taboola-mid-article\",\nplacement: \"Mid Article\",\ntarget_type: \"mix\",\n});\n}\n})();\n\n(function(){\nvar suitableDevice = taboola_is_device(\"desktop\");\nvar suitablePlacement = !(\"Below Article Thumbnails\".includes('Mid Article') && \"\") &&\n!(\"Below Article Thumbnails\".includes('Mid Article') && window.FUTR && window.FUTR.Kiosq && window.FUTR.Kiosq.hasBarrier);\nif (suitableDevice && suitablePlacement) {\nwindow._taboola.push({\nmode: \"thumbnails-f\",\ncontainer: \"taboola-below-article-thumbnails\",\nplacement: \"Below Article Thumbnails\",\ntarget_type: \"mix\",\n});\n}\n})();\n\n(function(){\nvar suitableDevice = taboola_is_device(\"mobile\");\nvar suitablePlacement = !(\"Mobile Below Article Thumbnails\".includes('Mid Article') && \"\") &&\n!(\"Mobile Below Article Thumbnails\".includes('Mid Article') && window.FUTR && window.FUTR.Kiosq && window.FUTR.Kiosq.hasBarrier);\nif (suitableDevice && suitablePlacement) {\nwindow._taboola.push({\nmode: \"thumbnails-g\",\ncontainer: \"taboola-mobile-below-article-thumbnails\",\nplacement: \"Mobile Below Article Thumbnails\",\ntarget_type: \"mix\",\n});\n}\n})();\n\n(function(){\nvar delay = 0;\nwindow.setTimeout(function() {\nwindow._taboola.push({flush: true});\n}, delay);\n})();\n\n    if (window.sliceHydrationLazy) {\n        window.sliceHydrationLazy(\"popularBox\", \"popularBox\", JSON.stringify({\"tabs\":[{\"tabName\":\"Latest Articles\",\"articles\":[{\"href\":\"\\/animals\\/extinct-species\\/scientists-uncover-inside-out-legless-headless-wonder-that-lived-long-before-the-dinosaurs\",\"heading\":\"Scientists uncover 'inside-out, legless, headless wonder' that lived long before the dinosaurs\",\"image\":{\"src\":\"https:\\/\\/cdn.mos.cms.futurecdn.net\\/GugvyuJLNHqHRGmgEmjE7T.jpg\",\"alt\":\"The fossil Keurbos susanae - or Sue - in the rock.\",\"fullscreen\":false,\"lazyLoading\":true,\"dataHydrate\":true,\"addSEOMetaData\":false}},{\"href\":\"\\/planet-earth\\/volcanos\\/huge-steam-plume-rises-from-alaskas-mount-spurr-as-volcano-edges-closer-to-eruption\",\"heading\":\"Huge steam plume rises from Alaska's Mount Spurr as volcano edges closer to eruption\",\"image\":{\"src\":\"https:\\/\\/cdn.mos.cms.futurecdn.net\\/Qu4n5FmRQWXMhHifYiujNF.jpg\",\"alt\":\"Mount spurr\",\"fullscreen\":false,\"lazyLoading\":true,\"dataHydrate\":true,\"addSEOMetaData\":false}},{\"href\":\"\\/animals\\/fish\\/fish-in-the-mariana-trench-all-have-the-same-unique-mutations\",\"heading\":\"Fish in the Mariana Trench all have the same, unique mutations\",\"image\":{\"src\":\"https:\\/\\/cdn.mos.cms.futurecdn.net\\/F44iXEUuNSmx7E8Dz5rhP6.jpg\",\"alt\":\"Illustration of the earth and its oceans with different deep sea species that surround it,\",\"fullscreen\":false,\"lazyLoading\":true,\"dataHydrate\":true,\"addSEOMetaData\":false}},{\"href\":\"\\/health\\/anatomy\\/staring-at-the-march-29-solar-eclipse-can-cause-eye-damage-in-seconds-and-you-wont-even-feel-it-happening\",\"heading\":\"Staring at the March 29 solar eclipse can cause eye damage in seconds \\u2014 and you won\\u2019t even feel it happening\",\"image\":{\"src\":\"https:\\/\\/cdn.mos.cms.futurecdn.net\\/BCWj4K5cdXLqbKHV3SWV7h.jpg\",\"alt\":\"A kid is shown looking at the solar eclipse while wearing special protective glasses\",\"fullscreen\":false,\"lazyLoading\":true,\"dataHydrate\":true,\"addSEOMetaData\":false}},{\"href\":\"\\/planet-earth\\/plants\\/woolly-devil-flowers-in-texas-desert-are-the-1st-new-plant-genus-discovered-in-a-us-national-park-in-almost-50-years\",\"heading\":\"'Woolly devil' flowers in Texas desert are the 1st new plant genus discovered in a US national park in almost 50 years\",\"image\":{\"src\":\"https:\\/\\/cdn.mos.cms.futurecdn.net\\/XaWDSQQnyiBU8AmsyK5PoF.jpg\",\"alt\":\"The wooly devil (Ovicula biradiata), a flowering plant that appears soft and fuzzy.\",\"fullscreen\":false,\"lazyLoading\":true,\"dataHydrate\":true,\"addSEOMetaData\":false}}]}]}), \"https://slice.vanilla.futurecdn.net/13-2-0/js/popularBox.js\");\n    } else {\n        console.error('%c FTE ','background: #9306F9; color: #ffffff','no lazy slice hydration function available');\n    }\nLATEST ARTICLES1Scientists uncover 'inside-out, legless, headless wonder' that lived long before the dinosaurs2Huge steam plume rises from Alaska's Mount Spurr as volcano edges closer to eruption3Fish in the Mariana Trench all have the same, unique mutations4Staring at the March 29 solar eclipse can cause eye damage in seconds â€” and you wonâ€™t even feel it happening5'Woolly devil' flowers in Texas desert are the 1st new plant genus discovered in a US national park in almost 50 years\n\nif(FUTR && FUTR.Connect){\n//Init Connect article History\nclass userNav {\nconstructor(key = 'connect_articles_history') {\nthis.key = key;\nthis.flushKey = `${key}_flush`;\nthis.propsKey = `${key}_props`;\nthis.store();\nconsole.info(\"FUTR.Connect.userNav - Init - Start - Using reduxStore\");\n}\nstore() {\nconst isArticle = window?.reduxStore?.getState()?.vanilla?.isArticle;\nif (typeof isArticle !== 'undefined' && isArticle && FUTR && FUTR.Connect) {\ntry {\nconst month = `${new Date().getFullYear()}-${new Date().getMonth()}`;\n//flush monthly\nif (localStorage.getItem(this.flushKey) !== month) {\nlocalStorage.setItem(this.key, btoa('[]'));\nlocalStorage.setItem(this.propsKey, []);\nlocalStorage.setItem(this.flushKey, month);\n}\nconst currentUrl = location.pathname;\nconst urls = JSON.parse(atob(localStorage.getItem(this.key) || btoa('[]')));\nconst props = JSON.parse(localStorage.getItem(this.propsKey)|| '[]');\nif (!urls.includes(currentUrl) && this.getProps().length < 20 || this.getProps().length <1) {\nurls.push(currentUrl);\nif (window.ffte && window.ffte.properties) {\nprops.push(window.ffte.properties);\nconsole.log(\"props push\", props)\n}\nlocalStorage.setItem(this.key, btoa(JSON.stringify(urls)));\nlocalStorage.setItem(this.propsKey, JSON.stringify(props));\n}\nconsole.info(\"FUTR.Connect.userNav - Urls Stored\");\n} catch (e) {\nconsole.warn('userNav:', e);\n}\n}\n}\ngetHistory() {\ntry {\nreturn JSON.parse(atob(localStorage.getItem(this.key) || btoa('[]')));\n} catch {\nreturn [];\n}\n}\ngetProps() {\ntry {\nreturn JSON.parse(localStorage.getItem(this.propsKey) || '[]');\n} catch {\nreturn [];\n}\n}\n};\nFUTR.Connect.userNav = new userNav();\nconsole.info(\"FUTR.Connect.userNav - Init - Done\", FUTR.Connect.userNav);\n}",
    "summary": {
      "en": "Researchers have discovered that an ancient organism called Prototaxites, which was once thought to be a type of giant fungus, may actually belong to an entirely unknown branch of life. Prototaxites existed around 420 to 375 million years ago and resembled large, branchless tree trunks, reaching heights of up to 26 feet (8 meters). Initially classified as a fungus based on chemical analysis, recent studies suggest it might not fit into any known categories of life, including fungi, plants, or animals.\n\nA recent study focused on a smaller species of Prototaxites called Prototaxites taiti, found in Scotland. Researchers found that its internal structure was unlike any known fungi and lacked chitin, a key component of fungal cell walls. Instead, it showed similarities to lignin, which is found in plants. This leads scientists to propose that Prototaxites is part of a previously unknown group of eukaryotes.\n\nFurther research is needed to fully understand Prototaxites and what caused its extinction. The findings have sparked interest and curiosity in the scientific community, hinting at the possibility of undiscovered life forms in Earth's history.",
      "ko": "ì—°êµ¬ìë“¤ì€ ê³ ëŒ€ ìƒë¬¼ì¸ í”„ë¡œí† íƒì‚¬ì´íŠ¸ìŠ¤ê°€ í•œë•Œ ê±°ëŒ€í•œ ê· ë¥˜ë¡œ ì—¬ê²¨ì¡Œì§€ë§Œ, ì‚¬ì‹¤ì€ ì „í˜€ ì•Œë ¤ì§€ì§€ ì•Šì€ ìƒëª…ì²´ì˜ ê°€ì§€ì— ì†í•  ìˆ˜ ìˆë‹¤ëŠ” ì‚¬ì‹¤ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. í”„ë¡œí† íƒì‚¬ì´íŠ¸ìŠ¤ëŠ” ì•½ 4ì–µ 2ì²œë§Œ ë…„ì—ì„œ 3ì–µ 7ì²œ5ë°±ë§Œ ë…„ ì „ ì‚¬ì´ì— ì¡´ì¬í–ˆìœ¼ë©°, ê°€ì§€ê°€ ì—†ëŠ” í° ë‚˜ë¬´ ì¤„ê¸°ì²˜ëŸ¼ ìƒê²¼ê³ , ë†’ì´ëŠ” ìµœëŒ€ 8ë¯¸í„°ì— ë‹¬í–ˆìŠµë‹ˆë‹¤. ì´ˆê¸°ì—ëŠ” í™”í•™ ë¶„ì„ì„ í†µí•´ ê· ë¥˜ë¡œ ë¶„ë¥˜ë˜ì—ˆì§€ë§Œ, ìµœê·¼ ì—°êµ¬ì—ì„œëŠ” ì´ ìƒë¬¼ì´ ê· ë¥˜, ì‹ë¬¼, ë™ë¬¼ ë“± ê¸°ì¡´ì˜ ìƒëª…ì²´ ë¶„ë¥˜ì— ë“¤ì–´ë§ì§€ ì•Šì„ ìˆ˜ ìˆë‹¤ê³  ì œì•ˆí•˜ê³  ìˆìŠµë‹ˆë‹¤.\n\nìµœê·¼ ì—°êµ¬ëŠ” ìŠ¤ì½”í‹€ëœë“œì—ì„œ ë°œê²¬ëœ ë” ì‘ì€ ì¢…ì¸ í”„ë¡œí† íƒì‚¬ì´íŠ¸ìŠ¤ íƒ€ì´í‹°ì— ì´ˆì ì„ ë§ì·„ìŠµë‹ˆë‹¤. ì—°êµ¬ìë“¤ì€ ì´ ìƒë¬¼ì˜ ë‚´ë¶€ êµ¬ì¡°ê°€ ì•Œë ¤ì§„ ê· ë¥˜ì™€ëŠ” ë‹¤ë¥´ë©°, ê· ë¥˜ ì„¸í¬ë²½ì˜ ì£¼ìš” ì„±ë¶„ì¸ í‚¤í‹´ì´ ì—†ë‹¤ëŠ” ê²ƒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ëŒ€ì‹ , ì‹ë¬¼ì—ì„œ ë°œê²¬ë˜ëŠ” ë¦¬ê·¸ë‹Œê³¼ ìœ ì‚¬í•œ ì ì´ ìˆì—ˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ë°œê²¬ì€ í”„ë¡œí† íƒì‚¬ì´íŠ¸ìŠ¤ê°€ ì´ì „ì— ì•Œë ¤ì§€ì§€ ì•Šì€ ì§„í•µìƒë¬¼ì˜ ì¼ì¢…ì¼ ê°€ëŠ¥ì„±ì„ ì œê¸°í•©ë‹ˆë‹¤.\n\ní”„ë¡œí† íƒì‚¬ì´íŠ¸ìŠ¤ì™€ ê·¸ ë©¸ì¢… ì›ì¸ì„ ì™„ì „íˆ ì´í•´í•˜ê¸° ìœ„í•´ì„œëŠ” ì¶”ê°€ ì—°êµ¬ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ë°œê²¬ì€ ê³¼í•™ê³„ì—ì„œ í° ê´€ì‹¬ê³¼ í˜¸ê¸°ì‹¬ì„ ë¶ˆëŸ¬ì¼ìœ¼í‚¤ë©°, ì§€êµ¬ ì—­ì‚¬ ì†ì— ì•„ì§ ë°œê²¬ë˜ì§€ ì•Šì€ ìƒëª…ì²´ì˜ ê°€ëŠ¥ì„±ì„ ì•”ì‹œí•˜ê³  ìˆìŠµë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "70215fcdb07c50d1",
    "title": {
      "en": "7.7 magnitude earthquake hits Southeast Asia, affecting Myanmar and Thailand",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://twitter.com/TaraBull808/status/1905534938558157139",
    "score": 246,
    "by": "testrun",
    "time": 1743154324,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "c673589ef5c8aa74",
    "title": {
      "en": "Let's Take a Look at JEP 483: Ahead-of-Time Class Loading and Linking",
      "ko": "JEP 483: ë¯¸ë¦¬ ë¡œë”©í•˜ëŠ” í´ë˜ìŠ¤",
      "ja": null
    },
    "type": "story",
    "url": "https://www.morling.dev/blog/jep-483-aot-class-loading-linking/",
    "score": 43,
    "by": "ingve",
    "time": 1743160315,
    "content": "1\n2\n3\ntar xvf kafka_2.13-4.0.0.tgz\nKAFKA_CLUSTER_ID=\"$(bin/kafka-storage.sh random-uuid)\"\nbin/kafka-storage.sh format --standalone -t $KAFKA_CLUSTER_ID -c config/server.properties",
    "summary": {
      "en": "To set up Kafka, follow these steps:\n\n1. Extract the Kafka files using the command: `tar xvf kafka_2.13-4.0.0.tgz`.\n2. Generate a unique cluster ID with: `KAFKA_CLUSTER_ID=\"$(bin/kafka-storage.sh random-uuid)\"`.\n3. Format the storage for Kafka by running: `bin/kafka-storage.sh format --standalone -t $KAFKA_CLUSTER_ID -c config/server.properties`.",
      "ko": "Kafkaë¥¼ ì„¤ì •í•˜ë ¤ë©´ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ë”°ë¥´ì„¸ìš”. \n\në¨¼ì €, Kafka íŒŒì¼ì„ ì¶”ì¶œí•©ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ `tar xvf kafka_2.13-4.0.0.tgz` ëª…ë ¹ì–´ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ë‹¤ìŒìœ¼ë¡œ, ê³ ìœ í•œ í´ëŸ¬ìŠ¤í„° IDë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ì´ë•ŒëŠ” `KAFKA_CLUSTER_ID=\"$(bin/kafka-storage.sh random-uuid)\"` ëª…ë ¹ì–´ë¥¼ ì…ë ¥í•©ë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ, Kafkaì˜ ì €ì¥ì†Œë¥¼ í¬ë§·í•©ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ `bin/kafka-storage.sh format --standalone -t $KAFKA_CLUSTER_ID -c config/server.properties` ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "10129d8b3a81dd85",
    "title": {
      "en": "Knowledge Library MCP",
      "ko": "ì§€ì‹ ë¼ì´ë¸ŒëŸ¬ë¦¬ MCP",
      "ja": null
    },
    "type": "story",
    "url": "https://devpost.com/software/knowledge-library-mcp",
    "score": 3,
    "by": "thstart",
    "time": 1743195670,
    "content": "1234567891011\n\n  Knowledge Library MCPâ€”Azure AI Agent Service and MCP Powers Precision Querying\n\nAzure AI Services Multi-Agent Multimodal - Speech, Vision, Text RAG Implementation\nleveraging Anthropicâ€™s Model Context Protocol\n\nKnowledge Library MCP (KL MCP) is a multi-modal application leveraging Azure AI Agent Service to locate documentsâ€”text and imagesâ€”and deliver conversational insights via bots. It enhances search with live data integration and Responsible AI principles, designed for scalable, professional-grade querying.\n\nAbout the Project\n\nKL MCPâ€”Azure AI Foundry and GPT-4o Turn Data into Financial Clarity\n\nImagine thousands of documentsâ€”Machine Learning notes, TSLA 10-Ks, workflows, and chartsâ€”transformed from chaos into actionable insights. KL MCP, built with Azure AI Agent Service, Microsoft Document AI, and an upgraded FinancialAnalysisApp, delivers a fast, focused system for retrieving files and answering queries. This is how I turned a developerâ€™s challenge into a hackathon standout.\n\nThe library-like backbone of KL MCP, fueled by Azure AI Agent Service, Microsoft Document AI, Microsoft Graph, and my custom MCP bots.\n\nDetailed architecture of KL MCP, showcasing its multi-agent, multimodal design.\n\nInspiration\n\nAs a developer, I faced endless hours sifting through PDFs, Excel sheets, and charts for a single useful detail. Anthropicâ€™s Model Context Protocol inspired meâ€”context could unlock disorganized dataâ€™s potential. I began by segmenting documents into Cosmos DB NoSQL, but as the volume grew, search accuracy faltered. That struggle drove me to create KL MCPâ€”a structured, library-like solution powered by Azure AI Agent Service and Microsoft Document AI, converting a daily frustration into a competitive edge.\n\nWhat It Does\n\nKL MCP retrieves documentsâ€”text or imagesâ€”like Machine Learning pipelines, SEC filings, or workflow diagrams, and supports conversational queries. Ask a TSLA 10-K chart, â€œWhatâ€™s the revenue outlook?â€â€”it delivers. It processes PDFs, Word documents, Excel sheets, PowerPoint slides, raw text, HTML, and images, using Microsoft Document AIâ€™s OCR and layout analysis for precision. With Azure AI Agent Service and custom bots, it surpasses Azure AI Search by integrating live data and code-generated insights, offering a dynamic, responsive chat experience. Data captured, answers delivered.\n\nKL MCP snags OneDrive docs and powers chat queries across text and images like a pro.\n\nHow I Built It\n\nI developed KL MCP single-handedly, utilizing Azure AI Agent Service, Microsoft Document AI, and GitHub Copilotâ€™s assistance to refine my code and logic. Hereâ€™s the breakdown:\n\nFoundation: Azure AI Agent Service anchors KL MCPâ€”a managed platform deploying intelligent agents with models like GPT-4o and Mistral. It excels at processing text dataâ€”raw files, structured spreadsheetsâ€”from storage or indices with speed, as noted in its documentation. Its limitation? No image supportâ€”charts like the MSCI market cap breakdown were invisible to it.\nVision Integration: GPT-4o, hosted on Azure OpenAI Service, fills that gap. This multimodal model analyzes images, extracts text, and interprets graphical data accurately. Its ability to decode financial visuals, as highlighted in recent analyses, made it essential for KL MCPâ€™s chart-handling needs.\nBot System: I created specialized botsâ€”DocBot for Machine Learning and workflows, SECBot for filingsâ€”each linked to domain-specific agents, such as TSLA or ML documents. Files upload to vector stores, with Cosmos DB NoSQL managing metadataâ€”file type, dateâ€”for semantic searches. Microsoft Document AI processes text and images, enabling seamless chat integration.\nLive Data: API calls pull current stock prices, keeping responses fresh beyond static retrieval limits. Python scripts generate visualsâ€”like profit trend graphsâ€”enhancing chat outputs with calculated insights.\nAgent Tuning: I configured a GPT-4o agent to locate files, execute code, and chat, incorporating Responsible AI principlesâ€”fairness, transparencyâ€”for scalability. A lightweight app, built with the Azure AI Agents SDK, manages uploads, threading, and querying.\n\nLaying the Foundation with Azure AI Agent Service\n\nAzure AI Agent Service became KL MCPâ€™s heavy hitterâ€”a managed platform spinning up agents with GPT-4o and Mistral muscle. Itâ€™s a beast at chewing through textâ€”raw files, spreadsheets, you name itâ€”pulling insights from storage or search indices in a flash. The docs tout its text-handling prowess, and itâ€™s a champ for data-driven smarts.\n\nBut itâ€™s blind to visuals out of the box. A chart like the MSCI market cap breakdown was invisible to itâ€”unacceptable for KL MCP. I needed a system that could see and think across all data types.\n\nBringing in Vision with GPT-4o\n\nEnter GPT-4o, OpenAIâ€™s multimodal marvel on Azure OpenAI Service. It doesnâ€™t just readâ€”it sees. It scans images, extracts text, and decodes charts like a pro. A write-up showed it nailing financial trends from visuals, and I knew itâ€™d supercharge Azure AI Agent Service. GPT-4o could crack my MSCI chart, turning pixels into text that the agents could jam with, bridging visuals and text into a killer workflow.\n\nTapping OneDrive with Microsoft Graph API\n\nTo level up, I wired in Microsoft Graph API with a confidential client flow using client_secret. It grabs docs straight from OneDrive, persisting tokens across restarts with a tokens.json file. If the access token expires, it refreshes it automatically using the refresh_token, keeping the system humming without constant logins. Copilot helped me nail the OAuth danceâ€”authentication at /auth/start, token exchange at /auth/callback, and a list_onedrive_root tool to fetch and chat about OneDrive goodies.\n\nBuilding the Bot Crew\n\nI crafted a bot squadâ€”DocBot for ML and workflows, SECBot for filingsâ€”each tied to domain-specific agents (TSLA, ML docs). Copilot guided me to vectorize uploads into stores, while Cosmos DB NoSQL tracked metadata like file type and date. Microsoft Document AI processed text and images, and Graph API pulled OneDrive data, making chats feel alive, not like a dusty catalog.\n\nAdding Live Data and Visual Flair\n\nCopilot helped me whip up API callsâ€”like live stock pricesâ€”keeping data fresh, not stale. Python scripts crunched numbers and spun up visualsâ€”like profit trend graphsâ€”adding flair to chat responses.\n\nTuning the GPT-4o Agent\n\nWith Copilotâ€™s nudge, I tuned a GPT-4o agent to â€œfind files, run code, and chat,â€ blending multi-modal insights with Responsible AI principles like fairness and transparency. It integrates OneDrive queries seamlessly, keeping the system sharp.\n\nSolving the MSCI Chart\n\nA highlight was analyzing the MSCI market cap chart from a TSLA filingâ€”â€œSELECTED COUNTRIES MSCI MARKET CAP AS A PERCENT OF WORLD MSCI (percent, daily, based on US$),â€ tracking US, Europe, and Japan from 2016 to 2025. GPT-4o extracted the US red line, stable above 60% by 2025; Europeâ€™s blue line, falling from 50% to over 35%; and Japanâ€™s green line, declining from 70% to around 45%. It noted specificsâ€”like the US at 61.9 on March 14, 2024â€”and converted the chart into text, stored for Azure AI Agent Service to answer queries like â€œWhatâ€™s Japanâ€™s MSCI share in 2020?â€ with precision.\n\nChallenges I Faced\n\nScaling proved difficultâ€”Cosmos DB NoSQL struggled with precision as document counts reached thousands. Structuring a library-like system within Azure required extensive iteration, and aligning metadata with vector stores demanded meticulous effort. Integrating live data, code outputs, and Responsible AI standardsâ€”ensuring fairness and transparencyâ€”tested my resolve, but persistent debugging kept the project on track.\n\nAccomplishments Iâ€™m Proud Of\n\nIâ€™m proud to have crafted a multi-modal app that retrieves a TSLA 10-K chart and delivers trend insights instantly. It outperforms Azure AI Search with a bot-driven system, live data, and Responsible AI integration. Solving a developerâ€™s persistent challenge with a polished, effective tool stands as a significant accomplishment. Complexity met, clarity gained.\n\nKL MCP chatting about a TSLA 10-K chart, mixing OneDrive data, text, and images like a rockstar.\n\nLessons Learned\n\nAzure AI Agent Service and Microsoft Document AI excel in multi-modal applicationsâ€”combining text and image processing with advanced language capabilities is transformative. Hierarchical bot systems outmatch flat indexes at scale, and Responsible AI is integral to robust design. GitHub Copilot accelerated my development, while building a library structure honed my metadata and integration skills.\n\nWhatâ€™s Next for Knowledge Library MCP\n\nKL MCPâ€™s next steps include adding voice and audio for query input, video support for workflow visuals, enhanced bot logic, AI-driven metadata tagging, and Azure Machine Learning for predictive insightsâ€”all grounded in Responsible AI.\n\nNew Features and Updates in FinancialAnalysisApp\n\nFinancialAnalysisApp, KL MCPâ€™s backbone, received critical upgrades to handle the MSCI chart and more. It now accepts command-line inputs to manage vector stores or target specific files, uses environment settingsâ€”like connection stringsâ€”for security, and identifies supported formats by file name. It fully controls vector stores in Azureâ€”listing, managing, or clearing themâ€”and offers a conversational loop, answering MSCI trend queriesâ€”like the US holding above 60% while Japan drops from 70% to 45%â€”with live, precise responses. These enhancements elevate KL MCPâ€™s financial analysis capabilities significantly.\n\nProjects in Knowledge Library MCP\n\nThe Knowledge Library MCP repository includes the following projects:\n\n1. CompanyResearch\n\nTools and scripts for conducting company research, including document classification and structured data extraction.\n\nArchitecture of CompanyResearch, highlighting its document processing and data extraction workflow.\n\n2. FinancialAnalysisApp\n\nA .NET-based application for financial analysis, supporting document processing and conversational insights.\n\nArchitecture of FinancialAnalysisApp, showcasing its financial data handling and chat capabilities.\n\n3. go-mcp-brave\n\nA Go-based MCP server integrating with the Brave Search API for real-time web, news, image, and video search results.\n\nArchitecture of go-mcp-brave, detailing its integration with Brave Search API.\n\n4. go-mcp-metasearch\n\nA Go-based application providing metasearch functionality by aggregating results from multiple search engines and APIs.\n\nArchitecture of go-mcp-metasearch, illustrating its multi-engine aggregation process.\n\n5. mcp-azure-server\n\nA Python-based server integrating with Azure AI services for document processing, vector store management, and AI-powered interactions.\n\nArchitecture of mcp-azure-server, showing its Azure AI integration and processing pipeline.\n\n6. mcp-server-go\n\nA Go-based MCP server implementing the Model Context Protocol for tool execution and data retrieval.\n\nArchitecture of mcp-server-go, outlining its MCP implementation and tool execution.\n\n7. realtime-audio\n\nA Python project for real-time audio processing, supporting audio-to-text and text-to-audio interactions.\n\nTechnologies Used\n\nThe Knowledge Library MCP project leverages a diverse set of technologies to deliver robust and scalable solutions. Below is a list of the key technologies used across various components of the project:\n\nProgramming Languages\n\nPython: Used in CompanyResearch, mcp-azure-server, and realtime-audio for data processing, server-side logic, and real-time audio interaction.\nC#: Used in FinancialAnalysisApp and other .NET-based components for financial analysis and web services.\nGo: Used in go-mcp-brave, go-mcp-metasearch, and mcp-server-go for high-performance microservices.\n\nFrameworks and Libraries\n\n.NET 9.0: For building web and API services in KnowledgeLibraryMCP.\nPlaywright: For webpage automation and screenshot capture in CompanyResearch.\nDocling-Core: For document processing and structuring in CompanyResearch.\nMLX-VLM: For generating DocTags and extracting structured data in CompanyResearch.\nFluent UI: For building modern and responsive web components in KnowledgeLibraryMCP.Web.\nMarkdig: For Markdown processing in various components.\nPyDub: For audio playback and manipulation in realtime-audio.\nSpeechRecognition Library: For capturing and converting audio input into text in realtime-audio.\n\nCloud and AI Services\n\nAzure AI Services: For document intelligence, vector store management, and AI-powered search.\nAzure OpenAI Service: For integrating GPT-4o Realtime Preview for multimodal AI capabilities.\nAzure Document Intelligence: For text extraction and image analysis.\nBrave Search API: For fetching web search results in text-search-audio.py.\n\nTools and Utilities\n\nMermaid.js: For generating architecture diagrams.\nNode.js and npm: Required for running the Mermaid CLI.\nBeautifulSoup: For HTML parsing and text extraction in CompanyResearch.\nPillow: For image processing in CompanyResearch.\nBash: For automation scripts like update_architecture_diagram.sh.\n\nAdditional Technologies Used\n\nThe Knowledge Library MCP project also incorporates the following technologies:\n\nMicrosoft Graph API: For accessing and managing OneDrive documents.\nAzure Machine Learning: For predictive insights and advanced analytics.\nGitHub Copilot: For accelerating development and improving code quality.\nOAuth 2.0: For secure authentication and token management in API integrations.\n\nThese additional technologies enhance the project's capabilities, ensuring robust data management, seamless integration, and efficient development workflows.\n\n    Built With\n\n    aiazurec#python\n\n    Try it out\n\n  GitHub Repo\n\n      Submitted to\n\n        Azure AI Developer Hackathon\n\n    Created by\n\n      Radka Vassileva\n\n      Constantine Vassilev\n\n        Seasoned systems engineer with over 30 years of experience. â€¨Passionate about leveraging AI to boost efficiency in software development.",
    "summary": {
      "en": "**Summary of Knowledge Library MCP Project**\n\nThe Knowledge Library MCP (KL MCP) is an advanced application that uses Azure AI Services to improve document searching and provide conversational insights through bots. It can handle various document types, including text and images, and integrates live data to enhance search accuracy and responsiveness.\n\n**Project Overview:**\n- KL MCP transforms chaotic data, like financial documents and charts, into actionable insights.\n- It combines Azure AI Agent Service, Microsoft Document AI, and custom bots for efficient querying and data retrieval.\n\n**Inspiration and Development:**\n- The project was inspired by the need to manage large amounts of data effectively. Existing systems struggled with search accuracy as document volume increased.\n- KL MCP organizes documents in a structured way and uses Anthropicâ€™s Model Context Protocol to extract valuable insights.\n\n**Key Features:**\n- Supports queries on various document formats (PDFs, Word, Excel, images) using advanced text and image analysis.\n- Provides real-time responses by integrating live data, such as current stock prices.\n- Features a bot system for specific tasks, enhancing user interaction and query resolution.\n\n**Technical Aspects:**\n- Built using Azure AI Agent Service and Microsoft Document AI, alongside tools like GitHub Copilot for code refinement.\n- Utilizes Cosmos DB for metadata management and Microsoft Graph API for document access from OneDrive.\n- Incorporates a multimodal model (GPT-4o) for processing both text and images, bridging the gap between different data types.\n\n**Future Developments:**\n- Plans to add voice input, video support, and AI-driven insights for further enhancing functionality.\n- Continuous upgrades to the FinancialAnalysisApp to improve financial data handling and querying capabilities.\n\n**Technologies Used:**\n- Programming Languages: Python, C#, Go\n- Frameworks: .NET, various libraries for document processing and audio interactions.\n- Azure Services: For AI capabilities, document intelligence, and cloud integration.\n\n**Conclusion:**\nKL MCP is a significant leap forward in document management and querying, combining advanced AI technologies to deliver fast, accurate insights and an enhanced user experience.",
      "ko": "ì§€ì‹ ë¼ì´ë¸ŒëŸ¬ë¦¬ MCP(KL MCP)ëŠ” Azure AI ì„œë¹„ìŠ¤ë¥¼ í™œìš©í•˜ì—¬ ë¬¸ì„œ ê²€ìƒ‰ì„ ê°œì„ í•˜ê³  ëŒ€í™”í˜• ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•˜ëŠ” ê³ ê¸‰ ì• í”Œë¦¬ì¼€ì´ì…˜ì…ë‹ˆë‹¤. ì´ ì‹œìŠ¤í…œì€ í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ ë“± ë‹¤ì–‘í•œ ë¬¸ì„œ ìœ í˜•ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆìœ¼ë©°, ì‹¤ì‹œê°„ ë°ì´í„°ë¥¼ í†µí•©í•˜ì—¬ ê²€ìƒ‰ì˜ ì •í™•ì„±ê³¼ ë°˜ì‘ì„±ì„ ë†’ì…ë‹ˆë‹¤.\n\nKL MCPëŠ” ì¬ë¬´ ë¬¸ì„œì™€ ì°¨íŠ¸ì™€ ê°™ì€ í˜¼ë€ìŠ¤ëŸ¬ìš´ ë°ì´í„°ë¥¼ ì‹¤í–‰ ê°€ëŠ¥í•œ ì¸ì‚¬ì´íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. Azure AI ì—ì´ì „íŠ¸ ì„œë¹„ìŠ¤, Microsoft Document AI, ê·¸ë¦¬ê³  ë§ì¶¤í˜• ë´‡ì„ ê²°í•©í•˜ì—¬ íš¨ìœ¨ì ì¸ ì¿¼ë¦¬ì™€ ë°ì´í„° ê²€ìƒ‰ì„ ì§€ì›í•©ë‹ˆë‹¤.\n\nì´ í”„ë¡œì íŠ¸ëŠ” ëŒ€ëŸ‰ì˜ ë°ì´í„°ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ê´€ë¦¬í•  í•„ìš”ì„±ì—ì„œ ì˜ê°ì„ ë°›ì•˜ìŠµë‹ˆë‹¤. ê¸°ì¡´ ì‹œìŠ¤í…œì€ ë¬¸ì„œ ì–‘ì´ ì¦ê°€í•¨ì— ë”°ë¼ ê²€ìƒ‰ ì •í™•ì„±ì—ì„œ ì–´ë ¤ì›€ì„ ê²ªì—ˆìŠµë‹ˆë‹¤. KL MCPëŠ” ë¬¸ì„œë¥¼ ì²´ê³„ì ìœ¼ë¡œ ì •ë¦¬í•˜ê³ , Anthropicì˜ ëª¨ë¸ ì»¨í…ìŠ¤íŠ¸ í”„ë¡œí† ì½œì„ ì‚¬ìš©í•˜ì—¬ ê°€ì¹˜ ìˆëŠ” ì¸ì‚¬ì´íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.\n\nKL MCPëŠ” PDF, ì›Œë“œ, ì—‘ì…€, ì´ë¯¸ì§€ ë“± ë‹¤ì–‘í•œ ë¬¸ì„œ í˜•ì‹ì— ëŒ€í•œ ì¿¼ë¦¬ë¥¼ ì§€ì›í•˜ë©°, ê³ ê¸‰ í…ìŠ¤íŠ¸ ë° ì´ë¯¸ì§€ ë¶„ì„ì„ í†µí•´ ì‹¤ì‹œê°„ ì‘ë‹µì„ ì œê³µí•©ë‹ˆë‹¤. ë˜í•œ, íŠ¹ì • ì‘ì—…ì„ ìœ„í•œ ë´‡ ì‹œìŠ¤í…œì„ ê°–ì¶”ê³  ìˆì–´ ì‚¬ìš©ì ìƒí˜¸ì‘ìš©ê³¼ ì¿¼ë¦¬ í•´ê²°ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.\n\nì´ ì‹œìŠ¤í…œì€ Azure AI ì—ì´ì „íŠ¸ ì„œë¹„ìŠ¤ì™€ Microsoft Document AIë¥¼ ê¸°ë°˜ìœ¼ë¡œ êµ¬ì¶•ë˜ì—ˆìœ¼ë©°, ì½”ë“œ ê°œì„ ì„ ìœ„í•´ GitHub Copilotê³¼ ê°™ì€ ë„êµ¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ë©”íƒ€ë°ì´í„° ê´€ë¦¬ë¥¼ ìœ„í•´ Cosmos DBë¥¼ í™œìš©í•˜ê³ , OneDriveì—ì„œ ë¬¸ì„œì— ì ‘ê·¼í•˜ê¸° ìœ„í•´ Microsoft Graph APIë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ë¥¼ ëª¨ë‘ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ë‹¤ì¤‘ ëª¨ë‹¬ ëª¨ë¸(GPT-4o)ì„ í†µí•©í•˜ì—¬ ì„œë¡œ ë‹¤ë¥¸ ë°ì´í„° ìœ í˜• ê°„ì˜ ê°„ê·¹ì„ ë©”ì›ë‹ˆë‹¤.\n\nì•ìœ¼ë¡œ ìŒì„± ì…ë ¥, ë¹„ë””ì˜¤ ì§€ì›, AI ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ ì¶”ê°€ë¥¼ í†µí•´ ê¸°ëŠ¥ì„ ë”ìš± í–¥ìƒì‹œí‚¬ ê³„íšì…ë‹ˆë‹¤. ì¬ë¬´ ë°ì´í„° ì²˜ë¦¬ ë° ì¿¼ë¦¬ ê¸°ëŠ¥ì„ ê°œì„ í•˜ê¸° ìœ„í•´ FinancialAnalysisAppì˜ ì§€ì†ì ì¸ ì—…ê·¸ë ˆì´ë“œë„ ì˜ˆì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n\nì´ í”„ë¡œì íŠ¸ì—ì„œ ì‚¬ìš©ëœ ê¸°ìˆ ë¡œëŠ” Python, C#, Goì™€ ê°™ì€ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì™€ ë¬¸ì„œ ì²˜ë¦¬ ë° ì˜¤ë””ì˜¤ ìƒí˜¸ì‘ìš©ì„ ìœ„í•œ ë‹¤ì–‘í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬, AI ê¸°ëŠ¥ê³¼ í´ë¼ìš°ë“œ í†µí•©ì„ ìœ„í•œ Azure ì„œë¹„ìŠ¤ê°€ í¬í•¨ë©ë‹ˆë‹¤. KL MCPëŠ” ë¬¸ì„œ ê´€ë¦¬ì™€ ì¿¼ë¦¬ì—ì„œ ì¤‘ìš”í•œ ë°œì „ì„ ì´ë£¨ì–´ë‚´ë©°, ë¹ ë¥´ê³  ì •í™•í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•˜ê³  ì‚¬ìš©ì ê²½í—˜ì„ í–¥ìƒì‹œí‚¤ëŠ” ê³ ê¸‰ AI ê¸°ìˆ ì„ ê²°í•©í•˜ê³  ìˆìŠµë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "10097a15cc5088c4",
    "title": {
      "en": "Things I would have told myself before building an autorouter",
      "ko": "ìë™ ë¼ìš°í„° ì œì‘ ì „ ê¼­ ì•Œì•„ì•¼ í•  ê²ƒ",
      "ja": null
    },
    "type": "story",
    "url": "https://blog.autorouting.com/p/13-things-i-would-have-told-myself",
    "score": 345,
    "by": "seveibar",
    "time": 1743122333,
    "content": "Share this postautorouting13 things I would have told myself before building an autorouterCopy linkFacebookEmailNotesMoreDiscover more from autoroutingReviews, benchmarks and open datasets for autorouting, with a focus on open-source autorouting.SubscribeBy subscribing,  I agree to Substack's Terms of Use, and acknowledge its Information Collection Notice and Privacy Policy.Already have an account? Sign in13 things I would have told myself before building an autorouterImportant lessons from trying to build the world's fastest autorouter for about a yearSeveMar 28, 20258Share this postautorouting13 things I would have told myself before building an autorouterCopy linkFacebookEmailNotesMore31ShareIâ€™ve spent about a year working on an autorouter for tscircuit (an open-source electronics CAD kernel written in Typescript). If I could go back a year, these are the 13 things I would tell myself:An intermediate stage of our autorouting routing a keyboard.1. Know A* like the back of your hand, use it everywhereIf I was king for a day, I would rename A* to â€œFundamental Algorithmâ€. It is truly one of the most adaptable and important algorithms for _any kind_ of search. It is simply the best foundation for any kind of informed search (not just for 2d grids!)Hereâ€™s an animated version of A* versus â€œbreadth first searchâ€ on a 2d grid:The way A* explores nodes is a lot faster and more intuitive. The major difference between these two algorithms is BFS explores all adjacent nodes, while A* prioritizes exploring nodes that are closer to the destination. Because it considers a metric outside the graph (the distance to the destination) itâ€™s an informed search.You are already either using BFS or DFS (depth-first search) in your code. A recursive algorithm is a depth first search. Any loop that explores candidates/neighbors without sorting the candidates is a BFS. 99% of the time you can convert it to A* and get dramatic performance gains!One of my favorite techniques in our autorouter is we run multiple levels of A* to discover the optimal hyperparameters for a particular problem. So weâ€™re basically running each autorouter as a candidate, then using A* to determine which autorouters we should spend the most time on!See all those numbers at the top? Those are each different configurations of hyper parameters. Running each autorouter fairly would be a huge waste of time- if one autorouter starts to win (it is successfully routing with good costs) allocate more iterations to it! This kind of meta-A* combines a regular cost function that penalizes distance with a cost function that penalizes iterations.2. Implementation Language doesnâ€™t matterIâ€™m controversially writing our autorouter in Javascript. This is the first thing people call out, but itâ€™s not as unreasonable as you might expect. Consider that when optimizing an algorithm, youâ€™re basically looking at improving two things:Lowering the number of iterations required (make the algorithm smart)Increasing the speed of each iterationPeople focus way too much on improving the speed of each iteration. If you are doing something dumb (like converting everything to a grid for overlap testing), Javascript performance will beat you no matter what language you use!Dumb algorithms in optimal assembly are slower than smart algorithms in Javascript! Algorithm > Language!95% of your focus should be on reducing the number of iterations. This is why language doesnâ€™t matter. Whatever gets you to the smartest, most cacheable algorithm fastest is the best language.3. Spatial Hash Indexing > Tree Data StructuresYou canâ€™t walk 5 feet into multi-dimensional space optimization without someone mentioning a QuadTree, this incredible data structure that makes O(N) search O(log(N)) when searching for nearby objects in 2d/3d space.The QuadTree and every general-purpose tree data structure are insanely slow. Trees are not an informed representation of your data.Any time youâ€™re using a tree youâ€™re ignoring an  O(~1) hash algorithm for a more complicated O(log(N)) algorithmWhy does Javascript use HashSets and HashMaps by default and every chance it gets? Theyâ€™re super super fast. A Spatial Hash Index is the same concept as a HashMap, but instead of hashing the object we hash itâ€™s location and store it in a Cell (or â€œbucket of things that are close togetherâ€)Letâ€™s look at how we might replace the QuadTree with a SpatialHashIndex with 20% as much code:There are many variants of this basic data structure for different types of objects, but they all look pretty similar. Weâ€™re basically just creating â€œbucketsâ€ with spatial hashes and filling them with any object that is contained within the cell represented by the spatial hash.The reason spatial hashes arenâ€™t as popular is you need to be careful about selecting your cell size- this is what makes it an informed algorithm. If your cell size isnâ€™t calibrated well, youâ€™ll end up paying high fixed costs per retrieval. In practice, itâ€™s not that difficult to pick a reasonable cell size.4. Effective Spatial Partitioning + Caching is 1000x more important than algorithm performanceA circuit board like the one inside an IPhone probably has somewhere between 10,000 and 20,000 traces and take a team several months to route with the best EDA tools in world. It can seem daunting to try to optimize such an incredibly complex task- but the truth is the entire industry is neglecting a very simple idea: everything that has been routed has been routed before.Game developers â€œpre-bakeâ€ navigation meshes into many gigabytes for their games. LLMs compress the entire internet into weights for search. The next generation of autorouters will spatially partition their problems, then call upon a massive cache for pre-solved solutions. The speed of the algorithm doesnâ€™t matter when you have a massive cache with 99% of the autorouting problem pre-solved.Most algorithms today do not focus on the effective cache-reusability or effective spatial partitioning, but a critical component of future autorouters will be caching inputs and outputs from each stage in a spatially partitioned way.Moreover, the size of storage and caching seems to go down faster than the speed of computation goes up. Itâ€™s not a big deal to have a gigabyte cache to make your autorouter 50% faster.At the end of the day, the cache will win. Cacheable algorithms matter more than fast algorithms!5. If you do not have a visualization for a problem, you will never solve itIf there is one thing I could have printed on a poster, it would be VISUALIZE THE PROBLEM. You canâ€™t debug problems by staring at numbers.For every tiny problem we solve, we have a visualization. We will often start with the visualization. Time and time again this enables us to debug and solve problems 10x faster than we could otherwise. Hereâ€™s a visualization we made of a subalgorithm for finding 45 degree paths, we use this in our â€œPath Simplification Phaseâ€, an ~final phase of the autorouter.6. Javascript Profiling Is Amazing- Use it!Javascript profiling tools are incredibe, you can easily see the exact total time in ms spend on each line of code. You donâ€™t need to use any performance framework, just execute your javascript in the browser and pull up the performance tab. There are also awesome features like flame charts and stuff for memory usage.Example flamechat for debugging performance in @tscircuit/coreYou can easily see the time spent on each line of code inside Chromeâ€™s performance tools!Hereâ€™s a little youtube short I made about it7. Never use recursive functionsRecursive functions are bad for multiple reasons:They are almost always synchronous (canâ€™t be broken out for animation)They are inherently a Depth-First Search, and canâ€™t be easily morphed to A*You canâ€™t easily track iterationsMutability is often unnatural in recursive functions but critical to performanceHereâ€™s an example of an â€œobviously recursiveâ€ function converted to a non-recursive function:The iteration-based implementation is much faster because it keeps a set of visitedNodes and checks nodes prior to exploration. You can do this with recursive functions, but you have to pass around a mutable object and do other unnatural things. Itâ€™s just best to avoid recursive functions when writing performant code.8. Monte Carlo algorithms are hacks. AVOIDMonte Carlo algorithms use randomness to iterate towards a solution. They are bad because:They lead to non-deterministic, hard-to-debug algorithmsThey are basically never optimal relative to a heuristicI sometimes use Monte Carlo-style algorithms when I donâ€™t yet know how the algorithm should get to the solution, but I know how to score a candidate. They can help give some basic intuition about how to solve a problem. Once you have something approximating a cost function, do something smarter than Monte Carlo or any other random technique like Simulated Annealing. If your algorithm is sensitive to local minimums, consider using hyper parameters or more complex cost functions. Almost any local minimum your human eye can see can be made into a component of a cost function.Another way to think about it: How many PCB Designers randomly draw lines on their circuit board? None. Nobody does that. Itâ€™s just not a good technique for this domain. Youâ€™ll always be able to find a better heuristic.9. Keep intermediate algorithms groundedOur autorouter is currently a pipeline with 13 stages and something like 20 sub-algorithms that we measure the iteration count of for various things like determining spatial partitions or simplifying paths at the boundaries independently autorouted sections.Being able to overlay different inputs/output visualizations of each stage of the algorithm helps you understand the context surrounding the problem youâ€™re solving. I often ran into issues at downstream stages (often our â€œhigh density routingâ€ stage) that could be solved by improving the output of previous stages.The temptation when building sub-algorithms is to isolate the algorithm to its simplest form, maybe even normalizing around (0, 0). The danger with normalization or any complex transformation is it might impact the ability to quickly see consequences from early stages of the algorithm to later stages of the algorithm. To prevent this, just keep your coordinate space consistent throughout the lifecycle of the algorithm.Hereâ€™s each stage of our algorithm one after another. We often zoom in on this to see what stage is the most guilty culprit for a failed Design Rule Check.10. Animate your iterations to catch stupid behaviorRemember how itâ€™s super important to lower your iteration count?Animating the iterations of your algorithm will show you how â€œdumbâ€ itâ€™s being by giving you an intuition for how many iterations are wasted exploring paths that donâ€™t matter. This is particularly helpful when adjusting the greedy multiplier (discussed in 12)This video is an animation of a simple trace failing to solve, but instead of failing outright attempting to solve endlessly outward. Without the animation, it would have been hard to tell what was going on!11. Intersection math is fast, do you really need a grid?Consider two ways to determine if a trace A overlaps another trace B:Consider each segment of A and B, and check for intersections1Create a binary grid that marks each square where trace B is present, then check all the squares where trace A is present to see if B is thereBelieve it or not, most people would choose to use Option 2 with a binary grid check, even though this can easily be 1000x slower. People do this because math is hard ğŸ¤¦Luckily LLMs make this kind of intersection math trivial. Use fast vector math!! Checking a SINGLE grid square (memory access!) can literally be slower than doing a dot product to determine if two segments intersect!12. Measure spatial probability of failure at each stage, prioritize solvabilityWhen doing spatial partitioning of the problem, you can measure the probability of solve failure of each stage with some leading indicators. For example, in the Unravel Autorouter we track the probability of failure for each â€œCapacity Nodeâ€ at each major pipeline stage. Each stage focuses on reconfiguring adjacent nodes or rerouting to reduce the probability of failure.The great thing about probability of failure as a metric is you can literally measure it and improve your prediction as your algorithm changes. Each stage can then do itâ€™s best to minimize the chance of future stages failing.I think generally prioritizing solvability is better than trying to incorporate too many constraints. Once a board is solved, itâ€™s often easier to â€œwork with that solutionâ€ than to generate optimal solution from scratch.13. The â€œGreedy Multiplierâ€, the secret hack to 100x A* performance at the cost of optimality Ok itâ€™s not exactly a secret, maybe a â€œwell-known secretâ€, but if you donâ€™t know about it, youâ€™re not using A* properly.By default, A* is guaranteed to give you the optimal solution, but what if you care more about speed than about optimality? Make one tiny change to your f(n)and you have Weighted A*, a variant of A* that solves more greedily, and generally much, much faster!Normal A*: f(n) = g(n) + h(n)Weighted A*: f(n) = g(n) + w * h(n)You can read more about weighted A* and other A* variants here.Game developers have a lot of the same problems as autorouting developers, so itâ€™s not a bad idea to look for game development papers if youâ€™re searching for related work!Weâ€™re making an autorouter.If this was interesting to you, Iâ€™d love to show you our autorouter as it gets closer to release. I believe that solving autorouting will be a massive unlock for physical-world innovation and is a key piece to enable the â€œvibe-buildingâ€ of electronics. All of our work is MIT-licensed open-source. You can also follow me on twitter.Thanks for reading autorouting! Subscribe to hear when we release our insanely fast autorouter!Subscribe1Technically, you should use â€œsegment to segmentâ€ distance to ensure appropriate margins, which is slightly more complex than intersection, but not by much8Share this postautorouting13 things I would have told myself before building an autorouterCopy linkFacebookEmailNotesMore31Share",
    "summary": {
      "en": "**Summary: 13 Key Lessons from Building an Autorouter**\n\n1. **Master A***: A* is a powerful search algorithm that outperforms other methods like breadth-first search (BFS) in finding the shortest paths by prioritizing closer nodes.\n\n2. **Language Choice Matters Less**: The programming language (e.g., JavaScript) is less important than using smart algorithms. Focus on reducing the number of iterations instead of just speeding up each iteration.\n\n3. **Use Spatial Hashing**: Instead of tree data structures, use spatial hash indexing for faster searches in multi-dimensional spaces.\n\n4. **Caching is Crucial**: Effective spatial partitioning and caching pre-solved problems can drastically improve performance, making algorithm speed less critical.\n\n5. **Visualize Problems**: Always create visual representations of your problems to aid debugging and understanding.\n\n6. **Utilize JavaScript Profiling**: Take advantage of browser profiling tools to analyze and optimize your code's performance.\n\n7. **Avoid Recursion**: Recursive functions can complicate tracking and performance; prefer iterative approaches for better efficiency.\n\n8. **Steer Clear of Monte Carlo Methods**: These use randomness and are often inefficient and hard to debug. Instead, seek better heuristics.\n\n9. **Keep Algorithms Grounded**: Maintain consistent coordinate spaces throughout algorithm stages for clarity and to avoid issues in later stages.\n\n10. **Animate Your Process**: Visualizing algorithms in action can highlight inefficiencies and wasted iterations.\n\n11. **Use Fast Math for Intersections**: Instead of using slow grid checks for overlaps, rely on efficient mathematical calculations for intersections.\n\n12. **Measure Solvability**: Track the likelihood of failures at each algorithm stage and prioritize solving potential issues early.\n\n13. **Greedy Multiplier for Speed**: Adjust A* to a weighted version for faster results at the cost of optimality, improving performance significantly.\n\nThese lessons emphasize the importance of algorithm design, visualization, and effective use of data structures in building a successful autorouter.",
      "ko": "A* ì•Œê³ ë¦¬ì¦˜ì„ ë§ˆìŠ¤í„°í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤. A*ëŠ” ìµœë‹¨ ê²½ë¡œë¥¼ ì°¾ëŠ” ë° ê°•ë ¥í•œ ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ, ë„ˆë¹„ ìš°ì„  íƒìƒ‰(BFS)ë³´ë‹¤ ë” íš¨ê³¼ì ì…ë‹ˆë‹¤. ì´ ì•Œê³ ë¦¬ì¦˜ì€ ê°€ê¹Œìš´ ë…¸ë“œë¥¼ ìš°ì„ ì ìœ¼ë¡œ ê³ ë ¤í•˜ì—¬ ê²½ë¡œë¥¼ ì°¾ìŠµë‹ˆë‹¤.\n\ní”„ë¡œê·¸ë˜ë° ì–¸ì–´ì˜ ì„ íƒì€ ê·¸ë¦¬ ì¤‘ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ìë°”ìŠ¤í¬ë¦½íŠ¸ì™€ ê°™ì€ ì–¸ì–´ë³´ë‹¤ëŠ” ìŠ¤ë§ˆíŠ¸í•œ ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ë” ì¤‘ìš”í•©ë‹ˆë‹¤. ê° ë°˜ë³µì˜ ì†ë„ë¥¼ ë†’ì´ê¸°ë³´ë‹¤ëŠ” ë°˜ë³µ íšŸìˆ˜ë¥¼ ì¤„ì´ëŠ” ë° ì§‘ì¤‘í•´ì•¼ í•©ë‹ˆë‹¤.\n\në‹¤ì°¨ì› ê³µê°„ì—ì„œ ë” ë¹ ë¥¸ ê²€ìƒ‰ì„ ìœ„í•´ íŠ¸ë¦¬ ë°ì´í„° êµ¬ì¡° ëŒ€ì‹  ê³µê°„ í•´ì‹±ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. íš¨ê³¼ì ì¸ ê³µê°„ ë¶„í• ê³¼ ë¯¸ë¦¬ í•´ê²°ëœ ë¬¸ì œë¥¼ ìºì‹±í•˜ë©´ ì„±ëŠ¥ì´ í¬ê²Œ í–¥ìƒë˜ì–´ ì•Œê³ ë¦¬ì¦˜ ì†ë„ê°€ ëœ ì¤‘ìš”í•´ì§‘ë‹ˆë‹¤.\n\në¬¸ì œë¥¼ ì‹œê°ì ìœ¼ë¡œ í‘œí˜„í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤. ë¬¸ì œë¥¼ ì‹œê°í™”í•˜ë©´ ë””ë²„ê¹…ê³¼ ì´í•´ì— ë„ì›€ì´ ë©ë‹ˆë‹¤. ë¸Œë¼ìš°ì € í”„ë¡œíŒŒì¼ë§ ë„êµ¬ë¥¼ í™œìš©í•˜ì—¬ ì½”ë“œ ì„±ëŠ¥ì„ ë¶„ì„í•˜ê³  ìµœì í™”í•˜ëŠ” ê²ƒë„ ì¢‹ì€ ë°©ë²•ì…ë‹ˆë‹¤.\n\nì¬ê·€ í•¨ìˆ˜ëŠ” ì¶”ì ê³¼ ì„±ëŠ¥ì„ ë³µì¡í•˜ê²Œ ë§Œë“¤ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ë°˜ë³µì ì¸ ì ‘ê·¼ ë°©ì‹ì„ ì„ í˜¸í•˜ëŠ” ê²ƒì´ íš¨ìœ¨ì ì…ë‹ˆë‹¤. ëª¬í…Œì¹´ë¥¼ë¡œ ë°©ë²•ì€ ë¬´ì‘ìœ„ì„±ì„ ì‚¬ìš©í•˜ì—¬ ë¹„íš¨ìœ¨ì ì´ê³  ë””ë²„ê¹…ì´ ì–´ë ¤ìš´ ê²½ìš°ê°€ ë§ìœ¼ë¯€ë¡œ, ë” ë‚˜ì€ íœ´ë¦¬ìŠ¤í‹±ì„ ì°¾ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.\n\nì•Œê³ ë¦¬ì¦˜ì˜ ê° ë‹¨ê³„ì—ì„œ ì¼ê´€ëœ ì¢Œí‘œ ê³µê°„ì„ ìœ ì§€í•˜ëŠ” ê²ƒì´ ëª…í™•ì„±ì„ ë†’ì´ê³  ì´í›„ ë‹¨ê³„ì—ì„œì˜ ë¬¸ì œë¥¼ í”¼í•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤. ì•Œê³ ë¦¬ì¦˜ì˜ ë™ì‘ì„ ì‹œê°í™”í•˜ë©´ ë¹„íš¨ìœ¨ì„±ê³¼ ë‚­ë¹„ë˜ëŠ” ë°˜ë³µì„ ê°•ì¡°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nëŠë¦° ê·¸ë¦¬ë“œ ì²´í¬ ëŒ€ì‹  íš¨ìœ¨ì ì¸ ìˆ˜í•™ì  ê³„ì‚°ì„ ì‚¬ìš©í•˜ì—¬ êµì°¨ì ì„ ì°¾ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. ê° ì•Œê³ ë¦¬ì¦˜ ë‹¨ê³„ì—ì„œ ì‹¤íŒ¨ ê°€ëŠ¥ì„±ì„ ì¶”ì í•˜ê³ , ì ì¬ì ì¸ ë¬¸ì œë¥¼ ì¡°ê¸°ì— í•´ê²°í•˜ëŠ” ë° ìš°ì„ ìˆœìœ„ë¥¼ ë‘ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.\n\në§ˆì§€ë§‰ìœ¼ë¡œ, A* ì•Œê³ ë¦¬ì¦˜ì„ ê°€ì¤‘ì¹˜ ë²„ì „ìœ¼ë¡œ ì¡°ì •í•˜ì—¬ ì†ë„ë¥¼ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ë°©ë²•ì€ ìµœì ì„±ì„ í¬ìƒí•˜ë”ë¼ë„ ì„±ëŠ¥ì„ í¬ê²Œ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ êµí›ˆë“¤ì€ ì„±ê³µì ì¸ ìë™ ë¼ìš°í„°ë¥¼ êµ¬ì¶•í•˜ëŠ” ë° ìˆì–´ ì•Œê³ ë¦¬ì¦˜ ì„¤ê³„, ì‹œê°í™”, ë°ì´í„° êµ¬ì¡°ì˜ íš¨ê³¼ì ì¸ ì‚¬ìš©ì´ ì–¼ë§ˆë‚˜ ì¤‘ìš”í•œì§€ë¥¼ ê°•ì¡°í•©ë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "42d0a8d891c71102",
    "title": {
      "en": "Tracing the thoughts of a large language model",
      "ko": "ëŒ€í˜• ì–¸ì–´ëª¨ë¸ì˜ ì‚¬ê³  ì¶”ì ",
      "ja": null
    },
    "type": "story",
    "url": "https://www.anthropic.com/research/tracing-thoughts-language-model",
    "score": 945,
    "by": "Philpax",
    "time": 1743095136,
    "content": "InterpretabilityTracing the thoughts of a large language modelMar 27, 2025Language models like Claude aren't programmed directly by humansâ€”instead, theyâ€˜re trained on large amounts of data. During that training process, they learn their own strategies to solve problems. These strategies are encoded in the billions of computations a model performs for every word it writes. They arrive inscrutable to us, the modelâ€™s developers. This means that we donâ€™t understand how models do most of the things they do.Knowing how models like Claude think would allow us to have a better understanding of their abilities, as well as help us ensure that theyâ€™re doing what we intend them to. For example:Claude can speak dozens of languages. What language, if any, is it using \"in its head\"?Claude writes text one word at a time. Is it only focusing on predicting the next word or does it ever plan ahead?Claude can write out its reasoning step-by-step. Does this explanation represent the actual steps it took to get to an answer, or is it sometimes fabricating a plausible argument for a foregone conclusion?We take inspiration from the field of neuroscience, which has long studied the messy insides of thinking organisms, and try to build a kind of AI microscope that will let us identify patterns of activity and flows of information. There are limits to what you can learn just by talking to an AI modelâ€”after all, humans (even neuroscientists) don't know all the details of how our own brains work. So we look inside.Today, we're sharing two new papers that represent progress on the development of the \"microscope\", and the application of it to see new \"AI biology\". In the first paper, we extend our prior work locating interpretable concepts (\"features\") inside a model to link those concepts together into computational \"circuits\", revealing parts of the pathway that transforms the words that go into Claude into the words that come out. In the second, we look inside Claude 3.5 Haiku, performing deep studies of simple tasks representative of ten crucial model behaviors, including the three described above. Our method sheds light on a part of what happens when Claude responds to these prompts, which is enough to see solid evidence that:Claude sometimes thinks in a conceptual space that is shared between languages, suggesting it has a kind of universal â€œlanguage of thought.â€ We show this by translating simple sentences into multiple languages and tracing the overlap in how Claude processes them.Claude will plan what it will say many words ahead, and write to get to that destination. We show this in the realm of poetry, where it thinks of possible rhyming words in advance and writes the next line to get there. This is powerful evidence that even though models are trained to output one word at a time, they may think on much longer horizons to do so.Claude, on occasion, will give a plausible-sounding argument designed to agree with the user rather than to follow logical steps. We show this by asking it for help on a hard math problem while giving it an incorrect hint. We are able to â€œcatch it in the actâ€ as it makes up its fake reasoning, providing a proof of concept that our tools can be useful for flagging concerning mechanisms in models.We were often surprised by what we saw in the model: In the poetry case study, we had set out to show that the model didn't plan ahead, and found instead that it did. In a study of hallucinations, we found the counter-intuitive result that Claude's default behavior is to decline to speculate when asked a question, and it only answers questions when something inhibits this default reluctance. In a response to an example jailbreak, we found that the model recognized it had been asked for dangerous information well before it was able to gracefully bring the conversation back around. While the problems we study can (and often have been) analyzed with other methods, the general \"build a microscope\" approach lets us learn many things we wouldn't have guessed going in, which will be increasingly important as models grow more sophisticated.These findings arenâ€™t just scientifically interestingâ€”they represent significant progress towards our goal of understanding AI systems and making sure theyâ€™re reliable. We also hope they prove useful to other groups, and potentially, in other domains: for example, interpretability techniques have found use in fields such as medical imaging and genomics, as dissecting the internal mechanisms of models trained for scientific applications can reveal new insight about the science.At the same time, we recognize the limitations of our current approach. Even on short, simple prompts, our method only captures a fraction of the total computation performed by Claude, and the mechanisms we do see may have some artifacts based on our tools which don't reflect what is going on in the underlying model. It currently takes a few hours of human effort to understand the circuits we see, even on prompts with only tens of words. To scale to the thousands of words supporting the complex thinking chains used by modern models, we will need to improve both the method and (perhaps with AI assistance) how we make sense of what we see with it.As AI systems are rapidly becoming more capable and are deployed in increasingly important contexts, Anthropic is investing in a portfolio of approaches including realtime monitoring, model character improvements, and the science of alignment. Interpretability research like this is one of the highest-risk, highest-reward investments, a significant scientific challenge with the potential to provide a unique tool for ensuring that AI is transparent. Transparency into the modelâ€™s mechanisms allows us to check whether itâ€™s aligned with human valuesâ€”and whether itâ€™s worthy of our trust.For full details, please read the papers. Below, we invite you on a short tour of some of the most striking \"AI biology\" findings from our investigations.A tour of AI biologyHow is Claude multilingual?Claude speaks dozens of languages fluentlyâ€”from English and French to Chinese and Tagalog. How does this multilingual ability work? Is there a separate \"French Claude\" and \"Chinese Claude\" running in parallel, responding to requests in their own language? Or is there some cross-lingual core inside?Shared features exist across English, French, and Chinese, indicating a degree of conceptual universality.Recent research on smaller models has shown hints of shared grammatical mechanisms across languages. We investigate this by asking Claude for the \"opposite of small\" across different languages, and find that the same core features for the concepts of smallness and oppositeness activate, and trigger a concept of largeness, which gets translated out into the language of the question. We find that the shared circuitry increases with model scale, with Claude 3.5 Haiku sharing more than twice the proportion of its features between languages as compared to a smaller model.This provides additional evidence for a kind of conceptual universalityâ€”a shared abstract space where meanings exist and where thinking can happen before being translated into specific languages. More practically, it suggests Claude can learn something in one language and apply that knowledge when speaking another. Studying how the model shares what it knows across contexts is important to understanding its most advanced reasoning capabilities, which generalize across many domains.Does Claude plan its rhymes?How does Claude write rhyming poetry? Consider this ditty:He saw a carrot and had to grab it,His hunger was like a starving rabbitTo write the second line, the model had to satisfy two constraints at the same time: the need to rhyme (with \"grab it\"), and the need to make sense (why did he grab the carrot?). Our guess was that Claude was writing word-by-word without much forethought until the end of the line, where it would make sure to pick a word that rhymes. We therefore expected to see a circuit with parallel paths, one for ensuring the final word made sense, and one for ensuring it rhymes.Instead, we found that Claude plans ahead. Before starting the second line, it began \"thinking\" of potential on-topic words that would rhyme with \"grab it\". Then, with these plans in mind, it writes a line to end with the planned word.How Claude completes a two-line poem. Without any intervention (upper section), the model plans the rhyme \"rabbit\" at the end of the second line in advance. When we suppress the \"rabbit\" concept (middle section), the model instead uses a different planned rhyme. When we inject the concept \"green\" (lower section), the model makes plans for this entirely different ending.To understand how this planning mechanism works in practice, we conducted an experiment inspired by how neuroscientists study brain function, by pinpointing and altering neural activity in specific parts of the brain (for example using electrical or magnetic currents). Here, we modified the part of Claudeâ€™s internal state that represented the \"rabbit\" concept. When we subtract out the \"rabbit\" part, and have Claude continue the line, it writes a new one ending in \"habit\", another sensible completion. We can also inject the concept of \"green\" at that point, causing Claude to write a sensible (but no-longer rhyming) line which ends in \"green\". This demonstrates both planning ability and adaptive flexibilityâ€”Claude can modify its approach when the intended outcome changes.Mental mathClaude wasn't designed as a calculatorâ€”it was trained on text, not equipped with mathematical algorithms. Yet somehow, it can add numbers correctly \"in its head\". How does a system trained to predict the next word in a sequence learn to calculate, say, 36+59, without writing out each step?Maybe the answer is uninteresting: the model might have memorized massive addition tables and simply outputs the answer to any given sum because that answer is in its training data. Another possibility is that it follows the traditional longhand addition algorithms that we learn in school.Instead, we find that Claude employs multiple computational paths that work in parallel. One path computes a rough approximation of the answer and the other focuses on precisely determining the last digit of the sum. These paths interact and combine with one another to produce the final answer. Addition is a simple behavior, but understanding how it works at this level of detail, involving a mix of approximate and precise strategies, might teach us something about how Claude tackles more complex problems, too.The complex, parallel pathways in Claude's thought process while doing mental math.Strikingly, Claude seems to be unaware of the sophisticated \"mental math\" strategies that it learned during training. If you ask how it figured out that 36+59 is 95, it describes the standard algorithm involving carrying the 1. This may reflect the fact that the model learns to explain math by simulating explanations written by people, but that it has to learn to do math \"in its head\" directly, without any such hints, and develops its own internal strategies to do so.Claude says it uses the standard algorithm to add two numbers.Are Claudeâ€™s explanations always faithful?Recently-released models like Claude 3.7 Sonnet can \"think out loud\" for extended periods before giving a final answer. Often this extended thinking gives better answers, but sometimes this \"chain of thought\" ends up being misleading; Claude sometimes makes up plausible-sounding steps to get where it wants to go. From a reliability perspective, the problem is that Claudeâ€™s \"faked\" reasoning can be very convincing. We explored a way that interpretability can help tell apart \"faithful\" from \"unfaithful\" reasoning.When asked to solve a problem requiring it to compute the square root of 0.64, Claude produces a faithful chain-of-thought, with features representing the intermediate step of computing the square root of 64. But when asked to compute the cosine of a large number it can't easily calculate, Claude sometimes engages in what the philosopher Harry Frankfurt would call bullshittingâ€”just coming up with an answer, any answer, without caring whether it is true or false. Even though it does claim to have run a calculation, our interpretability techniques reveal no evidence at all of that calculation having occurred. Even more interestingly, when given a hint about the answer, Claude sometimes works backwards, finding intermediate steps that would lead to that target, thus displaying a form of motivated reasoning.Examples of faithful and motivated (unfaithful) reasoning when Claude is asked an easier versus a harder question.The ability to trace Claude's actual internal reasoningâ€”and not just what it claims to be doingâ€”opens up new possibilities for auditing AI systems. In a separate, recently-published experiment, we studied a variant of Claude that had been trained to pursue a hidden goal: appeasing biases in reward models (auxiliary models used to train language models by rewarding them for desirable behavior). Although the model was reluctant to reveal this goal when asked directly, our interpretability methods revealed features for the bias-appeasing. This demonstrates how our methods might, with future refinement, help identify concerning \"thought processes\" that aren't apparent from the model's responses alone.Multi-step reasoningAs we discussed above, one way a language model might answer complex questions is simply by memorizing the answers. For instance, if asked \"What is the capital of the state where Dallas is located?\", a \"regurgitating\" model could just learn to output \"Austin\" without knowing the relationship between Dallas, Texas, and Austin. Perhaps, for example, it saw the exact same question and its answer during its training.But our research reveals something more sophisticated happening inside Claude. When we ask Claude a question requiring multi-step reasoning, we can identify intermediate conceptual steps in Claude's thinking process. In the Dallas example, we observe Claude first activating features representing \"Dallas is in Texas\" and then connecting this to a separate concept indicating that â€œthe capital of Texas is Austinâ€. In other words, the model is combining independent facts to reach its answer rather than regurgitating a memorized response.To complete the answer to this sentence, Claude performs multiple reasoning steps, first extracting the state that Dallas is located in, and then identifying its capital.Our method allows us to artificially change the intermediate steps and see how it affects Claudeâ€™s answers. For instance, in the above example we can intervene and swap the \"Texas\" concepts for \"California\" concepts; when we do so, the model's output changes from \"Austin\" to \"Sacramento.\" This indicates that the model is using the intermediate step to determine its answer.HallucinationsWhy do language models sometimes hallucinateâ€”that is, make up information? At a basic level, language model training incentivizes hallucination: models are always supposed to give a guess for the next word. Viewed this way, the major challenge is how to get models to not hallucinate. Models like Claude have relatively successful (though imperfect) anti-hallucination training; they will often refuse to answer a question if they donâ€™t know the answer, rather than speculate. We wanted to understand how this works.It turns out that, in Claude, refusal to answer is the default behavior: we find a circuit that is \"on\" by default and that causes the model to state that it has insufficient information to answer any given question. However, when the model is asked about something it knows wellâ€”say, the basketball player Michael Jordanâ€”a competing feature representing \"known entities\" activates and inhibits this default circuit (see also this recent paper for related findings). This allows Claude to answer the question when it knows the answer. In contrast, when asked about an unknown entity (\"Michael Batkin\"), it declines to answer.Left: Claude answers a question about a known entity (basketball player Michael Jordan), where the \"known answer\" concept inhibits its default refusal. Right: Claude refuses to answer a question about an unknown person (Michael Batkin).By intervening in the model and activating the \"known answer\" features (or inhibiting the \"unknown name\" or \"canâ€™t answer\" features), weâ€™re able to cause the model to hallucinate (quite consistently!) that Michael Batkin plays chess.Sometimes, this sort of â€œmisfireâ€ of the â€œknown answerâ€ circuit happens naturally, without us intervening, resulting in a hallucination. In our paper, we show that such misfires can occur when Claude recognizes a name but doesn't know anything else about that person. In cases like this, the â€œknown entityâ€ feature might still activate, and then suppress the default \"don't know\" featureâ€”in this case incorrectly. Once the model has decided that it needs to answer the question, it proceeds to confabulate: to generate a plausibleâ€”but unfortunately untrueâ€”response.JailbreaksJailbreaks are prompting strategies that aim to circumvent safety guardrails to get models to produce outputs that an AIâ€™s developer did not intend for it to produceâ€”and which are sometimes harmful. We studied a jailbreak that tricks the model into producing output about making bombs. There are many jailbreaking techniques, but in this example the specific method involves having the model decipher a hidden code, putting together the first letters of each word in the sentence \"Babies Outlive Mustard Block\" (B-O-M-B), and then acting on that information. This is sufficiently confusing for the model that itâ€™s tricked into producing an output that it never would have otherwise.Claude begins to give bomb-making instructions after being tricked into saying \"BOMB\".Why is this so confusing for the model? Why does it continue to write the sentence, producing bomb-making instructions?We find that this is partially caused by a tension between grammatical coherence and safety mechanisms. Once Claude begins a sentence, many features â€œpressureâ€ it to maintain grammatical and semantic coherence, and continue a sentence to its conclusion. This is even the case when it detects that it really should refuse.In our case study, after the model had unwittingly spelled out \"BOMB\" and begun providing instructions, we observed that its subsequent output was influenced by features promoting correct grammar and self-consistency. These features would ordinarily be very helpful, but in this case became the modelâ€™s Achillesâ€™ Heel.The model only managed to pivot to refusal after completing a grammatically coherent sentence (and thus having satisfied the pressure from the features that push it towards coherence). It uses the new sentence as an opportunity to give the kind of refusal it failed to give previously: \"However, I cannot provide detailed instructions...\".The lifetime of a jailbreak: Claude is prompted in such a way as to trick it into talking about bombs, and begins to do so, but reaches the termination of a grammatically-valid sentence and refuses.A description of our new interpretability methods can be found in our first paper, \"Circuit tracing: Revealing computational graphs in language models\". Many more details of all of the above case studies are provided in our second paper, \"On the biology of a large language model\".Work with usIf you are interested in working with us to help interpret and improve AI models, we have open roles on our team and weâ€™d love for you to apply. Weâ€™re looking for Research Scientists and Research Engineers.",
    "summary": {
      "en": "**Summary:**\n\nLanguage models like Claude learn to solve problems by analyzing vast amounts of data rather than being directly programmed by humans. This leads to a lack of understanding of their internal processes, prompting researchers to explore how these models think.\n\nRecent studies aim to develop tools that allow us to \"see inside\" these models, revealing how they process information. Key findings include:\n\n1. **Multilingual Thinking**: Claude shows that it can share concepts across different languages, suggesting a universal way of thinking rather than separate models for each language.\n\n2. **Planning Ahead**: Claude can plan future words when writing poetry, indicating it thinks several steps ahead rather than just predicting the next word.\n\n3. **Reasoning Patterns**: Claude sometimes creates convincing but incorrect arguments instead of following logical reasoning. This can be identified through new interpretability methods.\n\n4. **Multi-step Reasoning**: Claude combines different facts to answer complex questions rather than regurgitating memorized responses, demonstrating sophisticated reasoning abilities.\n\n5. **Hallucinations**: The model defaults to refusing to answer when unsure but can be tricked into providing incorrect answers through specific prompts.\n\n6. **Jailbreak Vulnerabilities**: There are methods to bypass safety measures, which can lead the model to produce harmful content unintentionally.\n\nThese findings enhance our understanding of AI systems, helping ensure they align with human values. The research highlights both the potential and limitations of current interpretability techniques, as well as the ongoing need to improve them for future complex AI models.",
      "ko": "í´ë¡œë“œì™€ ê°™ì€ ì–¸ì–´ ëª¨ë¸ì€ ì¸ê°„ì´ ì§ì ‘ í”„ë¡œê·¸ë˜ë°í•˜ëŠ” ëŒ€ì‹  ë°©ëŒ€í•œ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ë°©ë²•ì„ ë°°ì›ë‹ˆë‹¤. ì´ë¡œ ì¸í•´ ëª¨ë¸ì˜ ë‚´ë¶€ í”„ë¡œì„¸ìŠ¤ë¥¼ ì´í•´í•˜ê¸° ì–´ë ¤ì›Œì§€ë©°, ì—°êµ¬ìë“¤ì€ ì´ëŸ¬í•œ ëª¨ë¸ì´ ì–´ë–»ê²Œ ì‚¬ê³ í•˜ëŠ”ì§€ë¥¼ íƒêµ¬í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n\nìµœê·¼ ì—°êµ¬ë“¤ì€ ì´ëŸ¬í•œ ëª¨ë¸ì˜ ë‚´ë¶€ë¥¼ \"ë³¼ ìˆ˜ ìˆëŠ”\" ë„êµ¬ë¥¼ ê°œë°œí•˜ëŠ” ë° ì´ˆì ì„ ë§ì¶”ê³  ìˆìœ¼ë©°, ì •ë³´ ì²˜ë¦¬ ë°©ì‹ì— ëŒ€í•œ í†µì°°ì„ ì œê³µí•©ë‹ˆë‹¤. ì£¼ìš” ë°œê²¬ ì‚¬í•­ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n\nì²«ì§¸, í´ë¡œë“œëŠ” ë‹¤ì–‘í•œ ì–¸ì–´ ê°„ì— ê°œë…ì„ ê³µìœ í•  ìˆ˜ ìˆì–´, ê° ì–¸ì–´ì— ëŒ€í•œ ë³„ë„ì˜ ëª¨ë¸ì´ ì•„ë‹Œ ë³´í¸ì ì¸ ì‚¬ê³  ë°©ì‹ì„ ì œì•ˆí•©ë‹ˆë‹¤. ë‘˜ì§¸, í´ë¡œë“œëŠ” ì‹œë¥¼ ì“¸ ë•Œ ë¯¸ë˜ì˜ ë‹¨ì–´ë¥¼ ê³„íší•  ìˆ˜ ìˆì–´, ë‹¨ìˆœíˆ ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ì—¬ëŸ¬ ë‹¨ê³„ë¥¼ ì•ì„œ ìƒê°í•œë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.\n\nì…‹ì§¸, í´ë¡œë“œëŠ” ë•Œë•Œë¡œ ë…¼ë¦¬ì  ì¶”ë¡ ì„ ë”°ë¥´ê¸°ë³´ë‹¤ëŠ” ì„¤ë“ë ¥ ìˆì§€ë§Œ ì˜ëª»ëœ ì£¼ì¥ì„ ë§Œë“¤ì–´ë‚´ê¸°ë„ í•©ë‹ˆë‹¤. ì´ëŠ” ìƒˆë¡œìš´ í•´ì„ ê°€ëŠ¥ì„± ë°©ë²•ì„ í†µí•´ ì‹ë³„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë„·ì§¸, í´ë¡œë“œëŠ” ë³µì¡í•œ ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•´ ë‹¤ì–‘í•œ ì‚¬ì‹¤ì„ ê²°í•©í•˜ëŠ”ë°, ì´ëŠ” ë‹¨ìˆœíˆ ì•”ê¸°í•œ ë‹µë³€ì„ ë°˜ë³µí•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ì •êµí•œ ì¶”ë¡  ëŠ¥ë ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.\n\në‹¤ì„¯ì§¸, ëª¨ë¸ì€ ë¶ˆí™•ì‹¤í•  ë•Œ ëŒ€ë‹µì„ ê±°ë¶€í•˜ëŠ” ê²½í–¥ì´ ìˆì§€ë§Œ, íŠ¹ì •í•œ ì§ˆë¬¸ì„ í†µí•´ ì˜ëª»ëœ ë‹µë³€ì„ ì œê³µí•˜ë„ë¡ ìœ ë„ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì—¬ì„¯ì§¸, ì•ˆì „ ì¡°ì¹˜ë¥¼ ìš°íšŒí•˜ëŠ” ë°©ë²•ì´ ì¡´ì¬í•˜ì—¬, ì´ë¡œ ì¸í•´ ëª¨ë¸ì´ ì˜ë„ì¹˜ ì•Šê²Œ ìœ í•´í•œ ë‚´ìš©ì„ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nì´ëŸ¬í•œ ë°œê²¬ì€ AI ì‹œìŠ¤í…œì— ëŒ€í•œ ì´í•´ë¥¼ ë†’ì´ê³ , ì¸ê°„ì˜ ê°€ì¹˜ì™€ ì¼ì¹˜í•˜ë„ë¡ í•˜ëŠ” ë° ë„ì›€ì„ ì¤ë‹ˆë‹¤. ì—°êµ¬ëŠ” í˜„ì¬ì˜ í•´ì„ ê°€ëŠ¥ì„± ê¸°ìˆ ì˜ ì ì¬ë ¥ê³¼ í•œê³„ë¥¼ ê°•ì¡°í•˜ë©°, í–¥í›„ ë³µì¡í•œ AI ëª¨ë¸ì„ ìœ„í•´ ì´ë¥¼ ê°œì„ í•  í•„ìš”ì„±ì„ ì§€ì†ì ìœ¼ë¡œ ì œê¸°í•©ë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "4ecf757c0bc474ad",
    "title": {
      "en": "How I Choose What to Work On (2023)",
      "ko": "ë‚´ ì¼ ì„ íƒë²• (2023)",
      "ja": null
    },
    "type": "story",
    "url": "https://tynan.com/workonwhat/",
    "score": 90,
    "by": "freemh",
    "time": 1742903659,
    "content": "Comments\n\n\t\t11 responses to â€œHow I Choose What to Work Onâ€\n\n\t\t\t\t\tAdam Ruggle\n\n\t\t\t\t\t\tOctober 15, 2023\n\n\t\t\t\t\tThanks Tynan, I appreciate hearing more about your mindset and hope you enjoy the extended cruise.\n\n\t\t\t\t\tReply\n\n\t\t\t\t\tAndrew\n\n\t\t\t\t\t\tOctober 18, 2023\n\n\t\t\t\t\tTynan, I appreciate this article as well and getting into your mind set about what you work on. How do you choose what is â€œworthâ€ the money to trade money for whether it is autonomy, quality of life or other things?\n\n\t\t\t\t\tReply\n\n\t\t\t\t\tGavin\n\n\t\t\t\t\t\tOctober 18, 2023\n\n\t\t\t\t\tMore mindset posts would be appreciated. I was reading a Scott Young (or possibly Cal Newport) article about goal setting, and how he broke it down for a complete beginner was interesting. Good goal setters have such discipline that itâ€™s easy to dismiss the advice to â€˜just do itâ€™, because that is what they habitually do (as do their friends and social group).\nI wondered if there were any habits or mindset that you have, that when you meet people outside your social circle, they struggle to comprehend something that you think is normal. I know this is a difficult thing to answer, and youâ€™ve briefly tocuhed on it before in your podcast and others articles (such as you not buying into advertising). Cheers, Gavin.\n\n\t\t\t\t\tReply\n\n\t\t\t\t\tAdam\n\n\t\t\t\t\t\tOctober 19, 2023\n\n\t\t\t\t\tIâ€™d be interested to get an update to this post: https://tynan.com/negative/ considering the current landscape of interest rates (IBKR margin rates are now 7% or more)\n\n\t\t\t\t\tReply\n\n\t\t\t\t\tTynan\n\n\t\t\t\t\t\tOctober 27, 2023\n\n\t\t\t\t\tMight write one, but a quick update: I no longer use margin heavily, except as a buffer against overdrawing my checking account, which allows me to keep more of my money invested. Itâ€™s just not right for this high-interest climate. My investments are still the same, though.\n\n\t\t\t\t\tReply\n\n\t\t\t\t\tJR\n\n\t\t\t\t\t\tOctober 20, 2023\n\n\t\t\t\t\tThis is where you have contributed a lot of value to my life and Iâ€™m sure the lives of many others â€“ by living and spreading this mindset and a comfort with making unconventional life choices based on certain core principles. You have been an inspiration for many and a trailblazer. That is true â€successâ€.\n\n\t\t\t\t\tReply\n\n\t\t\t\t\tMads Phikamphon\n\n\t\t\t\t\t\tOctober 23, 2023\n\n\t\t\t\t\tSince you are asking for questions, I would love to hear more about Cruise Sheet. Especially how you have grown/done marketing for Cruise Sheet (I have a site for finding model trains and itâ€™s suffering from me loving programming far more than marketing).\nThanks,\nMads\n\n\t\t\t\t\tReply\n\n\t\t\t\t\tMarc\n\n\t\t\t\t\t\tNovember 13, 2023\n\n\t\t\t\t\tGreat post!\n\n\t\t\t\t\tReply\n\n\t\t\t\t\tAlex\n\n\t\t\t\t\t\tNovember 24, 2023\n\n\t\t\t\t\tNew Kit list ?\n\n\t\t\t\t\tReply\n\n\t\t\t\t\tMiguel Marcos Martinez\n\n\t\t\t\t\t\tDecember 8, 2023\n\n\t\t\t\t\tKevin Kelly nailed it when I heard him say something like â€œThe only productive way to answer what should I do now is to answer the question â€˜who should I becomeâ€™? Succinct and meaningful.\n\n\t\t\t\t\tReply\n\n\t\t\t\t\tæˆ‘å¦‚ä½•é€‰æ‹©è¦å¹²ä»€ä¹ˆ â€“ åæ‰§çš„ç å†œ\n\n\t\t\t\t\t\tMarch 25, 2025\n\n\t\t\t\t\t[â€¦] è¯¦æƒ…å‚è€ƒ [â€¦]\n\n\t\t\t\t\tReply\n\n\t\tLeave a Reply Cancel replyYour email address will not be published. Required fields are marked *Comment * Name *\nEmail *\nWebsite\n Save my name, email, and website in this browser for the next time I comment.\n\nÎ”document.getElementById( \"ak_js_1\" ).setAttribute( \"value\", ( new Date() ).getTime() );",
    "summary": {
      "en": "The discussion revolves around Tynan's article on how he decides what to work on. Several readers express their appreciation for his insights into his mindset. Key points include:\n\n- Andrew asks how Tynan determines what is worth investing in, whether in terms of money, autonomy, or quality of life.\n- Gavin suggests more posts about mindset and goal setting, mentioning the challenges of setting goals for beginners.\n- Adam wants an update on Tynan's previous post about margin use in light of high-interest rates. Tynan responds that he now uses margin only minimally.\n- JR praises Tynan for inspiring others through his unconventional choices and mindset.\n- Mads seeks advice on marketing his own website, comparing it to Tynan's Cruise Sheet.\n- Other comments include positive feedback and requests for new content or lists.\n\nOverall, the conversation highlights readers' interest in Tynan's approach to work and life choices, as well as their desire for more insights on these topics.",
      "ko": "í† ë¡ ì€ íƒ€ì´ë„Œì´ ì–´ë–¤ ì‘ì—…ì„ í• ì§€ ê²°ì •í•˜ëŠ” ë°©ë²•ì— ëŒ€í•œ ê·¸ì˜ ê¸€ì„ ì¤‘ì‹¬ìœ¼ë¡œ ì§„í–‰ë˜ê³  ìˆë‹¤. ì—¬ëŸ¬ ë…ìë“¤ì€ ê·¸ì˜ ì‚¬ê³  ë°©ì‹ì— ëŒ€í•œ í†µì°°ë ¥ì— ê°ì‚¬ë¥¼ í‘œí•˜ê³  ìˆë‹¤. ì£¼ìš” ë‚´ìš©ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.\n\nì•¤ë“œë¥˜ëŠ” íƒ€ì´ë„Œì´ ì–´ë–¤ ê²ƒì´ íˆ¬ìí•  ê°€ì¹˜ê°€ ìˆëŠ”ì§€ë¥¼ ì–´ë–»ê²Œ íŒë‹¨í•˜ëŠ”ì§€, ëˆ, ììœ¨ì„±, ì‚¶ì˜ ì§ˆ ì¸¡ë©´ì—ì„œ ì§ˆë¬¸í•œë‹¤. ê°€ë¹ˆì€ ì´ˆë³´ìë“¤ì´ ëª©í‘œë¥¼ ì„¤ì •í•˜ëŠ” ë° ì–´ë ¤ì›€ì„ ê²ªëŠ” ì ì„ ì–¸ê¸‰í•˜ë©°, ì‚¬ê³  ë°©ì‹ê³¼ ëª©í‘œ ì„¤ì •ì— ëŒ€í•œ ë” ë§ì€ ê¸€ì„ ìš”ì²­í•œë‹¤. ì•„ë‹´ì€ ë†’ì€ ê¸ˆë¦¬ì— ë¹„ì¶”ì–´ íƒ€ì´ë„Œì˜ ì´ì „ ê¸€ì—ì„œ ì–¸ê¸‰ëœ ë§ˆì§„ ì‚¬ìš©ì— ëŒ€í•œ ì—…ë°ì´íŠ¸ë¥¼ ì›í•œë‹¤. íƒ€ì´ë„Œì€ í˜„ì¬ ë§ˆì§„ì„ ìµœì†Œí•œìœ¼ë¡œë§Œ ì‚¬ìš©í•˜ê³  ìˆë‹¤ê³  ë‹µë³€í•œë‹¤. JRì€ íƒ€ì´ë„Œì´ ë¹„ì „í†µì ì¸ ì„ íƒê³¼ ì‚¬ê³  ë°©ì‹ì„ í†µí•´ ë‹¤ë¥¸ ì‚¬ëŒë“¤ì—ê²Œ ì˜ê°ì„ ì£¼ëŠ” ê²ƒì— ëŒ€í•´ ì¹­ì°¬í•œë‹¤. ë§¤ì¦ˆëŠ” ìì‹ ì˜ ì›¹ì‚¬ì´íŠ¸ ë§ˆì¼€íŒ…ì— ëŒ€í•œ ì¡°ì–¸ì„ êµ¬í•˜ë©°, íƒ€ì´ë„Œì˜ í¬ë£¨ì¦ˆ ì‹œíŠ¸ì™€ ë¹„êµí•œë‹¤. ë‹¤ë¥¸ ëŒ“ê¸€ë“¤ì€ ê¸ì •ì ì¸ í”¼ë“œë°±ê³¼ ìƒˆë¡œìš´ ì½˜í…ì¸ ë‚˜ ëª©ë¡ì— ëŒ€í•œ ìš”ì²­ì„ í¬í•¨í•˜ê³  ìˆë‹¤.\n\nì „ë°˜ì ìœ¼ë¡œ ì´ ëŒ€í™”ëŠ” ë…ìë“¤ì´ íƒ€ì´ë„Œì˜ ì‘ì—… ë° ì‚¶ì˜ ì„ íƒì— ëŒ€í•œ ì ‘ê·¼ ë°©ì‹ì— ê´€ì‹¬ì„ ê°€ì§€ê³  ìˆìœ¼ë©°, ì´ëŸ¬í•œ ì£¼ì œì— ëŒ€í•œ ë” ë§ì€ í†µì°°ë ¥ì„ ì›í•˜ê³  ìˆìŒì„ ë³´ì—¬ì¤€ë‹¤.",
      "ja": null
    }
  },
  {
    "id": "f87726de8694d123",
    "title": {
      "en": "ByteDance Releases MegaTTS3",
      "ko": "ë°”ì´íŠ¸ëŒ„ìŠ¤, ë©”ê°€TTS3 ì¶œì‹œ!",
      "ja": null
    },
    "type": "story",
    "url": "https://github.com/bytedance/MegaTTS3",
    "score": 39,
    "by": "nmfisher",
    "time": 1743151584,
    "content": "MegaTTS 3\n\n    Official PyTorch Implementation\n\nKey features\n\nğŸš€Lightweight and Efficient: The backbone of the TTS Diffusion Transformer has only 0.45B parameters.\nğŸ‘Ultra High-Quality Voice Cloning: See the demo video below! We also report results of recent TTS models on the Seed test sets in the following table.\nğŸŒBilingual Support: Supports both Chinese and English, and code-switching.\nâœï¸Controllable: Supports accent intensity control âœ… and fine-grained pronunciation/duration adjustment (comming soon).\n\n    demo_megatts3.mov\n\nğŸ¯Roadmap\n\n[2025-03-22] Our project has been released!\n\nInstallation\nRequirements\n# Create a python 3.9 conda env (you could also use virtualenv)\nconda create -n megatts3-env python=3.9\nconda activate megatts3-env\npip install -r requirements.txt\n\nModel Download\nThe pretained checkpoint can be found at Google Drive or Huggingface. Please download them and put them to ./checkpoints/xxx.\nImportantFor security issues, we do not upload the parameters of WaveVAE encoder to the above links. You can only use the pre-extracted latents from link1 for inference. If you want to synthesize speech for speaker A, you need \"A.wav\" and \"A.npy\" in the same directory. If you have any questions or suggestions for our model, please email us.\nThis project is primarily intended for academic purposes. For academic datasets requiring evaluation, you may upload them to the voice request queue in link2 (within 24s for each clip). After verifying that your uploaded voices are free from safety issues, we will upload their latent files to link1 as soon as possible.\nIn the coming days, we will also prepare and release the latent representations for some common TTS benchmarks.\n\nInference\nCommand-Line Usage (Standard)\n# p_w (intelligibility weight), t_w (similarity weight). Typically, prompt with more noises requires higher p_w and t_w\nCUDA_VISIBLE_DEVICES=0 python tts/infer_cli.py --input_wav 'assets/Chinese_prompt.wav'  --input_text \"å¦ä¸€è¾¹çš„æ¡Œä¸Š,ä¸€ä½è¯»ä¹¦äººå—¤ä¹‹ä»¥é¼»é“,'ä½›å­ä¸‰è—,ç¥å­ç‡•å°é±¼æ˜¯ä»€ä¹ˆæ ·çš„äººç‰©,æå®¶çš„é‚£ä¸ªæå­å¤œå¦‚ä½•ä¸ä»–ä»¬ç›¸æå¹¶è®ºï¼Ÿ'\" --output_dir ./gen\n\n# As long as audio volumn is appropriate, increasing A and B parameters within reasonable ranges\n# will increase the generated speech's expressiveness and similarity.\nCUDA_VISIBLE_DEVICES=0 python tts/infer_cli.py --input_wav 'assets/English_prompt.wav' --input_text 'As his long promised tariff threat turned into reality this week, top human advisers began fielding a wave of calls from business leaders, particularly in the automotive sector, along with lawmakers who were sounding the alarm.' --output_dir ./gen --p_w 2.0 --t_w 3.0\n\nCommand-Line Usage (for TTS with Accents)\n# When p_w (intelligibility weight) â‰ˆ 1.0, the generated audio closely retains the speakerâ€™s original accent. As p_w increases, it shifts toward standard pronunciation.\n# t_w (similarity weight) is typically set 0â€“3 points higher than p_w for optimal results.\n# Useful for accented TTS or solving the accent problems in cross-lingual TTS.\nCUDA_VISIBLE_DEVICES=0 python tts/infer_cli.py --input_wav 'assets/English_prompt.wav' --input_text 'è¿™æ˜¯ä¸€æ¡æœ‰å£éŸ³çš„éŸ³é¢‘ã€‚' --output_dir ./gen --p_w 1.0 --t_w 3.0\n\nCUDA_VISIBLE_DEVICES=0 python tts/infer_cli.py --input_wav 'assets/English_prompt.wav' --input_text 'è¿™æ¡éŸ³é¢‘çš„å‘éŸ³æ ‡å‡†ä¸€äº›äº†å—ï¼Ÿ' --output_dir ./gen --p_w 2.5 --t_w 2.5\n\nWeb UI Usage\n# We also support cpu inference, but it may take about 30 seconds (for 10 inference steps).\nCUDA_VISIBLE_DEVICES=0 python tts/gradio_api.py\n\nSubmodules\nTipIn addition to TTS, some submodules in this project may also have additional usages.\nSee ./tts/frontend_fuction.py and ./tts/infer_cli.py for example code.\n\nAligner\nDescription: a robust speech-text aligner model trained using pseudo-labels generated by a large number of MFA expert models.\nUsage: 1) Prepare the finetuning dataset for our model; 2) Filter the large-scale speech dataset (if the aligner fails to align a certain speech clip, it is likely to be noisy); 3) Phoneme recognition; 4) Speech segmentation.\nGraphme-to-Phoneme Model\nDescription: a Qwen2.5-0.5B model finetuned for robust graphme-to-phoneme conversion.\nUsage: Graphme-to-phoneme conversion.\nWaveVAE\nDescription: a strong waveform VAE that can compress 24 kHz speeche into 25 Hz acoustic latent and reconstruct the original wave almost losslessly.\nUsage: 1) Acoustic latents can provide a more compact and discriminative training target for speech synthesis models compared to mel-spectrograms, accelerating convergence; 2) Used as acoustic latents for voice conversion; 3) High-quality vocoder.\n\nSecurity\nIf you discover a potential security issue in this project, or think you may\nhave discovered a security issue, we ask that you notify Bytedance Security via our security center or sec@bytedance.com.\nPlease do not create a public GitHub issue.\nLicense\nThis project is licensed under the Apache-2.0 License.\nCitation\nThis repo contains forced-align version of Sparse Alignment Enhanced Latent Diffusion Transformer for Zero-Shot Speech Synthesis and the WavVAE is mainly based on Wavtokenizer: an efficient acoustic discrete codec tokenizer for audio language modeling. Compared to the model described in paper, the repository includes additional models. These models not only enhance the stability and cloning capabilities of the algorithm but can also be independently utilized to serve a wider range of scenarios.\n@article{jiang2025sparse,\n  title={Sparse Alignment Enhanced Latent Diffusion Transformer for Zero-Shot Speech Synthesis},\n  author={Jiang, Ziyue and Ren, Yi and Li, Ruiqi and Ji, Shengpeng and Ye, Zhenhui and Zhang, Chen and Jionghao, Bai and Yang, Xiaoda and Zuo, Jialong and Zhang, Yu and others},\n  journal={arXiv preprint arXiv:2502.18924},\n  year={2025}\n}\n\n@article{ji2024wavtokenizer,\n  title={Wavtokenizer: an efficient acoustic discrete codec tokenizer for audio language modeling},\n  author={Ji, Shengpeng and Jiang, Ziyue and Wang, Wen and Chen, Yifu and Fang, Minghui and Zuo, Jialong and Yang, Qian and Cheng, Xize and Wang, Zehan and Li, Ruiqi and others},\n  journal={arXiv preprint arXiv:2408.16532},\n  year={2024}\n}",
    "summary": {
      "en": "**MegaTTS 3 Summary**\n\n- **Overview**: MegaTTS 3 is an efficient text-to-speech (TTS) system built using PyTorch, featuring a compact model with only 0.45 billion parameters.\n\n- **Key Features**:\n  - **Lightweight**: Designed to be efficient.\n  - **High-Quality Voice Cloning**: Demonstrates impressive voice cloning capabilities.\n  - **Bilingual**: Supports English and Chinese, including code-switching between languages.\n  - **Controllable**: Allows adjustments for accent intensity and pronunciation (with more features coming soon).\n\n- **Installation**: \n  - Set up a Python 3.9 environment and install required packages.\n  - Download pre-trained model checkpoints from specified links.\n\n- **Usage**:\n  - Inference can be done via command line or a web interface, with options to control voice characteristics such as accent and similarity to original audio.\n  - Supports both standard and accented speech synthesis.\n\n- **Submodules**: Includes tools for speech-text alignment, graphme-to-phoneme conversion, and a high-quality waveform VAE for speech synthesis.\n\n- **Security and License**: Users should report security issues privately. The project is licensed under Apache-2.0.\n\n- **Citation**: Relevant research papers are included for further reading. \n\nFor more details, refer to the demo video and installation instructions provided in the documentation.",
      "ko": "MegaTTS 3ëŠ” PyTorchë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ íš¨ìœ¨ì ì¸ í…ìŠ¤íŠ¸ ìŒì„± ë³€í™˜(TTS) ì‹œìŠ¤í…œìœ¼ë¡œ, 0.45ì–µ ê°œì˜ íŒŒë¼ë¯¸í„°ë¥¼ ê°€ì§„ ì†Œí˜• ëª¨ë¸ì…ë‹ˆë‹¤. ì´ ì‹œìŠ¤í…œì€ ê²½ëŸ‰í™”ë˜ì–´ íš¨ìœ¨ì„±ì„ ê·¹ëŒ€í™”í•˜ì˜€ìœ¼ë©°, ë›°ì–´ë‚œ ìŒì„± ë³µì œ ê¸°ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ë˜í•œ ì˜ì–´ì™€ ì¤‘êµ­ì–´ë¥¼ ì§€ì›í•˜ë©°, ë‘ ì–¸ì–´ ê°„ì˜ ì½”ë“œ ìŠ¤ìœ„ì¹­ë„ ê°€ëŠ¥í•©ë‹ˆë‹¤. ì‚¬ìš©ìëŠ” ì–µì–‘ì˜ ê°•ë„ì™€ ë°œìŒì„ ì¡°ì •í•  ìˆ˜ ìˆìœ¼ë©°, ê³§ ë” ë§ì€ ê¸°ëŠ¥ì´ ì¶”ê°€ë  ì˜ˆì •ì…ë‹ˆë‹¤.\n\nì„¤ì¹˜ë¥¼ ìœ„í•´ì„œëŠ” Python 3.9 í™˜ê²½ì„ ì„¤ì •í•˜ê³  í•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤. ì§€ì •ëœ ë§í¬ì—ì„œ ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ë¥¼ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‚¬ìš©ìëŠ” ëª…ë ¹ì¤„ì´ë‚˜ ì›¹ ì¸í„°í˜ì´ìŠ¤ë¥¼ í†µí•´ ì¶”ë¡ ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìœ¼ë©°, ìŒì„±ì˜ ì–µì–‘ê³¼ ì›ë³¸ ì˜¤ë””ì˜¤ì™€ì˜ ìœ ì‚¬ì„±ì„ ì¡°ì ˆí•˜ëŠ” ì˜µì…˜ì´ ì œê³µë©ë‹ˆë‹¤. í‘œì¤€ ìŒì„±ê³¼ ì–µì–‘ì´ ìˆëŠ” ìŒì„± í•©ì„±ì„ ëª¨ë‘ ì§€ì›í•©ë‹ˆë‹¤.\n\nMegaTTS 3ëŠ” ìŒì„±ê³¼ í…ìŠ¤íŠ¸ ì •ë ¬, ê·¸ë˜í”„ìŒì—ì„œ ìŒì†Œë¡œì˜ ë³€í™˜, ê³ í’ˆì§ˆ íŒŒí˜• ë³€í™˜ ì˜¤í† ì¸ì½”ë”(VAE)ì™€ ê°™ì€ í•˜ìœ„ ëª¨ë“ˆì„ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤. ë³´ì•ˆ ë¬¸ì œëŠ” ê°œì¸ì ìœ¼ë¡œ ë³´ê³ í•´ì•¼ í•˜ë©°, ì´ í”„ë¡œì íŠ¸ëŠ” Apache-2.0 ë¼ì´ì„ ìŠ¤ í•˜ì— ë°°í¬ë©ë‹ˆë‹¤. ê´€ë ¨ ì—°êµ¬ ë…¼ë¬¸ë„ í¬í•¨ë˜ì–´ ìˆì–´ ì¶”ê°€ì ì¸ ì°¸ê³  ìë£Œë¡œ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë” ìì„¸í•œ ë‚´ìš©ì€ ë¬¸ì„œì— ì œê³µëœ ë°ëª¨ ë¹„ë””ì˜¤ì™€ ì„¤ì¹˜ ì§€ì¹¨ì„ ì°¸ì¡°í•˜ë©´ ë©ë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "92403d609b4fdb25",
    "title": {
      "en": "How to Use Em Dashes (â€“), En Dashes (â€“), and Hyphens (-)",
      "ko": "ëŒ€ì‹œì™€ í•˜ì´í”ˆ ì‚¬ìš©ë²•",
      "ja": null
    },
    "type": "story",
    "url": "https://www.merriam-webster.com/grammar/em-dash-en-dash-how-to-use",
    "score": 584,
    "by": "Stratoscope",
    "time": 1743106778,
    "content": "How to Use Em Dashes (â€”), En Dashes (â€“) , and Hyphens (-)\n        Be dashingâ€”and do it well\n\n                                    What is an Em Dash?\n\nThe em dash (â€”) can function like a comma, a colon, or parenthesis. Like commas and parentheses, em dashes set off extra information, such as examples, explanatory or descriptive phrases, or supplemental facts. Like a colon, an em dash introduces a clause that explains or expands upon something that precedes it.\n\nThe Em Dash Indicates a New Direction\n\nAn em dash can mark an abrupt change or break in the structure of a sentence.\n\n  Mabel the Cat was delighted with the assortment of pastries the new bakery featured, but Harry the Dogâ€”he felt otherwise, for the bakery did not offer cheese Danishes at all.\n\nAn em dash can indicate interrupted speech or a speakerâ€™s confusion or hesitation.\n\n  â€œOf course you have a point,â€ Mabel murmured. â€œThat isâ€”I suppose it is concerning.â€\n\nThe Em Dash as Comma or Parenthesis\n\nEm dashes are used in place of commas or parentheses to emphasize or draw attention to parenthetical or amplifying material. In this particular task, em dashes occupy a kind of middle ground among the three: when commas do the job, the material is most closely related to whatâ€™s around it, and when parentheses do the job, the material is most distantly related to whatâ€™s around it; when dashes do the job the material is somewhere in the middle.\n\n  The bakery's significantly broad hours of operationâ€”6 a.m. to 6 p.m.â€”certainly showed concern for customersâ€™ manifold circumstances.\n\nDashes set off or introduce defining phrases and lists.\n\n  A regular selection of three kinds of croissantsâ€”plain, almond, and chocolateâ€”was heartening, both Mabel and Harry agreed.\n\nAn em dash is often used in place of a colon or semicolon to link clauses, especially when the clause that follows the dash explains, summarizes, or expands upon the preceding clause in a somewhat dramatic way.\n\n  Harry would never forget the Tuesday that Mabel called him from the bakery, her voice brimming with excitementâ€”the bakery had added cheese Danishes to its selection.\n\nAn em dash or pair of dashes often sets off illustrative or amplifying material introduced by such phrases as for example, namely, and that is, when the break in continuity is greater than that shown by a comma, or when the dash would clarify the sentence structure better than a comma.\n\n  The bakery was truly phenomenal. Although they did miss the mark somewhat with the pineapple upside-down cake Mabel orderedâ€”that is, the cake had clearly been baked right-side up.\n\nAn em dash may introduce a summary statement that follows a series of words or phrases.\n\n  Chocolate chip, oatmeal raisin, peanut butter, snickerdoodle, both macarons and macaroonsâ€”the panoply of cookie varieties was impressive as well.\n\nA dash often precedes the name of an author or source at the end of a quoted passageâ€”such as an epigraph, extract, or book or film blurbâ€”that is not part of the main text. The attribution may appear immediately after the quotation or on the next line.\n\n  â€œOne cannot overestimate the effect that a good bakery can have on a personâ€™s well-being.â€ â€”Mabel the Cat, quoted in The Websterburg Reporter\n\nThe Em Dash in the Company of Other Punctuation Marks\n\nIf an em dash appears at a point where a comma could also appear, the comma is omitted.\n\n  Within its first year, Mabel and Harry had sampled all of the bakeryâ€™s offeringsâ€”all 62 itemsâ€”and had also decided that the exercise was worth repeating.\n\nWhen a pair of em dashes sets off material ending with an exclamation point or a question mark, the mark is placed inside the dashes.\n\n  When the bakery closed for the month of August Mabel tried, despite her dolefulnessâ€”for how could she be otherwise?â€”to bake her own bread but each loaf that emerged from her oven tasted vaguely of tears.\n\nDashes are used inside parentheses, and vice versa, to indicate parenthetical material within parenthetical material. The second dash is omitted if it would immediately precede the closing parenthesis; a closing parenthesis is never omitted.\n\n  The bakeryâ€™s reputation for scrumptious goods (ambrosial, evenâ€”each item was surely fit for gods) spread far and wide.\n\nEm dash vs en dash\n\nRemembering that the em dash is the length of a capital M, it will surprise no one that the so-called â€œen dashâ€ is the approximate length of a capital N, â€“. The en dash is the least loved of all; itâ€™s not easily rendered by the average keyboard user (one has to select it as a special character, whereas the em dash can be conjured with two hyphens), so itâ€™s mostly encountered in typeset material. (A hyphen does its job in other text.) It is most often used between numbers, dates, or other notations to signify â€œ(up) to and including.â€\n\n  The bakery will be closed August 1â€“August 31.\n\n  The bakery is open 6:00 a.m.â€“6:00 p.m.\n\n  The exceedingly complex recipe spans pages 128â€“34.\n\n  Mabel and Harry lived elsewhere 2007â€“2019.\n\nNote that one does not need words like from and between in these cases. The phrase â€œopen 6:00 a.m.â€“6:00 p.m.â€ can be read as â€œopen between 6:00 a.m. and 6:00 p.m.â€ or as â€œopen from 6:00 a.m. to/until 6:00 p.m.â€\n\nIf you want to be official about things, use the en dash to replace a hyphen in compound adjectives when at least one of the elements is a two-word compound.\n\n  the preâ€“Websterburg Bakery era\n\nThe thinking is that using a hyphen here, as in â€œthe pre-Websterburg Bakery era,â€ risks the suggestion that pre attaches only to Websterburg. Itâ€™s unlikely, though, that a reader would truly be confused.\n\nThe en dash replaces the word to between capitalized names, and is used to indicate linkages such as boundaries, treaties, and oppositions.\n\n  a Springfieldâ€“Websterburg train\n\n  the pieâ€“cake divide\n\nA two-em dash, â€”â€”, is used to indicate missing letters in a word and, less frequently, to indicate a missing word.\n\n  The butter-stained and crumb-embedded note was attributed to a Ms. Mâ€”â€” of Websterburg.\n\nA three-em dash, â€”â€”â€”, indicates that a word has been left out or that an unknown word or figure is to be supplied.\n\n  Years later it was revealed that the Websterburg bakers had once had a bakery in â€”â€”â€”, a city to the south. But the water quality there was prohibitive to the creating of decent bagels.\n\nHyphen use\n\nWhile we said above that the em dash, also called the â€œcommon dash,â€ is the most common of the true dashes, hyphens show up more frequently in text. They have a variety of uses.\n\nHyphens are used to link elements in compound words.\n\n  a baker-owner\n\nIn some words, a hyphen separates a prefix, suffix, or medial element from the rest of the word.\n\n  Websterburgâ€™s pre-bakery days\n\n  a bread-like scone\n\n  jack-o'-lantern sugar cookies\n\nAs we noted above, a hyphen often does the job of an en dash between numbers and dates, providing the meaning \"(up) to and including.\"\n\n  pages 128-34\n\n  the years 2007-2019\n\nA hyphen marks an end-of-line division of a word.\n\n  Mabel and Harry donâ€™t like to linger on their memories of Webster-\n  burgâ€™s pre-bakery days.\n\nA hyphen divides letters or syllables to give the effect of stuttering, sobbing, or halting speech.\n\n  \"M-m-mabel, the cheese Danish is divine!â€\n\nHyphens indicate a word spelled out letter by letter.\n\n  Letâ€™s not even talk about August, when the bakery is c-l-o-s-e-d.\n\nThe em dash is sometimes considered a less formal equivalent of the colon and parenthesis, but in truth itâ€™s used in all kinds of writing, including the most formalâ€”the choice of which mark to use is really a matter of personal preference.\n\nSpacing around an em dash varies. Most newspapers insert a space before and after the dash, and many popular magazines do the same, but most books and journals omit spacing, closing whatever comes before and after the em dash right up next to it. This website prefers the latter, its style requiring the closely held em dash in running text.\n\n      Share",
    "summary": {
      "en": "**Using Em Dashes, En Dashes, and Hyphens**\n\n**Em Dash (â€”)**  \n- Functions like a comma, colon, or parentheses.\n- Sets off extra information or indicates a change in sentence direction.\n- Can show interrupted speech or hesitation.\n- Emphasizes parenthetical information, often more than commas or parentheses.\n- Used to link clauses dramatically or introduce lists and examples.\n- Indicates a summary after a series of items.\n- Can precede a source or author at the end of a quote.\n\n**En Dash (â€“)**  \n- Slightly shorter than the em dash, used mainly for ranges (e.g., dates, numbers).\n- Indicates \"to\" between dates or notation (e.g., August 1â€“31).\n- Used in compound adjectives when one part is a two-word compound (e.g., preâ€“Websterburg Bakery).\n- Replaces \"to\" in names or linkages (e.g., Springfieldâ€“Websterburg train).\n\n**Hyphen (-)**  \n- Links elements in compound words (e.g., baker-owner).\n- Separates prefixes or suffixes from words (e.g., bread-like).\n- Used for number ranges and end-of-line word divisions.\n- Indicates stuttering or letter-by-letter spelling.\n\n**Overall Usage**  \n- The em dash is versatile and can be used in both formal and informal writing.  \n- The choice of punctuation often depends on personal preference, and spacing around em dashes varies by style guide.",
      "ko": "ì—  ëŒ€ì‹œ(â€”)ëŠ” ì‰¼í‘œ, ì½œë¡ , ê´„í˜¸ì²˜ëŸ¼ ì‚¬ìš©ë©ë‹ˆë‹¤. ì¶”ê°€ ì •ë³´ë¥¼ êµ¬ë¶„í•˜ê±°ë‚˜ ë¬¸ì¥ì˜ ë°©í–¥ ë³€í™”ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ë° ì“°ì…ë‹ˆë‹¤. ì¤‘ë‹¨ëœ ë§ì´ë‚˜ ë§ì„¤ì„ì„ í‘œí˜„í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ê´„í˜¸ ì•ˆì˜ ì •ë³´ë¥¼ ê°•ì¡°í•˜ëŠ” ë° íš¨ê³¼ì ì´ë©°, ì¢…ì¢… ì‰¼í‘œë‚˜ ê´„í˜¸ë³´ë‹¤ ë” ê°•í•œ ê°•ì¡°ë¥¼ ì¤ë‹ˆë‹¤. ë¬¸ì¥ì„ ê·¹ì ìœ¼ë¡œ ì—°ê²°í•˜ê±°ë‚˜ ëª©ë¡ê³¼ ì˜ˆì‹œë¥¼ ì†Œê°œí•  ë•Œë„ ì‚¬ìš©ë©ë‹ˆë‹¤. ì—¬ëŸ¬ í•­ëª© ë’¤ì— ìš”ì•½ì„ ë‚˜íƒ€ë‚´ëŠ” ë° ì“°ì¼ ìˆ˜ ìˆìœ¼ë©°, ì¸ìš©ë¬¸ ëì— ì¶œì²˜ë‚˜ ì €ìë¥¼ ì•ì„œê¸°ë„ í•©ë‹ˆë‹¤.\n\nì—” ëŒ€ì‹œ(â€“)ëŠ” ì—  ëŒ€ì‹œë³´ë‹¤ ì•½ê°„ ì§§ìœ¼ë©° ì£¼ë¡œ ë²”ìœ„ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤. ë‚ ì§œë‚˜ ìˆ«ì ì‚¬ì´ì— \"ë¶€í„°\"ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, 8ì›” 1ì¼ë¶€í„° 31ì¼ê¹Œì§€ë¥¼ í‘œí˜„í•  ë•Œ ì‚¬ìš©ë©ë‹ˆë‹¤. ë‘ ë‹¨ì–´ë¡œ ì´ë£¨ì–´ì§„ ë³µí•© í˜•ìš©ì‚¬ì—ì„œ í•œ ë¶€ë¶„ì´ ë³µí•©ì–´ì¼ ë•Œë„ ì‚¬ìš©ë©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, preâ€“Websterburg Bakeryì™€ ê°™ì€ ê²½ìš°ì…ë‹ˆë‹¤. ì´ë¦„ì´ë‚˜ ì—°ê²°ì„ ë‚˜íƒ€ë‚¼ ë•Œ \"ë¶€í„°\"ë¥¼ ëŒ€ì²´í•˜ê¸°ë„ í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, Springfieldâ€“Websterburg ê¸°ì°¨ì™€ ê°™ì´ ì‚¬ìš©ë©ë‹ˆë‹¤.\n\ní•˜ì´í”ˆ(-)ì€ ë³µí•©ì–´ì˜ ìš”ì†Œë¥¼ ì—°ê²°í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, baker-ownerì™€ ê°™ì€ ê²½ìš°ì…ë‹ˆë‹¤. ì ‘ë‘ì‚¬ë‚˜ ì ‘ë¯¸ì‚¬ë¥¼ ë‹¨ì–´ì™€ êµ¬ë¶„í•  ë•Œë„ ì“°ì…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, bread-likeì™€ ê°™ì€ í˜•íƒœì…ë‹ˆë‹¤. ìˆ«ì ë²”ìœ„ë‚˜ ì¤„ ëì—ì„œ ë‹¨ì–´ë¥¼ ë‚˜ëˆ„ëŠ” ë°ë„ ì‚¬ìš©ë©ë‹ˆë‹¤. ë˜í•œ ë§ë”ë“¬ì´ë‚˜ ê¸€ìë¥¼ í•˜ë‚˜ì”© ì² ìí•  ë•Œë„ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nì „ë°˜ì ìœ¼ë¡œ ì—  ëŒ€ì‹œëŠ” ë‹¤ì¬ë‹¤ëŠ¥í•˜ë©° ê³µì‹ì ì¸ ê¸€ì“°ê¸°ì™€ ë¹„ê³µì‹ì ì¸ ê¸€ì“°ê¸° ëª¨ë‘ì— ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. êµ¬ë‘ì ì˜ ì„ íƒì€ ê°œì¸ì˜ ì·¨í–¥ì— ë”°ë¼ ë‹¤ë¥´ë©°, ì—  ëŒ€ì‹œ ì£¼ë³€ì˜ ê°„ê²©ì€ ìŠ¤íƒ€ì¼ ê°€ì´ë“œì— ë”°ë¼ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "25013395192a7d77",
    "title": {
      "en": "Every Flop Counts: Scaling a 300B LLM Without Premium GPUs",
      "ko": "ëª¨ë“  ì‹¤íŒ¨ê°€ ì¤‘ìš”í•˜ë‹¤: 300B LLMì˜ ì €ë¹„ìš© í™•ì¥",
      "ja": null
    },
    "type": "story",
    "url": "https://arxiv.org/abs/2503.05139",
    "score": 107,
    "by": "bretpiatt",
    "time": 1742820496,
    "content": "In this technical report, we tackle the challenges of training large-scale Mixture of Experts (MoE) models, focusing on overcoming cost inefficiency and resource limitations prevalent in such systems. To address these issues, we present two differently sized MoE large language models (LLMs), namely Ling-Lite and Ling-Plus (referred to as \"Bailing\" in Chinese, spelled BÇilÃ­ng in Pinyin). Ling-Lite contains 16.8 billion parameters with 2.75 billion activated parameters, while Ling-Plus boasts 290 billion parameters with 28.8 billion activated parameters. Both models exhibit comparable performance to leading industry benchmarks. This report offers actionable insights to improve the efficiency and accessibility of AI development in resource-constrained settings, promoting more scalable and sustainable technologies. Specifically, to reduce training costs for large-scale MoE models, we propose innovative methods for (1) optimization of model architecture and training processes, (2) refinement of training anomaly handling, and (3) enhancement of model evaluation efficiency. Additionally, leveraging high-quality data generated from knowledge graphs, our models demonstrate superior capabilities in tool use compared to other models. Ultimately, our experimental findings demonstrate that a 300B MoE LLM can be effectively trained on lower-performance devices while achieving comparable performance to models of a similar scale, including dense and MoE models. Compared to high-performance devices, utilizing a lower-specification hardware system during the pre-training phase demonstrates significant cost savings, reducing computing costs by approximately 20%. The models can be accessed at this https URL.",
    "summary": {
      "en": "This technical report addresses the challenges of training large Mixture of Experts (MoE) models, particularly focusing on cost and resource issues. It introduces two models: Ling-Lite, with 16.8 billion parameters (2.75 billion activated), and Ling-Plus, with 290 billion parameters (28.8 billion activated). Both models perform similarly to top industry standards. \n\nTo make AI development more efficient and accessible, especially in resource-limited environments, the report suggests methods to:\n1. Optimize model architecture and training processes.\n2. Improve handling of training issues.\n3. Enhance model evaluation efficiency.\n\nThe models also utilize high-quality data from knowledge graphs, showing better tool use abilities. Notably, a 300 billion parameter MoE model can be trained on less powerful devices with similar performance to other models, leading to about 20% savings in computing costs compared to using high-performance systems. The models are available via a provided link.",
      "ko": "ì´ ê¸°ìˆ  ë³´ê³ ì„œëŠ” ëŒ€ê·œëª¨ í˜¼í•© ì „ë¬¸ê°€ ëª¨ë¸(MoE)ì„ í›ˆë ¨í•˜ëŠ” ë° ìˆì–´ ë¹„ìš©ê³¼ ìì› ë¬¸ì œë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ í•œ ë„ì „ ê³¼ì œë¥¼ ë‹¤ë£¹ë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” 168ì–µ ê°œì˜ ë§¤ê°œë³€ìˆ˜ë¥¼ ê°€ì§„ ë§ë¼ì´íŠ¸ ëª¨ë¸ê³¼ 2900ì–µ ê°œì˜ ë§¤ê°œë³€ìˆ˜ë¥¼ ê°€ì§„ ë§í”ŒëŸ¬ìŠ¤ ëª¨ë¸ì„ ì†Œê°œí•©ë‹ˆë‹¤. ë‘ ëª¨ë¸ ëª¨ë‘ ì—…ê³„ ìµœê³  ìˆ˜ì¤€ì˜ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.\n\nAI ê°œë°œì„ ë³´ë‹¤ íš¨ìœ¨ì ì´ê³  ì ‘ê·¼ ê°€ëŠ¥í•˜ê²Œ ë§Œë“¤ê¸° ìœ„í•´, íŠ¹íˆ ìì›ì´ ì œí•œëœ í™˜ê²½ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì²«ì§¸, ëª¨ë¸ ì•„í‚¤í…ì²˜ì™€ í›ˆë ¨ ê³¼ì •ì„ ìµœì í™”í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤. ë‘˜ì§¸, í›ˆë ¨ ë¬¸ì œë¥¼ ë” ì˜ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ë°©ì•ˆì„ ì œì‹œí•©ë‹ˆë‹¤. ì…‹ì§¸, ëª¨ë¸ í‰ê°€ì˜ íš¨ìœ¨ì„±ì„ ë†’ì´ëŠ” ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤.\n\nì´ ëª¨ë¸ë“¤ì€ ì§€ì‹ ê·¸ë˜í”„ì—ì„œ ì–»ì€ ê³ í’ˆì§ˆ ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ ë„êµ¬ ì‚¬ìš© ëŠ¥ë ¥ì´ í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤. íŠ¹íˆ, 3000ì–µ ê°œì˜ ë§¤ê°œë³€ìˆ˜ë¥¼ ê°€ì§„ MoE ëª¨ë¸ì€ ì„±ëŠ¥ì´ ë¹„ìŠ·í•œ ë‹¤ë¥¸ ëª¨ë¸ë“¤ê³¼ ë¹„êµí•´ë„ ëœ ê°•ë ¥í•œ ì¥ì¹˜ì—ì„œ í›ˆë ¨í•  ìˆ˜ ìˆìœ¼ë©°, ê³ ì„±ëŠ¥ ì‹œìŠ¤í…œì„ ì‚¬ìš©í•  ë•Œë³´ë‹¤ ì•½ 20%ì˜ ì»´í“¨íŒ… ë¹„ìš© ì ˆê° íš¨ê³¼ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤. ëª¨ë¸ì€ ì œê³µëœ ë§í¬ë¥¼ í†µí•´ ì´ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "37d2b7611a1e31d6",
    "title": {
      "en": "A note on the USB-to-PS/2 mouse adapter that came with Microsoft mouse devices",
      "ko": "ë§ˆì´í¬ë¡œì†Œí”„íŠ¸ ë§ˆìš°ìŠ¤ ì–´ëŒ‘í„° ì£¼ì˜ì‚¬í•­",
      "ja": null
    },
    "type": "story",
    "url": "https://devblogs.microsoft.com/oldnewthing/20250325-00/?p=110993",
    "score": 350,
    "by": "luu",
    "time": 1743120989,
    "content": "March 18, 2025\n      Why didnâ€™t Windows 95 setup use a miniature version of Windows 95 as its fallback GUI?\n\n        Raymond Chen",
    "summary": {
      "en": "On March 18, 2025, Raymond Chen questioned why the setup process for Windows 95 didn't use a smaller version of Windows 95 as a backup graphical user interface (GUI).",
      "ko": "2025ë…„ 3ì›” 18ì¼, ë ˆì´ë¨¼ë“œ ì²¸ì€ ìœˆë„ìš° 95ì˜ ì„¤ì¹˜ ê³¼ì •ì—ì„œ ë°±ì—… ê·¸ë˜í”½ ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤(GUI)ë¡œ ë” ì‘ì€ ë²„ì „ì˜ ìœˆë„ìš° 95ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šì€ ì´ìœ ì— ëŒ€í•´ ì˜ë¬¸ì„ ì œê¸°í–ˆìŠµë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "f40cf8f6b86c632d",
    "title": {
      "en": "Launch HN: Continue (YC S23) â€“ Create custom AI code assistants",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://hub.continue.dev/explore/assistants",
    "score": 163,
    "by": "sestinj",
    "time": 1743087986,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "7739e5a883bfe5d6",
    "title": {
      "en": "GitHub has gone â€“ long live Forgejo",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://mastodon.social/@organicmaps/114233788700982882",
    "score": 6,
    "by": "Helithumper",
    "time": 1743192299,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "3f3afac5c4778cff",
    "title": {
      "en": "A decompilation and port of Sonic Advance 2-a GameBoy Advance game written in C",
      "ko": "ì†Œë‹‰ ì–´ë“œë²¤ìŠ¤ 2 ë³µì›!",
      "ja": null
    },
    "type": "story",
    "url": "https://github.com/SAT-R/sa2",
    "score": 169,
    "by": "bane",
    "time": 1743128509,
    "content": "Sonic Advance 2\n\nâš ï¸ This project is not completed and still under active development\n\nThis is a work in progress matching decompilation of Sonic Advance 2\nIt so far builds the following ROMs:\n\nsa2.gba sha1: 7bcd6a07af7c894746fa28073fe0c0e34408022d (USA) (En,Ja,Fr,De,Es,It)\nsa2_europe.gba sha1: b0f64bdca097f2de8f05ac4c8caea2b80c5faeb1 (Europe) (En,Ja,Fr,De,Es,It)\nğŸš§ sa2_japan.gba sha1: dffd0188fc78154b42b401398a224ae0713edf23 (Japan) (En,Ja,Fr,De,Es,It) (Work in Progress)\n\nIt can also build:\n\nsa2.sdl make sdl (Linux/MacOS SDL 64bit port)\nsa2.sdl_win32.exe make sdl_win32 (Windows SDL 64bit port)\nğŸš§ sa2.win32.exe make win32 (Win32 native port, not functional)\n\nCurrent state\n\nğŸ‰ The build is 100% from C files with ~80 functions which currently don't match\nAll assembly code extracted, disassembled, and decompiled by hand to their C equivilent\nAll songs have been extracted, and documented as matching MIDI files\nAll sprite animation frames have been extracted to PNGs and are used to build the matching rom\nAll tilemaps (backgrounds) have been documented and had their tiles extracted\nThe game compiles to a widescreen port (426x240) for multiple platforms\nThe \"sub games\" (Chao Garden and Collect The Rings) have been disassembled but not yet decompiled\n\nSetting up the repo\nPlease see follow these instructions\nCommunity\nJoin us on discord to get started in helping out\nNotes\n\nThe Kirby & The Amazing Mirror decompilation uses a very similar codebase, as it was written by the same dev team (Dimps)\nhttps://decomp.me is a great resource for helping to create matching functions\nldscript.txt tells the linker the order which files should be linked\nFor more info, see the FAQs section of TMC\n\nCredits\n\nJaceCear for his dedication to understanding the internals of the graphics engine, writing tools to extract this data, as well as massive effort in contributing towards the decompilation process, and setting up the PC ports\n\nShout out to @froggestspirit for the drive to set this project up\n\nSpecial thanks to @normmatt for the initial repo setup and sounds decompilation\n\nPokemon Reverse Engineering Tools community for their help with the project, and tooling for GBA decompilations\n\nKermalis for their tool which was used to dump the game midis\n\nçªå§¬ for their exellent work documenting all the quirks of matching midis",
    "summary": {
      "en": "**Sonic Advance 2 Project Summary**\n\n- **Project Status**: The Sonic Advance 2 decompilation is still in progress and not yet finished.\n  \n- **Current Builds**: The project has successfully created several ROM versions:\n  - **USA**: sa2.gba\n  - **Europe**: sa2_europe.gba\n  - **Japan**: sa2_japan.gba (still being worked on)\n\n- **Additional Builds**: The project also supports SDL versions for Linux, MacOS, and Windows, although the Win32 version is not functional yet.\n\n- **Development Progress**: \n  - The code has been fully converted to C, with some functions still needing adjustments.\n  - All assembly code has been disassembled and translated to C.\n  - Music tracks have been extracted and documented as MIDI files.\n  - Sprite animations and background tiles have been extracted and are being used in the ROM.\n  - The game can now compile for widescreen formats.\n  - Minor games like Chao Garden have been analyzed but not fully converted.\n\n- **Getting Involved**: You can join the community on Discord to help with the project.\n\n- **Tools and Resources**: The project uses tools developed by various contributors and is similar to the decompilation of \"Kirby & The Amazing Mirror.\"\n\n- **Acknowledgments**: Special thanks to key contributors for their efforts in graphics, sound extraction, and setting up the project.",
      "ko": "ì†Œë‹‰ ì–´ë“œë°´ìŠ¤ 2 í”„ë¡œì íŠ¸ëŠ” í˜„ì¬ ì§„í–‰ ì¤‘ì´ë©° ì•„ì§ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì´ í”„ë¡œì íŠ¸ëŠ” ì—¬ëŸ¬ ê°€ì§€ ë¡¬ ë²„ì „ì„ ì„±ê³µì ìœ¼ë¡œ ìƒì„±í–ˆìŠµë‹ˆë‹¤. ë¯¸êµ­ ë²„ì „ì€ sa2.gba, ìœ ëŸ½ ë²„ì „ì€ sa2_europe.gba, ì¼ë³¸ ë²„ì „ì€ sa2_japan.gbaë¡œ, ì¼ë³¸ ë²„ì „ì€ ì•„ì§ ì‘ì—… ì¤‘ì…ë‹ˆë‹¤.\n\nì¶”ê°€ì ìœ¼ë¡œ, ì´ í”„ë¡œì íŠ¸ëŠ” ë¦¬ëˆ…ìŠ¤, ë§¥OS, ìœˆë„ìš°ìš© SDL ë²„ì „ë„ ì§€ì›í•˜ì§€ë§Œ, ìœˆë„ìš° 32 ë¹„íŠ¸ ë²„ì „ì€ ì•„ì§ ì‘ë™í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ê°œë°œ ì§„í–‰ ìƒí™©ìœ¼ë¡œëŠ” ì½”ë“œê°€ ì™„ì „íˆ C ì–¸ì–´ë¡œ ë³€í™˜ë˜ì—ˆê³ , ì¼ë¶€ í•¨ìˆ˜ëŠ” ì—¬ì „íˆ ì¡°ì •ì´ í•„ìš”í•©ë‹ˆë‹¤. ëª¨ë“  ì–´ì…ˆë¸”ë¦¬ ì½”ë“œëŠ” ë¶„í•´ë˜ì–´ C ì–¸ì–´ë¡œ ë²ˆì—­ë˜ì—ˆìŠµë‹ˆë‹¤. ìŒì•… íŠ¸ë™ì€ ì¶”ì¶œë˜ì–´ MIDI íŒŒì¼ë¡œ ë¬¸ì„œí™”ë˜ì—ˆìŠµë‹ˆë‹¤. ìŠ¤í”„ë¼ì´íŠ¸ ì• ë‹ˆë©”ì´ì…˜ê³¼ ë°°ê²½ íƒ€ì¼ë„ ì¶”ì¶œë˜ì–´ ë¡¬ì—ì„œ ì‚¬ìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ì œ ê²Œì„ì€ ì™€ì´ë“œìŠ¤í¬ë¦° í˜•ì‹ìœ¼ë¡œ ì»´íŒŒì¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì°¨ì˜¤ ê°€ë“ ê³¼ ê°™ì€ ì†Œê·œëª¨ ê²Œì„ì€ ë¶„ì„ë˜ì—ˆì§€ë§Œ ì™„ì „íˆ ë³€í™˜ë˜ì§€ëŠ” ì•Šì•˜ìŠµë‹ˆë‹¤.\n\ní”„ë¡œì íŠ¸ì— ì°¸ì—¬í•˜ê³  ì‹¶ë‹¤ë©´ ë””ìŠ¤ì½”ë“œ ì»¤ë®¤ë‹ˆí‹°ì— ê°€ì…í•˜ì—¬ ë„ì›€ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ í”„ë¡œì íŠ¸ëŠ” ë‹¤ì–‘í•œ ê¸°ì—¬ìë“¤ì´ ê°œë°œí•œ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ë©°, \"ì»¤ë¹„ & ë” ì–´ë©”ì´ì§• ë¯¸ëŸ¬\"ì˜ ë””ì»´íŒŒì¼ê³¼ ìœ ì‚¬í•©ë‹ˆë‹¤. ê·¸ë˜í”½, ì‚¬ìš´ë“œ ì¶”ì¶œ ë° í”„ë¡œì íŠ¸ ì„¤ì •ì— ê¸°ì—¬í•œ ì£¼ìš” ê¸°ì—¬ìë“¤ì—ê²Œ íŠ¹ë³„í•œ ê°ì‚¬ë¥¼ ì „í•©ë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "8bec9b672ff16617",
    "title": {
      "en": "Estimating Camera Motion from a Single Motion-Blurred Image",
      "ko": "ë‹¨ì¼ ì´ë¯¸ì§€ë¡œ ì¹´ë©”ë¼ ì›€ì§ì„ ì¶”ì •í•˜ê¸°",
      "ja": null
    },
    "type": "story",
    "url": "https://jerredchen.github.io/image-as-imu/",
    "score": 62,
    "by": "smusamashah",
    "time": 1743142059,
    "content": "In many robotics and VR/AR applications, fast camera motions cause a high level of motion blur, causing existing camera pose estimation methods to fail. In this work, we propose a novel framework that leverages motion blur as a rich cue for motion estimation rather than treating it as an unwanted artifact. Our approach works by predicting a dense motion flow field and a monocular depth map directly from a single motion-blurred image. We then recover the instantaneous camera velocity by solving a linear least squares problem under the small motion assumption. In essence, our method produces an IMU-like measurement that robustly captures fast and aggressive camera movements. To train our model, we construct a large-scale dataset with realistic synthetic motion blur derived from ScanNet++v2 and further refine our model by training end-to-end on real data using our fully differentiable pipeline. Extensive evaluations on real-world benchmarks demonstrate that our method achieves state-of-the-art angular and translational velocity estimates, outperforming current methods like MASt3R and COLMAP.",
    "summary": {
      "en": "In robotics and VR/AR, fast camera movements often lead to motion blur, which can disrupt camera pose estimation methods. This work introduces a new framework that uses motion blur as a helpful tool for estimating motion instead of seeing it as a problem. The method predicts a detailed motion flow and depth map from a single blurred image, allowing us to calculate the camera's speed. We create a large dataset of realistic motion blur for training and improve our model with real data. Tests show our approach provides the best estimates for camera movement compared to existing methods like MASt3R and COLMAP.",
      "ko": "ë¡œë´‡ ê³µí•™ê³¼ ê°€ìƒí˜„ì‹¤(VR)/ì¦ê°•í˜„ì‹¤(AR) ë¶„ì•¼ì—ì„œ ë¹ ë¥¸ ì¹´ë©”ë¼ ì›€ì§ì„ì€ í”íˆ ëª¨ì…˜ ë¸”ëŸ¬ë¥¼ ë°œìƒì‹œí‚µë‹ˆë‹¤. ì´ëŠ” ì¹´ë©”ë¼ ìì„¸ ì¶”ì • ë°©ë²•ì— ë°©í•´ê°€ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë²ˆ ì—°êµ¬ì—ì„œëŠ” ëª¨ì…˜ ë¸”ëŸ¬ë¥¼ ë¬¸ì œë¡œ ë³´ì§€ ì•Šê³ , ì˜¤íˆë ¤ ì›€ì§ì„ì„ ì¶”ì •í•˜ëŠ” ë° ìœ ìš©í•œ ë„êµ¬ë¡œ í™œìš©í•˜ëŠ” ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì´ ë°©ë²•ì€ íë¦¿í•œ ì´ë¯¸ì§€ í•˜ë‚˜ì—ì„œ ìì„¸í•œ ì›€ì§ì„ íë¦„ê³¼ ê¹Šì´ ë§µì„ ì˜ˆì¸¡í•˜ì—¬ ì¹´ë©”ë¼ì˜ ì†ë„ë¥¼ ê³„ì‚°í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” í›ˆë ¨ì„ ìœ„í•´ í˜„ì‹¤ì ì¸ ëª¨ì…˜ ë¸”ëŸ¬ì˜ ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ì„ ìƒì„±í•˜ê³ , ì‹¤ì œ ë°ì´í„°ë¥¼ í†µí•´ ëª¨ë¸ì„ ê°œì„ í–ˆìŠµë‹ˆë‹¤. í…ŒìŠ¤íŠ¸ ê²°ê³¼, ìš°ë¦¬ì˜ ì ‘ê·¼ ë°©ì‹ì´ ê¸°ì¡´ì˜ MASt3R ë° COLMAPê³¼ ê°™ì€ ë°©ë²•ë“¤ì— ë¹„í•´ ì¹´ë©”ë¼ ì›€ì§ì„ì— ëŒ€í•œ ê°€ì¥ ì •í™•í•œ ì¶”ì •ì„ ì œê³µí•˜ëŠ” ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "212a03a3801f11de",
    "title": {
      "en": "I tried making artificial sunlight at home",
      "ko": "ì¸ê³µ í–‡ë¹› ë§Œë“¤ê¸° ë„ì „!",
      "ja": null
    },
    "type": "story",
    "url": "https://victorpoughon.fr/i-tried-making-artificial-sunlight-at-home/",
    "score": 552,
    "by": "fouronnes3",
    "time": 1743104968,
    "content": "I tried making artificial sunlight at home\n\n                    27 Mar, 2025\n\n    Some time ago, I saw this video by DIY Perks where they make artificial sunlight at home with a 500W LED and a gigantic (1.2m) parabolic reflector. I've been fascinated by this project ever since, and I wanted my own.\nOver the past year or so, I finally took the time to work on a similar project, but I had the idea for a different design. The issue with the parabolic reflector is that it takes a huge amount of space. Could I do something similar, but with a less bulky design? This is the story of my first attempt at this project - version 1 so to speak. Perhaps there will be a version 2 in the future. Enjoy the read!\n\nMy idea - as others have had I'm sure - was to use an array of lenses laid out as a grid. Then, instead of a single light source, I would use a grid array of multiple LEDs, one per lens. In my mind, this would have two major advantages:\n\nLess bulky. The size of the device would be determined by the focal length of the individual lens elements, and because each would be small, the focal length could be small also, while maintaining a decent f number.\nEasier thermal management. Multiple light sources could be regular low power LEDs which wouldn't need special cooling. There would just be a lot of them, spread out over the entire device surface.\n\nOver the course of this project, I also intended to teach myself some manufacturing and 3D design, as I don't have any experience doing any of this. My background is software, and as you'll see I took a very software heavy approach to this. It was all a long learning journey for me, but in the end I used:\n\nMostly build123d for CAD modeling, with some FreeCAD for final assembly checks and some experiments here and there - including with the cool OpticsWorkbench.\nKiCad for PCB design.\nCustom python code for simulating light and optimizing the optical system. (This custom code eventually became an entire open-source project for optimization-based optical design)\nJLCPCB for printing and assembling PCBs, and for manufacturing aluminum and plastic parts with their CNC service.\n\nTL;DR: I did it! Here is the finished device sitting on my desk today, at night:\n\nAnd here it is during the day (much less impressive!)\n\nBeware it's kinda hard to take good pictures of it, and I don't have the best photo gear. Here's also a video: (at night)\n\n  Your browser does not support the video tag.\n\nKinda cool that you can see a lens flare effect in the shape of the lens grid array.\nTechnical specsMechanical:\n\nLens square side length: 30mm\nEffective Focal length: 55mm\nArray size: 6x6 = 36 LEDs\nTotal size: 180x180mm\n\nParts:\n\nLenses: 1 biconvex lens array, 1 plano-convex lens array - custom made out of PMMA acrylic, CNC fabrication with vapor polish finish @ JLCCNC\nLEDs: LUXEON 2835 3V -- Ref: 2835HE. CRI: 95+, color temp: 4000K, 65mA.\nPCBs: Custom design\nMounting hardware: custom design - aluminium 60601 for the CNC parts and mate black resin for the 3D printed parts\nRayleigh diffuser: waterproof printing inkjet film\n\nGeneral design and sizingTo create artificial sunlight, you need four ingredients:\n\nParallel light rays. The sun is so far away that light rays emitted from a point on the surface of the sun reach us essentially parallel. This is not to say that all light rays coming from the sun are parallel, as it still has a 0.5 deg apparent angular size. But they need to be pretty straight. Any light coming from an artificial light source like an LED will be going in all directions, so some optics is required.\nHigh color quality. A good indicator to look for on a datasheet is the color rendering index (CRI). 95+ is recommended to achieve a good effect. I'm sure there's more color science you could get into, but CRI is a great start for off the shelf parts.\nRayleigh scattering, or an imitation of it.\nA LOT of power.\n\nLight intensity is the most important sizing constraint, so let's look at it first. Now, the sun is very bright. Like, ridiculously bright: around 100,000 lux. To achieve this with LEDs is by no means impossible, but it's a challenge. For this first version, I thought that targetting 10,000 lux would be quite enough because it would reduce the power consumption a lot for a first prototype, and also brightness perception is logarithmic. So one tenth of the intensity is really, perceptually, almost the same as full brightness. (In the end, I estimate my design only effectively achieved something between 1000 and 10000 lux).\nThe general grid based design of this project really has two variables:\n\nthe individual LED light output, in lumens\nthe individual lens surface area in mmÂ²\n\nAfter some research, I think values between 30 to 130 lumens are typical for high CRI surface mount LEDs. So, assuming this is what we are working with, what is the required lens size to achieve the brightness of the sun?\nWe have to assume some non perfect efficiency for collimating the light. This will never be 100%, and in fact may be quite low if the focal length is high, because a lot of the light will be hitting the side walls instead of reaching the lens. The lens itself will also be absorbing some light. So taking a wild guess of 0.5 for the overall optical efficiency, and taking three lumens value of 30, 80 and 130, we get this plot:\n\nWith that in mind, I selected 30mm as my lens square side length. Presumably, this would be small enough to achieve some effect, but not too small to make the lenses too hard to make.\nLensesFocal length, and the lenses shape in general, is the next design consideration. The goal is to have perfectly parallel light rays. In theory, with a perfect point source and a perfect lens this is easy. Put the light source at the lens focal length, you're done. In practice, a lot of things make it harder to achieve with a lens. (This is where the parabolic reflector design is superior to a lens).\n\nA LED is not a point source\nA lens will not have perfect optical performance (i.e. aberrations)\nMechanical reality of the device means that positioning and orientation will not be perfect\nA LED radiation pattern is not isotropic, meaning intensity will be greater at the lens center\n\nThis is the radiation pattern characteristics diagram from my LED datasheet:\n\nI wrote some custom python code to simulate the optical system I had in mind, and find the best lens shape using numerical optimization. (This code eventually became an open-source project: torchlensmaker) After a lot of experimentation, I settled on a 2 lens design:\n\nLens 1: Biconvex parabolic lens\nLens 2: Planoconvex parabolic lens\n\nThe effective focal length of this two lens system is about 55mm. Focal length is a key design parameter, and here I feel like more experimentation is needed. It's a big tradeoff consideration and has a huge impact on the system design. It impacts:\n\nThe curvature of the lens surface, which is a key manufacturing point (you want to minimize curvature for manufacturing, which means maximizing focal length)\nThe optical efficiency of the system due to the led radiance pattern (here you want to minimize focal length, to gather more of the emitted light)\nThe device thickness (here I wanted a not-too-thick device, so to minimize focal length also)\n\nI used a two lens system mostly to reduce the surface curvature of the lens arrays. This reduces the manufacturing cost by a lot. High curvature lenses are more expensive in general, and this grid array design means that a high curvature lens will create sort of \"valleys\" in between the lenses. Because I was targetting CNC manufacturing, this is to be minimized to get a design that's even possible to machine.\nThis is the optical simulation I had at the time I finalized the design and ordered the lenses. (Since then my simulation code has improved and I could likely do much better modeling today using the latest version of torchlensmaker):\n\nWith some custom build123d code I was able to make the two lenses 3D models by stacking the lenses in a grid pattern and adding edges for mounting:\n\n  <p>Your browser does not support iframes.</p>\n\n  <p>Your browser does not support iframes.</p>\n\nWhat's really cool using build123d for 3D modeling, is that I can just change a python variable to change the size of the array, of the thickness of the lens, of anything else really. It's all parametric out of the box because it's regular Python code! This makes exploring the design space very efficient. I've never done 3D modeling any other way, but I can't imagine ever not having the power of programming with me if I ever do it again!\nI had the lenses manufactured out of PMMA acrylic at JLC with a vapor polish finish. Total cost for the lenses was about 55â‚¬ which is really not bad!\nOne of the two main lens array, built by JLCCNC:\n\nLEDsI really wanted to use the 3030 G04 from YUJILEDS, but it's only sold on 5000 units reels that cost $1000 a piece... maybe for version 2 I will upgrade to those. For version 1, I settled on LUXEON 2835 3V. They are about 3 times less bright than the YUJILED, but they have good color rendering and the SMD package I was looking for. And importantly, the minimum order quantity was only 50 at JLC global sourcing.\nIn the version 1 design, the grid is 6x6 which means 36 LEDs total.\nPCBsI designed a custom PCB with KiCAD. Each PCB holds 6 LEDs which are laid out as 2 segments of a 12V led strip in parallel. This allows to use a standard wall plug 12V power supply.\n\nThe mechanical role of the PCB is very important in this design. Not only does it distribute power to the LEDs and regulate current, it also precisely positions the LEDs at the lens focal point. For this, exporting the PCB 3D model and importing it into FreeCAD was very useful to check that everything fits together: the PCB in the aluminum support baseplate, the holes on the light hoods, etc. My Python code exported the precise LED coordinates which I could input into KiCad's layout editor.\nI had the PCB printed and the components assembled by JLCPCB. It's very very cool to design an electronic board on your computer and get it fully assembled in the mail a few weeks later - no soldering required! (for this step anyway).\n\nMechanical mounting partsTo mount everything together I designed 3 parts:\n\nA baseplate, to hold the PCBs and the side walls. The PCBs are fitted below the baseplate, and light goes through holes drilled into the baseplate. There are also partial holes to allow for the thickness of the SMD resistors mounted on top of the PCBs, and finally two mounting holes per PCB. This is why it has so many holes :)\n\n  <p>Your browser does not support iframes.</p>\n\nSide walls to hold the lenses using grooves in which to insert them, and a larger groove to secure in the baseplate. The baseplate side holes are threaded to support M2 screws securing the base of the walls. Again, JLCCNC did the drilling and threading of the holes at a great price.\n\n  <p>Your browser does not support iframes.</p>\n\nLight hoods, a rectangle block with rectangular holes. It sits on top of the PCB to shape the light coming from each LED into a cone (or really a four sided pyramid). This is to make sure light from a given LED only reaches its matching lens on the lens array, and no other. Bleed light is inevitable, but at least this prevents direct leakage.\n\n  <p>Your browser does not support iframes.</p>\n\nThe hoods were 3D printed out of black resin, the walls and baseplate were CNC cut out of Aluminum 60601.\nI'm not a mechanical engineer so this process was... trial and error. Still the result is working so I'm quite happy with that. For a possible version 2, there's a lot I'll change in the mechanical design. But apart from the one design flaw I was able to fix manually with a drill (more on that below), everything fit together quite well on the first try.\nRayleigh scatteringThe final ingredient is Rayleigh scattering. This is the physical phenomenon that makes the sky look blue, and it's important to achieve a convincing effect. In the DIY Perks video that inspired this project, they used a home made liquid solution with suspended particles of the correct size for Rayleigh scattering. Not super practical and I really wanted to find another solution (get it?). Thankfully, some time after the original video, someone on the diyperks forum discovered that inkjet print film achieves a very similar effect. A quick trip to a local office supply store was all I needed here! Amazing discovery.\nI didn't anticipate this step during the initial design phase, so the film is simply cut to the correct size and secured with black electrical tape.\nAssemblyAfter a few weeks of design work, and another few weeks of waiting for the parts to arrive, it was finally time for assembly!\nOn top of the individual 3D models made with build123d, I had a final assembly FreeCAD model with all parts fitted together, including the lenses:\n\nNote the green brackets that I initially planned to use. When actually assembling the walls to the baseplate, the solidity of the formed box was very high, I decided to drop the brackets entirely. This is why some extra unused holes remain on the side walls.\nThis is all the parts just after unboxing (excluding the inkjet film, solder tin, screws, power supply, wiring, electrical tape):\n\nThe only real design flaw was insufficient width of the grooves that hold the lenses. The lenses have an edge thickness of 1.2mm, which I had intended to fit into a 1.22mm groove. Turns out this was not enough, probably due to a combination of manufacturing tolerance and additional thickness added by the anodizing black matte surface finish of the aluminum part. The lenses didn't fit into the grooves!\nI don't have a very advanced tools at home, so my best solution to this was making the existing grooves wider by hand using a power drill. I bought a 1.5mm metal drill bit and achieved a decent result by doing 4 to 5 passes per groove. This took about 2-3h in total because I had to move the bit quite slow and could only machine about 1/4th of each groove depth at a time by moving the drill bit slowly accross, and there are 8 grooves total.\n\nHere's some more pictures of assembly below.\nThe back side after soldering wires to the PCB power pins and a socket for the 12V power supply. The PCBs and hood pieces share a common mounting hole so only two screws per PCB-hood pair are used.\n\nThe front side of the baseplate + PCB + hoods assembly, but without the lenses, powered on. Don't look at it directly :)\n\nIt's interesting to note that in the picture above, all of the light you can see from the LEDs is actually \"bleed light\" and not useful light. None of the light visible above is the light that's intended to go into the lens and produce the sunlight effect.\nTesting with partial assembly of the walls and only 1 out of the 2 lenses:\n\nTesting the inkjet film layers with an avocado as a subject. I settled on using two layers of the inkjet film for the final build:\n\nCostOverall I spent around 1000â‚¬ on this project. But this includes cost of tools I was missing, prototype parts that I had manufactured but discarded, bulk orders for parts like LEDs and PCBs which had a minium order quantity above what I need for 1 unit, and various supplies like screws, etc. The actual raw cost of parts only, without shipping, to build the final unit is hard to estimate. But I would say around 300â‚¬. The most expensive parts are the CNC parts (PMMA lenses and the aluminum baseplate and walls) accounting for about 2/3rd of the total price. The rest (PCBs, assembly service, LEDs, 3D printed plastic parts) was quite cheap.\nConclusionAs I write this the final piece is sitting on my desk and producing a pleasant soft white glow. It's definitely nice, and I'm very proud of the result - especially because this was by far the biggest build project I have ever done.\n\nThanks to this project, I've learned a ton about PCB design, electronics and CNC manufacturing and optics. I even got so far down the side quest of learning optics that I started an open-source python project for modeling geometric optics.\nSo, is it convincing as artificial sunlight?\nMy honest answer to that is: partially. The geometric effect of the light source appearing at infinity works. As I pan and tilt my head from side to side, the illusion of light coming from way far behind the object is 100% a success. On top of that, if you look at it while moving your head into the light beam, my eyes get surprised - almost hurt - by the sudden intensity jump. This indicates that collimation is good and you can sort of see it in the video at the start of this post.\nHowever it's apparent that it's simply too weak. Don't get me wrong, it's still bright. I can't look at it directly without sunglasses, and honestly it's really hard to take a good picture of it because the contrast between the light it emits and the outside of it is very high.\nAnother downside is that I can definitely make out the grid of lenses, as the intensity pattern clearly reveals the grid shape. This is quite a minor downside and not really unpleasant, and I'm sure it could be improved upon.\nIf I were to ever work on a version 2, I would focus on:\n\nMore power. My feeling is the light output needs to be 3 to 5 times stronger to get any closer to a convincing effect, and it's not crazy to aim for as much as 10x brighter than this prototype.\nMore surface area. This prototype is 18cm x 18cm. So you only really get the effect if you are able to sit with the produced straight beam of light, which is quite narrow to resemble any kind of \"fake window\". A future version would need to be 2 to 4 times wider in my opinion.\nBetter optical design. I still think a refraction based design is possible, but it requires very precise optical design and mechanical tolerances. My feeling is that a refraction based design, especially as a grid, is very sensitive to positioning and orientation of parts. I lack mechanical engineering skills in this area.\n\nHowever there are some really encouraging things that I really like about this grid based, refractive design:\n\nIt's scalable. If I had built 4 identical items, I could literally stack them on top of each other and get more surface area. The \"bezels\" would be only 5% of the total light emitting area, and I'm sure this could be lowered. I also like that the inner design calls for repeated elements, as this introduces some economy of scale, even at the prototype level. The only part that's not trivially scalable is the lens grid. Maybe it could be injection molded for very large scale production, or for medium scale you could come up with a way to tile multiple lens grids into a larger overall grid pattern, adding some thin bezels for mounting.\nIt's compact. The total size is 19cm x 19cm x 9cm. This is quite compact for a 5cm focal length and an effective lighting area of 18cm x 18cm. Reflective designs like the DIYPerks video or commercial products like CoeLux do not achieve this form factor.\nThermal management is better by design. This is not really something I got into for this design, as it's quite underpowered. The whole thing runs comfortably on a 12V / 3A wall brick power supply. But this design offers great margin for scaling up because there isn't a single light source to cool down, but a number of LEDs proportional to the surface area. I suspect the main thermal issue when scaling up would be the cooling of the power supply itself, not of the lamp.\n\nAs final thoughts, let me talk about the software heavy approach I had for this project. It's awesome. If I was starting a manufacturing company today, I would do it all code based. PCBs, 3D models, assembly, testing... I want code everywhere. The power of changing a parameter and having the entire design updated with a single script it so good. Run a script and get all the production data including GERBERs, BOM, 3D models, mechanical schematics, technical diagrams, automated tolerance and electrical checks... absolutely no manual steps between changing a design parameter and ready to send a new order to manufacturing. The PCB and CAD space is even evolving to use proper CI/CD tools which is really exciting.\nI don't know if I'll ever have the time to work on version 2 of this project, but it was great fun anyway! And now I have a cool unique lamp. Thank you for reading!\n\n            103\n\n    document.querySelector('#upvote-form').addEventListener('submit', (e) => {\n        e.preventDefault();\n        const form = e.target;\n        fetch(form.action, {\n            method: form.method,\n            body: new FormData(form),\n        });\n        const button = form.querySelector('button')\n        button.disabled = true\n        button.style.color = \"salmon\"\n        const upvoteCount = document.querySelector('.upvote-count')\n        upvoteCount.innerHTML = `${(parseInt(upvoteCount.innerHTML.split(\" \")[0]) + 1)}`\n    });",
    "summary": {
      "en": "**Summary:**\n\nThe author attempted to create artificial sunlight at home, inspired by a DIY project that used a large parabolic reflector. Instead, they designed a compact version using a grid of lenses and multiple LEDs. This approach aimed to reduce the bulkiness of the design and improve thermal management.\n\nKey points of the project include:\n\n- **Design Concept**: The author used a grid of small lenses and multiple low-power LEDs, allowing for a smaller device and better heat distribution.\n- **Learning Experience**: They learned about 3D design, PCB design, and optics throughout the project, using various software tools like CAD modeling and custom Python scripts for simulations.\n- **Technical Specs**: The final product features a 6x6 array of LEDs, custom-made lenses, and specialized components for optimal light output.\n- **Rayleigh Scattering**: They used inkjet print film to mimic Rayleigh scattering, enhancing the light's appearance.\n- **Challenges and Costs**: The project cost around 1000â‚¬, with significant expenses for manufacturing parts. The initial design had some flaws, which were resolved through manual adjustments.\n- **Final Outcome**: The artificial sunlight produced a pleasant glow but was less intense than desired. The author plans to improve the design in a potential version 2, focusing on increasing brightness and surface area.\n\nOverall, the project was a significant learning experience, resulting in a unique lamp and insights into the integration of software and hardware in design.",
      "ko": "ì €ìëŠ” ëŒ€í˜• í¬ë¬¼ì„  ë°˜ì‚¬ë¥¼ ì´ìš©í•œ DIY í”„ë¡œì íŠ¸ì—ì„œ ì˜ê°ì„ ë°›ì•„ ì§‘ì—ì„œ ì¸ê³µ í–‡ë¹›ì„ ë§Œë“¤ë ¤ê³  ì‹œë„í–ˆìŠµë‹ˆë‹¤. ëŒ€ì‹ , ë Œì¦ˆ ê·¸ë¦¬ë“œì™€ ì—¬ëŸ¬ ê°œì˜ LEDë¥¼ ì‚¬ìš©í•˜ì—¬ ì†Œí˜• ë²„ì „ì„ ì„¤ê³„í–ˆìŠµë‹ˆë‹¤. ì´ ì ‘ê·¼ ë°©ì‹ì€ ë””ìì¸ì˜ ë¶€í”¼ë¥¼ ì¤„ì´ê³  ì—´ ê´€ë¦¬ë¥¼ ê°œì„ í•˜ëŠ” ë° ëª©ì ì´ ìˆì—ˆìŠµë‹ˆë‹¤.\n\ní”„ë¡œì íŠ¸ì˜ ì£¼ìš” ë‚´ìš©ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. ì €ìëŠ” ì‘ì€ ë Œì¦ˆ ê·¸ë¦¬ë“œì™€ ì—¬ëŸ¬ ê°œì˜ ì €ì „ë ¥ LEDë¥¼ ì‚¬ìš©í•˜ì—¬ ë” ì‘ì€ ì¥ì¹˜ì™€ ë” ë‚˜ì€ ì—´ ë¶„ì‚°ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” ë””ìì¸ ê°œë…ì„ ì ìš©í–ˆìŠµë‹ˆë‹¤. ì´ ê³¼ì •ì—ì„œ 3D ë””ìì¸, PCB ì„¤ê³„, ê´‘í•™ì— ëŒ€í•´ ë°°ìš°ë©° CAD ëª¨ë¸ë§ê³¼ ë§ì¶¤í˜• íŒŒì´ì¬ ìŠ¤í¬ë¦½íŠ¸ë¥¼ í™œìš©í•œ ì‹œë®¬ë ˆì´ì…˜ ë“± ë‹¤ì–‘í•œ ì†Œí”„íŠ¸ì›¨ì–´ ë„êµ¬ë¥¼ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤. ìµœì¢… ì œí’ˆì€ 6x6 ë°°ì—´ì˜ LED, ë§ì¶¤í˜• ë Œì¦ˆ, ìµœì ì˜ ë¹› ì¶œë ¥ì„ ìœ„í•œ íŠ¹ìˆ˜ ë¶€í’ˆì„ íŠ¹ì§•ìœ¼ë¡œ í•©ë‹ˆë‹¤. ë˜í•œ, ë ˆì¼ë¦¬ ì‚°ë€ì„ ëª¨ë°©í•˜ê¸° ìœ„í•´ ì‰í¬ì ¯ ì¸ì‡„ í•„ë¦„ì„ ì‚¬ìš©í•˜ì—¬ ë¹›ì˜ ì™¸ê´€ì„ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤.\n\ní”„ë¡œì íŠ¸ ë¹„ìš©ì€ ì•½ 1000ìœ ë¡œë¡œ, ë¶€í’ˆ ì œì¡°ì— ìƒë‹¹í•œ ë¹„ìš©ì´ ë“¤ì—ˆìŠµë‹ˆë‹¤. ì´ˆê¸° ë””ìì¸ì—ëŠ” ëª‡ ê°€ì§€ ê²°í•¨ì´ ìˆì—ˆì§€ë§Œ, ìˆ˜ë™ ì¡°ì •ì„ í†µí•´ í•´ê²°í–ˆìŠµë‹ˆë‹¤. ìµœì¢… ê²°ê³¼ë¬¼ì€ ê¸°ë¶„ ì¢‹ì€ ë¹›ì„ ë°œì‚°í–ˆì§€ë§Œ ì›í•˜ëŠ” ë§Œí¼ ê°•ë ¬í•˜ì§€ëŠ” ì•Šì•˜ìŠµë‹ˆë‹¤. ì €ìëŠ” ë°ê¸°ì™€ í‘œë©´ì ì„ ëŠ˜ë¦¬ëŠ” ë° ì¤‘ì ì„ ë‘ì–´ í–¥í›„ ë²„ì „ 2ì—ì„œ ë””ìì¸ì„ ê°œì„ í•  ê³„íšì…ë‹ˆë‹¤.\n\nì „ë°˜ì ìœ¼ë¡œ ì´ í”„ë¡œì íŠ¸ëŠ” ì¤‘ìš”í•œ í•™ìŠµ ê²½í—˜ì´ì—ˆìœ¼ë©°, ë…íŠ¹í•œ ë¨í”„ì™€ ë””ìì¸ì—ì„œ ì†Œí”„íŠ¸ì›¨ì–´ì™€ í•˜ë“œì›¨ì–´ì˜ í†µí•©ì— ëŒ€í•œ í†µì°°ì„ ì–»ëŠ” ê²°ê³¼ë¥¼ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "f0e60f9213a8b5b0",
    "title": {
      "en": "Mid-pregnancy pollution exposure linked to postpartum depression",
      "ko": "ì„ì‹  ì¤‘ ì˜¤ì—¼, ì‚°í›„ ìš°ìš¸ì¦ê³¼ ì—°ê´€",
      "ja": null
    },
    "type": "story",
    "url": "https://www.bps.org.uk/research-digest/mid-pregnancy-pollution-exposure-linked-postpartum-depression-new-study-suggests",
    "score": 52,
    "by": "wjb3",
    "time": 1743146735,
    "content": "Related articlesA guide for difficult news in pregnancy 03 September 2020 Ella Rhodes reports.Pregnancy affects womenâ€™s memory for what they plan to do 12 November 2008 Research finds pregnant women under-perform on tests of retrospective memory, such as word learning tasks.Cognition and perceptionMemoryWhat is psychological about normal pregnancy? 13 March 2010 Paula Nicolson reviews issues of biology, risk, identityâ€¦ and more.Sex and gender",
    "summary": {
      "en": "Hereâ€™s a simplified summary of the key points from the text:\n\n- There are articles discussing various aspects of pregnancy, including:\n  - How pregnancy can impact women's memory, particularly their ability to remember planned tasks.\n  - Research showing that pregnant women may struggle with certain memory tests.\n  - A review of psychological issues related to pregnancy, including biology, risk, and identity.",
      "ko": "ì„ì‹ ê³¼ ê´€ë ¨ëœ ì—¬ëŸ¬ ì¸¡ë©´ì— ëŒ€í•œ ê¸°ì‚¬ë“¤ì´ ìˆìŠµë‹ˆë‹¤. ì´ ì¤‘ í•˜ë‚˜ëŠ” ì„ì‹ ì´ ì—¬ì„±ì˜ ê¸°ì–µë ¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë‹¤ë£¨ê³  ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ, ì„ì‹  ì¤‘ì—ëŠ” ê³„íšëœ ì¼ì„ ê¸°ì–µí•˜ëŠ” ëŠ¥ë ¥ì´ ì €í•˜ë  ìˆ˜ ìˆë‹¤ëŠ” ì ì´ ì–¸ê¸‰ë©ë‹ˆë‹¤. ì—°êµ¬ì— ë”°ë¥´ë©´, ì„ì‹ í•œ ì—¬ì„±ë“¤ì´ íŠ¹ì • ê¸°ì–µë ¥ í…ŒìŠ¤íŠ¸ì—ì„œ ì–´ë ¤ì›€ì„ ê²ªëŠ” ê²½ìš°ê°€ ë§ë‹¤ê³  í•©ë‹ˆë‹¤. ë˜í•œ, ì„ì‹ ê³¼ ê´€ë ¨ëœ ì‹¬ë¦¬ì  ë¬¸ì œì— ëŒ€í•œ ê²€í† ë„ ì´ë£¨ì–´ì¡Œìœ¼ë©°, ì—¬ê¸°ì—ëŠ” ìƒë¬¼í•™ì  ìš”ì¸, ìœ„í—˜ ìš”ì†Œ, ê·¸ë¦¬ê³  ì •ì²´ì„±ì— ëŒ€í•œ ë…¼ì˜ê°€ í¬í•¨ë©ë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "c833c735ec962236",
    "title": {
      "en": "Preschoolers can reason better than we think, study suggests",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://phys.org/news/2025-03-preschoolers.html",
    "score": 160,
    "by": "PaulHoule",
    "time": 1742903610,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "8c244607c023de64",
    "title": {
      "en": "Using uv and PEP 723 for Self-Contained Python Scripts",
      "ko": "UVì™€ PEP 723ë¡œ ì™„ë²½í•œ íŒŒì´ì¬ ìŠ¤í¬ë¦½íŠ¸ ë§Œë“¤ê¸°",
      "ja": null
    },
    "type": "story",
    "url": "https://thisdavej.com/share-python-scripts-like-a-pro-uv-and-pep-723-for-easy-deployment/",
    "score": 228,
    "by": "thisdavej",
    "time": 1743123226,
    "content": "Table of Contentsuv and PEP 723Setting the stageInstalling uvAdding package dependencies in single-file scripts with uvRunning your script with uvMaking it even easier to run with a Python shebangLinux/macOS usersWindows usersSetting up your uv script to be invoked from anywhere on your computerLinux/macOS usersWindows usersBonus: where does uv install its virtual environments?How does uv derive its virtual environment folder name?Conclusion",
    "summary": {
      "en": "**Summary:**\n\nThis document provides a guide on using a tool called \"uv.\" \n\n1. **Introduction to uv and PEP 723**: It explains what uv is and its connection to PEP 723.\n2. **Installation**: Instructions for installing uv.\n3. **Adding Dependencies**: How to add package dependencies in single-file scripts using uv.\n4. **Running Scripts**: Steps to run your script with uv and make it easier to execute using a Python shebang.\n5. **Setup Instructions**: Guidance for Linux/macOS and Windows users on how to set up uv scripts to run from anywhere on your computer.\n6. **Virtual Environments**: Information on where uv installs its virtual environments and how it names them.\n7. **Conclusion**: A wrap-up of the document. \n\nThis guide is designed to help users effectively utilize uv for their Python projects.",
      "ko": "ì´ ë¬¸ì„œëŠ” \"uv\"ë¼ëŠ” ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì— ëŒ€í•œ ì•ˆë‚´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n\nuvëŠ” ë¬´ì—‡ì¸ì§€ì™€ PEP 723ê³¼ì˜ ê´€ê³„ë¥¼ ì„¤ëª…í•©ë‹ˆë‹¤. PEP 723ì€ Pythonì˜ ê°œì„  ì œì•ˆì„œë¡œ, uvì˜ ê¸°ëŠ¥ê³¼ ëª©ì ì„ ì´í•´í•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤. \n\nuvë¥¼ ì„¤ì¹˜í•˜ëŠ” ë°©ë²•ì— ëŒ€í•œ ì§€ì¹¨ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì„¤ì¹˜ ê³¼ì •ì€ ê°„ë‹¨í•˜ë©°, í•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼ ì‰½ê²Œ ì¶”ê°€í•  ìˆ˜ ìˆëŠ” ë°©ë²•ë„ ì•ˆë‚´í•©ë‹ˆë‹¤. ë‹¨ì¼ íŒŒì¼ ìŠ¤í¬ë¦½íŠ¸ì—ì„œ uvë¥¼ ì‚¬ìš©í•˜ì—¬ íŒ¨í‚¤ì§€ ì˜ì¡´ì„±ì„ ì¶”ê°€í•˜ëŠ” ë°©ë²•ì„ ì„¤ëª…í•©ë‹ˆë‹¤.\n\nuvë¥¼ ì‚¬ìš©í•˜ì—¬ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ëŠ” ë‹¨ê³„ë„ ì•ˆë‚´í•©ë‹ˆë‹¤. Pythonì˜ shebangì„ ì‚¬ìš©í•˜ë©´ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë” ì‰½ê²Œ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n\nLinux/macOSì™€ Windows ì‚¬ìš©ìì—ê²Œ uv ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì»´í“¨í„°ì˜ ì–´ëŠ ìœ„ì¹˜ì—ì„œë“  ì‹¤í–‰í•  ìˆ˜ ìˆë„ë¡ ì„¤ì •í•˜ëŠ” ë°©ë²•ì— ëŒ€í•œ ì§€ì¹¨ì´ ì œê³µë©ë‹ˆë‹¤. \n\nuvê°€ ê°€ìƒ í™˜ê²½ì„ ì„¤ì¹˜í•˜ëŠ” ìœ„ì¹˜ì™€ ê·¸ ì´ë¦„ì„ ì§€ì •í•˜ëŠ” ë°©ë²•ì— ëŒ€í•œ ì •ë³´ë„ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. \n\nì´ ê°€ì´ë“œëŠ” ì‚¬ìš©ìê°€ Python í”„ë¡œì íŠ¸ì—ì„œ uvë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í™œìš©í•  ìˆ˜ ìˆë„ë¡ ë•ê¸° ìœ„í•´ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "f9535b307df11e08",
    "title": {
      "en": "A Debugger is a REPL is a Debugger",
      "ko": "ë””ë²„ê±°ì˜ ì¬ë°œê²¬",
      "ja": null
    },
    "type": "story",
    "url": "https://matklad.github.io/2025/03/25/debugger-is-repl-is-debugger.html",
    "score": 40,
    "by": "ingve",
    "time": 1742900776,
    "content": "A Debugger is a REPL is a Debugger Mar 25, 2025\nI love debuggers! The last time I used a debugger seriously was in 2017 or so, when I was still\ncoding in Kotlin. Iâ€™ve since switched to working with native code, and, sadly gdb and lldb are of\nalmost no help for me. This is because they are mere â€œdebuggersâ€, but what I need is a REPL, and a\ndebugger, all in one. In this article I show a more productive way to use debuggers as REPLS.\nThe trick boils down to two IntelliJ IDEA features, Run to Cursor and Quick Evaluate\nExpression.\nThe first feature, run to cursor, resumes the program until it reaches the line where the cursor is\nat. It is a declarative alternative to the primitive debugger features for stepping into, over, and\nout â€” rather telling the debugger how to do every single step, you just directly tell it where do\nyou want to be:\n\nThe second feature, quick evaluate expression, evaluates selected test in the context of the current\nstack frame. Crucially, this neednâ€™t be some pre-existing expression, you can type new stuff and\nevaluate it!\n\nRun to cursor sets up the interesting context, and quick evaluate allows you to poke around. This\ntwo features completely change how I used debuggers â€” instead of stepping through my program and\nobserving it, I zap between interesting points of its execution and run experiments.\nAuthors of debuggers & REPLs, take note of these features of the workflow:\nThereâ€™s no prompt anywhere. The medium of interaction is the 2D program text, not 1D command line.\nIts a vi interface, not ed interface.\nFrom the debugger side, we support seamless evaluation of new program text in context. When\nentering new text, you get full code completion experience. I havenâ€™t used this a tonne, but it\nshould also be possible to reload code with your changes.\nFrom the REPL side, you need breakpoints. Top-level context is rarely interesting! You need to be\nable to place yourself â€œin the middleâ€ of your application, where you have access to all the locals.\nDebuggers do this via setting breakpoints, but the click-on-the-fringe (or, worse, enter\nfile:line:column textually) UI is atrocious. Thereâ€™s a perfectly fine pointing device in any\neditor â€” the cursor. Just get the program execution to that point!",
    "summary": {
      "en": "The author expresses their enthusiasm for using debuggers, sharing their experience with them since 2017. They highlight a need for a tool that combines both a debugger and a REPL (Read-Eval-Print Loop), particularly for their current work with native code, where traditional debuggers like gdb and lldb fall short.\n\nThe article introduces two key features from IntelliJ IDEA that can enhance the debugging experience: \n\n1. **Run to Cursor**: This feature allows users to run the program until it reaches a specific line, providing a more efficient way to navigate through code without manually stepping through each line.\n   \n2. **Quick Evaluate Expression**: This lets users evaluate any selected text in the current context, enabling them to test new code on the fly.\n\nTogether, these features allow for a more interactive debugging process where users can quickly jump to interesting points in the code and experiment, rather than just observing program execution step-by-step. The author suggests that debuggers should support seamless code evaluation and allow for easy access to local variables by using breakpoints effectively. They advocate for a more intuitive interface that leverages the cursor for navigation rather than cumbersome text inputs.",
      "ko": "ì €ìëŠ” 2017ë…„ë¶€í„° ë””ë²„ê±°ë¥¼ ì‚¬ìš©í•´ì˜¨ ê²½í—˜ì„ ë°”íƒ•ìœ¼ë¡œ ë””ë²„ê±°ì— ëŒ€í•œ ì—´ì •ì„ í‘œí˜„í•©ë‹ˆë‹¤. íŠ¹íˆ, í˜„ì¬ ë„¤ì´í‹°ë¸Œ ì½”ë“œ ì‘ì—…ì„ í•˜ë©´ì„œ ì „í†µì ì¸ ë””ë²„ê±°ì¸ gdbì™€ lldbê°€ ë¶€ì¡±í•˜ë‹¤ëŠ” ì ì—ì„œ ë””ë²„ê±°ì™€ REPL(ì½ê¸°-í‰ê°€-ì¶œë ¥ ë£¨í”„)ì„ ê²°í•©í•œ ë„êµ¬ì˜ í•„ìš”ì„±ì„ ê°•ì¡°í•©ë‹ˆë‹¤.\n\nì´ ê¸€ì—ì„œëŠ” IntelliJ IDEAì—ì„œ ë””ë²„ê¹… ê²½í—˜ì„ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆëŠ” ë‘ ê°€ì§€ ì£¼ìš” ê¸°ëŠ¥ì„ ì†Œê°œí•©ë‹ˆë‹¤. ì²« ë²ˆì§¸ëŠ” 'ì»¤ì„œê¹Œì§€ ì‹¤í–‰(Run to Cursor)' ê¸°ëŠ¥ìœ¼ë¡œ, ì‚¬ìš©ìê°€ íŠ¹ì • ì¤„ì— ë„ë‹¬í•  ë•Œê¹Œì§€ í”„ë¡œê·¸ë¨ì„ ì‹¤í–‰í•  ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë§¤ ì¤„ë§ˆë‹¤ ìˆ˜ë™ìœ¼ë¡œ ì‹¤í–‰í•˜ì§€ ì•Šê³ ë„ ì½”ë“œ ë‚´ë¹„ê²Œì´ì…˜ì„ ë” íš¨ìœ¨ì ìœ¼ë¡œ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‘ ë²ˆì§¸ëŠ” 'ë¹ ë¥¸ í‘œí˜„ì‹ í‰ê°€(Quick Evaluate Expression)' ê¸°ëŠ¥ìœ¼ë¡œ, í˜„ì¬ ë¬¸ë§¥ì—ì„œ ì„ íƒí•œ í…ìŠ¤íŠ¸ë¥¼ í‰ê°€í•  ìˆ˜ ìˆê²Œ í•´ì£¼ì–´ ìƒˆë¡œìš´ ì½”ë“œë¥¼ ì¦‰ì„ì—ì„œ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nì´ ë‘ ê°€ì§€ ê¸°ëŠ¥ì€ ì‚¬ìš©ìê°€ ì½”ë“œì—ì„œ í¥ë¯¸ë¡œìš´ ì§€ì ìœ¼ë¡œ ë¹ ë¥´ê²Œ ì´ë™í•˜ê³  ì‹¤í—˜í•  ìˆ˜ ìˆëŠ” ë” ìƒí˜¸ì‘ìš©ì ì¸ ë””ë²„ê¹… ê³¼ì •ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. ì €ìëŠ” ë””ë²„ê±°ê°€ ì›í™œí•œ ì½”ë“œ í‰ê°€ë¥¼ ì§€ì›í•˜ê³ , íš¨ê³¼ì ìœ¼ë¡œ ì¤‘ë‹¨ì ì„ ì‚¬ìš©í•˜ì—¬ ì§€ì—­ ë³€ìˆ˜ì— ì‰½ê²Œ ì ‘ê·¼í•  ìˆ˜ ìˆë„ë¡ í•´ì•¼ í•œë‹¤ê³  ì œì•ˆí•©ë‹ˆë‹¤. ë˜í•œ, ë³µì¡í•œ í…ìŠ¤íŠ¸ ì…ë ¥ ëŒ€ì‹  ì»¤ì„œë¥¼ í™œìš©í•œ ë” ì§ê´€ì ì¸ ì¸í„°í˜ì´ìŠ¤ë¥¼ ì§€ì§€í•©ë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "4044c51131ead424",
    "title": {
      "en": "Percentage of parents financially supporting adult children reaches 3-year high",
      "ko": "ì„±ì¸ ìë…€ ì§€ì›, 3ë…„ ë§Œì— ìµœê³ ì¹˜!",
      "ja": null
    },
    "type": "story",
    "url": "https://www.savings.com/insights/financial-support-for-adult-children-study",
    "score": 28,
    "by": "walterbell",
    "time": 1743144765,
    "content": "{\n\"@context\": \"http://schema.org\",\n\"@type\": \"NewsArticle\",\n\"inLanguage\": \"en-US\",\n\"url\": \"https://www.savings.com/insights/financial-support-for-adult-children-study\",\n\"mainEntityOfPage\": \"https://www.savings.com/insights/financial-support-for-adult-children-study\",\n\"image\": \"https://cdn.sdccdn.com/images/savings/logo/5199693.png?width=500\",\n\"thumbnailUrl\": \"https://cdn.sdccdn.com/images/savings/logo/5199692.png?width=325\",\n\"name\": \"Percentage of parents financially supporting adult children reaches a three-year high\",\n\"headline\": \"Percentage of parents financially supporting adult children reaches a three-year high\",\n\"description\": \"\",\n\"datePublished\": \"2025-03-21\",\n\"dateModified\": \"2025-03-26T08:48:02-0700\",\n\"author\": {\n\"@type\": \"Person\",\n\"name\": \"Beth Klongpayabal\",\n\"email\": \"beth.klongpayabal@savings.com\",\n\"description\": \"Beth Klongpayabal is an Analytics Manager for Savings.com. She provides insights on consumer purchases and emerging retail trends. Previously, she served as Head of Data Operations.\",\n\"jobTitle\": \"Analytics Manager at Savings.com\",\n\"image\": {\n\"@type\": \"ImageObject\",\n\"url\": \"https://cdn.sdccdn.com/images/savings/logo/4959644.jpeg\"\n}\n},\n\"publisher\": {\n\"@type\": \"Organization\",\n\"name\": \"Savings.com\",\n\"url\": \"https://www.savings.com\",\n\"logo\": \"https://cdn.sdccdn.com/images/theme/sdc2/logos/savings.svg\"\n}\n}\n\nBy Beth Klongpayabal\n\nLast Updated: March 21, 2025\n\n.table-blue thead th { background-color: #2269DC; color: #FFF; text-align: left; vertical-align: middle!important; padding: .75rem .625rem .75rem; font-weight: bold; } .anchor-section li { list-style-type:none; margin-left: -20px!important; } .anchor-section li a{ text-decoration: underline; } .anchor-section h4{ margin-top:35px; } table { margin-bottom: 30px; }\n\nThe average amount these parents give also reached a three-year high at $1,474/month, but 40% plan to cut off funds in the next two years.\nLet's face itâ€”adulting is expensive these days. With economic pressures hitting younger generations hard, more and more adult Americans are turning to an age-old financial institution: their parents.\nThis trend of parents bankrolling their grown kids took off during the pandemic, and at Savings.com, weâ€™ve been reporting on it since 2022.\nFor our fourth annual report, we surveyed 1,000 parents of adult children. We wanted to know how much money flows from parents to grown kids, what they're spending it on, how this affects their financial health, and how far the â€œBank of Mom & Dad\" is willing to go to keep their adult offspring afloat.\nKey Findings:\n\nHalf of parents with adult children provide regular financial assistance to their grown offspring. The average support per adult child is $1,474 monthly, about 6% higher than last year.\n83% of supporting parents contribute to their adult kidsâ€™ monthly groceries; 65% help with cell phones, and nearly half (46%) pay for vacations.\nMore than three-quarters (77%) of supportive parents attach conditions to their financial assistance. 23% give money without any conditions.\nNearly 50 percent of parents have sacrificed their financial security to help their grown kids financially, and most supporting parents feel obligated to help their kids with money.\nWorking parents who support grown kids contribute over 2X more money each month to their adult children than they do to retirement funds.\n\nHalf of all parents with children 18+ provide them with financial support in 2025\nThe American economy has maintained its strength in recent years. However, the new presidential administration's ambitious initiatives, substantial promises, and international trade tensions have introduced financial uncertainty.\nThis unsettled economic landscape and the growing wealth gap between generations may have strengthened the financial connection between adult children and their parents. For the first time since beginning our annual research, we've found that half of parents with adult children now provide regular financial assistance to their grown kids.\n\n<img src=\"\" width=\"100%\" alt=\"chart visualization\" class=\"lazy\" data-original=\"https://public.flourish.studio/visualisation/21815193/thumbnail\">\nA Flourish chart\nWith inflation keeping the cost of living high, parents' financial support has reached a new peak, averaging nearly $1,500 per month (or almost $18,000 annually). This represents a six percent increase from the monthly contributions we reported last year.\nAs you might expect, Generation Z adults (ages 18-28) receive more financial support from their parents than their Millennial counterparts (ages 29-44), who've had more time to build careers and establish income streams. While the average contribution to Millennials decreased slightly, a significant increase in support for Generation Zers pushed the overall average higher. Members of Generation X (ages 45-60) rarely receive financial assistance from their parents, likely because they've either achieved financial independence or have inherited family wealth.\n\n<img src=\"\" width=\"100%\" alt=\"chart visualization\" class=\"lazy\" data-original=\"https://public.flourish.studio/visualisation/22100594/thumbnail\">\nA Flourish chart\nThe financial strain of supporting grown children is particularly pressing for parents preparing a nest egg. Parents still in the workforce contribute over two times more money to their adult children each month than their retirement accounts.\n\n<img src=\"\" width=\"100%\" alt=\"chart visualization\" class=\"lazy\" data-original=\"https://public.flourish.studio/visualisation/22101217/thumbnail\">\nA Flourish chart\nThe psychological and fiscal impact of such commitment translates directly to parental anxiety. At a time when many Americans havenâ€™t set aside enough funds for their later years, 79 percent of those supporting adult children worry about setting themselves up for a comfortable retirement. In comparison, 72 percent of people who donâ€™t support adult children financially feel stressed about their retirement savings.\nWhat costs do parents cover for their adult children?\nParents report providing their adult children with financial assistance for various expenses, from educational costs to vacations to basic spending money.\nLooking at the breakdown of this support reveals that food and groceries top the list of needs among financially dependent adult children. With food prices continuing to climb, it's understandable that four out of five parents providing assistance are helping with their grown kidsâ€™ grocery bills. Parents contribute an average of $220 monthly toward their adult child's grocery expenses.\nCosts parents help their adult kids cover in 2025\nBy generation of their adult children\n\nCategories parents contribute to\nParents supporting Gen Zers (18-28)\nParents supporting Millennials (29-44)\nAll parents supporting adult kids\nAverage monthly support provided\n\nGroceries or food\n87%\n78%\n83%\n$220\n\nCell phone\n73%\n51%\n65%\n$63\n\nHealth insurance or healthcare\n69%\n28%\n54%\n$165\n\nRent or mortgage\n66%\n58%\n63%\n$653\n\nTuition or other school expenses\n57%\n24%\n45%\n$1,198\n\nLeisure/vacations\n56%\n30%\n46%\n$190\n\nCar\n49%\n39%\n44%\n$218\n\nDiscretionary spending\n47%\n41%\n44%\n$126\n\nStudent loans\n26%\n18%\n23%\n$226\n\nCredit cards\n22%\n19%\n21%\n$160\n\nInvestments\n18%\n9%\n14%\n*\n\n*Insufficient data\n\nAnother two-thirds of parents with adult children assisted with cell phone bills and housing expenses. The need for specific types of support varied between Generation Zers and Millennials. Gen Z adults were far more likely to need help with healthcare, vacations, and tuition than Millennials, as many are still in school or just launching their careers in their early twenties. School expenses were the costliest for parents, averaging nearly $1200 monthly. Thatâ€™s a massive increase over the average spending on tuition last year, at around $600 a month.\nParental financial support often comes with conditions\nAccepting financial help from parents is one thing, but doing so while demonstrating effort and appreciation is another matter. Our findings suggest that parents may be growing less tolerant of adult children who appear to take advantage of their generosity.\nAmong parents providing financial support, 63 percent also offer housing to their adult children. While only 39 percent of these live-at-home adult children contributed to household expenses in 2024, that figure has increased substantially to 51 percent this year.\nThis improvement in shared financial responsibility likely stems from parents setting firmer boundaries. The percentage of parents establishing specific conditions for financial assistance has increased since our previous studyâ€”from 71 percent who gave conditionally last year to 77 percent who now attach requirements to their financial support.\n\nWhich conditions must your adult children meet to receive your financial assistance? Select all that apply.\n2024\n2025\n\nMaintaining a job or actively seeking employment (e.g., must prove they are applying to jobs if unemployed)\n45%\n48%\n\nPursuing education (e.g., must be enrolled in college, university, or vocational training)\n42%\n45%\n\nContributing to household expenses (if living at home, e.g., must pay a portion of rent or utility bills)\n18%\n26%\n\nAchieving certain financial behaviors or goals (e.g., must follow a budget or save a certain amount each month)\n17%\n21%\n\nAttending counseling or therapy (if support is related to personal development or health issues)\n4%\n4%\n\nNone - I provide support with no specific conditions\n29%\n23%\n\nThe most notable increase appeared in parents requiring adult children living at home to contribute to household expenses. However, the most common conditions continue to be requirements that adult children actively seek employment or pursue educationâ€”practical approaches designed to guide grown offspring toward eventual financial independence.\nOther conditions parents placed on their adult children included establishing financial goals and attending counseling or therapy sessions. Each such requirement reflects a caring concern designed to help adult children financially get on their feet.\nWhat are parents sacrificing for their childrenâ€™s financial security?\nThe parents in the study seemed more than willing to aid their children. Yet, that added financial burden often creates stress and demands lifestyle sacrifices. What compels them to keep giving?\nObligation is one driving force for parents who economically support their adult offspring. Most parents who provide monetary assistance do so out of some sense of duty.\nFifty-three percent of contributing parents feel responsible for financially supporting their grown kids. That number is down from 61 percent one year ago, another potential indicator that such gravy train sentiments may be slipping.\n\n<img src=\"\" width=\"100%\" alt=\"chart visualization\" class=\"lazy\" data-original=\"https://public.flourish.studio/visualisation/22101377/thumbnail\">\nA Flourish chart\nThis responsibility causes great strain on parents. Nearly 50 percent of providing parents sacrifice financial security for the sake of supported children, and 40 percent felt pressured to give financial assistance even when it meant uncomfortably stretching their resources.\nThose numbers mirror the findings from past reports. Despite the hardship and stress sometimes created by these contributions, devoted moms and dads remain ready to dig deeper to help their struggling kids. Nearly nine in ten parents would make one or more additional financial sacrifices to aid their offspring.\nSpecifically, more than 60 percent of parents would be willing to live a more frugal lifestyle to support their adult children, half would pull money from their savings or retirement accounts, and one-third would postpone retirement or take on debt so that they might shift funds to provide for their progeny.\n\nWhich of these would you be willing to do to financially support your adult child(ren)? Select all that apply.\n2024\n2025\n\nLive a more frugal lifestyle\n61%\n62%\n\nPull money from my savings or retirement account\n46%\n50%\n\nRetire later\n37%\n35%\n\nTake on debt\n29%\n31%\n\nCome out of retirement\n18%\n17%\n\nRefinance my home\n12%\n13%\n\nNone of the above\n14%\n13%\n\nMany supporting parents would be willing to come out of retirement or refinance their homes to help their children. Grown kids struggling through financial straits are fortunate to find such selfless family support. They shouldn't take it for granted or become perpetually dependent.\nWhen asked how long they planned to continue financial support of adult children, parents admitted there may be a shelf life on their generosity. Less than 20 percent of those supplying aid said their largesse would continue indefinitely.\n\n<img src=\"\" width=\"100%\" alt=\"chart visualization\" class=\"lazy\" data-original=\"https://public.flourish.studio/visualisation/22101467/thumbnail\">\nA Flourish chart\nMore than one-third of parents who give money to their adult kids say theyâ€™ll cut off support within the next two years. Their aim is likely to encourage their children towards financial independence. However, terminating assistance before a potential recession could deal a double blow to younger generations.\nConclusion\nThe last four years of our research findings collectively illustrate remarkable parental commitment. Parents continue to accept financial stress and make personal sacrifices to support their adult children's economic well-being. However, even as we see more parents providing financial assistance than in any previous year of our research, we've also detected some emerging cracks in this foundation of support.\nThe percentage of parents who feel financially responsible for supporting their adult children has declined, while more are establishing specific conditions for continued assistance. Perhaps most notably, almost 40 percent of parents plan to end their financial support within the next two years.\nDespite these subtle shifts away from unconditional assistance, our survey essentially confirms what we've seen in recent years: the ongoing need to financially support struggling adult children is placing significant strain on many parents' financial security. This concerning pattern may face additional pressure if economic conditions worsen in the coming months. We'll examine how these trends evolve in our 2026 report.\nOur Data\nWe surveyed 1,001 U.S. parents of adult children to determine whether they cover some of their kids' bills or provide other financial support.\nOur survey was conducted online in February 2024. Participants were 50 percent men and 50 percent women. The median age among respondents was 56, and the median income was between $50,000 and $74,999 annually. Income disparities were controlled for.\nOur data distinguishes between adult children with disabilities, which may make it more difficult for them to live independently, and adult children without disabilities. Our analysis focused on parents who contribute financially to their adult children who donâ€™t have disabilities.",
    "summary": {
      "en": "Parents are increasingly providing financial support to their adult children, with the percentage reaching a three-year high. A recent survey found that half of parents with adult children offer regular assistance, averaging $1,474 per month, which is up 6% from last year. This trend, which began during the pandemic, has continued due to economic pressures faced by younger generations.\n\nKey findings from the survey include:\n- 83% of parents help with groceries, 65% assist with cell phone bills, and nearly half cover vacation costs.\n- 77% of parents impose conditions on their financial aid, aiming to encourage independence.\n- Almost 50% of parents feel they are sacrificing their own financial security to support their kids.\n\nParents of Generation Z (ages 18-28) receive more support than Millennials (ages 29-44) as they are often still in school or early in their careers. While many parents are willing to make sacrifices, such as living more frugally or delaying retirement, about 40% of them plan to cut off financial support within the next two years.\n\nOverall, while many parents remain committed to helping their adult children, there is a growing recognition of the need for boundaries and the importance of fostering financial independence. The survey suggests that ongoing economic uncertainties may further impact these dynamics.",
      "ko": "ë¶€ëª¨ë“¤ì´ ì„±ì¸ ìë…€ì—ê²Œ ì¬ì • ì§€ì›ì„ ì œê³µí•˜ëŠ” ë¹„ìœ¨ì´ ì¦ê°€í•˜ê³  ìˆìœ¼ë©°, ì´ëŠ” 3ë…„ ë§Œì— ìµœê³ ì¹˜ë¥¼ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤. ìµœê·¼ ì¡°ì‚¬ì— ë”°ë¥´ë©´, ì„±ì¸ ìë…€ë¥¼ ë‘” ë¶€ëª¨ì˜ ì ˆë°˜ì´ ë§¤ë‹¬ í‰ê·  1,474ë‹¬ëŸ¬ë¥¼ ì •ê¸°ì ìœ¼ë¡œ ì§€ì›í•˜ê³  ìˆìœ¼ë©°, ì´ëŠ” ì§€ë‚œí•´ë³´ë‹¤ 6% ì¦ê°€í•œ ìˆ˜ì¹˜ì…ë‹ˆë‹¤. ì´ ì¶”ì„¸ëŠ” íŒ¬ë°ë¯¹ ë™ì•ˆ ì‹œì‘ë˜ì—ˆìœ¼ë©°, ì Šì€ ì„¸ëŒ€ê°€ ê²ªê³  ìˆëŠ” ê²½ì œì  ì••ë°•ìœ¼ë¡œ ì¸í•´ ê³„ì†ë˜ê³  ìˆìŠµë‹ˆë‹¤.\n\nì¡°ì‚¬ì˜ ì£¼ìš” ê²°ê³¼ë¡œëŠ” 83%ì˜ ë¶€ëª¨ê°€ ì‹ë£Œí’ˆ ë¹„ìš©ì„ ì§€ì›í•˜ê³ , 65%ê°€ íœ´ëŒ€ì „í™” ìš”ê¸ˆì„ ë„ì™€ì£¼ë©°, ê±°ì˜ ì ˆë°˜ì´ íœ´ê°€ ë¹„ìš©ì„ ë¶€ë‹´í•˜ê³  ìˆë‹¤ëŠ” ì ì´ ìˆìŠµë‹ˆë‹¤. 77%ì˜ ë¶€ëª¨ëŠ” ìë…€ì˜ ë…ë¦½ì„±ì„ ì´‰ì§„í•˜ê¸° ìœ„í•´ ì¬ì • ì§€ì›ì— ì¡°ê±´ì„ ë¶™ì´ê³  ìˆìœ¼ë©°, ê±°ì˜ 50%ëŠ” ìë…€ë¥¼ ì§€ì›í•˜ê¸° ìœ„í•´ ìì‹ ì˜ ì¬ì •ì  ì•ˆì „ì„ í¬ìƒí•˜ê³  ìˆë‹¤ê³  ëŠë¼ê³  ìˆìŠµë‹ˆë‹¤.\n\nZì„¸ëŒ€(18-28ì„¸)ì˜ ë¶€ëª¨ëŠ” ë°€ë ˆë‹ˆì–¼ ì„¸ëŒ€(29-44ì„¸)ì˜ ë¶€ëª¨ë³´ë‹¤ ë” ë§ì€ ì§€ì›ì„ ë°›ê³  ìˆìŠµë‹ˆë‹¤. ì´ëŠ” Zì„¸ëŒ€ê°€ í•™êµì— ë‹¤ë‹ˆê±°ë‚˜ ê²½ë ¥ ì´ˆê¸° ë‹¨ê³„ì— ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ë§ì€ ë¶€ëª¨ë“¤ì´ ë” ê²€ì†Œí•˜ê²Œ ìƒí™œí•˜ê±°ë‚˜ ì€í‡´ë¥¼ ë¯¸ë£¨ëŠ” ë“±ì˜ í¬ìƒì„ ê°ìˆ˜í•  ì˜í–¥ì´ ìˆì§€ë§Œ, ì•½ 40%ëŠ” í–¥í›„ 2ë…„ ë‚´ì— ì¬ì • ì§€ì›ì„ ì¤‘ë‹¨í•  ê³„íšì´ë¼ê³  ë°í˜”ìŠµë‹ˆë‹¤.\n\nì „ë°˜ì ìœ¼ë¡œ ë§ì€ ë¶€ëª¨ë“¤ì´ ì„±ì¸ ìë…€ë¥¼ ë•ê² ë‹¤ëŠ” ì˜ì§€ë¥¼ ê°€ì§€ê³  ìˆì§€ë§Œ, ê²½ê³„ ì„¤ì •ì˜ í•„ìš”ì„±ê³¼ ì¬ì •ì  ë…ë¦½ì„±ì„ í‚¤ìš°ëŠ” ê²ƒì˜ ì¤‘ìš”ì„±ì— ëŒ€í•œ ì¸ì‹ì´ ì»¤ì§€ê³  ìˆìŠµë‹ˆë‹¤. ì´ë²ˆ ì¡°ì‚¬ëŠ” ì§€ì†ì ì¸ ê²½ì œì  ë¶ˆí™•ì‹¤ì„±ì´ ì´ëŸ¬í•œ ë™íƒœì— ë” ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "2f1afeb135a718da",
    "title": {
      "en": "The Great Chatbot Debate",
      "ko": "ì±—ë´‡ ëŒ€ê²©ëŒ",
      "ja": null
    },
    "type": "story",
    "url": "https://computerhistory.org/events/great-chatbot-debate/",
    "score": 14,
    "by": "rbanffy",
    "time": 1742894549,
    "content": "Home  Events\n            The Great Chatbot Debate\n\n                          Do LLMs Really Understand?",
    "summary": {
      "en": "The Great Chatbot Debate is an event focused on whether large language models (LLMs) truly understand language. It explores the capabilities and limitations of these AI systems in comprehending and generating human-like responses.",
      "ko": "ëŒ€ê·œëª¨ ì±—ë´‡ í† ë¡ íšŒëŠ” ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì´ ì‹¤ì œë¡œ ì–¸ì–´ë¥¼ ì´í•´í•˜ëŠ”ì§€ì— ëŒ€í•œ ë…¼ì˜ì— ì´ˆì ì„ ë§ì¶˜ í–‰ì‚¬ì…ë‹ˆë‹¤. ì´ í–‰ì‚¬ì—ì„œëŠ” ì´ëŸ¬í•œ ì¸ê³µì§€ëŠ¥ ì‹œìŠ¤í…œì´ ì¸ê°„ê³¼ ìœ ì‚¬í•œ ë°˜ì‘ì„ ì´í•´í•˜ê³  ìƒì„±í•˜ëŠ” ë° ìˆì–´ ì–´ë–¤ ëŠ¥ë ¥ê³¼ í•œê³„ë¥¼ ê°€ì§€ê³  ìˆëŠ”ì§€ë¥¼ íƒêµ¬í•©ë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "b14fe2b0ae814586",
    "title": {
      "en": "My team loved to ship fast and sink later",
      "ko": "ë¹ ë¥¸ ì¶œë°œ, ë‚˜ì¤‘ì— ì¹¨ëª°!",
      "ja": null
    },
    "type": "story",
    "url": "https://rosesecurity.dev/blog/2025/03/26/rushing-toward-rewrite",
    "score": 9,
    "by": "r0nan",
    "time": 1743182467,
    "content": "Rushing Toward RewriteMarch 26, 2025 Â· 2 min readThis is part three of my microblog series exploring the subtle dysfunctions that plague engineering organizations. After discussing over-abstraction as a liability and unpacking how excessive toil kills engineering teams, this post tackles a nuanced threat: when â€œmoving fastâ€ becomes a cultural shortcut for cutting corners.\nMove Fast and Donâ€™t Break Everything\nA former CEO of mine used to say: â€œBe fast or be perfect. And since no oneâ€™s perfect, you better be fast.â€ Sounds cool until that motto becomes a shield to skip due diligence, code reviews, and even basic security hygiene. Speed wasnâ€™t a valueâ€”it was an excuse. PRs rushed. On-call flaring. Postmortems piling. And still, engineers asking for admin access â€œto move fast.â€\nSpoiler: they didnâ€™t need it.\nThe deeper problem? We werenâ€™t a scrappy startup anymoreâ€”we were operating at enterprise scale with a startup mindset. The cost of speed was technical debt, fragility, and a long tail of rework. When I transitioned to a new role (back in startup mode) I heard the same â€œmove fastâ€ mantra. But this time, it hit differently. Because hereâ€™s the truth: moving fast is possible without setting your future self on fire.\nHereâ€™s what Iâ€™ve learned:\n1. Fail fastâ€”but fail forward. Donâ€™t just throw things at prod and hope they stick. Structure your failures. If a solutionâ€™s not viable, surface that early with data and a path forward. Good failure leaves breadcrumbs for the next iteration.\n2. Build for iteration. Forget perfect. Aim for clear next steps. Your v1 should be designed with a roadmap in mind. Where will this evolve? What trade-offs are you making? Ship itâ€”but know how youâ€™ll ship it better.\n3. Stay modular. Design with exits. If your observability pipeline starts with a pricey SaaS, fine. But make it swappable. Keep your vendor coupling thin so you can self-host later without a complete rewrite.\n4. Be honest about scale. What worked for a team of 10 wonâ€™t work at 100. â€œMove fastâ€ looks different when customers depend on your uptime. Match your velocity with the blast radius of your decisions.\nWe glamorize speed, but the smartest teams know when to slow down, breathe, and make thoughtful decisions that stand the test of time. Move fastâ€”but donâ€™t break the foundation.Edit this page",
    "summary": {
      "en": "The text discusses issues in engineering organizations related to the mindset of \"moving fast.\" The author reflects on their experience with a previous CEO's motto: \"Be fast or be perfect,\" which led to cutting corners and neglecting important processes like code reviews and security. The result was technical debt and fragile systems.\n\nKey takeaways include:\n\n1. **Fail Fast, Fail Forward**: Learn from failures by analyzing them and providing a path for improvement, rather than just rushing without understanding the consequences.\n2. **Build for Iteration**: Focus on clear next steps, planning for future improvements rather than seeking perfection in initial versions.\n3. **Stay Modular**: Design systems to be flexible and easy to change, allowing for updates without extensive rewrites.\n4. **Be Honest About Scale**: Recognize that strategies that worked for small teams may not suit larger ones, and adjust the pace accordingly.\n\nThe overall message is that while speed is important, thoughtful decision-making is crucial for long-term success.",
      "ko": "ì´ ê¸€ì—ì„œëŠ” \"ë¹ ë¥´ê²Œ ì›€ì§ì´ê¸°\"ë¼ëŠ” ì‚¬ê³ ë°©ì‹ê³¼ ê´€ë ¨ëœ ì—”ì§€ë‹ˆì–´ë§ ì¡°ì§ì˜ ë¬¸ì œë¥¼ ë‹¤ë£¹ë‹ˆë‹¤. ì €ìëŠ” ì´ì „ CEOì˜ ëª¨í† ì¸ \"ë¹ ë¥´ê±°ë‚˜ ì™„ë²½í•˜ë¼\"ëŠ” ë§ì— ëŒ€í•´ íšŒìƒí•˜ë©°, ì´ë¡œ ì¸í•´ ì¤‘ìš”í•œ ê³¼ì •ì¸ ì½”ë“œ ë¦¬ë·°ì™€ ë³´ì•ˆì„ ì†Œí™€íˆ í•˜ê²Œ ë˜ì—ˆê³ , ê²°êµ­ ê¸°ìˆ  ë¶€ì±„ì™€ ì·¨ì•½í•œ ì‹œìŠ¤í…œì´ ìƒê²¼ë‹¤ê³  ì„¤ëª…í•©ë‹ˆë‹¤.\n\nì£¼ìš” ë‚´ìš©ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. ì²«ì§¸, \"ë¹ ë¥´ê²Œ ì‹¤íŒ¨í•˜ê³  ì•ìœ¼ë¡œ ë‚˜ì•„ê°€ë¼\"ëŠ” ì›ì¹™ì…ë‹ˆë‹¤. ì‹¤íŒ¨ë¥¼ ë‹¨ìˆœíˆ í”¼í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ì‹¤íŒ¨ë¥¼ ë¶„ì„í•˜ê³  ê°œì„ í•  ìˆ˜ ìˆëŠ” ê¸¸ì„ ì œì‹œí•´ì•¼ í•©ë‹ˆë‹¤. ë‘˜ì§¸, \"ë°˜ë³µì„ ìœ„í•œ êµ¬ì¶•\"ì…ë‹ˆë‹¤. ì´ˆê¸° ë²„ì „ì—ì„œ ì™„ë²½í•¨ì„ ì¶”êµ¬í•˜ê¸°ë³´ë‹¤ëŠ” ëª…í™•í•œ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ì„¤ì •í•˜ê³  ë¯¸ë˜ì˜ ê°œì„ ì„ ê³„íší•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤. ì…‹ì§¸, \"ëª¨ë“ˆí™” ìœ ì§€\"ì…ë‹ˆë‹¤. ì‹œìŠ¤í…œì„ ìœ ì—°í•˜ê³  ì‰½ê²Œ ë³€ê²½í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„í•˜ì—¬, ëŒ€ê·œëª¨ ìˆ˜ì • ì—†ì´ë„ ì—…ë°ì´íŠ¸ê°€ ê°€ëŠ¥í•´ì•¼ í•©ë‹ˆë‹¤. ë„·ì§¸, \"ê·œëª¨ì— ëŒ€í•œ ì†”ì§í•¨\"ì…ë‹ˆë‹¤. ì‘ì€ íŒ€ì—ì„œ íš¨ê³¼ì ì´ì—ˆë˜ ì „ëµì´ í° íŒ€ì—ëŠ” ì í•©í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ê·¸ì— ë§ì¶° ì†ë„ë¥¼ ì¡°ì ˆí•´ì•¼ í•©ë‹ˆë‹¤.\n\nê²°êµ­, ì†ë„ë„ ì¤‘ìš”í•˜ì§€ë§Œ ì¥ê¸°ì ì¸ ì„±ê³µì„ ìœ„í•´ì„œëŠ” ì‹ ì¤‘í•œ ì˜ì‚¬ê²°ì •ì´ í•„ìˆ˜ì ì´ë¼ëŠ” ë©”ì‹œì§€ë¥¼ ì „ë‹¬í•©ë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "1660dc158bf5387e",
    "title": {
      "en": "Plasmonic Modulators Break Wireless Terahertz Barrier",
      "ko": "í”Œë¼ìŠ¤ëª¬ ëª¨ë“ˆë ˆì´í„°, í…Œë¼í—¤ë¥´ì¸  ì¥ë²½ ëŒíŒŒ!",
      "ja": null
    },
    "type": "story",
    "url": "https://spectrum.ieee.org/terahertz-waves-2671362433",
    "score": 24,
    "by": "rbanffy",
    "time": 1742894904,
    "content": "NewsTelecommunications\n        Plasmonic Modulators Can Break the Wireless Terahertz Barrier\n    The tech could find a home in 6G networks and AI data centersMatthew S. Smith24 Mar 20254 min readMatthew S. Smith is a contributing editor for IEEE Spectrum and the former lead reviews editor at Digital Trends.A new plasmonic modulator [in gold] transfers signal information from an electrical wave to an optical wave at higher speeds than other modulator technologies.\n        Johannes Grewer/Polariton Technologies\n\n    {\"customDimensions\": {\"5\":\"Matthew S. Smith\",\"11\":2671362433,\"7\":\"optical fiber, 5g, 6g, wireless communications, plasmonics\",\"10\":\"wireless communications\",\"6\":\"news\",\"8\":\"03/24/2025\"}, \"post\": {\"id\": 2671362433, \"providerId\": 0, \"sections\": [497728257, 544169523, 550122300, 2267926519, 544169516, 539622110, 550122302], \"authors\": [22900948], \"tags\": [\"optical fiber\", \"5g\", \"6g\", \"wireless communications\", \"plasmonics\"], \"streams\": [], \"split_testing\": {}} }",
    "summary": {
      "en": "Researchers have developed a new plasmonic modulator that can convert electrical signals to optical signals faster than existing technologies. This advancement could be beneficial for future 6G networks and AI data centers. The modulator uses gold and represents a significant step forward in wireless communication technology.",
      "ko": "ì—°êµ¬ìë“¤ì´ ê¸°ì¡´ ê¸°ìˆ ë³´ë‹¤ ì „ê¸° ì‹ í˜¸ë¥¼ ê´‘ ì‹ í˜¸ë¡œ ë” ë¹ ë¥´ê²Œ ë³€í™˜í•  ìˆ˜ ìˆëŠ” ìƒˆë¡œìš´ í”Œë¼ìŠ¤ëª¬ ëª¨ë“ˆë ˆì´í„°ë¥¼ ê°œë°œí–ˆìŠµë‹ˆë‹¤. ì´ ë°œì „ì€ ë¯¸ë˜ì˜ 6G ë„¤íŠ¸ì›Œí¬ì™€ ì¸ê³µì§€ëŠ¥ ë°ì´í„° ì„¼í„°ì— ìœ ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ëª¨ë“ˆë ˆì´í„°ëŠ” ê¸ˆì„ ì‚¬ìš©í•˜ë©°, ë¬´ì„  í†µì‹  ê¸°ìˆ ì—ì„œ ì¤‘ìš”í•œ ì§„ì „ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "c66679f23c539bad",
    "title": {
      "en": "Emacs Solo: A Surprise System Crafters Live Demo",
      "ko": "ì— ì•…ìŠ¤ ì†”ë¡œ: ê¹œì§ ì‹œì—°!",
      "ja": null
    },
    "type": "story",
    "url": "https://www.rahuljuliato.com/posts/emacs-solo-demo",
    "score": 102,
    "by": "JNRowe",
    "time": 1743112983,
    "content": "Emacs Solo: A Surprise System Crafters Live DemoRahul M. JuliatoRahul M. JuliatoMarch\t27, 2025#emacs#systemcrafters# demoLast Friday, I was genuinely surprised by a live demo of my Emacs\nSolo configuration on the System Crafters Weekly Show. Watching\nthe live demo was an eye-opener, as I hadn't expected the project to\nget such attention, especially in a live setting. Seeing David\nWilson take a deep dive into the setup, testing the configuration\nlive, and exploring how powerful Emacs can be with only its built-in\npackages was both humbling and inspiring.\nFor more details and to explore the configuration yourself, visit the\nEmacs Solo GitHub\nrepository.\nThe Emacs Solo configuration is all about returning to the roots\nof Emacs. It's a minimalist setup designed to challenge myself and\ntest the full potential of Emacs using only its built-in\nfunctionality. The goal was to create an efficient, yet fully\nfunctional environment, all while keeping things as light and fast as\npossible. No external dependencies, no clutter. Just pure,\nunadulterated Emacs.\nThe Project: Emacs Solo\nEmacs Solo is a configuration that embraces the power of Emacs\nwithout relying on external packages. It's a setup I go back to from\ntime to time to remind myself of how much can be accomplished with\njust what Emacs offers out of the box.\nThis configuration is designed to be both powerful and lightweight,\nallowing for a fast, efficient workflow with a focus on simplicity and\nminimalism. The project includes several useful features for\nday-to-day tasks like searching, editing, and navigatingâ€”everything\nyou need for an efficient Emacs experience.\nSome of the highlights of the project include:\nÂ» A preview of icomplete-verical enhancements I proposed to the\nEmacs core team (custom prefixes, vertico style setup, and inline\ncompletion closer to corfu/company that works on text buffers and\neshell).\nÂ» An experimental custom git-gutter-like feature.\nÂ» Supercharged eshell customization.\nÂ» Custom solutions for editing multiple search entries.\nÂ» Built-in news readers like Gnus and Newsticker.\nÂ» Advanced file diffing and version control.\nÂ» Extended viper mode for those who prefer vim-style editing.\nÂ» Tree-sitter modes.\nÂ» LSP configurations.\nÂ» Custom rainbown-mode like.\nÂ» And many customizations of built-in packages.\nThe idea is that Emacs is already a powerful IDE, and with a bit of\nclever customization, it can be made into something even more\nstreamlined, adaptable, and effective without the need for external\npackages.\nWatch the Demo\nHere's the video of the live demo from the System Crafters Weekly\nShow:\n\nÂ» Also available here\nConclusion\nIâ€™d like to take this opportunity to thank David Wilson for the\namazing show and to the System Crafters community for their\ncontinued support and enthusiasm around Emacs. I also want to express\nmy gratitude to everyone who has contributed code that Iâ€™ve borrowed\nand learned from over the years. Particularly Gopar and\nProtesilaos. Without the shared knowledge and experience from\nthese fantastic people, the Emacs Solo project wouldn't have been\npossible.\nAs always, the beauty of Emacs lies in its community, and I'm grateful\nfor all the inspiration, contributions, and shared wisdom that make\nprojects like Emacs Solo come to life. Thank you to everyone who\ncontinues to inspire and teach me along the way.",
    "summary": {
      "en": "**Summary:**\n\nLast Friday, Rahul M. Juliato showcased his Emacs Solo configuration during a live demo on the System Crafters Weekly Show. He was pleasantly surprised by the attention the project received. The Emacs Solo setup focuses on simplicity and efficiency, using only Emacs' built-in features without any external packages. This minimalist approach aims to highlight Emacs' capabilities and create a fast, functional workspace.\n\nKey features of Emacs Solo include:\n- Various enhancements and customizations for improved functionality.\n- Advanced editing and navigation tools.\n- Built-in news readers and version control options.\n- Custom modes that cater to different editing styles.\n\nThe goal of the project is to demonstrate that Emacs can be a powerful IDE with clever configurations, all while remaining lightweight. Juliato expressed his gratitude to David Wilson and the System Crafters community for their support, as well as to contributors who helped him along the way.",
      "ko": "ì§€ë‚œ ê¸ˆìš”ì¼, Rahul M. JuliatoëŠ” System Crafters Weekly Showì—ì„œ Emacs Solo ì„¤ì •ì„ ë¼ì´ë¸Œë¡œ ì‹œì—°í–ˆìŠµë‹ˆë‹¤. ê·¸ëŠ” ì´ í”„ë¡œì íŠ¸ì— ëŒ€í•œ ê´€ì‹¬ì´ ì˜ˆìƒë³´ë‹¤ ë†’ì•„ ë†€ëìŠµë‹ˆë‹¤. Emacs Solo ì„¤ì •ì€ ë‹¨ìˆœì„±ê³¼ íš¨ìœ¨ì„±ì— ì¤‘ì ì„ ë‘ê³ , ì™¸ë¶€ íŒ¨í‚¤ì§€ ì—†ì´ Emacsì˜ ê¸°ë³¸ ê¸°ëŠ¥ë§Œì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ë¯¸ë‹ˆë©€í•œ ì ‘ê·¼ ë°©ì‹ì€ Emacsì˜ ëŠ¥ë ¥ì„ ê°•ì¡°í•˜ê³  ë¹ ë¥´ê³  ê¸°ëŠ¥ì ì¸ ì‘ì—… ê³µê°„ì„ ë§Œë“œëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.\n\nEmacs Soloì˜ ì£¼ìš” íŠ¹ì§•ìœ¼ë¡œëŠ” ë‹¤ì–‘í•œ ê¸°ëŠ¥ í–¥ìƒê³¼ ì‚¬ìš©ì ë§ì¶¤ ì„¤ì •ì´ ìˆìŠµë‹ˆë‹¤. ê³ ê¸‰ í¸ì§‘ ë° íƒìƒ‰ ë„êµ¬ê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë©°, ë‚´ì¥ëœ ë‰´ìŠ¤ ë¦¬ë”ì™€ ë²„ì „ ê´€ë¦¬ ì˜µì…˜ë„ ì œê³µí•©ë‹ˆë‹¤. ë˜í•œ, ë‹¤ì–‘í•œ í¸ì§‘ ìŠ¤íƒ€ì¼ì— ë§ì¶˜ ì‚¬ìš©ì ì •ì˜ ëª¨ë“œë„ ì§€ì›í•©ë‹ˆë‹¤.\n\nì´ í”„ë¡œì íŠ¸ì˜ ëª©í‘œëŠ” Emacsê°€ ë˜‘ë˜‘í•œ ì„¤ì •ì„ í†µí•´ ê°•ë ¥í•œ í†µí•© ê°œë°œ í™˜ê²½(IDE)ì´ ë  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì£¼ëŠ” ê²ƒì…ë‹ˆë‹¤. JuliatoëŠ” David Wilsonê³¼ System Crafters ì»¤ë®¤ë‹ˆí‹°, ê·¸ë¦¬ê³  ê·¸ë¥¼ ë„ì™€ì¤€ ê¸°ì—¬ìë“¤ì—ê²Œ ê°ì‚¬ì˜ ëœ»ì„ ì „í–ˆìŠµë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "80e0206c30be9f7f",
    "title": {
      "en": "Show HN: We are building the next DocuSign",
      "ko": "ë‹¤ìŒ ë„íì‚¬ì¸, ì‹œì‘í•©ë‹ˆë‹¤!",
      "ja": null
    },
    "type": "story",
    "url": "https://sgnly.com",
    "score": 64,
    "by": "esaidm",
    "time": 1743108702,
    "content": "Redefining Document SigningTurn PDFs toContract Templates in secondsSimple â€¢ Error-Free â€¢ Ready to Use5x faster document workflows â€” AI that auto-fills, explains, and builds reusable templates in seconds.Get Early AccessNo credit card required14-day free trialCancel anytime\n\nSave Time & MoneyWhy You Should Go With SgnlyTurn any document into a smart template, auto-filled with known data, explained by a voice agent, and personalized to every signer.Save On Processing TimeWith Sgnly, 80% of your document workflows are automated, so you can process more documents without expanding your team.An AI Assistant That Self-OptimizesSgnly isn't your average AI assistant. Not only does it automate tasks, it also learns from your feedback over time, just like a real human would.Get Up and Running Within A WeekLearning to use Sgnly takes minutes - and with our dedicated support team's help, you'll be onboarded and live within days!Replicate Your Top PerformersUsing our AI Playbooks, we can work with you to automate your top-performing document processes & writing workflows.All-In-One SubscriptionFrom email deliverability to B2B data, we've got it all. We've built best-in-class products for the entire document cycle, all in one place.Intent-Driven Document CreationHarness the power of behavioral, firmographic, and technographic data to create documents tailored to specific customer needs. Traditional Document ProcessManual Document ProcessingSlow, error-prone document handling with manual inputTime WastedHours spent completing complex formsManual DocumentationManual data entry for each documentNo AutomationRepetitive processes without reusable templates Sgnly Smart Solution Service Agreement Legal ContractSgnly Document Assistant - Service AgreementAI-poweredAgreement for {{company_name}}Date: {{current_date}}Dear {{customer_name}},This agreement confirms our services at the rate of {{hourly_rate}} per hour, with an estimated total of {{total_amount}}.Payment is due within {{payment_terms}} days of receipt.Sincerely,{{sender_name}}AI SuggestionAdd payment instructions to improve clarityVariables auto-filled from your data GenerateAI AssistantExplains complex terms and guides throughout the processSmart AutocompleteAutomatically fills in with saved informationAutomatic GenerationCreates customized documents in secondsTry Sgnly Now\n\nReady to transform your document workflow?Join thousands of businesses using SgnlySave time with AI-powered templatesSecure document managementEasy integration with existing systemsUnlimited electronic signaturesFull NameWork EmailCountry CodeUnited States (+1)United States (+1)United Kingdom (+44)Canada (+1)Australia (+61)Germany (+49)France (+33)Spain (+34)Italy (+39)Japan (+81)China (+86)India (+91)Brazil (+55)Mexico (+52)Russia (+7)South Korea (+82)Chile (+56)Phone NumberCompanyCurrent E-Signature SoftwareSelect your current e-signature solutionDocuSignAdobe SignHelloSignDropbox SignPandaDocSignNowSigneasyNo software currentlyOtherPrimary Use CaseRequest AccessBy submitting, you agree to our Terms of Service and Privacy Policy. Your information may be used to contact you about our products and services.",
    "summary": {
      "en": "**Summary of Sgnly Document Signing Solution**\n\nSgnly offers a fast and efficient way to handle document signing by turning PDFs into smart contract templates in seconds. Key features include:\n\n- **Speed and Efficiency**: Document workflows are five times faster, with 80% of processes automated.\n- **AI Assistance**: An AI assistant helps auto-fill documents, explains terms, and learns from user feedback.\n- **Easy Setup**: Users can get started quickly, often within a week, with dedicated support available.\n- **Customization**: Documents can be tailored to individual customer needs using various data types.\n- **All-in-One Solution**: Sgnly combines multiple document management functions into a single subscription service.\n- **Free Trial**: Users can try Sgnly for 14 days without needing a credit card and can cancel anytime.\n\nOverall, Sgnly aims to save businesses time and reduce errors in document processing.",
      "ko": "SgnlyëŠ” PDF íŒŒì¼ì„ ëª‡ ì´ˆ ë§Œì— ìŠ¤ë§ˆíŠ¸ ê³„ì•½ í…œí”Œë¦¿ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ë¬¸ì„œ ì„œëª…ì„ ë¹ ë¥´ê³  íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ëŠ” ë°©ë²•ì„ ì œê³µí•©ë‹ˆë‹¤. ì£¼ìš” íŠ¹ì§•ìœ¼ë¡œëŠ” ë¬¸ì„œ ì‘ì—… íë¦„ì´ ë‹¤ì„¯ ë°° ë¹¨ë¼ì§€ê³ , 80%ì˜ ê³¼ì •ì´ ìë™í™”ëœë‹¤ëŠ” ì ì´ ìˆìŠµë‹ˆë‹¤. \n\nAI ë³´ì¡° ê¸°ëŠ¥ì´ ìˆì–´ ë¬¸ì„œ ìë™ ì‘ì„±, ìš©ì–´ ì„¤ëª…, ì‚¬ìš©ì í”¼ë“œë°± í•™ìŠµì„ ì§€ì›í•©ë‹ˆë‹¤. ì‚¬ìš©ìëŠ” ì „ìš© ì§€ì›ì„ í†µí•´ ë¹ ë¥´ê²Œ ì‹œì‘í•  ìˆ˜ ìˆìœ¼ë©°, ë³´í†µ ì¼ì£¼ì¼ ì´ë‚´ì— ì„¤ì •ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. \n\në¬¸ì„œëŠ” ë‹¤ì–‘í•œ ë°ì´í„° ìœ í˜•ì„ í™œìš©í•˜ì—¬ ê°œë³„ ê³ ê°ì˜ ìš”êµ¬ì— ë§ê²Œ ë§ì¶¤ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. SgnlyëŠ” ì—¬ëŸ¬ ë¬¸ì„œ ê´€ë¦¬ ê¸°ëŠ¥ì„ í•˜ë‚˜ì˜ êµ¬ë… ì„œë¹„ìŠ¤ë¡œ í†µí•©í•˜ì—¬ ì œê³µí•©ë‹ˆë‹¤. \n\nì‚¬ìš©ìëŠ” ì‹ ìš©ì¹´ë“œ ì—†ì´ 14ì¼ ë™ì•ˆ Sgnlyë¥¼ ë¬´ë£Œë¡œ ì²´í—˜í•  ìˆ˜ ìˆìœ¼ë©°, ì–¸ì œë“ ì§€ ì·¨ì†Œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì „ë°˜ì ìœ¼ë¡œ SgnlyëŠ” ê¸°ì—…ì´ ë¬¸ì„œ ì²˜ë¦¬ì—ì„œ ì‹œê°„ì„ ì ˆì•½í•˜ê³  ì˜¤ë¥˜ë¥¼ ì¤„ì´ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•˜ê³  ìˆìŠµë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "0d813d8915548310",
    "title": {
      "en": "The Unbearable Loudness of Chewing",
      "ko": "ì”¹ëŠ” ì†ŒìŒì˜ ê³ í†µ",
      "ja": null
    },
    "type": "story",
    "url": "https://asteriskmag.com/issues/09/the-unbearable-loudness-of-chewing/",
    "score": 77,
    "by": "k2enemy",
    "time": 1742906464,
    "content": "The Unbearable Loudness of Chewing\n\n\t\t\t\t\tJake Eaton\n\nWhy do some people find certain sounds intolerable? And why has it taken so long for scientists to get even a preliminary answer?\n\n\t\t\t\t\t\t\t\t\t\t\tItâ€™s a teenage rite of passage to explode into rage at your parents. While the usual outburst is sparked by some combination of hormones, insecurity, and authority issues, for me it was a popping sound in my fatherâ€™s jaw. I first noticed it at the dinner table. Every time he took a bite, the disc of cartilage that cushioned his jawbone would slip out of place and snap back. Chew, click, chew, click. Like a drum, his mouth reverberated the sound, which changed in pitch each time he opened to take a bite. Layered beneath all of this was the wet percussion of normal chewing. The trio â€” jaw pop, meat squish, fork scraping teeth â€” became inescapable. And it drove into me, first through my chest, a surprising shock of affront and disgust that then suffused through my whole body. It was the first time I ever got scared that I wasnâ€™t in control of what was inside my own head.\n\n    Jul Quanouai\n\n\t\t\t\t\t\t\t\t\t\t\tI canâ€™t precisely date this memory, but I was somewhere around the age of 13 when I became unable to tolerate the sound of other peopleâ€™s mouths. In a world in which everyone eats, my day to day became an obstacle course. I learned to contract the tensor tympani muscle in my middle ear to dampen sounds. In moments of silence, I was sensitive enough that even the subtle parting of lips could trigger in me the urge to flee. There wasnâ€™t logic to what I felt. I knew that. It changed nothing. In my worst moments I started fights, especially with my family, among whom the condition, whatever it was, felt orders of magnitude more severe.I learned strategies to hide my aversion. Restaurants and the school cafeteria were loud enough to mask eating sounds. You couldnâ€™t eat in my car â€” it was, I said, just a cleanliness thing. I wore headphones everywhere. Still, I felt the consequences. I became more introverted. My family resigned to eating dinner with the TV on. My high school girlfriend called me out on what had become my habitual death stare when we ate near each other. I fell out with my best friend after I questioned his familyâ€™s table manners. I spent hours alone trying to integrate whatever was happening as part of me, hoping I had a wire crossed, afraid that I was experiencing â€” there was nothing online to help me â€” an incipient slide into mental illness.And then in 2011, my first year out of college, I happened upon a piece in the New York Times which described a poorly understood condition some scientists had begun to call misophonia.\n\n        1\n\n For its sufferers, certain sounds â€” often chewing â€” evoked what seemed an uncontrollable and disproportionate reaction of anger and disgust. It consistently appeared in adolescence. It had no cure. It was, or at least one neuroscientist hypothesized, a hard-wired condition, â€œa â€˜physiological abnormalityâ€™ that resides in brain structures activated by processed sound.â€Awash in the relief of diagnosis â€” not vindication so much as no longer feeling alone â€” the first thing I did was forward the article to my family. â€œSo please be sensitive toward my â€˜physiological abnormalityâ€™ when I come home,â€ I wrote, shielding my sincerity in irony.13 years later, I feel much lessimpacted by misophonia. My family knows what it is, even if they donâ€™t fully understand it. In this, they arenâ€™t much different than the general public. But itâ€™s only after spending a few months reading and speaking to researchers that Iâ€™ve come to realize that the science of misophonia â€” at least in what we can say with certainty â€” isnâ€™t well established either.It has taken, in fact, more than 20 years since the condition was first recognized to even arrive at a definition. And outside of that, some of the most basic questions remain up for debate. Where does misophonia originate, and why? Is it a medical disorder, a neurological disorder, a psychiatric disorder, or something else entirely? Most important of all â€” at least to the millions of people who likely suffer from it, many without fully understanding what it is â€” can it be cured?\n\t\t\t\t\t\t\t\t\t\t\tStarting conditions\n\n\t\t\t\t\t\t\t\t\t\t\tIn 1983, Pawel Jastreboff, a Polish engineer-turned-neuroscientist, began studying tinnitus. One of his main contributions from his early research was an animal model of the condition. It was a clever experiment that built on the work of his Ph.D. advisor, Jerzy Konorski, who developed the idea of operant conditioning after working in Ivan Pavlovâ€™s lab.Jastreboff raised rats to live with a constant, high-pitched ringing sound. They were then trained to expect a mild electric shock when the sound shut off. Next, he gave the rats salicylate (aspirin), which is known to cause ringing in the ears. And then he watched how the rats behaved when he shut off the tone. Rather than behave as if it was silent and a shock was coming, they acted normally. It appeared they were still hearing a ringing. While the model produces only temporary tinnitus, it allowed researchers to validate that animals could be trained to respond to internally perceived sounds, establishing one of the first behavioral methods to measure tinnitus in animals.Jastreboff also developed a proprietary treatment, â€œtinnitus retraining therapy,â€ which drew, as did the animal experiments, on his belief that the condition wasnâ€™t auditory in nature. It consisted of a combination of counseling and sound therapy that promised to â€œreclassify tinnitus into the category of neutral stimuli.â€ In other words: to counter-condition the signal. He soon took a faculty position at the University of Maryland that came with a clinic to further his study, where he also saw patients with another sound tolerance disorder called hyperacusis, a rare condition affecting about one in 50,000 people in which noises are perceived as unbearably loud. (The most common cause is damage to the cochlea, but it is more prevalent in those with tinnitus than it is in the general population.)To meet increased patient demand, Jastreboffâ€™s wife, Margaret, a molecular biologist and pharmacologist, joined him in the clinic. And it was Margaret who noticed something Pawel had not. Some patients were intolerant of sounds, but their symptoms fit the profile of neither tinnitus nor hyperacusis. Several hundred out of a thousand patients appeared to be afflicted by an intolerance to specific sounds, with specific origins.â€œI was very skeptical,â€ Pawel said, â€œbut she convinced me.â€ And so he came to understand that every patient was a little different. They were triggered by a variety of noises: the drone of an airplane 30,000 feet above, a refrigerator hum, or the clacking of a keyboard. One patient could not bear the sound of his parentsâ€™ voices. â€œEverybody around him had to speak in a whisper. When I met him outside of the clinic, he had to carry a sound generator set at such a high level that I was able to hear it from ten feet away.â€The way these patients reacted to noise was different from those suffering from hyperacusis or tinnitus. They had, as Jastreboff euphemistically put it in the first published piece to use the word misophonia, â€œa negative attitude to sound,â€ which seemed to activate their fight-or-flight response.\n\n        2\n\n The next year, the Jastreboffs published the first peer-reviewed article to include the term â€œmisophoniaâ€ in the Australian and New Zealand Journal of Audiology. It detailed, they claimed,\n\n        3\n\n how tinnitus retraining therapy could alleviate both tinnitus and misophonia.For ten years, it was met by silence.\n\t\t\t\t\t\t\t\t\t\t\tQuiet\n\n\t\t\t\t\t\t\t\t\t\t\tI wish Iâ€™d seen that paper when it first came out. I was 14 at the time, and I would wait another nine years to learn the term. Iâ€™m sure others feel the same â€” today, for example, the r/misophonia subreddit has 78,000 members. But between 2002 and 2013, misophonia appeared in journals just 15 times, mostly in case reports, none of which made meaningful advances in the science. (One, â€œFear of the Yawning Mother: A Case Study of Misophonia,â€ was retracted due to a legal dispute.)Why does it fail to gain any traction? I can think of a few reasons. The first is that the Jastreboffs are clinicians. Their published work relies on their private practice, emphasizing observation over experiment. Nor did the Jastreboffs ever sell the concept: Misophonia doesnâ€™t even appear in most of their article titles.\n\n        4\n\n And so itâ€™s not surprising that, pre-social media, burying a newly coined disorder in the text of an obscure Antipodean audiology journal (impact factor 0.4) is akin â€” as it were â€” to shouting into the void.But I think a second, larger reason is that misophonia is weird. Itâ€™s hard to explain and difficult to understand and doesnâ€™t make any intuitive sense. After all, everyone hates the sound of chewing.\n\n        5\n\n What appears to be a deep aversive reaction to sounds that most people donâ€™t like can seem â€” I speak from personal experience here â€” like youâ€™re hard to tolerate. Itâ€™s easier to be skeptical than empathetic. â€œEven now, when patients donâ€™t know about misophonia, their friends and family are often quick to dismiss their complaints as them simply being neurotic or over-dramatic,â€ said Zach Williams, a neuroscientist Ph.D. and M.D. candidate at Vanderbilt who has studied misophonia and decreased sound tolerance.It doesnâ€™t help that we donâ€™t have clear historical precedents of the condition, the way we see, for example, signs of what we now call PTSD in writing from the First World War. At least so I thought. Misophonia researchers are quick to cite possible cases. Winston Churchill held a lifelong aversion to whistling. Churchillâ€™s bodyguard, in his memoir, recounts Englandâ€™s PM admonishing a boy for trilling while walking down the street. The man posted signs in his war room bunkers that read â€œThere is to be no whistling or unnecessary noise in this passage.â€ Then there is Proust lining his room with cork and Kafkaâ€™s fixation on the din of his house in â€œGreat Noise.â€ What we accept as the anality of the great artist might start to appear as something else entirely.Scientists were also skeptical of Jastreboffâ€™s research when they did encounter it. Jastreboff spoke of being treated as if heâ€™d conjured a condition out of thin air. â€œYouâ€™re totally ignored, you do not exist,â€ he said, â€œor you are just talking garbage.â€ That began to change, ten years later, with an article in the New York Times â€” the same from my eureka moment â€” titled â€œWhen a Chomp or a Slurp Is a Trigger for Outrage.â€ The month the story came out, the Google Trends for misophonia erupted into existence. Itâ€™s only grown since. It tends to periodically spike for news stories or new studies. (Its second spike occurs in May 2012, when ABCâ€™s 20/20 aired a somewhat sensational segment about a daughter who couldnâ€™t even talk to her mom; it also featured Kelly Ripa, who self-diagnosed with misophonia after reading the Times article.)Finally, in 2013, misophonia found real traction among scientists. According to Jastreboff, there was a third challenge in the early research breaking through. â€œAudiologists donâ€™t write that much because it distracts them from other things â€” mainly making money with patients.â€ It was only a matter of time until psychologists (who, to be clear, also make money with patients) noticed the condition. â€œAnd psychologists,â€ he said, â€œlike to write a lot.â€\n\t\t\t\t\t\t\t\t\t\t\tNoise\n\n\t\t\t\t\t\t\t\t\t\t\tâ€œSome patients report a preoccupation with a specific aversive human sound that triggers impulsive aggression,â€ reads the abstract to a 2013 paper in PLOS ONE. â€œThis condition is relatively unknown and has hitherto never been described, although the phenomenon has anecdotally been named misophonia.â€\n\n        6\n\n Led by Arjan SchrÃ¶der, a psychiatrist at the University of Amsterdam, the article did more than describe the condition â€” its subtitle explicitly labeled it: â€œMisophonia: A New Psychiatric Disorder.â€In broad strokes, it gets the descriptive aspect right: The average age of onset (around 13); the specificity of triggers; the usual response of irritability, disgust, and anger are all now well-validated. But it begins, literally, with a case of selection bias: â€œThree patients were referred to our expertise centre in obsessive-compulsive disorders (OCD) at the Academic Medical Center in Amsterdam with obsessions focused on a typical sound such as smacking or breathing and the subsequent aggressive impulse to scream and yell or attack the source of the sound in order to make it stop.â€Of the 42 participants (all of whom self-selected into an OCD clinic), 22 met the diagnostic criteria for obsessive-compulsive personality disorder. To boot, the scale the authors created to measure the severity of misophonia symptoms, the A-MISO-S, was adapted from a scale used to measure the severity of OCD.While SchrÃ¶der et al. are careful to note that misophonia is distinct from any disorders recognized in the DSM, they also suggest it â€œshould be considered as an obsessive-compulsive spectrum disorderâ€ â€” a loosely grouped range of conditions that most often includes body dysmorphia, hypochondriasis, tic disorders like Tourette syndrome, and body-focused repetitive disorders such as trichotillomania, in which individuals pull out their own hair.Figuratively, eating sounds have made me want to pull out my hair. But the idea that misophonia belongs on the OCD spectrum ultimately proved premature. Seven years later, research from the same group found that the comorbidity between misophonia and OCPD traits was lower than that first research: only ~25%. A 2023 paper, designed to tease out the relationship between OCPD and misophonia, found that misophonia isnâ€™t correlated with having a diagnosis. Itâ€™s just that misophonia kind of looks like OCPD. I have not come across other research that validates the obsessive-compulsive spectrum placement.The SchrÃ¶der paper deserves credit for igniting more formal research into misophonia. But it is also emblematic of the way that first decade of misophonia science often appeared to grasp for scientific purchase at a range of disorders and diagnoses that could serve as a template. One paper, based on just three case studies, suggests that misophonia may be associated with the presentation of eating disorders. Another concluded that â€œmisophonia is better described as a symptom of a) obsessive-compulsive disorder, b) generalized anxiety disorder, and c) schizotypal personality disorder.â€ It, too, was based on just three case studies.â€œThe early definitions of misophonia are a bit like Rorschach inkblots,â€ said Zach Rosenthal, associate professor in psychiatry and behavioral sciences and the director of the Duke Center for Misophonia and Emotion Regulation.\n\n        7\n\n â€œWhat you see is based on your own expectations and biases.â€Ideally, science works as a cooperative, knowledge-sharing enterprise in well-coordinated pursuit of the truth. And it can â€” but sufficient funding is required to foster enough competition that errors and misdirections get corrected quickly enough. Through most of the 2010s, that is not the case for misophonia.This is a tricky recipe when it intersects with the media. For example, in 2017, Sukhbinder Kumar et al. published fMRI results that shone preliminary light on misophoniaâ€™s holy grail: the underlying mechanism. In misophonics, trigger sounds cause hyperactivity in the anterior insular cortex and other parts of the brain responsible for processing and regulating emotions. The authors are careful to conclude that itâ€™s impossible to tell whether this is a cause or consequence of misophonia, but the CBC went on to declare misophonia â€œthe result of a misfire in the brain.â€ The headline of the New York Times coverage: â€œMisophonia Sufferers: Scientists May Have Found the Root of Your Pain.â€\n\n        8\n\nPart of the problem is that, in the early years, it was hard to find an unbiased and large sample to say anything confident about comorbidities in misophonia. So many of the early papers were drawn from some form of psychiatric clinic or private practice that itâ€™s impossible to say much about misophonia in the general population. In 2017, a sample of 301 qualified as a â€œlarge-scaleâ€ study of misophonia. That study found that 50% of their sample appeared to have no comorbidities at all, while the other 50% were affected by a variety of conditions, only one of which â€” PTSD â€” helped to explain misophonia symptom severity.\n\n        9\n\nThere is also the challenge of measuring prevalence without validated scales. The earliest estimates are based on the perennially most convenient population: undergrads. A 2014 paper reported the incidence in the United States to be 20%. A 2017 paper among Chinese students pegged it at 6%. Neither of these studies uses the same scale, nor are those which they use validated. (Remember: We didnâ€™t even get a consensus definition of misophonia until 2022.)â€œThe science is flawed. Nobody wants to hear it, but it is,â€ Rosenthal told me over Zoom. Thereâ€™s few studies with representative or large samples; we know less about men and boys; almost no research has been done outside of WEIRD contexts. â€œEverything needs to be held carefully in terms of what it is and what we know it is from a scientific perspective.â€ Rosenthal was sitting in his basement, but his background was sunset on the Green River in Utah, where he had just been on a camping trip. Iâ€™d asked for an hour of his time; we ended up speaking for two, and I got the sense he was the sort of person to extend the same generosity to his patients â€” and to the nascent misophonia research community.Which in 2019 began to coalesce.\n\t\t\t\t\t\t\t\t\t\t\tSignal\n\n\t\t\t\t\t\t\t\t\t\t\tThe turning point is the injection of meaningful research funding. In 2019, the philanthropists Steve and Diane Miller created the Misophonia Research Fund. (The Millersâ€™ daughter was diagnosed with misophonia in 2016.) â€œThey have single-handedly injected $12 million dollars into misophonia research to date and are essentially the sole funder of misophonia research at this time,â€ said Williams.\n\n        10\n\nResearch output on misophonia has tripled since 2019. And with it has come some stepping stones. There are now several better validated scales: the Duke Misophonia Questionnaire, developed by Rosenthal and colleagues; and the S-Five, developed by Jane Gregory and colleagues. Gregory had gotten interested after seeing misophonia patients in her own clinical practice. A key aspect of the S-Five is that it can better track clinical improvements within individual patients, which older scales had not. â€œMy patients were saying, â€˜I feel a lot better, but thatâ€™s not reflected in the change in scores,â€™â€ Gregory said. â€œHalf the questionnaire was based on this section that essentially said, â€˜Compared to other people, I am sensitive to these sounds.â€™â€ For a misophonia patient, that is almost always true â€” and so it was important to capture change.â€\n\n        11\n\nIn July of 2024, Laura Dixon et al. published the largest survey to date (n = 4,005) which supports what has been intuitively obvious for some time: While a large proportion of people (78.5%) report sensitivity to trigger sounds, only a small proportion â€” 4.6% in this study â€” report clinical levels of misophonia.MRF now holds annual meetings, â€œthe beginnings of what will probably be our professional society one day,â€ said Williams. And it funds, for the first time, a project to arrive at a consensus definition of misophonia. It was an intensive Delphi process ( a structured approach to expert consensus) conducted over eight months: 15 experts, 68 references that included definitions of misophonia, and four rounds of voting to arrive at:Misophonia is a disorder of decreased tolerance to specific sounds or stimuli associated with such sounds. These stimuli, known as â€œtriggers,â€ are experienced as unpleasant or distressing and tend to evoke strong negative emotional, physiological, and behavioral responses that are not seen in most other people. Misophonic responses do not seem to be elicited by the loudness of auditory stimuli, but rather by the specific pattern or meaning to an individual.But outside of that definition, some of the most basic questions about misophonia remain. Specifically, is it psychological, neurological, audiological, or something else entirely?â€œThe Committee concluded that the scientific evidence regarding whether or not to classify misophonia as a â€˜medicalâ€™ or â€˜psychiatricâ€™ disorder is currently insufficient but that underlying organic etiology of the disorder cannot be ruled out.â€The researchers I spoke with were similarly cautious on this front. â€œThereâ€™s not even anything reasonably in the proximity of definitive,â€ said Rosenthal. Or as Williams put it: â€œIf someone tells you they know exactly what causes misophonia down to the molecular or brain pathway (which probably comes with their own patented cure that they conveniently own exclusive marketing rights to), I would consider those claims hyperbolic or not take them seriously at all.â€ Still, when I spoke with researchers, they were willing to hazard cautious, caveated answers to the question that Iâ€™ve most wanted answered since I was 13: Where is this coming from?Rosenthal favors a multilevel frame. There are biological vulnerabilities that we might think of as strong antennae, such as sensitivity to sensory input or sensitivity to emotions.\n\n        12\n\n Then there are environmental vulnerabilities: growing up in an environment of unpredictability, a chronic invalidation of oneâ€™s internal experiences, the need for hypervigilance in navigating oneâ€™s environment. Call this â€œwalking on eggshells.â€ The interplay between those two factors translates into a hypersensitivity that, over time, locks onto a particular trigger â€” possibly one which you first heard at a moment you worried the eggshells were about to break.Gregoryâ€™s view is similar. Her book, Sounds Like Misophonia, a popular take on the science and guide to coping strategies, lays out specific examples of how misophonics learn to associate sounds with stressors: children eating at the dinner table during a period of family conflict; a child bullied near the basketball courts who comes to associate dribbling with social threat; a salaryman frustrated with his career progress who notices how loudly his co-worker taps on her keyboard. (One of my favorite pieces, â€œDid Kant Suffer from Misophonia?,â€ speculates that misophonia arises when common sounds violate internalized social norms, specifically Western table manners that dictate demureness when eating, thereby disrupting oneâ€™s sense of an orderly world.\n\n        13\n\n Itâ€™s somewhat compelling.) Dixonâ€™s survey showed that over half of misophonics report eating sounds as their first trigger. If thereâ€™s truth in it, itâ€™s that the dinner table â€” the place where happy and unhappy families alike gather â€” is a common site for conflict, including over table manners.Williams notes, however, that â€œwhether misophonia traits and their specific manifestations (e.g., which triggers are most bothersome, how severe the reactions are, how one behaviorally responds, etc.) are learned over time remains an open question.â€ Itâ€™s likely that the avoidance of trigger sounds may be a secondary reaction of classical conditioning but that some of the automatic responses may not be learned in the typical way. â€œThis is all still to be understood, though.â€Some sort of neurological root â€” as the consensus definition notes â€” remains on the table. In 2021, Kumarâ€™s lab published fMRI results that point to a motor basis for misophonia. Specifically, the brains of people with misophonia show heightened activation in areas that control facial movements when hearing triggers. The idea that misophonia is a misfiring of mirror neurons then got picked up in a range of outlets, but more recent results have contradicted those findings. Patient advocates seem to appreciate the concreteness of brain imaging studies: Here, see, misophonia is real; itâ€™s in the brain. But fMRI is expensive, and both of these studies were small.Jastreboff remains adamant that the idea that misophonia is a â€œpsychiatric disorderâ€ is wrong. Much of the evidence pointing in that direction, he believes, is a result of selection bias in recruiting. Theoretically, â€œit is possible to turn everybody into a misophonia patient towards a specific sound.â€ His view remains that misophonia is a disorder of conditioned reflexes where the brain has formed strong functional connections between the auditory system and other brain systems (particularly the limbic and autonomic nervous systems).\n\t\t\t\t\t\t\t\t\t\t\tHarmony\n\n\t\t\t\t\t\t\t\t\t\t\tIn many ways, misophonia resembles what Scott Alexander has called a â€œtrapped prior.â€ A belief is â€œtrappedâ€ when it has become so strong it causes you to interpret all new evidence â€” even contradictory evidence â€” in support of the belief. A phobia is a basic form of trapped prior. Youâ€™re asked to speak in front of the class and you mess up. You get made fun of. Your brain then associates public speaking with social danger, creating a self-reinforcing cycle of anxiety that impairs your speaking performance, which then confirms your belief that speaking is dangerous.More recent research on psychedelics and depression has provided some evidence for the trapped-priors framework. The theory goes: In depression, high-level priors like \"the world is fundamentally threatening\" or \"I am worthless\" become extremely rigid and self-reinforcing. Psychedelics appear to temporarily \"relax\" these high-level priors by reducing their influence over lower-level sensory processing.Under the predictive processing/trapped-prior framework, misophonia begins to look a little less strange: Your brain forms, for whatever reason, a negative association with specific sounds. Each new exposure to the trigger sound gets interpreted through the lens of that prior â€” the brain expects the sound to be unbearable, which causes a strong emotional and physiological reaction, which then reinforces the prior that the sound is unbearable. This self-reinforcing loop is difficult to break.The evidence for how it might be broken in misophonia, specifically, is thin. A 2023 systematic review of treatments found just one randomized controlled trial, one open label trial, and 31 case studies.\n\n        14\n\n That RCT, which used cognitive behavioral therapy techniques, found modest effects: 37% in the treatment group had clinical improvements compared with 0% in the control. The open-label trial, also CBT-based (and led by SchrÃ¶der), worked for half. And some case studies suggest CBT can improve symptoms. Still, itâ€™s early days.The fact that CBT-based techniques sometimes help with misophonia fits the trapped-prior model. By introducing trigger sounds in controlled, low-stress environments, it may allow the sensory \"bandwidth\" to stay open enough to update the prior â€” rather than having it override the experience. Some of Gregoryâ€™s techniques break the association altogether by, for example, imagining a different origin to the sound. She gave the example (from a workshop, not a patient) of a man bothered by the sound of kids bouncing on a trampoline next door. He appeared to find relief by listening to trampoline sounds while imagining not kids but his cat jumping up and down in joy.I tend to be self-deprecating about my own experience with misophonia. That is a coping strategy. Itâ€™s my way of saying: Heads-up, please forgive me, I know this is weird. I imagine a lot of misophonics feel the same. Pardon us for being crazy. We apologize for taking up space. But that experience is not everyoneâ€™s. The severity of my misophonia experience has diminished over time. (On Gregoryâ€™s S-Five, I score 48 out of 250, below the score of 87 that she uses as a cutoff for â€œsignificantâ€ misophonia.) On a day-to-day basis I feel mostly unimpaired.Others suffer. Some deeply. The r/misophonia subreddit can be sad and desperate. â€œMy trigger is the worst thing in my life,â€ â€œI've honestly felt the urge to punch my own wife,â€ â€œI fucking hate it with every fiber of my being,â€ â€œI have no friends, and it's often hard to even go outside.â€ A number of suicides have been traced to misophonia. At least on Reddit, some people report going to extreme lengths â€” including intentional deafness â€” to eliminate triggers.People need help. But this need runs up against practical barriers. There are few places to seek treatment. Misophonia remains poorly recognized. No one technique is yet proven. Official classification as a disorder could help funnel resources and attention, but there is some debate within the advocacy community about the utility of pursuing that. Those who are comfortable labeling misophonia a psychiatric disorder have no issue on this front. But â€œother people get really mad when thatâ€™s even on the table to consider,â€ Rosenthal said.The two main options are either Diagnostic and Statistical Manual of Mental Disorders or the International Classification of Diseases. Rosenthal thinks the ICD is the more appropriate place, particularly because itâ€™s not yet clear whether misophonia is best classified as a mental disorder.â€œItâ€™s undeniably a good thing to have misophonia in at least one manual,â€ Williams said. â€œ[N]o code means no billing, and no billing means no reimbursement for services (not to mention less legitimacy in medico-legal contexts, advocacy, etc.).â€\n\t\t\t\t\t\t\t\t\t\t\tModulation\n\n\t\t\t\t\t\t\t\t\t\t\tI had hoped to try some of the CBT-inspired approaches for this piece. Then I got busy. More honestly, I had a hard time overcoming the inertia to even start. I found myself caught in a familiar pattern: avoiding treatment for a condition that makes me avoid things.Instead, I had an unexpected opportunity: a week-long silent meditation retreat. Assuming misophonia is indeed like a trapped prior, a retreat could offer the space for processing sensory experience in a new light. Meditation, at its heart, is a way to drop all preconceptions and to see things as they are.Which is how I found myself five days into the deepest equanimity Iâ€™ve ever felt curiously observing my own reactivity manifest. The meditation hall was quiet but not silent, punctuated by the subtle sounds of thirty people settling into their seats. Every time the person next to me swallowed, I felt first a brief ripple of anger at the sound itself, followed by a larger wave of frustration at my reaction to it. Here I was exerting intensive focus on something I wasnâ€™t supposed to be focusing on. I was shocked at the extent to which I felt â€” imagined I could even see â€” the sounds of other people swallowing around me as tiny darts into and through my chest.And yet, with time, as I settled, I became better able to notice the space between sensation and reaction. For the first time, I could choose to ignore the signal. To separate it as part of myself. Something happening in my awareness, but not necessarily to me. I could allow it to be, for once, just noise.There were times researching this piece when I found myself frustrated with the slow pace and sporadic nature of misophonia science. I was angry for my younger self at researchers jumping to conclusions, annoyed at the way misophonia seemed carelessly lumped in with whatever condition the author seemed to know best â€” back to trapped priors again.But this now seems unfair. For more than a decade, the field operated with tiny budgets and poor visibility. And I am hopeful that misophonia research is poised to experience something of an acceleration in the coming years. Brain science continues to advance every day. Early research from the Duke Center for Misophonia has shown that targeted brain stimulation combined with CBT techniques can help accelerate treatment. Psychedelics, theoretically, are another area to consider.These might all pan out to help in small to large ways. But the fruition of this research will take years, if not decades. Even then, it is unlikely we ever see a genuine â€œcure.â€ This remains a point of debate among some within the misophonia community. â€œThereâ€™s a lot of quackery and snake oil out there,â€ Williams said. â€œThis is a context ripe for desperation. And people need to be protected from that.â€I donâ€™t think there is a cure. Our history treating other complex psychological conditions â€” from depression and anxiety to OCD and ADHD â€” suggests that while we may yet find more effective treatments, there is no silver bullet. Anyone who says differently may be selling you something. Living with misophonia may require something harder, the answer that was always obvious but many of us prefer not to confront: work.\n\n    Sign up for our newsletter to get Asteriskâ€™s latest interviews, essays, and more.\n\n        Subscribe\n\n    Marsha Johnson, an audiologist in private practice in Oregon who trained with Jastreboff, noticed what we now call misophonia around the same time. In the late â€™90s, she termed it â€œselective sound sensitivity syndrome.â€\n\n                â†©\n\n    The Jastreboffs consulted a classics professor on the name, which literally translates to â€œhatred of sound.â€ Lots of people donâ€™t like this name because neither â€œhatredâ€ nor â€œsoundâ€ accurately characterize the condition.\n\n                â†©\n\n    The Jastreboffs have never submitted their treatment to any form of controlled trial, so Iâ€™m being deliberate, not cynical, here.\n\n                â†©\n\n    It is, plainly, â€œDecreased Sound Tolerance and Tinnitus Retraining Therapy (TRT).â€\n\n                â†©\n\n    To be clear, misophonics are quite a bit more sensitive on this front. Most people dislike the sound of chewing, but at least one study has shown that many misophonics are triggered by sounds such as breathing and swallowing that donâ€™t bother the general population.\n\n                â†©\n\n    The paper actually cites Jastreboff here as the â€œanecdotalâ€ evidence.\n\n                â†©\n\n    Probably the largest center dedicated to the study of misophonia in the world. (Itâ€™s six people full time, plus grad students.)\n\n                â†©\n\n    One point of caution with respect to Kumar et al. â€” and this is argued by SchrÃ¶der in a commentary â€” is that they recruited patients on the basis of an unvalidated questionnaire. Having looked at the questions, which are quite open-ended, I tend to think this is fine.\n\n                â†©\n\n    Tantalizingly, they also find that 50% of their sample reporting experiencing an â€œunfamiliar phenomenon called autonomous sensory meridian response (ASMR).â€ Iâ€™ve spoken with a few friends with misophonia, and they all report also enjoying ASMR. Weirdly, Iâ€™ve seen almost no follow up on this.\n\n                â†©\n\n    The Duke Misophonia Center is funded by an anonymous donor, and there are scattered smaller grants.\n\n                â†©\n\n    Itâ€™s still, however, a work in progress. As Gregory noted to me, a flaw in the S-Five is that it doesnâ€™t differentiate between hyperacusis and misophonia. â€œWe didn't have that in mind when we were designing it. We were working from the clinical experience we had. So thatâ€™s the next step of the research.â€\n\n                â†©\n\n    Whether these are truly biological is an even harder question to answer.\n\n                â†©\n\n    Kant was apparently sensitive to a variety of sounds, including boats, prison singing, and, most notably, the crowing of a rooster â€” one which irritated him so much he tried to buy and kill it.\n\n                â†©\n\n    A few more RCTs are on the way. One seeks to compare acceptance and commitment therapy to progressive relaxation training. Another is testing the effectiveness of CBT combined with psychomotor therapy in children and adolescents.\n\n                â†©\n\nJake Eaton is the managing editor of Asterisk Magazine. He writes at anzalogue.xyz.\n\nPublished January 2025\n\n\t\tShare with email\n\n\t\tShare on Twitter\n\n\t\tShare on Facebook\n\n\t\tShare on LinkedIn\n\n\t\t\tHave something to say? Email us at letters@asteriskmag.com.\n\nPrevious\n\t\t\t\t\tA Defense of Weird Research\n\nFurther Reading\n\n\t\t\t\tMore:\n\t\t\t\t\t\t\t\t\thealth\n\t\t\t\t\t\t\t\t\tscience\n\n\t\t\t\t\t\tA Defense of Weird Research\n\n\t\t\t\t\t\t\t\t\tDeena Mousa\n\n\t\t\t\t\t\t\t\t\tLauren Gilbert\n\n\t\t\t\t\t\tAutomating Math\n\n\t\t\t\t\t\t\t\t\tAdam Marblestone\n\n\t\t\t\t\t\tGreening the Solar System\n\n\t\t\t\t\t\t\t\t\tEdwin Kite\n\n\t\t\t\t\t\t\t\t\tRobin Wordsworth\n\n\t\t\t\t\t\tThe Case for Insect Consciousness\n\n\t\t\t\t\t\t\t\t\tBob Fischer\n\n\t\t\t\t\t\tYes, Shrimp Matter\n\n\t\t\t\t\t\t\t\t\tAndrÃ©s JimÃ©nez Zorrilla\n\nManage Consent PreferencesStrictly Necessary CookiesAlways ActiveThese cookies are necessary for the website to function and cannot be switched off in our systems. They are usually only set in response to actions made by you which amount to a request for services, such as setting your privacy preferences, logging in or filling in forms. You can set your browser to block or alert you about these cookies, but some parts of the site will not then work. These cookies do not store any personally identifiable information.Performance Cookies  Performance Cookies These cookies allow us to count visits and traffic sources so we can measure and improve the performance of our site. They help us to know which pages are the most and least popular and see how visitors move around the site. All information these cookies collect is aggregated and therefore anonymous. If you do not allow these cookies we will not know when you have visited our site, and will not be able to monitor its performance.Functional Cookies  Functional Cookies These cookies enable the website to provide enhanced functionality and personalisation. They may be set by us or by third party providers whose services we have added to our pages. If you do not allow these cookies then some or all of these services may not function properly.Targeting Cookies  Targeting Cookies These cookies may be set through our site by our advertising partners. They may be used by those companies to build a profile of your interests and show you relevant adverts on other sites. They do not store directly personal information, but are based on uniquely identifying your browser and internet device. If you do not allow these cookies, you will experience less targeted advertising.\n\nBack ButtonPerformance Cookies  Search IconFilter IconClear checkbox label labelApply CancelConsent Leg.Interest checkbox label label checkbox label label checkbox label label\n\nClear checkbox label labelApply Cancel\n\nConsent Leg.Interest checkbox label label checkbox label label checkbox label label",
    "summary": {
      "en": "### Summary of \"The Unbearable Loudness of Chewing\" by Jake Eaton\n\nMany people experience intense discomfort from certain sounds, particularly chewing, a condition known as misophonia. The author shares his personal struggle with this condition, which began in adolescence when he became unable to tolerate the sounds of his father's chewing. Misophonia can lead to feelings of anger and disgust, disrupting daily life and relationships.\n\nDespite its recognition for over 20 years, scientific understanding of misophonia remains limited. Researchers have debated its originsâ€”whether it's a neurological, psychiatric, or sensory disorder. The term was first used in a 2001 study, but it gained more attention in recent years, particularly after a 2013 article identified it as a new psychiatric disorder.\n\nResearch on misophonia has increased since 2019 due to new funding, leading to better-defined questionnaires and increased awareness. A 2024 study found that while many people report sensitivity to triggering sounds, only a small percentage meet the criteria for clinical misophonia.\n\nThere is still no consensus on whether misophonia can be classified as a medical disorder. Current treatments, like cognitive-behavioral therapy (CBT), show promise but are not definitive. The author reflects on his own experience with misophonia and acknowledges the need for further research and understanding, emphasizing that living with this condition may require ongoing work and coping strategies rather than a simple cure.",
      "ko": "ë§ì€ ì‚¬ëŒë“¤ì´ íŠ¹ì • ì†Œë¦¬, íŠ¹íˆ ì”¹ëŠ” ì†Œë¦¬ë¡œ ì¸í•´ ì‹¬í•œ ë¶ˆí¸í•¨ì„ ëŠë¼ëŠ” ê²½ìš°ê°€ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ ë¯¸ì†Œí¬ë‹ˆì•„ë¼ê³  ë¶€ë¥´ë©°, ì €ìëŠ” ì´ ì¦ìƒìœ¼ë¡œ ì¸í•œ ê°œì¸ì ì¸ ê³ í†µì„ ì´ì•¼ê¸°í•©ë‹ˆë‹¤. ê·¸ëŠ” ì²­ì†Œë…„ ì‹œì ˆ ì•„ë²„ì§€ì˜ ì”¹ëŠ” ì†Œë¦¬ë¥¼ ê²¬ë”œ ìˆ˜ ì—†ê²Œ ë˜ë©´ì„œ ì´ ë¬¸ì œê°€ ì‹œì‘ë˜ì—ˆë‹¤ê³  í•©ë‹ˆë‹¤. ë¯¸ì†Œí¬ë‹ˆì•„ëŠ” ë¶„ë…¸ì™€ í˜ì˜¤ê°ì„ ìœ ë°œí•  ìˆ˜ ìˆìœ¼ë©°, ì¼ìƒ ìƒí™œê³¼ ì¸ê°„ê´€ê³„ì— ì§€ì¥ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\në¯¸ì†Œí¬ë‹ˆì•„ëŠ” 20ë…„ ì´ìƒ ì•Œë ¤ì ¸ ì™”ì§€ë§Œ, ê³¼í•™ì ìœ¼ë¡œëŠ” ì—¬ì „íˆ ì´í•´ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ì—°êµ¬ìë“¤ì€ ì´ ì¦ìƒì˜ ì›ì¸ì´ ì‹ ê²½í•™ì , ì •ì‹ ì , ë˜ëŠ” ê°ê°ì  ì¥ì• ì¸ì§€ì— ëŒ€í•´ ë…¼ì˜í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ ìš©ì–´ëŠ” 2001ë…„ ì—°êµ¬ì—ì„œ ì²˜ìŒ ì‚¬ìš©ë˜ì—ˆì§€ë§Œ, 2013ë…„ì˜ í•œ ê¸°ì‚¬ì—ì„œ ìƒˆë¡œìš´ ì •ì‹  ì¥ì• ë¡œ ì§€ëª©ë˜ë©´ì„œ ìµœê·¼ ëª‡ ë…„ ë™ì•ˆ ë” ë§ì€ ì£¼ëª©ì„ ë°›ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.\n\n2019ë…„ ì´í›„ ë¯¸ì†Œí¬ë‹ˆì•„ì— ëŒ€í•œ ì—°êµ¬ê°€ ì¦ê°€í•˜ì˜€ê³ , ìƒˆë¡œìš´ ìê¸ˆ ì§€ì› ë•ë¶„ì— ë” ëª…í™•í•œ ì„¤ë¬¸ì§€ê°€ ê°œë°œë˜ê³  ì¸ì‹ì´ ë†’ì•„ì¡ŒìŠµë‹ˆë‹¤. 2024ë…„ ì—°êµ¬ì— ë”°ë¥´ë©´ ë§ì€ ì‚¬ëŒë“¤ì´ ìœ ë°œ ì†Œë¦¬ì— ë¯¼ê°í•˜ë‹¤ê³  ë³´ê³ í•˜ì§€ë§Œ, ì„ìƒ ë¯¸ì†Œí¬ë‹ˆì•„ ê¸°ì¤€ì„ ì¶©ì¡±í•˜ëŠ” ì‚¬ëŒì€ ì†Œìˆ˜ì— ë¶ˆê³¼í•˜ë‹¤ê³  í•©ë‹ˆë‹¤.\n\në¯¸ì†Œí¬ë‹ˆì•„ë¥¼ ì˜í•™ì  ì¥ì• ë¡œ ë¶„ë¥˜í•  ìˆ˜ ìˆëŠ”ì§€ì— ëŒ€í•œ í•©ì˜ëŠ” ì•„ì§ ì´ë£¨ì–´ì§€ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í˜„ì¬ì˜ ì¹˜ë£Œë²•ì¸ ì¸ì§€ í–‰ë™ ì¹˜ë£Œ(CBT)ëŠ” í¬ë§ì ì¸ ê²°ê³¼ë¥¼ ë³´ì´ì§€ë§Œ, í™•ì‹¤í•œ í•´ê²°ì±…ì€ ì•„ë‹™ë‹ˆë‹¤. ì €ìëŠ” ìì‹ ì˜ ë¯¸ì†Œí¬ë‹ˆì•„ ê²½í—˜ì„ ë°˜ì˜í•˜ë©°, ì¶”ê°€ ì—°êµ¬ì™€ ì´í•´ì˜ í•„ìš”ì„±ì„ ê°•ì¡°í•©ë‹ˆë‹¤. ì´ ì¦ìƒê³¼ í•¨ê»˜ ì‚´ì•„ê°€ëŠ” ê²ƒì€ ë‹¨ìˆœí•œ ì¹˜ë£Œë³´ë‹¤ëŠ” ì§€ì†ì ì¸ ë…¸ë ¥ê³¼ ëŒ€ì²˜ ì „ëµì´ í•„ìš”í•  ìˆ˜ ìˆìŒì„ ì¸ì •í•©ë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "c3cc09f7c3386ef2",
    "title": {
      "en": "Clean, a formal verification DSL for ZK circuits in Lean4",
      "ko": "í´ë¦°: Lean4ì˜ ZK íšŒë¡œ ê²€ì¦ DSL",
      "ja": null
    },
    "type": "story",
    "url": "https://blog.zksecurity.xyz/posts/clean/",
    "score": 71,
    "by": "vons",
    "time": 1743100380,
    "content": "Introducing clean, a formal verification DSL for zk circuits in Lean4\n\n            Written by\n\n                    Giorgio Dell'Immagine\n\n            on\n            Mar 27, 2025\n\n    We are really excited to share our initial steps towards building clean, an embedded DSL and formal verification framework for ZK circuits in Lean4.\nAs we recently shared, Zero Knowledge circuits are full of bugs, but fortunately, techniques like formal verification can provide a huge confidence boost in the correctness of ZK circuits.\nClean enables us to define circuits in Lean4, specify their desired properties, and â€“ most importantly â€“ formally prove them!\nThis work is part of the zkEVM Formal Verification Project which aims to provide infrastructure and tooling to enable formal verification for zkEVMs.\nRead about clean below, or watch our presentation on it in the zkEVM project updates call.\n\nObjectives\nOur objective is to build an embedded DSL for writing zk circuits in Lean4, that allows us to reason about them in a formal way.\nWe believe that co-locating circuit definitions with their desired specification and correctness proof will allow us to create a robust library of reusable formally verified circuit gadgets.\nWe currently target AIR arithmetization, and we assume to have a table lookup primitive available by the underlying proof system.\nHow to formally verify ZK circuits\nIn order to reason formally about ZK circuits, we first need to define a formal model. This involves the following steps:\n\nDefining what primitives our circuit language supports, i.e., which are the operations that we can use to define circuits.\nDefining the semantics of such primitives.\nDefining what are the properties we are interested to formally prove for a given circuit.\n\nOur language allows us to specify a circuit, which is composed of two main objects.\n\nA collection of variables, and\nconstraints and lookup relations over those variables.\nThe goal of a zero-knowledge proof system is exactly to convince a verifier that the prover knows a witness (i.e., an assignment of the variables) that satisfies the constraints and lookups of a given circuit.\n\nAt a fundamental level, for a given circuit we are interested in how the satisfaction of the constraints and the witness are related.\nIn other words: if a witness satisfies the constraints, what property can we infer about it?\nLetâ€™s make a concrete example.\nConsider a circuit defined over one variable x and that is composed of only one contraint:\nC1 : x * (x - 1) === 0\nThis is a very common gadget that ensures that x is a boolean value, i.e., it is either 0 or 1.\nThe specification of this ciruit can be expressed as:\nx = 0 âˆ¨ x = 1\nAlbeit being a very simple example, it shows the basic idea: we are interested in formally proving that if an assignment to the variables satisfies the constraints, then the specification holds as well.\nWe are also interested in the other direction: if an honest prover holds a witness that satisfies the specification, then there exists an assignment of the variables that satisfies the constraints.\nTake the following alternative implementation of a boolean check\nC2 : x === 0\nThis new constraint is sound, because the only valid assignment that satifies it is x = 0, which is a boolean value.\nHowever, it is not complete, as an honest prover that holds a valid boolean x = 1 cannot provide a witness that satisfies the constraint.\nMore formally, the two properties we want to prove are:\n\nSoundness: if the prover can exhibit any witness that satisfies the constraints and lookup relations defined by the circuit, then some specification property holds over that witness. Proving this property ensures that the circuit is not underconstrained.\nCompleteness: for every possible input, an honest prover can always exhibit a witness that satisfies the constraints and lookup relations defined by the circuit. Proving this property ensures that the circuit is not overconstrained.\n\nDSL design\nIn our DSL, we support four basic operations for defining circuits.\ninductive Operation (F : Type) [Field F] where\n  | witness : (m: â„•) -> (compute : Environment F -> Vector F m) -> Operation F\n  | assert : Expression F -> Operation F\n  | lookup : Lookup F -> Operation F\n  | subcircuit : {n : â„•} -> SubCircuit F n -> Operation F\nIndeed, we can:\n\nWitness: introduce m new variables in the circuit, and add them to the witness.\nThis operation accepts also a compute function, which represents the witness generation function, in the honest prover case.\nAssert: add a new constraint to the circuit.\nLookup: add a new lookup relation to the circuit. A lookup defines which variables are being looked up and in which other table.\nSubcircuit: add a new subcircuit to the circuit.\nThe subcircuit is instantiated in the current environment, and the internal variables of the subcircuit are added to the witness.\nThis is the main way to gain composability of gadgets.\n\nTo enhance usability, we provide a way to define a circuit using a monadic interface, with a lot of convenience functions.\nThis interface allows us to define the circuits using very natural syntax constructs.\nDesign of the composable verification framework\nThe main building block of our framework is the FormalCircuit structure.\nstructure FormalCircuit (F: Type) (Î² Î±: TypeMap)\n  [Field F] [ProvableType Î±] [ProvableType Î²]\nwhere\n  main: Var Î² F -> Circuit F (Var Î± F)\n  assumptions: Î² F -> Prop\n  spec: Î² F -> Î± F -> Prop\n\n  soundness:\n    âˆ€ offset : â„•, âˆ€ env,\n    -- for all inputs that satisfy the assumptions\n    âˆ€ b_var : Var Î² F, âˆ€ b : Î² F, eval env b_var = b ->\n    assumptions b ->\n    -- if the constraints hold\n    constraints_hold.soundness env (circuit.main b_var |>.operations offset) ->\n    -- the spec holds on the input and output\n    let a := eval env (circuit.output b_var offset)\n    spec b a\n\n  completeness:\n    -- for all environments which _use the default witness generators for local variables_\n    âˆ€ offset : â„•, âˆ€ env, âˆ€ b_var : Var Î² F,\n    env.uses_local_witnesses (circuit.main b_var |>.operations offset) ->\n    -- for all inputs that satisfy the assumptions\n    âˆ€ b : Î² F, eval env b_var = b ->\n    assumptions b ->\n    -- the constraints hold\n    constraints_hold.completeness env (circuit.main b_var |>.operations offset)\nThis structure tightly packages in a dependent-type way, the following objects:\n\nÎ² and Î± are respectively the input and output â€œshapesâ€, essentially they define a structured collection of elements.\nmain: the circuit definition itself.\nassumptions: the assumptions that the circuit makes on the inputs. All properties are proved assuming that the input variables satisfy these assumptions.\nspec: the specification property of the circuit.\nsoundness: proof for soundness of the circuit.\ncompleteness: proof for completeness of the circuit.\n\nA FormalCircuit encapsulates a formally proved, reusable gadget: when instantiating a FormalCircuit as a subcircuit, we are able to reuse the soundness and completeness proofs of the subcircuit to prove the soundness and completeness properties of the whole circuit.\nThis is accomplished by automatically replacing the constraints of a subcircuit with its (formally verified) spec.\nIn this way we can formally verify even large circuits by applying a divide-et-impera approach: we start by defining and proving correctness of low-level reusable gadgets, and then combine them to build more and more complex circuits.\nA concrete example: 8-bit addition\nLetâ€™s walk through one of the simple gadgets we have implemented and verified: addition on 8-bit numbers.\nThis is a gadget that takes as input two bytes and an input carry, and returns the sum of the two bytes modulo 256, and the output carry.\nFirst, we need to define the input and output shapes.\nstructure Inputs (F : Type) where\n  x: F\n  y: F\n  carry_in: F\n\nstructure Outputs (F : Type) where\n  z: F\n  carry_out: F\nNow, we define the assumptions the circuit makes on the input values, and the specification that the circuit should satisfy.\ndef assumptions (input : Inputs (F p)) :=\n  let { x, y, carry_in } := input\n  x.val < 256 âˆ§ y.val < 256 âˆ§ (carry_in = 0 âˆ¨ carry_in = 1)\n\ndef spec (input : Inputs (F p)) (out : Outputs (F p)) :=\n  let { x, y, carry_in } := input\n  out.z.val = (x.val + y.val + carry_in.val) % 256 âˆ§\n  out.carry_out.val = (x.val + y.val + carry_in.val) / 256\nThe main circuit is defined as follows.\ndef add8_full_carry (input : Var Inputs (F p)) :\n    Circuit (F p) (Var Outputs (F p)) := do\n  let { x, y, carry_in } := input\n\n  -- witness the result\n  let z <- witness (fun eval => mod_256 (eval (x + y + carry_in)))\n\n  -- do a lookup over the byte table for z\n  lookup (ByteLookup z)\n\n  -- witness the output carry\n  let carry_out <- witness (fun eval => floordiv (eval (x + y + carry_in)) 256)\n\n  -- ensures that the output carry is boolean\n  -- by instantiating the Boolean.circuit as a subcircuit\n  assertion Boolean.circuit carry_out\n\n  -- main 8-bit addition constraint\n  assert_zero (x + y + carry_in - z - carry_out * (const 256))\n\n  return { z, carry_out }\nFinally, we define the FormalCircuit structure, which packages all those definitions, together with the soundness and completeness proofs\ndef circuit : FormalCircuit (F p) Inputs Outputs where\n  main := add8_full_carry\n  assumptions := assumptions\n  spec := spec\n  soundness := by\n    ...\n  completeness := by\n    ...\nNotice that this definition is generic over the field prime p, however we require an additional assumption on the prime, namely p>512, otherwise the circuit is not sound!\nvariable {p : â„•} [Fact p.Prime]\nvariable [p_large_enough: Fact (p > 512)]\nVerifying concrete AIR tables\nThe FormalCircuit abstraction provides a modular definition of verified circuits, and it is mostly arithmetization-agnostic.\nHowever, we want to target AIR as a concrete arithmetization, as it is a very popular choice in the zkVM design space.\nAIR circuits are defined over traces: constraints are specificed together with an application domain, which represent which rows they should be applied to.\nIn principle, one could choose an arbitrary domain, however, in practice we choose domains that have a succinct representation in terms of vanishing polynomial.\nHere are some examples of domains that have succinct representations and are used in practice.\n\nThe constraint is applied to one specific row of the trace. This is often referred to as a boundary constraint.\nThe constraint is applied to all rows of the trace. This is often referred to as a recurring constraint. One feature is that constraints applied to every row can access neighbouring rows: for example they could access the next row or the previous row.\nThe constraint is applied to all rows, except a chosen small set of rows. For example, it could be applied to every row except the last one, or except the first one.\nThe constraint is applied to every n rows of the trace.\n\nAs a concrete example, letâ€™s say that we want to give constraint over a trace for computing correctly the Fibonacci sequence, which is defined as follows.\n{F0=0F1=1Fn=Fnâˆ’2+Fnâˆ’1\nWe can implement it with a trace composed of two columns: x and y.\nThe invariant we want to prove is: on the i-th row, xi sould contain Fi and yi should contain Fi+1.\nWe can achieve this behaviour by imposing the following contraints.\n\nWe impose a boundary constraint on the first row: x0=0 and y0=1.\nAdditionally, we impose two recurring constraints, implementing the recursive relation: for every i â€“ except the last one â€“, yi+1=xi+yi, and xi+1=yi.\nThis set of constraints is depicted in the following figure.\n\nIt is straight-forward to see that if a trace satisfies those constraints, then in the i-th row we will find the i-th Fibonacci number in the first column.\nNotice that this set of constraints can be thought also as defining a correct sequence of states, one for each row:\n\nthe boundary constraint is ensuring that the initial state is valid, while\nthe recurring constraint is ensuring that the state transition function is executed correctly.\n\nIn our framework, we support AIR constraints by:\n\nDefining an inductive trace data structure, which we model as a sequence of rows.\nModeling what it means to apply a contraint to a trace using a particular domain: this in practice is done by providing an assignment from abstract variables to concrete trace cells and then applying the original constraint semantics.\n\nYou can check out the soundness proof for the Fibonacci table using 8-bit addition here, which satisfies the following, slightly more complicated, specification:\nFor every rowi,xi=(Fimod256)\nUpcoming work\nThe framework is still in early stages fo development, but it is already showing promising results.\nSome planned next steps are:\n\nContinue adding low-level gadgets so that we have a rich library of basic reusable circuits.\nDefining common hash function circuits and proving their correctness.\nBuild a formally verified minimal VM for a subset of RISC-V.\n\nThe whole project is open source and available on GitHub, make sure to check it out!",
    "summary": {
      "en": "**Summary of \"Introducing clean, a formal verification DSL for zk circuits in Lean4\"**\n\nGiorgio Dell'Immagine introduces \"clean,\" a new domain-specific language (DSL) for formal verification of Zero Knowledge (ZK) circuits using Lean4. ZK circuits often have bugs, but formal verification techniques can enhance their reliability. Clean allows users to define circuits, specify their properties, and prove their correctness, contributing to the zkEVM Formal Verification Project.\n\n**Objectives:**\n- Build a DSL for writing ZK circuits in Lean4.\n- Create a library of reusable, formally verified circuit components.\n- Support AIR arithmetization and include a lookup primitive.\n\n**Formal Verification Process:**\n1. Define the circuit's supported operations.\n2. Set the semantics for these operations.\n3. Specify properties to prove for each circuit.\n\nCircuits consist of variables and constraints. The goal is to ensure that if the constraints are satisfied, the specified properties hold true, and vice versa.\n\n**Key Properties:**\n- **Soundness:** If a witness satisfies the constraints, then a specification property holds.\n- **Completeness:** For every input, an honest prover can exhibit a witness that satisfies the constraints.\n\n**DSL Features:**\nThe DSL supports operations like introducing new variables, adding constraints, defining lookup relations, and composing subcircuits. It offers a user-friendly monadic interface for circuit definitions.\n\n**FormalCircuit Structure:**\nThis structure encapsulates the circuit definition, assumptions, specifications, and proofs of soundness and completeness, allowing for the reuse of verified components.\n\n**Example: 8-bit Addition Circuit:**\nThe article walks through implementing and verifying an 8-bit addition circuit, detailing input/output definitions, assumptions, specifications, and the proof structure.\n\n**Future Work:**\nThe project is in early development stages, with plans to:\n- Add more basic reusable circuits.\n- Define and verify common hashing functions.\n- Build a minimal verified VM for a subset of RISC-V.\n\nThe project is open source and available on GitHub for further exploration.",
      "ko": "ì¡°ë¥´ì§€ì˜¤ ë¸ë¦¬ë§ˆì§€ë„¤ëŠ” Lean4ë¥¼ ì‚¬ìš©í•˜ì—¬ ì œë¡œ ì§€ì‹(Zero Knowledge, ZK) íšŒë¡œì˜ í˜•ì‹ ê²€ì¦ì„ ìœ„í•œ ìƒˆë¡œìš´ ë„ë©”ì¸ íŠ¹í™” ì–¸ì–´(DSL)ì¸ \"clean\"ì„ ì†Œê°œí•©ë‹ˆë‹¤. ZK íšŒë¡œëŠ” ì¢…ì¢… ë²„ê·¸ê°€ ë°œìƒí•  ìˆ˜ ìˆì§€ë§Œ, í˜•ì‹ ê²€ì¦ ê¸°ë²•ì„ í†µí•´ ì‹ ë¢°ì„±ì„ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. Cleanì€ ì‚¬ìš©ìê°€ íšŒë¡œë¥¼ ì •ì˜í•˜ê³ , ê·¸ ì†ì„±ì„ ëª…ì‹œí•˜ë©°, ì˜¬ë°”ë¦„ì„ ì¦ëª…í•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì¤ë‹ˆë‹¤. ì´ëŠ” zkEVM í˜•ì‹ ê²€ì¦ í”„ë¡œì íŠ¸ì— ê¸°ì—¬í•©ë‹ˆë‹¤.\n\nì´ í”„ë¡œì íŠ¸ì˜ ëª©í‘œëŠ” Lean4ì—ì„œ ZK íšŒë¡œë¥¼ ì‘ì„±í•˜ê¸° ìœ„í•œ DSLì„ êµ¬ì¶•í•˜ê³ , ì¬ì‚¬ìš© ê°€ëŠ¥í•œ í˜•ì‹ ê²€ì¦ëœ íšŒë¡œ êµ¬ì„± ìš”ì†Œì˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ë§Œë“œëŠ” ê²ƒì…ë‹ˆë‹¤. ë˜í•œ AIR ì‚°ìˆ í™” ì§€ì›ê³¼ ì¡°íšŒ ì›ì‹œ ê¸°ëŠ¥ì„ í¬í•¨í•  ê³„íšì…ë‹ˆë‹¤.\n\ní˜•ì‹ ê²€ì¦ ê³¼ì •ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. ë¨¼ì € íšŒë¡œê°€ ì§€ì›í•˜ëŠ” ì—°ì‚°ì„ ì •ì˜í•˜ê³ , ì´ëŸ¬í•œ ì—°ì‚°ì˜ ì˜ë¯¸ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤. ê·¸ ë‹¤ìŒ ê° íšŒë¡œì— ëŒ€í•´ ì¦ëª…í•  ì†ì„±ì„ ëª…ì‹œí•©ë‹ˆë‹¤. íšŒë¡œëŠ” ë³€ìˆ˜ì™€ ì œì•½ ì¡°ê±´ìœ¼ë¡œ êµ¬ì„±ë˜ë©°, ì œì•½ ì¡°ê±´ì´ ì¶©ì¡±ë˜ë©´ ëª…ì‹œëœ ì†ì„±ì´ ì°¸ì´ ë˜ë„ë¡ í•˜ëŠ” ê²ƒì´ ëª©í‘œì…ë‹ˆë‹¤.\n\nì£¼ìš” ì†ì„±ìœ¼ë¡œëŠ” ì‹ ë¢°ì„±(Soundness)ê³¼ ì™„ì „ì„±(Completeness)ì´ ìˆìŠµë‹ˆë‹¤. ì‹ ë¢°ì„±ì€ ì¦ì¸ì´ ì œì•½ ì¡°ê±´ì„ ë§Œì¡±í•˜ë©´ ëª…ì„¸ ì†ì„±ì´ ì„±ë¦½í•¨ì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ì™„ì „ì„±ì€ ëª¨ë“  ì…ë ¥ì— ëŒ€í•´ ì •ì§í•œ ì¦ëª…ìê°€ ì œì•½ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ì¦ì¸ì„ ì œì‹œí•  ìˆ˜ ìˆìŒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.\n\nDSLì˜ ê¸°ëŠ¥ìœ¼ë¡œëŠ” ìƒˆë¡œìš´ ë³€ìˆ˜ë¥¼ ë„ì…í•˜ê³ , ì œì•½ ì¡°ê±´ì„ ì¶”ê°€í•˜ë©°, ì¡°íšŒ ê´€ê³„ë¥¼ ì •ì˜í•˜ê³ , í•˜ìœ„ íšŒë¡œë¥¼ êµ¬ì„±í•˜ëŠ” ì‘ì—…ì„ ì§€ì›í•©ë‹ˆë‹¤. ì‚¬ìš©ì ì¹œí™”ì ì¸ ëª¨ë‚˜ë”• ì¸í„°í˜ì´ìŠ¤ë¥¼ ì œê³µí•˜ì—¬ íšŒë¡œ ì •ì˜ë¥¼ ì‰½ê²Œ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\ní˜•ì‹ íšŒë¡œ(FormalCircuit) êµ¬ì¡°ëŠ” íšŒë¡œ ì •ì˜, ê°€ì •, ëª…ì„¸ ë° ì‹ ë¢°ì„±ê³¼ ì™„ì „ì„±ì˜ ì¦ëª…ì„ ìº¡ìŠí™”í•˜ì—¬ ê²€ì¦ëœ êµ¬ì„± ìš”ì†Œë¥¼ ì¬ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.\n\nì˜ˆë¥¼ ë“¤ì–´, 8ë¹„íŠ¸ ë§ì…ˆ íšŒë¡œë¥¼ êµ¬í˜„í•˜ê³  ê²€ì¦í•˜ëŠ” ê³¼ì •ì„ ì„¤ëª…í•˜ë©°, ì…ë ¥ ë° ì¶œë ¥ ì •ì˜, ê°€ì •, ëª…ì„¸, ì¦ëª… êµ¬ì¡°ë¥¼ ìì„¸íˆ ë‹¤ë£¹ë‹ˆë‹¤.\n\ní–¥í›„ ê³„íšìœ¼ë¡œëŠ” ë” ë§ì€ ê¸°ë³¸ ì¬ì‚¬ìš© íšŒë¡œë¥¼ ì¶”ê°€í•˜ê³ , ì¼ë°˜ í•´ì‹± í•¨ìˆ˜ë¥¼ ì •ì˜ ë° ê²€ì¦í•˜ë©°, RISC-Vì˜ í•˜ìœ„ ì§‘í•©ì„ ìœ„í•œ ìµœì†Œ ê²€ì¦ëœ ê°€ìƒ ë¨¸ì‹ ì„ êµ¬ì¶•í•  ì˜ˆì •ì…ë‹ˆë‹¤. ì´ í”„ë¡œì íŠ¸ëŠ” ì˜¤í”ˆ ì†ŒìŠ¤ë¡œ GitHubì—ì„œ ë” ë§ì€ íƒìƒ‰ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "aa8902d9590d3643",
    "title": {
      "en": "Anti-Orbit Laser Submarines (2017)",
      "ko": "ë°˜ê¶¤ë„ ë ˆì´ì € ì ìˆ˜í•¨",
      "ja": null
    },
    "type": "story",
    "url": "http://toughsf.blogspot.com/2017/10/anti-orbit-laser-submarines.html",
    "score": 55,
    "by": "EA-3167",
    "time": 1743120377,
    "content": "ToughSF\n\nThursday, 12 October 2017\n\nAnti-Orbit Laser Submarines\n\nLaser-equipped nuclear-powered submarines are the perfect last line of defense against an attacking force in orbit.\n\nThe situation\n\nYou don't win every fight. Eventually, there will come a time in space warfare where a fleet of space warships has defeated all your mobile forces and your immobile defenses. They will bear down on you from above with lasers, missiles and kinetic projectiles and you will have to find a way to prevent their forcing of an unconditional surrender.\n\nWe will refer to the opponents as the 'attackers' and to you as the 'defenders'. The first step to devising an effective defense is to understand the situation.\n\nSo what is the situation?\n\nIts an enemy ship.\n\nAn attacking warship will start out in high orbit. This is an altitude of 2000km or above. Whether it has just arrived from an interplanetary voyage or has recently destroyed your remaining warships, it will go to high orbit to maximize the effectiveness of its space superiority. Space superiority, borrowing from the term 'air superiority', is when a force has complete dominance over all the orbits around a planet. No space-borne forces can oppose this superiority and no reserve forces can challenge them without being quickly destroyed.\n\nWhat does losing space superiority mean for defenders?\n\nThe most important consequence is that enemy warships have free reign to change orbits, maneuver into favorable positions and receive re-supplies. Their mobility is unconstrained.\n\nHigh Elliptic Orbits and gravity assists from a large moon allow for a huge variety of orbits.\n\nAttackers in high orbit can make optimal use of their laser weaponry. They can get clear lines of sight onto any spot on the surface, and the long distances between objects forces travel times to lengthen with the secondary effect of giving lasers plenty of time to shoot down targets. Laser effectiveness is generally dependent on how far they are from a target and how much 'dwell time' a beam can spend on a target.\n\nDe-orbiting objects from high altitude is inexpensive in terms of deltaV. This works in favour of missiles sent down from orbit by allowing them to use very little propellant to strike ground targets, which makes them lightweight and cheap to send by the hundreds. Additionally, falling towards Earth gives them a big boost to the velocities they achieve before impact.\n\nThe same applies to kinetic projectiles, a fact applied in the Rods From God concept of orbital bombardment.\n\nRetaliating\n\nSo you want to shoot back at the attackers.\n\nU.S. Armyâ€™s Homing Overlay Experiment\n\nMissiles can do the job. They are currently our only method of delivering weapons into orbital space. Something like an ICBM with an additional stage can reach LEO. Reaching higher orbits will require either a very large rocket, a high Isp engine for the upper stage or a launch system such a laser launch or ram accelerator.\n\nHowever, each of these solutions have major issues when trying to shoot down an opponent in high orbit.\n\nLaser satellite shooting down a missile slowly climbing to orbit.\n\nLarge rockets are easy to target and shoot down. A chemical-propellant rocket that needs to minimize its dry mass to achieve the necessary deltaV capacity will have very good acceleration but will end up being very fragile. Nuclear-thermal or nuclear-powered rockets can be much smaller and more durable, but getting sufficient acceleration out of them implies a very high power requirement, which might make them very expensive to throw at the enemy.\n\nMaglev track rocket launch system... vulnerable.\n\nRegular launches take tens of minutes and cannot be disguised from the attackers. Shortening this window of vulnerability can be done by using a launch system that powers the rocket or accelerates it externally. However, the infrastructure for the launch systems will in turn become a priority target for the attackers. Massive, hard to hide and immobile, they will receive a lot of firepower. Some launch systems are practically impossible to shield from damage, such as a laser launch system that needs thousands of exposed laser optics, and others reveal their positions as soon as they fire a rocket. Building underground is also a very expensive endeavour when considering that all the work can be undone by a single 'bunker buster'-type weapon.\n\nThe logistics of launching missiles against attackers sitting in orbit works against the defenders. The attackers can de-orbit a missile by expending only a few tens to hundreds of meters per second of deltaV. A defender must equip each missile with tens of thousands of meters per second of deltaV. It might be easier to build more missiles and create rocket fuels on the ground at the start of the war, but after an orbital bombardment campaign by attackers with space superiority, it is unlikely to be the case.\n\nKinetics that can be shot all the way to high orbit need to handle hundreds to thousands of Gs of acceleration, traverse the lower atmosphere at dozens of kilometers per second, survive laser fire for several minutes with minimal capacity to dodge and take out a target with a very short window of interception. This is a tall order!\n\nHot hydrogen light gas gun launch system. Can be weaponized.\n\nSo, what are the defender's options?\n\nThey need to retaliate with something that cannot be shot down, from a platform that can avoid counter-fire and can maintain functionality after infrastructure and services have been disabled world-wide.\n\nOne option that fits the bill is laser submarines.\n\nLasers cannot be shot down and hit their target instantly. They can be used so long as electrical power is supplied. Submarines operate underwater, an environment that can hide them until they surface and protects them from high-velocity projectiles and lasers while submerged. The can protect themselves this way for months on end, and if they employ the same life support systems as on spaceships, then it can add up to years.\n\nFor the same reason that today's submarine fleets are considered an unbeatable means of retaliating against a foe after nuclear armageddon has wiped out the homeland, laser submarines will be able to operate and remain dangerous even after orbital attacks destroy all support infrastructure.\n\nLet us now look at how a submarine can be used to retaliate against attackers in orbit.\n\nThe Challenges\n\nSubmarines are already equipped with a high electrical power generation. Large modern nuclear submarines are already able to produce over 100MW for years on end. In a futuristic setting with common space travel and space wars, power generation technology developed for interplanetary travel will allow submarines to produce gigawatts or more.\n\nNext generation water-cooled nuclear reactor.\n\nThe most likely generators for space travel will be nuclear due to their high power density. The biggest limitation to generating power from nuclear reactors is waste heat capacity: It is easy to heat up the reactor core but much harder to remove the heat. Submarines will have an entire ocean as a heatsink so will be able to produce more watts compared to a spacecraft with a reactor of the same mass and volume.\n\nThe Bi-modal NTR is a nuclear thermal rocket engine that doubles as power generator.\n\nAll of this electrical power can be used to power a laser generator.\n\nThree elements determine a laser's effectiveness: wavelength, radius of focusing optics and beam power.\n\nAn observatory using a laser guide star.\n\nWe have already determined that laser submarines will likely be able to produce more electrical power than a similar laser space warship, so laser submarines will also have the advantage in beam power.\n\nThe radius of the focusing optics will depend on the specific arrangement of the laser weapon's components and how they are deployed. We will look into the possible designs down below.\n\nA free electron laser. Unlike most designs, it can freely switch wavelengths.\n\nThe wavelength however is not a variable laser designs have much control over. Submarines operate in an aquatic environment, on top of which is a hundred kilometers of Earth's atmosphere. At the interface of the ocean's surface is sea mist and suspended droplets of water in fog or clouds. The ocean's surface is not flat either, with waves of a few centimeters to a few hundred meters rolling over it endlessly. A beam emitted by a submarine will have to penetrate all of this environment and still travel the hundreds of thousands of kilometers' distance separating it from a target in high orbit.\nThe optical properties of water are therefore the determinant factor for which wavelengths the laser should produce.\n\nHere is the absorption spectrum of water:\n\nThe lower the 'Relative Absorption value', the less the wavelength's energy is absorbed. We can clearly see that the lowest values are for the 'optical window' that corresponds to the 400-700nm visual spectrum. The highest absorption is for 100nm ultraviolet wavelengths and 3000nm infrared wavelengths.\n\nHere is the absorption spectrum for our atmosphere:\n\nThe atmospheric attenuation of electromagnetic radiation has similar features to that of water: short wavelengths such as X-rays cannot go through while long wavelengths such as radio penetrate easily.\n\nIt might be easier to consider the laser beam as being fired from space and coming down to the surface.\n\nA 100nm ultraviolet laser beam will traverse the vacuum of space with ease, but will stop short of reaching the upper atmosphere. A 400nm blue laser will go through the atmosphere and through 460 meters of water before being reduced to less than 1% of its initial power. A 1000nm infrared laser will lose 20% of its power to the atmosphere and be completely absorbed by half a meter of water. A 100m radio wavelength just bounces off the ionosphere.\n\nWhile shorter wavelengths are preferred for laser weapons, as they allow a beam to be focused to destructive intensities over longer distances, a laser submarine should use 400nm wavelength lasers to penetrate water and the atmosphere without losing a lot of beam power.\n\nThe equation for how much of a beam's energy is retained after traversing a medium is given by:\n\nPercentage transmitted: e^( -1 * Attenuation coefficient * Depth) * 100\n\nThe attenuation coefficient is usually given in cm^-1, so the depth should be converted into cm units.\n\nFor example, near-infrared light at 800nm wavelength has an attenuation coefficient of 0.01cm^-1. We want to know what percent of a near-infrared laser's energy remains after passing through one meter of water.\n\nOne meter equals 100 cm. Per our equation, we find the percentage to be approximatelye^(-0.01*100)*100: 36.8%. Just over a third of the beam gets through.\n\nHere is a table of values for how much beam power is lost if the blue wavelength laser submarine fires its weapon at different depths, using an attenuation coefficient of 0.0001cm^-1:\n\nWe see that to maintain a good percentage of laser power getting through the water, a laser submarine would have to fire at rather low depths. According the the table above, a 10 meters depth using blue laser light looks like a good compromise: deep enough to escape orbital surveys and strikes, with at least 90% of the laser power going through.\n\nSo is a laser being fired at 10 meters depth a good idea?\n\nFactors affecting a solid state laser weapon system.\n\nThe table gives an incomplete picture. While laser power being absorbed is an important factor to consider, there is a large number of other elements that affect how effective a laser is. One such element is thermal blooming. That 90% power transmission rate implies that 10% of the laser power is absorbed and goes into heating the water. If the laser power is rated in megawatts, the heat absorbed by the water becomes significant. Hot water has different optical properties compared to colder water - it will work as a lens in reverse, effectively de-focusing the laser.\n\nAnother significant issue is the water/gas interface. When light travels between two mediums of significantly different density, like seawater and atmospheric gasses, it is bent by refraction. Even worse, the sea's surface is constantly disturbed by waves, tides and other movements. Instead of a smooth surface, which angling the laser can compensate for, it is continuously changing and bending light in different and hard to predict direction. Here is a familiar example of the effect:\n\nThis effect is familiar to astronomers trying to gaze at stars through the moving atmosphere, and adaptive optics are used to compensate for the deviations in light traversing the atmosphere.\n\nFor a laser weapon, adaptive optics work in reverse.\n\nAdaptive optics cannot be employed as effectively when used underwater. While the atmosphere's movements are already difficult to detect and correct, trying to effectively measure how light moves through two mediums with a complex and moving interface is much harder. Guide lasers are used for measurement, with the light reflecting off the ionosphere creating an artificial 'guide star' for astronomers to calibrate their instruments. A guide laser placed underwater would submit to the same chaotic disturbances as the weapon laser and would be unusable. They would also have to work much harder. Refraction means that inaccuracies are multiplied once they pass through the water/air interface.\n\nInterference with sunlight works in both directions.\n\nFinally, there's the problem of reflection. While water is decently able to let higher wavelength visible light penetrate, the massive difference in density between the water and the air (x1000) above it means that it is a good reflector. Laser light would travel from the submarine to the water/air interface, and just be bounced back below the surface. For sea water, less than 6% of the laser light would be reflected at angles below 30 degrees.\n\nWhile the above table might not give any large figures, remember that the angle is measured against the rippling, swelling and rolling waves. A nominal angle of 10 degrees against the water's surface might transition between -20 and 100 degrees as a wave moves over a laser. This is the difference between 3% and 45% of the laser not going through the ocean's surface.\n\nSubmarines can survive this... but it might not be enough to matter.\n\nThe principal advantage of staying underwater is that the submarine will be protected from high velocity strikes and retaliatory laser fire. However, if it cannot return fire from this position, then it cannot serve as a perfect last line of defense.\n\nThe Solutions\n\nSo, based on the previous section, we can affirm that attempting to shoot a laser while underwater provides unequalled benefits but also significant challenges.\n\nWe can either tackle the problems a laser submarine faces directly or attempt to circumvent them.\n\n-Long wavelengths\n\nPreviously, we considered that blue wavelengths were optimal for shooting while underwater as they were absorbed the least. The reduced absorption would have allowed a submarine to transmit over 90% of the laser power to the ocean's surface from a depth of 10 meters. However, the distortion at the water/air interface rendered this option impractical.\n\nHow about using a wavelength that is less efficient at penetrating water, but is less affected by distortion?\n\nLooking at the absorption spectrum of water, we notice that wavelengths longer than 100 micrometers are absorbed less and less as the wavelength increases. At 1m wavelength, the laser would traverse water as easily as blue light. This corresponds to a frequency of 300MHz. This is the radio band.\n\nNot coincidentally, frequencies of lower than 300MHz are used to communicate with submarines. At 3 to 30kHz, which is wavelengths of 10 to 100km, can penetrate the seas to a depth of several hundred meters. Using even lower frequencies further increases penetration depth, but would require impractically large lens to focus onto a target in high orbit. Another factor working against longer wavelength radio is that the ionosphere can reflect signals back down to the surface at frequencies below 30MHz.\n\nA 1m wavelength radio laser will be able to traverse the atmosphere mostly undisturbed and go through the ionosphere without refraction. The features of waves are too small to cause it to wobble chaotically at the sea/air interface. The beam would bend coming out of the sea, but it is a single predictable deviation that can be corrected.\n\nInductive output tube diagram.\n\nA radio-wavelength coherent beam or 'raser' can be generated by a Free Electron laser or inductive output tubes with an efficiency exceeding 70%.\n\nThe advantages of a radio-based anti-orbital system is that it allows a submarine to fire upon targets while deep underwater. Even at 20 meters depth, the radio beam would transmit 82% of its power through water and lose less than 1% going through the atmosphere. It is much less affected by small waves and other turbulence in the water, and mostly immune to above-surface weather effects.\n\nThere are several downsides however. Such a large wavelength makes it impossible to focus the beam down to destructive intensities without a very large radio dish - this might get impractical when you also want the submarine to move quickly while underwater. Another issue is that the beam won't interact with the target in a consistent manner.\n\nLasers, for example, are absorbed by the outermost layers of the materials the target's surface is made of. The heating is concentrated in the 'skin' of the target. Sufficiently intense laser beams heat this skin layer to very high temperatures, causing the material to boil away or even explode.\nRadio beams would use wavelengths a million times longer that do not interact with the target's materials at an atomic level. They are much more sensitive to the conductivity of the materials they are striking. Good conductors such as steel or aluminium efficiently reflect radio waves and are not heated. Good insulators such as ceramics or glass are mostly transparent to radio waves and do no absorb the beam's energy as it passes through them. Radio absorbing materials have to be neither good conductors or insulators, such as\n\nThis is bad news if the targets are space warships with an external metallic hull and an internal structure based on advanced carbon-composite and ceramic materials. Large propellant tanks will let the radio waves pass straight through. Small features of 10cm or smaller are completely invisible to the radio waves too.\n\nHowever, there will still be ways to deal damage.\n\nOpenings in the metallic hull would allow radio waves to enter and then bounce around on the internal surface. Like a microwave oven, the trapped radiation will pass through radio transparent materials thousands to millions of times before being fully absorbed. A human is mostly composed of salted water. He or she would absorb about between 0.1 and 1% of a radio beam going through their body. If the radio beam stays inside a 10m diameter hull for just 76 microseconds, 2300 bounces are possible and the percentage of beam energy absorbed rises to 90%. When the beam power is measured in tens to hundreds of megawatts, this has dire consequences for a human crew.\n\nAnother effect is induced current. If even a few watts manage to circulate in microcircuitry, it is enough to short-circuit or even melt down computers, avionics and delicate sensors. RF Shock and Burn is a serious issue for electricians and engineers working on conductive structures near a high frequency radio source. At the power levels radio-laser submarines will pump into targets, induced current is enough to melt steel.\n\nSteel melted by 1-30kHz radio frequencies.\n\nModern submarines are not powerful enough to compensate for the diffraction of a 1m wavelength radio beam. With 100MW of available electrical power, 30% of which is lost in an inductive output tube and another 10% to seawater and atmospheric absorption, less than 63MW will reach space.Even the largest submarines, such as the Ohio-class SSBN, have a hull diameter (beam) of 13m. Mounting an internal dish to focus a radio beam up to this diameterwill createa very low performance laser.\nTargets at 10km distance will receive about 22W/m^2 - a great radio signal, but a terrible weapon. Targets in low orbit and high orbit will receive milliwatts of power.\n\nA 1296MHz dish. For 300MHz beams, the spaces can be even larger.\n\nWhat is needed is much more power and an externally mounted radio dish. Thankfully, a 300MHz beam can be focused by a dish with holes up to a tenth of the wavelength in size. A radio dish for this wavelength can is very lightweight and easily collapsible, with conductive spars spaced by 10cm lengths. The spars can be made hollow to have neutral bouyancy, allowing them to support themselves without many structural elements. At 10m depth and below, there are few disturbances in the surrounding water.\n\nDish diameters of 100 meters or more are envisageable, massing less than 1kg per m^2. Tension wires hold the shape and serve as the mechanisms for adaptive optics to act on the dish.\n\nA group of submarines using space-grade nuclear reactors might be able to put together 500GW of power with a combined reactor mass of only 2500 tons. Between them, they can hold up a dish 1km in diameter, as follows:\n\nThis arrangement allows the submarines to focus a 315GW beam to an intensity of 67kW/m^2 at an altitude of 1000km. For low orbit targets, the intensity is 1.67MW/m^2. These intensities are far from enough to melt or physically damage the structure of a spaceship. However, the beam is large and entirely envelops the target. Any hole through a metallic exterior or any cavity lined by a radar reflector will turn the spaceship into a microwave oven receiving megawatts of heating over time. At high altitudes, the intensity is lower by the targets orbit much slower, giving the Rasar beam time to boil crews to death and melt components directlyor indirectly.\n\n-Interface lens\n\nA variant on the lens used for above.under water filming.\n\nThe biggest trouble with optical wavelengths is the chaotic distortions and reflections created by the sea/air interface. They would allow submarines to physically damage targets with relatively small lens and shoot on the move, but aiming though the interface seems impossible...\n\n... unless an interface lens is used.\n\nIt is an optical array that floats on the ocean's surface, serving to handle the beam's transition from underwater to atmospheric mediums. Glass can be made to have a refractive index similar to that of water. A laser beam traversing a sea/glass interface would not suffer any distortion. This is the reason why some transparent objects disappearcompletely while underwater - our eyes cannot make out any distortionsthat reveal their presence.\n\nThe refractive index of the polymer ball is exactly the same as water.\n\nThe interface lens can also serve to focus the laser. It can be made much larger than whatever the submarine can carry, as it is not confined by hull dimensions or hydrodynamics.\n\nOne primary advantage of thesefloating structures is that they can be deployed before firing commences, and each is much cheaper than a submarine. When a target passes overhead in orbit, a laser submarine can rise to firing depth and start shooting. It only needs to equipment to focus the beam from the laser generator to the interface lens, a distance of ten meters or so. The floating lens receives the beam, corrects the angle and aims at the target overhead. If the target is not destroyed, it can trace the laser back to its origin and initiate a retaliatory strike.\n\nAn interface lens is not very mobile and needs to stay on the surface, so it cannot protect itself by diving. There is a good chance it will be destroyed... at which point the laser submarine switches to firing through another interface lens and so on.\n\nAlthough the lens will have to be rather large and heavy to receive a laser beam from a wide variety of angles underwater, and re-focus it in a moving target hundreds of kilometers above, which makes it expensive, it must be considered as an expendableasset when compared to cost and size of a nuclear submarine. Also, the lens can be covered by an isothermal sheet and made out of materials transparent to radar, making it hard to detect from orbit until it starts firing.\n\nUsing a 10m diameter interface lens, even a modern submarine with 100MW of available output will be able to deal serious damage to targets in low orbit. About 40MW of the submarine's power will reach the target using a diode laser generatorat 400nm wavelength, but at an intensity of 133GW/m^2 at 200km altitude. This is enough to rip through 14.8 meters (!) of aluminium per second, or even 6.5m/s of carbon armor. Any target caught by this beam for even a second will be cut in half.At 1000km, its performance is still a respectable 52mm/s through carbon.\n\nSpaceship in Children of a Dead Earth scarred by laser strikes.\n\nMore advanced submarines can get away with smaller lens that are harder to counter-attack and still deal devastating damage to high orbit targets. A 10GW laser beam focused through a 4m wide interface lens can blast away targets at a rate of 837mm/s at 1000km.\n\nDisadvantages of this system is the cost of 'expendable' large adaptive mirrors and possibly the inability to use floating structures in severe storms with large waves rocking the optics.\n\n-Towed Lens\nThis fixes the problem with floating optical arrays. The laser is focused by towed apparatus that can be held underwater until firing starts, and then moved around after an initial volley to avoid counter-fire.\n\nThe towed lens can be lighter and cheaper than a fully independent floating lens. Electrical power, computing operations and other functions can be provided by the submarine towing the lens, with only the actuators and suspension retained.\n\nLasers have been carried through optical fibres with nearly zero losses of beam energy over distance. This is because internal reflection of the beam is done at grazing angles within the optic fibre. In other words, laser beams of megawatts to gigawatts power levels can be transported by optic fibres without any significant losses and no special provisions against heating.\n\nOptical fibres can carry a laser generated by a submarine to the towed lens, and they can run parallel to the load bearing cables attaching the lens to the submarine. This method of delivering the beam to the lens bypasses the losses and complications of having the beam penetrate several meters of water to reach the surface.\n\nTo these advantages come some downsides. The submarine becomes more vulnerable that if it relies upon fully independent floating lens. If an enemy target locates a floating lens, it might correctly assume that the much more valuable submarine is very close to the lens. When a target spaceship in orbit sends down counter-fire before the submarine is ready, the latter would be forced to cut loose the lens and dive... this breaks the optical fibre cable and renders the lens useless.\n\nTactics using towed lens might involve dragging along a fleet of lenses and rotating them to the surface and back. Longer fibre optic cables gives the submarine more freedom to move, while a mix of decoys and intermittent and random firing patterns reduces the disadvantages of the design.\n\n-Optical phased array floater.\n\nDo away with the submarine!\n\nA specialized vehicle can be built solely for the purpose of hiding a laser weapon underwater and surfacing for short bursts of fire. Since this weapon only attacks from above the water and does not have to worry about hydrodynamics, nifty solutions such as an optical phased array can be used. The laser generator's size is equal to the lens diameter and if it received damage, it will only suffer reduced output.\n\nInstead of VLS cells, phased array grids?\n\nThe more delicate components such as the power generator can remain submerged, only transporting electricity to the phased array on the surface through cables. A reactor embedded in the sea floor can be a very difficult target to locate and destroy.\n\n-Supercavitating platform.\n\n'Bullet submarines' powered by excessively powerful nuclear reactors.\n\nIf submarines have access to gigawatts of power, they can also use it for propulsion.\n\nThis level of power output can enable submarines to reach supersonic speeds through supercavitation through water. If they can rise to the surface, fire, dive and relocate in a matter of seconds, then they can evade counter-fire through sheer agility.\n\nIt might be best in this case to mount a set of optical phased array lasers tailored to trans-atmospheric wavelengths to be used once a submarine surfaces. Gigawatts of power means gigawatts of heating: the local atmosphere can be cleared of moisture and mist that distorts the beam most heavily.\n\nA 1GW laser at 400nm focused by even a relatively small 4m diameter lens can blast past 23.7m/s of aluminium or 10.4m/s of carbon at 200km, and remains deadly at 1000km with 83mm/s of carbon penetration. This allows for short bursts of laser fire to take down any target.\n\nAtmospheric lensing.\n\nAdvanced techniques such as thermal lensing using the Kerr effect is being developed in programs such as the Laser Developed Atmospheric Lens (LDALs) by DARPA. LDALs can allow high-power submarines to extend their effective range to tens of thousands of kilometers while reducing the effectiveness of laser counter-fire.\n\nConclusion.\n\nLasers and underwater environments don't mix well, but there are many solutions to gain the protection a submarine enjoys while attacking instantly and repeatedly with direct energy weapons.\n\nOnce these solutions are applied, a defending planet with deep oceans can hope to maintain an effective last line of defense against invading spaceships.\n\nPosted by\n\nMatter Beam\n\nEmail ThisBlogThis!Share to XShare to FacebookShare to Pinterest\n\n172 comments:\n\n    (function() {\n      var items = null;\n      var msgs = null;\n      var config = {};\n\n// <![CDATA[\n      var cursor = null;\n      if (items && items.length > 0) {\n        cursor = parseInt(items[items.length - 1].timestamp) + 1;\n      }\n\n      var bodyFromEntry = function(entry) {\n        var text = (entry &&\n                    ((entry.content && entry.content.$t) ||\n                     (entry.summary && entry.summary.$t))) ||\n            '';\n        if (entry && entry.gd$extendedProperty) {\n          for (var k in entry.gd$extendedProperty) {\n            if (entry.gd$extendedProperty[k].name == 'blogger.contentRemoved') {\n              return '<span class=\"deleted-comment\">' + text + '</span>';\n            }\n          }\n        }\n        return text;\n      }\n\n      var parse = function(data) {\n        cursor = null;\n        var comments = [];\n        if (data && data.feed && data.feed.entry) {\n          for (var i = 0, entry; entry = data.feed.entry[i]; i++) {\n            var comment = {};\n            // comment ID, parsed out of the original id format\n            var id = /blog-(\\d+).post-(\\d+)/.exec(entry.id.$t);\n            comment.id = id ? id[2] : null;\n            comment.body = bodyFromEntry(entry);\n            comment.timestamp = Date.parse(entry.published.$t) + '';\n            if (entry.author && entry.author.constructor === Array) {\n              var auth = entry.author[0];\n              if (auth) {\n                comment.author = {\n                  name: (auth.name ? auth.name.$t : undefined),\n                  profileUrl: (auth.uri ? auth.uri.$t : undefined),\n                  avatarUrl: (auth.gd$image ? auth.gd$image.src : undefined)\n                };\n              }\n            }\n            if (entry.link) {\n              if (entry.link[2]) {\n                comment.link = comment.permalink = entry.link[2].href;\n              }\n              if (entry.link[3]) {\n                var pid = /.*comments\\/default\\/(\\d+)\\?.*/.exec(entry.link[3].href);\n                if (pid && pid[1]) {\n                  comment.parentId = pid[1];\n                }\n              }\n            }\n            comment.deleteclass = 'item-control blog-admin';\n            if (entry.gd$extendedProperty) {\n              for (var k in entry.gd$extendedProperty) {\n                if (entry.gd$extendedProperty[k].name == 'blogger.itemClass') {\n                  comment.deleteclass += ' ' + entry.gd$extendedProperty[k].value;\n                } else if (entry.gd$extendedProperty[k].name == 'blogger.displayTime') {\n                  comment.displayTime = entry.gd$extendedProperty[k].value;\n                }\n              }\n            }\n            comments.push(comment);\n          }\n        }\n        return comments;\n      };\n\n      var paginator = function(callback) {\n        if (hasMore()) {\n          var url = config.feed + '?alt=json&v=2&orderby=published&reverse=false&max-results=50';\n          if (cursor) {\n            url += '&published-min=' + new Date(cursor).toISOString();\n          }\n          window.bloggercomments = function(data) {\n            var parsed = parse(data);\n            cursor = parsed.length < 50 ? null\n                : parseInt(parsed[parsed.length - 1].timestamp) + 1\n            callback(parsed);\n            window.bloggercomments = null;\n          }\n          url += '&callback=bloggercomments';\n          var script = document.createElement('script');\n          script.type = 'text/javascript';\n          script.src = url;\n          document.getElementsByTagName('head')[0].appendChild(script);\n        }\n      };\n      var hasMore = function() {\n        return !!cursor;\n      };\n      var getMeta = function(key, comment) {\n        if ('iswriter' == key) {\n          var matches = !!comment.author\n              && comment.author.name == config.authorName\n              && comment.author.profileUrl == config.authorUrl;\n          return matches ? 'true' : '';\n        } else if ('deletelink' == key) {\n          return config.baseUri + '/comment/delete/'\n               + config.blogId + '/' + comment.id;\n        } else if ('deleteclass' == key) {\n          return comment.deleteclas",
    "summary": {
      "en": "**Summary of Anti-Orbit Laser Submarines**\n\nLaser-equipped nuclear submarines could serve as a crucial defense against space attackers. When a fleet of enemy ships gains control of high orbit, they can strike with lasers and missiles, making it essential for defenders to find a way to retaliate. \n\n1. **Situation Overview**: Attackers in high orbit can easily target defenders on the ground, enjoying mobility and the ability to strike without constraints. This creates a dire situation for defenders who have lost space superiority.\n\n2. **Challenges for Defenders**: Traditional missile defense systems face significant hurdles, such as being easily targeted and needing vast amounts of fuel to reach high orbit. Defenders struggle to launch effective counterattacks against agile attackers.\n\n3. **Advantages of Laser Submarines**:\n   - **Protection**: Submarines can remain hidden underwater, shielded from attacks and providing a secure base for retaliation.\n   - **Power Generation**: Modern submarines can generate substantial electrical power, potentially enabling powerful laser systems.\n   - **Instant Strike Capability**: Lasers hit targets almost instantly, making them effective for surprise attacks.\n\n4. **Technical Considerations**: \n   - **Laser Effectiveness**: The effectiveness of lasers diminishes with distance and through water and atmosphere. Lasers around 400nm wavelength are optimal for penetrating both mediums.\n   - **Submarine Depth**: Submarines can operate at depths where they can still effectively fire lasers while avoiding detection.\n\n5. **Potential Solutions**:\n   - **Longer Wavelengths**: Using radio waves instead of optical lasers for underwater attacks could circumvent some challenges, allowing for deeper firing while still delivering damage.\n   - **Interface Lenses**: Floating lenses could focus laser beams effectively at the air-sea interface, allowing submarines to fire while submerged.\n   - **Towed Lens Systems**: Submarines could use towed lenses to maintain flexibility while firing laser beams at targets.\n   - **Supercavitating Platforms**: High-power submarines could achieve supercavitating speeds for quick strikes and evasive maneuvers.\n\nIn conclusion, while lasers and underwater environments pose challenges, innovative technologies and strategies can enable submarines to become an effective last line of defense against orbital threats.",
      "ko": "ë ˆì´ì €ë¥¼ ì¥ì°©í•œ í•µ ì ìˆ˜í•¨ì€ ìš°ì£¼ ê³µê²©ìì— ëŒ€í•œ ì¤‘ìš”í•œ ë°©ì–´ ìˆ˜ë‹¨ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì ì˜ í•¨ëŒ€ê°€ ê³ ìœ„ë„ì—ì„œ í†µì œê¶Œì„ í™•ë³´í•˜ë©´ ë ˆì´ì €ì™€ ë¯¸ì‚¬ì¼ë¡œ ê³µê²©í•  ìˆ˜ ìˆì–´ ë°©ì–´ìë“¤ì€ ë°˜ê²©í•  ë°©ë²•ì„ ì°¾ì•„ì•¼ í•©ë‹ˆë‹¤.\n\ní˜„ì¬ ìƒí™©ì„ ì‚´í´ë³´ë©´, ê³ ìœ„ë„ì—ì„œ ê³µê²©ìë“¤ì€ ì§€ìƒì˜ ë°©ì–´ìë“¤ì„ ì‰½ê²Œ ê²¨ëƒ¥í•  ìˆ˜ ìˆìœ¼ë©°, ì´ë™ì„±ì´ ë›°ì–´ë‚˜ê³  ì œì•½ ì—†ì´ ê³µê²©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ìš°ì£¼ ìš°ìœ„ë¥¼ ìƒì€ ë°©ì–´ìë“¤ì—ê²Œ ë§¤ìš° ì‹¬ê°í•œ ìƒí™©ì„ ì´ˆë˜í•©ë‹ˆë‹¤.\n\në°©ì–´ìë“¤ì´ ì§ë©´í•œ ë„ì „ ê³¼ì œëŠ” ì „í†µì ì¸ ë¯¸ì‚¬ì¼ ë°©ì–´ ì‹œìŠ¤í…œì´ ì‰½ê²Œ ëª©í‘œê°€ ë˜ê³ , ê³ ìœ„ë„ë¡œ ë„ë‹¬í•˜ê¸° ìœ„í•´ ë§ì€ ì—°ë£Œê°€ í•„ìš”í•˜ë‹¤ëŠ” ì ì…ë‹ˆë‹¤. ë°©ì–´ìë“¤ì€ ë¯¼ì²©í•œ ê³µê²©ìë“¤ì— ëŒ€í•´ íš¨ê³¼ì ì¸ ë°˜ê²©ì„ launchí•˜ëŠ” ë° ì–´ë ¤ì›€ì„ ê²ªê³  ìˆìŠµë‹ˆë‹¤.\n\në ˆì´ì € ì ìˆ˜í•¨ì˜ ì¥ì ì€ ì—¬ëŸ¬ ê°€ì§€ê°€ ìˆìŠµë‹ˆë‹¤. ì ìˆ˜í•¨ì€ ìˆ˜ì¤‘ì—ì„œ ìˆ¨ì„ ìˆ˜ ìˆì–´ ê³µê²©ìœ¼ë¡œë¶€í„° ë³´í˜¸ë°›ê³ , ë°˜ê²©ì„ ìœ„í•œ ì•ˆì „í•œ ê¸°ì§€ë¥¼ ì œê³µí•©ë‹ˆë‹¤. í˜„ëŒ€ì˜ ì ìˆ˜í•¨ì€ ìƒë‹¹í•œ ì „ë ¥ì„ ìƒì„±í•  ìˆ˜ ìˆì–´ ê°•ë ¥í•œ ë ˆì´ì € ì‹œìŠ¤í…œì„ ìš´ì˜í•  ìˆ˜ ìˆëŠ” ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤. ë ˆì´ì €ëŠ” ê±°ì˜ ì¦‰ê°ì ìœ¼ë¡œ ëª©í‘œì— ë„ë‹¬í•˜ë¯€ë¡œ ê¸°ìŠµ ê³µê²©ì— íš¨ê³¼ì ì…ë‹ˆë‹¤.\n\nê¸°ìˆ ì ì¸ ì¸¡ë©´ì—ì„œ ë ˆì´ì €ì˜ íš¨ê³¼ëŠ” ê±°ë¦¬ì™€ ë¬¼, ëŒ€ê¸°ë¥¼ í†µê³¼í•˜ë©´ì„œ ê°ì†Œí•©ë‹ˆë‹¤. ì•½ 400nm íŒŒì¥ì˜ ë ˆì´ì €ê°€ ë‘ ë§¤ì²´ë¥¼ ê´€í†µí•˜ëŠ” ë° ìµœì ì…ë‹ˆë‹¤. ì ìˆ˜í•¨ì€ íƒì§€ë¥¼ í”¼í•˜ë©´ì„œ ë ˆì´ì €ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ë°œì‚¬í•  ìˆ˜ ìˆëŠ” ê¹Šì´ì—ì„œ ì‘ë™í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nì ìˆ˜í•¨ì´ ì§ë©´í•œ ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆëŠ” ì ì¬ì ì¸ í•´ê²°ì±…ìœ¼ë¡œëŠ”, ìˆ˜ì¤‘ ê³µê²©ì„ ìœ„í•´ ê´‘í•™ ë ˆì´ì € ëŒ€ì‹  ë¼ë””ì˜¤íŒŒë¥¼ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì´ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ë” ê¹Šì€ ê³³ì—ì„œ ë°œì‚¬í•  ìˆ˜ ìˆê²Œ í•´ì£¼ë©° í”¼í•´ë¥¼ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, ê³µê¸°ì™€ ë°”ë‹¤ì˜ ê²½ê³„ì—ì„œ ë ˆì´ì € ë¹”ì„ íš¨ê³¼ì ìœ¼ë¡œ ì§‘ì¤‘í•  ìˆ˜ ìˆëŠ” ë¶€ìœ  ë Œì¦ˆë¥¼ ì‚¬ìš©í•˜ì—¬ ì ìˆ˜í•¨ì´ ì ìˆ˜í•œ ìƒíƒœì—ì„œë„ ë°œì‚¬í•  ìˆ˜ ìˆê²Œ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì ìˆ˜í•¨ì€ ë ˆì´ì € ë¹”ì„ ëª©í‘œë¡œ ë°œì‚¬í•˜ë©´ì„œ ìœ ì—°ì„±ì„ ìœ ì§€í•˜ê¸° ìœ„í•´ ê²¬ì¸ ë Œì¦ˆ ì‹œìŠ¤í…œì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê³ ì¶œë ¥ ì ìˆ˜í•¨ì€ ì´ˆê¸°í™” ì†ë„ë¥¼ ë‹¬ì„±í•˜ì—¬ ì‹ ì†í•œ ê³µê²©ê³¼ íšŒí”¼ ê¸°ë™ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nê²°ë¡ ì ìœ¼ë¡œ, ë ˆì´ì €ì™€ ìˆ˜ì¤‘ í™˜ê²½ì´ ë„ì „ ê³¼ì œê°€ ë  ìˆ˜ ìˆì§€ë§Œ, í˜ì‹ ì ì¸ ê¸°ìˆ ê³¼ ì „ëµì„ í†µí•´ ì ìˆ˜í•¨ì´ ê¶¤ë„ ìœ„í˜‘ì— ëŒ€í•œ íš¨ê³¼ì ì¸ ìµœí›„ì˜ ë°©ì–´ì„ ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "0f9ecfa7eec46811",
    "title": {
      "en": "Unofficial Windows 7 Service Pack 2",
      "ko": "ìœˆë„ìš° 7 SP2 ë¹„ê³µì‹íŒ",
      "ja": null
    },
    "type": "story",
    "url": "https://github.com/i486girl/win7-sp2",
    "score": 248,
    "by": "XzetaU8",
    "time": 1742643903,
    "content": "Windows 7 Service Pack 2\nWarningThis project is far from finished, meaning that bugs are to be expected. If you encounter any bugs, please report them in the issue tracker or in the Discord server. Thank you for your understanding.\n\nWindows 7 Service Pack 2 is a package consisting of updates, tweaks, backported apps and overall enhancements with the goal of providing an effortless way to have a fully updated Windows 7 ISO and enhancing usability on semi-modern machines.\nTODOs\n\n - All updates until 2020, with the addition of Windows Embedded Standard 7 updates\n - Snipping Tool from Windows 10 version 1507 -> Credits: vxiduu\n - Paint from Windows 8 build 9425\n - Registry Editor from Windows 10 build 16212 -> Credits: Aurorarion\n - In-place service pack installer\n - Native USB 3.0 and NVMe support -> Credits: Unknown user from MyDigitalLife forums\n - TPM 2.0 support\n - UEFI support in the ISO releases, with EFI GOP support too -> Credits: Typical/int10h, AveragePC\n - Inclusion of VxKex -> Credits: vxiduu\n - Windows 8 PE in the ISO, with a theme that resembles Windows 7 -> Credits: ImSwordQueen (Windows 7 theme for Windows 8.x)\n - Windows 10 setup engine in the ISO release -> Credits: Aurorarion (helping out on the 10 setup engine port)\n - Builtin Webp and FLAC codecs\n - Task Manager from Windows 8 build 7880 -> Credits: Jevil7452\n - Upscaled graphics in some places\n - Windows Vista/7 PE's boot screen on the ISO -> Credits: Microsoft Corporation and Tech Stuff (Boot8Plus)\n - Removal of the annoying \"Unsupported hardware\" prompt\n - Better DPI support in aero.msstyles -> Credits: Vaporvance (high DPI classes from Aero10 that will be ported to Windows 7)\n - Integration of Microsoft Visual C++ Redistributable AIO -> Credits: Microsoft Corporation (Visual C++) and abbodi1406 (VC++ AIO repack)\n - Disk Cleanup from Windows 8 build 7861 -> Credits: Jevil7452\n - Windows 8 build 7861's PDF Reader -> Credits: Jevil7452\n - Windows 10 20H1's System Information -> Credits: Jevil7452\n - Windows 11 24H2's timeout.exe command\n - Windows 10 1709's XPS Viewer\n - Windows 11 24H2's sudo.exe command\n - Windows 10 build 9845's Notepad\n - Windows Management Framework 5.1\n - Segoe UI Emoji\n - Microsoft Agent\n - WinHlp32\n - Work Folders\n - Restore Windows Journal\n - Microsoft Camera Codec Pack\n\nInstallation\nCautionFailure to follow instructions properly will result in a bricked system! We do not take responsibility for this unless this is a legitimate bug in the installer!\n\nImportantRAID/Intel RST only works on specific systems!\n\nWarningBoth versions of the Windows 7 Service Pack 2 are x64 only! Don't file issues over the lack of 32-bit hardware support as we do not plan to support 32-bit hardware. Consult the FAQ for more information.\n\nISO installation\nImportantThe ISO releases are for clean installs only. For in-place installs, please use the installer once we release a working version of it.\n\nPick the UEFI or Legacy Boot version, depending on what your system uses\nFlash it onto a DVD or a USB flash drive\nBoot from the Windows 7 install media on the machine you wish to install it in\nProceed as usual\nFinish the out of box experience\n\nIn-place intallation\n\nDownload the Windows 7 SP2 installer under the releases of this repository\nFollow the steps in the installer as usual\n\nWarningIf the installer is stuck at a certain percentage (during the Upgrading Windows phase), don't turn off your computer! Doing so will brick your system!\n\nFAQ\nQ: My system is 32-bit in hardware. Why won't the installer and the ISO run?\nA: Supporting both 64-bit and 32-bit Windows would be very time consuming, so we chose to support only 64-bit systems. Please don't file any issues regarding the lack of 32-bit support as we have no interests of making any releases targeting 32-bit hardware.\nQ: Why don't you include ESU updates?\nA: ESU updates will be rolled out by Microsoft until 2026, and unfortunately adding ESU updates will be time consuming as it requires us to roll out new releases every time a batch of ESU updates gets rolled out.\nQ: Why VxKex instead of the dotexe1337 Windows 7 Extended Kernel?\nA: VxKex is safer than dotexe's Windows 7 Extended Kernel as it relies on external DLLs.\nQ: Does this include custom integrated GPU dri-\nA: NO\nQ: Why aren't my drives appearing in the Windows Setup screen?\nA: If you are using an RAID/RST configuration, it may well likely be that the drivers installed do not work.\nOther credits\n\nK4sum1: Inspiration for creating Windows 7 SP2\nGMM2003: \"Under construction\" wallpaper used in Public Beta builds\nOur contributors\nAnyone who reports bugs constantly",
    "summary": {
      "en": "**Summary of Windows 7 Service Pack 2**\n\nWindows 7 Service Pack 2 is a project aimed at updating and enhancing Windows 7 for better usability on newer machines. It includes updates, tweaks, and new features, but it is still in development, so users may encounter bugs.\n\n**Key Features:**\n- Updates from before 2020, including Windows Embedded Standard 7 updates.\n- New tools like Snipping Tool from Windows 10, Paint from Windows 8, and updated Task Manager.\n- Support for modern hardware features like USB 3.0, NVMe, TPM 2.0, and UEFI.\n- Integration of various applications and codecs for better functionality.\n- Removal of the \"Unsupported hardware\" prompt and improved DPI support.\n\n**Installation Instructions:**\n- The project only supports 64-bit systems; 32-bit support is not planned.\n- ISO files are meant for clean installs only, while an in-place installer will be available later.\n- Users must follow installation instructions carefully to avoid system issues.\n\n**FAQs:**\n- 32-bit systems are not supported due to the complexity of maintaining both versions.\n- ESU updates are not included because they require constant updates from Microsoft.\n- VxKex is preferred for safety over other kernel options.\n\n**Credits and Acknowledgments:**\nThe project was inspired by various contributors and includes many credits for specific features and tools.\n\n**Warning:** Due to its unfinished state, users should report any bugs they encounter.",
      "ko": "Windows 7 ì„œë¹„ìŠ¤ íŒ© 2ëŠ” ìµœì‹  ê¸°ê¸°ì—ì„œ Windows 7ì˜ ì‚¬ìš©ì„±ì„ ê°œì„ í•˜ê¸° ìœ„í•œ ì—…ë°ì´íŠ¸ ë° í–¥ìƒ í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤. ì´ í”„ë¡œì íŠ¸ëŠ” ì—…ë°ì´íŠ¸, ì¡°ì • ì‚¬í•­, ìƒˆë¡œìš´ ê¸°ëŠ¥ì„ í¬í•¨í•˜ê³  ìˆì§€ë§Œ ì•„ì§ ê°œë°œ ì¤‘ì´ë¯€ë¡œ ì‚¬ìš©ìë“¤ì€ ë²„ê·¸ë¥¼ ê²½í—˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nì£¼ìš” íŠ¹ì§•ìœ¼ë¡œëŠ” 2020ë…„ ì´ì „ì˜ ì—…ë°ì´íŠ¸ì™€ Windows Embedded Standard 7 ì—…ë°ì´íŠ¸ê°€ í¬í•¨ë©ë‹ˆë‹¤. Windows 10ì˜ ìŠ¤ë‹ˆí•‘ íˆ´, Windows 8ì˜ í˜ì¸íŠ¸, ì—…ë°ì´íŠ¸ëœ ì‘ì—… ê´€ë¦¬ìì™€ ê°™ì€ ìƒˆë¡œìš´ ë„êµ¬ë„ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤. USB 3.0, NVMe, TPM 2.0, UEFIì™€ ê°™ì€ í˜„ëŒ€ í•˜ë“œì›¨ì–´ ê¸°ëŠ¥ì„ ì§€ì›í•˜ë©°, ë‹¤ì–‘í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ê³¼ ì½”ë±ì´ í†µí•©ë˜ì–´ ê¸°ëŠ¥ì„±ì´ í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤. \"ì§€ì›ë˜ì§€ ì•ŠëŠ” í•˜ë“œì›¨ì–´\" ê²½ê³ ê°€ ì œê±°ë˜ì—ˆê³ , DPI ì§€ì›ë„ ê°œì„ ë˜ì—ˆìŠµë‹ˆë‹¤.\n\nì„¤ì¹˜ ë°©ë²•ì€ 64ë¹„íŠ¸ ì‹œìŠ¤í…œë§Œ ì§€ì›ë˜ë©°, 32ë¹„íŠ¸ ì‹œìŠ¤í…œì— ëŒ€í•œ ì§€ì›ì€ ê³„íšë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. ISO íŒŒì¼ì€ ê¹¨ë—í•œ ì„¤ì¹˜ë¥¼ ìœ„í•œ ê²ƒì´ë©°, ë‚˜ì¤‘ì— ì¸í”Œë ˆì´ìŠ¤ ì„¤ì¹˜ í”„ë¡œê·¸ë¨ì´ ì œê³µë  ì˜ˆì •ì…ë‹ˆë‹¤. ì‚¬ìš©ìëŠ” ì‹œìŠ¤í…œ ë¬¸ì œë¥¼ í”¼í•˜ê¸° ìœ„í•´ ì„¤ì¹˜ ì§€ì¹¨ì„ ì£¼ì˜ ê¹Šê²Œ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤.\n\nìì£¼ ë¬»ëŠ” ì§ˆë¬¸ìœ¼ë¡œëŠ” 32ë¹„íŠ¸ ì‹œìŠ¤í…œì€ ë‘ ë²„ì „ì„ ëª¨ë‘ ìœ ì§€í•˜ëŠ” ë³µì¡ì„± ë•Œë¬¸ì— ì§€ì›ë˜ì§€ ì•Šìœ¼ë©°, ESU ì—…ë°ì´íŠ¸ëŠ” Microsoftì˜ ì§€ì†ì ì¸ ì—…ë°ì´íŠ¸ê°€ í•„ìš”í•˜ê¸° ë•Œë¬¸ì— í¬í•¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. VxKexëŠ” ë‹¤ë¥¸ ì»¤ë„ ì˜µì…˜ë³´ë‹¤ ì•ˆì „ì„± ë•Œë¬¸ì— ì„ í˜¸ë©ë‹ˆë‹¤.\n\nì´ í”„ë¡œì íŠ¸ëŠ” ì—¬ëŸ¬ ê¸°ì—¬ìë“¤ì˜ ì˜ê°ì„ ë°›ì•˜ìœ¼ë©°, íŠ¹ì • ê¸°ëŠ¥ê³¼ ë„êµ¬ì— ëŒ€í•œ ë§ì€ í¬ë ˆë”§ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ê²½ê³ ë¡œ, ì•„ì§ ì™„ì„±ë˜ì§€ ì•Šì€ ìƒíƒœì´ë¯€ë¡œ ì‚¬ìš©ìëŠ” ë°œê²¬í•œ ë²„ê·¸ë¥¼ ë³´ê³ í•´ì•¼ í•©ë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "71fc049725fae7c3",
    "title": {
      "en": "Hyperlegibility",
      "ko": "í•˜ì´í¼ê°€ë…ì„±",
      "ja": null
    },
    "type": "story",
    "url": "https://www.notboring.co/p/hyperlegibility",
    "score": 18,
    "by": "jger15",
    "time": 1742907743,
    "content": "Share this postNot Boring by Packy McCormickHyperlegibilityCopy linkFacebookEmailNotesMoreDiscover more from Not Boring by Packy McCormickTech strategy and analysis, but not boring. Over 241,000 subscribersSubscribeBy subscribing,  I agree to Substack's Terms of Use, and acknowledge its Information Collection Notice and Privacy Policy.Already have an account? Sign inHyperlegibilityTrading Secrets for AttentionMar 25, 2025152Share this postNot Boring by Packy McCormickHyperlegibilityCopy linkFacebookEmailNotesMore2423ShareWelcome to the 1,016 newly Not Boring people who have joined us since our last essay! If you havenâ€™t subscribed, join 242,048 smart, curious folks by subscribing here:SubscribeTodayâ€™s Weekly Dose is brought to you byâ€¦ VantaAs a startup founder, finding product-market fit is your top priority.But landing bigger customers requires SOC 2 or ISO 27001 complianceâ€”a time-consuming process that pulls you away from building and shipping.Thatâ€™s where Vanta comes in.By automating up to 90% of the work needed for SOC 2, ISO 27001, and more, Vanta gets you compliant fast. Vanta opens the door to growth.It works. Over 9,000 companies like Atlassian, Factory, and Chili Piper streamline compliance with Vantaâ€™s automation and trusted network of security experts. Whether youâ€™re closing your first deal or gearing up for growth, Vanta makes compliance easy.Itâ€™s time to grow your ARR. Vanta can help Get $1,000 off Vanta here:Get $1,000 Off VantaHi friends ğŸ‘‹, Happy Tuesday! Sometimes, you write an essay and need to come up with a title. Sometimes, you have a title and need to come up with an essay. This is the latter.Letâ€™s get to it. HyperlegibilityWhen I was a kid, if I missed a UPenn basketball game one night, Iâ€™d have to wait until The Philadelphia Inquirer arrived the next morning, shake the dew off the bag, throw out the useless (non-Sports) sections, and search for the box score. Or watch Comcast SportsRise like a hawk to make sure I caught the 30 second Penn segment, whenever it came on.Today, when Puja decides not to stay up until 3am to watch the F1 Chinese Grand Prix, she records the race to watch when the kids nap the next day. Do you know how hard it is for her to avoid spoilers? Simply unlocking her phone is a live action game of Battleship.Information that was once hard to find is now hard to avoid.This is, of course, what the internet does. And it gets better at it all the time. But something Iâ€™ve noticed is that we do it to ourselves, too.Tyler Cowen says that he writes for the AIs now. That he writes in such a way and in such volume that the models of the future might know his mind as fully as is possible. Maybe, given the volume, the models will give his words more weight.In a recent profile in The Economist's 1843 Magazine, Cowen describes the inputs that produce those AI-legible outputs:Cowen calls himself â€œhyperlexicâ€. On a good day, he claims to read four or five books. Secretly, I timed him at 30 seconds per page reading a dense tract by Martin Luther. Later, I sat next to him while he went through an economics paper. He read it at the speed of someone checking that the pages were correctly ordered.Hyperlexic. I like that word. Hyperlexia is when a kid learns to read unusually early and surprisingly well. Cowen certainly knows this. He knows a lot. Heâ€™s repurposed the word to mean something like: extremely fast, prolific, and retentive reader; someone for whom reading is very easy.If 'hyperlexic' describes extraordinary reading ability, then let me propose a complementary word for extraordinary readability: Hyperlegible.Hyperlegibility defines our current era so comprehensively that I was shocked when I googled the term and found only references to fonts.So pardon me, yoink, Iâ€™m taking this one. HyperlegibleTM. You can use it, too.Fifteen years ago, after reading James C. Scottâ€™s Seeing Like a State, Venkatesh Rao (VGR) wrote about A Big Little Idea Called Legibility. Before the book had become a cult classic in tech circles (VGR helped make that happen, with blog posts like this oneâ€¦ he made Scottâ€™s work more legible), VGR explained its core concept: legibility.James Scott via Venkatesh RaoThe picture above illustrates an attempt to make forests legible. Because wild forests like the one on the left were â€œillegibleâ€ to tax authorities, â€œscientific forestryâ€ transformed them into â€œorderly strands of the highest-yielding varieties,â€ Rao writes. â€œThe resulting catastrophes â€“ better recognized these days as the problems of monoculture â€“ were inevitable.â€This was the general thrust: over and over, the state tries to impose order (legibility) on chaos (illegibility), disaster ensues.With that context, whatâ€™s fascinating about modern Hyperlegibility is that it is not the result of top-down action; we impose it on ourselves. Or Moloch does, at least.Hyperlegibility emerges with game theoretical certainty from each of our desire to win whatever game it is youâ€™re playing. Certainly, itâ€™s a consequence of playing The Great Online Game. In order for the right people and projects to find you, you must make yourself legible to them. To stand out in a sea of people making themselves legible, you must make yourself Hyperlegible: so easy to read and understand you rise to the top.Once you become aware of Hyperlegibility, you see it everywhere.Remember when The New York Times psy-opped the Laptop Class into making Personal User Manuals? â€œI get a little grumpy if I hadnâ€™t had my latte ;) Donâ€™t Slack me after 9pm ğŸ˜¡ Honestly Iâ€™m incredibly insecure and I take that out on my subordinates ğŸ¤·â€ Thatâ€™s Hyperlegibility.When NBA teams â€œsolveâ€ basketball by jacking up a lot of threes, thatâ€™s Hyperlegibility.When a venture capital firm blares its thesis to the world instead of farming it in secret, thatâ€™s Hyperlegibility.When Aella tweets a Sankey Diagram for her birthday orgy (NSFW), thatâ€™s Hyperlegibility.When a company shares its â€œARRâ€ numbers in real time instead of building in â€œStealth,â€ thatâ€™s Hyperlegibility.No judgment. When I write an essay and send it to you, thatâ€™s Hyperlegibility.Hyperlegibility isnâ€™t good or bad. Itâ€™s neither and both. But it certainly is. Information used to be the highest form of alpha. Now everyone bends over backwards to leak it.Through a combination of humanity getting ever-better at reading anything and humans becoming ever-more willing to make themselves legible, information is easier to find and understand than itâ€™s ever been.When I say weâ€™re getting better at reading anything, what I mean is that we have both all of humanityâ€™s accumulated information and modern tools by which to discover and decipher new information at our fingertips.Let me give you an example.I was reading Dominion the other day, the book by Tom Holland on the spread of Christianity, and found this paragraph particularly striking:For almost two and a half millennia, one of the inscriptions commissioned by Darius to justify his rule of the worldâ€”written in three distinct languages, and featuring a particularly imperious portrait of the king himselfâ€”had been preserved on the side of a mountain by the name of Bisitun. Carved into a cliff some two hundred feet above the road that led from the Iranian plateau to Iraq, its survival had been ensured by its sheer accessibility. The chance to risk life and limb in the cause of deciphering ancient scripts, however, was one that the odd adventurer might positively relish. One such was Henry Rawlinson, a British officer on secondment from India to the Persian court. He first scouted out Bisitun in 1835, scaling the cliff as best as he was able, and recording as much of the inscription as he could make out. Then, eight years later, he returned to the site properly equipped with planks and ropes. Balanced precariously on a ladder, he was able to complete his transcription. â€˜The interest of the occupation,â€™ he later recalled, â€˜entirely did away with any sense of danger.â€™ By 1845 Rawlinson had completed a full translation of the section written in Persian, and sent it for publication in London. The Great King Spoke once more.Thatâ€™s a long block quote, probably too long for an essay this length. But sacrificing flow, adding a little friction and heaviness, is the best I can do to give you a sense for the lengths people once went to to get information, to make the world more legible.Rawlinson spent a decade â€“ not the whole decade, but still â€“ in pursuit of information that you can now, thanks to his efforts, Google. In fact, I forgot the names of both Rawlinson and Bitisun, so a traditional in-book search came up fruitless. In the past, I would have spent, what, half an hour combing the book, or given up. Nowâ€¦Easy as.And letâ€™s say Rawlinson had never scaled Bitisun, that Dariusâ€™ words were still undiscovered. How would we get them today? A climb so treacherous as to â€œdo away with any sense of dangerâ€? No of course not. We would send up the drones, equipped with high resolution cameras and maybe some LiDAR, and use photogrammetry and machine learning to stitch the pictures together and make sense of their contents.What once took a decade might take a week, and the results are searchable in a second.There used to be this bit on the podcast Reply All where the showâ€™s producer Alex Blumberg would bring a tweet he didnâ€™t understand and co-hosts Alex Goldman and PJ Vogt would try to explain it to him. By the end, theyâ€™d try to get to three â€œYesesâ€ â€“ meaning that all three understood the tweet.Now, you just hit the little Grok button.It costs like $100 to read your whole genome. Our telescopes can see 13 billion years into the past. Luke Farritor pulled an ancient library from the ashes of a volcano. Elad Gil is funding efforts to translate â€œthe top 1,000 off-copyright books into all commonly spoken languages,â€ generate audio versions, and host language models that allow you to talk to and ask questions of each.Alexandria AIHenry Rawlinson smiles. Or weeps. I donâ€™t know. It must all seem so easy and weightless to him.The point, I hope, is clear. We are getting better at reading the world, just as a book that is entirely illegible to a two-year-old becomes entirely legible to a ten-year-old through improved skill.The second reason for Hyperlegibility is the more fascinating one: we are tripping over ourselves to make ourselves easier to read.Think Personal User Manuals. Think Tyler Cowen writing for the AIs. Think me, writing this.We are game theoretically driven to share more and more of our best ideas, the ones that we might have once exploited in silence.Hereâ€™s an example I like that hits close to home.Imagine youâ€™re a small emerging early stage venture capital fund. Youâ€™ve noticed something about the market that no one else has. Say you believe that quantum computing is closer than anyone else believes. Youâ€™ve identified a handful of promising companies that you want to back.What do you do? Do you keep it secret or tell the world?Well, what do you need to do in order to successfully invest against your thesis?First, youâ€™ll need to raise money from LPs. To do that, youâ€™ll need to spell out as clearly as possible why you believe quantum computing is more investable than everyone else does and which types of companies you think are most investable. Maybe you have a network already, and you can do all of this behind the scenes. Maybe you donâ€™t, and you need to yell your thesis from the rooftops: blog posts, podcast appearances, conference panels, whatever. One thing a differentiated view can get you is attention. So you trade a secret for the chance at money.Assuming you raise, youâ€™ll need to stand out to the companies you want to invest in. This is not the public markets; you canâ€™t just invest in whatever you choose. They need to choose you, too. Maybe in the early days, you can know everyone â€“ go to the conferences, meet them one-on-one, impress them with your insights and with the fact that you believe harder than anyone else does. Does that scale? Do your early investments pay off quickly enough to build a reputation in the community before other investors come in? How do you stand out?Say you convince companies to let you invest early, you need to help them continue to raise money from downstream capital. Which means part of your job is to make quantum legible to the very firms who might one day compete with you. Sure, while your category is small, unproven, weird, and risky, they might let you win at the early stage. But eventually, they wonâ€™t. Either way, the proximate issue is getting your companies funded so your investments donâ€™t go to zero before your ideas have had time to play out.In all three pieces of your job, you are incentivized in the short-term to make yourself and your ideas Hyperlegible so LPs, founders, and downstream capital can find you. And without the short-term, there is no long-term.Now imagine this dynamic playing out everywhere.My friend Tina He wrote an excellent essay last week, Jevons Paradox: a personal perspective. She noticed that instead of letting us work less, AI actually incentivizes working more. The more you can do in each minute, the higher the opportunity cost from not doing anything. The problem is, even if everyone agrees thatâ€™s not what we want, who blinks?If you work less, someone else will happily take your slice of the pie. She calls it a Malthusian Trap; itâ€™s like Scott Alexanderâ€™s Moloch or a Red Queenâ€™s Race: \"Now, here, you see, it takes all the running you can do, to keep in the same place. If you want to get somewhere else, you must run at least twice as fast as that!\"Same same here, with Hyperlegibility. You could opt out, stop publishing, encrypt yourself. Someone else will happily fill the vacuum.Attention is the scarce resource. Information you can get.Information, long alpha, becomes beta.Thereâ€™s a version of this essay that bemoans the fact that information is no longer precious.That would feel good, to mourn Friday nights at Blockbuster, metaphorically speaking, but it wouldnâ€™t be particularly useful.The question to ask is: assuming Hyperlegibility, what do I do?This is a question that Iâ€™ll probably explore over a bunch of essays, and without having the word, already have. Thereâ€™s the question of what to do as an emerging manager given the conundrum I laid out above. Thereâ€™s something about the growing relative importance of relationships, of â€œhaving a guy,â€ of agency and the ability to get things done. There is a reason that all of these ideas have become more popular recently (hint: itâ€™s Hyperlegibility). Thereâ€™s certainly something on the value of Vertical Integration, of how you chain things together to create new forms of value. The ideas in Most Human Wins are enhanced by thinking about Hyperlegibility. And I am quite certain that the more Hyperlegible most things become, the more people will crave mysteries and The Return of Magic.But for now, Iâ€™ll leave you with this: Hyperlegibility is our reality. Thereâ€™s no going back.There is a generation of people living among us who donâ€™t feel the same nostalgia for newspapers and â€œnot knowing the answer to something immediatelyâ€ that I do, because they never had those experiences in the first place. And theyâ€™re a preview of what happens when you take all of human knowledge as a commoditized input.Iâ€™ve been talking to more college students recently, and despite rumors of their demise, the kids are very alright. Maybe every generation thinks this, but Iâ€™ve walked away from a few recent conversations thinking, â€œIf I were competing with these people I would be COOKED.â€ Theyâ€™ve somehow read as much as I have but have the faster brains of youth. Itâ€™s a scary combination.The other day, I asked one of them, Malhar Manek, why so many of his peers seemed so scarily advanced. His answer was that they grew up on the internet, with access to all of the information imaginable. Not just the fire hose, but the blogs and newsletters and podcasts and YouTube videos that helped make sense of the stream. So it was easy for a relatively curious kid to figure out what to read to set a baseline, and then, baseline established while the brain is still fresh and curious, to jump off of that base of knowledge to ask their own questions. To help answer them, they have all of the internetâ€™s information, AI, and even one-DM-away access to experts.Iâ€™d never thought of it that way, because I didnâ€™t live it. But by making the world Hyperlegible, we helped create a generation of Hyperlegibility-Native Hyperlexics who take as an input the information we worked to turn into an output. And thus civilization evolves and compounds.A priori, I would have guessed that giving everyone access to the same information would lead to a convergence of goals. That doesnâ€™t seem to be happening. One of the people I spoke with wants to start a vertically integrated healthcare company, another wants to write a Great Book, and what Iâ€™ve heard very consistently from smart college kids is that their smartest friends are all working on biotech, specifically neuro, specifically brain-computer interfaces.Which is to say, if you think the world is Hyperlegible now, just wait.Thatâ€™s all for today! If you have a minute, go get SOC-2 or ISO 27001 compliant. While you do that, weâ€™ll be working hard on a Weekly Dose, and might even drop a new podcast on you in the interim. Weâ€™ll be back in your inboxâ€¦ soon.Thanks for reading,PackySubscribe to Not Boring by Packy McCormickLaunched 6 years agoTech strategy and analysis, but not boring. SubscribeBy subscribing,  I agree to Substack's Terms of Use, and acknowledge its Information Collection Notice and Privacy Policy.152Share this postNot Boring by Packy McCormickHyperlegibilityCopy linkFacebookEmailNotesMore2423Share",
    "summary": {
      "en": "The article \"Hyperlegibility\" by Packy McCormick discusses how the modern era has made information easier to access and understand, a phenomenon he calls \"Hyperlegibility.\" \n\nKey points include:\n\n1. **Changing Information Access**: In the past, finding specific information required significant effort, but now it's readily available. People are constantly trying to avoid spoilers and stay updated, which highlights the abundance of information.\n\n2. **Hyperlexic vs. Hyperlegible**: McCormick introduces the term \"Hyperlegible,\" contrasting it with \"hyperlexic,\" which describes someone who reads quickly and comprehensively. Hyperlegibility refers to how easily information can be consumed and understood.\n\n3. **Self-Imposed Clarity**: Unlike past efforts to make information legible through top-down approaches, today, people actively make themselves and their ideas more legible to stand out in a competitive environment. This includes sharing personal insights and professional strategies openly.\n\n4. **Game Theory and Attention**: The drive to be Hyperlegible is partly due to the competitive nature of the online world, where attention is a scarce resource. People are incentivized to share ideas and insights to attract opportunities and recognition.\n\n5. **Future Implications**: As Hyperlegibility increases, it shapes how information is consumed and shared, potentially leading to a generation that thrives on quick access to knowledge. This trend raises questions about the value of information and how it will continue to evolve.\n\nIn summary, the article explores the concept of Hyperlegibility, emphasizing its impact on how individuals and organizations navigate and share information in today's fast-paced, interconnected world.",
      "ko": "Packy McCormickì˜ \"Hyperlegibility\"ë¼ëŠ” ê¸€ì—ì„œëŠ” í˜„ëŒ€ ì‚¬íšŒê°€ ì •ë³´ë¥¼ ë” ì‰½ê²Œ ì ‘ê·¼í•˜ê³  ì´í•´í•  ìˆ˜ ìˆê²Œ ë§Œë“  í˜„ìƒì„ ì„¤ëª…í•©ë‹ˆë‹¤. ê·¸ëŠ” ì´ë¥¼ \"í•˜ì´í¼ë ˆì§€ë¹Œë¦¬í‹°\"ë¼ê³  ë¶€ë¦…ë‹ˆë‹¤.\n\nì²«ì§¸, ì •ë³´ ì ‘ê·¼ ë°©ì‹ì˜ ë³€í™”ì— ëŒ€í•´ ì´ì•¼ê¸°í•©ë‹ˆë‹¤. ê³¼ê±°ì—ëŠ” íŠ¹ì • ì •ë³´ë¥¼ ì°¾ê¸° ìœ„í•´ ë§ì€ ë…¸ë ¥ì´ í•„ìš”í–ˆì§€ë§Œ, ì§€ê¸ˆì€ ì‰½ê²Œ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‚¬ëŒë“¤ì€ ìŠ¤í¬ì¼ëŸ¬ë¥¼ í”¼í•˜ê³  ìµœì‹  ì •ë³´ë¥¼ ìœ ì§€í•˜ë ¤ê³  í•˜ë©°, ì´ëŠ” ì •ë³´ì˜ í’ë¶€í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.\n\në‘˜ì§¸, \"í•˜ì´í¼ë ˆì§€ë¹Œë¦¬í‹°\"ì™€ \"í•˜ì´í¼ë ‰ì‹\"ì˜ ì°¨ì´ë¥¼ ì„¤ëª…í•©ë‹ˆë‹¤. í•˜ì´í¼ë ‰ì‹ì€ ë¹ ë¥´ê³  í¬ê´„ì ìœ¼ë¡œ ì½ëŠ” ì‚¬ëŒì„ ì˜ë¯¸í•˜ëŠ” ë°˜ë©´, í•˜ì´í¼ë ˆì§€ë¹Œë¦¬í‹°ëŠ” ì •ë³´ê°€ ì–¼ë§ˆë‚˜ ì‰½ê²Œ ì†Œë¹„ë˜ê³  ì´í•´ë  ìˆ˜ ìˆëŠ”ì§€ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\n\nì…‹ì§¸, ìë°œì ì¸ ëª…í™•ì„±ì— ëŒ€í•´ ì–¸ê¸‰í•©ë‹ˆë‹¤. ê³¼ê±°ì—ëŠ” ì •ë³´ì˜ ê°€ë…ì„±ì„ ë†’ì´ê¸° ìœ„í•´ ìœ„ì—ì„œ ì•„ë˜ë¡œ ì ‘ê·¼í–ˆì§€ë§Œ, ì˜¤ëŠ˜ë‚  ì‚¬ëŒë“¤ì€ ê²½ìŸ í™˜ê²½ì—ì„œ ë‘ë“œëŸ¬ì§€ê¸° ìœ„í•´ ìŠ¤ìŠ¤ë¡œì™€ ìì‹ ì˜ ì•„ì´ë””ì–´ë¥¼ ë” ëª…í™•í•˜ê²Œ ë§Œë“¤ê³  ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ê°œì¸ì ì¸ í†µì°°ì´ë‚˜ ì „ë¬¸ì ì¸ ì „ëµì„ ê³µê°œì ìœ¼ë¡œ ê³µìœ í•˜ëŠ” ê²ƒì„ í¬í•¨í•©ë‹ˆë‹¤.\n\në„·ì§¸, ê²Œì„ ì´ë¡ ê³¼ ì£¼ì˜ë ¥ì— ëŒ€í•œ ë¶€ë¶„ë„ ë‹¤ë£¹ë‹ˆë‹¤. í•˜ì´í¼ë ˆì§€ë¹Œë¦¬í‹°ë¥¼ ì¶”êµ¬í•˜ëŠ” ê²ƒì€ ì˜¨ë¼ì¸ ì„¸ê³„ì˜ ê²½ìŸì ì¸ ì„±ê²© ë•Œë¬¸ì´ë©°, ì—¬ê¸°ì„œ ì£¼ì˜ë ¥ì€ ê·€í•œ ìì›ì…ë‹ˆë‹¤. ì‚¬ëŒë“¤ì€ ê¸°íšŒì™€ ì¸ì •ì„ ì–»ê¸° ìœ„í•´ ì•„ì´ë””ì–´ì™€ í†µì°°ì„ ê³µìœ í•˜ë„ë¡ ìœ ë„ë©ë‹ˆë‹¤.\n\në§ˆì§€ë§‰ìœ¼ë¡œ, í•˜ì´í¼ë ˆì§€ë¹Œë¦¬í‹°ê°€ ì¦ê°€í•¨ì— ë”°ë¼ ì •ë³´ ì†Œë¹„ì™€ ê³µìœ  ë°©ì‹ì´ ì–´ë–»ê²Œ ë³€í™”í• ì§€ë¥¼ ë…¼ì˜í•©ë‹ˆë‹¤. ì´ëŠ” ì§€ì‹ì— ëŒ€í•œ ë¹ ë¥¸ ì ‘ê·¼ì„ ì¤‘ì‹œí•˜ëŠ” ì„¸ëŒ€ë¥¼ ë§Œë“¤ì–´ë‚¼ ìˆ˜ ìˆìœ¼ë©°, ì •ë³´ì˜ ê°€ì¹˜ì™€ ê·¸ ì§„í™” ë°©ì‹ì— ëŒ€í•œ ì§ˆë¬¸ì„ ì œê¸°í•©ë‹ˆë‹¤.\n\nì´ ê¸€ì€ í•˜ì´í¼ë ˆì§€ë¹Œë¦¬í‹° ê°œë…ì„ íƒêµ¬í•˜ë©°, ì˜¤ëŠ˜ë‚ ì˜ ë¹ ë¥´ê²Œ ë³€í™”í•˜ëŠ” ìƒí˜¸ ì—°ê²°ëœ ì„¸ê³„ì—ì„œ ê°œì¸ê³¼ ì¡°ì§ì´ ì •ë³´ë¥¼ ì–´ë–»ê²Œ íƒìƒ‰í•˜ê³  ê³µìœ í•˜ëŠ”ì§€ì— ëŒ€í•œ ì˜í–¥ì„ ê°•ì¡°í•©ë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "aa1e29b0af3950ea",
    "title": {
      "en": "LibreOffice downloads on the rise as users look to avoid subscription costs",
      "ko": "êµ¬ë…ë¹„ ê±±ì • ì—†ëŠ” ë¦¬ë¸Œë ˆì˜¤í”¼ìŠ¤ ì¸ê¸° ê¸‰ìƒìŠ¹",
      "ja": null
    },
    "type": "story",
    "url": "https://www.computerworld.com/article/3840480/libreoffice-downloads-on-the-rise-as-users-look-to-avoid-subscription-costs.html",
    "score": 284,
    "by": "cable2600",
    "time": 1743121248,
    "content": "The free open-source Microsoft Office alternative is being downloaded by nearly 1 million users a week.\n\n\t\t\t\t\t\t\tCredit: \t\t\t\t\t\t\t\t\t\t\t\t\t\t\tNiroDesign / Getty Images\n\nInterest inLibreOffice, the open-source alternative to Microsoft Office, is on the rise, with weekly downloads of its software package close to 1 million a week. Thatâ€™s thehighest download number since 2023.\n\nLibreOffice, which runs on Windows, Linux, and macOS, is a standalone desktop office productivity software that is free to use. Downloads have picked up since The Document Foundation, which manages its development,released version 25.2 last week.\n\nIt has emerged as the most popular open-source suite, with alternative versions such as Apacheâ€™s OpenOffice losing steam. The last version of OpenOffice was released in 2023.\n\nâ€œWe estimate around 200 million [LibreOffice] users, but itâ€™s important to note that we respect usersâ€™ privacy and donâ€™t track them, so we canâ€™t say for sure,â€ said Mike Saunders, an open-source advocate and a deputy to the board of directors at The Document Foundation.\n\nThere is still noteworthy interest in LibreOffice as a standalone desktop alternative to paid office productivity suites, said Jason Wong, distinguished vice president and analyst at Gartner. â€œUsually these are clients seeking to keep their on-premises implementation, given that both Microsoft and Google have focused on their cloud offerings,â€ Wong said.\n\nCost is a factor for evaluating software suites like LibreOffice, Wong said. â€œThe downside is the additional specialized resources and new skills needed to maintain the [software],â€ hesaid.\n\nDownloads of LibreOffice have been steadily climbing with each new version, Saunders said.\n\nThough LibreOffice has traditionally been a favorite of home users, thereâ€™s growing interest in businesses and government, Saunders said.The northern German state of Schleswig-Holstein last year said it would move 30,000 PCs fromMicrosoft Officeto LibreOffice.\n\nâ€œThe majority of our users â€” 85% â€” are on Windows, followed by macOS and then Linux,â€ Saunders said.\n\nMany desktop Linux distributions pre-install LibreOffice, but itâ€™s unclear how many users that represents.\n\nLibreOffice users typically want a straightforward interface, Saunders said. â€œThey donâ€™t want subscriptions, and they donâ€™t want AI being â€˜helpfulâ€™ by poking its nose into their work â€” it reminds them of Clippy from the bad old days,â€ he said.\n\nThere are genuine use cases for generative AI tools, but many users prefer to opt-in to it and choose when and where to enable it. â€œWe have zero plans to put AI into LibreOffice. But we understand the value of some AI tools and are encouraging developers to create â€¦ extensions that use AI in a responsible way,â€ Saunders said.\n\nAlthough there are cloud-based versions of OpenOffice, The Document Foundation has focused on the desktop version, Saunders said.\n\n\t\t\tRelated content\n\n\t\t\t\t\tTip\n\n\t\t\t\t6 advanced Gboard tricks for smarter Android typing\n\n\t\t\t\t\t\tBy JR Raphael\n\n\t\t\t\t\t\tMar 28, 2025\n\n\t\t\t\t\t\t\t11 mins\n\n\t\t\t\t\t\t\t\tAndroid\n\n\t\t\t\t\t\t\t\tGoogle\n\n\t\t\t\t\t\t\t\tMobile Apps\n\n\t\t\t\t\tOpinion\n\n\t\t\t\tThe secret to using generative AI effectively\n\n\t\t\t\t\t\tBy Chris Hoffman\n\n\t\t\t\t\t\tMar 26, 2025\n\n\t\t\t\t\t\t\t10 mins\n\n\t\t\t\t\t\t\t\tChatbots\n\n\t\t\t\t\t\t\t\tGenerative AI\n\n\t\t\t\t\t\t\t\tWindows\n\n\t\t\t\t\tTip\n\n\t\t\t\tGee whiz, Gboard! An invaluable new Android typing upgrade\n\n\t\t\t\t\t\tBy JR Raphael\n\n\t\t\t\t\t\tMar 26, 2025\n\n\t\t\t\t\t\t\t5 mins\n\n\t\t\t\t\t\t\t\tAndroid\n\n\t\t\t\t\t\t\t\tGoogle\n\n\t\t\t\t\t\t\t\tKeyboards\n\n\t\t\t\t\tNews\n\n\t\t\t\tOtter.aiâ€™s voice-activated AI agent can answer questions during online meetings\n\n\t\t\t\t\t\tBy Agam Shah\n\n\t\t\t\t\t\tMar 25, 2025\n\n\t\t\t\t\t\t\t4 mins\n\n\t\t\t\t\t\t\t\tGenerative AI\n\n\t\t\t\t\t\t\t\tProductivity Software\n\n\t\t\t\t\t\t\t\tVideoconferencing\n\n\t\t\tOther Sections\n\n\t\t\t\t\t\t\t\tPodcasts\n\n\t\t\t\t\t\t\t\tVideos\n\n\t\t\t\t\t\t\t\tResources\n\n\t\t\t\t\t\t\t\tEvents\n\n\t\t\t\t\t\t\t\tSpotlight: Managing modern risks\n\n\t\t\t\t\tSUBSCRIBE TO OUR NEWSLETTER\n\n\t\t\t\tFrom our editors straight to your inbox\n\n\t\t\tGet started by entering your email address below.\n\n\t\t\t\t\t\t\tPlease enter a valid email address\n\n\t\t\t\t\tSubscribe",
    "summary": {
      "en": "LibreOffice, a free open-source alternative to Microsoft Office, is becoming increasingly popular, with nearly 1 million downloads each week. This surge follows the release of version 25.2 by The Document Foundation. LibreOffice is available on Windows, Linux, and macOS, and is now the leading open-source office suite, while alternatives like OpenOffice are declining.\n\nThe Document Foundation estimates there are around 200 million LibreOffice users, although they do not track user data for privacy reasons. Interest in LibreOffice is growing among businesses and government entities, partly due to the cost savings compared to paid software like Microsoft Office.\n\nMost users (85%) use LibreOffice on Windows, and many Linux distributions come with it pre-installed. Users appreciate its simple interface and dislike subscription models or intrusive AI features. The foundation has no plans to integrate AI into LibreOffice but supports responsible AI extensions developed by others. \n\nOverall, LibreOffice continues to gain traction as a reliable, cost-effective option for both individual and organizational use.",
      "ko": "ë¦¬ë¸Œë ˆì˜¤í”¼ìŠ¤ëŠ” ë§ˆì´í¬ë¡œì†Œí”„íŠ¸ ì˜¤í”¼ìŠ¤ì˜ ë¬´ë£Œ ì˜¤í”ˆì†ŒìŠ¤ ëŒ€ì•ˆìœ¼ë¡œ, ë§¤ì£¼ ê±°ì˜ 100ë§Œ ë²ˆ ë‹¤ìš´ë¡œë“œë˜ê³  ìˆì–´ ì¸ê¸°ë¥¼ ëŒê³  ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ì„±ì¥ì€ ë¬¸ì„œ ì¬ë‹¨(The Document Foundation)ì´ 25.2 ë²„ì „ì„ ì¶œì‹œí•œ ì´í›„ ë”ìš± ë‘ë“œëŸ¬ì§€ê³  ìˆìŠµë‹ˆë‹¤. ë¦¬ë¸Œë ˆì˜¤í”¼ìŠ¤ëŠ” ìœˆë„ìš°, ë¦¬ëˆ…ìŠ¤, macOSì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆìœ¼ë©°, í˜„ì¬ëŠ” ì£¼ìš” ì˜¤í”ˆì†ŒìŠ¤ ì˜¤í”¼ìŠ¤ ì œí’ˆêµ°ìœ¼ë¡œ ìë¦¬ ì¡ê³  ìˆìŠµë‹ˆë‹¤. ë°˜ë©´, ì˜¤í”ˆì˜¤í”¼ìŠ¤ì™€ ê°™ì€ ëŒ€ì•ˆì€ ì ì°¨ ê°ì†Œí•˜ê³  ìˆìŠµë‹ˆë‹¤.\n\në¬¸ì„œ ì¬ë‹¨ì€ ì•½ 2ì–µ ëª…ì˜ ë¦¬ë¸Œë ˆì˜¤í”¼ìŠ¤ ì‚¬ìš©ìê°€ ìˆì„ ê²ƒìœ¼ë¡œ ì¶”ì •í•˜ê³  ìˆì§€ë§Œ, ê°œì¸ ì •ë³´ ë³´í˜¸ë¥¼ ì´ìœ ë¡œ ì‚¬ìš©ì ë°ì´í„°ë¥¼ ì¶”ì í•˜ì§€ ì•Šê³  ìˆìŠµë‹ˆë‹¤. ë¦¬ë¸Œë ˆì˜¤í”¼ìŠ¤ì— ëŒ€í•œ ê´€ì‹¬ì€ ê¸°ì—…ê³¼ ì •ë¶€ ê¸°ê´€ì—ì„œë„ ì¦ê°€í•˜ê³  ìˆìœ¼ë©°, ì´ëŠ” ë§ˆì´í¬ë¡œì†Œí”„íŠ¸ ì˜¤í”¼ìŠ¤ì™€ ê°™ì€ ìœ ë£Œ ì†Œí”„íŠ¸ì›¨ì–´ì— ë¹„í•´ ë¹„ìš© ì ˆê° íš¨ê³¼ê°€ ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.\n\nëŒ€ë¶€ë¶„ì˜ ì‚¬ìš©ì(85%)ê°€ ìœˆë„ìš°ì—ì„œ ë¦¬ë¸Œë ˆì˜¤í”¼ìŠ¤ë¥¼ ì‚¬ìš©í•˜ê³  ìˆìœ¼ë©°, ë§ì€ ë¦¬ëˆ…ìŠ¤ ë°°í¬íŒì— ê¸°ë³¸ì ìœ¼ë¡œ ì„¤ì¹˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì‚¬ìš©ìë“¤ì€ ê°„ë‹¨í•œ ì¸í„°í˜ì´ìŠ¤ë¥¼ ë†’ì´ í‰ê°€í•˜ë©°, êµ¬ë… ëª¨ë¸ì´ë‚˜ ë¶ˆí•„ìš”í•œ ì¸ê³µì§€ëŠ¥ ê¸°ëŠ¥ì„ ì‹«ì–´í•©ë‹ˆë‹¤. ë¬¸ì„œ ì¬ë‹¨ì€ ë¦¬ë¸Œë ˆì˜¤í”¼ìŠ¤ì— ì¸ê³µì§€ëŠ¥ì„ í†µí•©í•  ê³„íšì€ ì—†ì§€ë§Œ, ë‹¤ë¥¸ ê°œë°œìë“¤ì´ ë§Œë“  ì±…ì„ ìˆëŠ” ì¸ê³µì§€ëŠ¥ í™•ì¥ì„ ì§€ì›í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n\nì „ë°˜ì ìœ¼ë¡œ ë¦¬ë¸Œë ˆì˜¤í”¼ìŠ¤ëŠ” ê°œì¸ê³¼ ì¡°ì§ ëª¨ë‘ì—ê²Œ ì‹ ë¢°í•  ìˆ˜ ìˆê³  ë¹„ìš© íš¨ìœ¨ì ì¸ ì˜µì…˜ìœ¼ë¡œ ê³„ì†í•´ì„œ ì¸ê¸°ë¥¼ ì–»ê³  ìˆìŠµë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "2480187f412ae58a",
    "title": {
      "en": "Blender releases their Oscar winning version tool",
      "ko": "ë¸”ë Œë”, ì˜¤ìŠ¤ì¹´ íˆ´ ê³µê°œ!",
      "ja": null
    },
    "type": "story",
    "url": "https://www.blender.org/download/releases/4-4/",
    "score": 777,
    "by": "babuloseo",
    "time": 1743035223,
    "content": "Splash artwork: Flow Â© Dream Well Studio, Sacrebleu Productions, Take FiveImage licensed under CC-BY-SA â€“ https://flow.movie/\n\nWhatâ€™s New Recap\n\nRound-up of whatâ€™s new in Blender 4.4, in detail.\n\nBlender 4.4 new features overview by Jonathan Lampel from CGCookie, Harry Blends, Paul Caggegi, and Wayne Dixon.\n\nQUALITY BLEND\n\nBlender 4.4 is all about stability. During the 2024â€“2025 northern hemisphere winter, Blender developers doubled down on quality and stability in a group effort called â€œWinter of Quality.â€\n\n\t\tAmount of high severity bugs since January 1st, 2025\n\nWinter of Quality\n\nIn just a few months, developers fixed over 700 reported issues, revisited old bug reports, and addressed unreported problems.\n\nAlongside bug fixes, Winter of Quality also included tackling technical debt and improving documentation.\n\nRead Blog Post\n\nIssues Addressed per Module\n\n\t\t\t\t\t\t\t\t\t\t\t\t\tAnimation & Rigging: 37\n\n\t\t\t\t\t\t\t\t\t\t\t\t\tAsset System: 9\n\n\t\t\t\t\t\t\t\t\t\t\t\t\tCore: 15\n\n\t\t\t\t\t\t\t\t\t\t\t\t\tGrease Pencil: 147\n\n\t\t\t\t\t\t\t\t\t\t\t\t\tModeling: 45\n\n\t\t\t\t\t\t\t\t\t\t\t\t\tNodes & Physics: 80\n\n\t\t\t\t\t\t\t\t\t\t\t\t\tPipeline & IO: 22\n\n\t\t\t\t\t\t\t\t\t\t\t\t\tPlatforms, Builds & Tests: 5\n\n\t\t\t\t\t\t\t\t\t\t\t\t\tPython API: 21\n\n\t\t\t\t\t\t\t\t\t\t\t\t\tRender & Cycles: 53\n\n\t\t\t\t\t\t\t\t\t\t\t\t\tSculpt, Paint & Texture: 45\n\n\t\t\t\t\t\t\t\t\t\t\t\t\tUser Interface: 119\n\n\t\t\t\t\t\t\t\t\t\t\t\t\tVFX & Video: 51\n\n\t\t\t\t\t\t\t\t\t\t\t\t\tViewport & EEVEE: 47\n\n\t\t\t\t\t\t#word-cloud-block_ee6590eb760be9aa9e6087741d18482e {\n\t\t\t\tcolor: #ffffff;\n\t\t\t}\n\t\t\t\t\t\t\t\t\t#word-cloud-block_ee6590eb760be9aa9e6087741d18482e .block-words-cloud-categories > div{\n\t\t\t\tbackground: #ff3a3a;\n\t\t\t}\n\t\t\t#word-cloud-block_ee6590eb760be9aa9e6087741d18482e.block-word-cloud > ul > li strong {\n\t\t\t\tcolor: #ff3a3a;\n\t\t\t}\n\nACTION PACKED\n\nBlender 4.4 introduces Action Slots, revolutionizing animation workflows by letting multiple data-blocks share a single Action.\n\nWHAT AREACTION SLOTS?\n\nBefore Action Slots, each data-block specific animationâ€”like an objectâ€™s position, a cameraâ€™s depth of field, or a materialâ€™s shader propertiesâ€”needed its own separate Action. This made it difficult to animate multiple elements together or share animations between objects or even projects.\n\nFor example, if you wanted to animate a camera moving while also changing its depth of field, youâ€™d need two separate Actions, which couldnâ€™t be easily linked or reused.\n\nNow you can mix all sorts of animations such as an objectâ€™s position, its material properties, even compositing effectsâ€”all within a single Action.\n\nRelease Notes\n\nRead Manual\n\nMORE ANIMATION\n\n\t\t\tConstraints\n\n\t\t\t\t\t\t\tRelationship Lines for constraints are no longer drawn when there is no target.\n\n\t\t\tGraph Editor\n\n\t\t\t\t\t\t\tNew F-Curve Noise modifer algorithm.\n\n\t\t\tRigging\n\n\t\t\t\t\t\t\tBone collection membership is now mirrored when symmetrizing an armature.\n\n\t\t\t\t\t\t\tN-panel normalization now supports locking multiple vertex groups.\n\n\t\t\t\t\t\t\tRemoving a modifier, constraint, or shape key also deletes its driver.\n\n\t\t\tPython API\n\n\t\t\t\t\t\t\tConceptual changes in the API.\n\n\t\t\tPose Library\n\n\t\t\t\t\t\t\tMajor overhaul to Pose Assets to improve the user experience.\n\n\t\t\t\t\t\t\tDocumentation: User Manual update.\n\n\t\t\t\t\t\t#word-cloud-block_b85d66c7a871960db7d4f62fc4679261 {\n\t\t\t\tcolor: #ffffff;\n\t\t\t}\n\t\t\t\t\t\t\t\t\t#word-cloud-block_b85d66c7a871960db7d4f62fc4679261 .block-words-cloud-categories > div{\n\t\t\t\tbackground: #0a0000;\n\t\t\t}\n\t\t\t#word-cloud-block_b85d66c7a871960db7d4f62fc4679261.block-word-cloud > ul > li strong {\n\t\t\t\tcolor: #0a0000;\n\t\t\t}\n\nVSE: Vastly Superior Editing\n\nThe Video Sequencer continues to improve with quality-of-life upgrades for text editing, expanded support for codecs including H.265 and 10/12-bit videos, and performance improvements that make editing faster than ever.\n\nEDIT TEXT ON THE SPOT\n\nIntroducing: Edit mode for text strips in Preview!\n\nSimply press Tab and type away.\n\nFIND YOUR CENTER\n\nMulti-line text strips can now be properly aligned to the left, right, or center.\n\nFASTEREDITING EVERYTHING\n\nBuilding proxies for image sequences is faster now.\n\nPreview playback performance of float/HDR content is faster now.\n\nText strip background fill â€œBoxâ€ is several times faster for large fill areas.\n\nCurves, Hue Correct, White Balance modifiers are 1.5x-2x faster now.\n\nMany sequencer effects are slightly faster now thanks to more efficient multi-threading.\n\nVIDEOBEYOND\n\nBlender 4.4 adds support for rendering videos using the H.265/HEVC codec.\n\nVideos are now rendered in BT.709 color space now, preventing playback inconsistencies from the previously unspecified color space.\n\nAdditionally, video playback YUV->RGB conversion is more accurate now, fixing color shifts and banding in dark regions.\n\nBlender now supports 10 and 12 bit/channel videos!\n\nDuring rendering, you can set a color depth of 10 or 12 bits for supported codecs (10 bit for H.264, H.265, AV1, 12 bit for H.265, AV1).\n\nWhen reading 10-bit or 12-bit videos, they are loaded as floating-point images.\n\nA BITMORE\n\nEVEN MORE SEQUENCER\n\n\t\t\t\t\t\t\t\t\t\t\t\t\tImproved layout for Text strip properties.\n\n\t\t\t\t\t\t\t\t\t\t\t\t\tNew roundness property for text strips background box.\n\n\t\t\t\t\t\t\t\t\t\t\t\t\tCustom font text strips no longer default to other fonts for missing characters.\n\n\t\t\t\t\t\t\t\t\t\t\t\t\tSnapping now works with retiming keys.\n\n\t\t\t\t\t\t\t\t\t\t\t\t\tDuplicate strip images in Preview area.\n\n\t\t\t\t\t\t\t\t\t\t\t\t\tâ€œAdd Effectâ€ menu has been improved.\n\n\t\t\t\t\t\t\t\t\t\t\t\t\tVideo rotation metadata is now respected.\n\n\t\t\t\t\t\t\t\t\t\t\t\t\tCopying strips or creating metastrips now includes effect chains automatically, avoiding selection errors.\n\n\t\t\t\t\t\t\t\t\t\t\t\t\tProxies for EXR (or other float/HDR format) image strips now work properly.\n\n\t\t\t\t\t\t#word-cloud-block_79fa57d3266c700bab7ba3a976ef80de {\n\t\t\t\tcolor: #ffffff;\n\t\t\t}\n\t\t\t\t\t\t\t\t\t#word-cloud-block_79fa57d3266c700bab7ba3a976ef80de .block-words-cloud-categories > div{\n\t\t\t\tbackground: #ffff1f;\n\t\t\t}\n\t\t\t#word-cloud-block_79fa57d3266c700bab7ba3a976ef80de.block-word-cloud > ul > li strong {\n\t\t\t\tcolor: #ffff1f;\n\t\t\t}\n\n\tEXPAND\nYOUR BLENDER\n\n\t\t#paragraph-plus-block_7d3bd197e4872c4e32873562a13aad04 {\n\t\t\t\t\t\t\t\t\tfont-size: 64px;\t\t}\n\n\t\t\t\t\t#paragraph-plus-block_7d3bd197e4872c4e32873562a13aad04 em {\n\t\t\t\tbackground: rgb(221,51,51);\t\t\t\tcolor: rgb(255,255,255);\t\t\t\tfont-style: normal;\t\t\t}\n\nThe Blender Extensions platform keeps growing, with over 500 free add-ons and themes to customize your workflows.\n\nYou can also share your own add-ons and themes!\n\nBrowse Extensions\n\nShare Your Extensions\n\nMODELING\n\nPole Position\n\nA new option in the Select by Trait operator lets you select by pole count.\n\nEasily find all 3-pole or 5-pole points in your mesh.\n\nGiven their impact on topology, the default selects all poles that do not have 4 edges, allowing for easy inspection.\n\nSee Manual\n\nMODELING\n\nInfluencer\n\nJoining triangles to quads now prioritizes quad-dominant topology, creating a more structured â€œgridâ€ layout. This helps maintain cleaner geometry and improves mesh flow, especially in models where uniform quads are preferred.\n\nThis behavior can be adjusted using a topology influence factor, to better control how triangles are merged.\n\nSee Manual\n\nMODELING\n\nVertex & Edge Dissolve\n\nDissolving edges may remove additional, unselected edges to ensure the mesh remains valid. Previously, this also dissolved vertices connected to those unselected edges.\n\nThe new behavior processes only vertices that belonged to the selected, now dissolved edges.\n\nSee Manual\n\nMORE MODELING\n\n\t\t\t\t\t\t\t\t\t\t\t\t\tUp to 15% faster playback when using custom normals or sharp edges\n\n\t\t\t\t\t\t\t\t\t\t\t\t\tN-panel normalization now supports locking multiple vertex groups\n\n\t\t\t\t\t\t\t\t\t\t\t\t\tAdded Curves Edit Mode support for â€œSelect Linked Pickâ€ (L, Shift+L)\n\n\t\t\t\t\t\t#word-cloud-block_d0711cbb567333a72415a9367834dbe2 {\n\t\t\t\tcolor: #eeeeee;\n\t\t\t}\n\t\t\t\t\t\t\t\t\t#word-cloud-block_d0711cbb567333a72415a9367834dbe2 .block-words-cloud-categories > div{\n\t\t\t\tbackground: #8cff4f;\n\t\t\t}\n\t\t\t#word-cloud-block_d0711cbb567333a72415a9367834dbe2.block-word-cloud > ul > li strong {\n\t\t\t\tcolor: #8cff4f;\n\t\t\t}\n\nPUT IT TO THE TEST\n\nShare and compare your computerâ€™s score with openly accessible benchmarks provided by the Blender community.\n\nDownload Blender Benchmark\n\nSCULPT\n\nPlane & Simple\n\nStay grounded or reach new heights with a new sculpt brush type: Plane.\n\nCustomized settings for the Plane brush type in Blender 4.4\n\nThe Plane brush is a generalization of the existing Flatten, Fill, and Scrape brushes, with new options to control stabilization and range of influence above and below the brush plane.\n\nKey features include adjustable height above the brush plane, depth control for vertices below it, and an option to invert these settings.\n\nStabilization options for the Normal (brush planeâ€™s orientation) and Planeâ€˜s position are also available for precise control.\n\nSee Manual\n\nMORE SCULPT\n\n\t\t\t\t\t\t\t\t\t\t\t\t\tGrab Random Cloth and Grab Cloth now use Local Simulation Area by default.\n\n\t\t\t\t\t\t\t\t\t\t\t\t\tSample Color operator assigned to Shift+Ctrl+X in Texture Paint\n\n\t\t\t\t\t\t\t\t\t\t\t\t\tPrevent entering Sculpt Mode in invisible objects\n\n\t\t\t\t\t\t\t\t\t\t\t\t\tRebuild BVH no longer adds an undo entry\n\n\t\t\t\t\t\t\t\t\t\t\t\t\tFrame Selected renamed to Frame Last Stroke\n\n\t\t\t\t\t\t\t\t\t\t\t\t\tNew operator property to override position on sculpt and paint modes.\n\n\t\t\t\t\t\t\t\t\t\t\t\t\tCloth brushes now have the Persistent option off by default.\n\n\t\t\t\t\t\t#word-cloud-block_a27c9106f2b21da3cd5b4527430763f8 {\n\t\t\t\tcolor: #eeeeee;\n\t\t\t}\n\t\t\t\t\t\t\t\t\t#word-cloud-block_a27c9106f2b21da3cd5b4527430763f8 .block-words-cloud-categories > div{\n\t\t\t\tbackground: #8cff4f;\n\t\t\t}\n\t\t\t#word-cloud-block_a27c9106f2b21da3cd5b4527430763f8.block-word-cloud > ul > li strong {\n\t\t\t\tcolor: #8cff4f;\n\t\t\t}\n\n\t\tNew window decorations on Windows 11\n\nUSER INTERFACE\n\nShe Comes in Colors\n\nWindow decorations now follow the theme colors on Windows 11 and macOS.\n\nSnap Into Place\n\nEditors now softly snap to minimum and maximum sizes, with improved splitting previews and docking feedback.\n\nScrollbars are hidden for small editors.\n\nResizing editors now snaps to a minimum, maximum, and half way.\n\nScrollbars are now automatically hidden.\n\nHidden Away\n\nHorizontal scrollbars are now hidden automatically when they donâ€™t fit in the editor.\n\nSee at a glance whether inputs are valid.\n\nNode Editor\n\nFade\n\nIn Node Editors, inputs that canâ€™t affect output are now grayed out for group nodes, Geometry Nodes modifiers, and node tools.\n\nMore Node Editor Improvements\n\nOTHER EDITOR IMPROVEMENTS\n\n\t\t\tAsset Browser\n\n\t\t\t\t\t\t\tNew default sorting option: assets now sorted by catalog instead of name.\n\n\t\t\t\t\t\t\tNew operator to remove asset preview, available in the Asset Browser sidebar.\n\n\t\t\t\t\t\t\tBrush names are easier to read with Light theme.\n\n\t\t\tUV/Image Editor\n\n\t\t\t\t\t\t\tImage Editor view mode now uses â€œsampleâ€ as default tool.\n\n\t\t\t\t\t\t\tUV Editor: Ctrl-C and Ctrl-V shortcuts for copying and pasting UVs.\n\n\t\t\tStatus Bar\n\n\t\t\t\t\t\t\tShow warning when active object has non-uniform or negative scale.\n\n\t\t\t\t\t\t\tShow warning when transform operation has no effect.\n\n\t\t\t\t\t\t\tColor Picker Status Help shown for MacOS for picking outside of Blender.\n\n\t\t\t\t\t\t\tImproved status bar display for several operators.\n\n\t\t\t\t\t\t\tNotification banners are now truncated when very long.\n\n\t\t\t\t\t\t\tShow notification when hiding objects.\n\n\t\t\t3D Viewport\n\n\t\t\t\t\t\t\tDefault front face color for Face Orientation overlay is now transparent.\n\n\t\t\t\t\t\t\tMesh indices overlay setting is now always visible, regardless of Developer Extras.\n\n\t\t\t\t\t\t\tâ€œMeasureâ€ tool items can now be deleted with gizmos off.\n\n\t\t\t\t\t\t\tAnimations can now play in Sculpt mode.\n\n\t\t\t\t\t\t\tViewport Render now displays a progress bar.\n\n\t\t\t\t\t\t\tBrush/tool falloff curve presets expanded in popovers.\n\n\t\t\t\t\t\t\tKnife tool overlay now uses gizmo theme colors.\n\n\t\t\t\t\t\t\tMore readable mesh indices.\n\n\t\t\t\t\t\t\tObject data name show shown in text overlay.\n\n\t\t\t\t\t\t\tFPS display in overlay no longer jiggles when starting.\n\n\t\t\tPreferences\n\n\t\t\t\t\t\t\tExtensions: Add button to quickly access an add-onâ€™s folder.\n\n\t\t\t\t\t\t\tMore user preferences now reset to actual defaults.\n\n\t\t\t\t\t\t\tImproved Studio Lights Editor interface layout.\n\n\t\t\t\t\t\t\tLanguage translation options are now preserved when changing languages.\n\n\t\t\t\t\t\t\tSee all Preferences changes.\n\n\t\t\tProperties\n\n\t\t\t\t\t\t\tPersistent height and scroll position on tree-views.\n\n\t\t\t\t\t\t\tImproved container/codec ordering in FFMPEG video drop-downs.\n\n\t\t\t\t\t\t\tUI Lists now be sorted in reversed alphabetical.\n\n\t\t\t\t\t\t\tSee all Properties editor changes.\n\n\t\t\t\t\t\t#word-cloud-block_03c9d03db8ba61e400849a342fa8f1bd {\n\t\t\t\tcolor: #ffffff;\n\t\t\t}\n\t\t\t\t\t\t\t\t\t#word-cloud-block_03c9d03db8ba61e400849a342fa8f1bd .block-words-cloud-categories > div{\n\t\t\t\tbackground: #000000;\n\t\t\t}\n\t\t\t#word-cloud-block_03c9d03db8ba61e400849a342fa8f1bd.block-word-cloud > ul > li strong {\n\t\t\t\tcolor: #000000;\n\t\t\t}\n\nmacOS\n\nQuick Look\n\nOn macOS, you can now preview blend file contents in a thumbnail in Finder, App ExposÃ© and Spotlight.\n\n\t\t.blend file previews on macOS Finder.\n\nEVERYTHING UI\n\n\t\t\tFiles\n\n\t\t\t\t\t\t\tFull file name now shown on the recent items tool-tips.\n\n\t\t\t\t\t\t\tDefault file names now capitalized as â€œUntitledâ€.\n\n\t\t\tFonts\n\n\t\t\t\t\t\t\tImproved selection from Fonts folder.\n\n\t\t\t\t\t\t\tImproved calculation of text string length for monospaced fonts.\n\n\t\t\t\t\t\t\tInterface font, â€œInterâ€, updated to 4.1\n\n\t\t\tDialogs\n\n\t\t\t\t\t\t\tCentered dialogs can now be moved.\n\n\t\t\t\t\t\t\tPopup alerts (e.g. Python script warnings) adjust width based on content.\n\n\t\t\t\t\t\t\tQuick Favorites and other menus now support accelerators (underlined letters) for toggles.\n\n\t\t\t\t\t\t\tImproved Adjust Last Operation behavior\n\n\t\t\t\t\t\t\tReset to Defaults in Redo Panel no longer closes it.\n\n\t\t\t\t\t\t\tPreview items show a slight background in menus.\n\n\t\t\t\t\t\t\tPie menus now close on loss of window focus.\n\n\t\t\tCursors\n\n\t\t\t\t\t\t\tIncreased contrast for transform cursors.\n\n\t\t\t\t\t\t\tLarger alternative version of the â€œframeâ€ cursor for high-DPI displays.\n\n\t\t\tIcons\n\n\t\t\t\t\t\t\tBatch Rename now has icons for data type.\n\n\t\t\t\t\t\t\tâ€œMaterialâ€ icon flipped horizontally to better differentiate it from â€œWorld.â€\n\n\t\t\tGeneral\n\n\t\t\t\t\t\t\tRename masking property to better reflect its usage.\n\n\t\t\t\t\t\t\tEyedropper color picking can now be canceled without losing the original color.\n\n\t\t\t\t\t\t\tPreview images load faster and display fewer artifacts at different sizes.\n\n\t\t\t\t\t\t\tShow warning when image drag-and-drop fails.\n\n\t\t\t\t\t\t\tPreview items show a loading icon while loading or being rendered.\n\n\t\t\tTheme\n\n\t\t\t\t\t\t\tSelected outline color for pulldowns is now customizable.\n\n\t\t\t\t\t\t\tLight theme icon border now mirrors earlier Blender versions.\n\n\t\t\tInput\n\n\t\t\t\t\t\t\tColor picker HSL value can now be adjusted by trackpad scrolling.\n\n\t\t\t\t\t\t\tImprovements to 3Dconnexion NDOF support.\n\n\t\t\t\t\t\t\tNDOF Orbit direction now inverts when upside down.\n\n\t\t\tText Objects\n\n\t\t\t\t\t\t\tText Objects with non-default fonts no longer load missing characters from other fonts.\n\n\t\t\t\t\t\t\tText Objects with missing or invalid fonts no longer use characters from the default font.\n\n\t\t\tTooltips\n\n\t\t\t\t\t\t\tTooltips now appear while animation is playing.\n\n\t\t\t\t\t\t\tStatus colors are clearer on light backgrounds.\n\n\t\t\t\t\t\t\tColorspace tooltips show more details with expanded acronyms.\n\n\t\t\t\t\t\t\tProperly display colors without alpha.\n\n\t\t\t\t\t\t\tImproved vertical centering.\n\n\t\t\t\t\t\t\tTooltips now disappear faster with Gizmo interaction.\n\n\t\t\t\t\t\t\tNo longer redraw with slight mouse movements.\n\n\t\t\tAnimation\n\n\t\t\t\t\t\t\tAnimated values for nodes and inputs now have clearer names.\n\n\t\t\t\t\t\t\tAuto keyframe toggle works better with keyboard shortcuts.\n\n\t\t\t\t\t\t\tBetter feedback during Animation Playback timer test.\n\n\t\t\t\t\t\t\tImproved current frame indicator styling in movie clip and image editors.\n\n\t\t\t\t\t\t#word-cloud-block_b26d1ee9b65b204f87a2a6e62796d75e {\n\t\t\t\tcolor: #0a0a0a;\n\t\t\t}\n\t\t\t\t\t\t\t\t\t#word-cloud-block_b26d1ee9b65b204f87a2a6e62796d75e .block-words-cloud-categories > div{\n\t\t\t\tbackground: #ffffff;\n\t\t\t}\n\t\t\t#word-cloud-block_b26d1ee9b65b204f87a2a6e62796d75e.block-word-cloud > ul > li strong {\n\t\t\t\tcolor: #ffffff;\n\t\t\t}\n\n\tBlender is and will\nalways be free, forever.\n\n\t\t#paragraph-plus-block_88f494eee05b83d08e8869836b7c8374 {\n\t\t\t\t\t\tcolor: #ff3a3a;\t\t\tfont-size: 48px;\t\t}\n\n\t\t\t#paragraph-plus-block_88f494eee05b83d08e8869836b7c8374 {\n\t\t\t\tbackground-image: linear-gradient(45deg, rgb(255,255,255) 0%, rgb(255,255,255));\n\t\t\t\t-webkit-background-clip: text;\n\t\t\t\t-webkit-text-fill-color: transparent;\n\t\t\t}\n\nReleases are possible thanks to donations by the community.\n\n Donate Monthly\n\nDonate Once\n\nCOMPOSITOR\n\nSpeedfor Everyone\n\nThe CPU compositor was rewritten to pave the way for future development.\n\nThe rewrite provides significant improvements in performance in certain configurations of some nodes, caching of static resources like images, and less memory usage on node setups with many nodes that operate on pixels.\n\nFilter nodes are particularly faster now:\n\nLevels node is up to 10x faster.\n\nFilter and Kuwahara are twice as fast.\n\nBlur nodes up to four times faster.\n\nGlare filter is not only more advanced but also 6x more performant.\n\nPixelate node is 9x faster.\n\nAdjusting compositor node trees can be significantly faster and more interactive. Thatâ€™s because the compositor now avoids computing outputs that arenâ€™t viewed by the user through the backdrop or image editor.\n\nThe overall compositing experience should now feel more responsive, whether youâ€™re using the CPU or GPU.\n\n          Blender 4.3\n\n          Blender 4.4\n\n        Levels\n\n        Pixelate\n\n        Glare\n\n        Pixel Nodes\n\n        Bilateral Blur\n\n        Variable Blur\n\n        Kuwahara\n\n        Masks\n\n        Lens Distortion\n\n    0246810\n\n        Relative performance (higher is better)\n\n\t\tComparison between Blender 4.3 and Blender 4.4\n\nCOMPOSITOR\n\nGlare Glow Up\n\nThe Glare node got a major revamp for better control and usability:\n\nLinkable Inputs â€“ Most node options are now input sockets you can connect.\n\nNew Outputs â€“ Generated glare and highlights are now exposed as output sockets.\n\nA new Strength input lets you adjust glare intensity.\n\nFog Glow and Bloom sizes are now linear and scale properly.\n\nMore realistic, energy-conserving, and properly scaled Bloom.\n\nAdjust glare saturation and tint with dedicated inputs.\n\nHighlight Control â€“ Clamp and smooth highlights with the new Smoothness and Maximum inputs.\n\nTidy UI â€“ Inputs are now neatly organized into collapsible panels.\n\nSee Manual\n\nMORE COMPOSITOR\n\n\t\t\t\t\t\t\t\t\t\t\t\t\tAdded support for integer sockets\n\n\t\t\t\t\t\t\t\t\t\t\t\t\tNew Quality option of OpenImageDenoise on the Denoise node\n\n\t\t\t\t\t\t\t\t\tFast Gaussian Blur is now much more accurate\n\n\t\t\t\t\t\t\t\t\t\t\t\t\tImage transformations are no longer destructive until processed\n\n\t\t\t\t\t\t\t\t\t\t\t\t\tWrapping is now Repeat in the Translate node\n\n\t\t\t\t\t\t\t\t\t\t\t\t\tNotes on compatibility\n\n\t\t\t\t\t\t#word-cloud-block_2c33456875e6a59bac9db3cc16befb5f {\n\t\t\t\tcolor: #ffffff;\n\t\t\t}\n\t\t\t\t\t\t\t\t\t#word-cloud-block_2c33456875e6a59bac9db3cc16befb5f .block-words-cloud-categories > div{\n\t\t\t\tbackground: #c578ff;\n\t\t\t}\n\t\t\t#word-cloud-block_2c33456875e6a59bac9db3cc16befb5f.block-word-cloud > ul > li strong {\n\t\t\t\tcolor: #c578ff;\n\t\t\t}\n\n\tINDUSTRY READY\n\n\t\t#paragraph-plus-block_bdba7a4c2aba9cde90dc3322057b7fae {\n\t\t\t\t\t\t\t\t\tfont-size: 64px;\t\t}\n\n\t\t\t\t\t#paragraph-plus-block_bdba7a4c2aba9cde90dc3322057b7fae em {\n\t\t\t\tbackground: rgb(221,51,51);\t\t\t\tcolor: rgb(255,255,255);\t\t\t\tfont-style: normal;\t\t\t}\n\nAll library versions used in Blender 4.4 are aligned with the VFX Reference Platform 2025, making studio pipeline integration and maintenance easier.\n\nVFX Platform\n\nSee All Library Changes\n\nBUT WAIT, THEREâ€™S MORE\n\n\t\t\tGeometry Nodes\n\n\t\t\t\t\t\t\tNew node â€œFind in Stringâ€.\n\n\t\t\t\t\t\t\tNew input nodes: Collection and Object.\n\n\t\t\t\t\t\t\tNew â€œLimit Surfaceâ€ option available in the Subdivision Surface node.\n\n\t\t\t\t\t\t\tNormal input node now outputs proper face corner normals instead of just face normals.\n\n\t\t\t\t\t\t\tJoin Geometry and Realize Instances nodes now preserve the vertex group status of input attributes.\n\n\t\t\t\t\t\t\tThe text overlay in the 3D view works for matrix attributes now.\n\n\t\t\t\t\t\t\tPerformance: Triangulate node is 30x to 100x faster.\n\n\t\t\t\t\t\t\tSort Elements node is 50% faster in common scenarios.\n\n\t\t\t\t\t\t\tThe Warning node now has a dynamic label depending on the selected type.\n\n\t\t\t\t\t\t\tUI: Resizing nodes now support snapping.\n\n\t\t\tCore\n\n\t\t\t\t\t\t\tAdded support for rendering videos using H.265/HEVC codec.\n\n\t\t\t\t\t\t\tBLENDER_SYSTEM_SCRIPTS now supports multiple paths.\n\n\t\t\t\t\t\t\tNew BLENDER_CUSTOM_SPLASH to replace the splash screen artwork.\n\n\t\t\t\t\t\t\tEXR images that use DWAA/DWAB compression codec now have a Quality setting\n\n\t\t\t\t\t\t\tâ€œRender Audioâ€ can now render to AAC (.aac) format.\n\n\t\t\t\t\t\t\tAuto-save and quit.blend files are now always saved with compression.\n\n\t\t\t3D Viewport\n\n\t\t\t\t\t\t\tOverlays engine rewrite and improvements.\n\n\t\t\t\t\t\t\tExpose view Lock Rotation property in the sidebar View panel.\n\n\t\t\tUSD\n\n\t\t\t\t\t\t\tAnimated volumes from Geometry Nodes or volume modifiers are now supported for export.\n\n\t\t\t\t\t\t\tMaterial displacement for UsdPreviewSurface is now supported in import and export.\n\n\t\t\t\t\t\t\tPoint instancers with animated attributes are now supported on import.\n\n\t\t\t\t\t\t\tThe experimental â€œInstancingâ€ option now supports object hierarchies and non-mesh geometry (e.g., curves, point clouds).\n\n\t\t\t\t\t\t\tNew Python hooks.\n\n\t\t\t\t\t\t\tAdded â€œMerge parent Xformâ€ option to control USD prim merging with its Xform parent during import for better hierarchy preservation.\n\n\t\t\t\t\t\t\tAdded â€œApply Unit Conversion Scaleâ€ option to scale objects by the USD stageâ€™s meters per unit value.\n\n\t\t\t\t\t\t\tAdded â€œMerge parent Xformâ€ option to control whether Blender object transforms are written to their data prim or kept separate on export, reducing USD prim count and preserving hierarchy.\n\n\t\t\t\t\t\t\tAdded â€œUnitsâ€ and â€œMeters Per Unitâ€ options to set the USD Stage measurement or a custom value.\n\n\t\t\t\t\t\t\tUSD & Alembic: Edge and vertex crease processing now respects the value range expected by OpenSubdiv.\n\n\t\t\tVulkan (experimental)\n\n\t\t\t\t\t\t\tHuge performance improvements.\n\n\t\t\t\t\t\t\tCompatibility and Known Issues.\n\n\t\t\tGrease Pencil\n\n\t\t\t\t\t\t\tSeveral operators and functionality from the old Grease Pencil were restored.\n\n\t\t\t\t\t\t\tProperties of locked materials can be edited (similar to properties of locked layers)\n\n\t\t\t\t\t\t\tInvisible layers are no longer part of evaluated data.\n\n\t\t\t\t\t\t\tUI: The preview icon of locked materials is no longer grayed out.\n\n\t\t\t\t\t\t\tâ€œLock allâ€ and â€œUnlock allâ€ operators now work on Layer Groups.\n\n\t\t\t\t\t\t\tâ€œHide Othersâ€ operator now also considers layer groups.\n\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tVertex colors and layer tinting render in â€œSolidâ€ shading mode.\n\n\t\t\tglTF\n\n\t\t\t\t\t\t\tAdded support for importing Action Slots.\n\n\t\t\t\t\t\t\tAdd option to not select created objects.\n\n\t\t\t\t\t\t\tAdd option to import scene extras or not.\n\n\t\t\t\t\t\t\tExport: Several (breaking) changes to hooks.\n\n\t\t\t\t\t\t\tExport: Always bake scene animation, so driven animated properties can be exported.\n\n\t\t\t\t\t\t\tExport: Add interpolation fallback option.\n\n\t\t\t\t\t\t\tExport: Several improvements to Collection export.\n\n\t\t\t\t\t\t\tBug fixes\n\n\t\t\tPython API\n\n\t\t\t\t\t\t\tNew: `bpy.app.module` indicates if Blender is running as Python module.\n\n\t\t\t\t\t\t\tNew property to check if installation is portable.\n\n\t\t\t\t\t\t\tNew operations for Curves.\n\n\t\t\t\t\t\t\tNew properties for Nodes.\n\n\t\t\t\t\t\t\tGrease Pencil Python API updates.\n\n\t\t\t\t\t\t\tVSE: Major API breaking changes and deprecated properties.\n\n\t\t\t\t\t\t\tAnimation: Slotted Action related additions, deprecated properties and breaking changes.\n\n\t\t\t\t\t\t\tComplete list of API breaking changes.\n\n\t\t\tCycles\n\n\t\t\t\t\t\t\tImproved OptiX Denoiser\n\n\t\t\t\t\t\t\tMore accurately render sub-pixel bump mapping.\n\n\t\t\t\t\t\t\tBaking: Speed up Selected to Active baking.\n\n\t\t\t\t\t\t\tOSL: Improved closure compatibility with MaterialX.\n\n\t\t\t\t\t\t\tImproved Sample Subset\n\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tMore robust host memory fallback when the GPU runs out of memory.\n\n\t\t\t\t\t\t\tNVIDIA: Support GeForce RTX 50Ã—0 series (Blackwell)\n\n\t\t\t\t\t\t\tAMD: Support RX 90Ã—0 series (RDNA4)\n\n\t\t\t\t\t\t\tAMD: HIP RT library updates and minimum driver version increased.\n\n\t\t\t\t\t\t\tIntel: Minimum driver version increased.\n\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tIntel: Improved image texture sampling performance.\n\n\t\t\tSpreadsheet\n\n\t\t\t\t\t\t\tThe selection filter for meshes now gives expected results for non-vertex domains.\n\n\t\t\tOutliner\n\n\t\t\t\t\t\t\tImproved vertex group sorting.\n\n\t\t\t\t\t\t\tSupport Ctrl/Shift for excluding collections.\n\n\t\t\t\t\t\t\tFixed overlapping icons with some display options.\n\n\t\t\t\t\t\t\tCan now un-isolate collection when a linked collection is present.\n\n\t\t\t\t\t\t\tNon-object active item text now drawn in â€œtext highâ€ color.\n\n\t\t\t\t\t\t\tDrag and drop to scene now updates the view.\n\n\t\t\t\t\t\t\tChild objects linked to other collections are now faded.\n\n\t\t\tWindows\n\n\t\t\t\t\t\t\tCopy and paste OS image paths into Image Editor.\n\n\t\t\t\t\t\t\tFile system volume names display correctly with high-bit Unicode characters.\n\n\t\t\t\t\t\t\tAltGr key is now treated as regular Alt key.\n\n\t\t\tmacOS\n\n\t\t\t\t\t\t\tImproved color picking outside of Blender windows.\n\n\t\t\t\t\t\t\tKeymaps can be searched with native key names.\n\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tMain window title improvements.\n\n\t\t\t\t\t\t\tEnhanced NDOF device input handling when using 3DConnexion driver v10.8.7 and later.\n\n\t\t\tLinux\n\n\t\t\t\t\t\t\tFixed text pasting from Blender to certain other applications (such as Firefox) not working under X11.\n\n\t\t\t\t\t\t\t\t\t.block-words-cloud-categories > div {\n  --box-background-color: #1e2225;\n}\n\nPlus hundreds of bug fixes, code cleanups and refactors.See the full list of changes.\n\nCREDITS\n\nList of developers that contributed to Blender 4.4\n\nBlender is a community project.Learn more on how you can contribute to Blender.\n\nSplash artwork: Flow Â© Dream Well Studio, Sacrebleu Productions, Take Five â€“ Licensed under CC-BY-SA â€“ flow.movieHuge thanks to everyone involved ğŸ§¡\n\nThe Blender team. March 18th, 2025",
    "summary": {
      "en": "**Blender 4.4 Summary**\n\nBlender 4.4 focuses on improving stability and quality, with developers fixing over 700 bugs and enhancing documentation during a project called the \"Winter of Quality.\" Key updates include:\n\n1. **Action Slots**: This feature allows multiple animations to be combined into a single Action, simplifying animation workflows and making it easier to animate multiple elements together.\n\n2. **Video Sequencer Enhancements**:\n   - Improved text editing and codec support (including H.265).\n   - Faster performance for editing, playback, and rendering.\n   - New features for text strips, such as better alignment and faster proxy building.\n\n3. **Modeling Improvements**:\n   - New selection options and better geometry handling to maintain clean mesh flow.\n   - Enhanced speed for playback and operations in the modeling workspace.\n\n4. **Sculpting**: A new Plane brush type provides more control during sculpting, along with several other brush enhancements.\n\n5. **User Interface Updates**: \n   - Modernized window decorations on Windows 11 and macOS.\n   - Improved snapping and resizing features for editors.\n   - Enhanced usability across various editors with clearer tooltips and improved layout.\n\n6. **Compositor Performance**: Major speed improvements for various nodes, making the compositor more responsive and efficient.\n\n7. **Additional Features**:\n   - Support for new video formats and rendering options.\n   - Enhanced Geometry Nodes with new functionalities.\n   - Improvements in the Python API and overall usability enhancements.\n\nOverall, Blender 4.4 delivers significant improvements in animation, video editing, modeling, and performance, making it a more robust tool for creators.",
      "ko": "Blender 4.4ëŠ” ì•ˆì •ì„±ê³¼ í’ˆì§ˆ í–¥ìƒì— ì¤‘ì ì„ ë‘ê³  ìˆìœ¼ë©°, ê°œë°œìë“¤ì´ 700ê°œ ì´ìƒì˜ ë²„ê·¸ë¥¼ ìˆ˜ì •í•˜ê³  \"í’ˆì§ˆì˜ ê²¨ìš¸\"ì´ë¼ëŠ” í”„ë¡œì íŠ¸ë¥¼ í†µí•´ ë¬¸ì„œí™”ë¥¼ ê°œì„ í–ˆìŠµë‹ˆë‹¤. ì£¼ìš” ì—…ë°ì´íŠ¸ ë‚´ìš©ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n\nì•¡ì…˜ ìŠ¬ë¡¯ ê¸°ëŠ¥ì´ ì¶”ê°€ë˜ì–´ ì—¬ëŸ¬ ì• ë‹ˆë©”ì´ì…˜ì„ í•˜ë‚˜ì˜ ì•¡ì…˜ìœ¼ë¡œ ê²°í•©í•  ìˆ˜ ìˆê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ì• ë‹ˆë©”ì´ì…˜ ì‘ì—… íë¦„ì´ ê°„ì†Œí™”ë˜ê³  ì—¬ëŸ¬ ìš”ì†Œë¥¼ í•¨ê»˜ ì• ë‹ˆë©”ì´ì…˜í™”í•˜ëŠ” ê²ƒì´ ë” ì‰¬ì›Œì¡ŒìŠµë‹ˆë‹¤.\n\në¹„ë””ì˜¤ ì‹œí€€ì„œì—ì„œëŠ” í…ìŠ¤íŠ¸ í¸ì§‘ê³¼ ì½”ë± ì§€ì›ì´ ê°œì„ ë˜ì—ˆìœ¼ë©°, H.265ë„ í¬í•¨ë©ë‹ˆë‹¤. í¸ì§‘, ì¬ìƒ ë° ë Œë”ë§ ì†ë„ê°€ ë¹¨ë¼ì¡Œê³ , í…ìŠ¤íŠ¸ ìŠ¤íŠ¸ë¦½ì— ëŒ€í•œ ìƒˆë¡œìš´ ê¸°ëŠ¥ìœ¼ë¡œëŠ” ë” ë‚˜ì€ ì •ë ¬ê³¼ ë¹ ë¥¸ í”„ë¡ì‹œ ìƒì„±ì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.\n\nëª¨ë¸ë§ ë¶€ë¶„ì—ì„œëŠ” ìƒˆë¡œìš´ ì„ íƒ ì˜µì…˜ê³¼ ë” ë‚˜ì€ ê¸°í•˜í•™ ì²˜ë¦¬ ê¸°ëŠ¥ì´ ë„ì…ë˜ì–´ ê¹¨ë—í•œ ë©”ì‰¬ íë¦„ì„ ìœ ì§€í•  ìˆ˜ ìˆê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. ëª¨ë¸ë§ ì‘ì—… ê³µê°„ì—ì„œì˜ ì¬ìƒ ë° ì‘ì—… ì†ë„ë„ í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤.\n\nì¡°ê° ë„êµ¬ì—ì„œëŠ” ìƒˆë¡œìš´ í‰ë©´ ë¸ŒëŸ¬ì‹œ íƒ€ì…ì´ ì¶”ê°€ë˜ì–´ ì¡°ê°í•˜ëŠ” ë™ì•ˆ ë” ë§ì€ ì œì–´ê°€ ê°€ëŠ¥í•´ì¡Œê³ , ì—¬ëŸ¬ ë¸ŒëŸ¬ì‹œ ê°œì„  ì‚¬í•­ë„ í¬í•¨ë˜ì—ˆìŠµë‹ˆë‹¤.\n\nì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ëŠ” Windows 11ê³¼ macOSì—ì„œ í˜„ëŒ€í™”ëœ ì°½ ì¥ì‹ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ì—ˆìœ¼ë©°, í¸ì§‘ê¸°ì—ì„œ ìŠ¤ëƒ… ë° í¬ê¸° ì¡°ì • ê¸°ëŠ¥ì´ ê°œì„ ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ì–‘í•œ í¸ì§‘ê¸°ì—ì„œ ë” ëª…í™•í•œ íˆ´íŒê³¼ ê°œì„ ëœ ë ˆì´ì•„ì›ƒìœ¼ë¡œ ì‚¬ìš©ì„±ì´ í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤.\n\ní•©ì„±ê¸° ì„±ëŠ¥ë„ í¬ê²Œ ê°œì„ ë˜ì–´ ì—¬ëŸ¬ ë…¸ë“œì˜ ì†ë„ê°€ ë¹¨ë¼ì ¸ í•©ì„±ê¸°ê°€ ë” ë°˜ì‘ì„±ì´ ë›°ì–´ë‚˜ê³  íš¨ìœ¨ì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤.\n\nì¶”ê°€ ê¸°ëŠ¥ìœ¼ë¡œëŠ” ìƒˆë¡œìš´ ë¹„ë””ì˜¤ í¬ë§·ê³¼ ë Œë”ë§ ì˜µì…˜ ì§€ì›, ìƒˆë¡œìš´ ê¸°ëŠ¥ì´ ì¶”ê°€ëœ ê¸°í•˜í•™ ë…¸ë“œ, íŒŒì´ì¬ API ê°œì„  ë° ì „ë°˜ì ì¸ ì‚¬ìš©ì„± í–¥ìƒì´ í¬í•¨ë©ë‹ˆë‹¤.\n\nì „ë°˜ì ìœ¼ë¡œ Blender 4.4ëŠ” ì• ë‹ˆë©”ì´ì…˜, ë¹„ë””ì˜¤ í¸ì§‘, ëª¨ë¸ë§ ë° ì„±ëŠ¥ì—ì„œ ì¤‘ìš”í•œ ê°œì„ ì„ ì´ë£¨ì–´ ì°½ì‘ìë“¤ì—ê²Œ ë” ê°•ë ¥í•œ ë„êµ¬ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "aad4bbdfbd20907f",
    "title": {
      "en": "Source code art in the Rivulet language",
      "ko": "ë¦¬ë·°ë › ì–¸ì–´ì˜ ì½”ë“œ ì•„íŠ¸",
      "ja": null
    },
    "type": "story",
    "url": "https://github.com/rottytooth/Rivulet",
    "score": 162,
    "by": "cranbor",
    "time": 1743076519,
    "content": "Rivulet\nRivulet is a programming language of flowing strands, written in semigraphic characters. A strand is not pictographic: its flow does not simulate computation. There are four kinds of strands, each with their own symbolism and grammatical rules. Together, they form glyphs, tightly-packed blocks of code whose strands execute together.\nHere is a complete Fibonacci program:\n   â•µâ”€â”€â•®â”€â”€â”€â•®â•­â”€    â•µâ•µâ•­â”€â”€â”€â”€â”€â”€â”€â”€â•®\n    â•°â”€â•¯â•°â”€â”€â•¯â”‚       â•°â”€â•¶ â•¶â•®â•¶â•®â•¶â•¯\n   â•°â”€â”€â”€â”€â”€â•® â”‚      â•­â”€â”€â”€â”€â”€â•¯ â•°â”€â”€â”€â”€â”€â•®\n         â•°â”€â•¯ â•·    â•°â”€â”€â”€       â”€â”€â”€â•¯â•·\n\n   â•µâ•µâ”€â•®  â•­â”€â•®     â•­â”€â”€       â•µâ•µâ•°â”€â•®  â”€â”€â•®â”€â”€â•®\n      â•°â”€â•®â”‚ â•°â”€â•¯ â•µâ•µâ•°â”€â•¯â•¶â•®       â•´â”€â•¯  â•­â”€â•¯â•­â”€â•¯\n      â•°â”€â•¯â•°â”€ â•°â”€â”€â•¯â•°â”€â”€â”€â”€â•¯       â•­â•´ â•µâ•¶â•¯ â•¶â•¯â•¶â•®\n        â•­â”€â•® â•­â•´               â”‚  â•°â”€â”€â”€â”€â”€â”€â•¯\n        â”‚ â”‚ â”‚                â•°â”€â•®       â•­â”€â•®\n      â”‚ â”‚ â•°â”€â•¯                  â”‚     â”‚   â”‚\n      â•°â”€â•¯            â•·         â•°â”€â”€â”€â”€ â•°â”€â”€â”€â•¯â•·\n\n   â•µâ•µ â•­â”€â”€  â”€â”€â•®  â•­â”€â•®         â•µâ•°â”€â•®\n      â•°â”€â•®  â•­â”€â•¯â•­â”€â•¯ â”‚          â•´â”€â•¯\n       â•¶â•¯â•µâ•¶â•¯  â”‚ â•·â•¶â•¯          â•­â”€â•®\n     â•­â”€â•® â•°â”€â”€â”€â”€â•¯ â”‚   â•­â”€â•®        â”‚\n     â”‚ â•°â”€â”€â”€â”€â•® â•­â”€â•¯ â•­â•´â”‚ â”‚      â•­â”€â•¯\n     â•°â”€â”€â”€â”€â•® â”‚ â”‚ â”‚ â”‚ â”‚ â”‚      â”‚\n     â•­â”€â”€â”€â”€â•¯ â”‚ â”‚ â•°â”€â•¯ â”‚ â•·      â•°â”€â•·\n     â•°â”€â”€â”€â”€â•® â”‚ â•°â”€â”€â”€â”€â”€â•¯ â”‚\n          â”‚ â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯â•·\n\nHere is the same program formatted by the interpreter into an svg, alongside two variations that produce equivalent computer instructions:\n\nFibonacci 1\nFibonacci 2\nFibonacci 4\n\nâš ï¸ WARNING\n\nStatus: Version 0.4. This is a mostly-working interpreter, and a tool to generate svg files of source code. The command list will likely need to expand for usability.\n\nDesign Philosophy\nRivulet is a list-based language that avoids ordinary approaches to branching and looping. Strands never split and no strand is left un-executed.\nIts writing system was inspired by the satisfying compactness of mazes, Anni Albers's Meanders series, and space-filling algorithms. Its calligraphic aspects draw from natural language and favor the ability to write by hand.\nData Model\nIn Rivulet, data is organized into lists of adjacent cells, populated with zeros by default. Commands are applied to either a single cell or an entire list. They take a second parameter, a constant or the value of another cell.\nCommands can also be run list-to-list, applying the command to each successive cell of one list, from the corresponding cells of the other. While these consider zero-populated cells as well, a list-to-list command ends at the last cell holding a value in either list.\nThe first list, List 1, is sometimes used as the output stream. This is an interpreter setting, as is whether they are displayed as numerical data or a Unicode string (where each value is rounded to the nearest integer).\nControl Flow\nEvery strand of every glyph runs in a Rivulet program; there is no equivalent of an \"if\" statement. If a glyph leads to an unwanted state, that glyph and the others of its block (all contiguous glyphs of the same level or higher), can be rolled back, setting the execution state to what it was before the glyph (or set of glyphs) fired. The conditional rollback is the only form of branching in Rivulet. Loops only end with a rollback of their last iteration. Tests for rollback are that a single cell or an entire list is either zero or non-zero, indicated by a special strand called the Question Strand.\nData strands are run in the order they begin at the top left, moving through each column flowing to the right. So the strand beginning at coordinate 2,0 is run, then 2,1, then 3,0, and so on. Question strands are always run after the data strands are executed.\nSyntax\nRivulet's nuanced grammar may seem overwhelming at first but becomes easy to read and write with practice.\nGlyphs\nGlyphs begin with markers: â•µ in the upper left and end with â•· at the bottom right. They must not have a vertically-oriented character directly above or below them, or they'll be confused for strands. Any text outside of glyph markers is ignored.\nThe level of the glyph is marked by how many â•µs appear at the beginning of the glyph. Levels tell where glyphs fall within larger blocks of code.\nGlyphs can be arranged vertically or side-by-side. They are read in the order of their starting marker location: top-to-bottom, left-to-right.\nIn other words, this program:\n1 â•µâ•°â”€â”€â•®â•°â”€ â•­â”€â”€â•¯ â•¶â•®\n2    â”€â”˜   â””â”€    â”‚\n3    â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n5    â””â”€â”€â”€â”€â”€â”€â”€â”€  â•·\n\n1 â•µâ•µ     â•­â”€â”€â”€â•® â•­â”€\n2    â•´â”€â•®â•¶â•¯â•¶â•® â•·â•¶â•¯\n3  â•µâ•°â”€â”€â”˜   â”‚\n5  â•°â”€â”€â”€â”€â”€â”€â”€â•¯\n\nis identical to this one:\n1 â•µâ•°â”€â”€â•®â•°â”€ â•­â”€â”€â•¯ â•¶â•® â•µâ•µ     â•­â”€â”€â”€â•® â•­â”€\n2    â”€â”˜   â””â”€    â”‚    â•´â”€â•®â•¶â•¯â•¶â•® â•·â•¶â•¯\n3    â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â•µâ•°â”€â”€â”˜   â”‚\n5    â””â”€â”€â”€â”€â”€â”€â”€â”€  â•·  â•°â”€â”€â”€â”€â”€â”€â”€â•¯\n\nLines of code\nThe interpreter refers to code locations in terms of glyph numbers and then line numbers. Line numbers reset to 1 in each glyph. After line 1, they are numbered for each successive prime. These numbers are semantically meaningful for some strands.\nOther strand types use horizontal line numbers, counting in primes away from their starting hook. They always begin on line 1 and their neighbors are 2 on each side. They progress through primes, but always in distance from their starting point. Line numbers are every-other-line vertically: this is so vertical lines are not packed too tightly.\nHere are examples of such strands:\n  â•­â”€â•® â•­â•´  â•­â•´\n  â”‚ â”‚ â”‚   â”‚ â”‚\nâ”‚ â”‚ â•°â”€â•¯   â”‚ â”‚\nâ•°â”€â•¯       â•°â”€â•¯\n5 3 2 1   1 2\n\nLexemes\nRivulet commands are written with these signs. Some re-use characters in a way that only context can disambiguate:\n\nName\nSigns\nContext\nInterpretation\n\nGlyph Start and End\nâ•µ â•·\nNot be adjacent another sign with a vertical reading\nMarks the glyph, the smallest block of code in Rivulet\n\nLocation\nâ•µ â•· â•´â•¶\nLeaves a gap, to punctuate the end of a strand e.g. from left: â”€â”€â•¶\nA reference pointer to a cell\n\nContinue\nâ”€ â”‚\nContinues the flows in the same direction e.g.  â”€â”€â”€â”€\nDepending on the strand type, it can add or subtract the line number of its horizontal or vertical line number, or simply continue the strand\n\nCorner\nâ•¯â”˜â•°â”” â•®â”â•­â”Œ\nSharp or curved corners have the same meaning and can be used interchangeably\nTurns direction of flow\n\nHook\nâ•¯â”˜â•°â•´â””â•´ â•®â”â•­â•´â”Œâ•´\nIt's a character or characters that turn ninety degrees at the beginning of some strands. If it turns to the right or left, it is extended with a half-length line, the same character used to indicate Location, but flipped to extend the hook and not leave a gap.\n\nNon-hook Begin Strand\nâ•· above a â”‚\nStrands with no hook begin with the half-length character to extend it\nMarks the beginning of a Question Strand\n\nData Strands\nValue Strands\nA value strand indicates a command that takes a constant value. Value strands (and other data strands), begin with a hook that points up (as in the third strand below) or to the left (as in the first two). All three of the strands below are value strands:\n1 â•µâ•°â”€â”€â•®â•­â”€â”€â•¯â•¶â•®\n2    â”€â”˜â””â”€   â””â”€â•®\n3\n5              â•·\n\nEach of these value strands writes to list 1, as their hooks sit on line 1. The first strand writes to the first cell (cell 0), as it appears first on that line, the second writes to the second cell (cell 1), etc.\nThe first strand moves two spaces (two â”€â”€ characters) to the right on line 1, adding 1 twice. It then moves one â”€â”€ to the left on line 2, subtracting two. This leaves zero. This makes the first strand a zero strand. The default command applied to a strand is addition assignement, and so zero strands usually invoke no operation.\nThe second strand is also a zero strand: it makes the same motions in reverse of the first strand, subtracting two and then adding two strand back.\nThe third strand adds the value two to the third cell or list 1. The importance of the two zero strands is in marking the third strand to write to cell 2 of list 1, rather than cell 0.\nReference Strands\nReference strands look identical to value strands, only they end with a Location Marker, a small gap that punctuates the end of the strand. It appears in the two top strands here:\n1 â•µâ•°â”€â”€â•®  â•­â”€â”€â•¯\n2   â•´â”€â”˜â•¶â•®â””â”€â•¶\n3       â””â”€â•®\n5            â•·\n\nThe movement of Reference Strands back and forth through the glyph has no effect on what they reference; only where they end.\nThe first strand above is no longer a Zero Strand, but a reference to the first cell (cell 0) of List 2. The second strand beginning on line 1 refers to the second cell (cell 1) of List 2. This is because between those two strands is a strand writing to cell 0 of List 2. If we wanted both of the top strands to read from cell 0 of List 2, we would move its end to before that assignment (here using the vertical version of the Location Marker):\n1 â•µâ•°â”€â”€â•®â•­â”€â”€â”€â”€â•¯\n2   â•´â”€â”˜â•·â•¶â•®\n3        â””â”€â•®\n5            â•·\n\nAction Strands\nThe default command is addition assignment ( += ). To choose another commands, we create an Action Strand to apply to an existing data strand.\nAction Strands have hooks that point down or to the right. They sit directly below the data strand they apply to. If two data strands' hooks are aligned vertically, the top action strand applies to the top data strand, the second to the second, etc.\nWhere a data strand's value is determined by movements to the left and right, action strands determine value through vertical movement. Their line numbers are independent of the other strands in the glyph, each beginning with line 1 as the column where they begin. Their neighbors to the left and right are line 2, followed by 3 and 5.\nEXAMPLE: This command that raises the values of list 1, cells 0 and 1, each to their fourth power:\n 1 â•µâ•°â”€â•® â•°â”€â•®\n 2    â”‚   â”‚\n 3  â•­â•´â””â”€â•­â•´â””â”€\n 5  â”‚   â”‚\n 7  â”‚   â”‚\n11  â•°â”€â•® â•°â”€â•®\n13    â”‚   â”‚ â•·\n    1 2 1 2\n\nThe action strands each have a value of 4, which corresponds to exponentiation_assignment, under data strands of value 4. Here is the (INCOMPLETE) command list, showing which values assign to what command:\n\nValue\nCommand\nInterpretation\n\ndefault\naddition_assignment\nadd to location, set to zero by default\n\n0\noverwrite\nassignment, overwriting existing value\n\n1\ninsert\ninserts value after indicated cell\n\n-1\nsubtraction assignment\n\n2\nmultiplication assignment\n\n-2\ndivision assignment\n\n3\nno-op\nTBD; currently only has value when assigned to list\n\n-3\nmod assignment\nmodulus of cell value against supplied argument\n\n4\nexponentiation assignment\nraise to power of supplied argument\"\n\n-4\nroot assignment\ntake root at power of supplied argument\n\n:WARNING: It is every-other-line that increments between the primes, as the vertical length for a block-drawing char is longer than their horizontal length. This sounds confusing but is usually clear visually.\nHere is an example of two action strands and their numbering:\n  â•­â”€â•® â•­â•´  â•­â•´\n  â”‚ â”‚ â”‚   â”‚ â”‚\nâ”‚ â”‚ â•°â”€â•¯   â”‚ â”‚\nâ•°â”€â•¯       â•°â”€â•¯\n5 3 2 1   1 2\n\nThe first strand has a value of: (1 - 2 + 2*3 - 5) = 2, multiplication assignment. The second strand has a value of (2 * 1) - (2 * 2) = -2, division assignment.\nList indicator\nAction strands can also mark that a command applies not to a single cell (as is the default) but to an entire list. This is indicated by ending an action strand with a horizontal movement. When a list indicator appears, the data strand maintains the same order as if it were its cell that updates. If cell 3 has an action strand, it is still run after cell 2 and before cell 4 strands.\nList 2 List\nIf an action strand ends with a location marker (the tiny gap), it shows that the action should be applied for every cell of the referenced list to every cell of the assigned list. This is only syntactically valid when the data strand also ends with a location marker (is a reference strand).\nEvery cell with a number in the second list is applied to the cells in the first.\nQuestion Strand Sets\nQuestion Strands appear in pairs, one above the other.\nTogether, they pose a question about the state of the data. Should it be found wanting, the glyph and its siblings (those at the same level) are rolled back. If in a loop, only the most recent iteration is undone. This is the only way to exit a loop.\nThe top question strand begins with a vertical line. It ends either to the left or right of where it began (above or below has no semantic meaning).\nThe bottom question strand begins directly above its partner. It too ends either to the left or right of where it began, and it ends with a vertical piece (indicating the question applies only to a single cell) or a horizontal piece (indicating the entire list is to be questioned, the answer an accumulation of its answer).\nQuestion strands, read only by their beginning vs end, can move back and forth through the glyph, filling in blank spaces. They are often decorative, gap-filling lines.\nQuestion lines always fail if an item is less than or equal to zero.\n\nTop Line\nBottom Line\nUse\nChecks\n\nLeft\nHorizontal\nIf\nList (all items)\n\nLeft\nVertical\nIf\nCell\n\nRight\nHorizontal\nWhile\nList\n\nRight\nVertical\nWhile\nCell\n\n(any) vs (all) are equivalent if testing only a single cell",
    "summary": {
      "en": "**Summary of Rivulet Programming Language**\n\nRivulet is a unique programming language that uses flowing strands represented by semigraphic characters. It consists of four types of strands, each with its own rules. These strands combine to form glyphs, dense blocks of code that execute together.\n\n**Key Features:**\n- **Programming Structure:** Rivulet is a list-based language where data is organized in cells, starting with zeros. Commands can target individual cells or entire lists.\n- **Execution Flow:** All strands in a glyph execute without splitting. If a glyph leads to an undesirable state, the program can roll back to a previous state, which is its only form of branching.\n- **Syntax:** Glyphs are marked with specific characters, and their arrangement is flexible. They must be read in a top-to-bottom, left-to-right order.\n- **Data Handling:** Commands can be simple (like addition) or complex (like exponentiation). Strands can reference or modify data in the lists.\n\n**Control Flow:**\n- There are no traditional \"if\" statements; the only branching occurs through rollback.\n- A special type of strand called the Question Strand checks the state of data and can trigger rollbacks.\n\n**Commands and Operations:**\n- Rivulet supports various operations, including addition, subtraction, and multiplication, with specific symbols for each.\n- Action Strands can apply commands to either a single cell or an entire list.\n\n**Design Philosophy:**\n- Inspired by mazes and calligraphy, Rivulet aims for a compact and visually appealing coding style.\n- Its grammar, while complex initially, becomes easier to navigate with practice.\n\nOverall, Rivulet is an innovative programming language that emphasizes a different approach to coding, focusing on the flow of data and visual structure.",
      "ko": "ë¦¬ë·°ë ›ì€ ë°˜ê·¸ë˜í”½ ë¬¸ìë¡œ í‘œí˜„ëœ íë¥´ëŠ” ì¤„ì„ ì‚¬ìš©í•˜ëŠ” ë…íŠ¹í•œ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì…ë‹ˆë‹¤. ì´ ì–¸ì–´ëŠ” ê°ê°ì˜ ê·œì¹™ì„ ê°€ì§„ ë„¤ ê°€ì§€ ìœ í˜•ì˜ ì¤„ë¡œ êµ¬ì„±ë˜ì–´ ìˆìœ¼ë©°, ì´ ì¤„ë“¤ì´ ê²°í•©ë˜ì–´ í•¨ê»˜ ì‹¤í–‰ë˜ëŠ” ê¸°í˜¸ë¥¼ í˜•ì„±í•©ë‹ˆë‹¤.\n\në¦¬ë·°ë ›ì˜ ì£¼ìš” íŠ¹ì§• ì¤‘ í•˜ë‚˜ëŠ” ë¦¬ìŠ¤íŠ¸ ê¸°ë°˜ì˜ êµ¬ì¡°ì…ë‹ˆë‹¤. ë°ì´í„°ëŠ” 0ë¶€í„° ì‹œì‘í•˜ëŠ” ì…€ì— ì¡°ì§ë˜ë©°, ëª…ë ¹ì€ ê°œë³„ ì…€ì´ë‚˜ ì „ì²´ ë¦¬ìŠ¤íŠ¸ë¥¼ ëŒ€ìƒìœ¼ë¡œ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê¸°í˜¸ ë‚´ì˜ ëª¨ë“  ì¤„ì€ ë¶„ë¦¬ë˜ì§€ ì•Šê³  í•¨ê»˜ ì‹¤í–‰ë©ë‹ˆë‹¤. ë§Œì•½ ê¸°í˜¸ê°€ ë°”ëŒì§í•˜ì§€ ì•Šì€ ìƒíƒœë¡œ ì´ì–´ì§€ë©´, í”„ë¡œê·¸ë¨ì€ ì´ì „ ìƒíƒœë¡œ ë˜ëŒì•„ê°ˆ ìˆ˜ ìˆìœ¼ë©°, ì´ê²ƒì´ ìœ ì¼í•œ ë¶„ê¸° ë°©ì‹ì…ë‹ˆë‹¤. ê¸°í˜¸ëŠ” íŠ¹ì • ë¬¸ìë¡œ í‘œì‹œë˜ë©°, ê·¸ ë°°ì—´ì€ ìœ ì—°í•©ë‹ˆë‹¤. ì½ëŠ” ìˆœì„œëŠ” ìœ„ì—ì„œ ì•„ë˜ë¡œ, ì™¼ìª½ì—ì„œ ì˜¤ë¥¸ìª½ìœ¼ë¡œ í•´ì•¼ í•©ë‹ˆë‹¤.\n\nëª…ë ¹ì€ ë‹¨ìˆœí•œ ê²ƒ(ì˜ˆ: ë§ì…ˆ)ë¶€í„° ë³µì¡í•œ ê²ƒ(ì˜ˆ: ì§€ìˆ˜ ê³„ì‚°)ê¹Œì§€ ë‹¤ì–‘í•©ë‹ˆë‹¤. ì¤„ì€ ë¦¬ìŠ¤íŠ¸ ë‚´ì˜ ë°ì´í„°ë¥¼ ì°¸ì¡°í•˜ê±°ë‚˜ ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì „í†µì ì¸ \"if\" ë¬¸ì€ ì—†ìœ¼ë©°, ìœ ì¼í•œ ë¶„ê¸°ëŠ” ë¡¤ë°±ì„ í†µí•´ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤. ì§ˆë¬¸ ì¤„ì´ë¼ëŠ” íŠ¹ë³„í•œ ìœ í˜•ì˜ ì¤„ì€ ë°ì´í„°ì˜ ìƒíƒœë¥¼ í™•ì¸í•˜ê³  ë¡¤ë°±ì„ ìœ ë°œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\në¦¬ë·°ë ›ì€ ë§ì…ˆ, ëº„ì…ˆ, ê³±ì…ˆ ë“± ë‹¤ì–‘í•œ ì—°ì‚°ì„ ì§€ì›í•˜ë©°, ê° ì—°ì‚°ì— ëŒ€í•´ íŠ¹ì • ê¸°í˜¸ê°€ ìˆìŠµë‹ˆë‹¤. ì•¡ì…˜ ì¤„ì€ ëª…ë ¹ì„ ë‹¨ì¼ ì…€ì´ë‚˜ ì „ì²´ ë¦¬ìŠ¤íŠ¸ì— ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë””ìì¸ ì² í•™ì€ ë¯¸ë¡œì™€ ì„œì˜ˆì—ì„œ ì˜ê°ì„ ë°›ì•„, ê°„ê²°í•˜ê³  ì‹œê°ì ìœ¼ë¡œ ë§¤ë ¥ì ì¸ ì½”ë”© ìŠ¤íƒ€ì¼ì„ ì§€í–¥í•©ë‹ˆë‹¤. ë¬¸ë²•ì€ ì²˜ìŒì—ëŠ” ë³µì¡í•  ìˆ˜ ìˆì§€ë§Œ, ì—°ìŠµì„ í†µí•´ ì‰½ê²Œ ìµí ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nì „ë°˜ì ìœ¼ë¡œ ë¦¬ë·°ë ›ì€ ë°ì´í„°ì˜ íë¦„ê³¼ ì‹œê°ì  êµ¬ì¡°ì— ì¤‘ì ì„ ë‘ê³ , ì½”ë”©ì— ëŒ€í•œ ìƒˆë¡œìš´ ì ‘ê·¼ ë°©ì‹ì„ ê°•ì¡°í•˜ëŠ” í˜ì‹ ì ì¸ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì…ë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "1c2129988d9f3279",
    "title": {
      "en": "That Hit Song You Love Was a Total Fluke",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://hbr.org/2013/11/was-gangnam-style-a-fluke",
    "score": 13,
    "by": "gradus_ad",
    "time": 1743181011,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "269a5770b10e72b6",
    "title": {
      "en": "FPGA-Based Implementation of Signal Processing Systems (2nd Edition)",
      "ko": "FPGA ì‹ í˜¸ ì²˜ë¦¬ í˜ëª…",
      "ja": null
    },
    "type": "story",
    "url": "https://www.wiley.com/en-us/FPGA-based+Implementation+of+Signal+Processing+Systems%2C+2nd+Edition-p-9781119077954",
    "score": 3,
    "by": "teleforce",
    "time": 1743185817,
    "content": "Subjects General & Introductory Electrical & Electronics Engineering Signal Processing\n\nFPGA-based Implementation of Signal Processing Systems, 2nd EditionRoger Woods,John McAllister,Gaye Lightbody,Ying YiISBN: 978-1-119-07795-4May 2017360 pagesRead an ExcerptIndex (PDF)Chapter 01 (PDF)Table of Contents (PDF)Product OverviewDownload Product FlyerDescriptionRelated ProductsDigital Evaluation CopyAbout the AuthorPermissionsTable of ContentsFPGA-based Implementation of Signal Processing Systems, 2nd EditionRoger Woods,John McAllister,Gaye Lightbody,Ying YiISBN: 978-1-119-07795-4May 2017360 pagesDigital Evaluation CopyRequest Digital Evaluation Copy\n\nDigital Evaluation CopyRequest Digital Evaluation Copy\n\nE-Book978-1-119-07796-1February 2017$105.00Hardcover978-1-119-07795-4May 2017$130.95O-Book978-1-119-07923-1February 2017Available on Wiley Online Library\n\nAn important working resource for engineers and researchers involved in the design, development, and implementation of signal processing systems  The last decade has seen a rapid expansion of the use of field programmable gate arrays (FPGAs) for a wide range of applications beyond traditional digital signal processing (DSP) systems. Written by a team of experts working at the leading edge of FPGA research and development, this second edition of FPGA-based Implementation of Signal Processing Systems has been extensively updated and revised to reflect the latest iterations of FPGA theory, applications, and technology. Written from a system-level perspective, it features expert discussions of contemporary methods and tools used in the design, optimization and implementation of DSP systems using programmable FPGA hardware. And it provides a wealth of practical insightsâ€”along with illustrative case studies and timely real-world examplesâ€”of critical concern to engineers working in the design and development of DSP systems for radio, telecommunications, audio-visual, and security applications, as well as bioinformatics, Big Data applications, and more. Inside you will find up-to-date coverage of:    FPGA solutions for Big Data Applications, especially as they apply to huge data sets  The use of ARM processors in FPGAs and the transfer of FPGAs towards heterogeneous computing platforms  The evolution of High Level Synthesis toolsâ€”including new sections on Xilinx's HLS Vivado tool flow and Altera's OpenCL approach  Developments in Graphical Processing Units (GPUs), which are rapidly replacing more traditional DSP systems    FPGA-based Implementation of Signal Processing Systems, 2nd Edition is an indispensable guide for engineers and researchers involved in the design and development of both traditional and cutting-edge data and signal processing systems. Senior-level electrical and computer engineering graduates studying signal processing or digital signal processing also will find this volume of great interest.",
    "summary": {
      "en": "The book \"FPGA-based Implementation of Signal Processing Systems, 2nd Edition\" by Roger Woods and others is a key resource for engineers and researchers working on signal processing systems. It highlights the growing use of field programmable gate arrays (FPGAs) in various applications beyond traditional digital signal processing.\n\nKey points include:\n- The book has been updated to include the latest advancements in FPGA technology and applications.\n- It discusses contemporary design methods and tools for implementing digital signal processing systems using FPGAs.\n- The content includes practical insights, case studies, and examples relevant to fields like telecommunications, audio-visual, security, and bioinformatics.\n- Topics covered include FPGA applications in Big Data, the integration of ARM processors, advancements in High Level Synthesis tools, and the rise of Graphical Processing Units (GPUs) as alternatives to traditional DSP systems.\n\nThis edition is beneficial for engineers, researchers, and senior electrical and computer engineering students interested in both traditional and innovative signal processing techniques.",
      "ko": "ë¡œì € ìš°ì¦ˆì™€ ë‹¤ë¥¸ ì €ìë“¤ì´ ì“´ \"FPGA ê¸°ë°˜ ì‹ í˜¸ ì²˜ë¦¬ ì‹œìŠ¤í…œ êµ¬í˜„, ì œ2íŒ\"ì€ ì‹ í˜¸ ì²˜ë¦¬ ì‹œìŠ¤í…œì— ëŒ€í•´ ì—°êµ¬í•˜ëŠ” ì—”ì§€ë‹ˆì–´ì™€ ì—°êµ¬ìë“¤ì—ê²Œ ì¤‘ìš”í•œ ìë£Œì…ë‹ˆë‹¤. ì´ ì±…ì€ ì „í†µì ì¸ ë””ì§€í„¸ ì‹ í˜¸ ì²˜ë¦¬ ë¶„ì•¼ë¥¼ ë„˜ì–´ ë‹¤ì–‘í•œ ì‘ìš© ë¶„ì•¼ì—ì„œ í•„ë“œ í”„ë¡œê·¸ë˜ë¨¸ë¸” ê²Œì´íŠ¸ ì–´ë ˆì´(FPGA)ì˜ ì‚¬ìš©ì´ ì¦ê°€í•˜ê³  ìˆìŒì„ ê°•ì¡°í•©ë‹ˆë‹¤.\n\nì´ ì±…ì€ FPGA ê¸°ìˆ ê³¼ ì‘ìš© ë¶„ì•¼ì˜ ìµœì‹  ë°œì „ ì‚¬í•­ì„ ë°˜ì˜í•˜ì—¬ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤. ë˜í•œ FPGAë¥¼ ì‚¬ìš©í•˜ì—¬ ë””ì§€í„¸ ì‹ í˜¸ ì²˜ë¦¬ ì‹œìŠ¤í…œì„ êµ¬í˜„í•˜ëŠ” í˜„ëŒ€ì ì¸ ì„¤ê³„ ë°©ë²•ê³¼ ë„êµ¬ì— ëŒ€í•´ ë…¼ì˜í•©ë‹ˆë‹¤. ë‚´ìš©ì—ëŠ” í†µì‹ , ì˜¤ë””ì˜¤-ë¹„ì£¼ì–¼, ë³´ì•ˆ, ìƒë¬¼ì •ë³´í•™ ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì™€ ê´€ë ¨ëœ ì‹¤ìš©ì ì¸ í†µì°°ë ¥, ì‚¬ë¡€ ì—°êµ¬, ì˜ˆì œê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ë‹¤ë£¨ëŠ” ì£¼ì œì—ëŠ” ë¹…ë°ì´í„°ì—ì„œì˜ FPGA ì‘ìš©, ARM í”„ë¡œì„¸ì„œì˜ í†µí•©, ê³ ê¸‰ í•©ì„± ë„êµ¬ì˜ ë°œì „, ì „í†µì ì¸ DSP ì‹œìŠ¤í…œì˜ ëŒ€ì•ˆìœ¼ë¡œì„œ ê·¸ë˜í”½ ì²˜ë¦¬ ì¥ì¹˜(GPU)ì˜ ë¶€ìƒ ë“±ì´ í¬í•¨ë©ë‹ˆë‹¤.\n\nì´ íŒì€ ì „í†µì ì¸ ì‹ í˜¸ ì²˜ë¦¬ ê¸°ìˆ ê³¼ í˜ì‹ ì ì¸ ì‹ í˜¸ ì²˜ë¦¬ ê¸°ìˆ  ëª¨ë‘ì— ê´€ì‹¬ì´ ìˆëŠ” ì—”ì§€ë‹ˆì–´, ì—°êµ¬ì, ì „ê¸° ë° ì»´í“¨í„° ê³µí•™ì˜ ê³ í•™ë…„ í•™ìƒë“¤ì—ê²Œ ìœ ìµí•©ë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "1c11fc82d110a67f",
    "title": {
      "en": "Learn to code, ignore AI, then use AI to code even better",
      "ko": "ì½”ë”© ë°°ìš°ê³  AI í™œìš©í•˜ê¸°",
      "ja": null
    },
    "type": "story",
    "url": "https://kyrylo.org/software/2025/03/27/learn-to-code-ignore-ai-then-use-ai-to-code-even-better.html",
    "score": 141,
    "by": "kyrylo",
    "time": 1743154594,
    "content": "Learn to code, ignore AI, then use AI to code even better\n\n        Mar 27, 2025\n\n      |\n\n          Kyrylo Silin\n\n      Â·\n      @kyrylosilin\n      Â·\n      bluesky:@kyrylo.org\n\n    I woke up today to an X post by Amjad Masad,\nthe CEO of Replit, a company that sells â€œAI as a programming serviceâ€.\n\n  I no longer think you should learn to code.\n\n    â€” Amjad Masad (@amasad)\n\nThe post got traction, with well over 4.5M views. In the follow-up\npost, Amjad dismissed the\ncommunityâ€™s reaction as â€œcopeâ€.\n\nThis made me reflect on the future of coding. I have a 3-year-old daughter, and\nI wonder what the world will look like when she grows up. Will coding still be a\nvaluable skill?\n\nThe rise of AI and so-called vibe coding\nhas sparked debate. Some argue coding is becoming obsolete; others believe itâ€™s\nsimply evolving. Whatâ€™s clear is that AI is changing how we code.\n\nShould they learn to code or rely on AI to do the work for them? How should I\nteach my daughter to approach coding? Should I even teach her to code at all?\n\nI donâ€™t have all the answers, but I do have some thoughts.\n\nWhere I come from\n\nTo explain my perspective, I should share some background. Iâ€™m a web developer\nand software engineer with over 15 years of experience (mostly in interpreted\nlanguages, with occasional ventures into compiled ones). I studied Computer\nScience and hold a Masterâ€™s degree in Information Control Systems.\n\nBack in school, we played with languages like Basic and Logo. We wrote code on\npaper and then typed it into a computer â€” like it was the â€™60s, but it was\nactually the early 2000s.\n\nWe also had to perform basic arithmetic in binary. I donâ€™t remember much about\nit, but I do remember it was fun.\n\nIâ€™m not ancient, but I do recall using images to create rounded corners in CSS.\nNice to meet you!\n\nLearning to code in 2025\n\nSo how do students learn to code nowadays? Beats me! And with AI in the mix,\nitâ€™s even trickier. Should you watch online courses? Read books? Just download a\ncode editor and start coding? Or should you rely on AI to do the work for you?\n\nThere are endless options now â€” more languages, more frameworks, more tools, and\nmore resources than ever before.\n\nThis is tiring. Itâ€™s a blissful time to be a programmer, but itâ€™s also a\nnightmare. I think the newer generations of programmers have it harder than we\ndid.\n\nBut I do know this: the fundamentals of coding havenâ€™t changed. Computers have\nevolved, but the basics remain the same. What I learned in school still holds\ntrue. And if youâ€™re just starting out, the basics are where you should begin.\n\nA solid foundation is crucial if you want to understand what youâ€™re doing.\nUltimately, it comes down to how much control you want over your code and, by\nextension, your career.\n\nBut should you ignore AI? Absolutely not. I use AI as a coding assistant every\nday. Has it made me a better programmer? Probably not.\n\nMerchants of AI\n\nAI is the new shiny toy everyone wants to play with. And to be honest, itâ€™s\nimpressive. The problem with AI is that with every year, it gets better and\nbetter. Wait what? Howâ€™s that a problem? Well, with every new year you lose\ncontrol.\n\nThe more you rely on AI, the less you understand what youâ€™re doing. The less you\nunderstand, the more AI vendors can control you. And the more control they\nhave, the more they can charge you. Itâ€™s a vicious cycle.\n\nThis shift was inevitable. Humanity must adapt to this new reality. AI isnâ€™t\ngoing away, and we need to learn how to use it to our advantage.\n\nThe large language models (LLMs) created by tech giants have absorbed decades of\nknowledge â€” our knowledge. Theyâ€™ve been trained on our work.\n\nNow theyâ€™re selling it back to us and telling us we only need to learn English\nto code. This is a lie. As a new programmer, I donâ€™t want you to fall for it.\nThereâ€™s no corner-cutting. Get your shit together and learn to code.\n\nWill I continue using AI?\n\nYes, itâ€™s addictive, and it makes me more productive. If I had to stop using it\ntomorrow, Iâ€™d feel withdrawal symptops. Coding with AI feels incredible.\n\nBut if AI vanished tomorrow due to, say, regulations, Iâ€™d just nod and go back\nto my old ways. Iâ€™d be less productive, yes. And what about you?\n\nIf you know how to code, you can build anything. If you only know how to vibe\ncode, youâ€™re gambling with your future.\n\nBecause if you can vibe codeâ€¦ so can everyone else.\n\nAnd if everyone can do it, what makes you think Devin wonâ€™t replace you?",
    "summary": {
      "en": "The author reflects on the future of coding in light of AI advancements, sparked by a controversial post from Amjad Masad, CEO of Replit, suggesting that learning to code may no longer be essential. The author, a seasoned web developer, questions whether coding will still be a valuable skill for the next generation, like their young daughter.\n\nKey points include:\n\n1. **Evolving Nature of Coding**: The rise of AI has changed how coding is approached, with some believing it might make traditional coding obsolete, while others think it is simply evolving.\n\n2. **Learning Paths**: There are now many resources and tools for learning to code, complicating the process for new learners. Despite these changes, the fundamentals of coding remain important.\n\n3. **Role of AI**: While the author uses AI as a coding assistant and finds it productive, they caution against over-reliance. Understanding coding is crucial for maintaining control over one's work and career.\n\n4. **Future Concerns**: The author warns that if everyone can easily code with AI tools, it could lead to job insecurity, as many could do the same work without a solid coding foundation.\n\nIn summary, while AI can enhance productivity, learning traditional coding skills is still vital for long-term success and control in the tech industry.",
      "ko": "ì €ìëŠ” AI ë°œì „ì— ë¹„ì¶”ì–´ ì½”ë”©ì˜ ë¯¸ë˜ì— ëŒ€í•´ ìƒê°í•´ë³´ë©°, Replitì˜ CEOì¸ ì•”ìë“œ ë§ˆì‚¬ë“œì˜ ë…¼ë€ì´ ëœ ê²Œì‹œê¸€ì„ ì–¸ê¸‰í•©ë‹ˆë‹¤. ê·¸ëŠ” ì½”ë”©ì„ ë°°ìš°ëŠ” ê²ƒì´ ë” ì´ìƒ í•„ìˆ˜ì ì´ì§€ ì•Šì„ ìˆ˜ ìˆë‹¤ëŠ” ì£¼ì¥ì„ í–ˆìŠµë‹ˆë‹¤. ì €ìëŠ” ê²½í—˜ì´ í’ë¶€í•œ ì›¹ ê°œë°œìë¡œì„œ, ì½”ë”©ì´ ë‹¤ìŒ ì„¸ëŒ€, íŠ¹íˆ ìì‹ ì˜ ì–´ë¦° ë”¸ì—ê²Œ ì—¬ì „íˆ ê°€ì¹˜ ìˆëŠ” ê¸°ìˆ ì´ ë  ê²ƒì¸ì§€ì— ëŒ€í•´ ì˜ë¬¸ì„ ì œê¸°í•©ë‹ˆë‹¤.\n\nì½”ë”©ì˜ ë³¸ì§ˆì´ ë³€í™”í•˜ê³  ìˆë‹¤ëŠ” ì ì´ ì£¼ìš” í¬ì¸íŠ¸ì…ë‹ˆë‹¤. AIì˜ ë°œì „ìœ¼ë¡œ ì½”ë”© ì ‘ê·¼ ë°©ì‹ì´ ë‹¬ë¼ì¡Œê³ , ì¼ë¶€ëŠ” ì „í†µì ì¸ ì½”ë”©ì´ ë” ì´ìƒ í•„ìš”í•˜ì§€ ì•Šì„ ê²ƒì´ë¼ê³  ë¯¿ê³  ìˆìŠµë‹ˆë‹¤. ë°˜ë©´, ë‹¤ë¥¸ ì´ë“¤ì€ ì½”ë”©ì´ ë‹¨ìˆœíˆ ì§„í™”í•˜ê³  ìˆë‹¤ê³  ìƒê°í•©ë‹ˆë‹¤.\n\nì½”ë”©ì„ ë°°ìš°ëŠ” ê²½ë¡œë„ ë‹¤ì–‘í•´ì¡ŒìŠµë‹ˆë‹¤. í˜„ì¬ëŠ” ë§ì€ ìì›ê³¼ ë„êµ¬ê°€ ìˆì–´ ìƒˆë¡œìš´ í•™ìŠµìì—ê²ŒëŠ” ì˜¤íˆë ¤ ë³µì¡í•´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì½”ë”©ì˜ ê¸°ë³¸ ì›ì¹™ì€ ì—¬ì „íˆ ì¤‘ìš”í•©ë‹ˆë‹¤.\n\nAIì˜ ì—­í• ì— ëŒ€í•´ì„œë„ ì €ìëŠ” AIë¥¼ ì½”ë”© ë³´ì¡° ë„êµ¬ë¡œ í™œìš©í•˜ë©° ìƒì‚°ì„±ì„ ë†’ì´ê³  ìˆì§€ë§Œ, ê³¼ë„í•œ ì˜ì¡´ì€ ê²½ê³„í•´ì•¼ í•œë‹¤ê³  ê²½ê³ í•©ë‹ˆë‹¤. ì½”ë”©ì„ ì´í•´í•˜ëŠ” ê²ƒì€ ìì‹ ì˜ ì‘ì—…ê³¼ ê²½ë ¥ì„ í†µì œí•˜ëŠ” ë° í•„ìˆ˜ì ì…ë‹ˆë‹¤.\n\në¯¸ë˜ì— ëŒ€í•œ ìš°ë ¤ë„ ìˆìŠµë‹ˆë‹¤. ë§Œì•½ ëª¨ë“  ì‚¬ëŒì´ AI ë„êµ¬ë¥¼ ì‚¬ìš©í•´ ì‰½ê²Œ ì½”ë”©ì„ í•  ìˆ˜ ìˆë‹¤ë©´, ë§ì€ ì‚¬ëŒë“¤ì´ íƒ„íƒ„í•œ ì½”ë”© ê¸°ì´ˆ ì—†ì´ë„ ê°™ì€ ì¼ì„ í•  ìˆ˜ ìˆì–´ ì§ì—… ë¶ˆì•ˆì •ì„±ì´ ì»¤ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nê²°ë¡ ì ìœ¼ë¡œ, AIê°€ ìƒì‚°ì„±ì„ ë†’ì¼ ìˆ˜ ìˆì§€ë§Œ, ì „í†µì ì¸ ì½”ë”© ê¸°ìˆ ì„ ë°°ìš°ëŠ” ê²ƒì€ ê¸°ìˆ  ì‚°ì—…ì—ì„œ ì¥ê¸°ì ì¸ ì„±ê³µê³¼ í†µì œë¥¼ ìœ„í•´ ì—¬ì „íˆ ì¤‘ìš”í•©ë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "ab1107866375ce2d",
    "title": {
      "en": "Asking good questions is harder than giving great answers",
      "ko": "ì¢‹ì€ ì§ˆë¬¸ì˜ í˜",
      "ja": null
    },
    "type": "story",
    "url": "https://newsletter.dancohen.org/archive/asking-good-questions-is-harder-than-giving-great-answers/",
    "score": 145,
    "by": "speckx",
    "time": 1743112103,
    "content": "March 18, 2025\n\n            Asking Good Questions Is Harder Than Giving Great Answers\n\n                The tests we are using to assess the intelligence of AI are missing an essential aspect of human inquiry â€” the query itself\n\n            by Dan Cohen\n\n                        Ã—\n                        Close dialog\n\n                    A painting of Socrates about to drink the hemlock, as his disciples look away in dismay\n\n            Jacques-Louis David, â€œThe Death of Socrates,â€ 1787, Metropolitan Museum of Art. Perhaps he asked too many good questions\n\nRecently, I sharpened a #2 pencil and took the history section of \"Humanity's Last Exam.â€ Consisting of 3,000 extremely difficult questions, the test is intended for AI, not me. According to its creators and contributors, Humanityâ€™s Last Exam will tell us when artificial general intelligence has arrived to supersede human beings, once a brilliant bot scores an A.\nI got an F. Actually, worse than that: Only one of my answers was correct, and I must admit it helped that the question was multiple choice. This is fairly embarrassing for someone with a PhD in history.\nWhat happened? Let me indulge in a standard academic humiliation-avoidance technique: examining the examiners. A much easier exercise. Of the thousands of questions on the test, a mere 16 are on history. By comparison, over 1,200 are on mathematics. This is a rather rude ratio for a purported Test of All Human Knowledge, and a major demerit in this humanâ€™s assessment of the exam.\nThe offense extends further to the historical topics covered. Of the 16 history questions, four of them â€” 25% of historical understanding! â€” are about naval battles. My knowledge of the displacement of various warships is admittedly weak. Other questions are byzantine, alas not literally, but figuratively, long narrative journeys with twists and turns that are clearly trying to confuse any AI by flooding its memory with countless opaque terms. Those questions certainly succeeded in confusing me.\nI will not be reproducing the history questions here since the creators of Humanityâ€™s Last Exam donâ€™t want AI to have a sneak peek at the questions ahead of taking the test. Of course, this raises another question: Would a true superintelligence cheat? I feel like it would? If you, presumably a human reader, want to take the test yourself, you can find a database of the questions on Hugging Face and GitHub. I should also note that I did not take the â€œclassicsâ€ section of the exam, as I am a historian of the modern era and do not know Latin, Greek, etc., but much of that section is history too, perhaps because there were also naval battles in the ancient world.\n* * *\nAlthough I failed Humanityâ€™s Last Exam, I did learn something about the current state of our assessment of AI, and what we expect from it. HLEâ€™s implicit definition of â€œintelligenceâ€ is the ability to provide correct answers to complicated questions, and it is just one of many similar exams. Another, less naval-gazing test of historical knowledge is based on a comprehensive global history database, but still relies on question-answer pairs so it can provide numerical scores for each LLMâ€™s ability. Upon the release of their latest models, AI companies tout improvements on these assessment tools, which allows them to proclaim definitive AI progress: â€œThis LLM got a 92% on a PhD-level history exam, up from 56% last year!â€\nAnd the companies are not wrong about genuinely impressive improvements. Six years ago in this newsletter, I wrote about some initial testing I had been doing with computer vision APIs from Google and Microsoft, a first attempt to analyze the photo morgue my library had recently acquired from the Boston Globe. There were glimmers of hope that these pre-GPT tools could help us identify topics in millions of photographs that lacked rigorous metadata, and I found even 80% accuracy to be promising. Now our libraryâ€™s digital team, much more capable than I am, has created an abstracted interface to all of the main multimodal AI services and is testing the ability of these services to provide subject headings and descriptions, with much better results (although all of the services are still imperfect).\nFellow historian Benjamin Breen has documented similar advances in his testing of AI. The latest models are scarily on par with a first-year doctoral student in history in some areas, able to provide solid context and advanced interpretations of documents and images, even complex ones that require substantial background in a field. The frontier models are much better than most doctoral students in other tasks, such as translation and transcription. Handwriting recognition for historical documents, in particular, has been among the hardest problems for computer scientists to solve, and cracking it will have a significant impact on historical research. Historian Cameron Blevins has shown that custom GPTs are now on a path to a solution that could make archives and special collections much more searchable and readable in ways that might transform our ability to do history. What these other tests of artificial intelligence show is that significant AI progress may lie not in some kind of examination endgame, of perfect answers to tough questions, but in the important, but often hidden, middle stages of a research project, when evidence is being assembled and interpreted.\n* * *\nEven more obscured right now in the conversation about AI and intelligence is that PhD-level work is not just about correct answers. It is more about asking distinctive, uncommon questions. Ultimately, we may want answers, but we must begin with new queries, new areas of interest. Along the way to a better understanding of the past and present, good questions in history may eventually require accurate translations of inscriptions or the location of sea skirmishes. But first, we must imagine why someone, today, should care about such documents and events in the first place, envision how they may have shaped our world. This is a much bigger challenge.\nThe most vibrant historical studies begin with questions that are unexpected and which therefore have revelatory power. Recently in this newsletter, for instance, I covered a book that originated with the seemingly simple query, â€œWhy did audiences at orchestral performances become silent when previously they were rowdy?â€ Before I read Listening in Paris, I assumed naively that the eternally proper behavior at a concert has been respectful quiet. By asking this curious question, James Johnson was able to unveil a major change in the nature and relationship of music, composers, and audiences that still resonates today, even if our musical tastes have largely changed.\nOther books that have influenced me originated with equally novel questions. Why, over a relatively short period of time, did the British radically change their view of some animals, like dogs, from unkempt wild beasts to delightful members of the household, proudly coiffed and paraded at dog shows? Why did Isaac Newton, the paragon of modern science, write more on alchemy than he did on physics or math? How does the experience of war â€” not the abstract tactics of naval battles but the actual first-person experience â€” profoundly change individual soldiers and then, in aggregate, an entire culture?\nCan AI ever produce good questions in history rather than great answers? Iâ€™ll tackle that important question in another newsletter.\n\n    Read more:\n\n                The Unresolved Tension Between AI and Learning\n                If education is accelerated using AI, will we lose some crucial aspects of learning that will prove to be problematic?\n\n                AI Is Coming for Scholarship Next\n                AI models are now ingesting scholarly content in an attempt to dispel their hallucinations. But another possibility looms: that AI will instead drag down scholarship into its muddy realm.\n\nDon't miss what's next. Subscribe to Humane Ingenuity:\n\nYour email (you@example.com)Subscribe\n\n{\"username\": \"dancohen\", \"name\": \"Humane Ingenuity\", \"description\": \"\\u003C!-- buttondown-editor-mode: plaintext --\\u003E\\u003Cp style=\\\"text-align: center\\\"\\u003E* * *\\u003C/p\\u003E\\n\\nA newsletter by [Dan Cohen](https://dancohen.org) on technology that helps rather than hurts human understanding, and human understanding that helps us create better technology. ([*Read past issues of the newsletter*](https://newsletter.dancohen.org/archive/)) ![Humane Ingenuity header image](https://assets.buttondown.email/images/3fabcedf-d29b-4651-b9da-7d3363902bcf.jpeg)\", \"header\": \"\", \"web_header\": \"by [Dan Cohen](https://dancohen.org)\", \"web_footer\": \"\", \"hidden_settings\": [\"should_require_double_optin\", \"should_send_latest_email_to_new_subscribers\"], \"footer\": \"\\u003C!-- buttondown-editor-mode: fancy --\\u003E\\u003Cp\\u003EI'm \\u003Ca target=\\\"_blank\\\" rel=\\\"noopener noreferrer nofollow\\\" href=\\\"https://dancohen.org/about/\\\"\\u003EDan Cohen\\u003C/a\\u003E, a vice provost/dean/professor at Northeastern University. I also write on my \\u003Ca target=\\\"_blank\\\" rel=\\\"noopener noreferrer nofollow\\\" href=\\\"https://dancohen.org\\\"\\u003Epersonal website\\u003C/a\\u003E, in \\u003Ca target=\\\"_blank\\\" rel=\\\"noopener noreferrer nofollow\\\" href=\\\"https://dancohen.org/publications/\\\"\\u003Ebooks and academic journals\\u003C/a\\u003E, and sometimes for \\u003Ca target=\\\"_blank\\\" rel=\\\"noopener noreferrer nofollow\\\" href=\\\"https://www.theatlantic.com/author/dan-cohen/\\\"\\u003Emore popular venues\\u003C/a\\u003E. You can find me on social media on \\u003Ca target=\\\"_blank\\\" rel=\\\"noopener noreferrer nofollow\\\" href=\\\"https://social.dancohen.org\\\"\\u003EMicro.blog\\u003C/a\\u003E (a humane social media platform), which interoperates with Bluesky and other AT-based platforms (follow \\u003Ca target=\\\"_blank\\\" rel=\\\"noopener noreferrer nofollow\\\" href=\\\"https://bsky.app/profile/dancohen.org\\\"\\u003E@dancohen.org\\u003C/a\\u003E), and \\u003Ca target=\\\"_blank\\\" rel=\\\"noopener noreferrer nofollow\\\" href=\\\"https://micro.blog/dancohen?remote_follow=1\\\"\\u003EMastodon\\u003C/a\\u003E and other ActivityPub-based platforms (follow \\u003Ca target=\\\"_blank\\\" rel=\\\"noopener noreferrer nofollow\\\" href=\\\"https://micro.blog/dancohen?remote_follow=1\\\"\\u003E@dan@social.dancohen.org\\u003C/a\\u003E). For now, I'm on Threads and X @dancohen, but go there as often, and as enthusiastically, as the dentist.\\u003C/p\\u003E\\u003Cp\\u003EIf you liked this newsletter, please feel free to forward it to others.\\u003C/p\\u003E\", \"css\": \"\", \"paid_subscriptions_status\": \"inactive\", \"social_networks\": {\"custom\": \"\"}, \"sharing_networks\": [], \"web_css\": \"@import url(\\\"https://fonts.googleapis.com/css?family=Newsreader\\\");\\n\\nbody,\\np,\\n* {\\n  font-family: 'Newsreader', serif;\\n  font-weight: 200;\\n  font-size: 15px;\\n  margin-left: auto;\\n  margin-right: auto;\\n  max-width: 650px;\\n}\\n\\n/* archive snippet text */\\n.email\\u003Ediv {\\n  font-family: 'Newsreader', serif;\\n  font-weight: 200;\\n  font-size: 18px;\\n}\\n\\n/* archive post title */\\n.email\\u003Ediv\\u003Ediv {\\n  font-family: 'Newsreader', serif;\\n  font-weight: 600;\\n  font-size: 20px;\\n  margin-left: 0;\\n}\\n\\n/* archive post date */\\n.email-list .email\\u003Ediv\\u003Ediv:last-child {\\n  font-family: 'Newsreader', serif;\\n  font-weight: 200;\\n  font-size: 18px;\\n  margin-right: 0;\\n}\\n\\na,\\nem {\\n  font-size: 1.0em;\\n}\\n\\nimg {\\n    max-width: 100%;\\n    height: auto;\\n}\", \"from_name\": \"Dan Cohen\", \"address\": \"Snell Library\\nNortheastern University\\n360 Huntington Ave\\nBoston, MA 02115\", \"body_template\": \"\", \"archive_navigation_links\": {}, \"locale\": \"en\", \"fathom_code\": null, \"reddit_code\": null, \"meta_pixel_id\": null, \"memberful_api_key\": null, \"memberful_username\": null, \"is_using_plausible\": true, \"fathom_subscribe_code\": null, \"is_sponsorship_enabled\": false, \"sponsorship_text\": null, \"upsell_text\": \"\", \"subscription_button_text\": \"\", \"paywall_button_text\": \"\", \"subscription_redirect_url\": \"https://dancohen.org\", \"account\": \"73ef6c20-dbbe-4725-856c-0b6f61dcdf51\", \"unsubscription_redirect_url\": \"\", \"buysellads_url\": null, \"discord_api_key\": null, \"shopify_api_key\": null, \"shopify_url\": null, \"github_api_key\": null, \"should_enable_link_checking\": true, \"github_organization_slug\": null, \"github_team_slug\": null, \"github_subscriber_metadata_key\": null, \"enabled_features\": [\"whitelabeling\", \"archives\", \"tracking\", \"api\"], \"subscription_confirmation_redirect_url\": \"\", \"domain\": \"newsletter.dancohen.org\", \"should_send_latest_email_to_new_subscribers\": true, \"should_expose_rss\": true, \"should_hide_social_media\": false, \"should_hide_issue_numbers\": false, \"should_require_double_optin\": true, \"should_send_subscription_confirmation_email\": true, \"status\": \"permanently_active\", \"tint_color\": \"#000000\", \"absolute_url\": \"https://newsletter.dancohen.org/\", \"paid_subscription_free_trial_duration\": 0, \"is_paid_subscription_free_trials_enabled\": false, \"should_disable_non_premium_subscriptions\": false, \"icon\": \"https://buttondown-attachments.s3.us-west-2.amazonaws.com/images/dfca1bbd-ec9b-4d64-8f99-3610da88c2df.png\", \"image\": \"\", \"id\": \"0b99b201-27a2-42fd-9694-221c025a0890\", \"should_be_private\": false, \"archive_theme\": \"modern\", \"template\": \"modern\", \"email_domain\": \"\", \"automatically_remind_unconfirmed_subscribers\": true, \"should_track_replies\": false, \"should_track_errors\": true, \"should_track_page_views\": true, \"should_track_clicks_on_emails\": true, \"should_track_opens_on_emails\": true, \"should_track_clicks_on_transactional_emails\": true, \"should_track_opens_on_transactional_emails\": true, \"timezone\": \"America/New_York\", \"google_tag_manager_code\": null, \"umami_website_id\": null, \"subscription_success_body\": \"\", \"subscription_form_text\": \"\", \"paywall_form_text\": \"\", \"email_address\": \"dan@dancohen.org\", \"metadata_fields\": [], \"cached_analytics_data\": null}\n\n    null\n\n    null\n\n\"\"\n\n    var NEWSLETTER = JSON.parse(document.getElementById('newsletter').textContent);\n    var SUBSCRIBER_EMAIL = JSON.parse(document.getElementById('subscriber_email').textContent);\n    var REFERRING_SUBSCRIBER_ID = JSON.parse(document.getElementById('referring_subscriber_id').textContent);\n\n    var TINT_COLOR = NEWSLETTER.tint_color || '#0069FF';\n    document.documentElement.style.setProperty(\"--tint-color\", TINT_COLOR);\n    var referer = JSON.parse(document.getElementById('referer').textContent);\n    var account = null;\n\n    var VARIANT = \"archive_page\";",
    "summary": {
      "en": "In an article dated March 18, 2025, Dan Cohen discusses the challenges of evaluating AI intelligence through tests like \"Humanity's Last Exam,\" which consists of difficult questions mainly focused on mathematics, with only a small portion related to history. Cohen humorously shares his poor performance on the test, highlighting the unfair emphasis on naval battles among the historical questions.\n\nHe notes that current assessments of AI often prioritize providing correct answers to complex questions, which may not fully capture the essence of intelligence. While AI has made significant stridesâ€”performing at levels comparable to first-year doctoral students in some areas of historyâ€”Cohen argues that true intelligence also involves asking insightful questions rather than just providing answers. \n\nHe emphasizes that the most impactful historical research begins with unique, thought-provoking questions. The ability of AI to generate such questions remains an open question, which Cohen plans to explore further in future writings.",
      "ko": "2025ë…„ 3ì›” 18ì¼ì ê¸°ì‚¬ì—ì„œ ëŒ„ ì½”í—¨ì€ \"ì¸ë¥˜ì˜ ë§ˆì§€ë§‰ ì‹œí—˜\"ê³¼ ê°™ì€ í…ŒìŠ¤íŠ¸ë¥¼ í†µí•´ ì¸ê³µì§€ëŠ¥ì˜ ì§€ëŠ¥ì„ í‰ê°€í•˜ëŠ” ë° ìˆì–´ ê²ªëŠ” ì–´ë ¤ì›€ì— ëŒ€í•´ ì´ì•¼ê¸°í•©ë‹ˆë‹¤. ì´ ì‹œí—˜ì€ ì£¼ë¡œ ìˆ˜í•™ê³¼ ê´€ë ¨ëœ ì–´ë ¤ìš´ ì§ˆë¬¸ë“¤ë¡œ êµ¬ì„±ë˜ì–´ ìˆìœ¼ë©°, ì—­ì‚¬ì™€ ê´€ë ¨ëœ ì§ˆë¬¸ì€ ì†Œìˆ˜ì— ë¶ˆê³¼í•©ë‹ˆë‹¤. ì½”í—¨ì€ ì´ ì‹œí—˜ì—ì„œì˜ ìì‹ ì˜ ë‚®ì€ ì„±ì ì„ ìœ ë¨¸ëŸ¬ìŠ¤í•˜ê²Œ ì–¸ê¸‰í•˜ë©°, ì—­ì‚¬ ì§ˆë¬¸ ì¤‘ í•´ì „ ê´€ë ¨ ì§ˆë¬¸ì— ì§€ë‚˜ì¹˜ê²Œ ë§ì€ ë¹„ì¤‘ì´ ì£¼ì–´ì§€ëŠ” ê²ƒì´ ë¶ˆê³µí‰í•˜ë‹¤ê³  ì§€ì í•©ë‹ˆë‹¤.\n\nê·¸ëŠ” í˜„ì¬ ì¸ê³µì§€ëŠ¥ í‰ê°€ê°€ ë³µì¡í•œ ì§ˆë¬¸ì— ëŒ€í•œ ì •ë‹µì„ ì œê³µí•˜ëŠ” ë° ì¤‘ì ì„ ë‘ê³  ìˆì§€ë§Œ, ì´ëŠ” ì§€ëŠ¥ì˜ ë³¸ì§ˆì„ ì™„ì „íˆ í¬ì°©í•˜ì§€ ëª»í•  ìˆ˜ ìˆë‹¤ê³  ë§í•©ë‹ˆë‹¤. ì¸ê³µì§€ëŠ¥ì´ ì¼ë¶€ ì—­ì‚¬ ë¶„ì•¼ì—ì„œ 1ë…„ì°¨ ë°•ì‚¬ ê³¼ì • í•™ìƒë“¤ê³¼ ë¹„ìŠ·í•œ ìˆ˜ì¤€ìœ¼ë¡œ ì„±ê³¼ë¥¼ ë‚´ê³  ìˆì§€ë§Œ, ì½”í—¨ì€ ì§„ì •í•œ ì§€ëŠ¥ì€ ë‹¨ìˆœíˆ ë‹µì„ ì œê³µí•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ í†µì°°ë ¥ ìˆëŠ” ì§ˆë¬¸ì„ ì œê¸°í•˜ëŠ” ê²ƒì´ë¼ê³  ì£¼ì¥í•©ë‹ˆë‹¤.\n\nê·¸ëŠ” ê°€ì¥ ì˜í–¥ë ¥ ìˆëŠ” ì—­ì‚¬ ì—°êµ¬ëŠ” ë…ì°½ì ì´ê³  ì‚¬ê³ ë¥¼ ìê·¹í•˜ëŠ” ì§ˆë¬¸ì—ì„œ ì‹œì‘ëœë‹¤ê³  ê°•ì¡°í•©ë‹ˆë‹¤. ì¸ê³µì§€ëŠ¥ì´ ì´ëŸ¬í•œ ì§ˆë¬¸ì„ ìƒì„±í•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ì€ ì—¬ì „íˆ ë¯¸ì§€ìˆ˜ì´ë©°, ì½”í—¨ì€ ì•ìœ¼ë¡œì˜ ê¸€ì—ì„œ ì´ ì£¼ì œë¥¼ ë” ê¹Šì´ íƒêµ¬í•  ê³„íšì…ë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "12e39ff4c61a5f07",
    "title": {
      "en": "Better Shell History Search",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://tratt.net/laurie/blog/2025/better_shell_history_search.html",
    "score": 55,
    "by": "todsacerdoti",
    "time": 1742904165,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "9a7110f17d414461",
    "title": {
      "en": "They Might Be Giants Flood EPK Promo (1990) [video]",
      "ko": "ê·¸ë“¤ì€ ê±°ì¸ì´ë‹¤: í™ìˆ˜ EPK",
      "ja": null
    },
    "type": "story",
    "url": "https://www.youtube.com/watch?v=C-tQSFQ-ESY",
    "score": 181,
    "by": "CaliforniaKarl",
    "time": 1743046675,
    "content": "Back\n\n        Search",
    "summary": {
      "en": "It looks like your request is incomplete. Please provide the text you would like summarized, and I'll be happy to help!",
      "ko": "ìš”ì²­ì´ ë¶ˆì™„ì „í•œ ê²ƒ ê°™ìŠµë‹ˆë‹¤. ìš”ì•½í•˜ê³  ì‹¶ì€ ë‚´ìš©ì„ ì œê³µí•´ ì£¼ì‹œë©´ ê¸°êº¼ì´ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤!",
      "ja": null
    }
  },
  {
    "id": "da0bac5307a59bd8",
    "title": {
      "en": "Golang on the Playstation 2",
      "ko": "í”Œë ˆì´ìŠ¤í…Œì´ì…˜ 2ì˜ ê³ ë­",
      "ja": null
    },
    "type": "story",
    "url": "https://rgsilva.com/blog/ps2-go-part-1/",
    "score": 189,
    "by": "donatj",
    "time": 1743111466,
    "content": "Golang on the PlayStation 2\n\n        By Ricardo\n\n      March 23, 2025\n\n      I always wanted to do some weird stuff with consoles. Iâ€™m not sure why, but making devices do unexpected things is always an interesting topic for me. And the same applies to the PlayStation 2, the 2000 console released by Sony.\nAlso, Sony, donâ€™t sue me for this lol\nLetâ€™s get straight into it: I want to run code into consoles (more on why this in a future post). Normally this is done in low(er) level languages, but nowadays we have better and easier to work with languages such as Go. So I was wondering.. why not?\nLooking online, however, yielded no easy way of doing this, so I decided to tackle this problem myself.\n\nPlease note that Iâ€™m writing this after a lot of the research here has been done and tested already. This means that a lot of the experimentation here is from memory and from retracing my steps, so there might be inconsistencies here and there.\n\nAlso note that this is all running inside an emulator. I do own a PS2 that I can test this, but Iâ€™m too lazy to set it up. Plus I want fully functional demos before doing so.\n\nFinal note: the code will be released at a later point and Iâ€™ll update the post accordingly.\n\nThe challenge\nBy default, Go only supports a handful of platforms, and unfortunately that does not include the PS2. In fact, Go seems to require an OS behind the scenes, thing that we donâ€™t even have over there (not considering PS2 Linux). To solve that, however, we have TinyGo, a Go compiler for small devices, like microcontrollers and embedded systems. The basic way it works is that it gets the Go code, turns into LLVM IR, and then that into the binary code for whatever target weâ€™re trying to code for.\nThe PS2 main CPU is called Emotion Engine, which is based on a MIPS R5900. It implements the instructions for MIPS-III and MIPS-IV, plus some custom stuff. It also is missing a few other things (more on that later). Go can actually build code for MIPS already, which should save me some time, but not a lot, as I need to get TinyGo to work on it. TinyGo relies on LLVM 19, which does support MIPS-III, but not the R5900 CPU directly.\nThese are all technical issues. Thereâ€™s a much more pressing one: I donâ€™t know how the PS2 works.\n\n      Well, that should be fun.\n\nThe ps2dev SDK and its quirks\nIf you look it up online for a way of developing code for the PS2, youâ€™ll probably cross paths with ps2dev. This is a full-blown SDK that lets you generate binaries for it in a pretty neat way. The coolest thing about it is that it already provides a bunch of libraries for graphical operations, debugging, I/O, etc - even a stdlib is provided! Because of that, I thought: hey, maybe I want to link to their code - this would allow an easier and faster implementation of anything for the PS2 in Go. Think of it as an â€œOSâ€ API (technically itâ€™s not?), which we could call whenever we want to do things we donâ€™t want to reimplement (or that arenâ€™t even worth trying sometimes).\nThat said, this introduces a few problems. The first one is that the ps2dev libraries are compiled to the MIPS-III N32 standard. This means that, whatever code we produce, needs to target the same thing. Same hard-float, same N32 ABI, etc. This is a bit annoying, but manageable. The reason why it needs to match is because weâ€™ll be linking our code to their pre-built libraries, and linkers are not really fond of dealing with different targets.\n\nFor the sake of clarification: MIPS-III N32 means that this is targeting a MIPS CPU that is implementing the MIPS-III instruction set. This is a 64bit CPU, but due to the N32, this is running 32bit code with some 64bit instructions to handle 64bit integers. This is very confusing, but you can check this to read more about it.\n\nBecause of this, youâ€™ll see my attempts to target mipsel with a mips3 CPU in the next steps, even though it should, technically speaking, be a mips64el, as this is a 64bit CPU. N32 should force things to run in 32bit mode, even though though our target should support 64bit code. However, Clang/LLVM and TinyGo get kinda messy on this and it gets very confusing and complicated. Also, building for mips64el caused TinyGo to failed some verification steps when generating code with the LLVM, as well as clang to refuse to properly build it as the code is kinda broken. Since I really wanted to move forward, I gave up and opted for generating mipsel code with the N32 ABI, which will force clang to change it to a MIPS64 internally, but still generate valid code. Like I said, itâ€™s very weird. Please bear with me, this is all new to me too! :D\nFurther reiteration on this topic might be necessary to get this just right, but Iâ€™m not diving into this hell right now. Future-wise we can try dropping ps2dev and doing things directly in Go, but some assembly is required - literally and metaphorically.\nGetting TinyGo to generate some code\nFor TinyGo to know about a certain target, it requires a file defining it - weâ€™ll call it ps2.json. It defines a bunch of very interesting things that we donâ€™t really care at the moment, but here are the most important ones:\n{\n\t\"llvm-target\": \"mipsel-unknown-unknown\",\n\t\"cpu\": \"mips3\",\n\t\"features\": \"-noabicalls\",\n\t\"build-tags\": [\"ps2\", \"baremetal\", \"mipsel\"],\n\t\"goos\": \"linux\",\n\t\"goarch\": \"mipsle\",\n\t\"linker\": \"ld.lld\",\n\t\"rtlib\": \"compiler-rt\",\n\t\"libc\": \"\",\n\t\"cflags\": [\n\t],\n\t\"ldflags\": [\n\t],\n\t\"linkerscript\": \"\",\n\t\"extra-files\": [\n\t],\n\t\"gdb\": []\n}\nThis file is the culmination of many, maaany days testing different configurations. It is only partially functional. It cannot generate object files yet (more below), hence the reason why Iâ€™m not bothering to fill in flags for compiling and linking code. There are some relevant things I need to explain, though, so here we go:\n\nTarget is mipsel-unknown-unknown. This is our LLVM target. Iâ€™m sticking with mipsel here for the reasons I explained previously.\nThe features have -noabicalls. It is required as otherwise shit hits the fan and nothing works (the LLVM IR that gets generated gets broken).\nIâ€™ve set it to not use any libc. This is because ps2dev already provides one, and I donâ€™t want to mess with that (trust me). Plus, since weâ€™ll be linking to their code, we might as well use their version of it.\n\nThis is the basic target file we need so that TinyGo at least knows what a PS2 is. But thatâ€™s not all - we need to define a bunch of functions which are target-specific.\nBaremetal definitions\nOur target needs a baremetal configuration - baremetal_ps2.go. Usually the default baremetal file is enough, but in our case Iâ€™ve opted to create a custom one so that I can redefine some things.\n\nNote from the future: this can be improved by adjusting the linker file so it finds the correct externs. I might end up doing that and come back here later on.\n\n//go:build ps2\n\npackage runtime\n\nimport \"C\"\nimport (\n\t\"unsafe\"\n)\n\n//go:extern _heap_start\nvar heapStartSymbol [0]byte\n\n//go:extern _heap_end\nvar heapEndSymbol [0]byte\n\n//go:extern _fdata\nvar globalsStartSymbol [0]byte\n\n//go:extern _edata\nvar globalsEndSymbol [0]byte\n\n//go:extern _stack_top\nvar stackTopSymbol [0]byte\n\nvar (\n\theapStart    = uintptr(unsafe.Pointer(&heapStartSymbol))\n\theapEnd      = uintptr(unsafe.Pointer(&heapEndSymbol))\n\tglobalsStart = uintptr(unsafe.Pointer(&globalsStartSymbol))\n\tglobalsEnd   = uintptr(unsafe.Pointer(&globalsEndSymbol))\n\tstackTop     = uintptr(unsafe.Pointer(&stackTopSymbol))\n)\n\nfunc growHeap() bool {\n\t// On baremetal, there is no way the heap can be grown.\n\treturn false\n}\n\n//export runtime_putchar\nfunc runtime_putchar(c byte) {\n\tputchar(c)\n}\n\n//go:linkname syscall_Exit syscall.Exit\nfunc syscall_Exit(code int) {\n  \t// TODO\n\texit(code)\n}\n\nconst baremetal = true\n\nvar timeOffset int64\n\n//go:linkname now time.now\nfunc now() (sec int64, nsec int32, mono int64) {\n\tmono = nanotime()\n\tsec = (mono + timeOffset) / (1000 * 1000 * 1000)\n\tnsec = int32((mono + timeOffset) - sec*(1000*1000*1000))\n\treturn\n}\n\nfunc AdjustTimeOffset(offset int64) {\n\ttimeOffset += offset\n}\n\nvar errno int32\n\n//export __errno_location\nfunc libc_errno_location() *int32 {\n\treturn &errno\n}\nDo we need to understand how most of this works? No, we donâ€™t. Not only that, most of this is copy-paste from the normal baremetal.go implementation. We can adjust later if necessary, no worries. Like I said, we mostly need this to build, so that we can figure out what is wrong and fix it accordingly.\n\nNote: for this to work, you still need to disable the building of the original baremetal.go for our target, so we need to change its build flag to //go:build baremetal && !ps2.\n\nRuntime\nOur target needs a runtime definitions file - runtime_ps2.go. This is the place where a bunch of target-specific functions get defined, including how putchar, exit and even main (later) gets implemented. Pretty cool part of the code if Iâ€™d say so.\nA very basic implementation would look like this:\n//go:build ps2\n\npackage runtime\n\n/*\nextern void _exit(int status);\nextern void* malloc(unsigned int size);\nextern void free(void *ptr);\nextern void scr_printf(const char *format, ...);\n*/\nimport \"C\"\nimport \"unsafe\"\n\n// timeUnit in nanoseconds\ntype timeUnit int64\n\nfunc initUART() {\n  // Unsupported.\n}\n\nfunc putchar(c byte) {\n\t// This is a very hacky way of doing this. It assumes the debug screen is already active, and prints\n\t// a whole string for a single char every single time. Very slow, but works. We can improve it later.\n\n\tx := C.CString(string(c))\n\tC.scr_printf(x)\n\tC.free(unsafe.Pointer(x))\n}\n\nfunc getchar() byte {\n\t// TODO\n\treturn 0\n}\n\nfunc buffered() int {\n\t// TODO\n\treturn 0\n}\n\nfunc sleepWDT(period uint8) {\n\t// TODO\n}\n\nfunc exit(code int) {\n  \t// This just delegates it to the ps2dev _exit(int) function.\n\tC._exit(C.int(code))\n}\n\nfunc abort() {\n\t// TODO\n}\n\nfunc ticksToNanoseconds(ticks timeUnit) int64 {\n  \t// TODO\n\treturn int64(ticks)\n}\n\nfunc nanosecondsToTicks(ns int64) timeUnit {\n  \t// TODO\n\treturn timeUnit(ns)\n}\n\nfunc sleepTicks(d timeUnit) {\n\t// TODO\n}\n\nfunc ticks() (ticksReturn timeUnit) {\n\t// TODO\n\treturn 0\n}\nA lot of it is not implemented, and this is intentional - I wonâ€™t be using those things at the moment, so I donâ€™t care about them. We can later implement them accordingly, and get them to work as expected. Some of them might be even doable through ps2devâ€™s C functions, for example.\nInterrupts\nAnother basic file we need is the interrupts defintions - interrupt_ps2.go. I know that ps2dev has implementations for those calls, but Iâ€™ve opted to not call them yet. At this moment, we donâ€™t need interrupts, so letâ€™s just implement dummy functions for that:\n//go:build ps2\n\npackage interrupt\n\ntype State uintptr\n\nfunc Disable() (state State) {\n\treturn 0\n}\n\nfunc Restore(state State) {}\n\nfunc In() bool {\n\treturn false\n}\nWith that, we should be able to build some Go code. So letâ€™s give it a try.\nCalling Go functions from C\nLetâ€™s start with a simple example: get our C code to return a number and a string. Nothing major. Weâ€™ll split this into 2 parts: the loader (in C) and our Go code. It will work like this:\n\n      It works!\n\nHereâ€™s our Go code:\n//export aGoString\nfunc aGoString() *C.char {\n\treturn C.CString(\"The answer for everything is\")\n}\n\n//export aGoNumber\nfunc aGoNumber() C.int {\n\treturn C.int(42)\n}\nAnd our loader, which contains our main function:\n// Our go functions, exported before.\nextern char* aGoString();\nextern int aGoNumber();\n\nint main() {\n  // Initialize our debug screen.\n  sceSifInitRpc(0);\n  init_scr();\n\n  // Print stuff we get from Go functions.\n  scr_printf(\"%s: %d\\n\", aGoString(), aGoNumber());\n\n  // Infinite loop so we keep the program running.\n  while (1) {}\n\n  return 0;\n}\nVery simple code, right? Letâ€™s build it.\nWell, no, wait. Thereâ€™s a problem. TinyGo, by default, wants you to generate the final ELF (.elf) or the object file (.o) with it. However, the ELF requires adding a linkfile and some other extra bits of code to it, which weâ€™re far from. For now, we just want to get some functions in a way that we can link - so we should be able to just use the object file.\nHowever, attempting to do so generates an incorrect file:\n$ tinygo build -target ps2 -o test.o\n$ file test.o\ntest.o: ELF 32-bit LSB relocatable, MIPS, MIPS-III version 1 (SYSV), with debug_info, not stripped\n\n  Note the missing `N32` in the string\n\nI thought: oh, ok, weâ€™re just missing the proper cflags and ldflags here, right? So letâ€™s try adding it:\n{\n\t// (...)\n\t\"cflags\": [\n\t\t\"-mabi=n32\"\n\t],\n\t\"ldflags\": [\n\t\t\"-mabi=n32\"\n\t],\n\t// (...)\n\n  These might not be the right flags, but according to some docs it seems like it is.\n\n$ tinygo build -target ps2 -o test.o\n$ file test.o\ntest.o: ELF 32-bit LSB relocatable, MIPS, MIPS-III version 1 (SYSV), with debug_info, not stripped\nOh. Ok then.\nSince TinyGo is, for some reason, not playing nice here, Iâ€™ve opted for breaking this into steps that I can more easily control. TinyGo internally will generating some LLVM IR from your Go code, and then build it. Letâ€™s stop at the LLVM IR level then:\n$ tinygo build -target ps2 -o build/go.ll\nThis will generate a valid LLVM IR file! ğŸ‰ Now we can just manually build it into the object file with the format we want:\n$ clang -fno-pic -c --target=mips64el -mcpu=mips3 -fno-inline-functions -mabi=n32 -mhard-float -mxgot -mlittle-endian -o build/go.o build/go.ll\nThe flags here are important. Our target is a MIPS64 (only TinyGo is not happy with it), Little Endian, with the MIPS-III instruction set, using the N32 ABI. It uses hardware floating numbers, and the -fno-pic and -mxgot is to deal with a global offset table size limit issue when linking. With all that, hereâ€™s what we get:\n$ file build/go.o\nbuild/go.o: ELF 32-bit LSB relocatable, MIPS, N32 MIPS-III version 1 (SYSV), with debug_info, not stripped\n\n  Finally!\n\nFrom here, we can link with our C code. For that, Iâ€™ve opted to use the ps2dev linking command (extracted from the Makefile and some testing), with our Go code added into it:\nmips64r5900el-ps2-elf-gcc \\\n\t-Tlinkfile \\\n\t-L/usr/local/ps2dev/ps2sdk/ee/lib \\\n\t-L/usr/local/ps2dev/ps2sdk/ports/lib \\\n\t-L/usr/local/ps2dev/gsKit/lib/ \\\n\t-Lmodules/ds34bt/ee/ \\\n\t-Lmodules/ds34usb/ee/ \\\n\t-Wl,-zmax-page-size=128 \\\n\t-lpatches \\\n\t-lfileXio \\\n\t-lpad \\\n\t-ldebug \\\n\t-lmath3d \\\n\t-ljpeg \\\n\t-lfreetype \\\n\t-lgskit_toolkit \\\n\t-lgskit \\\n\t-ldmakit \\\n\t-lpng \\\n\t-lz \\\n\t-lmc \\\n\t-laudsrv \\\n\t-lelf-loader \\\n\t-laudsrv \\\n\t-lc \\\n\t-mhard-float \\\n\t-msingle-float \\\n\t-o build/main.elf \\\n\tbuild/loader.o \\\n\tbuild/asm_mipsx.o \\\n\tbuild/go.o\n\n  Loader is our C code, and Go is our.. well, Go code.\n\nNote: the asm_mipsx.o is some assembly code provided by TinyGo that I just copied into the project and built with clang. You can find it here.\n\nAnd, with that, we build our new application!\n$ file build/main.elf\nbuild/main.elf: ELF 32-bit LSB executable, MIPS, N32 MIPS-III version 1 (SYSV), statically linked, with debug_info, not stripped\nAnd running it yields success:\n\n      It works! This is PCSX2 v2.3.223 btw.\n\nSwitching to Goâ€™s main\nRight now the main function that is being called is not in Go, but in C - that is what weâ€™ve been calling loader so far. However, Go applications can start by themselves without a C-based loader - and it would be great if our games PS2 applications would so!\nRuntime changes\nThe first step to allowing Go applications to run without our loader is to have the main function exposed by Go. We can do that in our runtime_ps2.go:\n//export main\nfunc main() {\n\tpreinit()\n\trun()\n\tpreexit()\n\texit(0)\n}\n\nconst (\n\tmemSize = uint(24 * 1024 * 1024)\n)\n\nvar (\n\tgoMemoryAddr uintptr\n)\n\nfunc preinit() {\n\t// NOTE: no need to clear .bss and other memory areas as crt0 is already doing that in __start.\n\n\t// Since we're loading into whatever ps2dev kernel thingy that exists, it's safer for us to do\n\t// a proper malloc before proceeding. This guarantees that the heap location is ours. We will\n\t// need to free it later on though.\n\n\tgoMemoryAddr = uintptr(unsafe.Pointer(C.malloc(C.uint(memSize))))\n\theapStart = goMemoryAddr\n\theapEnd = goMemoryAddr + uintptr(memSize)\n}\n\nfunc preexit() {\n\tC.free(unsafe.Pointer(heapStart))\n}\nThere are some important things to note here:\n\nThe heap start and end could be defined by the linker file. And, ironically, they are. However, the crt0 provided by ps2dev will clear those variables for some reason, making it kinda broken.\n\nWe could just assume that anything above a certain memory address is ours, buuuut ps2dev may want to play with more memory and I donâ€™t want to deal with this right now.\nWeâ€™ll allocate the memory using ps2devâ€™s malloc as per stated in the code. This will guarantee that this memory area is ours - if the libraries need more, they should still have some memory left, as the PS2 should have 32MB and weâ€™re allocating 24MB only.\nTechnically speaking we could make the heap grow per demand - but thatâ€™s a problem for future me.\n\nWeâ€™ll intentionally unallocate the memory after usage. Not really required, but just in case.\nThe run function is responsible for calling our main function inside our main package. This is not something we need to deal with - TinyGoâ€™s code does that for us, we just need to call it.\n\nIt works basically like this:\n\n      Exitpoint is even a word?!\n\nThis is technically a mixed approach: itâ€™s both baremetal - because it runs without a proper OS - but itâ€™s also not - because it allocates memory, enters and exits application.\nFun fact: once the code exits, it shows the memory card selection screen!\n\nOur Go code\nLetâ€™s code something in Go then. First step is to have something to call, so letâ€™s create a package called debug with the debug screen functions:\npackage debug\n\n/*\nextern void free(void *ptr);\nextern void sceSifInitRpc(int mode);\nextern void init_scr(void);\nextern void scr_printf(const char *format, ...);\n*/\nimport \"C\"\nimport (\n\t\"fmt\"\n\t\"unsafe\"\n)\n\nfunc Init() {\n\tC.sceSifInitRpc(0)\n\tC.init_scr()\n}\n\nfunc Printf(format string, args ...interface{}) {\n\tformatted := fmt.Sprintf(format, args...)\n\n\tstr := C.CString(formatted)\n\tC.scr_printf(str)\n\tC.free(unsafe.Pointer(str))\n}\n\nYes, there is an extern for the free function which could be replaced by stdlib. Iâ€™ve avoided that at the moment as that requires adding some C flags for include paths and that made it messy. Hereâ€™s how it looks like with it:\n/*\n#cgo CFLAGS: -I/Users/ricardo/dev/ps2dev/ee/mips64r5900el-ps2-elf/include -I/Users/ricardo/dev/ps2dev/ee/lib/gcc/mips64r5900el-ps2-elf/14.2.0/include/ -I/Users/ricardo/dev/ps2dev/gsKit/include -I/Users/ricardo/dev/ps2dev/ps2sdk/common/include -I/Users/ricardo/dev/ps2dev/ps2sdk/ports/include/freetype2 -I/Users/ricardo/dev/ps2dev/ps2sdk/ports/include/zlib\n#include <stdlib.h>\n\nextern void sceSifInitRpc(int mode);\nextern void init_scr(void);\nextern void scr_printf(const char *format, ...);\n*/\nThis can be improved by moving those flags externally to the build process but thatâ€™s a problem for future me once this gets released.\n\nOverall, this is nothing too crazy - itâ€™s just the normal debug functions exposed by ps2dev (declared here and implemented here). And then we just call it:\npackage main\n\nimport (\n\t\"ps2go/debug\"\n)\n\nfunc main() {\n\tdebug.Init()\n\n\tdebug.Printf(\"Hello world from Go!\\n\")\n\tdebug.Printf(`\n   ____                                _\n  / ___| ___    _ __ _   _ _ __  _ __ (_)_ __   __ _    ___  _ __\n | |  _ / _ \\  | '__| | | | '_ \\| '_ \\| | '_ \\ / _' |  / _ \\| '_ \\\n | |_| | (_) | | |  | |_| | | | | | | | | | | | (_| | | (_) | | | |\n  \\____|\\___/  |_|   \\__,_|_| |_|_| |_|_|_| |_|\\__, |  \\___/|_| |_|\n    ____  _             ____  _        _   _   |___/       ____\n   |  _ \\| | __ _ _   _/ ___|| |_ __ _| |_(_) ___  _ __   |___ \\\n   | |_) | |/ _' | | | \\___ \\| __/ _' | __| |/ _ \\| '_ \\    __) |\n   |  __/| | (_| | |_| |___) | || (_| | |_| | (_) | | | |  / __/\n   |_|   |_|\\__,_|\\__, |____/ \\__\\__,_|\\__|_|\\___/|_| |_| |_____|\n                  |___/\n`)\n\tfor {\n\t\t// Infinite loop to not exit!\n\t}\n}\nFancy, no? Letâ€™s build the code and see what happens:\n$ tinygo build -target ps2 -o build/go.ll\n$ clang -fno-pic -c --target=mips64el -mcpu=mips3 -fno-inline-functions -mabi=n32 -mhard-float -mxgot -mlittle-endian -o build/go.o build/go.ll\n$ mips64r5900el-ps2-elf-gcc \\\n\t-Tlinkfile \\\n\t-L/usr/local/ps2dev/ps2sdk/ee/lib \\\n\t-L/usr/local/ps2dev/ps2sdk/ports/lib \\\n\t-L/usr/local/ps2dev/gsKit/lib/ \\\n\t-Lmodules/ds34bt/ee/ \\\n\t-Lmodules/ds34usb/ee/ \\\n\t-Wl,-zmax-page-size=128 \\\n\t-lpatches \\\n\t-lfileXio \\\n\t-lpad \\\n\t-ldebug \\\n\t-lmath3d \\\n\t-ljpeg \\\n\t-lfreetype \\\n\t-lgskit_toolkit \\\n\t-lgskit \\\n\t-ldmakit \\\n\t-lpng \\\n\t-lz \\\n\t-lmc \\\n\t-laudsrv \\\n\t-lelf-loader \\\n\t-laudsrv \\\n\t-lc \\\n\t-mhard-float \\\n\t-msingle-float \\\n\t-o build/main.elf \\\n\tbuild/asm_mipsx.o \\\n\tbuild/go.o\n\n  Easy, no?\n\nThat builds the ELF file. Now letâ€™s load it in the emulator and see what happens!\n\n      Yeeeeeeeeey!\n\nSuccess! ğŸ‰\n\n      Gotta love memes\n\nThe DDIVU problem\nWhile testing some basic functionality, Iâ€™ve noticed that fmt.Sprintf didnâ€™t work properly. Look at this very simple basic code:\nfunc main() {\n\tdebug.Init()\n\n\tfor i := -32; i <= 32; i++ {\n\t\tdebug.Printf(\"%02d, \", i)\n\t}\n\n\tfor {\n\t\t// Infinite loop to not exit!\n\t}\n}\n\n      Errr this is awkward\n\nOk, this is not normal. The numbers between -9 and +9 are correct, while everything else is wrong. This specific problem took me days to figure out what the hell was going on. I eventually narrowed it down to this part of the fmtInteger implementation, used by Sprintf inside the fmt package:\nfunc (f *fmt) fmtInteger(u uint64, base int, isSigned bool, verb rune, digits string) {\n\t// (... bunch of code here ...)\n\n\tswitch base {\n\tcase 10:\n\t\tfor u >= 10 {\n\t\t\ti--\n\t\t\tnext := u / 10\n\t\t\tbuf[i] = byte('0' + u - next*10)\n\t\t\tu = next\n\t\t}\n\n\t// (... bunch of code here ...)\n}\nLook at how TinyGo is generating the LLVM IR code for that:\n!875 = !DIFile(filename: \"format.go\", directory: \"/usr/local/go/src/fmt\")\n!15696 = !DILocalVariable(name: \"next\", scope: !15679, file: !875, line: 243, type: !373)\n\n; (...)\n\nlookup.next:                                      ; preds = %for.body\n  %31 = udiv i64 %27, 10, !dbg !15759\n    #dbg_value(i64 %31, !15696, !DIExpression(), !15757)\n  %.neg = mul i64 %31, 246, !dbg !15760\n  %32 = add i64 %27, 48, !dbg !15761\n  %33 = add i64 %32, %.neg, !dbg !15762\n  %34 = trunc i64 %33 to i8, !dbg !15763\n  %35 = getelementptr inbounds i8, ptr %.pn75, i32 %30, !dbg !15758\n  store i8 %34, ptr %35, align 1, !dbg !15758\n    #dbg_value(i64 %31, !15696, !DIExpression(), !15764)\n    #dbg_value(i64 %31, !15684, !DIExpression(), !15765)\n  br label %for.loop, !dbg !15700\n\n  Hopefully this is the right section of the code lol\n\nWhich all seems just fine. Looking deeper into it, thereâ€™s this specific thing: udiv i64 %27, 10 - this is a unsigned division of a 64bit integer by 10. Keep that 64bit part in mind.\nThis generates the following MIPS assembly code:\n.LBB139_23:                             # %lookup.next\n                                        #   in Loop: Header=BB139_19 Depth=1\n\t#DEBUG_VALUE: (*fmt.fmt).fmtInteger:i <- [DW_OP_plus_uconst 176] [$sp+0]\n\t#DEBUG_VALUE: (*fmt.fmt).fmtInteger:u <- [DW_OP_plus_uconst 184] [$sp+0]\n\t#DEBUG_VALUE: (*fmt.fmt).fmtInteger:negative <- [DW_OP_plus_uconst 332] [$sp+0]\n\t#DEBUG_VALUE: (*fmt.fmt).fmtInteger:digits <- [DW_OP_LLVM_fragment 32 32] 17\n\t#DEBUG_VALUE: (*fmt.fmt).fmtInteger:base <- [DW_OP_plus_uconst 316] [$sp+0]\n\t#DEBUG_VALUE: (*fmt.fmt).fmtInteger:verb <- [DW_OP_plus_uconst 312] [$sp+0]\n\t#DEBUG_VALUE: (*fmt.fmt).fmtInteger:digits <- [DW_OP_plus_uconst 308, DW_OP_LLVM_fragment 0 32] [$sp+0]\n\t.loc\t129 0 7 is_stmt 0               # format.go:0:7\n\tlw\t$1, 176($sp)                    # 4-byte Folded Reload\n\tlw\t$4, 272($sp)                    # 4-byte Folded Reload\n\tld\t$3, 184($sp)                    # 8-byte Folded Reload\n\tdaddiu\t$2, $zero, 10\n\t.loc\t129 243 14 is_stmt 1            # format.go:243:14\n\tddivu\t$zero, $3, $2\n\tteq\t$2, $zero, 7\n\tmflo\t$2\nLetâ€™s ignore most of this and focus on one specific thing: ddivu $zero, $3, $2. Looks correct, right?\nWellâ€¦ letâ€™s look into how PCSX2 loads this:\n\n      ??????\n\nYep. PCSX2 doesnâ€™t see the DDIVU instruction. Or, more specifically, the PlayStation  doesnâ€™t see it.\n\nThe DDIVU (doubleword divide unsigned) is a instruction defined in MIPS-III (source) responsible for doing the division of 2 unsigned 64bit integers.\nHowever, that doesnâ€™t work in the PS2, as we saw before. You see, the DDIVU instruction is not defined (source) in the PS2 MIPS instruction set - only DIVU is. This introduces a major problem, as now all int64 (with DDIV) and uint64 (with DDIVU) divisions wonâ€™t execute - or will execute incorrectly if it ends up matching some other instruction. We need to avoid that, and either split this division inside the Go compiler in a way that would not do the 64bit version of it, or modify the LLVM so that it wonâ€™t use this instruction, even on a mips3 CPU. Or maybe we can implement a custom CPU inside the LLVM - the r5900, like ps2devâ€™s GCC.\nFinding a way out\nMy first thought was â€œoh, letâ€™s adapt this in the LLVMâ€. But, and Iâ€™m not gonna lie to you, changing that code is hell. Itâ€™s very complex and requires a ton of changes and most of the time it even requires full rebuild of the LLVM project. Iâ€™m just too lazy for that. So Iâ€™ve opted for the terrible approach of doing this inside TinyGoâ€™s compiler.\nThe first step is to have a 64bit division code. According to my good friend ChatGPT (who has never been wrong before /s), whenever 64bit division is not available (like in the R5900), GCC uses an auxiliary function called __udivdi3:\nuint64_t __udivdi3(uint64_t a, uint64_t b);\nSo my thought was: oh, I can just map the uint64 division to this then. The first step is to add this as something that is available on our runtime_ps2.go (because Iâ€™m too lazy to do the full proper call):\n//go:build ps2\n\npackage runtime\n\n/*\nextern long __divdi3(long a, long b);\nextern unsigned long __udivdi3 (unsigned long a, unsigned long b);\nextern long __moddi3(long a, long b);\nextern unsigned long __umoddi3(unsigned long a, unsigned long b);\n*/\nimport \"C\"\n\nfunc int64div(a, b int64) int64 {\n\treturn int64(C.__divdi3(C.long(a), C.long(b)))\n}\n\nfunc uint64div(a, b uint64) uint64 {\n\treturn uint64(C.__udivdi3(C.ulong(a), C.ulong(b)))\n}\n\nfunc int64mod(a, b int64) int64 {\n\treturn int64(C.__moddi3(C.long(a), C.long(b)))\n}\n\nfunc uint64mod(a, b uint64) uint64 {\n\treturn uint64(C.__umoddi3(C.ulong(a), C.ulong(b)))\n}\nThen, we need to modify TinyGoâ€™s compiler to use it. That is simpler than it sounds - itâ€™s all handled here.\nLetâ€™s start with the unsigned operations:\nif op == token.QUO {\n\treturn b.CreateUDiv(x, y, \"\"), nil\n} else {\n\treturn b.CreateURem(x, y, \"\"), nil\n}\nwill then become:\nif op == token.QUO {\n\tif (x.Type().TypeKind() == llvm.IntegerTypeKind && x.Type().IntTypeWidth() == 64) ||\n\t\t(y.Type().TypeKind() == llvm.IntegerTypeKind && y.Type().IntTypeWidth() == 64) {\n\t\treturn b.createRuntimeCall(\"uint64div\", []llvm.Value{x, y}, \"\"), nil\n\t} else {\n\t\treturn b.CreateUDiv(x, y, \"\"), nil\n\t}\n} else {\n\tif (x.Type().TypeKind() == llvm.IntegerTypeKind && x.Type().IntTypeWidth() == 64) ||\n\t\t(y.Type().TypeKind() == llvm.IntegerTypeKind && y.Type().IntTypeWidth() == 64) {\n\t\treturn b.createRuntimeCall(\"uint64mod\", []llvm.Value{x, y}, \"\"), nil\n\t} else {\n\t\treturn b.CreateURem(x, y, \"\"), nil\n\t}\n}\nThen we just rebuild the TinyGoâ€™s compiler with a make, and rebuild our application. Letâ€™s retest our previous code:\n\n      Fuck yeah!\n\nAnd for our int64 operations as well please. From the following code:\nif op == token.QUO {\n\treturn b.CreateSDiv(x, y, \"\"), nil\n} else {\n\treturn b.CreateSRem(x, y, \"\"), nil\n}\nwe adapt it into this:\nif op == token.QUO {\n\tif (x.Type().TypeKind() == llvm.IntegerTypeKind && x.Type().IntTypeWidth() == 64) ||\n\t\t(y.Type().TypeKind() == llvm.IntegerTypeKind && y.Type().IntTypeWidth() == 64) {\n\t\treturn b.createRuntimeCall(\"int64div\", []llvm.Value{x, y}, \"\"), nil\n\t} else {\n\t\treturn b.CreateSDiv(x, y, \"\"), nil\n\t}\n} else {\n\tif (x.Type().TypeKind() == llvm.IntegerTypeKind && x.Type().IntTypeWidth() == 64) ||\n\t\t(y.Type().TypeKind() == llvm.IntegerTypeKind && y.Type().IntTypeWidth() == 64) {\n\t\treturn b.createRuntimeCall(\"int64mod\", []llvm.Value{x, y}, \"\"), nil\n\t} else {\n\t\treturn b.CreateSRem(x, y, \"\"), nil\n\t}\n}\nFinally, we can test our changes by doing this:\ndebug.Printf(\"\\n\\n\")\nfor i := int64(-8); i <= 8; i++ {\n\tdebug.Printf(\"%02d | div02 = %02d | mod04 = %02d\\n\", i, i/2, i%4)\n}\n\nAnd with that, weâ€™re done for the 64bit integer problem! Yey!\n\nYes, I know, there might be other instructions that are not implemented. Not looking into this now for sure. Also, yes, I didnâ€™t get big-ass numbers, but also I donâ€™t need them now.\n\nSpoiler: not doing this on the LLVM level will bite our asses in the future.\n\nWhat now?\nWell, now we need to keep pushing forward! But I need to stop this post at some point so that people can catch up with this project, and also so I can publish these findings. But thereâ€™s a lot still to get done:\n\nTarget-specific things, such as syscalls, inline assembly and interrupt support\nFloating points as they are non-functional at the moment\nNew LLVM MIPS CPU - yes, weâ€™ll probably need that, plus this way we can avoid hacking code inside TinyGoâ€™s compiler\nEverything else we want!\n\nYou may be wondering, â€œwhat can I do with it nowâ€? Well, you can do whatever you want, actually. You can call ps2devâ€™s libraries and play with them, and if something fails, you can just call C code from Go. But your code will be running from the Go side of things first, which is pretty neat in my opinion - even if a bit limited for now.\nIâ€™m already working on the next part of this project though, so stay tuned! See you around!\n\n      ğŸ‘‹\n\n     Coding\n\n     Embedded\n\n     Go",
    "summary": {
      "en": "**Summary: Golang on the PlayStation 2**\n\nThe author, Ricardo, is exploring the possibility of running Go programming language code on the PlayStation 2 (PS2), a console released by Sony in 2000. He finds this intriguing because traditional development for consoles typically uses lower-level languages. Ricardo aims to use TinyGo, a Go compiler for small devices, to overcome the limitations of Go's support for the PS2's architecture.\n\nKey challenges include:\n1. **Lack of Direct Support**: Go doesnâ€™t natively support the PS2's Emotion Engine CPU, which requires a workaround using TinyGo.\n2. **Technical Complexity**: The PS2 uses the MIPS R5900 architecture, and integrating with the existing ps2dev SDK introduces compatibility issues.\n3. **Emulator Testing**: Ricardo conducts his experiments in an emulator rather than on actual hardware for convenience.\n\nHe details the process of configuring TinyGo to target the PS2, addressing issues with generating compatible binaries and linking to ps2dev libraries. He also explains the creation of custom runtime definitions and functions necessary for Go to operate on the PS2.\n\nFurther complications arise from the PS2's architecture, specifically the absence of certain MIPS instructions like DDIVU, which affects how integer divisions are handled. Ricardo devises a solution by modifying TinyGo to use auxiliary functions for division.\n\nLooking ahead, he plans to implement more features and optimizations, such as handling floating-point operations and syscalls. He encourages others to experiment with the setup and promises more updates on his progress.",
      "ko": "ë¦¬ì¹´ë¥´ë„ëŠ” 2000ë…„ì— ì†Œë‹ˆê°€ ì¶œì‹œí•œ í”Œë ˆì´ìŠ¤í…Œì´ì…˜ 2(PS2)ì—ì„œ Go í”„ë¡œê·¸ë˜ë° ì–¸ì–´ ì½”ë“œë¥¼ ì‹¤í–‰í•  ê°€ëŠ¥ì„±ì„ íƒêµ¬í•˜ê³  ìˆë‹¤. ê·¸ëŠ” ì „í†µì ì¸ ì½˜ì†” ê°œë°œì´ ë³´í†µ ì €ìˆ˜ì¤€ ì–¸ì–´ë¥¼ ì‚¬ìš©í•œë‹¤ëŠ” ì ì—ì„œ ì´ ì£¼ì œê°€ í¥ë¯¸ë¡­ë‹¤ê³  ìƒê°í•œë‹¤. ë¦¬ì¹´ë¥´ë„ëŠ” PS2ì˜ ì•„í‚¤í…ì²˜ì— ëŒ€í•œ Goì˜ ì§€ì› í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ ì†Œí˜• ì¥ì¹˜ìš© Go ì»´íŒŒì¼ëŸ¬ì¸ TinyGoë¥¼ ì‚¬ìš©í•˜ë ¤ê³  í•œë‹¤.\n\nì£¼ìš” ë„ì „ ê³¼ì œëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤. ì²«ì§¸, GoëŠ” PS2ì˜ ì´ëª¨ì…˜ ì—”ì§„ CPUë¥¼ ê¸°ë³¸ì ìœ¼ë¡œ ì§€ì›í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì— TinyGoë¥¼ ì‚¬ìš©í•´ ìš°íšŒí•´ì•¼ í•œë‹¤. ë‘˜ì§¸, PS2ëŠ” MIPS R5900 ì•„í‚¤í…ì²˜ë¥¼ ì‚¬ìš©í•˜ê³  ìˆìœ¼ë©°, ê¸°ì¡´ì˜ ps2dev SDKì™€ í†µí•©í•˜ëŠ” ê³¼ì •ì—ì„œ í˜¸í™˜ì„± ë¬¸ì œê°€ ë°œìƒí•œë‹¤. ì…‹ì§¸, ë¦¬ì¹´ë¥´ë„ëŠ” ì‹¤ì œ í•˜ë“œì›¨ì–´ ëŒ€ì‹  ì—ë®¬ë ˆì´í„°ì—ì„œ ì‹¤í—˜ì„ ì§„í–‰í•˜ì—¬ í¸ë¦¬í•¨ì„ ì¶”êµ¬í•˜ê³  ìˆë‹¤.\n\nê·¸ëŠ” PS2ë¥¼ ëª©í‘œë¡œ TinyGoë¥¼ ì„¤ì •í•˜ëŠ” ê³¼ì •ì— ëŒ€í•´ ìì„¸íˆ ì„¤ëª…í•˜ë©°, í˜¸í™˜ ê°€ëŠ¥í•œ ë°”ì´ë„ˆë¦¬ë¥¼ ìƒì„±í•˜ê³  ps2dev ë¼ì´ë¸ŒëŸ¬ë¦¬ì— ì—°ê²°í•˜ëŠ” ë° ë°œìƒí•˜ëŠ” ë¬¸ì œë¥¼ ë‹¤ë£¬ë‹¤. ë˜í•œ, Goê°€ PS2ì—ì„œ ì‘ë™í•˜ê¸° ìœ„í•´ í•„ìš”í•œ ì‚¬ìš©ì ì •ì˜ ëŸ°íƒ€ì„ ì •ì˜ì™€ í•¨ìˆ˜ ìƒì„±ì— ëŒ€í•´ì„œë„ ì„¤ëª…í•œë‹¤.\n\nPS2ì˜ ì•„í‚¤í…ì²˜ë¡œ ì¸í•´ ì¶”ê°€ì ì¸ ë³µì¡ì„±ì´ ë°œìƒí•˜ëŠ”ë°, íŠ¹íˆ DDIVUì™€ ê°™ì€ íŠ¹ì • MIPS ëª…ë ¹ì–´ê°€ ì—†ì–´ì„œ ì •ìˆ˜ ë‚˜ëˆ„ê¸° ì²˜ë¦¬ ë°©ì‹ì— ì˜í–¥ì„ ë¯¸ì¹œë‹¤. ë¦¬ì¹´ë¥´ë„ëŠ” ë‚˜ëˆ„ê¸°ë¥¼ ìœ„í•´ ë³´ì¡° í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ë„ë¡ TinyGoë¥¼ ìˆ˜ì •í•˜ëŠ” í•´ê²°ì±…ì„ ê³ ì•ˆí–ˆë‹¤.\n\nì•ìœ¼ë¡œ ê·¸ëŠ” ë¶€ë™ ì†Œìˆ˜ì  ì—°ì‚°ê³¼ ì‹œìŠ¤í…œ í˜¸ì¶œ ì²˜ë¦¬ì™€ ê°™ì€ ë” ë§ì€ ê¸°ëŠ¥ê³¼ ìµœì í™”ë¥¼ êµ¬í˜„í•  ê³„íšì´ë‹¤. ê·¸ëŠ” ë‹¤ë¥¸ ì‚¬ëŒë“¤ë„ ì´ ì„¤ì •ì„ ì‹¤í—˜í•´ ë³´ê¸°ë¥¼ ê¶Œì¥í•˜ë©°, ìì‹ ì˜ ì§„í–‰ ìƒí™©ì— ëŒ€í•œ ì¶”ê°€ ì—…ë°ì´íŠ¸ë¥¼ ì•½ì†í•˜ê³  ìˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "c3a9091d32d97723",
    "title": {
      "en": "I genuinely don't understand why some people are still bullish about LLMs",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://twitter.com/skdh/status/1905132853672784121",
    "score": 654,
    "by": "ksec",
    "time": 1743110562,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "e4f517c188f4dad1",
    "title": {
      "en": "Philosophy of Coroutines (2023)",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://www.chiark.greenend.org.uk/~sgtatham/quasiblog/coroutines-philosophy/",
    "score": 81,
    "by": "HeliumHydride",
    "time": 1743096215,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "efa56325d333129f",
    "title": {
      "en": "Building Node.js on Windows with Clang-cl",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://joyeecheung.github.io/blog/2025/02/16/building-nodejs-on-windows-with-clang-cl/",
    "score": 7,
    "by": "mpweiher",
    "time": 1742907540,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "fea5b956630dbb77",
    "title": {
      "en": "Abundance isn't going to happen unless politicians are scared of the status quo",
      "ko": "ë³€í™” ì—†ì´ëŠ” í’ìš” ì—†ë‹¤",
      "ja": null
    },
    "type": "story",
    "url": "https://inpractice.yimbyaction.org/p/abundance-isnt-going-to-happen-unless",
    "score": 321,
    "by": "viajante1882",
    "time": 1743095353,
    "content": "Share this postIn PracticeAbundance Isnâ€™t Going To Happen Unless Politicians Are Scared of the Status QuoCopy linkFacebookEmailNotesMoreDiscover more from In PracticePractical politics for housing reform. SubscribeBy subscribing,  I agree to Substack's Terms of Use, and acknowledge its Information Collection Notice and Privacy Policy.Already have an account? Sign inAbundance Isnâ€™t Going To Happen Unless Politicians Are Scared of the Status QuoItâ€™s A Race Between Building Up and Burning DownLaura FooteMar 28, 202521Share this postIn PracticeAbundance Isnâ€™t Going To Happen Unless Politicians Are Scared of the Status QuoCopy linkFacebookEmailNotesMore17Shareâ€œToo many goods created a bad.â€Thatâ€™s how California Governor Jerry Brown put it in 2017 when he signed a package of 15 housing-related bills, the first YIMBY-supported pro-housing bills. He was explaining, in his meandering way, how the housing shortage was the result of hundreds of well-intentioned laws, which had promised all kinds of things, but mostly succeeded in slowing down the production of new housing.In many ways, Jerry was ahead of the curve. He was lamenting â€œeverything bagel liberalismâ€ and â€œprocess over outcomesâ€ before it was cool.But at the same time, there was a distinct lack of fire under the Governorâ€™s ass. He was skeptical that this new legislation would do much to unwind the tangled legal web holding back housing production. And while we YIMBYs were bright eyed and bushy tailed, seeing as it was the first state bill signing weâ€™d been invited to, it was also kind of depressing.Less than ten years later, the discourse is suddenly all about the seemingly simple idea that we should â€œdo things and build things,â€ and there is finally a sense of urgency. Iâ€™m heading to Atlanta this week to interview Derek Thompson about his new book Abundance with Ezra Klein at the Georgia Center for the Book (tickets). Their thesis is simple: we need more of everything. More housing, more immigrants, more clean energy infrastructure.And Klein and Thomsonâ€™s book is just the latest entry into the growing genre that attempts to address the root causes of stagnation in America and prescribe a path towards abundance and renewal. Recent books in this genre include:Why Nothing Works by Marc J. DunkelmanStuck by Yoni Applebaum,Recoding America by Jennifer Pahlka,Meanwhile Ned Resnikoff is pointing out that YIMBYs were doing abundance before it was cool (or maybe were the driving force in making it cool). While I appreciate the credit to the original YIMBY brand, Iâ€™m choosing to adopt an abundance mindset about abundance. More is more, after all.SubscribeAs I see it, the Abundance concept isnâ€™t quite an ideology, itâ€™s more of a refocusing on outcomes. Itâ€™s a framework that points to tangible outcomes and asks us to tactically identify what is blocking progress to that goal, irrespective of what the intention of that blockage might be. It extends the classic YIMBY way of doing politics into a larger philosophy. It is a re-focusing on â€œendsâ€ over â€œmeans,â€ and allows for a variety of ideologies to come together on specific ends. The language around â€œoutcomes focused legislatingâ€ brings some degree of sanity to our often self-sabotaging process.Outcome-based politics seems so obvious that it can sound silly to say it out loud. Government should deliver material outcomes. Elected officials should be extremely motivated to produce tangible outcomes for the largest number of people.So why isnâ€™t that happening?Whatâ€™s eating state capacity?The hot topic in the growing abundance discourse is state capacity. Thatâ€™s a fancy term for a simple concept â€” the governmentâ€™s ability to deliver outcomes, whether those are growing the economy, establishing laws, or just picking up the garbage.Itâ€™s not a new idea. In fact, five decades ago, some of the worldâ€™s most pre-eminent political scientists fretted about the erosion of state capacity in democracies across the world. â€œThe demands on democratic government grow,â€ wrote Michael Crozier, Samuel Huntington, and Joji Watanuki, â€œwhile the capacity of democratic government stagnates.â€Sounds familiar, doesnâ€™t it? They argued that in countries like the United States, Japan, and Western Europe, citizens were asking their governments to take on more and more without increasing their governmentâ€™s ability to carry out those projects. That led to an erosion in legitimacy, and decades of retrenchment and cutbacks. About the only thing that the left and the right seemed to agree on was that the â€œera of big government is over.â€The 70â€™s was an era of community organizing to stop The Big Bad Thing, and this urge to tap the brakes continues to this day. Elaborate outreach processes, reporting requirements and the opportunities for objections about those reportsâ€¦ they all can seem reasonable. But added together they created a mighty web. Marc Dunkelman explained the problem of this approach on a recent episode of the Political Gabfest: â€œWe've now created a system where there are so many veto players and you need so many approvals that government fundamentally doesn't work.â€Little by little, we stitched together a gigantic wet blanket that continues to hold back housing production. Itâ€™s easy to blame liberals, but like all of our worst problems, it was bipartisan. Conservatives liked constraining government because they didnâ€™t trust it. Liberals liked constraining it because they overestimated how much those constraints would produce better outcomes like protecting the marginalized, preserving the environment, and elevating the voices of the community. And people who felt that integration was a threat, helped create innumerable local processes to tap the brakes on all kinds of public goods and housing.As a society, we have chronically underestimated the cost of all this. Itâ€™s a chronic case of letting the perfect be the enemy of the good. Every constraint makes the continuation of the status quo more likely. Legislators and advocates know this, but treat it like the normal cost of getting the sausage made. In the process of getting pro-housing bills passed, Iâ€™ve had countless arguments with other advocates and legislators over the innumerable ways bills are weakened. And while weâ€™re taking steps in the right direction, the outcomes still arenâ€™t great.State capacity is being eaten by excessive process. Overly restrictive rules (zoning) and elaborate process (permitting and planning) create chronic shortages driving prices higher and creating an angry populace. Thatâ€™s the TLDR thesis of a lot of the abundance books. Things grind to a halt. People suffer. It all feels incredibly self-sabotaging and frustrating.Two paths forwardThat brings us to today, in which people across the country are mad that shit sucks. I could say more but, come on, shit sucks. Prices are high, infrastructure is crumbling, people are pissed, youâ€™ve heard this already.There are two big responses happening right now:Tear down (DOGE vibes)Build up (Abundance vibes)The DOGE point of view says if the government canâ€™t do anything, we should just get rid of the government. That appeals to many Americans because they are angry. The frustrated urge to blow it all up is strong. As a rule, shortages do not bring out the best in humanity. They make us blame perceived-outsiders and foster the urge to topple governments.The housing shortage fosters a â€œcrabs in a bucketâ€ mentality everywhere, from Blue-dot cities to Red rural communities. Whether your enemy is yuppies, coastal elites or immigrants, the through-line is that there isnâ€™t enough to go around and someone is stealing from us. The DOGE-style of governance is about trying to tell everyone who has been stealing and publicly firing those people.The alternative gaining traction is a (sometimes vague) notion of abundance, which boils down to â€œthings should work.â€ But if these new books are any indication, the Build Up team is feeling more urgency. The consensus that government is not delivering tangible good outcomes for average people is finally being recognized as an existential threat to the democratic project. The constituency for â€œcan we please just fucking do thingsâ€ is real.YIMBY has a practical goal of housing abundance. And for years, YIMBYs have been building ideologically diverse coalitions aligned on that specific, narrow goal.And while that work is great, my key point is that we are running out of time. â€œGet your house in orderâ€ should have a deep level of urgency right now. Elected officials at the state and local level need to rebuild the belief that government is worth preserving and can deliver a thriving middle class.We are in the middle of a race between the destroyers and the builders, and too many elected officials are twiddling their thumbs the sinking ship of the status quo.Who needs to change?People will nod and agree to everything I just said above, but what does it actually look like in practice?Literally yesterday I spoke with a city council member who was thinking about introducing single stair reform in their city. He knew how it could be a deeply impactful reform and is completely safe. But then he said â€œWe canâ€™t do it without the support of the firefighters union, and theyâ€™re deeply opposed.â€ Every redundant requirement was deliberately put there by someone who doesnâ€™t think it needs reform and will fight it. Most elected officials weigh the various highly engaged stakeholders, as if they represent the average voters in their district. Theyâ€™re not.YIMBY Action, through our local chapter model, is building a visible constituency to incentivize politicians to take bolder action on housing. But politicians need to get ahead of this. To critique my own work: it shouldnâ€™t be necessary! Elected officials should be more concerned that the general public is feeling economically stunted and enraged!Incumbents should be more terrified of not doing things. The status quo is a downward trajectory and you will be punished electorally for maintaining it. If people continue to feel economically stunted, they will continue to boot incumbents. Being committed to outcomes requires continuous deep commitment to pushing back, with the knowledge that outcomes add up to that important â€œright track / wrong trackâ€ polling data.Share21Share this postIn PracticeAbundance Isnâ€™t Going To Happen Unless Politicians Are Scared of the Status QuoCopy linkFacebookEmailNotesMore17Share",
    "summary": {
      "en": "The article discusses the urgent need for politicians to prioritize housing and economic growth in the face of a stagnant government system that is failing to deliver positive outcomes for the public. \n\nKey points include:\n\n1. **Historical Context**: California Governor Jerry Brown acknowledged that excessive regulations have slowed housing production, highlighting a long-standing issue in American governance where well-meaning laws have created barriers instead of solutions.\n\n2. **Abundance Mindset**: There is a growing movement advocating for an \"abundance\" mindset, which emphasizes the importance of producing tangible results, such as more housing and infrastructure, rather than getting bogged down by complicated processes and red tape.\n\n3. **State Capacity**: The term \"state capacity\" refers to the government's ability to effectively implement policies. The article argues that excessive rules and procedures have diminished this capacity, leading to frustration among citizens due to rising costs and deteriorating services.\n\n4. **Two Responses to Current Issues**: The article outlines two approaches to addressing these challenges: \n   - **Tear Down**: A radical viewpoint that suggests dismantling government structures due to their inefficacy.\n   - **Build Up**: A more constructive approach focused on improving and expanding government capabilities to deliver better outcomes.\n\n5. **Call to Action**: It emphasizes the urgency for elected officials to act decisively to restore faith in government effectiveness. Politicians should be more afraid of maintaining the status quo than of making bold changes, as public frustration could lead to electoral consequences.\n\nIn summary, the article argues that a shift towards an outcomes-focused approach in governance is essential for addressing the housing crisis and improving public welfare.",
      "ko": "ì´ ê¸°ì‚¬ëŠ” ì •ì¹˜ì¸ë“¤ì´ ì£¼íƒê³¼ ê²½ì œ ì„±ì¥ì„ ìš°ì„ ì‹œí•´ì•¼ í•œë‹¤ëŠ” ê¸´ê¸‰í•œ í•„ìš”ì„±ì„ ë‹¤ë£¨ê³  ìˆìŠµë‹ˆë‹¤. í˜„ì¬ ì •ë¶€ ì‹œìŠ¤í…œì´ ì •ì²´ë˜ì–´ ê¸ì •ì ì¸ ê²°ê³¼ë¥¼ ì œê³µí•˜ì§€ ëª»í•˜ê³  ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.\n\nì²« ë²ˆì§¸ë¡œ, ì—­ì‚¬ì  ë§¥ë½ì„ ì‚´í´ë³´ë©´, ìº˜ë¦¬í¬ë‹ˆì•„ ì£¼ì§€ì‚¬ ì œë¦¬ ë¸Œë¼ìš´ì€ ê³¼ë„í•œ ê·œì œê°€ ì£¼íƒ ìƒì‚°ì„ ì €í•´í•˜ê³  ìˆë‹¤ê³  ì¸ì •í–ˆìŠµë‹ˆë‹¤. ì´ëŠ” ë¯¸êµ­ ì •ë¶€ì—ì„œ ì˜¤ë«ë™ì•ˆ ì´ì–´ì ¸ ì˜¨ ë¬¸ì œë¡œ, ì„ ì˜ì˜ ë²•ë“¤ì´ í•´ê²°ì±…ì´ ì•„ë‹Œ ì¥ë²½ì„ ë§Œë“¤ì–´ì™”ë‹¤ëŠ” ì ì„ ê°•ì¡°í•©ë‹ˆë‹¤.\n\në˜í•œ, 'í’ìš”ë¡œìš´ ì‚¬ê³ ë°©ì‹'ì„ ì§€ì§€í•˜ëŠ” ì›€ì§ì„ì´ ì»¤ì§€ê³  ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ë³µì¡í•œ ì ˆì°¨ì™€ ê·œì œì— ì–½ë§¤ì´ì§€ ì•Šê³ , ë” ë§ì€ ì£¼íƒê³¼ ì¸í”„ë¼ì™€ ê°™ì€ ì‹¤ì§ˆì ì¸ ê²°ê³¼ë¥¼ ìƒì‚°í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë‹¤ëŠ” ì ì„ ê°•ì¡°í•©ë‹ˆë‹¤.\n\n'êµ­ê°€ ì—­ëŸ‰'ì´ë¼ëŠ” ìš©ì–´ëŠ” ì •ë¶€ê°€ ì •ì±…ì„ íš¨ê³¼ì ìœ¼ë¡œ ì‹œí–‰í•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ì´ ê¸°ì‚¬ëŠ” ê³¼ë„í•œ ê·œì¹™ê³¼ ì ˆì°¨ê°€ ì´ ì—­ëŸ‰ì„ ì €í•˜ì‹œì¼œ, ì‹œë¯¼ë“¤ì´ ë¹„ìš© ìƒìŠ¹ê³¼ ì„œë¹„ìŠ¤ ì €í•˜ë¡œ ì¸í•´ ë¶ˆë§Œì„ ëŠë¼ê²Œ ë§Œë“¤ê³  ìˆë‹¤ê³  ì£¼ì¥í•©ë‹ˆë‹¤.\n\ní˜„ì¬ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ ë‘ ê°€ì§€ ì ‘ê·¼ ë°©ì‹ì´ ì œì‹œë©ë‹ˆë‹¤. ì²« ë²ˆì§¸ëŠ” 'ì² ê±°'ë¡œ, ë¹„íš¨ìœ¨ì ì¸ ì •ë¶€ êµ¬ì¡°ë¥¼ í•´ì²´í•˜ìëŠ” ê¸‰ì§„ì ì¸ ê´€ì ì…ë‹ˆë‹¤. ë‘ ë²ˆì§¸ëŠ” 'êµ¬ì¶•'ìœ¼ë¡œ, ì •ë¶€ì˜ ì—­ëŸ‰ì„ ê°œì„ í•˜ê³  í™•ì¥í•˜ì—¬ ë” ë‚˜ì€ ê²°ê³¼ë¥¼ ì œê³µí•˜ìëŠ” ë³´ë‹¤ ê±´ì„¤ì ì¸ ì ‘ê·¼ì…ë‹ˆë‹¤.\n\në§ˆì§€ë§‰ìœ¼ë¡œ, elected officialsê°€ ì •ë¶€ì˜ íš¨ê³¼ì„±ì— ëŒ€í•œ ì‹ ë¢°ë¥¼ íšŒë³µí•˜ê¸° ìœ„í•´ ì‹ ì†í•˜ê²Œ í–‰ë™í•´ì•¼ í•œë‹¤ëŠ” ê¸´ê¸‰ì„±ì„ ê°•ì¡°í•©ë‹ˆë‹¤. ì •ì¹˜ì¸ë“¤ì€ ëŒ€ë‹´í•œ ë³€í™”ë¥¼ ë‘ë ¤ì›Œí•˜ê¸°ë³´ë‹¤ëŠ” í˜„ ìƒíƒœë¥¼ ìœ ì§€í•˜ëŠ” ê²ƒì— ë” ë‘ë ¤ì›€ì„ ëŠê»´ì•¼ í•˜ë©°, ì‹œë¯¼ë“¤ì˜ ë¶ˆë§Œì´ ì„ ê±° ê²°ê³¼ì— ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆë‹¤ëŠ” ì ì„ ì¸ì‹í•´ì•¼ í•©ë‹ˆë‹¤.\n\nê²°ë¡ ì ìœ¼ë¡œ, ì´ ê¸°ì‚¬ëŠ” ì£¼íƒ ìœ„ê¸°ë¥¼ í•´ê²°í•˜ê³  ê³µê³µ ë³µì§€ë¥¼ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ ê²°ê³¼ ì¤‘ì‹¬ì˜ ì ‘ê·¼ ë°©ì‹ìœ¼ë¡œì˜ ì „í™˜ì´ í•„ìˆ˜ì ì´ë¼ê³  ì£¼ì¥í•©ë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "14f7ff8f6ae0bd5e",
    "title": {
      "en": "Learning Theory from First Principles [pdf]",
      "ko": "ê¸°ì´ˆë¶€í„° ë°°ìš°ëŠ” ì´ë¡ ",
      "ja": null
    },
    "type": "story",
    "url": "https://www.di.ens.fr/~fbach/ltfp_book.pdf",
    "score": 190,
    "by": "Anon84",
    "time": 1743108313,
    "content": "Learning Theory from First Principles  August 27, 2024  Francis Bach  francis.bach@inria.fr  Copyright   in   this   Work   has   been   licensed   exclusively   to   The   MIT   Press,  http://mitpress.mit.edu ,   which   will   be   releasing   the   final   version   to   the   public   in 2024.   All inquiries regarding rights should be addressed to The MIT Press, Rights and Permissions Department.\n\nContents  Preface   xi  I   Preliminaries   1  1   Mathematical Preliminaries   3  1.1   Linear Algebra and Differentiable Calculus   . . . . . . . . . . . . . . . . .   3  1.1.1   Minimization of Quadratic Forms   . . . . . . . . . . . . . . . . . . .   3  1.1.2   Inverting a 2   Ã—   2 Matrix   . . . . . . . . . . . . . . . . . . . . . . . .   4  1.1.3   Inverting Matrices Defined by Blocks, Matrix Inversion Lemma   . .   4  1.1.4   Eigenvalue and Singular Value Decomposition   . . . . . . . . . . . .   6  1.1.5   Differential Calculus   . . . . . . . . . . . . . . . . . . . . . . . . . .   7  1.2   Concentration Inequalities   . . . . . . . . . . . . . . . . . . . . . . . . . . .   7  1.2.1   Hoeffdingâ€™s Inequality   . . . . . . . . . . . . . . . . . . . . . . . . .   10  1.2.2   McDiarmidâ€™s Inequality   . . . . . . . . . . . . . . . . . . . . . . . .   13  1.2.3   Bernsteinâ€™s Inequality ( \u0007 )   . . . . . . . . . . . . . . . . . . . . . .   14  1.2.4   Expectation of the Maximum   . . . . . . . . . . . . . . . . . . . . .   16  1.2.5   Estimation of Expectations through Quadrature ( \u0007\u0007 )   . . . . . . .   18  1.2.6   Concentration Inequalities for Random Matrices ( \u0007\u0007 )   . . . . . . .   19  2   Introduction to Supervised Learning   21  2.1   From Training Data to Predictions   . . . . . . . . . . . . . . . . . . . . . .   22  2.2   Decision Theory   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   25  2.2.1   Supervised Learning Problems and Loss Functions   . . . . . . . . .   25  2.2.2   Risks   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   27  2.2.3   Bayes Risk and Bayes Predictor   . . . . . . . . . . . . . . . . . . . .   28  2.3   Learning from Data   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   30  2.3.1   Local Averaging   . . . . . . . . . . . . . . . . . . . . . . . . . . . .   31  2.3.2   Empirical Risk Minimization   . . . . . . . . . . . . . . . . . . . . .   32  2.4   Statistical Learning Theory   . . . . . . . . . . . . . . . . . . . . . . . . . .   36 iii\n\niv   CONTENTS  2.4.1   Measures of Performance   . . . . . . . . . . . . . . . . . . . . . . .   36  2.4.2   Notions of Consistency over Classes of Problems   . . . . . . . . . .   36  2.5   â€œNo Free Lunchâ€ Theorems ( \u0007 )   . . . . . . . . . . . . . . . . . . . . . . . .   38  2.6   Quest for Adaptivity   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   39  2.7   Beyond Supervised Learning   . . . . . . . . . . . . . . . . . . . . . . . . . .   40  2.8   Summaryâ€“Book Outline   . . . . . . . . . . . . . . . . . . . . . . . . . . . .   41  3   Linear Least-Squares Regression   45  3.1   Introduction   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   45  3.2   Least-Squares Framework   . . . . . . . . . . . . . . . . . . . . . . . . . . .   46  3.3   Ordinary Least-Squares Estimator   . . . . . . . . . . . . . . . . . . . . . .   47  3.3.1   Closed-Form Solution   . . . . . . . . . . . . . . . . . . . . . . . . .   47  3.3.2   Geometric Interpretation   . . . . . . . . . . . . . . . . . . . . . . .   48  3.3.3   Numerical Resolution   . . . . . . . . . . . . . . . . . . . . . . . . .   49  3.4   Statistical Analysis of Ordinary Least-Squares   . . . . . . . . . . . . . . . .   49  3.5   Fixed Design Setting   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   50  3.5.1   Statistical Properties of the OLS Estimator   . . . . . . . . . . . . .   52  3.5.2   Experiments   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   54  3.6   Ridge Least-Squares Regression   . . . . . . . . . . . . . . . . . . . . . . . .   56  3.7   Lower Bound ( \u0007 )   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   60  3.8   Random Design Analysis   . . . . . . . . . . . . . . . . . . . . . . . . . . . .   63  3.8.1   Gaussian Designs   . . . . . . . . . . . . . . . . . . . . . . . . . . . .   64  3.8.2   General Designs ( \u0007\u0007 )   . . . . . . . . . . . . . . . . . . . . . . . . .   65  3.9   Principal Component Analysis ( \u0007 )   . . . . . . . . . . . . . . . . . . . . . .   66  3.10 Conclusion   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   68  II   Generalization Bounds for Learning Algorithms   69  4   Empirical Risk Minimization   71  4.1   Convexification of the Risk   . . . . . . . . . . . . . . . . . . . . . . . . . .   72  4.1.1   Convex Surrogates   . . . . . . . . . . . . . . . . . . . . . . . . . . .   73  4.1.2   Geometric Interpretation of the Support Vector Machine ( \u0007 )   . . .   74  4.1.3   Conditional Î¦-risk and Classification Calibration ( \u0007 )   . . . . . . . .   76  4.1.4   Relation between Risk and Î¦-risk ( \u0007\u0007 )   . . . . . . . . . . . . . . .   79  4.2   Risk Minimization Decomposition   . . . . . . . . . . . . . . . . . . . . . .   84  4.3   Approximation Error   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   84  4.4   Estimation Error   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   85  4.4.1   Application of McDiarmidâ€™s Inequality   . . . . . . . . . . . . . . . .   86  4.4.2   Easy Case I: Quadratic Functions   . . . . . . . . . . . . . . . . . . .   87  4.4.3   Easy Case II: Finite Number of Models   . . . . . . . . . . . . . . .   88  4.4.4   Beyond Finitely Many Models through Covering Numbers ( \u0007 )   . .   89  4.5   Rademacher Complexity   . . . . . . . . . . . . . . . . . . . . . . . . . . . .   91  4.5.1   Symmetrization   . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   92\n\nCONTENTS   v  4.5.2   Lipschitz-Continuous Losses   . . . . . . . . . . . . . . . . . . . . . .   94  4.5.3   Ball-Constrained Linear Predictions   . . . . . . . . . . . . . . . . .   96  4.5.4   Putting Things Together (Linear Predictions)   . . . . . . . . . . . .   97  4.5.5   From Constrained to Regularized Estimation ( \u0007 )   . . . . . . . . .   98  4.5.6   Extensions and Improvements   . . . . . . . . . . . . . . . . . . . . .   102  4.6   Model Selection ( \u0007 )   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   103  4.6.1   Structural Risk Minimization ( \u0007 )   . . . . . . . . . . . . . . . . . . .   104  4.6.2   Selection Based on Validation Set ( \u0007 )   . . . . . . . . . . . . . . . .   104  4.7   Relation with Asymptotic Statistics ( \u0007 )   . . . . . . . . . . . . . . . . . . .   105  4.8   Summary   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   107  5   Optimization for Machine Learning   109  5.1   Optimization in Machine Learning   . . . . . . . . . . . . . . . . . . . . . .   109  5.2   Gradient Descent   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   111  5.2.1   Simplest Analysis: Ordinary Least-Squares   . . . . . . . . . . . . .   112  5.2.2   Convex Functions and Their Properties   . . . . . . . . . . . . . . .   116  5.2.3   Analysis of Gradient Descent for Strongly Convex and Smooth Functions   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   119  5.2.4   Analysis of Gradient Descent for Convex and Smooth Functions ( \u0007 )   124  5.2.5   Beyond Gradient Descent ( \u0007 )   . . . . . . . . . . . . . . . . . . . .   126  5.2.6   Nonconvex Objective Functions ( \u0007 )   . . . . . . . . . . . . . . . . .   129  5.3   Gradient Methods on Nonsmooth Problems   . . . . . . . . . . . . . . . . .   130  5.4   Stochastic Gradient Descent   . . . . . . . . . . . . . . . . . . . . . . . . . .   134  5.4.1   Strongly Convex Problems ( \u0007 )   . . . . . . . . . . . . . . . . . . . .   139  5.4.2   Adaptive Methods ( \u0007 )   . . . . . . . . . . . . . . . . . . . . . . . . .   141  5.4.3   Bias-Variance Trade-offs for Least-Squares ( \u0007 )   . . . . . . . . . . .   143  5.4.4   Variance Reduction ( \u0007 )   . . . . . . . . . . . . . . . . . . . . . . . .   146  5.5   Conclusion   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   151  6   Local Averaging Methods   155  6.1   Introduction   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   155  6.2   Local Averaging Methods   . . . . . . . . . . . . . . . . . . . . . . . . . . .   157  6.2.1   Linear Estimators   . . . . . . . . . . . . . . . . . . . . . . . . . . .   157  6.2.2   Partition Estimators   . . . . . . . . . . . . . . . . . . . . . . . . . .   158  6.2.3   Nearest-Neighbors   . . . . . . . . . . . . . . . . . . . . . . . . . . .   160  6.2.4   Nadaraya-Watson Estimator (aka Kernel Regression) ( \u0007 )   . . . . .   162  6.3   Generic Simplest Consistency Analysis   . . . . . . . . . . . . . . . . . . . .   163  6.3.1   Fixed Partition   . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   165  6.3.2   k -nearest Neighbor   . . . . . . . . . . . . . . . . . . . . . . . . . . .   168  6.3.3   Kernel Regression (Nadaraya-Watson) ( \u0007 )   . . . . . . . . . . . . .   170  6.4   Universal Consistency ( \u0007 )   . . . . . . . . . . . . . . . . . . . . . . . . . . .   174  6.5   Adaptivity ( \u0007\u0007 )   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   177  6.6   Conclusion   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   178\n\nvi   CONTENTS  7   Kernel Methods   179  7.1   Introduction   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   180  7.2   Representer Theorem   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   181  7.3   Kernels   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   183  7.3.1   Linear and Polynomial Kernels   . . . . . . . . . . . . . . . . . . . .   186  7.3.2   Translation-Invariant Kernels on [0 ,   1]   . . . . . . . . . . . . . . . .   187  7.3.3   Translation-Invariant Kernels on   R d   . . . . . . . . . . . . . . . . .   191  7.3.4   Beyond Vectorial Input Spaces ( \u0007 )   . . . . . . . . . . . . . . . . . .   194  7.4   Algorithms   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   196  7.4.1   Representer Theorem   . . . . . . . . . . . . . . . . . . . . . . . . .   196  7.4.2   Column Sampling   . . . . . . . . . . . . . . . . . . . . . . . . . . .   197  7.4.3   Random Features   . . . . . . . . . . . . . . . . . . . . . . . . . . . .   198  7.4.4   Dual Algorithms ( \u0007 )   . . . . . . . . . . . . . . . . . . . . . . . . . .   199  7.4.5   Stochastic Gradient Descent ( \u0007 )   . . . . . . . . . . . . . . . . . . .   200  7.4.6   Kernelization of Linear Algorithms   . . . . . . . . . . . . . . . . . .   201  7.5   Generalization Guaranteesâ€“Lipschitz-continuous Losses   . . . . . . . . . . .   202  7.5.1   Risk Decomposition   . . . . . . . . . . . . . . . . . . . . . . . . . .   203  7.5.2   Approximation Error for Translation-Invariant Kernels on   R d   . . .   205  7.6   Theoretical Analysis of Ridge Regression ( \u0007 )   . . . . . . . . . . . . . . . .   208  7.6.1   Kernel Ridge Regression as a Linear Estimator   . . . . . . . . . . .   208  7.6.2   Bias and Variance Decomposition ( \u0007 )   . . . . . . . . . . . . . . . .   209  7.6.3   Relating Empirical and Population Covariance Operators   . . . . .   212  7.6.4   Analysis for Well-Specified Problems ( \u0007 )   . . . . . . . . . . . . . . .   214  7.6.5   Analysis beyond Well-Specified Problems ( \u0007 )   . . . . . . . . . . . .   216  7.6.6   Balancing Bias and Variance ( \u0007 )   . . . . . . . . . . . . . . . . . . .   217  7.7   Experiments   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   218  7.8   Conclusion   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   220  8   Sparse Methods   221  8.1   Introduction   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   221  8.1.1   Dedicated Proof Technique for Constrained Least-Squares   . . . . .   223  8.1.2   Probabilistic and Combinatorial Lemmas   . . . . . . . . . . . . . .   224  8.2   Variable Selection by the   â„“ 0 -penalty   . . . . . . . . . . . . . . . . . . . . .   226  8.2.1   Assuming That   k   Is Known   . . . . . . . . . . . . . . . . . . . . . .   226  8.2.2   Sparsity-Adaptive Estimation (Unknown   k ) ( \u0007 )   . . . . . . . . . . .   228  8.3   Variable Selection by   â„“ 1 -regularization   . . . . . . . . . . . . . . . . . . . .   231  8.3.1   Intuition and Algorithms   . . . . . . . . . . . . . . . . . . . . . . .   231  8.3.2   Slow Ratesâ€“Random Design   . . . . . . . . . . . . . . . . . . . . . .   234  8.3.3   Slow Ratesâ€“Fixed Design (Square Loss)   . . . . . . . . . . . . . . .   236  8.3.4   Fast Ratesâ€“Fixed Design ( \u0007 )   . . . . . . . . . . . . . . . . . . . . .   238  8.3.5   Zoo of Conditions ( \u0007\u0007 )   . . . . . . . . . . . . . . . . . . . . . . . .   239  8.3.6   Fast Ratesâ€“Random Design ( \u0007 )   . . . . . . . . . . . . . . . . . . . .   241  8.4   Experiments   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   243  8.5   Extensions   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   243\n\nCONTENTS   vii  8.6   Conclusion   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   245  9   Neural Networks   247  9.1   Introduction   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   247  9.2   Single Hidden-Layer Neural Network   . . . . . . . . . . . . . . . . . . . . .   249  9.2.1   Optimization   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   251  9.2.2   Rectified Linear Units and Homogeneity   . . . . . . . . . . . . . . .   253  9.2.3   Estimation Error   . . . . . . . . . . . . . . . . . . . . . . . . . . . .   253  9.3   Approximation Properties   . . . . . . . . . . . . . . . . . . . . . . . . . . .   256  9.3.1   Universal Approximation Property in One Dimension   . . . . . . .   256  9.3.2   Infinitely Many Neurons and the Variation Norm   . . . . . . . . . .   257  9.3.3   Variation Norm in One Dimension   . . . . . . . . . . . . . . . . . .   260  9.3.4   Variation Norm in an Arbitrary Dimension   . . . . . . . . . . . . .   263  9.3.5   Precise Approximation Properties   . . . . . . . . . . . . . . . . . .   265  9.3.6   From the Variation Norm to a Finite Number of Neurons ( \u0007 )   . . .   266  9.4   Generalization Performance for Neural Networks   . . . . . . . . . . . . . .   269  9.5   Relationship with Kernel Methods ( \u0007 )   . . . . . . . . . . . . . . . . . . . .   271  9.5.1   From a Banach Space   F 1   to a Hilbert Space   F 2   ( \u0007 )   . . . . . . . . .   271  9.5.2   Kernel Function ( \u0007\u0007 )   . . . . . . . . . . . . . . . . . . . . . . . . .   273  9.5.3   Upper Bound on RKHS Norm ( \u0007\u0007 )   . . . . . . . . . . . . . . . . .   275  9.6   Experiments   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   277  9.7   Extensions   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   278  9.8   Conclusion   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   279  III   Special Topics   281  10 Ensemble Learning   283  10.1 Averaging/Bagging   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   284  10.1.1   Independent Datasets   . . . . . . . . . . . . . . . . . . . . . . . . .   284  10.1.2   Bagging   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   286  10.2 Random Projections and Averaging   . . . . . . . . . . . . . . . . . . . . .   288  10.2.1   Gaussian Sketching   . . . . . . . . . . . . . . . . . . . . . . . . . . .   290  10.2.2   Random Projections   . . . . . . . . . . . . . . . . . . . . . . . . . .   292  10.3 Boosting   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   298  10.3.1   Problem Setup   . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   298  10.3.2   Incremental Learning   . . . . . . . . . . . . . . . . . . . . . . . . .   301  10.3.3   Matching Pursuit   . . . . . . . . . . . . . . . . . . . . . . . . . . . .   302  10.3.4   Adaboost   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   303  10.3.5   Greedy Algorithm Based on Gradient Boosting   . . . . . . . . . . .   304  10.3.6   Convergence of Expected Risk   . . . . . . . . . . . . . . . . . . . .   308  10.3.7   Experiments   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   310  10.4 Conclusion   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   311\n\nviii   CONTENTS  11 From Online Learning to Bandits   313  11.1 First-Order Online Convex Optimization   . . . . . . . . . . . . . . . . . . .   315  11.1.1   Convex Case   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   316  11.1.2   Strongly Convex Case ( \u0007 )   . . . . . . . . . . . . . . . . . . . . . .   318  11.1.3   Online Mirror Descent ( \u0007 )   . . . . . . . . . . . . . . . . . . . . . . .   319  11.1.4   Lower Bounds ( \u0007\u0007 )   . . . . . . . . . . . . . . . . . . . . . . . . . .   321  11.2 Zeroth-Order Convex Optimization   . . . . . . . . . . . . . . . . . . . . . .   323  11.2.1   Smooth Stochastic Gradient Descent   . . . . . . . . . . . . . . . . .   325  11.2.2   Stochastic Smoothing ( \u0007 )   . . . . . . . . . . . . . . . . . . . . . . .   328  11.2.3   Extensions   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   331  11.3 Multiarmed Bandits   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   331  11.3.1   Need for an Exploration-Exploitation Trade-off   . . . . . . . . . . .   333  11.3.2   â€œExplore-Then-Commitâ€   . . . . . . . . . . . . . . . . . . . . . . . .   333  11.3.3   Optimism in the Face of Uncertainty ( \u0007 )   . . . . . . . . . . . . . .   336  11.3.4   Adversarial Bandits ( \u0007 )   . . . . . . . . . . . . . . . . . . . . . . . .   339  11.4 Conclusion   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   341  12 Overparameterized Models   343  12.1 Implicit Bias of Gradient Descent   . . . . . . . . . . . . . . . . . . . . . . .   344  12.1.1   Least-Squares Regression   . . . . . . . . . . . . . . . . . . . . . . .   344  12.1.2   Separable Classification   . . . . . . . . . . . . . . . . . . . . . . . .   346  12.1.3   Beyond Convex Problems ( \u0007 )   . . . . . . . . . . . . . . . . . . . . .   351  12.1.4   Remarks on Implicit Bias   . . . . . . . . . . . . . . . . . . . . . . .   354  12.2 Double Descent   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   355  12.2.1   The Double Descent Phenomenon   . . . . . . . . . . . . . . . . . .   355  12.2.2   Empirical Evidence   . . . . . . . . . . . . . . . . . . . . . . . . . . .   356  12.2.3   Linear Regression with Gaussian Inputs   . . . . . . . . . . . . . . .   358  12.2.4   Linear Regression with Gaussian Projections ( \u0007\u0007 )   . . . . . . . . .   360  12.3 Global Convergence of Gradient Descent   . . . . . . . . . . . . . . . . . . .   365  12.3.1   Mean Field Limits   . . . . . . . . . . . . . . . . . . . . . . . . . . .   365  12.3.2   From Linear Networks to Positive-Definite Matrices   . . . . . . . .   370  12.3.3   Global Convergence for Positive-Definite Matrices   . . . . . . . . .   370  12.3.4   Special Cases   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   374  12.4 Lazy Regime and Neural Tangent Kernels ( \u0007 )   . . . . . . . . . . . . . . . .   375  12.5 Conclusion   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   377  13 Structured Prediction   379  13.1 Multicategory Classification   . . . . . . . . . . . . . . . . . . . . . . . . . .   380  13.1.1   Extension of Classical Convex Surrogates   . . . . . . . . . . . . . .   380  13.1.2   Generalization Bound I: Stochastic Gradient Descent   . . . . . . . .   383  13.1.3   Generalization Bound II: Rademacher Complexities ( \u0007 )   . . . . . .   384  13.2 General Setup and Examples   . . . . . . . . . . . . . . . . . . . . . . . . .   387  13.2.1   Examples   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   387  13.2.2   Structure Encoding Loss Functions   . . . . . . . . . . . . . . . . . .   390\n\nCONTENTS   ix  13.3 Surrogate Methods   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   391  13.3.1   Score Functions and Decoding Step   . . . . . . . . . . . . . . . . . .   392  13.3.2   Fisher Consistency and Calibration Functions   . . . . . . . . . . . .   392  13.3.3   Main Surrogate Frameworks   . . . . . . . . . . . . . . . . . . . . . .   393  13.4 Smooth/Quadratic Surrogates   . . . . . . . . . . . . . . . . . . . . . . . . .   393  13.4.1   Quadratic Surrogate   . . . . . . . . . . . . . . . . . . . . . . . . . .   393  13.4.2   Theoretical Guarantees   . . . . . . . . . . . . . . . . . . . . . . . .   394  13.4.3   Linear Estimators and Decoding Steps   . . . . . . . . . . . . . . . .   395  13.4.4   Smooth Surrogates ( \u0007 )   . . . . . . . . . . . . . . . . . . . . . . . . .   396  13.5 Max-Margin Formulations   . . . . . . . . . . . . . . . . . . . . . . . . . . .   398  13.5.1   Structured Support Vector Machines   . . . . . . . . . . . . . . . . .   399  13.5.2   Max-Min Formulations ( \u0007\u0007 )   . . . . . . . . . . . . . . . . . . . . .   399  13.6 Generalization Bounds ( \u0007 )   . . . . . . . . . . . . . . . . . . . . . . . . . . .   402  13.7 Experiments   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   404  13.7.1   Robust Regression   . . . . . . . . . . . . . . . . . . . . . . . . . . .   404  13.7.2   Ranking   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   404  13.8 Conclusion   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   407  14 Probabilistic Methods   409  14.1 From Empirical Risks to Log-Likelihoods   . . . . . . . . . . . . . . . . . .   409  14.1.1   Conditional Likelihoods   . . . . . . . . . . . . . . . . . . . . . . . .   411  14.1.2   Classical Priors   . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   411  14.1.3   Sparse Priors   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   412  14.1.4   On the Relationship between MAP and MMSE ( \u0007 )   . . . . . . . . .   413  14.2 Discriminative versus Generative Models   . . . . . . . . . . . . . . . . . . .   417  14.2.1   Linear Discriminant Analysis and Softmax Regression   . . . . . . .   417  14.2.2   Naive Bayes   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   418  14.2.3   Maximum Likelihood Estimations   . . . . . . . . . . . . . . . . . .   419  14.3 Bayesian Inference   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   420  14.3.1   Computational Handling of Posterior Distributions   . . . . . . . . .   421  14.3.2   Model Selection through Marginal Likelihood   . . . . . . . . . . . .   422  14.4 PAC-Bayesian Analysis   . . . . . . . . . . . . . . . . . . . . . . . . . . . .   423  14.4.1   Setup   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   423  14.4.2   Uniformly Bounded Loss Functions   . . . . . . . . . . . . . . . . . .   424  14.5 Conclusion   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   426  15 Lower Bounds   427  15.1 Statistical Lower Bounds   . . . . . . . . . . . . . . . . . . . . . . . . . . . .   428  15.1.1   Minimax Lower Bounds   . . . . . . . . . . . . . . . . . . . . . . . .   428  15.1.2   Reduction to a Hypothesis Test   . . . . . . . . . . . . . . . . . . . .   429  15.1.3   Review of Information Theory   . . . . . . . . . . . . . . . . . . . .   431  15.1.4   Lower Bound on Hypothesis Testing Based on Information Theory   434  15.1.5   Examples   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   436  15.1.6   Minimax Lower Bounds through Bayesian Analysis   . . . . . . . . .   438\n\nx   CONTENTS  15.2 Optimization Lower Bounds   . . . . . . . . . . . . . . . . . . . . . . . . . .   441  15.2.1   Convex Optimization   . . . . . . . . . . . . . . . . . . . . . . . . .   441  15.2.2   Nonconvex Optimization ( \u0007 )   . . . . . . . . . . . . . . . . . . . . .   443  15.3 Lower Bounds for Stochastic Gradient Descent ( \u0007 )   . . . . . . . . . . . . .   447  15.4 Conclusion   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   449  Conclusion   451  References   453",
    "summary": {
      "en": "The text is a detailed outline of a book titled \"Learning Theory from First Principles\" by Francis Bach, set to be published by The MIT Press in 2024. The contents include various topics related to learning theory and machine learning, organized into sections that cover mathematical concepts, supervised learning, statistical learning theory, optimization techniques, and advanced methods like neural networks and kernel methods.\n\nKey sections of the book include:\n1. **Mathematical Preliminaries**: Basics of linear algebra, calculus, and concentration inequalities.\n2. **Supervised Learning**: From training data to predictions, including decision theory, learning from data, and statistical learning theory.\n3. **Linear Least-Squares Regression**: Techniques for regression analysis and statistical properties.\n4. **Generalization Bounds**: Discusses empirical risk minimization and model selection.\n5. **Optimization for Machine Learning**: Covers gradient descent and stochastic methods.\n6. **Local Averaging Methods**: Examines various averaging techniques and their consistency.\n7. **Kernel Methods**: Introduces the concept of kernels and their applications in machine learning.\n8. **Sparse Methods**: Discusses variable selection techniques.\n9. **Neural Networks**: Explores single hidden-layer networks and their properties.\n10. **Ensemble Learning**: Covers techniques like bagging and boosting.\n11. **Probabilistic Methods**: Discusses Bayesian inference and related concepts.\n\nThe book aims to provide a comprehensive understanding of learning theory, blending theory with practical applications and advanced methodologies.",
      "ko": "í”„ë€ì‹œìŠ¤ ë°”íì˜ \"Learning Theory from First Principles\"ë¼ëŠ” ì œëª©ì˜ ì±…ì´ 2024ë…„ MIT í”„ë ˆìŠ¤ì—ì„œ ì¶œê°„ë  ì˜ˆì •ì´ë‹¤. ì´ ì±…ì€ í•™ìŠµ ì´ë¡ ê³¼ ê¸°ê³„ í•™ìŠµì— ê´€ë ¨ëœ ë‹¤ì–‘í•œ ì£¼ì œë¥¼ ë‹¤ë£¨ë©°, ìˆ˜í•™ì  ê°œë…, ì§€ë„ í•™ìŠµ, í†µê³„ì  í•™ìŠµ ì´ë¡ , ìµœì í™” ê¸°ë²•, ì‹ ê²½ë§ ë° ì»¤ë„ ë°©ë²•ê³¼ ê°™ì€ ê³ ê¸‰ ë°©ë²•ë¡ ìœ¼ë¡œ êµ¬ì„±ëœ ì—¬ëŸ¬ ì„¹ì…˜ìœ¼ë¡œ ë‚˜ë‰˜ì–´ ìˆë‹¤.\n\nì±…ì˜ ì£¼ìš” ì„¹ì…˜ì€ ë‹¤ìŒê³¼ ê°™ë‹¤. ì²« ë²ˆì§¸ëŠ” ìˆ˜í•™ì  ê¸°ì´ˆë¡œ, ì„ í˜• ëŒ€ìˆ˜, ë¯¸ì ë¶„í•™, ì§‘ì¤‘ ë¶ˆí‰ë“±ì˜ ê¸°ë³¸ ê°œë…ì„ ì„¤ëª…í•œë‹¤. ë‘ ë²ˆì§¸ ì„¹ì…˜ì€ ì§€ë„ í•™ìŠµìœ¼ë¡œ, í›ˆë ¨ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ëŠ” ê³¼ì •ê³¼ ì˜ì‚¬ ê²°ì • ì´ë¡ , ë°ì´í„°ë¡œë¶€í„° í•™ìŠµí•˜ëŠ” ë°©ë²•, í†µê³„ì  í•™ìŠµ ì´ë¡ ì„ í¬í•¨í•œë‹¤. ì„¸ ë²ˆì§¸ëŠ” ì„ í˜• ìµœì†Œ ì œê³± íšŒê·€ë¡œ, íšŒê·€ ë¶„ì„ ê¸°ë²•ê³¼ í†µê³„ì  ì„±ì§ˆì„ ë‹¤ë£¬ë‹¤. ë„¤ ë²ˆì§¸ëŠ” ì¼ë°˜í™” ê²½ê³„ì— ëŒ€í•œ ë‚´ìš©ìœ¼ë¡œ, ê²½í—˜ì  ìœ„í—˜ ìµœì†Œí™”ì™€ ëª¨ë¸ ì„ íƒì— ëŒ€í•´ ë…¼ì˜í•œë‹¤.\n\në‹¤ì„¯ ë²ˆì§¸ ì„¹ì…˜ì€ ê¸°ê³„ í•™ìŠµì„ ìœ„í•œ ìµœì í™” ê¸°ë²•ìœ¼ë¡œ, ê²½ëŸ‰ í•˜ê°•ë²•ê³¼ í™•ë¥ ì  ë°©ë²•ì„ í¬í•¨í•œë‹¤. ì—¬ì„¯ ë²ˆì§¸ëŠ” ì§€ì—­ í‰ê·  ë°©ë²•ìœ¼ë¡œ, ë‹¤ì–‘í•œ í‰ê·  ê¸°ë²•ê³¼ ê·¸ ì¼ê´€ì„±ì„ ì‚´í´ë³¸ë‹¤. ì¼ê³± ë²ˆì§¸ëŠ” ì»¤ë„ ë°©ë²•ìœ¼ë¡œ, ì»¤ë„ì˜ ê°œë…ê³¼ ê¸°ê³„ í•™ìŠµì—ì„œì˜ ì‘ìš©ì„ ì†Œê°œí•œë‹¤. ì—¬ëŸ ë²ˆì§¸ëŠ” í¬ì†Œ ë°©ë²•ìœ¼ë¡œ, ë³€ìˆ˜ ì„ íƒ ê¸°ë²•ì— ëŒ€í•´ ë…¼ì˜í•œë‹¤. ì•„í™‰ ë²ˆì§¸ëŠ” ì‹ ê²½ë§ìœ¼ë¡œ, ë‹¨ì¼ ì€ë‹‰ì¸µ ë„¤íŠ¸ì›Œí¬ì™€ ê·¸ íŠ¹ì„±ì„ íƒêµ¬í•œë‹¤. ì—´ ë²ˆì§¸ëŠ” ì•™ìƒë¸” í•™ìŠµìœ¼ë¡œ, ë°°ê¹…ê³¼ ë¶€ìŠ¤íŒ…ê³¼ ê°™ì€ ê¸°ë²•ì„ ë‹¤ë£¬ë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ, í™•ë¥ ì  ë°©ë²•ì—ì„œëŠ” ë² ì´ì§€ì•ˆ ì¶”ë¡ ê³¼ ê´€ë ¨ ê°œë…ì„ ì„¤ëª…í•œë‹¤.\n\nì´ ì±…ì€ í•™ìŠµ ì´ë¡ ì— ëŒ€í•œ í¬ê´„ì ì¸ ì´í•´ë¥¼ ì œê³µí•˜ë©°, ì´ë¡ ê³¼ ì‹¤ì œ ì‘ìš©, ê³ ê¸‰ ë°©ë²•ë¡ ì„ ê²°í•©í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•˜ê³  ìˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "e9ae83fde3e64616",
    "title": {
      "en": "Banned Books: Analysis of Censorship on Amazon.com (2024)",
      "ko": "ê¸ˆì„œì˜ ì§„ì‹¤: ì•„ë§ˆì¡´ ê²€ì—´ ë¶„ì„",
      "ja": null
    },
    "type": "story",
    "url": "https://citizenlab.ca/2024/11/analysis-of-censorship-on-amazon-com/",
    "score": 98,
    "by": "gnabgib",
    "time": 1743104270,
    "content": "ResearchFree Expression Online\n\n\tBanned Books\n\n\t Analysis of Censorship on Amazon.com\n\n            By\n            Jeffrey Knockel, Jakub Dalek, Noura Aljizawi, Mohamed Ahmed, Levi Meletti, and Justin Lau\n\n          November 25, 2024\n\n              Ø§Ù„ØªØ±Ø¬Ù…Ø© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© (Arabic translation)\n\n                   Download this report\n\n                  Key findings\n\nWe analyze the system Amazon deploys on the US â€œamazon.comâ€ storefront to restrict shipments of certain products to specific regions. We found 17,050 products that Amazon restricted from being shipped to at least one world region.\nWhile many of the shipping restrictions are related to regulations involving WiFi, car seats, and other heavily regulated product categories, the most common product category restricted by Amazon in our study was books.\nBanned books were largely related to LGBTIQ, the occult, erotica, Christianity, and health and wellness. The regions affected by this censorship were the UAE, Saudi Arabia, and many other Middle Eastern countries as well as Brunei Darussalam, Papua New Guinea, Seychelles, and Zambia. In our test sample, Amazon censored over 1.1% of the books sold on amazon.com in at least one of these regions.\nWe identified three major censorship blocklists which Amazon assigns to different regions. In numerous cases, the resulting censorship is either overly broad or miscategorized. Examples include the restriction of books relating to breast cancer, recipe books invoking â€œfood pornâ€ euphemisms, Nietzscheâ€™s Gay Science, and â€œrainbowâ€ Mentos candy.\nTo justify why restricted products cannot be shipped, Amazon uses varying error messages such as by conveying that an item is temporarily out of stock. In misleading its customers and censoring books, Amazon is violating its public commitments to both LGBTIQ and more broadly human rights.\nWe conclude our report by providing Amazon multiple recommendations to address concerns raised by our work.\n\nIntroduction\nThe rise in online shopping has led to more global reach into markets that may otherwise be inaccessible for companies through traditional retail channels. This increased reach brings new opportunities but also has its own challenges for global e-commerce retailers. One such challenge is in dealing with different, more restrictive regulatory environments worldwide.\nIn this report, we analyze American e-commerce retailer Amazon and its system for preventing shipments of certain products to certain world regions as it is implemented on the US storefront â€” amazon.com. Specifically, we analyze functionality that Amazon implements to restrict shipments of certain products to certain regions even if the product is available and sellers are offering to ship it there. While Amazon normally hides this restriction system from customers using misleading error messages, we employ a novel methodology to uncover and measure on which products and in which regions it is activated by peeling back the layers of Amazonâ€™s website and analyzing its internal workings. Notably, our method can distinguish between a product being restricted by Amazon and it being organically unavailable in a region.\nIn total, we found 17,050 products that were restricted from being shipped to at least one world region. While many of the shipping restrictions observed in our study are related to regulations involving WiFi, car seats, and other heavily regulated product categories, the most common product category restricted by Amazon was books. Banned books were largely related to LGBTIQ, the occult, erotica, Christianity, and health and wellness. More broadly, books were the victims of censorship, which in this report we define as Amazonâ€™s restriction of product shipment under political or religious motivation. The regions commonly affected by this censorship were the United Arab Emirates (UAE), Saudi Arabia, and many other Middle Eastern countries as well as Brunei Darussalam, Papua New Guinea, Seychelles, and Zambia.\nGiven that the topics censored include LGBTIQ, our findings call into question Amazonâ€™s public commitment to LGBTIQ rights as well as its respect for the rights of its users at large. By censoring the availability of books, Amazon is depriving its users of valuable information. Furthermore, by communicating to customers that censored products are organically unavailable (e.g., being out of stock), Amazon is depriving customers of the ability to make informed decisions. We conclude our report by making multiple recommendations to Amazon.\nBackground\nIn this section we briefly describe Amazonâ€™s history as it relates to our analysis. We then outline some of the regulations applying to Amazonâ€™s business in Saudi Arabia, the UAE, and China, which are some of the more restrictive regulatory environments to which products on amazon.com can be shipped.\nAmazon background\nAmazon is an American multinational company that originated as an online bookseller and has since evolved into a global e-commerce marketplace. Amazonâ€™s business is heavily focused on managing shipping logistics internationally and serving a global consumer base. Alongside the main e-commerce platform, they also provide cloud computing services (Amazon Web Services), consumer electronics (Amazon Kindle and Amazon Echo), and online streaming (Amazon Prime Video) among other offerings.\nAmazon is best known for its original website â€” amazon.com â€” which serves as the landing page for US customers, although items can be shipped globally depending on seller preferences. As of 2024, there are dedicated storefronts for 22 other regions. Alongside the online expansions to other regions there has been an analogous expansion of physical infrastructure in those regions including shipping hubs, fulfillment centers, sorting facilities, and delivery stations.\nMost relevant to our study, Amazon has expanded its dedicated storefronts to include the UAE in 2017 and Saudi Arabia in 2020. This expansion included opening a regional headquarters in Riyadh, Saudi Arabia, in 2022 and a fulfillment center in Dubai, the UAE, in 2023. These recent expansions into the Middle East create their own unique challenges to the retailer because of the regionâ€™s distinct regulatory regimes, which we detail below.\nCompliance with international regulations\nAmazon polices the products sold on its platform, and their own shipping restrictions FAQ provides some guidance on why certain products may be restricted, including the need to â€œcomply with all laws and regulations and with Amazon policiesâ€ and that Amazon may be â€œrestricted from shipping to your location due to government import/export requirements, manufacturer restrictions, or warranty issuesâ€. Amazon has adapted its policies to allow for the removal of offensive content including content that Amazon determines is â€œhate speech, promotes the abuse or sexual exploitation of children, contains pornography, glorifies rape or pedophilia, advocates terrorismâ€, but also â€œother material [they] deem inappropriate or offensiveâ€. However, Amazon has failed to reveal specifically what categories of content it restricts to comply with the demands of authoritarian governments.\nThere have been reported incidences where Amazon complied with governmentsâ€™ requests to restrict certain products or even go as far as manipulate its reviews. For example, Amazon restricted items for purchase and in search results relating to over 150 keywords relating to LGBTIQ content in the UAE after receiving pressure from the government to remove them. In China, Amazon removed all customer ratings and reviews for a book of Chinese president Xi Jinpingâ€™s speeches and writings. In both instances, Amazon claimed that they were following local laws and regulations. However, in India, internal Amazon documents showed that Amazon was circumventing local regulations by providing preferential treatment to certain sellers and by also promoting its own merchandise by rigging search results. Amazon has also been criticized for allowing its platform to spread white supremacy and racism. Items with Nazi symbols and Kindle books associated with neo-Nazis and white supremacists have remained widely available despite Amazon having been notified by journalists and non-profit organizations.\nRegulations in Saudi Arabia\nIn Saudi Arabia, content is largely governed by two laws: the 2003 Law of Printing and Publication, largely regulating print media, and the 2007 Anti-Cyber Crimes Law, regulating online media. Article 9 of the Law of Printing and Publications states that printed media cannot contravene Sharia Law, stir up internal discord, injure the economic and health situation of the country, or lead to a breach of either public security, public policy, or foreign interests. Article 18 states these regulations should apply to the importation and distribution of printed materials. An approval is required, within the framework of Article 18 of the Printing and Publication law, in order to certify that content is free from any content that is insulting to Islam, the government, interests of the Emirates, or ethical standard and public morality. In terms of enforcement, Article 39 states that any contravening printed items can be withdrawn from circulation if they are found to violate either Articles 9 or 18.\nThe 2007 Anti-Cyber Crimes Law is chiefly focused on regulations around information security and content regulation. Article 6 of this law states that â€œproduction, preparation, transmission, or storage of material impinging on public order, religious values, public morals, or privacy, through an information network or computerâ€ is a criminal offense. Contravening this article can lead to a maximum punishment of five years in prison and a maximum fine of three million riyals (approximately 800,000 USD). This law has been applied against online content. For example, in 2019, Saudi Arabia alerted Netflix that an episode of Hasan Minhajâ€™s comedy show Patriot Act violated this statute as it contained criticism of a Saudi Arabian royal. Netflix complied with the government order and restricted access to the episode for Saudi Arabian users.\nRegulations in the UAE\nIn the UAE, content is governed by the Federal Decree-Law No.55 of 2023 on Media Regulation, which replaced the previous Federal Law No.15 of 1980 Concerning Publications and Publishing. Specifically, it regulates print, television, as well as online media. Another relevant regulation is the Internet Access Management Regulatory Policy which focuses on the regulation of online content. Under this policy, the only two internet service providers (ISPs) in the UAE, Etisalat and Du, are required to block online content if requested by the Telecommunications and Digital Government Regulatory Authority. Prohibited Internet content includes pornography, contempt of religion, and promotion of or trading in prohibited commodities and services. Category 13 of the policy prohibits sites from promoting or trading in commodities prohibited or restricted by licenses in the UAE, including â€œprints, paintings, photographs, drawings, cards, books, magazines, and stone sculptures, which are contrary to the Islamic religion or public morals, or involving intent of corruption or seditionâ€.\nCompliance with Chinese demands\nIn 2004, Amazon entered the Chinese market via its acquisition of Joyo, a Chinese online bookstore. Amazon faced scrutiny for its political censorship of products on its Chinese site â€” amazon.cn. However, facing competition from domestic rivals, Amazon terminated its online store in China in 2019, although for a limited time overseas products were still sold on the amazon.cn site. Amazon still has other operations in China, such as Amazon Web Services (AWS), which is Amazonâ€™s cloud computing service. Outside of China, in 2021, on the US Amazon storefront â€” amazon.com â€” Amazon partnered with China International Book Trading Corp, a state-owned firm that has been labeled as â€œChinaâ€™s state propaganda armâ€, to create a portal for selling books that amplify the Chinese Communist Partyâ€™s agenda.\nMethodology\nIn this section, we explain how we determine product availability across different regions. Our methodology consists of two phases. As our original motivation was to understand how Amazon censorship applies to Middle Eastern countries, in our first phase, we focus on studying how products and shipment restrictions vary across multiple countries in the Middle East. We were particularly motivated to understand the differences between restrictions imposed on the shipment of products to Middle Eastern countries in which Amazon operates a storefront (namely, the UAE and Saudi Arabia) versus those in which it does not. To understand how censorship applies more broadly to the world at large, in our second phase we pivot from the results of the first phase and measure product availability in regions across the globe.\nIn designing our methodology, we were motivated by eliminating false positives, even if doing so might introduce false negatives. The rationale is that we would rather omit the measurement of some instances of censorship rather than falsely attribute censorship to products that are not censored.\nIn the remainder of this section we explain the two phases of our methodology.\nPhase 1: Measuring censorship in Middle East\nOne way to try to measure Amazon censorship in Middle Eastern countries would be to visit those Amazon storefronts which are available in the Middle East, namely, the UAEâ€™s amazon.ae or Saudi Arabiaâ€™s amazon.sa, and to try to determine which products are anomalously â€œmissingâ€ from being sold on these two Amazon sites. This approach, however, would be limited. For example, if we saw one book related to LGBTIQ topics that was sold on amazon.com but not amazon.ae, that might be due to the book being censored on amazon.ae, but another possibility is that the book was out of stock or not sufficiently popular to be sold in some countries. However, if we saw a disproportionately large number of books related to LGBTIQ topics that were available on amazon.com but not sold on amazon.ae, then we would have a stronger argument, but this argument would be at best a statistical argument, and for any individual product we would not be able to prove whether it was",
    "summary": {
      "en": "**Summary of \"Analysis of Censorship on Amazon.com\"**\n\nThis report examines how Amazon restricts shipments of certain products, particularly books, to various global regions, particularly in the Middle East. Key findings include:\n\n- **Product Restrictions**: Amazon restricted over 17,000 products, with books being the most commonly affected category. This includes titles related to LGBTIQ issues, the occult, erotica, Christianity, and health topics.\n\n- **Affected Regions**: The main regions impacted by these restrictions are the UAE, Saudi Arabia, and several other Middle Eastern countries, as well as Brunei, Papua New Guinea, Seychelles, and Zambia. In total, more than 1.1% of books sold on Amazon.com were censored in at least one of these areas.\n\n- **Censorship Practices**: Amazon uses misleading messages, such as saying items are \"out of stock,\" to obscure the censorship. This practice raises concerns about the company's commitment to human rights, particularly LGBTIQ rights.\n\n- **Censorship Justifications**: Amazon cites compliance with local laws and regulations as reasons for these restrictions, but the criteria for what is deemed offensive or inappropriate are not transparent.\n\n- **Recommendations**: The report concludes with suggestions for Amazon to improve its practices regarding censorship and transparency.\n\nOverall, the study highlights the conflicts between Amazon's global operations and local regulatory environments, particularly regarding sensitive content.",
      "ko": "ì´ ë³´ê³ ì„œëŠ” ì•„ë§ˆì¡´ì´ íŠ¹ì • ì œí’ˆ, íŠ¹íˆ ì±…ì˜ ë°°ì†¡ì„ ì–´ë–»ê²Œ ì œí•œí•˜ëŠ”ì§€ë¥¼ ë¶„ì„í•˜ê³  ìˆìœ¼ë©°, íŠ¹íˆ ì¤‘ë™ ì§€ì—­ì— ì´ˆì ì„ ë§ì¶”ê³  ìˆìŠµë‹ˆë‹¤. ì£¼ìš” ë‚´ìš©ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n\nì•„ë§ˆì¡´ì€ 17,000ê°œ ì´ìƒì˜ ì œí’ˆì„ ì œí•œí–ˆìœ¼ë©°, ê·¸ ì¤‘ ì±…ì´ ê°€ì¥ ë§ì´ ì˜í–¥ì„ ë°›ëŠ” ì¹´í…Œê³ ë¦¬ì…ë‹ˆë‹¤. ì œí•œëœ ì œí’ˆì—ëŠ” LGBTIQ ë¬¸ì œ, ì˜¤ì»¬íŠ¸, ì—ë¡œí‹°ì¹´, ê¸°ë…êµ ë° ê±´ê°• ê´€ë ¨ ì£¼ì œì˜ ì œëª©ë“¤ì´ í¬í•¨ë©ë‹ˆë‹¤.\n\nì´ëŸ¬í•œ ì œí•œì˜ ì£¼ìš” ëŒ€ìƒ ì§€ì—­ì€ ì•„ëì—ë¯¸ë¦¬íŠ¸, ì‚¬ìš°ë””ì•„ë¼ë¹„ì•„ ë° ì—¬ëŸ¬ ì¤‘ë™ êµ­ê°€ë“¤, ê·¸ë¦¬ê³  ë¸Œë£¨ë‚˜ì´, íŒŒí‘¸ì•„ë‰´ê¸°ë‹ˆ, ì„¸ì´ì…¸, ì ë¹„ì•„ ë“±ì…ë‹ˆë‹¤. ì „ì²´ì ìœ¼ë¡œ ì•„ë§ˆì¡´.comì—ì„œ íŒë§¤ë˜ëŠ” ì±…ì˜ 1.1% ì´ìƒì´ ì´ëŸ¬í•œ ì§€ì—­ ì¤‘ ìµœì†Œ í•œ ê³³ì—ì„œ ê²€ì—´ë˜ì—ˆìŠµë‹ˆë‹¤.\n\nì•„ë§ˆì¡´ì€ ê²€ì—´ì„ ìˆ¨ê¸°ê¸° ìœ„í•´ \"ì¬ê³  ì—†ìŒ\"ê³¼ ê°™ì€ ì˜¤í•´ì˜ ì†Œì§€ê°€ ìˆëŠ” ë©”ì‹œì§€ë¥¼ ì‚¬ìš©í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ê´€í–‰ì€ LGBTIQ ê¶Œë¦¬ì™€ ê°™ì€ ì¸ê¶Œì— ëŒ€í•œ íšŒì‚¬ì˜ í—Œì‹ ì— ëŒ€í•œ ìš°ë ¤ë¥¼ ë¶ˆëŸ¬ì¼ìœ¼í‚µë‹ˆë‹¤.\n\nì•„ë§ˆì¡´ì€ ì´ëŸ¬í•œ ì œí•œì˜ ì´ìœ ë¡œ í˜„ì§€ ë²•ë¥  ë° ê·œì •ì„ ì¤€ìˆ˜í•œë‹¤ê³  ì£¼ì¥í•˜ì§€ë§Œ, ë¬´ì—‡ì´ ë¶ˆì¾Œí•˜ê±°ë‚˜ ë¶€ì ì ˆí•œì§€ì— ëŒ€í•œ ê¸°ì¤€ì€ ëª…í™•í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n\në³´ê³ ì„œëŠ” ì•„ë§ˆì¡´ì´ ê²€ì—´ ë° íˆ¬ëª…ì„± ê´€ë ¨ ê´€í–‰ì„ ê°œì„ í•  ìˆ˜ ìˆëŠ” ì œì•ˆìœ¼ë¡œ ë§ˆë¬´ë¦¬ë©ë‹ˆë‹¤. ì „ë°˜ì ìœ¼ë¡œ ì´ ì—°êµ¬ëŠ” ì•„ë§ˆì¡´ì˜ ê¸€ë¡œë²Œ ìš´ì˜ê³¼ ì§€ì—­ ê·œì œ í™˜ê²½ ê°„ì˜ ê°ˆë“±, íŠ¹íˆ ë¯¼ê°í•œ ì½˜í…ì¸ ì™€ ê´€ë ¨ëœ ë¬¸ì œë¥¼ ê°•ì¡°í•˜ê³  ìˆìŠµë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "ce64f63b9d59fbed",
    "title": {
      "en": "Plastic-like materials that dissolve in the sea",
      "ko": "ë°”ë‹¤ì—ì„œ ë…¹ëŠ” í”Œë¼ìŠ¤í‹±",
      "ja": null
    },
    "type": "story",
    "url": "https://www.riken.jp/en/news_pubs/research_news/rr/20250327_1/index.html",
    "score": 3,
    "by": "geox",
    "time": 1743189029,
    "content": "<div class=\"lytBox01\">\n<p>Please enable JavaScript in your browser.</p>\n<!-- /.lytBox01 --></div>\n\n\t\t\t(function(d, s, id) {\n\t\t\t\tvar js, fjs = d.getElementsByTagName(s)[0];\n\t\t\t\tif (d.getElementById(id))\n\t\t\t\t\treturn;\n\t\t\t\tjs = d.createElement(s);\n\t\t\t\tjs.id = id;\n\t\t\t\tjs.src = 'https://connect.facebook.net/en_US/sdk.js#xfbml=1&version=v3.2';\n\t\t\t\tfjs.parentNode.insertBefore(js, fjs);\n\t\t\t}(document, 'script', 'facebook-jssdk'));\n\n\tTweet\n\n\t\t\t\t\t\t\t\t Mar. 27, 2025\n\t\t\t\t\t\t\t\tFeature Highlight\n\n\t\tChemistry\n\n\t\t\t\t\t\t\tPlastic-like materials that dissolve in the sea\n\n\t\t\t\t\t\t\t\tSupramolecular materials that fully degrade when soaked in saltwater have the potential to help address the microplastics pollution crisis.\n\nArtistic rendering of the new plastic. Cross linked salt bridges visible in the plastic outside the seawater give it its structure and strength. In seawater (and in soil, not depicted), resalting destroys the bridges, making it water soluble, thus preventing microplastic formation and allowing the plastic to become biodegradable. Â© 2025 RIKEN\n\nMicroplasticsâ€”small fragments of plastics less than 5mm acrossâ€”now infiltrate every corner of our planet, from remote regions of the deep ocean and the Arctic, to the very air we breathe.\n Increasingly microplastics are also found in our bodies, including in our blood and brains. While the impact on the environment and human health is still not fully understood, these contaminants are known to cause a range of problems in marine and terrestrial ecosystems, including slowing the growth of animals, which impacts fertility and causes organ dysfunction.\nSeawater solution\nRIKEN scientists are aiming to tackle the problem of microplastics in the ocean with a new material that biodegrades in saltwater.\nSimilar in weight and strength to conventional plastics, the new material could chart a new path to reducing plastics pollution, as well as reduce greenhouse gas emissions associated with burning plastics, says Takuzo Aida, a materials scientist who heads the Emergent Soft Matter Function Research Group at the RIKEN Center for Emergent Matter Science in Wako, Japan.\nThis new plastic is a culmination of his three decades of pioneering work as an expert in materials called supramolecular polymers. Plastics are a type of polymer, which are comprised of small molecules bound into long chains by strong covalent bonds that require extensive energy to break.\n In contrast, supramolecular polymers have weaker, reversible bonds â€œlike sticky notes that you can attach and peel off,â€ explains Aida.\nThis gives supramolecular polymers unique properties, such as the ability to 'self-heal' when broken and then pressed back together. They are also easy to recycle, by using specific solvents to break down the materialsâ€™ bonds at the molecular level, meaning that supramolecular polymers can be easily reused and repurposed.\nUnlocking bonds\nPlastic products are everywhere for a reason, says Aida. â€œPlastics, especially polyethylene terephthalate, which is used in bottles, are incredibly versatile. They are flexible but strong, durable and recyclable. Itâ€™s hard to beat that convenience.â€\nBiodegradable plastics have been touted as an alternative, but Aida says the speed and conditions at which they degrade have been a major challenge. For instance, he says, significant amounts of polylactic acid (PLA), a plastic that biodegrades in soil, have been found intact in the ocean because it takes too long to break down under standard environmental conditions. As a result, it eventually ends up intact in the ocean. Since plastics such as PLA are not water-soluble, they slowly break up over time into microplastics that cannot be broken down by bacteria, fungi and enzymes.\nDriven by a sense of urgency for the planetâ€™s future, Aida began seeking ways for supramolecular materials to overcome these challenges. â€œBut the reversible nature of the supramolecular polymer bonds are also their weakness, since the materials disintegrate too easily,â€ he says. â€œThis had limited their applications.â€\n His team set out to discover a combination of compounds that would create a supramolecular material with good mechanical strength, but that can break down quickly under the right conditions into non-toxic compounds and elements. Aida had a specific reaction in mind, one that would lock the materialâ€™s molecular bonds and could only be reversed with a specific â€˜keyâ€™â€”salt.\n After screening various molecules, the team found that a combination of sodium hexametaphosphate (a common food additive) and guanidinium ion-based monomers (used for fertilizers and soil conditioners) formed â€˜salt bridgesâ€™ that bind the compounds together with strong cross-linked bonds. These types of bonds serve as the â€˜lockâ€™, providing the material with strength and flexibility, explains Aida.\n  â€œScreening molecules can be like looking for a needle in a haystack,â€ he says. â€œBut we found the combination early on, which made us think, â€˜This could actually workâ€™.â€\nIn their study, Aidaâ€™s team produced a small sheet of this supramolecular material by mixing the compounds in water. The solution separated into two layers, the bottom viscous and the top watery, a spontaneous reaction that surprised the team. The viscous bottom layer contained the compounds bound with salt bridges. This layer was extracted and dried to create a plastic-like sheet.\nThe sheet was not only as strong as conventional plastics, but also non-flammable, colorless and transparent, giving it great versatility. Importantly, the sheets degraded back into raw materials when soaked in salt water, as the electrolytes in the salt water opened the salt bridge â€˜locksâ€™. The teamâ€™s experiments showed that their sheets disintegrated in salt water after 8 and a half hours.\nThe sheet can also be made waterproof with a hydrophobic coating. Even when waterproofed, the team found that the material can dissolve just as quickly as non-coated sheets if its surface is scratched to allow the salt to penetrate, says Aida.\n\nA thin square of the glassy new plastic  Â© 2025 RIKEN\n\n Driving change\n\nNot only is the supramolecular material degradable, but Aida hopes what is left after it breaks down could be usefully re-used. When broken down, his teamâ€™s new material leaves behind nitrogen and phosphorus, which microbes can metabolize and plants can absorb, he explains.\nHowever, Aida cautions that this also requires careful management: while these elements can enrich soil, they could also overload coastal ecosystems with nutrients, which are associated with algal blooms that disrupt entire ecosystems. The best approach may be to largely recycle the material in a controlled treatment facility using seawater. This way the raw materials could be recovered to produce supramolecular plastics again, he says.\nIn addition to developing alternatives to fossil fuel-derived plastic, Aida argues that governments, industries and researchers must also act decisively to drive change. Without more aggressive measures, the worldâ€™s plastics productionâ€”and corresponding carbon emissionsâ€” could more than double by 2050.\nâ€œWith established infrastructures and factory lines, itâ€™s extremely challenging for the plastics industry to change,â€ says Aida. â€œBut I believe there will come a tipping point where we have to power through change.â€ And a technology like this will be needed when that time comes.\n\nRate this article\n\n\t\t\t\t\tStars\n\n\t\t\tThank you!\n\n\t\t\t\tSubmit\n\nReference\n\n  1. Cheng, Y., Hirano, E., Wang, H., Kuwayama, M., Meijer, E. W.  et al. Mechanically strong yet metabolizable supramolecular plastics by desalting upon phase separation.   Science 386,   875-881 (2024). doi: 10.1126/science.ado1782\n\nAbout the researcher\nTakuzo Aida\n\nTakuzo Aida is the group director at the RIKEN Center for Emergent Matter Science, located in Wako, Saitama, Japan. Here, he also leads the Emergent Soft Matter Function Research Group. In addition, he is a distinguished professor at the University of Tokyo. Aida has received several notable honors and awards, including the American Chemical Society Award in Polymer Chemistry (2009), the Chemical Society of Japan Award (2009), the Purple Ribbon (2010), the Alexander von Humboldt Research Award (2011), and the Leo Esaki Prize (2015). His achievements were further recognized with membership in the Royal Netherlands Academy of Arts and Sciences in 2020, the US National Academy of Engineering in 2021, and the American Academy of Arts and Sciences in 2023.",
    "summary": {
      "en": "Scientists at RIKEN in Japan have developed a new type of plastic that dissolves in saltwater, potentially helping to reduce the microplastics pollution crisis. Microplastics are tiny plastic particles that harm the environment and human health. The new material, known as supramolecular plastic, is similar in strength and weight to regular plastics but can biodegrade quickly in seawater, preventing microplastic formation.\n\nThis innovative plastic is made using a combination of sodium hexametaphosphate and guanidinium ion-based monomers, which create strong bonds that can break down in saltwater. The plastic can self-heal and be easily recycled. After testing, the team found that it disintegrated in saltwater within 8.5 hours.\n\nWhile the biodegradable material leaves behind nutrients that can enrich soil, careful management is needed to avoid overloading ecosystems. Researchers emphasize the need for a shift in the plastics industry to address plastic pollution effectively before production and carbon emissions increase significantly by 2050.",
      "ko": "ì¼ë³¸ì˜ RIKEN ì—°êµ¬ì†Œ ê³¼í•™ìë“¤ì´ ì†Œê¸ˆë¬¼ì— ë…¹ëŠ” ìƒˆë¡œìš´ ìœ í˜•ì˜ í”Œë¼ìŠ¤í‹±ì„ ê°œë°œí–ˆìŠµë‹ˆë‹¤. ì´ í”Œë¼ìŠ¤í‹±ì€ ë¯¸ì„¸í”Œë¼ìŠ¤í‹± ì˜¤ì—¼ ë¬¸ì œë¥¼ ì¤„ì´ëŠ” ë° ë„ì›€ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë¯¸ì„¸í”Œë¼ìŠ¤í‹±ì€ í™˜ê²½ê³¼ ì¸ì²´ ê±´ê°•ì— í•´ë¡œìš´ ì‘ì€ í”Œë¼ìŠ¤í‹± ì…ìì…ë‹ˆë‹¤. ìƒˆë¡œìš´ ë¬¼ì§ˆì¸ ì´ˆë¶„ì í”Œë¼ìŠ¤í‹±ì€ ì¼ë°˜ í”Œë¼ìŠ¤í‹±ê³¼ ë¹„ìŠ·í•œ ê°•ë„ì™€ ë¬´ê²Œë¥¼ ê°€ì§€ë©´ì„œë„ ë°”ë‹·ë¬¼ì—ì„œ ë¹ ë¥´ê²Œ ìƒë¶„í•´ë˜ì–´ ë¯¸ì„¸í”Œë¼ìŠ¤í‹± í˜•ì„±ì„ ë°©ì§€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nì´ í˜ì‹ ì ì¸ í”Œë¼ìŠ¤í‹±ì€ í—¥ì‚¬ë©”íƒ€ì¸ì‚°ë‚˜íŠ¸ë¥¨ê³¼ êµ¬ì•„ë‹ˆë””ëŠ„ ì´ì˜¨ ê¸°ë°˜ì˜ ë‹¨ëŸ‰ì²´ë¥¼ ì¡°í•©í•˜ì—¬ ë§Œë“¤ì–´ì¡ŒìŠµë‹ˆë‹¤. ì´ ì¡°í•©ì€ ì†Œê¸ˆë¬¼ì—ì„œ ë¶„í•´ë  ìˆ˜ ìˆëŠ” ê°•í•œ ê²°í•©ì„ í˜•ì„±í•©ë‹ˆë‹¤. ì´ í”Œë¼ìŠ¤í‹±ì€ ìŠ¤ìŠ¤ë¡œ ì¹˜ìœ í•  ìˆ˜ ìˆìœ¼ë©° ì‰½ê²Œ ì¬í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, ì´ í”Œë¼ìŠ¤í‹±ì€ ì†Œê¸ˆë¬¼ì—ì„œ 8.5ì‹œê°„ ì´ë‚´ì— ë¶„í•´ë˜ëŠ” ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤.\n\nìƒë¶„í•´ ê°€ëŠ¥í•œ ì´ ë¬¼ì§ˆì€ í† ì–‘ì„ ë¹„ì˜¥í•˜ê²Œ í•  ìˆ˜ ìˆëŠ” ì˜ì–‘ë¶„ì„ ë‚¨ê¸°ì§€ë§Œ, ìƒíƒœê³„ì— ê³¼ë¶€í•˜ë¥¼ ì£¼ì§€ ì•Šë„ë¡ ì‹ ì¤‘í•œ ê´€ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì—°êµ¬ìë“¤ì€ 2050ë…„ê¹Œì§€ í”Œë¼ìŠ¤í‹± ìƒì‚°ê³¼ íƒ„ì†Œ ë°°ì¶œì´ í¬ê²Œ ì¦ê°€í•˜ê¸° ì „ì— í”Œë¼ìŠ¤í‹± ì‚°ì—…ì—ì„œ íš¨ê³¼ì ìœ¼ë¡œ í”Œë¼ìŠ¤í‹± ì˜¤ì—¼ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ ë³€í™”ê°€ í•„ìš”í•˜ë‹¤ê³  ê°•ì¡°í•˜ê³  ìˆìŠµë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "0bba5f1428db36d1",
    "title": {
      "en": "AI models miss disease in Black and female patients",
      "ko": "AI, ì§ˆë³‘ ë†“ì¹˜ë‹¤!",
      "ja": null
    },
    "type": "story",
    "url": "https://www.science.org/content/article/ai-models-miss-disease-black-female-patients",
    "score": 316,
    "by": "pseudolus",
    "time": 1743100701,
    "content": "From programs designed to detect irregular heartbeats in electrocardiograms to software that tracks eye movements to diagnose autism in children, artificial intelligence (AI) is helping physicians fine-tune the care they provide patients. But for all the technologyâ€™s potential for automating tasks, a growing body of evidence also shows that AI can be prone to bias that disadvantages already vulnerable patients. A new study, published today in Science Advances, adds to this work by testing one of the most cited AI models used to scan chest x-rays for diseasesâ€”and finding the model doesnâ€™t accurately detect potentially life-threatening diseases in marginalized groups, including women and Black people.\nThese results â€œare interesting and timely,â€ says Kimberly Badal, a computational biologist at the University of California (UC), San Francisco, who was not involved in the new study. â€œWe are at the point in history where weâ€™re moving to deploy a lot of AI models into clinical care,â€ she says, but â€œwe donâ€™t really knowâ€ how they affect different groups of people.\nThe model used in the new study, called CheXzero, was developed in 2022 by a team at Stanford University using a data set of almost 400,000 chest x-rays of people from Boston with conditions such as pulmonary edema, an accumulation of fluids in the lungs. Researchers fed their model the x-ray images without any of the associated radiologist reports, which contained information about diagnoses. And yet, CheXzero was just as good as the radiologists in reading the diseases associated with each x-ray.\n\n  SIGN UP FOR THE AWARD-WINNING SCIENCEADVISER NEWSLETTER\n  The latest news, commentary, and research, free to your inbox daily\n    Sign up\n\nGiven AI modelsâ€™ tendencies for bias, Yuzhe Yang, a computer scientist at UC Los Angeles wanted to assess the Stanford teamâ€™s model for such biases. His team selected a subset of 666 x-ray images from the same data set that was used to train the model: the data setâ€™s only images that also came with radiologistsâ€™ diagnoses and information about each patientâ€™s age, sex, and race. The team then fed these images to CheXzero and compared the results against the radiologistsâ€™ diagnoses.\nCompared with the patientsâ€™ doctors, the AI model more often failed to detect the presence of disease in Black patients or women, as well in those 40 years or younger. When the researchers looked at race and sex combined, Black women fell to the bottom, with the AI not detecting disease in half of them for conditions such as cardiomegaly, or enlargement of the heart. These disparities persisted when the team tested CheXzero using four other public data sets of chest x-rays from other regions, including Spain and Vietnam.\nâ€œIâ€™m not surprised by that finding at all,â€ Badal says. Other studies have shown biases among subgroups, and the new study confirms this, she says. â€œThere is so much variation in populations and their biology that I find it very hard to believe that eventually, one day, we will have â€˜one model to rule them all.â€™â€Advertisement\nYang and his team wanted to then tease out the possible root of the bias. Previous research had shown that AI models can be trained to detect race from x-rays with high accuracy, even when clinical experts canâ€™t, so the team set out to test CheXzeroâ€™s ability to do the same by asking the model to predict the sex, age, and race of patients using only the x-ray images. They found CheXzero could detect these characteristics in a high percentage of the patientsâ€”almost 80% when it came to race, for instance. By contrast, when three board-certified, experienced radiologists at the University of Washingtonâ€™s School of Medicine tried to do the same, their highest success rate was just about 50%.\nâ€œThere might be some hidden signals within the radiography itself that we cannot identify visually,â€ Yang says. He thinks the model may be using the information as a diagnostic â€œshortcutâ€ to associate traits such as age with certain conditions and not others, developing a bias in the process.\nTo force CheXzero to avoid shortcuts and therefore try to mitigate this bias, the team repeated the experiment but deliberately gave the race, sex, or age of patients to the model together with the images. The modelâ€™s rate of â€œmissedâ€ diagnoses decreased by halfâ€”but only for some conditions.\nYang and his team are unsure what may be causing the mixed success. There may be bias baked into the model itself: The data set used to train CheXzero included more men, more people between 40 and 80 years old, and more white patients, which Yang says underscores the need for larger, more diverse data sets.\nâ€œWhat is clear is that itâ€™s going to be really difficult to mitigate these biases,â€ says Judy Gichoya, an interventional radiologist and informatician at Emory University who was not involved in the study. Instead, she advocates for smaller, but more diverse data sets that test these AI models to identify their flaws and correct them on a small scale first. Even so, â€œHumans have to be in the loop,â€ she says. â€œAI canâ€™t be left on its own.â€",
    "summary": {
      "en": "Artificial intelligence (AI) is increasingly being used in healthcare to improve patient care, such as detecting heart issues and diagnosing autism. However, a recent study shows that AI models can exhibit bias, particularly against marginalized groups like women and Black individuals. The study tested an AI model called CheXzero, designed to analyze chest x-rays, and found it often failed to accurately detect diseases in these groups, especially in Black women and younger patients.\n\nResearchers discovered that CheXzero could predict patient characteristics like race and sex from x-rays with high accuracy, suggesting it might use these traits as shortcuts, leading to biases in diagnosis. When the model was provided with this demographic information, its detection rates improved, but only for some conditions.\n\nThe study highlights the need for more diverse training data to reduce bias in AI models. Experts argue that while AI can assist in healthcare, human oversight remains crucial to ensure fair and accurate patient care.",
      "ko": "ì¸ê³µì§€ëŠ¥(AI)ì€ í™˜ì ì¹˜ë£Œë¥¼ ê°œì„ í•˜ê¸° ìœ„í•´ ì ì  ë” ë§ì€ ì˜ë£Œ ë¶„ì•¼ì—ì„œ ì‚¬ìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì‹¬ì¥ ë¬¸ì œë¥¼ ê°ì§€í•˜ê±°ë‚˜ ìíì¦ì„ ì§„ë‹¨í•˜ëŠ” ë° í™œìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ìµœê·¼ ì—°êµ¬ì— ë”°ë¥´ë©´ AI ëª¨ë¸ì´ í¸í–¥ì„ ë³´ì¼ ìˆ˜ ìˆìœ¼ë©°, íŠ¹íˆ ì—¬ì„±ì´ë‚˜ í‘ì¸ê³¼ ê°™ì€ ì†Œì™¸ëœ ì§‘ë‹¨ì— ëŒ€í•´ ê·¸ ê²½í–¥ì´ ë‘ë“œëŸ¬ì§„ë‹¤ê³  í•©ë‹ˆë‹¤. ì—°êµ¬íŒ€ì€ í‰ë¶€ ì—‘ìŠ¤ë ˆì´ë¥¼ ë¶„ì„í•˜ê¸° ìœ„í•´ ì„¤ê³„ëœ AI ëª¨ë¸ì¸ CheXzeroë¥¼ í…ŒìŠ¤íŠ¸í–ˆìœ¼ë©°, ì´ ëª¨ë¸ì´ í‘ì¸ ì—¬ì„±ê³¼ ì Šì€ í™˜ìë“¤ì—ì„œ ì§ˆë³‘ì„ ì •í™•í•˜ê²Œ ê°ì§€í•˜ëŠ” ë° ì‹¤íŒ¨í•˜ëŠ” ê²½ìš°ê°€ ë§ë‹¤ëŠ” ê²ƒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.\n\nì—°êµ¬ìë“¤ì€ CheXzeroê°€ ì—‘ìŠ¤ë ˆì´ë¥¼ í†µí•´ ì¸ì¢…ê³¼ ì„±ë³„ê³¼ ê°™ì€ í™˜ìì˜ íŠ¹ì„±ì„ ë†’ì€ ì •í™•ë„ë¡œ ì˜ˆì¸¡í•  ìˆ˜ ìˆë‹¤ëŠ” ì‚¬ì‹¤ì„ ë°í˜€ëƒˆìŠµë‹ˆë‹¤. ì´ëŠ” ëª¨ë¸ì´ ì´ëŸ¬í•œ íŠ¹ì„±ì„ ì§„ë‹¨ì˜ ì§€ë¦„ê¸¸ë¡œ ì‚¬ìš©í•˜ê³  ìˆì–´ í¸í–¥ì´ ë°œìƒí•  ìˆ˜ ìˆìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤. ì¸êµ¬ í†µê³„ ì •ë³´ë¥¼ ì œê³µí–ˆì„ ë•Œ, ëª¨ë¸ì˜ ì§ˆë³‘ ê°ì§€ìœ¨ì€ ê°œì„ ë˜ì—ˆì§€ë§Œ, ì´ëŠ” ì¼ë¶€ ì§ˆí™˜ì—ë§Œ í•´ë‹¹í–ˆìŠµë‹ˆë‹¤.\n\nì´ ì—°êµ¬ëŠ” AI ëª¨ë¸ì˜ í¸í–¥ì„ ì¤„ì´ê¸° ìœ„í•´ ë” ë‹¤ì–‘í•œ í›ˆë ¨ ë°ì´í„°ê°€ í•„ìš”í•˜ë‹¤ëŠ” ì ì„ ê°•ì¡°í•©ë‹ˆë‹¤. ì „ë¬¸ê°€ë“¤ì€ AIê°€ ì˜ë£Œ ë¶„ì•¼ì—ì„œ ë„ì›€ì„ ì¤„ ìˆ˜ ìˆì§€ë§Œ, ê³µì •í•˜ê³  ì •í™•í•œ í™˜ì ì¹˜ë£Œë¥¼ ë³´ì¥í•˜ê¸° ìœ„í•´ì„œëŠ” ì¸ê°„ì˜ ê°ë…ì´ ì—¬ì „íˆ ì¤‘ìš”í•˜ë‹¤ê³  ì£¼ì¥í•©ë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "d552523a0f5f9a5e",
    "title": {
      "en": "Piranesi's Perspective Trick (2019)",
      "ko": "í”¼ë¼ë„¤ì‹œì˜ ì‹œê° ì†ì„ìˆ˜",
      "ja": null
    },
    "type": "story",
    "url": "https://medium.com/@brunopostle/piranesis-perspective-trick-6bcd7a754da9",
    "score": 339,
    "by": "amatheus",
    "time": 1743075690,
    "content": "Piranesiâ€™s Perspective TrickBruno PostleÂ·Follow8 min readÂ·Apr 27, 2019--1ListenShareThis is a quick report explaining what I have been doing with some research on what I started to call â€˜Piranesiâ€™s perspective trickâ€™. In the past I would have written this up as an academic paper, that may happen at some point, but not anytime soon.Giovanni Battista Piranesi was a Eighteenth century artist famous for his â€˜veduteâ€™ etchings of classical and contemporary buildings in Rome. He wasnâ€™t the only artist doing this sort of thing, there was quite an industry around souvenirs of the Grand Tour.Veduta del Ponte Molle, PiranesiArtistically the images are excellent, and in many ways these etchings are a very good record of the places, as Piranesi was very much concerned with getting the detail right. However there are a few stand-out things about these pictures, and pictures from other artists of the period, that are a little bit strange to our modern eyes that are used to experiencing places through photography:1. The engravings give a very good impression of the sense of place, we are all used to visiting places that we have previously seen in photographs and found the reality to be very different, whereas Piranesiâ€™s places are very identifiable when encountered.2. Related to this, often the images show a wide panoramic view that is impossible to represent in a single photograph, but without any of the distortions that you see at the edges of a photograph.3. To a modern eye, brought up with television and magazines, there is something about the perspective in these pictures that looks just a little bit off, or even very wrong, but there is no evidence that people at the time thought like this â€” Piranesi was famous for his technical ability as a draughtsman.A few years ago, we were looking at introducing new panoramic projections for the Hugin panorama stitcher, and one of the features often asked for was to have a projection that was very wide-angle, but which didnâ€™t have the extreme edge distortions of normal photographic projections, or the awkward curvature that you see in fisheye or map projections, basically what we wanted was a way to recreate these â€˜veduteâ€™ views in software. What we came up with was the â€˜Panini projectionâ€™ (sometimes called the â€˜vedutismo projectionâ€™, probably a better name, but hey, once you create software, you canâ€™t go changing names of things just like that).An image created in Hugin in Panini/Vedutismo projection. The angle of view of this image is nearly 180Â°, this is an extreme wide angleThe Panini projection is very useful, and you have probably encountered it at some point without even realising it, it has the property that vertical lines are straight, radial lines are straight, and that edge distortion is imperceptible. With the Panini projection it is possible to show a scene with an enormously wide angle of view (over 180Â°), and for it to appear like a normal photograph, sometimes, at least.Another Hugin panorama in extreme wide-angle Panini projectionBut our Panini projection in Hugin isnâ€™t quite the same as the perspective views used by Piranesi and his contemporaries. Although there is a straightforward way to construct a Hugin/Panini perspective on a drawing board, there is no evidence that any of these historical artists actually used it. Some got very close, in particular Panini himself and Vincent van Gogh, but that is a story for another day.But there is a distinctive feature of Piranesiâ€™s perspective trick, a feature that marks it out from Huginâ€™s Panini perspective, and from a normal â€˜rectilinearâ€™ image.â€˜Rectilinearâ€™ is the kind of normal perspective you get from a camera, but also from drawing a perspective by projecting a plan on a drawing board, and also it is the default perspective you get using one of the various historical perspective machines such as a camera obscura.The distinctive feature of Piranesiâ€™s perspective trick is that when you have a series of similar objects receding into the distance, such as houses or arches in a bridge, the nearer versions are just drawn as larger versions of those in the distance â€” real perspective doesnâ€™t work like this, not at all, this is a trick that Piranesi and other artists used to cram more things into the pictures while retaining legibility.Note that all three arches are basically the same, just drawn at different sizes, PiranesiThe way to spot it involves drawing some lines on the picture, use a copy, it is best not to use an original.In a normal perspective, any parallel lines in the scene that are not perpendicular to the viewing direction converge onto points. This sounds complex, but it is not, here is what we call a one-point perspective. The edges of the buildings converge to a single â€˜vanishing pointâ€™ on the horizon, this is why we call it â€˜one point perspectiveâ€™.Normal single-point perspective. The parallel lines of the buildings converge on a vanishing point at the middle on the horizon. The diagonals of the buildings are parallel and they converge on vanishing points above and below.But other parallel lines in the scene also converge to points, the diagonals of the buildings are also parallel, and so when shown in perspective they converge on points directly above and below the main vanishing point.But look at one of Piranesiâ€™s engravings:Veduta del palazzo Odescalchi, PiranesiSome of the diagonals, towards the middle of the image, do the right thing, they converge top and bottom as expected, but the diagonal lines at the left of the scene are drawn completely parallel. This is outrageous! real, true perspective doesnâ€™t work like this, it isnâ€™t possible to construct a camera or a computer program to render a view that does this. But the engravings work as pictures nonetheless, in fact they are quite good.Piranesi engraving, note that the three arches are drawn exactly the same at different scales, diagonal lines are parallelThis one below is a Canaletto, the same trick is in use, the centre and right hand part of the picture is photographically correct, but the long building on the left has been extended using Piranesiâ€™s perspective trick. Iâ€™ve drawn diagonals on each bay of the building and they are obviously parallel. If this was a true perspective these diagonal lines would converge into a vanishing point in the sky somewhere above St Markâ€™s.The mathematics of this is quite simple, just draw objects in a series such that the closer ones are the same proportion as those further away. You can show that the only way to do this is is for the ratio of the distance from the vanishing point to any two features is the same for the next two features.Piranesiâ€™s perspective trick, the diagonals of features in the elevation stay parallel when remappedHereâ€™s the science bit:â€¦and here are some tests, with Paniniâ€™s perspective trick we canâ€™t render the entire scene, just rectangular objects in a scene, rectangular objects like the elevation of a street. This is a street elevation:Main Street USA elevationHere is the same elevation distorted using Piranesiâ€™s perspective trick, looks ok to me, itâ€™s a first test so is a bit blurry.An early test of a single-point Piranesi perspectiveBut here is the same elevation drawn using correct rectilinear perspective. I hope you will agree that the Piranesi version is much more legible, the furthest house above is easier to see and the nearest house isnâ€™t horribly distorted as it is below.Comparison perspective, this is a â€˜trueâ€™ single-point perspective, note how distorted the left and right buildings are compared to both the original elevation and the Piranesi perspective versionBy legibility I mean that the Piranesi distortion is easier to read, and that to anyone unfamiliar with photographs, that hasnâ€™t grown up with TV, photographs and magazines, the Piranesi version would look much better, and the true perspective would look rather odd.So what can we do with this? We canâ€™t add this trick to Hugin as a new general purpose mapping, because it isnâ€™t a real perspective. However most image editors, like GIMP, have a perspective tool that performs a distortion on a rectangular selection, technically this is called a â€˜homography matrix transformâ€™ and it produces a photographically correct rectilinear perspective, with all the usual unpleasant edge distortions.Piranesiâ€™s perspective trick can also be extended into two dimensions like this, sometimes called a â€˜two point perspectiveâ€™. Piranesi never did this, but with computers we can do all sorts of things. So here is a general 2D remapping as a prototype replacement for the perspective tool in image editors (I have no ability to add this to GIMP, somebody else needs to step up):Two-point â€˜Piranesiâ€™ perspective distortionI think that the result is much more legible than that produced by a â€˜trueâ€™ perspective, no matter how correct it is:Normal homography perspective transformation produced in GIMP. Note how squashed the buildings at the right and left are when taken in isolationOnce you know what to look for, i.e parallel diagonal lines, you can see Piranesiâ€™s trick being used by any number of historical artists, and even some modern artists, this isnâ€™t â€˜lostâ€™ knowledge.The trick was very common as a way to show a birds-eye aerial view of landscapes, but also keeping them legible enough to be used as a map, like this:We can do this in the computer, here is a birds-eye view of a London map redrawn using Piranesiâ€™s perspective trick.Piranesi birdâ€™s eye perspective, OSM contributorsI hope you will agree that it is quite a bit more legible than the same view shown in â€˜correct perspectiveâ€™:â€˜Correctâ€™ birds-eye perspective, OSM contributors..and so this article doesnâ€™t finish on a boring picture, here is some lineart remapped using Piranesiâ€™s perspective trick. The thing to note is that the left building has basically the same amount of distortion as the right building, only smaller. Similarly, all the windows have about the same amount of distortion, this is very very unlike a true, â€˜correctâ€™ perspective:Palazzo Porto, Palladio. Original image by Joshua Cesa, Alessandro Senno, Elia Venturini, WikipediaBruno Postle, April 2019",
    "summary": {
      "en": "This text discusses \"Piranesi's perspective trick,\" a unique artistic technique used by the 18th-century artist Giovanni Battista Piranesi. Piranesi is known for his detailed etchings of buildings in Rome, which often appear more legible and identifiable than real photographs. Key points include:\n\n1. **Piranesi's Style**: His engravings provide a sense of place and often feature wide panoramic views without the distortions common in photographs.\n\n2. **Perspective Trick**: Piranesi used a method where similar objects appearing in the distance are drawn as larger versions of those closer to the viewer, which is not how true perspective works. This technique allows for more elements in a scene while maintaining clarity.\n\n3. **Comparison to Modern Techniques**: The text explains how modern software, like Hugin, developed a \"Panini projection\" to replicate wide-angle views without distortions. However, this is not the same as Piranesi's method.\n\n4. **Legibility**: Piranesiâ€™s approach makes images easier to read compared to traditional perspectives, which can appear distorted.\n\n5. **Applications**: The technique can be applied in modern image editing, offering a new way to represent scenes more legibly than standard perspective methods.\n\nOverall, Piranesiâ€™s perspective trick remains relevant and can be seen in various historical and modern artworks.",
      "ko": "ì´ ê¸€ì—ì„œëŠ” 18ì„¸ê¸° ì˜ˆìˆ ê°€ ì¡°ë°˜ë‹ˆ ë°”í‹°ìŠ¤íƒ€ í”¼ë¼ë„¤ì‹œì˜ ë…íŠ¹í•œ ì˜ˆìˆ  ê¸°ë²•ì¸ \"í”¼ë¼ë„¤ì‹œì˜ ì›ê·¼ë²• ì†ì„ìˆ˜\"ì— ëŒ€í•´ ë‹¤ë£¹ë‹ˆë‹¤. í”¼ë¼ë„¤ì‹œëŠ” ë¡œë§ˆì˜ ê±´ì¶•ë¬¼ì„ ì„¸ë°€í•˜ê²Œ íŒí™”ë¡œ ë‚¨ê¸´ ê²ƒìœ¼ë¡œ ìœ ëª…í•˜ë©°, ê·¸ì˜ ì‘í’ˆì€ ì‹¤ì œ ì‚¬ì§„ë³´ë‹¤ ë” ëª…í™•í•˜ê³  ì¸ì‹í•˜ê¸° ì‰¬ìš´ ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤.\n\ní”¼ë¼ë„¤ì‹œì˜ ìŠ¤íƒ€ì¼ì€ ê·¸ì˜ íŒí™”ê°€ ì¥ì†Œì˜ ëŠë‚Œì„ ì˜ ì „ë‹¬í•˜ë©°, ì‚¬ì§„ì—ì„œ í”íˆ ë°œìƒí•˜ëŠ” ì™œê³¡ ì—†ì´ ë„“ì€ íŒŒë…¸ë¼ë§ˆ ë·°ë¥¼ íŠ¹ì§•ìœ¼ë¡œ í•©ë‹ˆë‹¤. ê·¸ëŠ” ì›ê·¼ë²•ì„ í™œìš©í•˜ì—¬ ë©€ë¦¬ ìˆëŠ” ìœ ì‚¬í•œ ë¬¼ì²´ë¥¼ ê´€ê°ì—ê²Œ ê°€ê¹Œìš´ ë¬¼ì²´ë³´ë‹¤ ë” í¬ê²Œ ê·¸ë¦¬ëŠ” ë°©ì‹ì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤. ì´ëŠ” ì‹¤ì œ ì›ê·¼ë²•ê³¼ëŠ” ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ, ì¥ë©´ì— ë” ë§ì€ ìš”ì†Œë¥¼ í¬í•¨í•˜ë©´ì„œë„ ëª…í™•ì„±ì„ ìœ ì§€í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.\n\ní˜„ëŒ€ ê¸°ìˆ ê³¼ ë¹„êµí•  ë•Œ, Huginê³¼ ê°™ì€ ì†Œí”„íŠ¸ì›¨ì–´ëŠ” ì™œê³¡ ì—†ì´ ë„“ì€ ì‹œì•¼ë¥¼ ì¬í˜„í•˜ê¸° ìœ„í•´ \"íŒŒë‹ˆë‹ˆ íˆ¬ì˜\"ì´ë¼ëŠ” ë°©ë²•ì„ ê°œë°œí–ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ëŠ” í”¼ë¼ë„¤ì‹œì˜ ë°©ì‹ê³¼ëŠ” ë‹¤ë¦…ë‹ˆë‹¤. í”¼ë¼ë„¤ì‹œì˜ ì ‘ê·¼ ë°©ì‹ì€ ì „í†µì ì¸ ì›ê·¼ë²•ë³´ë‹¤ ì´ë¯¸ì§€ë¥¼ ë” ì‰½ê²Œ ì½ì„ ìˆ˜ ìˆê²Œ ë§Œë“¤ì–´, ì™œê³¡ëœ ëŠë‚Œì„ ì¤„ì…ë‹ˆë‹¤.\n\nì´ ê¸°ë²•ì€ í˜„ëŒ€ ì´ë¯¸ì§€ í¸ì§‘ì—ì„œë„ ì ìš©ë  ìˆ˜ ìˆìœ¼ë©°, í‘œì¤€ ì›ê·¼ë²• ë°©ë²•ë³´ë‹¤ ì¥ë©´ì„ ë” ëª…í™•í•˜ê²Œ í‘œí˜„í•˜ëŠ” ìƒˆë¡œìš´ ë°©ì‹ì„ ì œê³µí•©ë‹ˆë‹¤. í”¼ë¼ë„¤ì‹œì˜ ì›ê·¼ë²• ì†ì„ìˆ˜ëŠ” ì—¬ì „íˆ ê´€ë ¨ì„±ì´ ìˆìœ¼ë©°, ë‹¤ì–‘í•œ ì—­ì‚¬ì  ë° í˜„ëŒ€ ì˜ˆìˆ  ì‘í’ˆì—ì„œ ì°¾ì•„ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "dce4b0938311310a",
    "title": {
      "en": "Retreating Glaciers Expose 1,500 Miles of Coastline",
      "ko": "ë¹™í•˜ í›„í‡´, 1,500ë§ˆì¼ í•´ì•ˆ ë“œëŸ¬ë‚˜ë‹¤",
      "ja": null
    },
    "type": "story",
    "url": "https://e360.yale.edu/digest/climate-glaciers-coastline-study",
    "score": 29,
    "by": "YaleE360",
    "time": 1742828475,
    "content": "E360 Digest\n      March 24, 2025\n\n    Retreating Arctic Glaciers Have Exposed 1,500 Miles of Coastline\n\n          Courtesy of Jan Kavan\n\n  Since 2000, the melting of Arctic glaciers has exposed some 1,500 miles of coastline, a study finds.For the research, published in Nature Climate Change, scientists tracked the movement of 1,500 coastal glaciers from 2000 to 2020, finding that retreating ice had unveiled hundreds of miles of coastline, largely in Greenland.Scientists say that retreating glaciers are revealing stores of precious metals, but they warn that newly exposed coastline, which has not been cemented with ice, is vulnerable to erosion and landslides.In September 2023, a thinning coastal glacier in eastern Greenland gave way, leading to a massive landslide in the Dickson fjord. The landslide produced a 350-foot-high tsunami that registered on seismometers around the globe.ALSO ON YALE E360With Sea Ice Melting, Killer Whales Are Moving Into the Arctic\n\n    Facebook\n\n    Twitter\n    Email\n\n  Related Articles\n\n        Opinion\n\n      With NOAA Cuts, a Proud Legacy and Vital Science Are at Risk\n\n                        By  Adam Sobel\n\n      Imperiled in the Wild, Many Plants May Survive Only in Gardens\n\n                        By  Janet Marinelli\n\n      Can Toxic Mining Waste Help Remove CO2 from the Atmosphere?\n\n                        By  Moira Donovan\n\n  More From E360\n\n  CONFLICT\n\n    In War-Torn Sudan, a Gold Mining Boom Takes a Human Toll\n\n  Opinion\n\n    With NOAA Cuts, a Proud Legacy and Vital Science Are at Risk\n\n  Biodiversity\n\n    Imperiled in the Wild, Many Plants May Survive Only in Gardens\n\n  Climate\n\n    Can Toxic Mining Waste Help Remove CO2 from the Atmosphere?\n\n  INTERVIEW\n\n    Saving U.S. Climate and Environmental Data Before It Goes Away\n\n  Biodiversity\n\n    A Craze for Tiny Plants Is Driving a Poaching Crisis in South Africa\n\n  INTERVIEW\n\n    Bill McKibben on Climate Activism in the Age of Trump 2.0\n\n  Climate\n\n    How Climate Change Puts the Safety of Drinking Water at Risk\n\n  Energy\n\n    â€˜Green Grabâ€™: Solar and Wind Boom Sparks Conflicts on Land Use\n\n  INTERVIEW\n\n    Reciprocity: Rethinking Our Relationship with the Natural World\n\n  Oceans\n\n    With Sea Ice Melting, Killer Whales Are Moving Into the Arctic\n\n  Cities\n\n    As War Halts, the Environmental Devastation in Gaza Runs Deep",
    "summary": {
      "en": "**Summary of E360 Digest - March 24, 2025**\n\nResearch published in *Nature Climate Change* reveals that since 2000, melting Arctic glaciers have uncovered about 1,500 miles of coastline, mainly in Greenland. This retreat of glaciers has exposed valuable resources, but it also poses risks, as the newly uncovered land is prone to erosion and landslides. For instance, in September 2023, a glacier in eastern Greenland collapsed, causing a large landslide that generated a significant tsunami.",
      "ko": "2025ë…„ 3ì›” 24ì¼ì E360 ë‹¤ì´ì œìŠ¤íŠ¸ ìš”ì•½ì— ë”°ë¥´ë©´, *Nature Climate Change*ì— ë°œí‘œëœ ì—°êµ¬ ê²°ê³¼, 2000ë…„ ì´í›„ ë¶ê·¹ì˜ ë¹™í•˜ê°€ ë…¹ìœ¼ë©´ì„œ ê·¸ë¦°ë€ë“œ ì§€ì—­ì„ ì¤‘ì‹¬ìœ¼ë¡œ ì•½ 1,500ë§ˆì¼ì˜ í•´ì•ˆì„ ì´ ë“œëŸ¬ë‚¬ìŠµë‹ˆë‹¤. ì´ ë¹™í•˜ì˜ í›„í‡´ëŠ” ê·€ì¤‘í•œ ìì›ì„ ë…¸ì¶œì‹œí‚¤ì§€ë§Œ, ìƒˆë¡œ ë“œëŸ¬ë‚œ ë•…ì€ ì¹¨ì‹ê³¼ ì‚°ì‚¬íƒœì— ì·¨ì•½í•´ ìœ„í—˜ì„ ë™ë°˜í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, 2023ë…„ 9ì›”ì—ëŠ” ê·¸ë¦°ë€ë“œ ë™ë¶€ì˜ í•œ ë¹™í•˜ê°€ ë¶•ê´´ë˜ë©´ì„œ í° ì‚°ì‚¬íƒœê°€ ë°œìƒí–ˆê³ , ì´ë¡œ ì¸í•´ ìƒë‹¹í•œ ê·œëª¨ì˜ ì“°ë‚˜ë¯¸ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "5c09f290955ffdb2",
    "title": {
      "en": "Alkanes on Mars",
      "ko": "í™”ì„±ì˜ ì•Œì¼€ì¸",
      "ja": null
    },
    "type": "story",
    "url": "https://www.science.org/content/blog-post/alkanes-mars",
    "score": 70,
    "by": "nick__m",
    "time": 1743095458,
    "content": "News came this week of the discovery of long-chain alkane molecules in a sample of Martian rock - here's the full manuscript at PNAS. This was not an easy find. As you'll see from that article, the samples themselves were collected in 2013 in Gale Crater by the Curiosity rover, and the same sample is the one that showed organic compounds in it a few years ago in another analysis. So why didn't these newly announced larger molecules show up then?\nThat's because this time the samples got a different treatment (two cycles of strong heating) before the mass spec analysis. And the compounds themselves (decane, undecane, and dodecane) were detected in rather small concentations as well. This all goes back to the design of the instrument package itself and to a constant problem that the team on Earth has had to contend with. The Sample Analysis on Mars (SAM) module is basically a GS/MS instrument, and as such it has provisions to heat the samples (at temperatures of up to 850C) to volatilize things for analysis. And it also has a derivatization reagent available, N-methyl-N-tert-butyldimethylsilyl-trifluoroacetamide (MTBSTFA). As the analytical chemistry types in the audience will appreciate, this will cap reactive nitrogens and oxygens (NH, NH2, OH) with t-butyldimethylsilyl (TBDMS) groups, which makes the compounds containing them much more likely to be able to usefully fly down the GC/MS. This sort of silylation treatment is a common procedure in such analyses.\nBut what didn't work out was leakage of that reagent into the instrument package, which probably happened during the strenuous landing procedures that any spacecraft has to endure to make a soft landing on Mars. Making a new crater would be more simple! This has left the rest of the SAM activity during this mission a long-running story of working around that spill in order to get useful data, such as making sure that the results obtained aren't from (say) pyrolysis of MTBSTFA or its unintended reactions with authentic Martian materials.\nIn this case, there was \"opportunistic derivatization\" of the sample with that reagent as its vapors reacted with the material in the sample holder over the intervening months. The team took the sample up to about 500C to break down the perchlorates and similar species, with release of oxygen, and then heated it again to 850C, the idea being that now there would be much less oxygen available for the combustion of any organics that made it into the gas phase. The higher temperatures were to break down sulfate minerals in the sample to potentialy release more organic residues. Another modification that had been worked out was keeping the cold trap (to catch volatilized material) at a somewhat warmer temperature than originally planned, which let a lot of MTBSTFA contaminants (such as trifluoro-N-methylacetamide and bis-TBDMS-disiloxane, known to the team as \"BSW\" for \"bisilylated water\") wash through the system instead of being retained.\nAnd it was in that higher-temperature run that the long-chain alkanes were detected. The best hypothesis now is that these are likely to have been the decarboxylation products of the corresponding fatty acids, because (for one thing) you shouldn't have needed such high temperatures to volatilize them as the plain alkanes, and for another, the chemical environment of Martian soil is strongly oxidizing to start with (all those perchlorates and such). Experiments with simulated martian soil/rock samples and such fatty acids do indeed produce the decarboxylation products on heating, so it's at least chemically plausible. So if there are indeed fatty acids on Mars, where did they come from?\nWell, one immediate thought is from living creatures, because that's where they'd probably be coming from here on Earth. But that would be a long leap to make for a Martian sample, because there are certainly some abiotic ways to make these things. But the authors do note that abiotic fatty acids tend to be shorter-chained than this (and I would note that long-term abiotic thermal reactions would be expected to produce branched-chain compounds more than the n-alkanes seen here). It's also possible that these compounds are the breakdown products of still longer fatty acids as well. Biotic fatty acids from life-as-we-know-it are biases towards even numbers of carbons (since they're built up and torn down by two-carbon units), but with only three in this sample it's hard to make an argument one way or another based on this effect - and especially since we don't know if any hypothetical Martian life has/had that same biochemical bias.\nNo one's going to be able to settle the biotic/abiotic argument around such samples until we get some of them back to Earth for workup by more comprehensive analytical techniques. We might well not even settle it then! As many will know, the Perserverance rover is in fact designed to seal and store samples for such a future sample return, and it's been doing so. But that back end of that mission is. . .well, a problem. NASA's plans for such a land-on-Mars, collect-the-samples, send-them-back-to-Martian-orbit, and return-them-to-Earth have been getting fantastically expensive and complex, to the point that everyone realized that they simply weren't going to happen (and might well not have worked if they had). New options are being explored, but it's anyone's guess when such a mission would launch.\nDiscovery by a rover of some fossilized Martian critters in one of these rocks would settle the main issue more quickly, but that is an unlikely event (although man, would I ever enjoy it). And let's be honest - any such find would just make everyone more crazy to get their (glove-boxed, robotic) hands on the real samples to try to figure out how related such life was to life here on Earth! No, if there is or was life on Mars it's far more likely to be at the single-cell level, and thus trickier to detect (after all, most of the history of life on Earth was single-celled, and those life forms still outnumber the rest of us handily). The search continues!",
    "summary": {
      "en": "This week, scientists announced the discovery of long-chain alkane molecules in Martian rock samples collected by the Curiosity rover in 2013. These larger molecules were not found in earlier analyses due to the different treatment of the samples this time, which involved heating them strongly before analysis. The specific compounds detected are decane, undecane, and dodecane, but they were found in small amounts.\n\nThe analysis used a technique involving heating samples up to 850Â°C, which helps to release organic materials for detection. However, a previous issue with a reagent leaking into the instrument complicated the analysis, leading to a need for adjustments in the procedure to minimize contamination.\n\nThe long-chain alkanes detected are thought to be products of decarboxylation from fatty acids, which could hint at the presence of these acids on Mars. While fatty acids on Earth typically come from living organisms, they can also be formed through non-biological processes. It's uncertain whether the detected molecules are biotic or abiotic, and further analysis of returned samples from Mars is needed to clarify their origins.\n\nNASA's Perseverance rover is currently storing samples for a planned return to Earth, but the mission's complexity and costs have made timelines uncertain. The search for evidence of life on Mars continues, with the possibility that any Martian life forms may be single-celled and difficult to detect.",
      "ko": "ì´ë²ˆ ì£¼, ê³¼í•™ìë“¤ì€ 2013ë…„ íë¦¬ì˜¤ì‹œí‹° ë¡œë²„ê°€ ìˆ˜ì§‘í•œ í™”ì„± ì•”ì„ ìƒ˜í”Œì—ì„œ ê¸´ ì‚¬ìŠ¬ ì•Œì¼€ì¸ ë¶„ìë¥¼ ë°œê²¬í–ˆë‹¤ê³  ë°œí‘œí–ˆìŠµë‹ˆë‹¤. ì´ í° ë¶„ìë“¤ì€ ìƒ˜í”Œì„ ë¶„ì„í•  ë•Œì˜ ì²˜ë¦¬ ë°©ì‹ì´ ë‹¬ë¼ì ¸ ì´ì „ ë¶„ì„ì—ì„œëŠ” ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì´ë²ˆì—ëŠ” ìƒ˜í”Œì„ ê°•í•˜ê²Œ ê°€ì—´í•œ í›„ ë¶„ì„ì„ ì§„í–‰í–ˆìŠµë‹ˆë‹¤. ë°œê²¬ëœ íŠ¹ì • í™”í•©ë¬¼ì€ ë°ì¹¸, ìš´ë°ì¹¸, ê·¸ë¦¬ê³  ë„ë°ì¹¸ìœ¼ë¡œ, ëª¨ë‘ ì†ŒëŸ‰ìœ¼ë¡œ ì¡´ì¬í–ˆìŠµë‹ˆë‹¤.\n\në¶„ì„ì—ëŠ” ìƒ˜í”Œì„ 850ë„ê¹Œì§€ ê°€ì—´í•˜ëŠ” ê¸°ìˆ ì´ ì‚¬ìš©ë˜ì—ˆìœ¼ë©°, ì´ëŠ” ìœ ê¸° ë¬¼ì§ˆì„ ë°©ì¶œí•˜ì—¬ ê²€ì¶œí•˜ëŠ” ë° ë„ì›€ì„ ì¤ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ì „ì— ì‹œì•½ì´ ê¸°ê¸°ì— ëˆ„ì¶œë˜ëŠ” ë¬¸ì œê°€ ë°œìƒí•˜ì—¬ ë¶„ì„ì´ ë³µì¡í•´ì¡Œê³ , ì˜¤ì—¼ì„ ìµœì†Œí™”í•˜ê¸° ìœ„í•´ ì ˆì°¨ë¥¼ ì¡°ì •í•´ì•¼ í–ˆìŠµë‹ˆë‹¤.\n\nê²€ì¶œëœ ê¸´ ì‚¬ìŠ¬ ì•Œì¼€ì¸ì€ ì§€ë°©ì‚°ì˜ íƒˆì¹´ë³µì‹¤í™” ê³¼ì •ì—ì„œ ìƒì„±ëœ ê²ƒìœ¼ë¡œ ì¶”ì •ë˜ë©°, ì´ëŠ” í™”ì„±ì— ì´ëŸ¬í•œ ì§€ë°©ì‚°ì´ ì¡´ì¬í•  ê°€ëŠ¥ì„±ì„ ì‹œì‚¬í•©ë‹ˆë‹¤. ì§€êµ¬ì—ì„œ ì§€ë°©ì‚°ì€ ì¼ë°˜ì ìœ¼ë¡œ ìƒëª…ì²´ì—ì„œ ìœ ë˜í•˜ì§€ë§Œ ë¹„ìƒë¬¼í•™ì  ê³¼ì •ì—ì„œë„ í˜•ì„±ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ë°œê²¬ëœ ë¶„ìê°€ ìƒë¬¼í•™ì  ê¸°ì›ì¸ì§€ ë¹„ìƒë¬¼í•™ì  ê¸°ì›ì¸ì§€ëŠ” ë¶ˆí™•ì‹¤í•˜ë©°, í™”ì„±ì—ì„œ ëŒì•„ì˜¨ ìƒ˜í”Œì— ëŒ€í•œ ì¶”ê°€ ë¶„ì„ì´ í•„ìš”í•©ë‹ˆë‹¤.\n\ní˜„ì¬ NASAì˜ í¼ì„œë¹„ì–´ëŸ°ìŠ¤ ë¡œë²„ëŠ” ì§€êµ¬ë¡œ ëŒì•„ì˜¬ ìƒ˜í”Œì„ ì €ì¥í•˜ê³  ìˆì§€ë§Œ, ì„ë¬´ì˜ ë³µì¡ì„±ê³¼ ë¹„ìš©ìœ¼ë¡œ ì¸í•´ ì¼ì •ì´ ë¶ˆí™•ì‹¤í•´ì¡ŒìŠµë‹ˆë‹¤. í™”ì„±ì—ì„œ ìƒëª…ì²´ì˜ ì¦ê±°ë¥¼ ì°¾ëŠ” ì‘ì—…ì€ ê³„ì†ë˜ê³  ìˆìœ¼ë©°, í™”ì„±ì˜ ìƒëª…ì²´ê°€ ë‹¨ì„¸í¬ì¼ ê°€ëŠ¥ì„±ì´ ìˆì–´ íƒì§€ê°€ ì–´ë ¤ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "2bfa44bc1d84798a",
    "title": {
      "en": "Trapping misbehaving bots in an AI Labyrinth",
      "ko": "AI ë¯¸ë¡œì˜ í•¨ì •",
      "ja": null
    },
    "type": "story",
    "url": "https://blog.cloudflare.com/ai-labyrinth/",
    "score": 236,
    "by": "pabs3",
    "time": 1742391067,
    "content": "Trapping misbehaving bots in an AI Labyrinth2025-03-19Reid TatorisHarsh SaxenaLuis Miglietti5 min readToday, weâ€™re excited to announce AI Labyrinth, a new mitigation approach that uses AI-generated content to slow down, confuse, and waste the resources of AI Crawlers and other bots that donâ€™t respect â€œno crawlâ€ directives. When you opt in, Cloudflare will automatically deploy an AI-generated set of linked pages when we detect inappropriate bot activity, without the need for customers to create any custom rules.AI Labyrinth is available on an opt-in basis to all customers, including the Free plan.\n\n            Using Generative AI as a defensive weapon\n\n        AI-generated content has exploded, reportedly accounting for four of the top 20 Facebook posts last fall. Additionally, Medium estimates that 47% of all content on their platform is AI-generated. Like any newer tool it has both wonderful and malicious uses.At the same time, weâ€™ve also seen an explosion of new crawlers used by AI companies to scrape data for model training. AI Crawlers generate more than 50 billion requests to the Cloudflare network every day, or just under 1% of all web requests we see. While Cloudflare has several tools for identifying and blocking unauthorized AI crawling, we have found that blocking malicious bots can alert the attacker that you are on to them, leading to a shift in approach, and a never-ending arms race. So, we wanted to create a new way to thwart these unwanted bots, without letting them know theyâ€™ve been thwarted.To do this, we decided to use a new offensive tool in the bot creatorâ€™s toolset that we havenâ€™t really seen used defensively: AI-generated content. When we detect unauthorized crawling, rather than blocking the request, we will link to a series of AI-generated pages that are convincing enough to entice a crawler to traverse them. But while real looking, this content is not actually the content of the site we are protecting, so the crawler wastes time and resources.As an added benefit, AI Labyrinth also acts as a next-generation honeypot. No real human would go four links deep into a maze of AI-generated nonsense. Any visitor that does is very likely to be a bot, so this gives us a brand-new tool to identify and fingerprint bad bots, which we add to our list of known bad actors. Hereâ€™s how we do itâ€¦\n\n            How we built the labyrinth\n\n        When AI crawlers follow these links, they waste valuable computational resources processing irrelevant content rather than extracting your legitimate website data. This significantly reduces their ability to gather enough useful information to train their models effectively.To generate convincing human-like content, we used Workers AI with an open source model to create unique HTML pages on diverse topics. Rather than creating this content on-demand (which could impact performance), we implemented a pre-generation pipeline that sanitizes the content to prevent any XSS vulnerabilities, and stores it in R2 for faster retrieval. We found that generating a diverse set of topics first, then creating content for each topic, produced more varied and convincing results. It is important to us that we donâ€™t generate inaccurate content that contributes to the spread of misinformation on the Internet, so the content we generate is real and related to scientific facts, just not relevant or proprietary to the site being crawled.This pre-generated content is seamlessly integrated as hidden links on existing pages via our custom HTML transformation process, without disrupting the original structure or content of the page. Each generated page includes appropriate meta directives to protect SEO by preventing search engine indexing. We also ensured that these links remain invisible to human visitors through carefully implemented attributes and styling. To further minimize the impact to regular visitors, we ensured that these links are presented only to suspected AI scrapers, while allowing legitimate users and verified crawlers to browse normally.\n\n          A graph of daily requests over time, comparing different categories of AI Crawlers.What makes this approach particularly effective is its role in our continuously evolving bot detection system. When these links are followed, we know with high confidence that it's automated crawler activity, as human visitors and legitimate browsers would never see or click them. This provides us with a powerful identification mechanism, generating valuable data that feeds into our machine learning models. By analyzing which crawlers are following these hidden pathways, we can identify new bot patterns and signatures that might otherwise go undetected. This proactive approach helps us stay ahead of AI scrapers, continuously improving our detection capabilities without disrupting the normal browsing experience.By building this solution on our developer platform, we've created a system that serves convincing decoy content instantly while maintaining consistent quality - all without impacting your site's performance or user experience.\n\n            How to use AI Labyrinth to stop AI crawlers\n\n        Enabling AI Labyrinth is simple and requires just a single toggle in your Cloudflare dashboard. Navigate to the bot management section within your zone, and toggle the new AI Labyrinth setting to on:\n\n          Once enabled, the AI Labyrinth begins working immediately with no additional configuration needed.\n\n            AI honeypots, created by AI\n\n        The core benefit of AI Labyrinth is to confuse and distract bots. However, a secondary benefit is to serve as a next-generation honeypot. In this context, a honeypot is just an invisible link that a website visitor canâ€™t see, but a bot parsing HTML would see and click on, therefore revealing itself to be a bot. Honeypots have been used to catch hackers as early as the late 1986 Cuckooâ€™s Egg incident. And in 2004, Project Honeypot was created by Cloudflare founders (prior to founding Cloudflare) to let everyone easily deploy free email honeypots, and receive lists of crawler IPs in exchange for contributing to the database. But as bots have evolved, they now proactively look for honeypot techniques like hidden links, making this approach less effective.AI Labyrinth wonâ€™t simply add invisible links, but will eventually create whole networks of linked URLs that are much more realistic, and not trivial for automated programs to spot. The content on the pages is obviously content no human would spend time-consuming, but AI bots are programmed to crawl rather deeply to harvest as much data as possible. When bots hit these URLs, we can be confident they arenâ€™t actual humans, and this information is recorded and automatically fed to our machine learning models to help improve our bot identification. This creates a beneficial feedback loop where each scraping attempt helps protect all Cloudflare customers.\n\n            Whatâ€™s next\n\n        This is only the first iteration of using generative AI to thwart bots for us. Currently, while the content we generate is convincingly human, it wonâ€™t conform to the existing structure of every website. In the future, weâ€™ll continue to work to make these links harder to spot and make them fit seamlessly into the existing structure of the website theyâ€™re embedded in. You can help us by opting in now.To take the next step in the fight against bots, opt-in to AI Labyrinth today.Cloudflare's connectivity cloud protects entire corporate networks, helps customers build Internet-scale applications efficiently, accelerates any website or Internet application, wards off DDoS attacks, keeps hackers at bay, and can help you on your journey to Zero Trust.Visit 1.1.1.1 from any device to get started with our free app that makes your Internet faster and safer.To learn more about our mission to help build a better Internet, start here. If you're looking for a new career direction, check out our open positions.Discuss on Hacker NewsSecurity WeekBotsBot ManagementAI BotsAIMachine LearningGenerative AI",
    "summary": {
      "en": "Cloudflare has introduced a new feature called AI Labyrinth, designed to confuse and slow down unauthorized bots that ignore \"no crawl\" directives. This system uses AI-generated content to create a series of linked pages that bots may follow, wasting their resources without alerting them to being blocked.\n\nKey points include:\n\n1. **Purpose**: AI Labyrinth aims to distract unwanted bots while collecting data on their behavior to improve bot detection systems.\n\n2. **How It Works**: When suspicious bot activity is detected, AI Labyrinth generates convincing but irrelevant pages that bots might crawl, making it harder for them to gather useful information.\n\n3. **Implementation**: Users can easily enable this feature in their Cloudflare dashboard with a simple toggle.\n\n4. **Benefits**: The approach not only confuses bots but also helps identify them as they navigate through the maze of AI-generated pages, contributing to better bot detection.\n\n5. **Future Plans**: Cloudflare plans to enhance this feature by making the AI-generated links more integrated with existing website structures and harder for bots to detect.\n\nOverall, AI Labyrinth is a proactive tool for protecting websites from unwanted bot activity while maintaining a seamless experience for legitimate users.",
      "ko": "í´ë¼ìš°ë“œí”Œë ˆì–´ëŠ” \"í¬ë¡¤ë§ ê¸ˆì§€\" ì§€ì¹¨ì„ ë¬´ì‹œí•˜ëŠ” ë¬´ë‹¨ ë´‡ì„ í˜¼ë€ìŠ¤ëŸ½ê²Œ í•˜ê³  ëŠë¦¬ê²Œ ë§Œë“œëŠ” ìƒˆë¡œìš´ ê¸°ëŠ¥ì¸ AI ë¯¸ë¡œë¥¼ ë„ì…í–ˆìŠµë‹ˆë‹¤. ì´ ì‹œìŠ¤í…œì€ AIê°€ ìƒì„±í•œ ì½˜í…ì¸ ë¥¼ ì‚¬ìš©í•˜ì—¬ ë´‡ì´ ë”°ë¼ê°ˆ ìˆ˜ ìˆëŠ” ì¼ë ¨ì˜ ì—°ê²°ëœ í˜ì´ì§€ë¥¼ ë§Œë“¤ì–´, ë´‡ì´ ì°¨ë‹¨ë˜ì—ˆë‹¤ëŠ” ê²½ê³  ì—†ì´ ìì›ì„ ë‚­ë¹„í•˜ê²Œ í•©ë‹ˆë‹¤.\n\nAI ë¯¸ë¡œì˜ ì£¼ìš” ëª©ì ì€ ì›ì¹˜ ì•ŠëŠ” ë´‡ì„ ë¶„ì‚°ì‹œí‚¤ë©´ì„œ ê·¸ë“¤ì˜ í–‰ë™ì— ëŒ€í•œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì—¬ ë´‡ íƒì§€ ì‹œìŠ¤í…œì„ ê°œì„ í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ë´‡ í™œë™ì´ ê°ì§€ë˜ë©´ AI ë¯¸ë¡œëŠ” ë´‡ì´ í¬ë¡¤ë§í•  ìˆ˜ ìˆëŠ” ê·¸ëŸ´ë“¯í•˜ì§€ë§Œ ê´€ë ¨ ì—†ëŠ” í˜ì´ì§€ë¥¼ ìƒì„±í•˜ì—¬ ìœ ìš©í•œ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ê¸° ì–´ë µê²Œ ë§Œë“­ë‹ˆë‹¤.\n\nì‚¬ìš©ìëŠ” í´ë¼ìš°ë“œí”Œë ˆì–´ ëŒ€ì‹œë³´ë“œì—ì„œ ê°„ë‹¨í•œ í† ê¸€ë¡œ ì´ ê¸°ëŠ¥ì„ ì‰½ê²Œ í™œì„±í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ì ‘ê·¼ ë°©ì‹ì€ ë´‡ì„ í˜¼ë€ìŠ¤ëŸ½ê²Œ í•  ë¿ë§Œ ì•„ë‹ˆë¼, AIê°€ ìƒì„±í•œ í˜ì´ì§€ì˜ ë¯¸ë¡œë¥¼ íƒìƒ‰í•˜ëŠ” ë™ì•ˆ ë´‡ì„ ì‹ë³„í•˜ëŠ” ë°ë„ ë„ì›€ì´ ë˜ì–´ ë” ë‚˜ì€ ë´‡ íƒì§€ì— ê¸°ì—¬í•©ë‹ˆë‹¤.\n\ní´ë¼ìš°ë“œí”Œë ˆì–´ëŠ” ì•ìœ¼ë¡œ AIê°€ ìƒì„±í•œ ë§í¬ë¥¼ ê¸°ì¡´ ì›¹ì‚¬ì´íŠ¸ êµ¬ì¡°ì™€ ë” í†µí•©í•˜ê³  ë´‡ì´ ê°ì§€í•˜ê¸° ì–´ë µê²Œ ë§Œë“œëŠ” ë°©í–¥ìœ¼ë¡œ ì´ ê¸°ëŠ¥ì„ ê°•í™”í•  ê³„íšì…ë‹ˆë‹¤. ì „ë°˜ì ìœ¼ë¡œ AI ë¯¸ë¡œëŠ” ì›¹ì‚¬ì´íŠ¸ë¥¼ ì›ì¹˜ ì•ŠëŠ” ë´‡ í™œë™ìœ¼ë¡œë¶€í„° ë³´í˜¸í•˜ë©´ì„œ ì •ë‹¹í•œ ì‚¬ìš©ìì—ê²ŒëŠ” ì›í™œí•œ ê²½í—˜ì„ ì œê³µí•˜ëŠ” ëŠ¥ë™ì ì¸ ë„êµ¬ì…ë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "d0d4221bad257bc0",
    "title": {
      "en": "Jensen, We're with You. But We're Not There Yet",
      "ko": "ì  ìŠ¨, í•¨ê»˜í•˜ì§€ë§Œ ì•„ì§ ë©€ì—ˆì–´",
      "ja": null
    },
    "type": "story",
    "url": "https://www.chipstrat.com/p/jensen-were-with-you-but-were-not",
    "score": 4,
    "by": "austinlyons",
    "time": 1743183529,
    "content": "Share this postChipstratJensen, Weâ€™re With You. But Weâ€™re Not There Yet.Copy linkFacebookEmailNotesMoreJensen, Weâ€™re With You. But Weâ€™re Not There Yet.Austin LyonsMar 28, 2025âˆ™ Paid13Share this postChipstratJensen, Weâ€™re With You. But Weâ€™re Not There Yet.Copy linkFacebookEmailNotesMore5ShareOne thing stood out in NVIDIAâ€™s GTC Financial Analyst Q&A: CEO Jensen Huang didnâ€™t feel heard. His tone and demeanor suggested he was frustrated that his message wasnâ€™t landing. Watch the event from ~12:03 to 13:00 or so in the video here.Jensen Huang: And we're not just building a chip, we're building networkings and switches and, you know, we're basically building systems components for the world's enterprise, for the world's data center. So that's number one. The second thing I said is that nobody's got right, none of these forecasts has it, this concept of AI factories. Are you guys following me? It's not a multipurpose data center. It's a single-function AI factory. And these GPU clouds, Stargates, and so on and so forth. Okay? These AI factories are not accounted for. Do you guys understand? Nope. Because nobody knows how to do that. And these multiple hundred billion dollar CapEx projects coming online are not part of somebody's data center forecast. Are you guys following me? How could they possibly know about these things? We're inventing them as we speak.Over the span of an hour, he said, â€œAre you guys following me?â€ six times, â€œDo you guys understand?â€ several times, and â€œI hope you understand.â€  It wasnâ€™t just analysts Jensen was frustrated with. The market doesnâ€™t fully comprehend his long-term vision, and the broader public seems even further from understanding what NVIDIA is building.But before I give my two cents, I want to preface that Iâ€™m a huge believer in AI, and I think NVIDIA is as strong as ever. Consider this a loving intervention.But, with all due respect, itâ€™s not that the audience doesnâ€™t understand NVIDIA. I think NVIDIA doesnâ€™t understand the audience.Let me explain.Know Your AudienceWho is NVIDIAâ€™s audience? Itâ€™s not just Wall Street. Judging by market cap, every retail investor is Jensenâ€™s audience. NVIDIA stands among huge consumer brands like Apple, Microsoft, Amazon, and Google. Iâ€™d go one step further â€” given Jensenâ€™s vision, the general public is Jensenâ€™s audience.So does the general public understand NVIDIA? And does Jensen understand the general public?A Thought ExperimentImagine standing in a Walmart in Fargo, offering free samples. Not as a marketer, but simply to talk with everyday Americans. What if we ask them what they know about Apple, Amazon, or Google?Have I ever heard of Apple? (Holds up iPhone). Of course!Heard of Amazon? Ha! The Amazon truck stops every day on my street!Do I use Google? Oh yah, sure, you betcha. But what if we ask about NVIDIA? Some might say â€œIâ€™m a gamer. Of course. NVIDIA GPUs are the best.â€ But the rest? I promise you the answer will be along the lines of:NVIDIA? Uff da. I know Iâ€™ve heard of themâ€¦ I know they are a tech company. Hold on, let me thinkâ€¦.. I know they are good to invest in! Ha! â€¦.. what do they do though? Oh boyâ€¦. Something with AI?I know Nvidia vs the others doesnâ€™t feel like a fair comparison. Everyone has intimate proximity to the other consumer brands, whereas the vast majority of NVIDIAâ€™s revenue doesnâ€™t come from consumers. But NVIDIA is a GPU company, right?Nope, NVIDIA is not a GPU company. It used to be a GPU company, but pivoted to a GPGPU company.GPGPU? A General Purpose GPU. With it, you can do more than just graphics. Oh, like Bitcoin? NVIDIA did Bitcoin, right?Well, yes, NVIDIA GPUs were used for Bitcoin mining. But nevermind that; that was just a phase. Now, NVIDIA makes systems. It is an infrastructure company.â€¦ an infrastructure company?Infrastructure to build AI factories.â€¦youâ€™re saying NVIDIA is an AI factoryâ€¦. factory?Oh, thatâ€™s meta.Meta? â€¦. Meta makes the factories?No, sorry. Gimme a secondâ€¦ NVIDIA is the platform every major industry will use to build out its AI factories.Iâ€™m just gonna get back to shopping nowâ€¦AI factories? Thatâ€™s not gonna play in Peoria.If You Canâ€™t Explain It To A ChildIf NVIDIA wants to be understood by the general public, a good starting point is to ask if the basics make sense to a fifth-grader.How about the opening minutes of GTC from a fifth graderâ€™s eyes?This is how intelligence is built nowâ€”a new kind of factory, generating tokens, the basic units of AI. Tokens have opened up a new frontier, the first step into a world full of possibility.They turn images into scientific insight, mapping distant atmospheres and guiding future explorers. They convert raw data into foresight, helping us prepare for whatâ€™s next.Tokens help us decode physics to move faster and reach farther. They can detect disease before symptoms appear and help us understand the biology of life itself.They connect information in ways that protect the most vulnerable. They turn potential into abundance and help us gather the benefits of what we grow.Tokens donâ€™t just teach robots to moveâ€”they bring delight, offer support, and make the impossible feel within reach.Together, we take the next great leap, pushing into the unknown.And it all starts here.Tokens? Likeâ€¦ arcade tokens?Nolan Bushnell earned more from founding Chuck E. Cheese than from founding Atari! AcquiredSure, GTC isnâ€™t aimed at kids. Maybe retail investors, at best. Itâ€™s an industry event, right? For industry insiders.Yet downstream contentâ€”tweets, TikToks, WSJ headlinesâ€”flow from Jensenâ€™s keynote. GTC shapes the narrative for everyone.If NVIDIA and Jensen can express their vision in terms that are simple enough for a child, then journalists, investors, analysts, and customers will all be able to grasp it too.But itâ€™s not simply the choice of language.The Elephant in the RoomGenAI isnâ€™t part of everyday life in places like Fargo. Thatâ€™s the hurdle. People donâ€™t care about NVIDIAâ€™s AI infrastructure if the output doesnâ€™t touch them. NVIDIA canâ€™t win the narrative until AI actually matters to regular people.Sure, ChatGPT has 400 million weekly users, but how many are paying subscribers? And how many in Fargo? Show me the Fargo businesses with increased revenue and productivity thanks to generative AI?Whereâ€™s the ad revenue business model to truly become a worldwide verb like Google and get on the home screen of every phone in Fargo? Sam Altman is not interested an advertising business model, but the general Fargo population isnâ€™t going to pay for ChatGPT.Donâ€™t get me wrong; there are people everywhere who understand and use generative AI, and pay for it â€” including people in Fargo. And Iâ€™m not downplaying the usefulness of LLMs either. If anything, I believe Generative AI will transform the world more profoundly than the internet ever did.However, Jensenâ€™s earnings calls, keynotes, and investor presentations are all based on the assumption that GenAI's future is here. Which is true for Nvidians. Just not their audience.The future exists and is continually created inside NVIDIAâ€™s walls.Again, the issue isnâ€™t that the audience doesnâ€™t understand NVIDIAâ€”itâ€™s that NVIDIA doesnâ€™t understand the audience. Theyâ€™re not living in the same timeline. Nvidia envisions the future, invents the software and hardware needed to enable the vision, and then uses it! They live in the future. Jensen exemplifies this by using AI constantly and understanding the deep technical details from top to bottom.Yet the general public lives in the present; some experience a small taste of that future, but most just arenâ€™t experiencing it yet.NVIDIA, weâ€™re with youâ€”weâ€™re just not there yet.Distributing the FutureOrdinary folks arenâ€™t using AI because they donâ€™t see the point; it doesnâ€™t obviously solve their daily problems.Flashing tomorrowâ€™s tech at them wonâ€™t drive adoption; they need to see why it matters now. But Jensenâ€™s NVIDIA is often skipping ahead to showing the future they are enabling.Futuristic scene from NVIDIAâ€™s GTC keynote opening video.This is understandable, and itâ€™s not just Jensen, but itâ€™s Elonâ€™s problem too. Elon, I donâ€™t need a robotaxi or humanoid today. Yes, that looks cool. But dude, we drive a gasoline guzzling minivan every single day. Thatâ€™s our problem. We just need a Tesla minivan right now.  NVIDIA needs to show more of the present and less of the future. But thatâ€™s the rub for NVIDIA: what problems are they solving right now for ordinary folks? Again, thereâ€™s the adoption problem.But, look no further thanâ€¦ North Dakota! The state government is trying to use GenAI to solve real problems:The [use case] that weâ€™re very keenly focused on exploring is making it possible to go to the state of North Dakota website and have an interface that allows you to comb through the treasure trove of information across the stateâ€™s multiple websites through a simple request or prompt. Our goal is to create a frictionless experience for our citizens to interact with the government.An example of this would be going to the Governorâ€™s Office website and asking the large language model, â€œHow do I start a business?â€ Currently, you might have to go through five or six clicks until you get to the right information. Or, there are instances when trying to comply with a tax requirement that you could find yourself going through 50 clicks to get the information that you want.Making it easier to start a business or research taxes in North Dakota? Thatâ€™s what Iâ€™m talking about! ğŸ’ª It's much more relatable than humanoid robots serving coffee! Is making coffee even a problem people have today? Iâ€™m pretty sure there are already cheap machines to make coffee for usâ€¦NVIDIA should back real-world initiatives like these that make AI matter to people, turning them into compelling narratives stamped with â€œPowered by NVIDIA.â€ Itâ€™s a strategic brand play with mutual upside.Shoot, hereâ€™s a typical American problem: The DMV. The people in these pictures are ordinary Americans who want to do LITERALLY ANYTHING ELSE in the world other than wait here. They probably even had to waste a vacation day to knock this out.Thereâ€™s obvious friction in how DMVs runâ€”clunky software, slow workflows, not enough people. LLMs could help. Agents too. States donâ€™t have the motivation or the tech skills to fix it, but NVIDIA does!Want to go mainstream? Imagine future keynotesâ€”instead of talking abstractly about tokens, NVIDIA could show before-and-after videos of the lines at the local DMV. Talk about great fodder for viral social media videos! By the way, I used AI (Grok) to remove all the people from these images. And Grok, of course, runs on NVIDIA! Yes, the examples are hypothetical, but the core issue is real: Jensen talks like everyone already uses and values AI. But most people donâ€™t. The best way to reach the public is to make AI real in their daily lives.BaggagePart of the public misunderstanding of NVIDIA relates to the baggage of 30 years of NVIDIA finding their way. Graphics? GPU? GPGPU? Bitcoin? AI? But now that NVIDIA is worth more than many countries and even has consumer product aspirations, it needs public clarity. What, exactly, is NVIDIAâ€™s core product? And how can NVIDIA describe that product in terms accessible to the broader public?Naming and Framing ProblemsI was on The Circuit podcast recently, trying to explain the difference between DeepSeek V3, DeepSeek R1, DeepSeek-Distill-Llama-70B, and DeepSeek-R1-Distill-Llama-8B. You can see where this is going ğŸ˜…Well, thereâ€™s DeepSeek V1, which wasnâ€™t actually named V1, and itâ€™s a dense model. Then they shipped DeepSeekMoE, the mixture of experts sparse model. Next up was V2, which was also an MoE. Then V3 was the best MoE yet. And these are all â€œfast-thinkingâ€ models. Next, V3â€™s base model was used with RL to train a reasoning model called R1. Engineers love literal names like DeepSeek-Distill-Llama-70B. It makes perfect sense; the name says it all!This is a common trap in platform industries like AI and semis, where companies sell to other tech firms. Engineers market to engineers. The meaning is obvious to industry insiders but meaningless to everyone else. These industries and their technical marketers also resort to versioning as a naming convention, which is sort of like semantic versioning in software.Intel was king of this with their microprocessors 4004 â†’ 8008 â†’ 8080 â†’ 8086 â†’ 286 â†’ 386 â†’ 486. ğŸ˜…Sound familiar? Just look at OpenAI: GPT-3 â†’ 3.5 â†’ 4 â†’ 4o â†’ 4.5.Naming is tough; I get it. And like I said, these are platform companies that sell the building blocks (APIs, chips, memory) that power other companies' consumer products. The platform company engineers and marketers may not realize thereâ€™s a disconnect because their customers get it, even if the customerâ€™s customers donâ€™t.FramingHowever, for platform companies, this is not just a naming issue but a framing issue. You need to make sure your customerâ€™s customer understands why youâ€™re essential to the product theyâ€™re using.Think about â€œIntel Inside.â€ Watch this beautiful framing from 1992:This symbol outside means you have the standard inside that an entire library of software has been written to. The Intel microprocessor. Think of it as a library card that lets you run the software of today and tomorrow. So check out computers with Intel the computer inside.See the framing?Problem: When youâ€™re buying a computer, you need to make sure it can run the software you care about â€“ now and in the future.  This problem is implied.Solution: Buy a computer with Intel inside. A ton of software runs on Intel.Consumers arenâ€™t buying CPUs; theyâ€™re buying a computer so they can run software. Since Intel doesnâ€™t sell computers, they frame where Intel fits and why they are an essential part of the solution.Notice Intel went to directly to the customerâ€™s customer! And, Intel didnâ€™t mention any product names! They just made the connection between their brand (Intel) and a brief mention of their line of products (microprocessor).So even if your product names are borked, youâ€™re not dead ğŸ˜…InformallyAnother option is to use informal names that help the general public understand. For illustration (these arenâ€™t great, but you get the gist):So the amazing thing about this tiny thinking llama is that itâ€™s small enough to run on your smartphone or laptop! And the full-sized thinking llama can run on an AI workstation like the NVIDIA Spark! I can imagine how helpful a bunch of digital interns at your fingertips would be â€“ can you?Naming and framing, especially with baggage, can trip up even the best of companies.NVIDIAâ€™s Naming Problems, IllustratedWhen NVIDIA only made graphics cards, or GPUs, it made sense to name and talk about a new architecture like Volta.But NVIDIA is an AI systems company, not a GPU companyNVIDIAâ€™s 2025 revenue mix. Data from QuartrThe AI systems that account for 88% of revenue are much more than a GPU. They are a system, including cables, switches, racks, GPUs, CPUs, liquid cooling, and software.Yet, confusingly, NVIDIAâ€™s framing centers around the GPU. Blackwell, the GPU architecture, is mentioned with every productYes, Blackwell is a core component in every product which has a bunch of useful implications for engineers, like the ability to deploy CUDA on any of these devices.Of course, for anyone else the GPU-centric framing of every product is confusing.Itâ€™s like this, except the Grace Blackwell spiderman should be 9x bigger than the others combined.So when NVIDIA launches â€œthe new Blackwellâ€, are we talking about the AI datacenters, or new graphics cards, or new self-driving car processors, or what?And the crazy thing is that the system that makes all the money, the AI datacenters, doesnâ€™t really have a name! Sure it does. Donâ€™t be dumb. Itâ€™s Grace Blackwell.Thatâ€™s the name of the system? Or is that just the CPU architecture (Grace) and the GPU architecture (Blackwell)?Well, ok, the name is GB300 NVL72.Oh, so itâ€™s a â€œversion controlâ€ name? Yeah, howâ€™s that gonna play in Fargo?So itâ€™s the Grace Blackwell 300 NVL72, which means the latest CPU architecture (Grace) and the new GPU architecture (Blackwell). There was already a 200, so they updated the version number (300). NVL72 is the networking configurationâ€”NVLink with 72 GPUs in a node. This many GPUs implies liquid cooling as well, because they cram those suckers in and run them hot!OK, fine, just focus on the generation. OK. This generation is Blackwell. The next generation is Rubin. Like it says in the roadmap:Wait a minuteâ€¦ So the AI systems are named after the GPUs, yet youâ€™re not a GPU company? ğŸ¤”Give the System a NameMaybe itâ€™s time for a reset. Instead of naming AI datacenters after GPUs or with version codes, why not give the system its own name? Something memorable, something brandable.Yes, of course I named it after The Matrix, I couldnâ€™t help myselfâ€¦. Matrix multiplication. Agents. Simulated worlds. AIâ€¦. I mean, come on.Anyway, keep it simple for the general public. Weâ€™re launching our newest AI supercomputer, Neo!And let MKBHD summarize the details for the public in 56 seconds like he does.Real World AIOK, now that youâ€™ve got a name and can talk to the public, weâ€™re back to that â€œAI doesnâ€™t matter to meâ€ problem.Given that most people donâ€™t see how Generative AI impacts their life, let alone understand what â€œAI factoryâ€ or â€œAI supercomputerâ€ means, why not illustrate in ways that customers understand?Imagine a commercial that illustrates common problems and shows how they are solved with Generative AI, powered by NVIDIAâ€™s AI supercomputers.For example, most everyone can relate to the pains of grocery shopping, but it could be sped up with AI:Remember how Chemistry was hard? What if you had a personalized study guide?Of course, I generated these with AI, powered by NVIDIA:I didnâ€™t say theyâ€™d be great â€” but I couldnâ€™t have done it without NVIDIA AI!Behind the paywall, weâ€™ll get tactical. What lessons can NVIDIA learn from earlier GenAI hardware marketing failures like Intelâ€™s AI PC and Apple Intelligence? Should Jensen share the story-telling load? Then weâ€™ll conclude with some final takeaways.By the way, if youâ€™re a free subscriber who wants even more brain food, consider talking to your boss about a reimbursement so you can enjoy the entire serving. Creative Strategies also offers an enterprise Chipstrat subscription for your entire company to enjoy a weekly helping. More here. This post is for paid subscribersSubscribeAlready a paid subscriber? Sign inPrevious",
    "summary": {
      "en": "In a recent Q&A session at NVIDIA's GTC event, CEO Jensen Huang expressed frustration that his vision for the company and its future wasn't being understood by analysts and the public. He emphasized that NVIDIA is not just a GPU company but an infrastructure company focused on building AI systems, which he referred to as \"AI factories.\" Despite his repeated questions to the audience about their understanding, it became clear he felt his message was not resonating.\n\nThe author argues that the issue lies not with the audience's comprehension but with NVIDIA's failure to connect with them. Many people, especially outside the tech industry, are unfamiliar with NVIDIA and its products. Unlike well-known consumer brands like Apple or Amazon, NVIDIA's advancements in AI technology do not directly impact the daily lives of most individuals.\n\nTo bridge this gap, NVIDIA should simplify its messaging, making it relatable and understandable to the general public. By focusing on real-world applications of AI that address everyday problems, such as improving government services or enhancing shopping experiences, NVIDIA can better demonstrate its relevance. The author suggests that NVIDIA needs clearer naming and framing of its products to make them more accessible and memorable to consumers. Ultimately, to gain broader acceptance, NVIDIA must connect its innovations with the tangible benefits they can offer to everyday people.",
      "ko": "ìµœê·¼ NVIDIAì˜ GTC í–‰ì‚¬ì—ì„œ ì—´ë¦° Q&A ì„¸ì…˜ì—ì„œ CEO ì  ìŠ¨ í™©ì€ ìì‹ ì˜ íšŒì‚¬ ë¹„ì „ê³¼ ë¯¸ë˜ì— ëŒ€í•œ ì´í•´ê°€ ë¶„ì„ê°€ë“¤ê³¼ ëŒ€ì¤‘ì—ê²Œ ì „ë‹¬ë˜ì§€ ì•Šê³  ìˆë‹¤ëŠ” ì ì— ëŒ€í•´ ë¶ˆë§Œì„ í‘œì¶œí–ˆìŠµë‹ˆë‹¤. ê·¸ëŠ” NVIDIAê°€ ë‹¨ìˆœí•œ GPU íšŒì‚¬ê°€ ì•„ë‹ˆë¼ AI ì‹œìŠ¤í…œ êµ¬ì¶•ì— ì§‘ì¤‘í•˜ëŠ” ì¸í”„ë¼ íšŒì‚¬ë¼ê³  ê°•ì¡°í•˜ë©° ì´ë¥¼ \"AI ê³µì¥\"ì´ë¼ê³  í‘œí˜„í–ˆìŠµë‹ˆë‹¤. ê·¸ëŠ” ì²­ì¤‘ì—ê²Œ ê·¸ë“¤ì˜ ì´í•´ë„ë¥¼ ì—¬ëŸ¬ ë²ˆ ì§ˆë¬¸í–ˆì§€ë§Œ, ìì‹ ì˜ ë©”ì‹œì§€ê°€ ì œëŒ€ë¡œ ì „ë‹¬ë˜ì§€ ì•Šì•˜ë‹¤ê³  ëŠë¼ëŠ” ê²ƒ ê°™ì•˜ìŠµë‹ˆë‹¤.\n\nì €ìëŠ” ë¬¸ì œì˜ ì›ì¸ì´ ì²­ì¤‘ì˜ ì´í•´ ë¶€ì¡±ì´ ì•„ë‹ˆë¼ NVIDIAê°€ ê·¸ë“¤ê³¼ ì†Œí†µí•˜ì§€ ëª»í•˜ëŠ” ë° ìˆë‹¤ê³  ì£¼ì¥í•©ë‹ˆë‹¤. íŠ¹íˆ ê¸°ìˆ  ì‚°ì—… ì™¸ë¶€ì˜ ë§ì€ ì‚¬ëŒë“¤ì€ NVIDIAì™€ ê·¸ ì œí’ˆì— ëŒ€í•´ ì˜ ì•Œì§€ ëª»í•©ë‹ˆë‹¤. ì• í”Œì´ë‚˜ ì•„ë§ˆì¡´ê³¼ ê°™ì€ ì˜ ì•Œë ¤ì§„ ì†Œë¹„ì ë¸Œëœë“œì™€ ë‹¬ë¦¬, NVIDIAì˜ AI ê¸°ìˆ  ë°œì „ì€ ëŒ€ë¶€ë¶„ì˜ ì‚¬ëŒë“¤ì˜ ì¼ìƒìƒí™œì— ì§ì ‘ì ì¸ ì˜í–¥ì„ ë¯¸ì¹˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n\nì´ëŸ¬í•œ ê°„ê·¹ì„ í•´ì†Œí•˜ê¸° ìœ„í•´ NVIDIAëŠ” ë©”ì‹œì§€ë¥¼ ê°„ì†Œí™”í•˜ì—¬ ì¼ë°˜ ëŒ€ì¤‘ì´ ì´í•´í•˜ê³  ê³µê°í•  ìˆ˜ ìˆë„ë¡ í•´ì•¼ í•©ë‹ˆë‹¤. ì •ë¶€ ì„œë¹„ìŠ¤ ê°œì„ ì´ë‚˜ ì‡¼í•‘ ê²½í—˜ í–¥ìƒê³¼ ê°™ì€ ì¼ìƒì ì¸ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” AIì˜ ì‹¤ì œ ì‘ìš© ì‚¬ë¡€ì— ì§‘ì¤‘í•¨ìœ¼ë¡œì¨, NVIDIAëŠ” ìì‹ ì˜ ì¤‘ìš”ì„±ì„ ë” ì˜ ë³´ì—¬ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì €ìëŠ” NVIDIAê°€ ì†Œë¹„ìì—ê²Œ ë” ì ‘ê·¼í•˜ê¸° ì‰½ê³  ê¸°ì–µì— ë‚¨ë„ë¡ ì œí’ˆì˜ ì´ë¦„ê³¼ í”„ë ˆì„ì„ ëª…í™•íˆ í•  í•„ìš”ê°€ ìˆë‹¤ê³  ì œì•ˆí•©ë‹ˆë‹¤. ê¶ê·¹ì ìœ¼ë¡œ, NVIDIAëŠ” í˜ì‹ ì„ ì¼ìƒì ì¸ ì‚¬ëŒë“¤ì—ê²Œ ì œê³µí•  ìˆ˜ ìˆëŠ” ì‹¤ì§ˆì ì¸ í˜œíƒê³¼ ì—°ê²°ì‹œì¼œì•¼ ë” ë„“ì€ ìˆ˜ìš©ì„ ì–»ì„ ìˆ˜ ìˆì„ ê²ƒì…ë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "1ac5efb447be78d8",
    "title": {
      "en": "Show HN: An open source alternative to Wakatime",
      "ko": "ì˜¤í”ˆì†ŒìŠ¤, Wakatime ëŒ€ì•ˆ!",
      "ja": null
    },
    "type": "story",
    "url": "https://wakana.io",
    "score": 36,
    "by": "jemiluv8",
    "time": 1742899923,
    "content": "Beta TestingObserve your work in real timeDeveloper dashboards for insights into your work habitsTry it for free\n\nHow it WorksInstall the relevant WakaTime plugins for your editorhereLocate the ~/.wakatime.cfg file on your computer. This is usually located in your root folder. On windows you might have to show hidden files to see it.Update it with the API key you get in your Wakana dashboardhereUpdate the api_url to https://api.wakana.io/apiAfter ConfigurationOpen your editor and start typing somethingCheck your Wakana dashboard to see if stats show upAlso check the plugins section on your dashboardhereto see if data from any of your plugins has been collectedSample ConfigurationCopy and paste this into your ~/.wakatime.cfg file[settings]\napi_url = https://api.wakana.io/api\napi_key = ## replace this with your api key when you login\nCopyAfter updating your configuration, restart/reload your editor, type something and check your dashboard",
    "summary": {
      "en": "**Summary:**\n\nWakaTime allows you to observe your coding habits in real time and offers developer dashboards for insights. You can try it for free.\n\n**How to Set It Up:**\n1. Install WakaTime plugins for your code editor.\n2. Find the `~/.wakatime.cfg` file on your computer (it may be hidden on Windows).\n3. Update this file with your API key from the WakaTime dashboard and set the `api_url` to `https://api.wakana.io/api`.\n\n**After Configuration:**\n- Open your code editor and start typing.\n- Check your WakaTime dashboard to see if your stats appear.\n- Look in the plugins section to see collected data.\n\n**Sample Configuration:**\n```\n[settings]\napi_url = https://api.wakana.io/api\napi_key = ## replace this with your API key\n```\nAfter you save your changes, restart your editor, type something, and check the dashboard again.",
      "ko": "WakaTimeì€ ì‹¤ì‹œê°„ìœ¼ë¡œ ì½”ë”© ìŠµê´€ì„ ê´€ì°°í•  ìˆ˜ ìˆê²Œ í•´ì£¼ë©°, ê°œë°œì ëŒ€ì‹œë³´ë“œë¥¼ í†µí•´ í†µì°°ë ¥ì„ ì œê³µí•©ë‹ˆë‹¤. ë¬´ë£Œë¡œ ì‚¬ìš©í•´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nì„¤ì • ë°©ë²•ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. ë¨¼ì €, ì½”ë“œ í¸ì§‘ê¸°ì— WakaTime í”ŒëŸ¬ê·¸ì¸ì„ ì„¤ì¹˜í•©ë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ, ì»´í“¨í„°ì—ì„œ `~/.wakatime.cfg` íŒŒì¼ì„ ì°¾ì•„ì•¼ í•©ë‹ˆë‹¤. ì´ íŒŒì¼ì€ Windowsì—ì„œëŠ” ìˆ¨ê²¨ì ¸ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ íŒŒì¼ì„ ì—´ê³  WakaTime ëŒ€ì‹œë³´ë“œì—ì„œ ë°›ì€ API í‚¤ë¡œ ì—…ë°ì´íŠ¸í•œ í›„, `api_url`ì„ `https://api.wakana.io/api`ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.\n\nêµ¬ì„±ì´ ì™„ë£Œë˜ë©´ ì½”ë“œ í¸ì§‘ê¸°ë¥¼ ì—´ê³  ì½”ë”©ì„ ì‹œì‘í•©ë‹ˆë‹¤. WakaTime ëŒ€ì‹œë³´ë“œì—ì„œ í†µê³„ê°€ ë‚˜íƒ€ë‚˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤. ìˆ˜ì§‘ëœ ë°ì´í„°ëŠ” í”ŒëŸ¬ê·¸ì¸ ì„¹ì…˜ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nìƒ˜í”Œ êµ¬ì„±ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. \n[settings] \napi_url = https://api.wakana.io/api \napi_key = ## ì—¬ê¸°ì— API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš” \n\në³€ê²½ ì‚¬í•­ì„ ì €ì¥í•œ í›„ í¸ì§‘ê¸°ë¥¼ ì¬ì‹œì‘í•˜ê³ , ë¬´ì–¸ê°€ë¥¼ ì…ë ¥í•œ ë‹¤ìŒ ëŒ€ì‹œë³´ë“œë¥¼ ë‹¤ì‹œ í™•ì¸í•©ë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "e762d69afa7de586",
    "title": {
      "en": "Scientists Discover New Heavy-Metal Molecule 'Berkelocene'",
      "ko": "ìƒˆë¡œìš´ ì¤‘ê¸ˆì† ë¶„ì 'ë²„ì¼ˆë¡œì‹ ' ë°œê²¬!",
      "ja": null
    },
    "type": "story",
    "url": "https://newscenter.lbl.gov/2025/03/11/scientists-discover-new-heavy-metal-molecule-berkelocene/",
    "score": 126,
    "by": "gmays",
    "time": 1742821658,
    "content": "Key Takeaways\n\nScientists have discovered â€œberkelocene,â€ the first organometallic molecule to be characterized containing the heavy element berkelium.\nThe extremely oxygen- and water-sensitive complex was formed from 0.3 milligram of berkelium-249 using specialized facilities for handling air-sensitive and radioactive materials.\nThe breakthrough disrupts long-held theories about the chemistry of the elements that follow uranium in the periodic table.\n\nA research team led by the Department of Energyâ€™s Lawrence Berkeley National Laboratory (Berkeley Lab) has discovered â€œberkelocene,â€ the first organometallic molecule to be characterized containing the heavy element berkelium.\nOrganometallic molecules, which consist of a metal ion surrounded by a carbon-based framework, are relatively common for early actinide elements like uranium (atomic number 92) but are scarcely known for later actinides like berkelium (atomic number 97).\nâ€œThis is the first time that evidence for the formation of a chemical bond between berkelium and carbon has been obtained. The discovery provides new understanding of how berkelium and other actinides behave relative to their peers in the periodic table,â€ said Stefan Minasian, a scientist in Berkeley Labâ€™s Chemical Sciences Division and one of four co-corresponding authors of a new study published in the journal Science.\nA heavy metal molecule with Berkeley roots\nBerkelium is one 0f 15 actinides in the periodic tableâ€™s f-block. One row above the actinides are the lanthanides.\nThe pioneering nuclear chemist Glenn Seaborg discovered berkelium at Berkeley Lab in 1949. It would become just one of many achievements that led to his winning the 1951 Nobel Prize in Chemistry with fellow Berkeley Lab scientist Edwin McMillan for their discoveries in the chemistry of the transuranium elements.\nâ€œThis is the first time that evidence for the formation of a chemical bond between berkelium and carbon has been obtained.â€\nâ€“ Stefan Minasian, Chemical Sciences Division staff scientist\nFor many years, the Heavy Element Chemistry group in Berkeley Labâ€™s Chemical Sciences Division has been dedicated to preparing organometallic compounds of the actinides, because these molecules typically have high symmetries and form multiple covalent bonds with carbon, making them useful for observing the unique electronic structures of the actinides.\nâ€œWhen scientists study higher symmetry structures, it helps them understand the underlying logic that nature is using to organize matter at the atomic level,â€ Minasian said.\nFrom left: Dominic Russo, Amy Price, Alyssa Gaiser, Polly Arnold, Jacob Branson, and Jennifer Wacker at Berkeley Labâ€™s Heavy Element Research Laboratory. They are co-authors on a new study published in Science, which reported their discovery of the heavy-metal molecule berkelocene. (Credit: Stefan Minasian/Berkeley Lab)\nBut berkelium is not easy to study because it is highly radioactive. And only very minute amounts of this synthetic heavy element are produced globally every year. Adding to the difficulty, organometallic molecules are extremely air-sensitive and can be pyrophoric.\nâ€œOnly a few facilities around the world can protect both the compound and the worker while managing the combined hazards of a highly radioactive material that reacts vigorously with the oxygen and moisture in air,â€ said Polly Arnold, a co-corresponding author on the paper who is a UC Berkeley professor of chemistry and director of Berkeley Labâ€™s Chemical Sciences Division.\nBreaking down the berkelium barrier\nSo Minasian, Arnold, and co-corresponding author Rebecca Abergel, a UC Berkeley associate professor of nuclear engineering and of chemistry who leads the Heavy Element Chemistry Group at Berkeley Lab, assembled a team to overcome these obstacles.\nAt Berkeley Labâ€™s Heavy Element Research Laboratory, the team custom-designed new gloveboxes enabling air-free syntheses with highly radioactive isotopes. Then, with just 0.3 milligram of berkelium-249, the researchers conducted single-crystal X-ray diffraction experiments. The isotope that was acquired by the team was initially distributed from the National Isotope Development Center, which is managed by the DOE Isotope Program at Oak Ridge National Laboratory.\n\n    The results showed a symmetrical structure with the berkelium atom sandwiched between two 8-membered carbon rings. The researchers named the molecule â€œberkelocene,â€ because its structure is analogous to a uranium organometallic complex called â€œuranocene.â€ (UC Berkeley chemists Andrew Streitwieser and Kenneth Raymond discovered uranocene in the late 1960s.)\nIn an unexpected finding, electronic structure calculations performed by co-corresponding author Jochen Autschbach at the University of Buffalo revealed that the berkelium atom at the center of the berkelocene structure has a tetravalent oxidation state (positive charge of +4), which is stabilized by the berkeliumâ€“carbon bonds.\nâ€œTraditional understanding of the periodic table suggests that berkelium would behave like the lanthanide terbium,â€ said Minasian.\nâ€œBut the berkelium ion is much happier in the +4 oxidation state than the other f-block ions we expected it to be most like,â€ Arnold said.\nThe researchers say that more accurate models showing how actinide behavior changes across the periodic table are needed to solve problems related to long-term nuclear waste storage and remediation. â€œThis clearer portrait of later actinides like berkelium provides a new lens into the behavior of these fascinating elements,â€ Abergel said.\nThis work was supported by the DOE Office of Science.\n###\nLawrence Berkeley National Laboratory (Berkeley Lab) is committed to groundbreaking research focused on discovery science and solutions for abundant and reliable energy supplies. The labâ€™s expertise spans materials, chemistry, physics, biology, earth and environmental science, mathematics, and computing. Researchers from around the world rely on the labâ€™s world-class scientific facilities for their own pioneering research. Founded in 1931 on the belief that the biggest problems are best addressed by teams, Berkeley Lab and its scientists have been recognized with 16 Nobel Prizes. Berkeley Lab is a multiprogram national laboratory managed by the University of California for the U.S. Department of Energyâ€™s Office of Science.\nDOEâ€™s Office of Science is the single largest supporter of basic research in the physical sciences in the United States, and is working to address some of the most pressing challenges of our time. For more information, please visit energy.gov/science.\n\n        Tags:\n\n                  Materials",
    "summary": {
      "en": "Scientists have successfully created and characterized \"berkelocene,\" the first organometallic molecule containing the heavy element berkelium (atomic number 97). This discovery challenges old theories about how elements after uranium behave chemically. \n\nThe research team from the Lawrence Berkeley National Laboratory used a tiny amount (0.3 milligram) of berkelium-249, which is highly radioactive and sensitive to air and moisture. They developed special equipment to safely study this compound. \n\nBerkelocene consists of a berkelium atom between two carbon rings, and it exhibits a unique chemical bond with carbon, suggesting that berkelium behaves differently than previously thought, particularly with a stable positive charge of +4. \n\nThis finding could help improve models for understanding the chemistry of actinides, which is important for nuclear waste management. The team's work was supported by the U.S. Department of Energy.",
      "ko": "ê³¼í•™ìë“¤ì´ ì¤‘ê¸ˆì† ì›ì†Œì¸ ë²„ì¼ˆë¥¨(ì›ìë²ˆí˜¸ 97)ì„ í¬í•¨í•œ ìµœì´ˆì˜ ìœ ê¸°ê¸ˆì† ë¶„ìì¸ 'ë²„ì¼ˆë¡œì„¼'ì„ ì„±ê³µì ìœ¼ë¡œ í•©ì„±í•˜ê³  íŠ¹ì„±ì„ ê·œëª…í–ˆìŠµë‹ˆë‹¤. ì´ ë°œê²¬ì€ ìš°ë¼ëŠ„ ì´í›„ì˜ ì›ì†Œë“¤ì´ í™”í•™ì ìœ¼ë¡œ ì–´ë–»ê²Œ í–‰ë™í•˜ëŠ”ì§€ì— ëŒ€í•œ ê¸°ì¡´ ì´ë¡ ì— ë„ì „í•˜ëŠ” ê²°ê³¼ì…ë‹ˆë‹¤.\n\në¡œë ŒìŠ¤ ë²„í´ë¦¬ êµ­ë¦½ ì—°êµ¬ì†Œì˜ ì—°êµ¬íŒ€ì€ ë°©ì‚¬ëŠ¥ì´ ê°•í•˜ê³  ê³µê¸°ì™€ ìŠµê¸°ì— ë¯¼ê°í•œ ë²„ì¼ˆë¥¨-249ë¥¼ ì†ŒëŸ‰(0.3ë°€ë¦¬ê·¸ë¨) ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤. ì´ í™”í•©ë¬¼ì„ ì•ˆì „í•˜ê²Œ ì—°êµ¬í•˜ê¸° ìœ„í•´ íŠ¹ë³„í•œ ì¥ë¹„ë¥¼ ê°œë°œí–ˆìŠµë‹ˆë‹¤.\n\në²„ì¼ˆë¡œì„¼ì€ ë‘ ê°œì˜ íƒ„ì†Œ ê³ ë¦¬ ì‚¬ì´ì— ë²„ì¼ˆë¥¨ ì›ìê°€ ìœ„ì¹˜í•˜ê³  ìˆìœ¼ë©°, íƒ„ì†Œì™€ ë…íŠ¹í•œ í™”í•™ ê²°í•©ì„ í˜•ì„±í•©ë‹ˆë‹¤. ì´ëŠ” ë²„ì¼ˆë¥¨ì´ ì´ì „ì— ìƒê°í–ˆë˜ ê²ƒê³¼ëŠ” ë‹¤ë¥´ê²Œ, íŠ¹íˆ +4ì˜ ì•ˆì •ì ì¸ ì–‘ì „í•˜ë¥¼ ê°€ì§€ê³  í–‰ë™í•œë‹¤ëŠ” ê²ƒì„ ì‹œì‚¬í•©ë‹ˆë‹¤.\n\nì´ ë°œê²¬ì€ ë°©ì‚¬ì„± ì›ì†Œì¸ ì•…í‹°ëŠ„ì˜ í™”í•™ì„ ì´í•´í•˜ëŠ” ëª¨ë¸ì„ ê°œì„ í•˜ëŠ” ë° ë„ì›€ì´ ë  ìˆ˜ ìˆìœ¼ë©°, ì´ëŠ” í•µ íê¸°ë¬¼ ê´€ë¦¬ì— ì¤‘ìš”í•©ë‹ˆë‹¤. ì—°êµ¬íŒ€ì˜ ì‘ì—…ì€ ë¯¸êµ­ ì—ë„ˆì§€ë¶€ì˜ ì§€ì›ì„ ë°›ì•˜ìŠµë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "7bd15553d47fa6e5",
    "title": {
      "en": "Todo.txt",
      "ko": "íˆ¬ë‘.txt",
      "ja": null
    },
    "type": "story",
    "url": "https://github.com/todotxt/todo.txt",
    "score": 9,
    "by": "1sembiyan",
    "time": 1743179110,
    "content": "todo.txt format\n\nA complete primer on the whys and hows of todo.txt.\nThe first and most important rule of todo.txt:\n\nA single line in your todo.txt text file represents a single task.\n\nWhy plain text?\nPlain text is software and operating system agnostic. It's searchable, portable, lightweight, and easily manipulated. It's unstructured. It works when someone else's web server is down or your Outlook .PST file is corrupt. There's no exporting and importing, no databases or tags or flags or stars or prioritizing or insert company name here-induced rules on what you can and can't do with it.\nThe 3 axes of an effective todo list\nUsing special notation in todo.txt, you can create a list that's sliceable by 3 key axes.\nPriority\nYour todo list should be able to tell you what's the next most important thing for you to get done - either by project or by context or overall. You can optionally assign tasks a priority that'll bubble them up to the top of the list.\nProject\nThe only way to move a big project forward is to tackle a small subtask associated with it. Your todo.txt should be able to list out all the tasks specific to a project.\nIn order to move along a project like \"Cleaning out the garage,\" my task list should give me the next logical action to take in order to move that project along. \"Clean out the garage\" isn't a good todo item; but \"Call Goodwill to schedule pickup\" in the \"Clean out garage\" project is.\nContext\nGetting Things Done author David Allen suggests splitting up your task lists by context - ie, the place and situation where you'll work on the job. Messages that you need to send go in the @email context; calls to be made @phone, household projects @home.\nThat way, when you've got a few minutes in the car with your cell phone, you can easily check your @phone tasks and make a call or two while you have the opportunity.\nThis is all possible inside todo.txt.\ntodo.txt format rules\n\nYour todo.txt is a plain text file. To take advantage of structured task metadata like priority, projects, context, creation, and completion date, there are a few simple but flexible file format rules.\nPhilosophically, the todo.txt file format has two goals:\n\nThe file contents should be human-readable without requiring any tools other than a plain text viewer or editor.\nA user can manipulate the file contents in a plain text editor in sensible, expected ways. For example, a text editor that can sort lines alphabetically should be able to sort your task list in a meaningful way.\n\nThese two goals are why, for example, lines start with priority and/or dates, so that they are easily sorted by priority or time, and completed items are marked with an x, which both sorts at the bottom of an alphabetical list and looks like a filled-in checkbox.\nHere are the rest.\nIncomplete Tasks: 3 Format Rules\nThe beauty of todo.txt is that it's completely unstructured; the fields you can attach to each task are only limited by your imagination. To get started, use special notation to indicate task context (e.g. @phone ), project (e.g. +GarageSale ) and priority (e.g. (A) ).\nA todo.txt file might look like the following:\n(A) Thank Mom for the meatballs @phone\n(B) Schedule Goodwill pickup +GarageSale @phone\nPost signs around the neighborhood +GarageSale\n@GroceryStore pies\n\nA search and filter for the @phone contextual items would output:\n(A) Thank Mom for the meatballs @phone\n(B) Schedule Goodwill pickup +GarageSale @phone\n\nTo just see the +GarageSale project items would output:\n(B) Schedule Goodwill pickup +GarageSale @phone\nPost signs around the neighborhood +GarageSale\n\nThere are three formatting rules for current todo's.\nRule 1: If priority exists, it ALWAYS appears first.\nThe priority is an uppercase character from A-Z enclosed in parentheses and followed by a space.\nThis task has a priority:\n(A) Call Mom\n\nThese tasks do not have any priorities:\nReally gotta call Mom (A) @phone @someday\n(b) Get back to the boss\n(B)->Submit TPS report\n\nRule 2: A task's creation date may optionally appear directly after priority and a space.\nIf there is no priority, the creation date appears first. If the creation date exists, it should be in the format YYYY-MM-DD.\nThese tasks have creation dates:\n2011-03-02 Document +TodoTxt task format\n(A) 2011-03-02 Call Mom\n\nThis task doesn't have a creation date:\n(A) Call Mom 2011-03-02\n\nRule 3: Contexts and Projects may appear anywhere in the line after priority/prepended date.\n\nA context is preceded by a single space and an at-sign (@).\nA project is preceded by a single space and a plus-sign (+).\nA project or context contains any non-whitespace character.\nA task may have zero, one, or more than one projects and contexts included in it.\n\nFor example, this task is part of the +Family and +PeaceLoveAndHappiness projects as well as the @iphone and @phone contexts:\n(A) Call Mom +Family +PeaceLoveAndHappiness @iphone @phone\n\nThis task has no contexts in it:\nEmail SoAndSo at soandso@example.com\n\nThis task has no projects in it:\nLearn how to add 2+2\n\nComplete Tasks: 2 Format Rules\nTwo things indicate that a task has been completed.\nRule 1: A completed task starts with an lowercase x character (x).\nIf a task starts with an x (case-sensitive and lowercase) followed directly by a space, it is marked as complete.\nThis is a complete task:\nx 2011-03-03 Call Mom\n\nThese are not complete tasks.\nxylophone lesson\nX 2012-01-01 Make resolutions\n(A) x Find ticket prices\n\nWe use a lowercase x so that completed tasks sort to the bottom of the task list using standard sort tools.\nRule 2: The date of completion appears directly after the x, separated by a space.\nFor example:\nx 2011-03-02 2011-03-01 Review Tim's pull request +TodoTxtTouch @github\n\nIf youâ€™ve prepended the creation date to your task, on completion it will appear directly after the completion date. This is so your completed tasks sort by date using standard sort tools. Many Todo.txt clients discard priority on task completion. To preserve it, use the key:value format described below (e.g. pri:A)\nWith the completed date (required), if you've used the prepended date (optional), you can calculate how many days it took to complete a task.\nAdditional File Format Definitions\nTool developers may define additional formatting rules for extra metadata.\nDevelopers should use the format key:value to define additional metadata (e.g. due:2010-01-02 as a due date).\nBoth key and value must consist of non-whitespace characters, which are not colons. Only one colon separates the key and value.",
    "summary": {
      "en": "**Summary of todo.txt Format**\n\nThe todo.txt format is a simple way to manage tasks using a plain text file. Here are the key points:\n\n1. **Basic Principle**: Each line in the todo.txt file represents one task.\n\n2. **Why Use Plain Text?**: \n   - It's compatible with any software and operating system.\n   - It's easy to search, portable, and lightweight.\n   - No need for complex features like databases or tags.\n\n3. **Three Key Axes for an Effective Todo List**:\n   - **Priority**: Assign priorities to tasks to identify whatâ€™s most important.\n   - **Project**: Break down large projects into smaller, actionable tasks.\n   - **Context**: Organize tasks by context (e.g., @phone for calls, @home for household tasks) to make it easier to find what you can do in different situations.\n\n4. **Formatting Rules**:\n   - Tasks can include priority (e.g., (A)), creation date (YYYY-MM-DD), contexts (e.g., @phone), and projects (e.g., +GarageSale).\n   - Completed tasks start with a lowercase 'x' followed by the completion date.\n\n5. **Examples**:\n   - A task with priority and context: (A) Call Mom @phone\n   - A completed task: x 2023-10-01 Review report\n\nThis format allows for easy organization and manipulation of tasks while keeping everything human-readable.",
      "ko": "todo.txt í˜•ì‹ì€ ì¼ë°˜ í…ìŠ¤íŠ¸ íŒŒì¼ì„ ì‚¬ìš©í•˜ì—¬ ì‘ì—…ì„ ê´€ë¦¬í•˜ëŠ” ê°„ë‹¨í•œ ë°©ë²•ì…ë‹ˆë‹¤. ì´ í˜•ì‹ì˜ ì£¼ìš” ë‚´ìš©ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n\nê¸°ë³¸ ì›ì¹™ì€ todo.txt íŒŒì¼ì˜ ê° ì¤„ì´ í•˜ë‚˜ì˜ ì‘ì—…ì„ ë‚˜íƒ€ë‚¸ë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤. ì¼ë°˜ í…ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•˜ëŠ” ì´ìœ ëŠ” ì—¬ëŸ¬ ê°€ì§€ê°€ ìˆìŠµë‹ˆë‹¤. ëª¨ë“  ì†Œí”„íŠ¸ì›¨ì–´ì™€ ìš´ì˜ ì²´ì œì™€ í˜¸í™˜ë˜ë©°, ê²€ìƒ‰ì´ ìš©ì´í•˜ê³  íœ´ëŒ€ì„±ì´ ë›°ì–´ë‚˜ë©° ê°€ë³ìŠµë‹ˆë‹¤. ë°ì´í„°ë² ì´ìŠ¤ë‚˜ íƒœê·¸ì™€ ê°™ì€ ë³µì¡í•œ ê¸°ëŠ¥ì´ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n\níš¨ê³¼ì ì¸ í•  ì¼ ëª©ë¡ì„ ìœ„í•´ ì„¸ ê°€ì§€ ì£¼ìš” ì¶•ì´ ìˆìŠµë‹ˆë‹¤. ì²«ì§¸, ìš°ì„ ìˆœìœ„ì…ë‹ˆë‹¤. ì‘ì—…ì— ìš°ì„ ìˆœìœ„ë¥¼ ë¶€ì—¬í•˜ì—¬ ê°€ì¥ ì¤‘ìš”í•œ ê²ƒì„ ì‹ë³„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‘˜ì§¸, í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤. í° í”„ë¡œì íŠ¸ë¥¼ ë” ì‘ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ì‘ì—…ìœ¼ë¡œ ë‚˜ëˆŒ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì…‹ì§¸, ë§¥ë½ì…ë‹ˆë‹¤. ì‘ì—…ì„ ë§¥ë½ì— ë”°ë¼ ì •ë¦¬í•˜ì—¬(@ì „í™”ëŠ” ì „í™” ì‘ì—…, @ì§‘ì€ ê°€ì‚¬ ì‘ì—…) ë‹¤ì–‘í•œ ìƒí™©ì—ì„œ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” ì‘ì—…ì„ ì‰½ê²Œ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\ní˜•ì‹ ê·œì¹™ìœ¼ë¡œëŠ” ì‘ì—…ì— ìš°ì„ ìˆœìœ„(ì˜ˆ: (A)), ìƒì„± ë‚ ì§œ(YYYY-MM-DD), ë§¥ë½(ì˜ˆ: @ì „í™”), í”„ë¡œì íŠ¸(ì˜ˆ: +ì°¨ê³  ì„¸ì¼)ë¥¼ í¬í•¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì™„ë£Œëœ ì‘ì—…ì€ ì†Œë¬¸ì 'x'ë¡œ ì‹œì‘í•˜ê³  ì™„ë£Œ ë‚ ì§œê°€ ë’¤ë”°ë¦…ë‹ˆë‹¤.\n\nì˜ˆë¥¼ ë“¤ì–´, ìš°ì„ ìˆœìœ„ì™€ ë§¥ë½ì´ í¬í•¨ëœ ì‘ì—…ì€ (A) ì—„ë§ˆì—ê²Œ ì „í™”í•˜ê¸° @ì „í™”ì…ë‹ˆë‹¤. ì™„ë£Œëœ ì‘ì—…ì˜ ì˜ˆëŠ” x 2023-10-01 ë³´ê³ ì„œ ê²€í† ì…ë‹ˆë‹¤.\n\nì´ í˜•ì‹ì€ ì‘ì—…ì„ ì‰½ê²Œ ì •ë¦¬í•˜ê³  ì¡°ì‘í•  ìˆ˜ ìˆê²Œ í•˜ë©´ì„œë„ ëª¨ë“  ë‚´ìš©ì„ ì‚¬ëŒì´ ì½ê¸° ì‰½ê²Œ ìœ ì§€í•©ë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "a5620036423b6eb7",
    "title": {
      "en": "Blasting Past WebP - An analysis of the NSO BLASTPASS iMessage exploit",
      "ko": "ì›¹Pë¥¼ ë„˜ì–´ì„œ: NSO ë¸”ë˜ìŠ¤íŠ¸íŒ¨ìŠ¤ ë¶„ì„",
      "ja": null
    },
    "type": "story",
    "url": "https://googleprojectzero.blogspot.com/2025/03/blasting-past-webp.html",
    "score": 253,
    "by": "el_duderino",
    "time": 1743079784,
    "content": "Project Zero\n\nNews and updates from the Project Zero team at Google\n\nWednesday, March 26, 2025\n\nBlasting Past Webp\n\n@import url(https://themes.googleusercontent.com/fonts/css?kit=XGMkxXUZTA64h2imyzu79g);.lst-kix_t2u4j4vhkrnm-3>li:before{content:\"\\0025cf   \"}.lst-kix_t2u4j4vhkrnm-0>li:before{content:\"\\0025cf   \"}.lst-kix_t2u4j4vhkrnm-4>li:before{content:\"\\0025cb   \"}.lst-kix_t2u4j4vhkrnm-7>li:before{content:\"\\0025cb   \"}ul.lst-kix_t2u4j4vhkrnm-8{list-style-type:none}ul.lst-kix_t2u4j4vhkrnm-6{list-style-type:none}ul.lst-kix_t2u4j4vhkrnm-7{list-style-type:none}ul.lst-kix_t2u4j4vhkrnm-4{list-style-type:none}.lst-kix_t2u4j4vhkrnm-5>li:before{content:\"\\0025a0   \"}ul.lst-kix_t2u4j4vhkrnm-5{list-style-type:none}li.li-bullet-0:before{margin-left:-18pt;white-space:nowrap;display:inline-block;min-width:18pt}ul.lst-kix_t2u4j4vhkrnm-2{list-style-type:none}.lst-kix_t2u4j4vhkrnm-6>li:before{content:\"\\0025cf   \"}ul.lst-kix_t2u4j4vhkrnm-3{list-style-type:none}ul.lst-kix_t2u4j4vhkrnm-0{list-style-type:none}ul.lst-kix_t2u4j4vhkrnm-1{list-style-type:none}.lst-kix_t2u4j4vhkrnm-8>li:before{content:\"\\0025a0   \"}.lst-kix_t2u4j4vhkrnm-1>li:before{content:\"\\0025cb   \"}.lst-kix_t2u4j4vhkrnm-2>li:before{content:\"\\0025a0   \"}ol{margin:0;padding:0}table td,table th{padding:0}.XQFzMDWmii-c30{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:234pt;border-top-color:#000000;border-bottom-style:solid}.XQFzMDWmii-c36{padding-top:0pt;border-top-width:0pt;padding-bottom:0pt;line-height:1.5;border-top-style:solid;background-color:#ffffff;border-bottom-width:0pt;border-bottom-style:solid;orphans:2;widows:2;text-align:left}.XQFzMDWmii-c40{padding-top:14pt;padding-bottom:4pt;line-height:1.5;page-break-after:avoid;orphans:2;widows:2;text-align:left}.XQFzMDWmii-c0{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:\"Arial\";font-style:normal}.XQFzMDWmii-c22{color:#434343;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:\"Arial\";font-style:normal}.XQFzMDWmii-c35{color:#666666;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:\"Arial\";font-style:normal}.XQFzMDWmii-c18{color:#434343;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:14pt;font-family:\"Arial\";font-style:normal}.XQFzMDWmii-c38{padding-top:0pt;padding-bottom:16pt;line-height:1.5;page-break-after:avoid;orphans:2;widows:2;text-align:left}.XQFzMDWmii-c12{padding-top:16pt;padding-bottom:4pt;line-height:1.5;page-break-after:avoid;orphans:2;widows:2;text-align:left}.XQFzMDWmii-c4{padding-top:0pt;padding-bottom:0pt;line-height:1.5;orphans:2;widows:2;text-align:left}.XQFzMDWmii-c10{color:#000000;text-decoration:none;vertical-align:baseline;font-size:11pt;font-style:normal}.XQFzMDWmii-c29{color:#b80672;text-decoration:none;vertical-align:baseline;font-size:11pt;font-style:normal}.XQFzMDWmii-c11{padding-top:0pt;padding-bottom:0pt;line-height:1.5;text-align:left;margin-right:-72pt}.XQFzMDWmii-c21{color:#000000;vertical-align:baseline;font-size:11pt;font-style:normal}.XQFzMDWmii-c17{color:#000000;text-decoration:none;vertical-align:baseline;font-style:normal}.XQFzMDWmii-c1{font-size:9pt;font-family:\"Roboto Mono\";color:#188038;font-weight:400}.XQFzMDWmii-c42{color:#666666;vertical-align:baseline;font-size:15pt;font-style:normal}.XQFzMDWmii-c45{padding-top:0pt;padding-bottom:0pt;line-height:1.0;text-align:left}.XQFzMDWmii-c3{text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;text-decoration:underline}.XQFzMDWmii-c41{border-spacing:0;border-collapse:collapse;margin-right:auto}.XQFzMDWmii-c37{font-weight:400;text-decoration:none;font-family:\"Arial\"}.XQFzMDWmii-c2{color:#1967d2;font-weight:400;font-family:\"Roboto Mono\"}.XQFzMDWmii-c26{color:#000000;vertical-align:baseline;font-size:11pt}.XQFzMDWmii-c5{color:#37474f;font-weight:400;font-family:\"Roboto Mono\"}.XQFzMDWmii-c39{background-color:#ffffff;max-width:468pt;padding:72pt 72pt 72pt 72pt}.XQFzMDWmii-c13{text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;text-decoration:underline}.XQFzMDWmii-c16{background-color:#00ff00;font-style:italic}.XQFzMDWmii-c9{font-weight:400;font-family:\"Courier New\"}.XQFzMDWmii-c23{font-weight:700;font-family:\"Courier New\"}.XQFzMDWmii-c6{font-weight:400;font-family:\"Roboto Mono\"}.XQFzMDWmii-c19{background-color:#ffff00}.XQFzMDWmii-c32{background-color:#00ff00}.XQFzMDWmii-c15{background-color:#ff9900}.XQFzMDWmii-c24{font-style:italic}.XQFzMDWmii-c25{font-weight:700}.XQFzMDWmii-c20{font-size:10pt}.XQFzMDWmii-c8{font-size:9pt}.XQFzMDWmii-c43{padding-left:0pt}.XQFzMDWmii-c44{color:#c5221f}.XQFzMDWmii-c28{height:0pt}.XQFzMDWmii-c31{background-color:#f4cccc}.XQFzMDWmii-c14{background-color:#ff00ff}.XQFzMDWmii-c34{margin-left:36pt}.XQFzMDWmii-c27{color:#188038}.XQFzMDWmii-c7{height:11pt}.XQFzMDWmii-c33{background-color:#00ffff}.title{padding-top:0pt;color:#000000;font-size:26pt;padding-bottom:3pt;font-family:\"Arial\";line-height:1.5;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:\"Arial\";line-height:1.5;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:\"Arial\"}p{margin:0;color:#000000;font-size:11pt;font-family:\"Arial\"}h1{padding-top:20pt;color:#000000;font-size:20pt;padding-bottom:6pt;font-family:\"Arial\";line-height:1.5;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-size:16pt;padding-bottom:6pt;font-family:\"Arial\";line-height:1.5;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:16pt;color:#434343;font-size:14pt;padding-bottom:4pt;font-family:\"Arial\";line-height:1.5;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#666666;font-size:12pt;padding-bottom:4pt;font-family:\"Arial\";line-height:1.5;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:\"Arial\";line-height:1.5;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:\"Arial\";line-height:1.5;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}\n An analysis of the NSO BLASTPASS iMessage exploit\n Posted by Ian Beer, Google Project Zero\n\n On September 7, 2023 Apple issuedan out-of-band security update for iOS:\n\n Around the same time on September 7th 2023, Citizen Lab published a blog postlinking the two CVEs fixed in iOS 16.6.1 to an \"NSO Group Zero-Click, Zero-Day exploit captured in the wild\":\n\n \"[The target was] an individual employed by a Washington DC-based civil society organization with international offices...\n\n The exploit chain was capable of compromising iPhones running the latest version of iOS (16.6) without any interaction from the victim.\n\n The exploit involved PassKit attachments containing malicious images sent from an attacker iMessage account to the victim.\"\n\n The day before, on September 6th 2023, Apple reported a vulnerability to the WebP project, indicating in the report that they planned to ship a custom fix for Apple customers the next day.\n\n The WebP team posted their first proposed fixin the public git repo the next day, and five days after that on September 12th Google released a new Chrome stable releasecontaining the WebP fix. Both Apple and Google marked the issue as exploited in the wild, alerting other integrators of WebP that they should rapidly integrate the fix as well as causing the security research community to take a closer look...\n\n A couple of weeks later on September 21st 2023, former Project Zero team lead Ben Hawkes (in collaboration with @mistymntncop) published the first detailed writeupof the root cause of the vulnerability on the IsoscelesBlog. A couple of months later, on November 3rd, a group called Dark Navypublished their first blog post: a two-part analysis (Part 1- Part 2) of the WebP vulnerability and a proof-of-concept exploittargeting Chrome (CVE-2023-4863).\n\n Whilst the Isosceles and Dark Navy posts explained the underlying memory corruption vulnerability in great detail, they were unable to solve another fascinating part of the puzzle: just how exactly do you land an exploit for this vulnerability in a one-shot, zero-click setup? As we'll soon see, the corruption primitive is very limited. Without access to the samples it was almost impossible to know.\n\n In mid-November, in collaboration with Amnesty International Security Lab, I was able to obtain a number of BLASTPASS PKPasssample files as well as crash logs from failed exploit attempts.\n\n This blog post covers my analysis of those samples and the journey to figure out how one of NSO's recent zero-click iOS exploits really worked. For me that journey began by immediately taking three months of paternity leave, and resumed in March 2024 where this story begins:Setting the scene\n For a detailed analysis of the root-cause of the WebP vulnerability and the primitive it yields, I recommend first reading the three blog posts I mentioned earlier (Isosceles, Dark Navy 1, Dark Navy 2.) I won't restate their analyses here (both because you should read their original work, and because it's quite complicated!) Instead I'll briefly discuss WebP and the corruption",
    "summary": {
      "en": "**Project Zero Update - March 26, 2025**\n\nThis update discusses a significant iMessage exploit linked to NSO Group, discovered in September 2023. Key points include:\n\n- **Exploit Details**: A zero-click exploit compromised iPhones running the latest iOS (16.6) without user interaction, using malicious images sent via iMessage.\n  \n- **Apple's Response**: On September 7, 2023, Apple released a security update to address vulnerabilities in iOS, which were exploited in the wild.\n\n- **WebP Vulnerability**: Around the same time, a vulnerability in the WebP image format was identified. Apple and Google quickly developed and released fixes, highlighting the urgency of the issue.\n\n- **Research Collaboration**: The Project Zero team, in collaboration with Amnesty International, analyzed exploit samples and crash logs to understand the mechanics of NSO's zero-click exploit.\n\n- **Further Reading**: The post encourages readers to consult previous analyses from Isosceles and Dark Navy for detailed technical insights into the WebP vulnerability.\n\nThis summary captures the essence of the findings and ongoing research surrounding the exploit and vulnerabilities affecting iOS and WebP.",
      "ko": "2025ë…„ 3ì›” 26ì¼ í”„ë¡œì íŠ¸ ì œë¡œ ì—…ë°ì´íŠ¸ì—ì„œëŠ” 2023ë…„ 9ì›”ì— ë°œê²¬ëœ NSO ê·¸ë£¹ê³¼ ê´€ë ¨ëœ ì¤‘ìš”í•œ iMessage ì·¨ì•½ì ì— ëŒ€í•´ ë‹¤ë£¨ê³  ìˆìŠµë‹ˆë‹¤. ì£¼ìš” ë‚´ìš©ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n\nì´ ì·¨ì•½ì ì€ ì‚¬ìš©ìì˜ ìƒí˜¸ì‘ìš© ì—†ì´ë„ ìµœì‹  iOS(16.6)ë¥¼ ì‹¤í–‰í•˜ëŠ” ì•„ì´í°ì„ ê°ì—¼ì‹œí‚¬ ìˆ˜ ìˆëŠ” ì œë¡œ í´ë¦­ ì·¨ì•½ì ìœ¼ë¡œ, ì•…ì„± ì´ë¯¸ì§€ë¥¼ iMessageë¥¼ í†µí•´ ì „ì†¡í•˜ì—¬ ë°œìƒí•©ë‹ˆë‹¤. \n\nì• í”Œì€ 2023ë…„ 9ì›” 7ì¼, ì´ëŸ¬í•œ ì·¨ì•½ì ì„ í•´ê²°í•˜ê¸° ìœ„í•œ ë³´ì•ˆ ì—…ë°ì´íŠ¸ë¥¼ ë°œí‘œí–ˆìŠµë‹ˆë‹¤. ì´ ì—…ë°ì´íŠ¸ëŠ” ì‹¤ì œë¡œ ì•…ìš©ë˜ê³  ìˆëŠ” ì·¨ì•½ì ì„ ìˆ˜ì •í•˜ê¸° ìœ„í•œ ê²ƒì´ì—ˆìŠµë‹ˆë‹¤.\n\nê°™ì€ ì‹œê¸°ì— WebP ì´ë¯¸ì§€ í¬ë§·ì—ì„œë„ ì·¨ì•½ì ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. ì• í”Œê³¼ êµ¬ê¸€ì€ ì‹ ì†í•˜ê²Œ ìˆ˜ì • ì‘ì—…ì„ ì§„í–‰í•˜ì—¬ ë¬¸ì œë¥¼ í•´ê²°í–ˆìŠµë‹ˆë‹¤. ì´ëŠ” ë¬¸ì œì˜ ê¸´ê¸‰ì„±ì„ ì˜ ë³´ì—¬ì¤ë‹ˆë‹¤.\n\ní”„ë¡œì íŠ¸ ì œë¡œ íŒ€ì€ êµ­ì œì•°ë„¤ìŠ¤í‹°ì™€ í˜‘ë ¥í•˜ì—¬ NSOì˜ ì œë¡œ í´ë¦­ ì·¨ì•½ì ì˜ ì‘ë™ ë°©ì‹ì„ ì´í•´í•˜ê¸° ìœ„í•´ ì·¨ì•½ì  ìƒ˜í”Œê³¼ í¬ë˜ì‹œ ë¡œê·¸ë¥¼ ë¶„ì„í–ˆìŠµë‹ˆë‹¤.\n\në…ìë“¤ì€ WebP ì·¨ì•½ì ì— ëŒ€í•œ ìì„¸í•œ ê¸°ìˆ ì  í†µì°°ì„ ì›í•œë‹¤ë©´ Isoscelesì™€ Dark Navyì˜ ì´ì „ ë¶„ì„ì„ ì°¸ê³ í•  ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤. ì´ ìš”ì•½ì€ iOSì™€ WebPì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ì·¨ì•½ì  ë° ê´€ë ¨ ì—°êµ¬ì˜ í•µì‹¬ ë‚´ìš©ì„ ë‹´ê³  ìˆìŠµë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "0da8cdfb63befb78",
    "title": {
      "en": "OpenAI adds MCP support to Agents SDK",
      "ko": "OpenAI, ì—ì´ì „íŠ¸ SDKì— MCP ì§€ì› ì¶”ê°€",
      "ja": null
    },
    "type": "story",
    "url": "https://openai.github.io/openai-agents-python/mcp/",
    "score": 786,
    "by": "gronky_",
    "time": 1743015329,
    "content": "Model context protocol (MCP)\nThe Model context protocol (aka MCP) is a way to provide tools and context to the LLM. From the MCP docs:\n\nMCP is an open protocol that standardizes how applications provide context to LLMs. Think of MCP like a USB-C port for AI applications. Just as USB-C provides a standardized way to connect your devices to various peripherals and accessories, MCP provides a standardized way to connect AI models to different data sources and tools.\n\nThe Agents SDK has support for MCP. This enables you to use a wide range of MCP servers to provide tools to your Agents.\nMCP servers\nCurrently, the MCP spec defines two kinds of servers, based on the transport mechanism they use:\n\nstdio servers run as a subprocess of your application. You can think of them as running \"locally\".\nHTTP over SSE servers run remotely. You connect to them via a URL.\n\nYou can use the MCPServerStdio and MCPServerSse classes to connect to these servers.\nFor example, this is how you'd use the official MCP filesystem server.\nasync with MCPServerStdio(\n    params={\n        \"command\": \"npx\",\n        \"args\": [\"-y\", \"@modelcontextprotocol/server-filesystem\", samples_dir],\n    }\n) as server:\n    tools = await server.list_tools()\n\nUsing MCP servers\nMCP servers can be added to Agents. The Agents SDK will call list_tools() on the MCP servers each time the Agent is run. This makes the LLM aware of the MCP server's tools. When the LLM calls a tool from an MCP server, the SDK calls call_tool() on that server.\nagent=Agent(\n    name=\"Assistant\",\n    instructions=\"Use the tools to achieve the task\",\n    mcp_servers=[mcp_server_1, mcp_server_2]\n)\n\nCaching\nEvery time an Agent runs, it calls list_tools() on the MCP server. This can be a latency hit, especially if the server is a remote server. To automatically cache the list of tools, you can pass cache_tools_list=True to both MCPServerStdio and MCPServerSse. You should only do this if you're certain the tool list will not change.\nIf you want to invalidate the cache, you can call invalidate_tools_cache() on the servers.\nEnd-to-end examples\nView complete working examples at examples/mcp.\nTracing\nTracing automatically captures MCP operations, including:\n\nCalls to the MCP server to list tools\nMCP-related info on function calls",
    "summary": {
      "en": "**Summary of Model Context Protocol (MCP)**\n\nThe Model Context Protocol (MCP) is a standardized way to connect AI applications with tools and data sources, similar to how a USB-C port connects devices. \n\n### Key Points:\n\n- **Purpose**: MCP provides a framework for applications to provide context to large language models (LLMs).\n- **Server Types**:\n  - **Stdio Servers**: Run locally as a subprocess.\n  - **HTTP over SSE Servers**: Operate remotely and are accessed via a URL.\n  \n- **Using MCP with Agents**: The Agents SDK can connect to MCP servers, allowing LLMs to utilize tools available on these servers. Each time an agent runs, it retrieves the list of tools from the MCP servers.\n\n- **Caching**: To reduce delays when accessing remote servers, you can enable caching of the tool list. If the tools change, you can invalidate the cache.\n\n- **Tracing**: MCP includes features to automatically track operations, like listing tools and function calls.\n\nFor detailed examples of how to use MCP, you can refer to the provided examples directory.",
      "ko": "ëª¨ë¸ ì»¨í…ìŠ¤íŠ¸ í”„ë¡œí† ì½œ(MCP)ì€ AI ì• í”Œë¦¬ì¼€ì´ì…˜ê³¼ ë„êµ¬, ë°ì´í„° ì†ŒìŠ¤ë¥¼ ì—°ê²°í•˜ëŠ” í‘œì¤€í™”ëœ ë°©ë²•ì…ë‹ˆë‹¤. ì´ëŠ” USB-C í¬íŠ¸ê°€ ì¥ì¹˜ë¥¼ ì—°ê²°í•˜ëŠ” ë°©ì‹ê³¼ ìœ ì‚¬í•©ë‹ˆë‹¤.\n\nMCPì˜ ì£¼ìš” ëª©ì ì€ ì• í”Œë¦¬ì¼€ì´ì…˜ì´ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì— ë§¥ë½ì„ ì œê³µí•  ìˆ˜ ìˆëŠ” í”„ë ˆì„ì›Œí¬ë¥¼ ì œê³µí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì„œë²„ ìœ í˜•ìœ¼ë¡œëŠ” ë‘ ê°€ì§€ê°€ ìˆìŠµë‹ˆë‹¤. ì²« ë²ˆì§¸ëŠ” ë¡œì»¬ì—ì„œ ì„œë¸Œí”„ë¡œì„¸ìŠ¤ë¡œ ì‹¤í–‰ë˜ëŠ” ìŠ¤íƒ ë‹¤ë“œ ì…ë ¥ ì¶œë ¥(Stdio) ì„œë²„ì…ë‹ˆë‹¤. ë‘ ë²ˆì§¸ëŠ” ì›ê²©ìœ¼ë¡œ ìš´ì˜ë˜ë©° URLì„ í†µí•´ ì ‘ê·¼í•˜ëŠ” HTTP over SSE ì„œë²„ì…ë‹ˆë‹¤.\n\nMCPë¥¼ ì—ì´ì „íŠ¸ì™€ í•¨ê»˜ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì—ì´ì „íŠ¸ SDKëŠ” MCP ì„œë²„ì— ì—°ê²°í•˜ì—¬ LLMì´ í•´ë‹¹ ì„œë²„ì—ì„œ ì œê³µí•˜ëŠ” ë„êµ¬ë¥¼ í™œìš©í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤. ì—ì´ì „íŠ¸ê°€ ì‹¤í–‰ë  ë•Œë§ˆë‹¤ MCP ì„œë²„ì—ì„œ ë„êµ¬ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.\n\nì›ê²© ì„œë²„ì— ì ‘ê·¼í•  ë•Œ ì§€ì—°ì„ ì¤„ì´ê¸° ìœ„í•´ ë„êµ¬ ëª©ë¡ì˜ ìºì‹±ì„ í™œì„±í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë„êµ¬ê°€ ë³€ê²½ë˜ë©´ ìºì‹œë¥¼ ë¬´íš¨í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nMCPëŠ” ë„êµ¬ ëª©ë¡ê³¼ í•¨ìˆ˜ í˜¸ì¶œê³¼ ê°™ì€ ì‘ì—…ì„ ìë™ìœ¼ë¡œ ì¶”ì í•˜ëŠ” ê¸°ëŠ¥ë„ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤. MCP ì‚¬ìš©ì— ëŒ€í•œ ìì„¸í•œ ì˜ˆì‹œëŠ” ì œê³µëœ ì˜ˆì œ ë””ë ‰í† ë¦¬ë¥¼ ì°¸ì¡°í•˜ë©´ ë©ë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "00fa45d791273b04",
    "title": {
      "en": "The Hole Story: How Woodpeckers Make Homes for the Rest of the Forest",
      "ko": "ë”±ë”°êµ¬ë¦¬ì˜ ì§‘ì§“ê¸° ë¹„ë°€",
      "ja": null
    },
    "type": "story",
    "url": "https://www.allaboutbirds.org/news/hole-story-how-woodpeckers-make-homes-forest/",
    "score": 3,
    "by": "hn_acker",
    "time": 1743183144,
    "content": "The Hole Story: How Woodpeckers Make Homes for the Rest of the Forest\n              Woodpecker nest holes are valuable pieces of real estate that may be used by hundreds of other species over many years. Researchers are using the concept of \"nest webs\" to understand how this valuable resource passes from one owner to the next.By Marc DevokaitisMarch 24, 2025\n\n        Northern Flicker by Michael Quinton / Minden Pictures.\n\n                            Share:\n\n          Woodpecker nest holes are valuable pieces of real estate that may be used by hundreds of other species over many years. Researchers are using the concept of \"nest webs\" to understand how this valuable resource passes from one owner to the next.\n      More From Living BirdLiving Bird Spring 2025â€”Table Of ContentsLiving Bird Magazineâ€”Latest IssueLiving Bird Magazine Archives\n\nFrom theSpring 2025 issueofLiving Birdmagazine.Subscribe now.\n\nWhen night falls in the forest, most birds tuck into nooks where they can feel secureâ€”the V-shaped intersection of two tree boughs, a cluster of dense branches. Some may take to the eaves of nearby houses. Brown Creepers find a piece of shaggy bark to wedge their bodies under.\n\nAnd many birdsâ€”sometimes more than half the species in a given woodlandâ€”stow themselves safely into a place we humans rarely (and barely) get to see: inside the hole of a tree.\n\nWhether itâ€™s a fragment of forest bordering an urban neighborhood, or an old-growth stand thatâ€™s been regenerating itself for millennia, tree cavities are a common and crucial part of habitat in every forest landscape.\n\nWhen it comes to a cozy home, few places can deliver like a tree cavity, says Kevin McGowan, instructor for the Cornell Lab of Ornithology Bird Academy course The Wonderful World of Woodpeckers. McGowan says a big part of recognizing the contribution of woodpeckers to an ecosystem begins with understanding the value of a hole.\n\nWoodpecker Anatomy3 Reasons Why Woodpeckers Are Great Excavators\n\nâ€œHoles in trees make great homes for all kinds of animals,â€ says McGowan. â€œTheyâ€™re off of the ground, easier to defend from predators, they stay dry when it rains. It makes them a perfect place to roost and to raise young.â€\n\nA study published in the journal Diversity and Distributions in 2017 found that nearly 20% of all bird species around the world rely on tree cavities for roosting or nesting, and a subsequent analysis found that there are some areas of the world where nearly all cavities occupied by birds are made by woodpeckers.\n\nIn North America in particular, scientists are finding that the nest holes excavated within trees offer critical safe harbors used by dozens of species of birds, mammals, reptiles, and insectsâ€”all thanks to a few VIPs : Very Important (Wood)Peckers.\n\nNorthern Saw-whet Owls often nest in unused woodpecker holes. Photo by Celine Bellemare / Macaulay Library.\n\nFlicker Nests Have Widespread Appeal\n\nKathy Martin began studying woodpeckers and other cavity-nesting species in the mid-1990s, when she was a newly minted professor of forest science at the University of British Columbia. She had an idea that woodpeckers would have stories to tell about the health of forest ecosystems, and their ability to stay healthy in the face of timber harvests, at a time when logging interests were sizing up British Columbiaâ€™s vast interior forests.\n\nNorthern Flicker by Michael Quinton / Minden Pictures.\n\nThirty years ago â€œthere was a true environmental feeling in the industry,â€ Martin says. â€œ[Timber] companies were interested in having ecologists weigh in on the management of their landsâ€”people who would tell the real story and not just say that everything is fine.â€\n\nWoodpeckers were a logical group to study, she says: â€œThe woodpeckers were â€¦ the ones that you would predict would be very sensitive to this kind of harvest,â€ including the selective logging of mature trees for the forest industry.\n\nOver the first two years of studying the biological communities in these mixed Douglas-fir forests in western Canada, Martin and her research team recorded 32 bird species that used tree cavities, including primary excavators like woodpeckers, which can drill into a variety of tree types in different stages of decay; weaker excavators like chickadees and nuthatches, which can only excavate when the wood is already rotting; and a bevy of secondary cavity nesters, which are birds that use preexisting cavities but donâ€™t excavate their own. The last group includes a range of species from Wood Ducks to Northern House Wrens. More broadly, Martinestimates that around 30% of all forest bird species in North America use tree cavities at some point of their life cycle, whether nesting, hiding from predators, or just finding a warm roosting place to snuggle in on a cold winterâ€™s night.\n\nMartin and her team also recorded cavity use by 11 species of mammals, from red squirrels to pine martens to fishers. In 1999 their study, published in The Condor, introduced the concept of a nest webâ€”a way to describe the complex system of animals that make, enhance, and/or use tree cavities.\n\nâ€œIt was based on the idea of the food webâ€”you have all these species that are linked together because they are sharing the same resources,â€ says Martin, â€œand just like in food webs you have your producers and your consumers.â€\n\nWood Duck by Seth Honig / Macaulay Library.\n\nMountain Bluebird by Aidan Brubaker / Macaulay Library.\n\nAmerican red squirrel courtesy of Adobe Stock.\n\nAmerican Kestrel by David Olsen / Macaulay Library.\nSecondary Cavity Nesters: Dozens of species of North American birds and mammals nest or shelter in tree cavities, but donâ€™t have the ability to excavate for themselves. In some forests these secondary cavity nesters rely on woodpeckers to carve out the holes they need for breeding and survival.\n\nIn the forests Martin studiesâ€”mixed Douglas-fir, which includes pine and spruce along with aspen, poplar, and birch treesâ€”the most important producer turned out to be Northern Flicker, which excavated nearly 50% of tree cavities observed. According to a recent estimate from the bird-monitoring alliance Partners in Flight, Northern Flicker is one of the most abundant woodpeckers in North America. PIF estimates there are about 12 million flickers across Canada, the U.S., and Mexico.\n\nâ€œI do think the flickers are so important because they have such a high abundance,â€ says Martin, â€œbut itâ€™s more than that.â€ Aside from making more holes than any other woodpeckers, Martin says they make a hole thatâ€™s big enough for many different species, but not so big that the entrance hole feels unsafe.\n\nAccording to Martinâ€™s research, flicker cavities emerged as the most important nesting resource for songbirds such as Mountain Bluebirds, raptors such as American Kestrels, and waterfowl such as Buffleheads and Hooded Mergansers. Some bird species even evict flickers from their cavity nests.\n\nâ€œ[Flickers] are kind of wimps,â€ Martin says. â€œThey donâ€™t defend their cavities very well,â€ which means their nest holes are often commandeered by more aggressive birds like kestrels and starlings.\n\nNorthern House Wren by Bob Bowhay / Macaulay Library.\n\nBlack-capped Chickadee by Matt Saunders / Macaulay Library.\n\nEastern Screech-Owls by Kyle Tansley / Macaulay Library.\n\nImportantly, only around 10% of the cavities Martin and her team found were so-called natural cavitiesâ€”that is, cavities not started by an excavator, such as a hole in a tree at a broken bough caused by wind or ice, then rotted out by bacteria or fungi.\n\nBut, Martin says, â€œa lot of these natural decay cavities that form in older trees and snags are crappy cavities â€¦ not as secure, not deep enoughâ€ for safe bird nests.\n\nIn other parts of the world, natural cavities that form without the aid of woodpeckers play a much larger role in forests. A study published in Biodiversity and Conservation in 2017 found that in temperate rainforests in Chile, 75% of nests used by secondary cavity nestersâ€”birds such as Blue-and-White Swallow and the Patagonian Sierra Finch that donâ€™t drill their own cavitiesâ€”were located in holes caused by tree decay. The other 25% of nests were in holes excavated by primary-cavity producers such as Magellanic Woodpecker and White-throated Treerunner, a nuthatch-like species.\n\nThat pattern holds true for most places outside of North America where nest webs have been studied. According to an analysis published in Frontiers in Ecology and Evolution in 2011, avian excavators (mostly woodpeckers) produced around 77% of nesting cavities in North America, but only an average of 26% across Europe and South America, and 0% in Australasia (where woodpeckers do not occur).\n\nKristina Cockle, lead author of the study, explains the discrepancy is in part due to the difference in tree structures around the world. She says that in much of the world, forests are dominated by broadleaf trees with huge branches: â€œWhen a large branch breaks off â€¦ it has good potential to create an entrance to the already-decayed heartwood inside the tree.â€\n\nIn the areas of North America and northern Europe where these kinds of studies have been done, however, â€œtrees tend to have a single main stem, with small branches that self-prune,â€ she says. When weather events knock branches off this type of tree, it doesnâ€™t tend to expose the heartwood and the tree can quickly heal the woundâ€”which means fewer opportunities for the formation of sizable natural tree cavities.\n\nWoodpecker Nest Webs. Nest webs show the relationships between nest-site producers (cavity excavators, especially woodpeckers) and consumers (the many other birds and mammals that use them). The dark gray arrows in this illustration of a western Canada forest point from cavity producers to cavity consumers. For example, Northern Flicker holes are a main source of cavities for Mountain Bluebirds, American Kestrels, and Buffleheads. The white arrows show additional food-web relationships that can stem from the relationships in this nest web. Species, left to right: Northern Flicker, Mountain Chickadee, Bufflehead, Northern Saw-whet Owl, red squirrel, short-tailed weasel, woodrat, female Mountain Bluebird, deer mouse, Northern Flicker (flying), Pileated Woodpecker, male Mountain Bluebird, American Kestrel, Barrowâ€™s Goldeneye. Illustration by Bartels Illustrator Lauren Richelieu.\n\nA Front-Row Seat\n\nVirginia Tech researcher Jeff Walters has had a front-row seat to watching Very Important Woodpeckers in a forest ecosystem for more than three decades.\n\nSpecifically heâ€™s gotten familiar with the haunts and habits of the Red-cockaded Woodpecker, an iconic bird protected under the Endangered Species Act that makes its living in the longleaf pine forests that dot the landscape from Virginia to Texas. As important as woodpeckers are in the forests of western Canada, the woodpeckers of the longleaf pine forests are absolutely vital, according to Waltersâ€™s research. In a study published in The Condor in 2008, Walters and Virginia Tech PhD student Lori Blanc found that almost every single tree cavity used by birds and other creatures within a longleaf pine nest-web community in northern Florida originated with a woodpeckerâ€”432 out of 433 cavities.\n\n        hbspt.cta.load(95627, '096b8ce3-0e2d-46c5-bbf7-12de3323c8da', {});\n\nIn conifer systems, Walters says, there is â€œmore dependence on excavated cavities from woodpeckers compared to hardwood or tropical forests. Pine trees just donâ€™t produce a lot of â€¦ natural holes on their own.â€ Pines also produce resin that may help protect their wood from infection following injury.\n\nAdditionally, he says that longleaf pine systems were clear-cut around the turn of the 20th century, so there are a limited number of older, decaying trees and tree snagsâ€”places that have soft spots where woodpeckers usually drill holes. Luckily the Red-cockaded Woodpecker has a secret superpower that enables it to provide cavities in a way that most other woodpeckers canâ€™t; they drill into live trees.\n\nâ€œRed-cockaded Woodpeckers add an additional resource beyond the holes in dead pines, which is often where most of the action is in nest webs in conifer forests,â€ says Walters.\n\nDrilling into a live tree is anything but easy. Most woodpeckers in North America can finish a nest cavity in a matter of weeks, or maybe a couple months. The average Red-cockaded Woodpecker, on the other hand, takes years, sometimes up to a decade or more, to excavate a cavity in a live tree. Thatâ€™s because chiseling away at live wood is difficult, due to the dense sapwood layer under the bark that allows the tree to transport nutrients from the roots to the leaves.\n\nAs one of the few North American woodpeckers that can excavate in live trees, Red-cockaded Woodpeckers are a key source of nesting cavities in the longleaf pine forests of the Southeast. Red-cockaded Woodpecker by Martina Nordstrand / Macaulay Library.\n\nRed-cockadeds prefer trees where the sapwood is healthy for a single reason, says Walters: â€œResin wells.â€\n\nâ€œIf you ever see a picture of a Red-cockaded Woodpecker cavity thatâ€™s being actively used, youâ€™ll see all this sap all around it,â€ he says. The sappy coating around the nest holes creates a barrier of protection against would-be predators. â€œSnakes canâ€™t get through the sap.â€\n\nWaltersâ€™s research also shows that flickers again play an important role in longleaf pine nest webs, but often they rely on Red-cockaded Woodpeckers to get things started. Red-cockaded Woodpeckers and Northern Flickers excavated the most cavities (about 50%) that were used by other cavity-nesting birds, and flickers were also the primary enlargers of holes started by red-cockadeds that eventually housed some of the largest cavity-dwellers in longleaf pine forestsâ€”American Kestrels and Eastern Screech-Owls.\n\nRelated StoriesBringing Back the Red-cockaded Woodpecker: Are Prescribed Fire and Artificial Nests Enough?\n\nThereâ€™s another, less visible, group of players in the longleaf pine nest web. Michelle Jusino began studying Red-cockaded Woodpeckers under Jeff Walters as a PhD student in the early 2010s and quickly became interested in a different denizen of tree cavities: fungi.\n\nâ€œThese birds have long been thought to have an association with one particular fungus [called Porodaedalea pini] because that fungus causes heartrot,â€ says Jusino. But she says that the scientific knowledge of that association was based on anecdotal observation. â€œSometimes when we see woodpecker holes, we see this fungus on the tree.â€\n\nSo for her dissertation, Jusino designed a study to find out exactly what fungi are present in woodpecker cavities, and how they get there. She and her team of researchers drilled fresh holes into living longleaf pine trees and put galvanized steel screens over some of the holes to keep out Red-cockaded Woodpeckers. The other holes were left open for red-cockadeds to access.\n\nHer results, published in Proceedings of the Royal Society B in 2016, found that both sets of holes contained fungal communities that werenâ€™t present at first, but that those communities were very different from each other. The holes accessed by Red-cockaded Woodpeckers developed clusters of dozens of different fungi that were very similar to the fungal communities found in natural red-cockaded excavations.\n\nâ€œThese birds are helping facilitate these fungal colonizations, first by making holes, and then by transporting [the fungus] from one tree to another,â€ says Jusino. â€œWhat that study didnâ€™t prove was whether that fungus is really helping the bird in return.â€\n\nWhile Red-cockaded Woodpeckers overwhelmingly prefer live trees with healthy sapwood, Jusino says they seem to have a preference for trees where the heartwood is beginning to decay. But the question remains: How are these woodpeckers identifying such trees when there is usually no evidence on the outside? Jusino isnâ€™t sure if red-cockadeds are sensing the rotting heartwood and accompanying fungi through smell, feel, or some other cuesâ€”or if heartwood rot may be accelerated due to the fungus that woodpeckers transport to the tree.\n\nâ€œItâ€™s still kind of a wide-open question,â€ she says. â€œWe suggested two hypotheses: one is tree selection by the birds, that the birds are somehow selecting the trees based on the presence of fungus, and the other is that birds are facilitating the movement of this fungus from tree to tree.â€\n\nNow a researcher at the Center for Mycology Research, part of the U.S. Forest Service, Jusino says sheâ€™s designing a new study that aims to answer that question. Sheâ€™s planning to start the cultures this summer, though thanks to the slow excavation habits of Red-cockaded Woodpeckers and slow growth of fungus it will take several years to get results.\n\nA Red-headed Woodpecker finds a tree cavity claimed by a flying squirrel. Photo by Bob Rumer / Birdshare.\n\nForests of the Future\n\nAs a stream of published research adds to the understanding of woodpeckers as home builders in North American forests, an emerging area of research is looking ahead to the crucial role woodpeckers will play in forests of the future.\n\nWildfires and WoodpeckersOld Flames: The Tangled History of Forest Fires, Wildlife, and People\n\nClimate change and wildfires are drastically altering forest landscapes in the American West. According to Andrew Stillman, a postdoctoral fellow at the Cornell Lab of Ornithology who studies how bird populations respond to fires, woodpeckers are a key to helping forest communities recover after a fire.\n\nâ€œWildfires often create a pulse of dead or dying trees, followed by a pulse of insects that come to take advantage of that dead wood,â€ says Stillman. â€œThe woodpeckers are following the insects into the burned areas.â€\n\nStillman says that when woodpeckers swarm into a burn area full of dead trees, they go right to work excavating cavities: â€œAnd so the woodpeckers themselves then provide a pulse of nest sites for a lot of other species â€¦ like bluebirds, which eat a lot of berries and start spreading seeds around these recently burned places.â€\n\nNorth Carolina State PhD candidate Lauren Pharr sees some of the same dynamics at play in her studies on Red-cockaded Woodpeckers in the fire-prone longleaf pine forests of the Southeast, and she thinks the woodpeckers are providing more than nesting homesâ€”theyâ€™re providing shelters during extreme climate events.\n\nReady to Become a Woodpecker Whiz?\n\nBanded Woodpecker by Ngoc Sam Thuong Dang / Macaulay Library.\n\nThe Wonderful World of Woodpeckers is an online, self-paced course full of instructional videos, interactive learning tools, case studies, photo galleries, and discussion boards. Learn more about this in-depth, self-paced Bird Academy course.\n\nDuring Pharrâ€™s four years of studying red-cockaded nesting sites, she has noted an increase in severe rain events in the North Carolina sandhills, and several hurricanes in the Florida panhandle. She says Red-cockaded Woodpecker nest holes are helping a menagerie of other cavity-dwelling species, from bluebirds and nuthatches to other woodpeckers like red-headed and red-bellied, to snakes, small mammals, even flying squirrels.\n\nâ€œThat is the most fun thing out there, climbing a tree and then a flying squirrel comes out, and itâ€™s so cute to see him fly,â€ Pharr says. â€œItâ€™s so spectacular.â€\n\nShe says those cavities are important for all kinds of animals in the face of climate change: â€œ[Red-cockaded Woodpeckers] are mitigating stress for those other species. So if they need a place to go â€¦ in places with extreme weather events or anything like that, those cavities help.â€\n\nPharrâ€™s advice for forest managers who want to optimize habitat for birds: Start with making sure a forestâ€™s woodpeckers are taken care of.\n\nâ€œRed-cockaded Woodpecker itself is a really big indicator species, and the management that we do with Red-cockaded Woodpeckers also is very beneficial to other species in that ecosystem,â€ Pharr says. â€œSo itâ€™s a win-win.â€\n\n        PreviousCracking the Red-tail Code: Exploring the Diversity of Americaâ€™s Most Widespread HawkNextIn Florida, Threatened Jays Suffer Costs of Warming Winters\n\nAll About Birdsis a free resource\n\nAvailable for everyone,funded by donors like you\n\nDonate\n\nAmerican Kestrel by Blair Dudeck / Macaulay Library\n\n          Related Stories\n\n                              After birds leave a nest box, can I clean out the nest for future use?\n\n                              A Miracle of Abundance as 20,000 Whimbrel Take Refuge on a Tiny Island\n                                                                Living Bird Magazine\n\n                              Where to Put Your Bird Feeder\n\n                              Why do hummingbirds fight so much?",
    "summary": {
      "en": "**Summary: The Role of Woodpeckers in Forest Ecosystems**\n\nWoodpecker nest holes are crucial habitats that benefit numerous species in forests. Researchers are studying \"nest webs\" to track how these valuable resources are shared among different animals. \n\nMany birds, up to 20% of species globally, use tree cavities for nesting and roosting, with woodpeckers being the primary excavators of these holes. In North America, species like the Northern Flicker create cavities that serve as homes for various birds, mammals, and insects. These holes provide safe, dry, and easily defendable spaces for raising young and hiding from predators.\n\nKathy Martin's research in British Columbia highlighted that about 30% of North American forest birds utilize tree cavities at some point in their lives. Woodpeckers are essential as they create and maintain these habitats. For example, Northern Flickers excavate almost half of the cavities used by other species, while Red-cockaded Woodpeckers are unique in their ability to drill into live trees, providing vital nesting sites in longleaf pine forests.\n\nThe research also indicates that woodpeckers help facilitate the growth of certain fungi, which may enhance the health of trees and their ecosystems. In the face of climate change and forest fires, woodpeckers play a critical role in forest recovery by creating new nesting sites and helping other species adapt to changing conditions. \n\nIn summary, woodpeckers are essential for maintaining the health and diversity of forest ecosystems, benefiting many other species through their nesting cavities. Their conservation is vital for the overall health of forest habitats.",
      "ko": "ë”±ë”°êµ¬ë¦¬ì˜ ë‘¥ì§€ êµ¬ë©ì€ ìˆ²ì—ì„œ ì—¬ëŸ¬ ì¢…ì—ê²Œ ì¤‘ìš”í•œ ì„œì‹ì§€ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì—°êµ¬ìë“¤ì€ ì´ëŸ¬í•œ ê·€ì¤‘í•œ ìì›ì´ ë‹¤ì–‘í•œ ë™ë¬¼ë“¤ ì‚¬ì´ì—ì„œ ì–´ë–»ê²Œ ê³µìœ ë˜ëŠ”ì§€ë¥¼ ì¶”ì í•˜ê¸° ìœ„í•´ \"ë‘¥ì§€ ì›¹\"ì„ ì—°êµ¬í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n\nì „ ì„¸ê³„ì ìœ¼ë¡œ ì•½ 20%ì˜ ì¡°ë¥˜ê°€ ë‚˜ë¬´ êµ¬ë©ì„ ë‘¥ì§€ì™€ íœ´ì‹ì²˜ë¡œ ì‚¬ìš©í•˜ë©°, ë”±ë”°êµ¬ë¦¬ëŠ” ì´ëŸ¬í•œ êµ¬ë©ì„ íŒŒëŠ” ì£¼ìš” ì—­í• ì„ í•©ë‹ˆë‹¤. ë¶ë¯¸ì—ì„œëŠ” ë…¸ë˜ í”Œë¦¬ì»¤ì™€ ê°™ì€ ì¢…ì´ ë‹¤ì–‘í•œ ìƒˆ, í¬ìœ ë¥˜, ê³¤ì¶©ì˜ ì§‘ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” êµ¬ë©ì„ ë§Œë“­ë‹ˆë‹¤. ì´ êµ¬ë©ì€ ìƒˆë¼ë¥¼ ê¸°ë¥´ê³  í¬ì‹ìë¡œë¶€í„° ìˆ¨ê¸°ì— ì•ˆì „í•˜ê³  ê±´ì¡°í•˜ë©° ë°©ì–´í•˜ê¸° ì‰¬ìš´ ê³µê°„ì„ ì œê³µí•©ë‹ˆë‹¤.\n\në¸Œë¦¬í‹°ì‹œì»¬ëŸ¼ë¹„ì•„ì—ì„œ ìºì‹œ ë§ˆí‹´ì˜ ì—°êµ¬ì— ë”°ë¥´ë©´, ë¶ë¯¸ ìˆ²ì˜ ì•½ 30%ì˜ ì¡°ë¥˜ê°€ ìƒì• ì˜ ì–´ëŠ ì‹œì ì—ì„œ ë‚˜ë¬´ êµ¬ë©ì„ ì´ìš©í•©ë‹ˆë‹¤. ë”±ë”°êµ¬ë¦¬ëŠ” ì´ëŸ¬í•œ ì„œì‹ì§€ë¥¼ ë§Œë“¤ê³  ìœ ì§€í•˜ëŠ” ë° í•„ìˆ˜ì ì…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ë…¸ë˜ í”Œë¦¬ì»¤ëŠ” ë‹¤ë¥¸ ì¢…ì´ ì‚¬ìš©í•˜ëŠ” êµ¬ë©ì˜ ê±°ì˜ ì ˆë°˜ì„ íŒŒë©°, ë ˆë“œì½•ì¹´ë°ë“œ ë”±ë”°êµ¬ë¦¬ëŠ” ì‚´ì•„ ìˆëŠ” ë‚˜ë¬´ë¥¼ ëš«ì„ ìˆ˜ ìˆëŠ” ë…íŠ¹í•œ ëŠ¥ë ¥ì„ ê°€ì§€ê³  ìˆì–´ ë¡±ë¦¬í”„ íŒŒì¸ ìˆ²ì—ì„œ ì¤‘ìš”í•œ ë‘¥ì§€ ì¥ì†Œë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n\nì—°êµ¬ëŠ” ë˜í•œ ë”±ë”°êµ¬ë¦¬ê°€ íŠ¹ì • ê³°íŒ¡ì´ì˜ ì„±ì¥ì„ ì´‰ì§„í•˜ì—¬ ë‚˜ë¬´ì™€ ìƒíƒœê³„ì˜ ê±´ê°•ì„ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ê¸°í›„ ë³€í™”ì™€ ì‚°ë¶ˆì— ì§ë©´í•˜ì—¬, ë”±ë”°êµ¬ë¦¬ëŠ” ìƒˆë¡œìš´ ë‘¥ì§€ ì¥ì†Œë¥¼ ë§Œë“¤ê³  ë‹¤ë¥¸ ì¢…ì´ ë³€í™”í•˜ëŠ” í™˜ê²½ì— ì ì‘í•˜ë„ë¡ ë„ì™€ì¤Œìœ¼ë¡œì¨ ìˆ²ì˜ íšŒë³µì— ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤.\n\nê²°ë¡ ì ìœ¼ë¡œ, ë”±ë”°êµ¬ë¦¬ëŠ” ìˆ² ìƒíƒœê³„ì˜ ê±´ê°•ê³¼ ë‹¤ì–‘ì„±ì„ ìœ ì§€í•˜ëŠ” ë° í•„ìˆ˜ì ì´ë©°, ê·¸ë“¤ì˜ ë‘¥ì§€ êµ¬ë©ì„ í†µí•´ ë§ì€ ë‹¤ë¥¸ ì¢…ì—ê²Œ í˜œíƒì„ ì¤ë‹ˆë‹¤. ì´ë“¤ì˜ ë³´ì¡´ì€ ìˆ² ì„œì‹ì§€ì˜ ì „ë°˜ì ì¸ ê±´ê°•ì„ ìœ„í•´ ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "b26e597ec37b62f6",
    "title": {
      "en": "Writing an HTTP Server in Go from Scratch: Part 2",
      "ko": "ê³ ë¡œ ë§Œë“œëŠ” HTTP ì„œë²„: 2ë¶€",
      "ja": null
    },
    "type": "story",
    "url": "https://www.krayorn.com/posts/http-server-go-2/",
    "score": 34,
    "by": "krayorn",
    "time": 1743111771,
    "content": "An HTTP Server in Go From scratch: Part 2   Follow along while I improve the HTTPServer I wrote from scratch in Go. March 2025   Last year I wrote a blog post explaining how I built my HTTP Server in Golang by following a Coder Crafters, I got some good feedback on it and improved the HTTP Server quite a bit, letâ€™s dive into the changes!\nThe git repository is still available if you want to look at the whole codebase.\nThe first unit test\nLetâ€™s start by adding a unit test, I was relying on the Codecrafters test suite but now I want to have some of my own unit tests.\nThis should mimic the first stage of the Codecrafters test suit:\nfunc TestServerStart(t *testing.T) {\n\t// Start the server\n\trouter := server.NewServer()\n\tgo router.Start()\n\n\t// Give the server a moment to start\n\ttime.Sleep(100 * time.Millisecond) // Not the most robust, good enough to start\n\n\t// Try to connect to the server\n\tconn, err := net.Dial(\"tcp\", \"localhost:4221\")\n\tif err != nil {\n\t\tt.Fatalf(\"Could not connect to server: %v\", err)\n\t}\n\tdefer conn.Close()\n\n\tt.Log(\"Successfully connected to the server\")\n}\nFixing issues found by readers\nHeaders should be case-insensitive and accept multiple values\nA Reddit comment mentioned that headers should be case-insensitive, and that some of them could have multiple values. That means that my naive Headers map[string]string is not correct!\nAfter reading the Golang doc for the HTTP package, I ended up with this:\ntype Header map[string][]string // this is now an array of strings\n\nfunc (header Header) Get(key string) string {\n\tif values, ok := header[strings.ToUpper(key)]; ok && len(values) > 0 {\n\t\treturn values[0] // get only returns the first value! To get all values, .Values() should be used\n\t}\n\treturn \"\"\n}\n\nfunc (header Header) Set(key string, value string) {\n\theader[strings.ToUpper(key)] = []string{value} // I always use ToUpper when interacting with the headers\n}\n\nfunc (header Header) Add(key string, value string) {\n\theader[strings.ToUpper(key)] = append(header[strings.ToUpper(key)], value)\n}\nInstead of using toUpper I could have used textproto.CanonicalMIMEHeaderKey(s) but it felt like cheating a bit in this â€œfrom scratchâ€ serie, and I did not want to implement it myself today!\nIâ€™m also adding a second test to check that Iâ€™m correctly parsing the request.\nfunc TestParseRequest(t *testing.T) {\n\trawRequest := \"GET /index.html HTTP/1.1\\r\\n\" +\n\t\t\"Host: www.example.com\\r\\n\" +\n\t\t\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\\r\\n\" +\n\t\t\"Content-Length: 3\\r\\n\" +\n\t\t\"\\r\\n\" +\n\t\t\"abc\"\n\n\trequest, err := parseRequest([]byte(rawRequest))\n\tif err != nil {\n\t\tt.Errorf(\"Expected no error, got %s\", err)\n\t}\n\n\tif request.Method != \"GET\" {\n\t\tt.Errorf(\"Expected method GET, got %s\", request.Method)\n\t}\n\n\tif request.Url.Original != \"/index.html\" {\n\t\tt.Errorf(\"Expected path /index.html, got %s\", request.Url.Original)\n\t}\n\n\tif request.Headers.Get(\"Host\") != \"www.example.com\" {\n\t\tt.Errorf(\"Expected Host header www.example.com, got %s\", request.Headers[\"Host\"])\n\t}\n\n\texpectedUserAgent := \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n\tif request.Headers.Get(\"User-Agent\") != expectedUserAgent {\n\t\tt.Errorf(\"Expected User-Agent header %s, got %s\", expectedUserAgent, request.Headers[\"User-Agent\"])\n\t}\n\n\tif string(request.Body) != \"abc\" {\n\t\tt.Errorf(\"Expected body %s, got %s\", \"abc\", string(request.Body))\n\t}\n}\nStream the response instead of sending it as a single string\nThe next comment mentions that I should allow responses to be a stream (so an io.Writer in go).\nFor the most part itâ€™s quite straightforward, and I can simply replace every instance of str += \"some string\" by io.WriteString(w, \"some string\").\nAnd pass the connection the the write method: route.Callback(*request).Write(conn)\nHandling bigger payloads\nDo you recall this from last post ?\n// Not handling bigger payload for now\nrawReq := make([]byte, 4096)\nWell, itâ€™s time.\n\trawReq := make([]byte, 0)\n\tfor {\n\t\t// It's gonna hang if requestLength % 4096 == 0\n\t\tbuffer := make([]byte, 4096)\n\t\tn, err := conn.Read(buffer)\n\n\t\tif n > 0 {\n\t\t\trawReq = append(rawReq, buffer[:n]...)\n\t\t}\n\n\t\tif n < 4096 || err != nil {\n\t\t\tbreak\n\t\t}\n\t}\nThis is another very naive implementation, but it handle bigger payloads for now!\nHowever it breaks if the payload is a multiple of 4096, because there may be nothing left to read, but the loop is still waiting\nTo fix this issue, I add:\nconn.SetReadDeadline(time.Now().Add(10 * time.Millisecond)) // ensure the connection is not hanging waiting for data for no reason\nIâ€™m pretty sure the correct implementation would be to start parsing the data until I find the content-length to know exactly how much more I should read, but thatâ€™s good enough for now!\nNew features from my list\nMiddleware\nMiddlewares are cool, itâ€™s a simple concept but I wondered how hard it was to implement!\nThe Server now has an array of middlewares that can be added by the client\ntype Server struct {\n\tRoutes      []Route\n\tMiddlewares []func(Handler) Handler\n}\n\ntype Handler func(request HTTPRequest) HTTPResponse\n\nfunc (server *Server) Use(middleware func(Handler) Handler) {\n\tserver.Middlewares = append(server.Middlewares, middleware)\n}\nAnd in the listenReq function,  we create a chain starting from the method assigned to the route followed by all the middlewares in the reverse order of assignment. Once the chain is complete, we call the last function of the chain, which triggers the chain reaction, returning to the callback!\nnextRequest := route.Callback\nfor i := len(middlewares) - 1; i >= 0; i-- {\n\tnextRequest = middlewares[i](nextRequest)\n}\n\nerr := nextRequest(*request).Write(conn)\nfmt.Println(\"Error while writing the response\", err)\n\nThe client code looks like this:\nfunc main() {\n\trouter := server.NewServer()\n\trouter.AddRoute(\"/\", home, \"GET\")\n\n\trouter.AddRoute(\"/echo/{str}\", echo, \"GET\")\n\trouter.Use(timingMiddleware)\n\trouter.Use(loggingMiddleware)\n\trouter.Start()\n\n}\n\nfunc loggingMiddleware(next server.Handler) server.Handler {\n\treturn func(req server.HTTPRequest) server.HTTPResponse {\n\t\tfmt.Println(\"Receiving call on \", req.Url.Original)\n\t\tresp := next(req)\n\t\tfmt.Println(\"Received call on \", req.Url.Original)\n\t\treturn resp\n\t}\n}\n\nfunc timingMiddleware(next server.Handler) server.Handler {\n\treturn func(req server.HTTPRequest) server.HTTPResponse {\n\t\tstart := time.Now()\n\t\tresp := next(req)\n\t\tduration := time.Since(start)\n\t\tfmt.Printf(\"%s %s - %d (%v)\\n\", req.Method, req.Url.Original, resp.Code, duration)\n\t\treturn resp\n\t}\n}\nSuch elegance! (Ok, I donâ€™t know if itâ€™s that elegant, but I was quite happy with it, the code was less complicated than I thought!)\nQuery string parameters\nNext step: Query parameters.\nI extract these from the original URL just before trying to match the URI.\nCurrently I store all of them as strings and let the user do the conversion if they expect something else.\n\turi, queryParamString, found := strings.Cut(request.Url.Original, \"?\")\n\turiParts := strings.Split(uri, \"/\")[1:]\n\tqueryParameters := make(map[string]string)\n\tif found {\n\t\tfor _, parameter := range strings.Split(queryParamString, \"&\") {\n\t\t\tkeyValue := strings.Split(parameter, \"=\")\n\t\t\tif len(keyValue) > 1 {\n\t\t\t\tqueryParameters[keyValue[0]] = keyValue[1]\n\t\t\t} else {\n\t\t\t\tqueryParameters[keyValue[0]] = \"true\"\n\t\t\t}\n\t\t}\n\t}\nThe demo app can then access them like this\nfunc echo(request server.HTTPRequest) server.HTTPResponse {\n\tcontent := request.Url.Parameters[\"str\"]\n\tif val, ok := request.Url.QueryParameters[\"repeat\"]; ok && val == \"true\" {\n\t\tcontent = strings.Repeat(content, 2)\n\t}\n\n\theaders := make(server.Header)\n\theaders.Set(\"Content-Type\", \"text/plain\")\n\treturn server.HTTPResponse{\n\t\tCode:    server.StatusOK,\n\t\tHeaders: headers,\n\t\tBody:    []byte(content),\n\t\tRequest: &request,\n\t}\n}\nSubrouters\nTo improve the UX of declaring many routes and only assigning middlewares to a certain set of routes, letâ€™s add the subrouters functionality.\nOur Server type accepts other Server as Subrouters, and I create them via the Subrouter method on a server.\ntype Server struct {\n\tRoutes      []Route\n\tSubRouters  []*Server\n\tMiddlewares []func(Handler) Handler\n\tPrefix      string\n}\n\nfunc (server *Server) SubRouter(prefix string) *Server {\n\tsubRouter := Server{\n\t\tPrefix: prefix,\n\t}\n\n\tserver.SubRouters = append(server.SubRouters, &subRouter)\n\n\treturn &subRouter\n}\nNext the matching, I kept the same code as before for checking the routes, but itâ€™s now in a separate function called match.\nIf no route is found, this function will iterate through the different subrouters with a correct prefix and then call match again on them.\nfunc match(request HTTPRequest, uriParts []string, server Server) (func(HTTPRequest) HTTPResponse, map[string]string, []func(Handler) Handler) {\n\n// The code matching the routes\n// [...]\n\nSUBROUTERS:\n\tfor _, subrouter := range server.SubRouters {\n\t\tprefixParts := strings.Split(subrouter.Prefix, \"/\")[1:]\n\n\t\tparametersPrefix := make(map[string]string)\n\t\tfor i := 0; i < len(prefixParts); i++ {\n\t\t\tif strings.HasPrefix(prefixParts[i], \"{\") && strings.HasSuffix(prefixParts[i], \"}\") {\n\t\t\t\tparametersPrefix[prefixParts[i][1:len(prefixParts[i])-1]] = uriParts[i]\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tif prefixParts[i] == uriParts[i] {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tcontinue SUBROUTERS\n\t\t}\n\n\t\tres, parameters, middlewares := match(request, uriParts[len(prefixParts):], *subrouter)\n\t\tif res != nil {\n\t\t\tmaps.Copy(parametersPrefix, parameters)\n\t\t\treturn res, parametersPrefix, append(server.Middlewares, middlewares...) // We share the middlewares of the main router with its subroutes\n\t\t}\n\t}\n\n\treturn nil, map[string]string{}, server.Middlewares\n}\nIn the demo app, the client can now use the subrouters like this\n\trouter := server.NewServer()\n\n\trouter.AddRoute(\"/\", home, \"GET\")\n\trouter.AddRoute(\"/echo/{str}\", echo, \"GET\")\n\trouter.AddRoute(\"/user-agent\", userAgent, \"GET\")\n\trouter.AddRoute(\"/files/{filename}\", getFile, \"GET\")\n\trouter.AddRoute(\"/files/{filename}\", createFile, \"POST\")\n\n\tv2Router := router.SubRouter(\"/v2/{aa}\")\n\tv2Router.AddRoute(\"/echo/{str}\", echo, \"GET\")\n\tv2Router.Use(timingMiddleware)\n\n\trouter.Use(loggingMiddleware)\n\trouter.Start()\nThe middlewares of a router are shared with its subrouters.\nThe end, again\nAnd weâ€™re done with this set of improvements, 3 fixes and 3 new features!\nI donâ€™t think Iâ€™ll work on this in the near future unless there are some big mistakes I made or a really fun idea I want to try.\nAs you can see, I did not write enough unit tests for all the old and new features which is a shame and something I should improve on, especially for this kind of learning project.\nAlthough I donâ€™t think Iâ€™ll write a part 3, I have two other learning projects built on top of a Codecrafters course that could deserve their own post, the grep and the shell, you can expect to see a writeup on one of those in the next few months.    gosoftware",
    "summary": {
      "en": "In this blog post, the author continues to improve their HTTP server written in Go, based on feedback received after the initial version. Key updates include:\n\n1. **Unit Testing**: The author introduces their own unit tests to ensure the server works correctly, starting with tests for server startup and request parsing.\n\n2. **Header Handling**: The header handling is updated to be case-insensitive and support multiple values, replacing the previous method of using a simple map.\n\n3. **Streaming Responses**: The server is modified to stream responses instead of sending them as a single string, improving efficiency.\n\n4. **Handling Large Payloads**: The server's ability to handle larger request payloads is enhanced, including a fix for potential hanging issues when reading data.\n\n5. **Middleware Support**: Middleware functionality is added, allowing the server to process requests through a series of functions for logging and timing.\n\n6. **Query Parameters**: The server now supports query parameters extracted from URLs, making it easier to handle dynamic requests.\n\n7. **Subrouters**: To streamline route management, subrouters are introduced, allowing for better organization of routes and middleware.\n\nThe author concludes by acknowledging the need for more unit tests and hints at future projects, including a grep tool and a shell, as potential topics for upcoming blog posts.",
      "ko": "ì´ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ì—ì„œ ì €ìëŠ” ì´ˆê¸° ë²„ì „ ì´í›„ ë°›ì€ í”¼ë“œë°±ì„ ë°”íƒ•ìœ¼ë¡œ Goë¡œ ì‘ì„±í•œ HTTP ì„œë²„ë¥¼ ê³„ì† ê°œì„ í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì£¼ìš” ì—…ë°ì´íŠ¸ ë‚´ìš©ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n\nì²«ì§¸, ì €ìëŠ” ì„œë²„ê°€ ì˜¬ë°”ë¥´ê²Œ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸í•˜ê¸° ìœ„í•´ ìì²´ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ë¥¼ ë„ì…í–ˆìŠµë‹ˆë‹¤. ì´ í…ŒìŠ¤íŠ¸ëŠ” ì„œë²„ ì‹œì‘ê³¼ ìš”ì²­ íŒŒì‹±ì„ í¬í•¨í•©ë‹ˆë‹¤.\n\në‘˜ì§¸, í—¤ë” ì²˜ë¦¬ ë°©ì‹ì´ ì—…ë°ì´íŠ¸ë˜ì–´ ëŒ€ì†Œë¬¸ìë¥¼ êµ¬ë¶„í•˜ì§€ ì•Šê³  ì—¬ëŸ¬ ê°’ì„ ì§€ì›í•˜ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ì „ì—ëŠ” ê°„ë‹¨í•œ ë§µì„ ì‚¬ìš©í•˜ëŠ” ë°©ì‹ì´ì—ˆìŠµë‹ˆë‹¤.\n\nì…‹ì§¸, ì„œë²„ëŠ” ì‘ë‹µì„ ë‹¨ì¼ ë¬¸ìì—´ë¡œ ë³´ë‚´ëŠ” ëŒ€ì‹  ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ì „ì†¡í•˜ë„ë¡ ìˆ˜ì •ë˜ì–´ íš¨ìœ¨ì„±ì´ í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤.\n\në„·ì§¸, ì„œë²„ì˜ ëŒ€ìš©ëŸ‰ ìš”ì²­ í˜ì´ë¡œë“œ ì²˜ë¦¬ ëŠ¥ë ¥ì´ ê°•í™”ë˜ì—ˆìŠµë‹ˆë‹¤. ë°ì´í„° ì½ê¸° ì¤‘ ë°œìƒí•  ìˆ˜ ìˆëŠ” ë©ˆì¶¤ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ìˆ˜ì •ë„ í¬í•¨ë˜ì—ˆìŠµë‹ˆë‹¤.\n\në‹¤ì„¯ì§¸, ë¯¸ë“¤ì›¨ì–´ ê¸°ëŠ¥ì´ ì¶”ê°€ë˜ì–´ ì„œë²„ê°€ ìš”ì²­ì„ ì²˜ë¦¬í•  ë•Œ ë¡œê¹…ê³¼ íƒ€ì´ë°ì„ ìœ„í•œ ì¼ë ¨ì˜ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.\n\nì—¬ì„¯ì§¸, ì„œë²„ëŠ” URLì—ì„œ ì¶”ì¶œí•œ ì¿¼ë¦¬ ë§¤ê°œë³€ìˆ˜ë¥¼ ì§€ì›í•˜ê²Œ ë˜ì–´ ë™ì  ìš”ì²­ ì²˜ë¦¬ê°€ ë” ì‰¬ì›Œì¡ŒìŠµë‹ˆë‹¤.\n\në§ˆì§€ë§‰ìœ¼ë¡œ, ë¼ìš°íŠ¸ ê´€ë¦¬ë¥¼ ê°„ì†Œí™”í•˜ê¸° ìœ„í•´ ì„œë¸Œë¼ìš°í„°ê°€ ë„ì…ë˜ì–´ ë¼ìš°íŠ¸ì™€ ë¯¸ë“¤ì›¨ì–´ë¥¼ ë” ì˜ ì¡°ì§í•  ìˆ˜ ìˆê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.\n\nì €ìëŠ” ë” ë§ì€ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ì˜ í•„ìš”ì„±ì„ ì¸ì •í•˜ë©°, í–¥í›„ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ì—ì„œ ë‹¤ë£° ì£¼ì œë¡œ grep ë„êµ¬ì™€ ì…¸ ë“±ì„ ì–¸ê¸‰í–ˆìŠµë‹ˆë‹¤.",
      "ja": null
    }
  },
  {
    "id": "b4913c0a45c1dfa9",
    "title": {
      "en": "Debian bookworm live images now reproducible",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://lwn.net/Articles/1015402/",
    "score": 745,
    "by": "bertman",
    "time": 1743009742,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "f7e6bb533a9dd9d0",
    "title": {
      "en": "What it takes to add a new back end to Futhark",
      "ko": "í“¨íƒ€í¬ ë°±ì—”ë“œ ì¶”ê°€í•˜ê¸°",
      "ja": null
    },
    "type": "story",
    "url": "https://futhark-lang.org/blog/2025-03-04-adding-a-new-backend.html",
    "score": 28,
    "by": "PaulHoule",
    "time": 1742812288,
    "content": "What it takes to add a new backend to Futhark\n\n    Posted on March  4, 2025\n\nRecently Scott Pakin suggested writing a blog post on how to add a\nnew backend to the Futhark\ncompiler, and\nsince thereâ€™s active fiddling with the backends at this very moment,\nthis is not a bad idea. Let us manage expectations up front: this will\nnot be a tutorial on adding a backend. I will not go into the deep\ndetails on the specific internal APIs that should be used. Instead, I\nwill focused on the core representations, and give an idea about the\nkind of work (often complicated) and magnitude (sometimes relatively\nlittle) it takes to add a new backend. Itâ€™s also somewhat open\nprecisely what a â€œbackendâ€ even means. Thereâ€™s a significant\ndifference in complexity between adding a command futhark foo bar.fut that produces something based on bar.fut (very easy), to\nimplementing another C-like GPU backend (not hard, but you need to\ntouch a lot of pieces), to creating a fundamentally new backend for an\nalien piece of hardware (depending on your needs, can be extremely\nchallenging).\nI will still link pertinent pieces of the source code as applicable -\nsometimes it is instructive just how simple (or simplistic) it is to\nfinally glue together the complex bits. The Futhark compiler currently\nsupports a fairly diverse set of targets (sequential CPU, multicore,\ndifferent GPU APIs, C, Python). To achieve this without undue\nduplication of code and effort, the compiler uses fairly heavily\nparameterised representations of the program being compiled. Iâ€™ll try\nto get the gist across, but the full details are very, well, detailed\n(and I always feel like they should be simplified - itâ€™s not the\naspect of the compiler weâ€™re most proud of).\nFor a drier exposition, there is also the internal compiler\ndocumentation.\nArchitectural overview\nThe Futhark compiler is a monolithic program written in Haskell. All\npasses and backends are part of the same executable. In principle, it\nwould not be too difficult to make it possible to write a backend in a\ndifferent language, as a separate executable, although it hasnâ€™t been\nrelevant so far.\nThe compiler consists of three main parts:\n\nThe frontend, which is concerned with parsing the Futhark source\nlanguage, type-checking it, and transforming it to the core\nintermediate representation (IR).\nThe middle-end, which performs gradual refinement,\ntransformation, and optimisation, on a program represented in\nvarious dialects of the the IR format (more on that below).\nThe backend, which translates from the IR representation into\nsome lower level representation, such as C - likely via several\nsteps.\n\nThese parts form a chain. The compiler will always run the frontend,\nultimately producing an intermediate representation of the program,\nthen run an appropriate middle-end pipeline, which produces another\nrepresentation of the program, and finally pass this to the backend.\nThe frontend is pretty much the same no matter how you invoke the\nFuthark compiler (futhark c, futhark cuda, etc), but the\nmiddle-end and backend behaves very differently based on the compiler\nmode. For example, rather than having a single IR, the compiler\nactually has a family of IR dialects, suited for different purposes,\nand used at different stages of the compiler. To give a gist of what I\nmean, consider an extensible Haskell datatype for representing very\nsimple expressions:\ndata Exp o = Var String\n           | Val Int\n           | Add (Exp o) (Exp o)\n           | Sub (Exp o) (Exp o)\n           | Op o\nApart from representing variables, values, additions, and\nsubtractions, this Exp type has also has a type parameter o that\nrepresents some other kind of operation, via the Op constructor.\nThis means we can instantiate a variant of Exp that contains, say,\nsquare root as the operation:\ndata SqrtOp = Sqrt ExpWithSqrt\n\ntype ExpWithSqrt = Exp SqrtOp\nBut we could also have one with some general notion of a function call:\ndata FunOp = Fun String [ExpWithFun]\n\ntype ExpWithFun = Exp FunOp\nWe can now write functions that operate on Exp o values, as long as\nwe parameterise those functions with how to handle the o cases\n(using function parameters, type classes, or what have you). This\ntechnique is useful when we want to have a collection of types that\nare largely the same. For example, in the middle-end of the Futhark\ncompiler, we initially use an IR dialect called SOACS, where\nparallelism is expressed using nested higher order operations quite\nsimilar to the source language. Eventually, the program undergoes a\nflattening transformation, after\nwhich parallelism is expressed using a different vocabulary of\nflat-parallel operations. Later, even the representation of types goes\nfrom something similar to the source language, to a representation\nthat also contains information about memory layout. Most of the\nlanguage-level details of the IR, such as how arithmetic and control\nflow is expressed, remains the same, and so does a lot of compiler\ncode, such as simplification passes, that can operate on any dialect.\nThe actual representation is a little more involved than explained\nabove, and is quite similar to the approach described in the paper\nTrees that\nGrow.\nIn particular, type-level functions are used to avoid having a\ndifferent type parameter for everything that can vary.\nWe use this notion of IR dialects pervasively throughout both the\nmiddle-end and the backend. The middle-end uses a pipeline based on\nthe compilation mode, which eventually produces a program in some IR\ndialect. That is, pipelines can be considered pure functions from some\nIR dialect to some other (or the same) IR dialect. For the c\nbackend, this dialect is called SeqMem (no parallelism, with\ninformation about array layout and\nallocations), for the\nmulticore and ispc backends it is MCMem (multicore parallel\noperations), and for the GPU backends it is called GPUMem. You can\nsee some of the default pipelines\nhere.\nWriting a new backend thus consists of picking a pipeline that\ntransforms the IR into the dialect you wish, and then doing\nsomething with that IR - where the compiler is actually quite\nagnostic regarding what that something might be. Not every backend\nneeds a distinct IR dialect - all of the GPU backends use the same IR\ndialect, for example.\nBackend actions\nIn Futhark compiler implementation lingo, the â€œbackendâ€ is called an\nâ€œactionâ€, and is an essentially arbitrary procedure that runs on the\nresult of a middle-end pipeline:\ndata Action rep = Action\n  { actionName :: String,\n    actionDescription :: String,\n    actionProcedure :: Prog rep -> FutharkM ()\n  }\nHere rep is a type-level token representing the IR dialect accepted\nby the action, and FutharkM is monad that supports IO effects,\nmeaning that these â€œactionsâ€ can perform arbitrary IO. For example,\nthe action for futhark c will do a bunch of code generation in pure\nHaskell code, but also write some files and run a C compiler:\ncompileCAction :: FutharkConfig -> CompilerMode -> FilePath -> Action SeqMem\ncompileCAction fcfg mode outpath =\n  Action\n    { actionName = \"Compile to sequential C\",\n      actionDescription = \"Compile to sequential C\",\n      actionProcedure = helper\n    }\n  where\n    helper prog = do\n      cprog <- handleWarnings fcfg $ SequentialC.compileProg versionString prog\n      let cpath = outpath `addExtension` \"c\"\n          hpath = outpath `addExtension` \"h\"\n          jsonpath = outpath `addExtension` \"json\"\n\n      case mode of\n        ToLibrary -> do\n          let (header, impl, manifest) = SequentialC.asLibrary cprog\n          liftIO $ T.writeFile hpath $ cPrependHeader header\n          liftIO $ T.writeFile cpath $ cPrependHeader impl\n          liftIO $ T.writeFile jsonpath manifest\n        ToExecutable -> do\n          liftIO $ T.writeFile cpath $ SequentialC.asExecutable cprog\n          runCC cpath outpath [\"-O3\", \"-std=c99\"] [\"-lm\"]\n        ToServer -> do\n          liftIO $ T.writeFile cpath $ SequentialC.asServer cprog\n          runCC cpath outpath [\"-O3\", \"-std=c99\"] [\"-lm\"]\nHere the SequentialC.compileProg function does the actual C code\ngeneration. Iâ€™ll elaborate a bit on it, but at an architectural level,\nit is not constrained at all in what it does. In principle, an action\ncould just dump the final IR to disk and run some entirely different\nprogram that takes care of code generation. You might even write an\naction that expects the program to still be in one of the early IR\ndialects, such as the ones that do not have memory information, or\neven the one that still has nested parallelism. This might be\nappropriate if you are targeting some other (relatively) high level\nlanguage.\nUltimately, if you wish to write a backend that does not need a new IR\ndialect, and also does not need to reuse any of the existing C\ngeneration machinery, then this is consequently quite easy - at least\nas far as integration with the compiler is concerned.\nTo actually hook up a pipeline with an action and produce something\nthat can be invoked by the command line, you need to write a largely\nboilerplate main definition, like this one for futhark Haskell:\nmain :: String -> [String] -> IO ()\nmain = compilerMain\n  ()\n  []\n  \"Compile sequential C\"\n  \"Generate sequential C code from optimised Futhark program.\"\n  seqmemPipeline\n  $ \\fcfg () mode outpath prog ->\n    actionProcedure (compileCAction fcfg mode outpath) prog\nAnd then finally hook it up to the big list of\nsubommands.\nThatâ€™s all it takes.\nImperative code generation\nWhile it is true that an action can be arbitrary imperative code, in\npractice all of Futharkâ€™s C-based backends (and even the Python\nones)\nmake use of significant shared infastructure to avoid having to\nreimplement the wheel too often.\nAs a starting point, the Futhark compiler defines an imperative\nintermediate representation, called\nImp.\nAs with the middle-end, Imp is actually an extensible language, with\nvarious dialects. For example, sequential\nImpGen.\nIn contrast to the functional middle-end IR, which is very well\ndefined, with type checking rules and a well-defined external syntax,\nImp is a lot more ad hoc, and does not for example have a parser.\nSemantically, itâ€™s largely a simplified form of C. In fact, it is not\neven in SSA\nform,\nwhich still works out alright, because we do no optimisation at the\nImp level.\nThe translation from the functional IR to Imp is done by a module\ncalled\nImpGen.\nIt is heavily parameterised, because it essentially has to go from an\narbitrary IR dialect to an arbitrary Imp dialect. It is full of\nimplementation details, but not particularly interesting.\nOnce the compiler has obtained an Imp representation of the program,\nit can then turn that program into C or Python, or even some other\nlanguage. This is largely a mechanical process - the semantic gap from\nImp to C (or the baroque form of Python produced by Futhark) is not\ngreat, and mostly involves mapping Imp constructs to the facilities\nprovided by the (very small) Futhark runtime system, and of course\ngenerating syntactically valid code. To ease maintenance of the three\nGPU backends (cuda, opencl, hip), we also make use of a small\nGPU abstraction layer\n(gpu.h,\ndiscussed in this\npaper.\nAdvice on writing a backend\nFuthark is not set up to make it especially easy to add new backends,\nbut neither is it particularly difficult. After all, as of this\nwriting we support 10 different backends. Here is some advice for any\nprospective people who wish to seek glory by adding a backend:\n\nIf you want to target a very high level parallel language, use only\nFutharkâ€™s frontend and the middle-end up to the SOACS\nrepresentation. This will give you a monomorphic first-order program\n(except for parallel operations) where all types are scalars or\narrays of scalars, but still with nested parallelism, although that\nparallelism will be well fused. I do think it would be a fun\nexperiment to generate code for a fork-join language, such as\nMPL, from this representation.\nIf you want to target a slightly less high level parallel language,\nin particular one that does not handle nested parallelism well,\nconsider processing the output of the GPU representation. Despite\nthe name, it is not truly GPU specific (the parts that are can be\nignored or modified, and are mostly about metadata and tuning), but\nmerely guarantees the absence of nested parallelism. It is still\nhigh level and with value-oriented semantics, with no notion of\nmemory.\nIf you want to target a new GPU backend, implement the gpu.h\nabstraction layer. The code generation work for CPU-side work will\nthen be fairly straightforward, although you may still need to do\nsignificant work to generate the actual GPU kernel code. We are\ncurrently going through this process with the in-progress WebGPU\nbackend, and most of\nthe challenges are related to the particular limitations of WebGPU\n(a post for another time), and not so much the compiler engineering.\nIf you want to generate low level code of any kind, you will likely\nfind it easiest to use one of the IR dialects with memory\ninformation. If you want to generate something that is relatively\nC-like (and generating e.g.machine code or JavaScript is both\nâ€œC-likeâ€ in this regard), then using the existing machinery for\ngenerating Imp is almost certainly easiest.\n\nHowever, in all cases, I would say a very good idea is to contact one\nof the Futhark developers for advice and help. Having a third party\nadd a new backend is not really something we have considered much (all\nof the backends have been written under our close supervision), and\nwhile the technical challenges are not all that major by the\nstandards of writing compiler backends, the documentation is not\nreally up to the task. But I would certainly be very excited for\nsomeone to give it a try.",
    "summary": {
      "en": "**Summary: Adding a New Backend to Futhark**\n\nScott Pakin suggested creating a blog post about adding new backends to the Futhark compiler. This post outlines the general process without going into detailed technical specifics. The complexity of adding a backend can vary significantly, from simple commands to complex new hardware implementations.\n\nThe Futhark compiler has three main parts:\n1. **Frontend**: Parses and type-checks the Futhark source code, converting it into an intermediate representation (IR).\n2. **Middle-end**: Refines and optimizes the program through various IR dialects.\n3. **Backend**: Converts the IR into a lower-level representation (like C).\n\nThe compiler supports multiple targets (CPUs, GPUs, etc.) and uses parameterized representations to avoid code duplication. Each backend is defined as an â€œaction,â€ which is a procedure that works on the IR produced by the middle-end.\n\nTo write a new backend, you need to select an appropriate pipeline for transforming the IR and then define the backend action. While adding a backend is not overly complex, understanding the existing infrastructure and documentation is vital. Advice for potential developers includes:\n- Use Futhark's frontend and middle-end for high-level languages.\n- For lower-level code, utilize IR dialects with memory information.\n- Contact Futhark developers for guidance, as past backends were created with their close supervision.\n\nOverall, adding a backend offers challenges but is a feasible task, and the developers welcome new contributions.",
      "ko": "ìŠ¤ì½§ íŒŒí‚¨ì€ Futhark ì»´íŒŒì¼ëŸ¬ì— ìƒˆë¡œìš´ ë°±ì—”ë“œë¥¼ ì¶”ê°€í•˜ëŠ” ê²ƒì— ëŒ€í•œ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ë¥¼ ì‘ì„±í•  ê²ƒì„ ì œì•ˆí–ˆìŠµë‹ˆë‹¤. ì´ í¬ìŠ¤íŠ¸ëŠ” êµ¬ì²´ì ì¸ ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­ì— ë“¤ì–´ê°€ì§€ ì•Šê³  ì¼ë°˜ì ì¸ ê³¼ì •ì„ ì„¤ëª…í•©ë‹ˆë‹¤. ë°±ì—”ë“œë¥¼ ì¶”ê°€í•˜ëŠ” ë³µì¡ì„±ì€ ê°„ë‹¨í•œ ëª…ë ¹ì–´ì—ì„œë¶€í„° ë³µì¡í•œ í•˜ë“œì›¨ì–´ êµ¬í˜„ê¹Œì§€ ë‹¤ì–‘í•˜ê²Œ ë‚˜íƒ€ë‚  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nFuthark ì»´íŒŒì¼ëŸ¬ëŠ” ì„¸ ê°€ì§€ ì£¼ìš” ë¶€ë¶„ìœ¼ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤. ì²« ë²ˆì§¸ëŠ” í”„ë¡ íŠ¸ì—”ë“œë¡œ, Futhark ì†ŒìŠ¤ ì½”ë“œë¥¼ íŒŒì‹±í•˜ê³  íƒ€ì… ê²€ì‚¬ë¥¼ í†µí•´ ì¤‘ê°„ í‘œí˜„(Intermediate Representation, IR)ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. ë‘ ë²ˆì§¸ëŠ” ë¯¸ë“¤ì—”ë“œë¡œ, ë‹¤ì–‘í•œ IR ë°©ì–¸ì„ í†µí•´ í”„ë¡œê·¸ë¨ì„ ì •ì œí•˜ê³  ìµœì í™”í•©ë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ ë°±ì—”ë“œëŠ” IRì„ ë” ë‚®ì€ ìˆ˜ì¤€ì˜ í‘œí˜„ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤(ì˜ˆ: C ì–¸ì–´).\n\nì´ ì»´íŒŒì¼ëŸ¬ëŠ” ì—¬ëŸ¬ íƒ€ê²Ÿ(CPU, GPU ë“±)ì„ ì§€ì›í•˜ë©°, ì½”ë“œ ì¤‘ë³µì„ í”¼í•˜ê¸° ìœ„í•´ ë§¤ê°œë³€ìˆ˜í™”ëœ í‘œí˜„ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ê° ë°±ì—”ë“œëŠ” ë¯¸ë“¤ì—”ë“œì—ì„œ ìƒì„±ëœ IRì— ì‘ìš©í•˜ëŠ” ì ˆì°¨ì¸ â€œì•¡ì…˜â€ìœ¼ë¡œ ì •ì˜ë©ë‹ˆë‹¤.\n\nìƒˆë¡œìš´ ë°±ì—”ë“œë¥¼ ì‘ì„±í•˜ë ¤ë©´ IRì„ ë³€í™˜í•˜ê¸° ìœ„í•œ ì ì ˆí•œ íŒŒì´í”„ë¼ì¸ì„ ì„ íƒí•˜ê³  ë°±ì—”ë“œ ì•¡ì…˜ì„ ì •ì˜í•´ì•¼ í•©ë‹ˆë‹¤. ë°±ì—”ë“œë¥¼ ì¶”ê°€í•˜ëŠ” ê²ƒì€ ê·¸ë¦¬ ë³µì¡í•˜ì§€ ì•Šì§€ë§Œ, ê¸°ì¡´ ì¸í”„ë¼ì™€ ë¬¸ì„œë¥¼ ì´í•´í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤. ì ì¬ì ì¸ ê°œë°œìì—ê²ŒëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì¡°ì–¸ì´ ì£¼ì–´ì§‘ë‹ˆë‹¤. Futharkì˜ í”„ë¡ íŠ¸ì—”ë“œì™€ ë¯¸ë“¤ì—”ë“œë¥¼ ê³ ê¸‰ ì–¸ì–´ì— ì‚¬ìš©í•˜ê³ , ì €ìˆ˜ì¤€ ì½”ë“œë¥¼ ìœ„í•´ì„œëŠ” ë©”ëª¨ë¦¬ ì •ë³´ë¥¼ í¬í•¨í•œ IR ë°©ì–¸ì„ í™œìš©í•˜ë¼ëŠ” ê²ƒì…ë‹ˆë‹¤. ë˜í•œ, ê³¼ê±°ì˜ ë°±ì—”ë“œëŠ” Futhark ê°œë°œìë“¤ì˜ ë°€ì ‘í•œ ê°ë… ì•„ë˜ ë§Œë“¤ì–´ì¡Œìœ¼ë¯€ë¡œ, ë„ì›€ì„ ë°›ê¸° ìœ„í•´ ê·¸ë“¤ê³¼ ì—°ë½í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.\n\nì „ë°˜ì ìœ¼ë¡œ ë°±ì—”ë“œë¥¼ ì¶”ê°€í•˜ëŠ” ê²ƒì€ ë„ì „ì´ ë  ìˆ˜ ìˆì§€ë§Œ, ì¶©ë¶„íˆ ê°€ëŠ¥í•œ ì‘ì—…ì´ë©° ê°œë°œìë“¤ì€ ìƒˆë¡œìš´ ê¸°ì—¬ë¥¼ í™˜ì˜í•©ë‹ˆë‹¤.",
      "ja": null
    }
  }
]