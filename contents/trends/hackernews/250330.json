[
  {
    "id": "f3ab3de7a255b5ff",
    "title": {
      "en": "Buy once, use forever A directory of one-time purchase software. Add yours",
      "ko": "ì˜êµ¬ ì†Œí”„íŠ¸ì›¨ì–´ ê°€ì´ë“œ",
      "ja": "ä¸€ç”Ÿä½¿ãˆã‚‹ã‚½ãƒ•ãƒˆä¸€è¦§"
    },
    "type": "story",
    "url": "https://buyoncesoftware.com/",
    "score": 135,
    "by": "richbowen",
    "time": 1743294514,
    "content": "Buy software, onceSay goodbye to subscription fatigue!Discover software you can buy once and own forever--no recurring charges, just tools that work for you, for life.Get featured for $99CategoriesAllAddonsAIBusiness & FinanceCADCommunicationContent & SEOData & AnalyticsDesignDevelopmentDocument & WritingEducationEntertainmentInfrastructureMarketingMusicNote TakingPhoto & VideoPrivacy & SecurityProductivitySocial MediaTemplate & ResourceUtilityMediBang Paint ProBy MediBang DesignMediBang Paint Pro is a digital painting and comic creation software. It's available for Windows, Mac, and iPad. MediBang Paint Pro is a FREE digital painting and comic creation software. It's available for Windows, Mac, and iPad.Website Buy Now Fire AlpacaBy Fire Alpaca DesignFireAlpaca is the free Digital Painting Software that is available in 10 languages and compatible with both Mac and Windows. Simple tools and controls let you draw an illustration easily. Download FireAlpaca right now!Website Buy Now DevonThinkBy Devon Technologies ProductivityDEVONthink is a knowledge base, information manager, and much more. In today's world, everything is digital. From shopping receipts to important research papers, your life often fills your hard drive in the form of emails, PDFs, Word documents, multimedia files, and more. Questions eventually pop up, like where do you store all of this stuff? How do you organize these very different file types, and even better, how do you find the exact file you're looking for the second you need it? It's almost as if you need a second brain just to keep your digital life straight.Website Buy Now BroadcastBy Simon Chiu MarketingBroadcast is a self-hosted email marketing platform  Unlimited email lists, unlimited subscribers, send one-time campaigns, send automation sequences, set up in 5 minutes35% OFFBF2024Website Buy Now LocalCanâ„¢By LocalCan Development#1 Ngrok alternative. Without subscription. With .local domains and top-rated UX.25% OFFBF25Website Buy Now ScreenpipeBy Screenpipe UtilityScreenpipe captures your computer while you work - including your meetings - letting you go back to any moment in an instant.30% OFFWebsite Buy Now ProtegoBy Edgar Sanchez UtilityProtego helps you block unwanted content, hide specific topics, and avoid spoilers on Reddit. The perfect Safari extension for a cleaner, more focused Reddit browsing experience on your Mac.25% OFFWebsite Buy Now DeskVaultBy Strongly Typed Business & FinanceAnalyze, chart, query and combine revenue and activity across all your Stripe accounts, all on your computer. Get smart summaries of recent important events and upcoming action items, view a calendar of upcoming payouts and renewals, or just list the raw data.30% OFFBF24Website Buy Now Small BetsBy Daniel Vassallo Social MediaSmall Bets is an online community teaching people how to make money through small entrepreneurial projects, rather than risking everything on a big startup. Members get lifetime access to expert-led courses, a supportive community, and practical guidance on launching profitable side projects.$50 OFFBF2024Website Buy Now FridayGPTBy Naveen Naidu AIAI Copilot for your Mac. Instant access to multiple LLM models, voice-to-text and quick AI actions.30% OFFABFCM30Website Buy Now Kerligâ„¢By Kerlig AI#1 Grammarly alternative. AI Writing Assistant & Chat for macOS, 350+ models, vision, attachments, presets, tones of voice.50% OFF, 25% OFFBF50, BF25Website Buy Now ThreeDeeBy ThreeDee DesignA massive cartoon 3D models pack: 22+ diverse bundles.30% OFFblackfriday2024Website Buy Now XnapperBy Xnapper UtilityXnapper takes beautiful screenshots instantly. Focus on your content while it handles backgrounds, text recognition, annotations & more.40% OFFblackfriday2024Website Buy Now InspotypeBy Inspotype DesignInspotype makes designer's lives easier by quickly and seamlessly pairing fonts, color schemes and visual aesthetics for digital products.20% OFFBLACKFRIDAY2024Website Buy Now ContrastsBy Christoph Wendt UtilityContrasts is your tool for color contrast checking and accessibility. WCAG-compliant and ready for the European Accessibility Act. Improve your digital world now.40% OFFWebsite Buy Now Previous123â€¦Next",
    "summary": {
      "en": "**Summary:**\n\nDiscover software that you can buy once and own forever, eliminating subscription fees. Here are some featured software options:\n\n1. **MediBang Paint Pro**: A free digital painting and comic creation tool available on Windows, Mac, and iPad.\n2. **Fire Alpaca**: Free digital painting software supporting multiple languages and easy-to-use tools for illustrations.\n3. **DEVONthink**: An information management tool that helps organize and find various digital files like emails and documents.\n4. **Broadcast**: A self-hosted email marketing platform with unlimited lists and subscribers.\n5. **LocalCanâ„¢**: An alternative to Ngrok without subscriptions, offering great user experience.\n6. **Screenpipe**: A utility for capturing your computer screen and meetings for easy access later.\n7. **Protego**: A Safari extension that blocks unwanted content and topics on Reddit.\n8. **DeskVault**: A tool for analyzing revenue and activity across Stripe accounts.\n9. **Small Bets**: An online community focused on making money through small projects with lifetime access to courses and support.\n10. **FridayGPT**: An AI assistant for Mac providing quick access to various models and voice-to-text features.\n11. **Kerligâ„¢**: An AI writing assistant and chat alternative to Grammarly for macOS.\n12. **ThreeDee**: A collection of diverse cartoon 3D models.\n13. **Xnapper**: A screenshot tool that enhances images with text recognition and annotations.\n14. **Inspotype**: A tool for quickly pairing fonts and color schemes for design projects.\n15. **Contrasts**: A color contrast checking tool ensuring accessibility compliance.\n\nExplore these options to find tools that fit your needs without ongoing costs!",
      "ko": "í•œ ë²ˆ êµ¬ë§¤í•˜ë©´ ì˜êµ¬ì ìœ¼ë¡œ ì†Œìœ í•  ìˆ˜ ìˆëŠ” ì†Œí”„íŠ¸ì›¨ì–´ë¥¼ ì°¾ì•„ë³´ì„¸ìš”. êµ¬ë…ë£Œê°€ í•„ìš” ì—†ëŠ” ì œí’ˆë“¤ì…ë‹ˆë‹¤. ë‹¤ìŒì€ ì¶”ì²œ ì†Œí”„íŠ¸ì›¨ì–´ ëª©ë¡ì…ë‹ˆë‹¤.\n\nMediBang Paint ProëŠ” ìœˆë„ìš°, ë§¥, ì•„ì´íŒ¨ë“œì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ë¬´ë£Œ ë””ì§€í„¸ í˜ì¸íŒ… ë° ë§Œí™” ì œì‘ ë„êµ¬ì…ë‹ˆë‹¤. Fire AlpacaëŠ” ì—¬ëŸ¬ ì–¸ì–´ë¥¼ ì§€ì›í•˜ë©°, ì¼ëŸ¬ìŠ¤íŠ¸ë ˆì´ì…˜ì„ ìœ„í•œ ì‚¬ìš©í•˜ê¸° ì‰¬ìš´ ë„êµ¬ë¥¼ ì œê³µí•˜ëŠ” ë¬´ë£Œ ë””ì§€í„¸ í˜ì¸íŒ… ì†Œí”„íŠ¸ì›¨ì–´ì…ë‹ˆë‹¤. DEVONthinkëŠ” ì´ë©”ì¼ê³¼ ë¬¸ì„œ ê°™ì€ ë‹¤ì–‘í•œ ë””ì§€í„¸ íŒŒì¼ì„ ì •ë¦¬í•˜ê³  ì°¾ëŠ” ë° ë„ì›€ì„ ì£¼ëŠ” ì •ë³´ ê´€ë¦¬ ë„êµ¬ì…ë‹ˆë‹¤. BroadcastëŠ” ë¬´ì œí•œ ëª©ë¡ê³¼ êµ¬ë…ìë¥¼ ì§€ì›í•˜ëŠ” ìì²´ í˜¸ìŠ¤íŒ… ì´ë©”ì¼ ë§ˆì¼€íŒ… í”Œë«í¼ì…ë‹ˆë‹¤. LocalCanâ„¢ì€ êµ¬ë… ì—†ì´ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” Ngrok ëŒ€ì•ˆìœ¼ë¡œ, ë›°ì–´ë‚œ ì‚¬ìš©ì ê²½í—˜ì„ ì œê³µí•©ë‹ˆë‹¤.\n\nScreenpipeëŠ” ì»´í“¨í„° í™”ë©´ê³¼ íšŒì˜ë¥¼ ìº¡ì²˜í•˜ì—¬ ë‚˜ì¤‘ì— ì‰½ê²Œ ì ‘ê·¼í•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ëŠ” ìœ í‹¸ë¦¬í‹°ì…ë‹ˆë‹¤. ProtegoëŠ” Safari í™•ì¥ í”„ë¡œê·¸ë¨ìœ¼ë¡œ, Redditì—ì„œ ì›ì¹˜ ì•ŠëŠ” ì½˜í…ì¸ ì™€ ì£¼ì œë¥¼ ì°¨ë‹¨í•©ë‹ˆë‹¤. DeskVaultëŠ” Stripe ê³„ì •ì˜ ìˆ˜ìµê³¼ í™œë™ì„ ë¶„ì„í•˜ëŠ” ë„êµ¬ì…ë‹ˆë‹¤. Small BetsëŠ” ì‘ì€ í”„ë¡œì íŠ¸ë¥¼ í†µí•´ ëˆì„ ë²Œê¸° ìœ„í•œ ì˜¨ë¼ì¸ ì»¤ë®¤ë‹ˆí‹°ë¡œ, í‰ìƒ ë™ì•ˆ ê°•ì˜ì™€ ì§€ì›ì„ ì œê³µí•©ë‹ˆë‹¤. FridayGPTëŠ” ë§¥ìš© AI ë¹„ì„œë¡œ, ë‹¤ì–‘í•œ ëª¨ë¸ê³¼ ìŒì„± ì¸ì‹ ê¸°ëŠ¥ì— ë¹ ë¥´ê²Œ ì ‘ê·¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nKerligâ„¢ëŠ” macOSìš© AI ê¸€ì“°ê¸° ë„ìš°ë¯¸ë¡œ, Grammarlyì˜ ëŒ€ì•ˆì…ë‹ˆë‹¤. ThreeDeeëŠ” ë‹¤ì–‘í•œ ë§Œí™” 3D ëª¨ë¸ì„ ëª¨ì•„ë†“ì€ ì»¬ë ‰ì…˜ì…ë‹ˆë‹¤. XnapperëŠ” í…ìŠ¤íŠ¸ ì¸ì‹ê³¼ ì£¼ì„ ì¶”ê°€ ê¸°ëŠ¥ìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ í–¥ìƒì‹œí‚¤ëŠ” ìŠ¤í¬ë¦°ìƒ· ë„êµ¬ì…ë‹ˆë‹¤. InspotypeëŠ” ë””ìì¸ í”„ë¡œì íŠ¸ë¥¼ ìœ„í•œ ê¸€ê¼´ê³¼ ìƒ‰ìƒ ì¡°í•©ì„ ë¹ ë¥´ê²Œ ì°¾ì•„ì£¼ëŠ” ë„êµ¬ì…ë‹ˆë‹¤. ContrastsëŠ” ì ‘ê·¼ì„± ì¤€ìˆ˜ë¥¼ ë³´ì¥í•˜ëŠ” ìƒ‰ìƒ ëŒ€ë¹„ ê²€ì‚¬ ë„êµ¬ì…ë‹ˆë‹¤.\n\nì´ ì˜µì…˜ë“¤ì„ ì‚´í´ë³´ë©° ì§€ì†ì ì¸ ë¹„ìš© ì—†ì´ í•„ìš”í•œ ë„êµ¬ë¥¼ ì°¾ì•„ë³´ì„¸ìš”!",
      "ja": "ä¸€åº¦è³¼å…¥ã™ã‚Œã°æ°¸é ã«æ‰€æœ‰ã§ãã‚‹ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚’è¦‹ã¤ã‘ã¦ã€å®šæœŸçš„ãªã‚µãƒ–ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³æ–™é‡‘ã‚’ãªãã—ã¾ã—ã‚‡ã†ã€‚ä»¥ä¸‹ã¯ãŠã™ã™ã‚ã®ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã§ã™ã€‚\n\nMediBang Paint Proã¯ã€Windowsã€Macã€iPadã§åˆ©ç”¨ã§ãã‚‹ç„¡æ–™ã®ãƒ‡ã‚¸ã‚¿ãƒ«ãƒšã‚¤ãƒ³ãƒˆã¨æ¼«ç”»åˆ¶ä½œãƒ„ãƒ¼ãƒ«ã§ã™ã€‚Fire Alpacaã¯ã€è¤‡æ•°ã®è¨€èªã«å¯¾å¿œã—ãŸç„¡æ–™ã®ãƒ‡ã‚¸ã‚¿ãƒ«ãƒšã‚¤ãƒ³ãƒˆã‚½ãƒ•ãƒˆã§ã€ã‚¤ãƒ©ã‚¹ãƒˆåˆ¶ä½œã«ä¾¿åˆ©ãªä½¿ã„ã‚„ã™ã„ãƒ„ãƒ¼ãƒ«ãŒæƒã£ã¦ã„ã¾ã™ã€‚DEVONthinkã¯ã€ãƒ¡ãƒ¼ãƒ«ã‚„æ–‡æ›¸ãªã©ã®ã•ã¾ã–ã¾ãªãƒ‡ã‚¸ã‚¿ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ•´ç†ã—ã€æ¤œç´¢ã™ã‚‹ãŸã‚ã®æƒ…å ±ç®¡ç†ãƒ„ãƒ¼ãƒ«ã§ã™ã€‚Broadcastã¯ã€ç„¡åˆ¶é™ã®ãƒªã‚¹ãƒˆã¨è³¼èª­è€…ã‚’æŒã¤è‡ªå·±ãƒ›ã‚¹ãƒˆå‹ã®ãƒ¡ãƒ¼ãƒ«ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã§ã™ã€‚\n\nLocalCanâ„¢ã¯ã€ã‚µãƒ–ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³ãªã—ã§åˆ©ç”¨ã§ãã‚‹Ngrokã®ä»£æ›¿å“ã§ã€å„ªã‚ŒãŸãƒ¦ãƒ¼ã‚¶ãƒ¼ä½“é¨“ã‚’æä¾›ã—ã¾ã™ã€‚Screenpipeã¯ã€ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã®ç”»é¢ã‚„ä¼šè­°ã‚’ã‚­ãƒ£ãƒ—ãƒãƒ£ã—ã€å¾Œã§ç°¡å˜ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã§ã™ã€‚Protegoã¯ã€Safariã®æ‹¡å¼µæ©Ÿèƒ½ã§ã€Redditä¸Šã®ä¸è¦ãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚„ãƒˆãƒ”ãƒƒã‚¯ã‚’ãƒ–ãƒ­ãƒƒã‚¯ã—ã¾ã™ã€‚DeskVaultã¯ã€Stripeã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®åç›Šã‚„æ´»å‹•ã‚’åˆ†æã™ã‚‹ãŸã‚ã®ãƒ„ãƒ¼ãƒ«ã§ã™ã€‚\n\nSmall Betsã¯ã€å°ã•ãªãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’é€šã˜ã¦ãŠé‡‘ã‚’ç¨¼ãã“ã¨ã«ç„¦ç‚¹ã‚’å½“ã¦ãŸã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã§ã€ã‚³ãƒ¼ã‚¹ã‚„ã‚µãƒãƒ¼ãƒˆã«ç”Ÿæ¶¯ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã™ã€‚FridayGPTã¯ã€Macç”¨ã®AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã€ã•ã¾ã–ã¾ãªãƒ¢ãƒ‡ãƒ«ã‚„éŸ³å£°ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã¸ã®æ©Ÿèƒ½ã«è¿…é€Ÿã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã™ã€‚Kerligâ„¢ã¯ã€macOSå‘ã‘ã®AIãƒ©ã‚¤ãƒ†ã‚£ãƒ³ã‚°ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã€Grammarlyã®ä»£æ›¿ã¨ã—ã¦åˆ©ç”¨ã§ãã¾ã™ã€‚ThreeDeeã¯ã€å¤šæ§˜ãªã‚«ãƒ¼ãƒˆã‚¥ãƒ¼ãƒ³3Dãƒ¢ãƒ‡ãƒ«ã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã§ã™ã€‚Xnapperã¯ã€ãƒ†ã‚­ã‚¹ãƒˆèªè­˜ã‚„æ³¨é‡ˆæ©Ÿèƒ½ã‚’å‚™ãˆãŸã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆãƒ„ãƒ¼ãƒ«ã§ã™ã€‚Inspotypeã¯ã€ãƒ‡ã‚¶ã‚¤ãƒ³ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãŸã‚ã«ãƒ•ã‚©ãƒ³ãƒˆã¨ã‚«ãƒ©ãƒ¼ã‚¹ã‚­ãƒ¼ãƒ ã‚’ç´ æ—©ãçµ„ã¿åˆã‚ã›ã‚‹ãƒ„ãƒ¼ãƒ«ã§ã™ã€‚Contrastsã¯ã€ã‚¢ã‚¯ã‚»ã‚·ãƒ“ãƒªãƒ†ã‚£åŸºæº–ã‚’æº€ãŸã™ãŸã‚ã®è‰²ã®ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆã‚’ãƒã‚§ãƒƒã‚¯ã™ã‚‹ãƒ„ãƒ¼ãƒ«ã§ã™ã€‚\n\nã“ã‚Œã‚‰ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’æ¢ã—ã¦ã€ç¶™ç¶šçš„ãªã‚³ã‚¹ãƒˆãªã—ã§è‡ªåˆ†ã«åˆã£ãŸãƒ„ãƒ¼ãƒ«ã‚’è¦‹ã¤ã‘ã¦ãã ã•ã„ã€‚"
    }
  },
  {
    "id": "abe58b40c749c235",
    "title": {
      "en": "My TV started playing a video in full screen by itself. What happened?",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://support.vizio.com/s/article/Ambient-or-Scenic-Mode-showing-on-my-TV?language=en_US",
    "score": 123,
    "by": "decimalenough",
    "time": 1743295305,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "4ba75e729c4fc4d5",
    "title": {
      "en": "Everyone knows all the apps on your phone",
      "ko": "ëª¨ë‘ ì•„ëŠ” ì•±ë“¤",
      "ja": "ã¿ã‚“ãªã®ã‚¢ãƒ—ãƒªäº‹æƒ…"
    },
    "type": "story",
    "url": "https://peabee.substack.com/p/everyone-knows-what-apps-you-use",
    "score": 148,
    "by": "gniting",
    "time": 1743283592,
    "content": "Share this postPea BeeEveryone knows all the apps on your phoneCopy linkFacebookEmailNotesMoreDiscover more from Pea Beetales from indian web rabbit holes.Over 2,000 subscribersSubscribeBy subscribing,  I agree to Substack's Terms of Use, and acknowledge its Information Collection Notice and Privacy Policy.Already have an account? Sign inEveryone knows all the apps on your phoneMar 28, 202568Share this postPea BeeEveryone knows all the apps on your phoneCopy linkFacebookEmailNotesMore1013ShareUntil a few years ago, any app you installed on an Android device could see all other apps on your phone without your permission. Since 2022, with Android 11, Google removed this access from app developers. Under their new package visibility policy, apps should only see other installed apps if itâ€™s essential to their core functionality. Developers must also explicitly declare these apps in the AndroidManifest.xml file - a required configuration file for all Android apps.For extremely specific use cases such as file managers, browsers or antivirus apps, Google grants an exception by allowing QUERY_ALL_PACKAGES permission, which provides full visibility into installed apps. I donâ€™t use Android as my primary phone, but I have a spare one and I was really curious to find out which apps from Indian companies had checks to see what other apps I had installed.So I downloaded a few dozen Indian apps I could think of on top of my head and started reading their manifest files. Surely they will be respectful of my privacy and will only query apps essential to their app's core functionality? ğŸ™ƒSubscribeIt's worth acknowledging that there are some legitimate reasons for an app to check which other apps are installed on your phone. For example, an app might check which UPI apps are installed to show relevant payment options. Most of the manifest files I examined included checks for these apps. Some also looked for app cloning or multi-account apps, likely for security and fraud detection. All acceptable use cases.But a few Indian companies went above and beyond with these checks. Letâ€™s start with Swiggy. It has a staggering 154 package names listed in its manifest file, allowing it to query those apps on my phone. Hereâ€™s the full list:I donâ€™t even know where to begin unpacking this madness. How is knowing whether I have the Xbox or the Playstation app installed on my phone essential to their Swiggy's core functionality? How will knowing if I have the Naukri or Upstox app help them deliver groceries to my doorstep?The wide range of categories of apps in this list strongly suggests Swiggy is collecting installed apps data for user profiling and to build a behavioural profile of their customers. This seems to be against Play Store's policies which considers the list of installed apps to be personal and sensitive user data.This reminded me of that ppt from Blume Ventures - the one that blue tick twitter accounts living in certain pin codes of Bengaluru passionately discuss amongst themselves for a week every year. It had this interesting slide on apps used by different Indias:Swiggy queries most of these apps and more on your phone. It not only knows which India you belong to, but it can pinpoint exactly where you fall within it.Let's talk about another app now, and it's the usual suspect, the undisputed champion of asshole design - Zepto. They have listed 165 apps to check for on your device.ï¿¼From Netflix to Bumble to Binance, the list includes nearly every popular app across all categories. There were recent reports of Zepto displaying different prices for iOS and Android users. With the help of this data, they can also show different pricing for different Android phones, which some customers are already seeing.Even though Swiggy and Zepto have to declare these apps to query in the manifest file, as a user, you have no visibility into this list when you download their apps from the Play Store.I also analyzed Swiggy and Zepto's apps for their delivery riders. The app query list is different from their consumer apps. Both include checks to see which other companies their riders work for. Hereâ€™s Zepto's list:But Swiggy takes it a step further - it also checks for personal loan apps, personal finance apps, and even keeps tabs on apps like like Ludo King or Carrom Pool on their delivery riders' phones.Can't we even play Ludo in peace without being spied on by our employers? Does even downtime need to be tracked by Swiggy? Itâ€™s embarrassing that Swiggy feels the need to include these ridiculous app queries on their delivery riders' phones.Speaking of personal loan apps in India, their predatory practices are well documented. A couple of years ago, there was a major crackdown that led to the removal of thousands of such apps from the Play Store. I took a look at some that still exist. Kreditbee is listed as one of the top apps in the personal loans space on the play store with over 50 million downloads. And can you believe their app checks for 860 apps installed on your phone? 860!!! I am sorry you may have to squint or zoom in a little to view this list. ï¿¼I only skimmed through this list - there are just too many apps. I hope someone reading this can do a thorough analysis. It's probably because of the bubble I live in, but I hadnâ€™t even heard of most of these apps. Even though most of them have tens of millions of downloads.Beyond the usual categories, I see there are checks for apps like Tamil Calendar, Odia Calendar, Qibla Direction Finder, mandir apps, astrology apps. They know what theyâ€™re doing.There is \"Jodii for Diploma, +2,10 below\", a matrimony app for those who havenâ€™t graduated high school. It has 10M+ downloads.Then there is also \"à¤—à¤¾à¤¯ à¤­à¥ˆà¤‚à¤¸ à¤–à¤°à¥€à¤¦à¥‡à¤‚ à¤¬à¥‡à¤šà¥‡à¤‚ Animall\" (cow buy/sell marketplace?) which also has more than 10M downloads.This list of apps is a window into how a large part of India uses their phones - their daily lives, habits, and priorities. Another leading personal loan app, Moneyview, with over 50 million downloads, has included checks for a staggering 944 apps in its manifest file - the highest among all the apps I examined. I am not including it in this post, you can read the full list here. I'm surprised KreditBee and Moneyview apps passed the Play Store's review. Play Store policy explicitly restricts personal loan apps from using the QUERY_ALL_PACKAGES permission.  But these apps are bypassing this restriction by individually listing every app they want to detect in their manifest file instead.I found only one manifest file which had the high-risk and sensitive QUERY_ALL_PACKAGES permission - it was Credâ€™s. Play Store grants a \"temporary exception\" to include this permission if apps have â€œa verifiable core purpose facilitating financial-transactions involving financially regulated instrumentsâ€.  But none of the other apps in the same segment as Cred I analyzed like PhonePe or PayTM had this permission in their manifest files. In fact, Cred offers personal loans too which as per Play Storeâ€™s Personal loans policy, is not eligible for this exception. Not sure how Cred is still allowed to keep this permission, which lets it see all the apps on your phone without any disclosures.I read the manifest files of around 50 popular apps from Indian companies. Apart from Swiggy, Zepto, Cred, and a couple of personal loan apps, most had fairly reasonable and respectful app query lists. Guess I expected worse. Maybe I am too cynical about these apps - could they actually be the good guys? ğŸ™ƒAs I was about to conclude this exercise, I noticed a couple of interesting lines when I was skimming through the manifest file of one of the apps:<queries>\n  [...]\n  <intent>\n    <action android:name=\"android.intent.action.MAIN\" />\n  </intent>\n  [...]\n</queries>I am no expert in Android development, but from what I understand, the \"ACTION_MAIN\" filter in the configuration above allows visibility to all installed apps that, simply put, have a screen.Since most installed apps run in the foreground and have a user interface, this filter grants developers access to see all the apps on your phone - without needing the QUERY_ALL_PACKAGES permission!To be sure, I vibe co -- I can't say it without wincing -- I vibe coded a basic android app and added the same \"ACTION_MAIN\" filter in my manifest file. And when I queried for installed packages, just as expected, this little hack returned a list of all the apps on my phone!!!This seems like a massive privacy loophole in Android. Surely Play Store would reject apps that use this hack as this is a blatant violation of their store's user data policy? Out of 47 Indian apps I randomly analyzed, 31 of them used the \"ACTION_MAIN\" filter - giving them access to see all the apps on your phone without any disclosure. That's 2 out of 3 apps.Apps using this hack: Astrotalk, Axis Mobile, Bajaj Finserv, BookMyShow, Cars24, Cure.fit, Fibe, Groww, Housing, Instamart, Ixigo, JioHotstar, KreditBee, KukuTV, LazyPay, Ludo King, Meesho, MoneyTap, Moneyview, Navi, NoBroker, Nykaa, Ola, PhonePe, PhysicsWallah, Slice, Spinny, Swiggy, Swiggy Delivery, Tata Neu, and Zomato.Apps that don't use this hack: Airtel Thanks, Blinkit, Byjuâ€™s, MyGate, Dream11, Flipkart, HDFC Mobile, Healthify, INDmoney, MyJio, Paytm, PaisaBazaar, ShareChat, Unacademy, Vedantu, ZeptoEven fucking Ludo King has this in its manifest file. So most Indian companies can actually see all the apps on your phone - they're just sneakier about it than the likes of Swiggy and Zepto. So much for being the good guys.In fact, Swiggy has got this filter config too, yet it still chooses to explicitly lists the apps it queries when it could just as easily do this discreetly behind closed doors like others. But Iâ€™m not complaining. This oversight from them gives a glimpse into Swiggyâ€™s data collection practices. If Google had enforced this policy properly, we might have had similar visibility into other companies as well.All the manifest files I read are in my Github. The majority were downloaded on March 18 or 19.This hack isnâ€™t exclusively used by apps from Indian companies. I checked the manifest files of some other popular apps. Facebook, Instagram, Snapchat, Subway Surfers, and Truecaller all have this config. Meanwhile, Amazon, Spotify, X, Discord, and WhatsApp didnâ€™t. I didnâ€™t investigate further beyond these.This makes me wonder, what was the whole purpose of Google's package visibility policy? It was supposed to protect users, yet most apps seem to have found ways around it anyway.And installed app data is very sensitive and personal. In 2022, Vice reported that a data marketplace called Narrative was selling data on users who had downloaded period-tracking apps right after news emerged that Roe v. Wade (which had federally protected abortion rights in the U.S.) could be overturned. This is frightening to even think about. Installed apps data is one data point. The extensive set of permissions each and every one of these apps have included in their manifest files, often far beyond whatâ€™s necessary is another can of worm for someone else to open. Iâ€™ll conclude this post with a tiny example from Zepto. They ask for READ_SMS permission. You can deny it, but itâ€™s mandatory if you sign up for Zepto Postpaid. When you grant the permission, this is the list of sender IDs they check for in your inbox:Most of them are TRAI sender IDs of banks. They're likely reading these for their Postpaid plan eligibility check. They can still read this even if you never opt for it. And look how they've sneaked in SMSes from Blinkit, Swiggy, Bigbasket, Flipkart too.Their competitors are probably doing the same, they just didnâ€™t leave behind such an obvious trail of evidence in the app itself. The point is when any app gets permissions like READ_SMS, as users, we have no visibility over when or what itâ€™s accessing.Please remember the next time you casually install an app on your Android device, this information is being broadcast to the whole world. Data brokers will use it to profile you, cross-reference it with data about you from other ad networks and eventually it will be used to decide how much youâ€™ll be asked to pay the next time you order a samosa.Thank you for reading. In case you subscribed to this newsletter after reading the \"What's inside this QR code menu at this cafe?\" post and can't find it anymore. Here's my tweet about it.I am also on Bluesky.Thanks for reading Pea Bee! Subscribe for free to receive new posts and support my work.Subscribe68Share this postPea BeeEveryone knows all the apps on your phoneCopy linkFacebookEmailNotesMore1013SharePrevious",
    "summary": {
      "en": "The article discusses privacy concerns regarding how certain Android apps, particularly from Indian companies like Swiggy, Zepto, and KreditBee, access information about other apps installed on users' phones. \n\nKey points include:\n\n1. **Changed Policies**: Google changed its policy in 2022 to restrict apps from seeing all installed apps on a phone without permission, but some apps still find ways around this.\n\n2. **Excessive Queries**: Some apps, like Swiggy and Zepto, have extensive lists of other apps they query, raising suspicion about user profiling and privacy violations. For example, Swiggy checks for 154 apps and Zepto for 165, even including irrelevant apps like gaming and finance apps.\n\n3. **Potential Loopholes**: Many apps utilize a loophole in Androidâ€™s system that allows them to see all installed apps without explicit permission, using a configuration called \"ACTION_MAIN\".\n\n4. **Wide Data Collection**: Some apps, particularly in the personal loan sector, check for hundreds of apps, which suggests they are gathering detailed user profiles, despite Googleâ€™s policies meant to protect user data.\n\n5. **Lack of Transparency**: Users are often unaware of what data is being collected or shared by the apps they install, which can lead to privacy breaches and misuse of their information.\n\nThe article emphasizes the importance of being cautious when installing apps, as they may be collecting sensitive data without users' knowledge.",
      "ko": "ì´ ê¸°ì‚¬ëŠ” íŠ¹ì • ì•ˆë“œë¡œì´ë“œ ì•±, íŠ¹íˆ ì¸ë„ ê¸°ì—…ì¸ ìŠ¤ìœ„ê¸°, ì œí”„í† , í¬ë ˆë”§ë¹„ì™€ ê°™ì€ ì•±ë“¤ì´ ì‚¬ìš©ì íœ´ëŒ€í°ì— ì„¤ì¹˜ëœ ë‹¤ë¥¸ ì•±ì— ëŒ€í•œ ì •ë³´ë¥¼ ì–´ë–»ê²Œ ì ‘ê·¼í•˜ëŠ”ì§€ì— ëŒ€í•œ ê°œì¸ì •ë³´ ë³´í˜¸ ë¬¸ì œë¥¼ ë‹¤ë£¨ê³  ìˆìŠµë‹ˆë‹¤.\n\nì²« ë²ˆì§¸ë¡œ, êµ¬ê¸€ì€ 2022ë…„ì— ì•±ì´ ì‚¬ìš©ìì˜ í—ˆê°€ ì—†ì´ ì„¤ì¹˜ëœ ëª¨ë“  ì•±ì„ ë³¼ ìˆ˜ ì—†ë„ë¡ ì •ì±…ì„ ë³€ê²½í–ˆì§€ë§Œ, ì—¬ì „íˆ ì¼ë¶€ ì•±ì€ ì´ë¥¼ ìš°íšŒí•˜ëŠ” ë°©ë²•ì„ ì°¾ê³  ìˆìŠµë‹ˆë‹¤. \n\në‘ ë²ˆì§¸ë¡œ, ìŠ¤ìœ„ê¸°ì™€ ì œí”„í† ì™€ ê°™ì€ ì•±ë“¤ì€ ë‹¤ë¥¸ ì•±ì— ëŒ€í•œ ì¿¼ë¦¬ê°€ ì§€ë‚˜ì¹˜ê²Œ ë§ì•„ ì‚¬ìš©ì í”„ë¡œíŒŒì¼ë§ê³¼ ê°œì¸ì •ë³´ ì¹¨í•´ì— ëŒ€í•œ ì˜êµ¬ì‹¬ì„ ë¶ˆëŸ¬ì¼ìœ¼í‚µë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ìŠ¤ìœ„ê¸°ëŠ” 154ê°œì˜ ì•±ì„ í™•ì¸í•˜ê³ , ì œí”„í† ëŠ” 165ê°œì˜ ì•±ì„ ì²´í¬í•˜ë©°, ê²Œì„ì´ë‚˜ ê¸ˆìœµ ì•±ê³¼ ê°™ì€ ê´€ë ¨ ì—†ëŠ” ì•±ë„ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n\nì„¸ ë²ˆì§¸ë¡œ, ë§ì€ ì•±ë“¤ì´ ì•ˆë“œë¡œì´ë“œ ì‹œìŠ¤í…œì˜ í—ˆì ì„ ì´ìš©í•´ ëª…ì‹œì ì¸ í—ˆê°€ ì—†ì´ ëª¨ë“  ì„¤ì¹˜ëœ ì•±ì„ ë³¼ ìˆ˜ ìˆëŠ” ë°©ë²•ì„ ì‚¬ìš©í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ë“¤ì€ \"ACTION_MAIN\"ì´ë¼ëŠ” ì„¤ì •ì„ í™œìš©í•©ë‹ˆë‹¤.\n\në„¤ ë²ˆì§¸ë¡œ, íŠ¹íˆ ê°œì¸ ëŒ€ì¶œ ë¶„ì•¼ì˜ ì¼ë¶€ ì•±ë“¤ì€ ìˆ˜ë°± ê°œì˜ ì•±ì„ í™•ì¸í•˜ë©°, ì´ëŠ” ì‚¬ìš©ìì— ëŒ€í•œ ìƒì„¸í•œ í”„ë¡œíŒŒì¼ì„ ìˆ˜ì§‘í•˜ê³  ìˆìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤. ì´ëŠ” êµ¬ê¸€ì˜ ì‚¬ìš©ì ë°ì´í„° ë³´í˜¸ ì •ì±…ì—ë„ ë¶ˆêµ¬í•˜ê³  ë°œìƒí•˜ëŠ” ì¼ì…ë‹ˆë‹¤.\n\në§ˆì§€ë§‰ìœ¼ë¡œ, ì‚¬ìš©ìë“¤ì€ ìì‹ ì´ ì„¤ì¹˜í•œ ì•±ì´ ì–´ë–¤ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê±°ë‚˜ ê³µìœ í•˜ëŠ”ì§€ ì˜ ì•Œì§€ ëª»í•˜ëŠ” ê²½ìš°ê°€ ë§ì•„ ê°œì¸ì •ë³´ ì¹¨í•´ì™€ ì •ë³´ ì˜¤ìš©ì˜ ìœ„í—˜ì— ì²˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ê¸°ì‚¬ëŠ” ì•± ì„¤ì¹˜ ì‹œ ì£¼ì˜ê°€ í•„ìš”í•˜ë‹¤ëŠ” ì ì„ ê°•ì¡°í•˜ê³  ìˆìŠµë‹ˆë‹¤.",
      "ja": "ã“ã®è¨˜äº‹ã§ã¯ã€ç‰¹ã«ã‚¤ãƒ³ãƒ‰ã®ä¼æ¥­ã§ã‚ã‚‹Swiggyã€Zeptoã€KreditBeeãªã©ã®ä¸€éƒ¨ã®Androidã‚¢ãƒ—ãƒªãŒã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ä»–ã®ã‚¢ãƒ—ãƒªã«é–¢ã™ã‚‹æƒ…å ±ã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ã“ã¨ã«é–¢ã™ã‚‹ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ã®æ‡¸å¿µã«ã¤ã„ã¦è¿°ã¹ã¦ã„ã¾ã™ã€‚\n\né‡è¦ãªãƒã‚¤ãƒ³ãƒˆã¨ã—ã¦ã€ã¾ãšGoogleã¯2022å¹´ã«ã€ã‚¢ãƒ—ãƒªãŒãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¨±å¯ãªã—ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã™ã¹ã¦ã®ã‚¢ãƒ—ãƒªã‚’è¦‹ã‚‹ã“ã¨ã‚’åˆ¶é™ã™ã‚‹æ–¹é‡ã‚’å¤‰æ›´ã—ã¾ã—ãŸãŒã€ä¸€éƒ¨ã®ã‚¢ãƒ—ãƒªã¯ä¾ç„¶ã¨ã—ã¦ã“ã®åˆ¶é™ã‚’å›é¿ã™ã‚‹æ–¹æ³•ã‚’è¦‹ã¤ã‘ã¦ã„ã¾ã™ã€‚\n\næ¬¡ã«ã€Swiggyã‚„Zeptoã®ã‚ˆã†ãªã‚¢ãƒ—ãƒªã¯ã€ä»–ã®ã‚¢ãƒ—ãƒªã«å¯¾ã—ã¦åºƒç¯„å›²ã«ã‚ãŸã‚‹å•ã„åˆã‚ã›ã‚’è¡Œã£ã¦ãŠã‚Šã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã‚„ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ä¾µå®³ã«ã¤ã„ã¦ç–‘å¿µã‚’æŠ±ã‹ã›ã¦ã„ã¾ã™ã€‚å…·ä½“çš„ã«ã¯ã€Swiggyã¯154ã®ã‚¢ãƒ—ãƒªã‚’ãƒã‚§ãƒƒã‚¯ã—ã€Zeptoã¯165ã®ã‚¢ãƒ—ãƒªã‚’ç¢ºèªã—ã¦ãŠã‚Šã€ã‚²ãƒ¼ãƒ ã‚„é‡‘èé–¢é€£ã®ã‚¢ãƒ—ãƒªãªã©ã€é–¢é€£æ€§ã®ãªã„ã‚¢ãƒ—ãƒªã‚‚å«ã¾ã‚Œã¦ã„ã¾ã™ã€‚\n\nã•ã‚‰ã«ã€å¤šãã®ã‚¢ãƒ—ãƒªã¯Androidã®ã‚·ã‚¹ãƒ†ãƒ ã«å­˜åœ¨ã™ã‚‹æŠœã‘ç©´ã‚’åˆ©ç”¨ã—ã¦ã€æ˜ç¤ºçš„ãªè¨±å¯ãªã—ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã™ã¹ã¦ã®ã‚¢ãƒ—ãƒªã‚’è¦‹ã‚‹ã“ã¨ãŒã§ãã‚‹ã€ŒACTION_MAINã€ã¨ã„ã†è¨­å®šã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚\n\nã¾ãŸã€ç‰¹ã«å€‹äººãƒ­ãƒ¼ãƒ³é–¢é€£ã®ã‚¢ãƒ—ãƒªã¯ã€æ•°ç™¾ã®ã‚¢ãƒ—ãƒªã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦ãŠã‚Šã€ã“ã‚Œã¯è©³ç´°ãªãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åé›†ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºå”†ã—ã¦ã„ã¾ã™ã€‚ã“ã‚Œã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’ä¿è­·ã™ã‚‹ãŸã‚ã®Googleã®æ–¹é‡ã«åã—ã¦ã„ã¾ã™ã€‚\n\næœ€å¾Œã«ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ãŸã‚¢ãƒ—ãƒªãŒã©ã®ã‚ˆã†ãªãƒ‡ãƒ¼ã‚¿ã‚’åé›†ã¾ãŸã¯å…±æœ‰ã—ã¦ã„ã‚‹ã®ã‹ã‚’çŸ¥ã‚‰ãªã„ã“ã¨ãŒå¤šãã€ã“ã‚ŒãŒãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ã®ä¾µå®³ã‚„æƒ…å ±ã®æ‚ªç”¨ã«ã¤ãªãŒã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ã“ã®è¨˜äº‹ã¯ã€ã‚¢ãƒ—ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹éš›ã«ã¯æ…é‡ã«ãªã‚‹ã“ã¨ã®é‡è¦æ€§ã‚’å¼·èª¿ã—ã¦ã„ã¾ã™ã€‚"
    }
  },
  {
    "id": "245bdd8a48ef8f5c",
    "title": {
      "en": "Towards fearless SIMD, 7 years later",
      "ko": "ë‘ë ¤ì›€ ì—†ëŠ” SIMD, 7ë…„ í›„",
      "ja": "æã‚ŒçŸ¥ã‚‰ãšã®SIMDã€7å¹´å¾Œ"
    },
    "type": "story",
    "url": "https://linebender.org/blog/towards-fearless-simd/",
    "score": 46,
    "by": "raphlinus",
    "time": 1743292320,
    "content": "Towards fearless SIMD, 7 years later\nRaph Levien, March 29, 2025\nSeven years ago I wrote a blog post Towards fearless SIMD, outlining a vision for Rust as a compelling language for writing fast SIMD programs.\nWhere are we now?\nUnfortunately, the present-day experience of writing SIMD in Rust is still pretty rough, though there has been progress, and there are promising efforts underway.\nAs in the previous post, this post will outline a possible vision.\nUp to now, Linebender projects have not used SIMD, but that is changing.\nAs we work on CPU/GPU hybrid rendering techniques, it's clear that we need SIMD to get maximal performance of the CPU side.\nWe also see opportunities in faster color conversion and accelerated 2D geometry primitives.\nThis blog post is also a companion to a podcast I recorded recently with AndrÃ© Popovitch.\nThat podcast is a good introduction to SIMD concepts, while this blog post focuses more on future directions.\nA simple example\nAs a running example, we'll compute a sigmoid function for a vector of 4 values.\nThe scalar version is as follows:\nfn sigmoid(x: [f32; 4]) -> [f32; 4] {\n    x.map(|y| y / (1.0 + y * y).sqrt())\n}\n\nThis particular simple code autovectorizes nicely (Godbolt link), but more complex examples often fail to autovectorize, often because of subtle differences in floating point semantics.\n(Editorial note: a previous version of this post didn't autovectorize (Godbolt) because optimization level was set at -O, which is less aggressive than -C opt-level=3, the latter of which is the default for release builds)\nSafety\nOne of the biggest problems with writing SIMD in Rust is that all exposed SIMD intrinsics are marked as unsafe, even in cases where they can be used safely.\nThe reason is that support for SIMD features varies widely, and executing a SIMD instruction on a CPU that does not support it is undefined behavior â€“ the chip can crash, ignore the instruction, or do something unexpected.\nTo be used safely, there must be some other mechanism to establish that the CPU does support the feature.\nHere's the running example in hand-written intrinsic code, showing the need to write unsafe to access SIMD intrinsics at all:\n#[cfg(target_arch = \"aarch64\")]\nfn sigmoid_neon(x: [f32; 4]) -> [f32; 4] {\n    use core::arch::aarch64::*;\n    unsafe {\n        let x_simd = core::mem::transmute(x);\n        let x_squared = vmulq_f32(x_simd, x_simd);\n        let ones = vdupq_n_f32(1.0);\n        let sum = vaddq_f32(ones, x_squared);\n        let sqrt = vsqrtq_f32(sum);\n        let ratio = vdivq_f32(x_simd, sqrt);\n        core::mem::transmute(ratio)\n    }\n}\n\n#[cfg(target_arch = \"x86_64\")]\nfn sigmoid_sse2(x: [f32; 4]) -> [f32; 4] {\n    use core::arch::x86_64::*;\n    unsafe {\n        let x_simd = core::mem::transmute(x);\n        let x_squared = _mm_mul_ps(x_simd, x_simd);\n        let ones = _mm_set1_ps(1.0);\n        let sum = _mm_add_ps(ones, x_squared);\n        let sqrt = _mm_sqrt_ps(sum);\n        let ratio = _mm_div_ps(x_simd, sqrt);\n        core::mem::transmute(ratio)\n    }\n}\n\nThis is quite a simplified example.\nFor one, the SIMD width is fixed at 4 lanes (128 bits).\nMost likely, in practice you'd iterate over a larger slice, taking chunks equal to the natural SIMD width.\nMultiversioning\nA central problem important for SIMD is multiversioning and runtime dispatch.\nIn some cases, you know the exact CPU target, for example when compiling a binary you'll run only on your machine (in which case target-cpu=native is appropriate).\nBut when distributing software more widely, there may be a range of capabilities.\nFor highest performance, it's necessary to compile multiple versions of the code, and do runtime detection to dispatch to the best SIMD code the hardware can run.\nThis problem was expressed in the original fearless SIMD blog post, and there hasn't been significant advance at the Rust language level since then.\nIn the C++ world, the Highway library provides excellent SIMD support for a very wide range of targets, and also solves the multiversioning problem.\nAmong other uses are the codecs for the JPEG-XL image format.\nSuch codecs are an ideal use case for SIMD programming in general, and shipping them in a browser requires a good solution to multiversioning.\nHighway has a really good explanation of their approach to multiversioning.\nIt will be useful to study it carefully to see how they've solved various problems.\nAnd a concise way of saying what I'd like to see is \"Highway for Rust.\"\nOne possible approach is a crate called multiversion, which uses macros to replicate the code for multiple versions.\nA more recent macro-based approach is rust-target-feature-dispatch.\nIt is generally a similar approach to multiversion, and the specific differences are set out in that crate's README.\nAnother approach, as I believe first advocated in my 2018 blog post, is to write functions polymorphic on a zero-sized type representing the SIMD capabilities, then rely on monomorphization to create the various versions.\nOne motivation for this approach is to encode safety in Rust's type system.\nHaving the zero-sized token is proof of the underlying CPU having a certain level of SIMD capability, so calling those intrinsics is safe.\nA major library that uses this approach is pulp, which also powers the faer linear algebra library.\nI started putting together a pulp version of the running example, but ran into the immediate problem that it lacks a sqrt intrinsic (this would be easy enough to add, however).\nIt also works a bit differently, in that it only supports vectors of the natural width, not ones of a fixed width.\nFor general linear algebra, that's fine, but for some other applications it adds friction, for example colors with alpha are naturally chunks of 4 scalars.\nTo see an example of pulp code, as well as some discussion, see this Zulip thread.\nIn fearless_simd#2 I propose a prototype of reasonably-ergonomic SIMD multiversioning.\nLike the original fearless_simd prototype, vector data types are polymorphic on SIMD level.\nThe new prototype goes beyond that in several important ways.\nFor one, arithmetic traits in std::ops are implemented for vector types, so it's possible to add two vectors together, multiply vectors by scalars, etc.\nHere's what the running example looks like in that prototype:\n#[inline(always)]\nfn sigmoid_impl<S: Simd>(simd: S, x: [f32; 4]) -> [f32; 4] {\n    let x_simd: f32x4<S> = x.simd_into(simd);\n    (x_simd / (1.0 + x_simd * x_simd).sqrt()).into()\n}\n\nsimd_dispatch!(sigmoid(level, rgba: [f32; 4]) -> [f32; 4] = sigmoid_impl);\n\nAn advantage of the fearless_simd#2 prototype over pulp is a feature for downcasting based on SIMD level, so it's possible to write different code optimized for different chips.\nSee the srgb example in that pull request for more detail.\nThough there are clear advantages, at this point I'm not sure whether this is the direction to go.\nIt would be a lot of work to build out all the needed types and operations, with potentially a large amount of repetitive boilerplate code in the library, which in turn may cause issues with compile time.\nAnother possible direction is a smarter, compiler-like proc macro which synthesizes the SIMD intrinsics as needed based on the types and operations in the source program.\nOne additional consideration for Rust is that the implementation of runtime feature detection is slower than it should be.\nThus, feature detection and dispatch shouldn't be done at every function call.\nA good working solution is to do feature detection once, at the start of the program, then pass that token down through function calls.\nIt's workable but definitely an ergonomic paper cut.\nFP16 and AVX-512\nA general trend in parallel computation, really fueled by AI workloads, is smaller scalars with higher throughputs.\nWhile not yet common on x86_64, the FP16 extension is supported on all Apple Silicon desktop CPUs and most recent high-ish end ARM-based phones.\nSince Neon is only 128 bits wide, having 8 lanes is welcome.\nI find the f16 format to be especially useful for pixel values, as it can encode color values with more than enough precision to avoid visual artifacts (8 bits is not quite enough, though it is good enough for some applications, as long as you're not trying to do HDR).\nNative Rust support for the f16 type has not yet landed (tracked in rust#125440), which makes use of this scalar size harder.\nHowever, there is some support in the half library, and also the fearless_simd#2 prototype exports a number of FP16 Neon instructions through inline assembly.\nWhen true f16 support lands, it will be possible to switch over to intrinsics, which will have better optimization and ergonomics (for example, the same method will splat constants converted to f16 at compile time and f32 variables to be converted at runtime).\nAVX-512 is a somewhat controversial SIMD capability.\nIt first appeared in the ill-fated Larrabee project, which shipped in limited numbers as the Xeon Phi starting in 2010, and has since appeared in scattered Intel CPUs, but with compromises.\nIn particular, sprinkling even a small amount of AVX-512 code into a program could result in downclocking, reducing performance for all workloads (see Stack Overflow thread on throttling for more details).\nThese days, the most likely way to get a CPU with AVX-512 is an AMD Zen 4 or Zen 5; it is on their strength that AVX-512 makes up about 16% of computers in the Steam hardware survey.\nThe increased width is not the main reason to be enthusiastic about AVX-512.\nIndeed, on Zen 4 and most Zen 5 chips, the datapath is 256 bits so full 512 bit instructions are \"double pumped.\" The most exciting aspect is predication based on masks, a common implementation technique on GPUs.\nIn particular, memory load and store operations are safe when the mask bit is zero, which is especially helpful for using SIMD efficiently on strings.\nWithout predication, a common technique is to write two loops, the first handling only even multiples of the SIMD width, and a second, usually written as scalars, to handle the odd-size \"tail\".\nThere are lots of problems with this - code bloat, worse branch prediction, inability to exploit SIMD for chunks slightly less than the natural SIMD width (which gets worse as SIMD grows wider), and risks that the two loops don't have exactly the same behavior.\nGoing forward, Intel has proposed AVX10, and will hopefully ship AVX 10.2 chips in the next few years.\nThis extension has pretty much all of the features of AVX-512, with some cleanups and new features (until recently, AVX10 was defined has having a 256 bit base width and optionally 512, but 512 is now the baseline).\nIn addition, AVX10.2 will include 16-bit floats (currently available only in the Sapphire Rapids high-end server and workstation chips).\nAbout std::simd\nThe \"portable SIMD\" work has been going on for many years and currently has a home as the nightly std::simd.\nWhile I think it will be very useful in many applications, I am not personally very excited about it for my applications.\nFor one, because it emphasizes portability, it encourages a \"lowest common denominator\" approach, while I believe that for certain use cases it will be important to tune algorithms to best use the specific quirks of the different SIMD implementations.\nFor two, std::simd does not itself solve the multiversion problem.\nFrom my perspective, it's probably best to consider it as a souped-up version of autovectorization.\nLanguage evolution\nRust's out of the box support for SIMD is still quite rough, especially the need to use unsafe extensively.\nWhile some of the gap can be filled with libraries, arguably it should be a goal of the language itself to support safe SIMD code.\nThere is progress in this direction.\nFirst, the original version of target_feature requires unsafe to call into any function annotated with #[target_feature].\nA proposal to relax that so that functions already under a target_feature gate can call safely call into another function with the same gate is called \"target_feature 1.1\" and is scheduled to ship in 1.86.\nClosely related, once inside the suitable target_feature gate, the majority of SIMD intrinsics (broadly, those that don't do memory access through pointers) should be considered safe by the compiler, and that feature (safe intrinsics in core::arch) is also in flight.\nThere's more that can be done to help the Rust compiler recognize when SIMD use is safe, in particular to allow target_features when a concrete witness to the SIMD level is passed in as a function argument.\nThe \"struct target_features\" proposal (RFC 3525) enables target_feature in such cases, and is one of the proposals considered in the proposed Rust project goal Nightly support for ergonomic SIMD multiversioning.\nIn general, improving Rust SIMD support will require both libraries and support in the Rust language.\nDifferent approaches at the library level may indicate different language features to best support them.\nLooking forward\nMy main goal in putting these prototypes forward, as well as writing these blog posts, is to spark conversation on how best to support SIMD programming in Rust.\nIf done well, it is a great opportunity for the language, and fits in with its focus on performance and portability.\nAs we build out the Vello hybrid CPU/GPU renderer, performance of the CPU components will rely heavily on SIMD, so we need to invest in writing a lot of SIMD code.\nThe most conservative approach would be hand-writing unsafe intrinsics-based code for all targets, but that's a lot of work and the use of unsafe is unappealing.\nI'd love for the Rust ecosystem can come together and build good infrastructure, competitive with Highway.\nFor now, I think it's time to carefully consider the design space and try to come to consensus on what that should look like.",
    "summary": {
      "en": "### Summary of \"Towards Fearless SIMD, 7 Years Later\"\n\nIn March 2025, Raph Levien revisits his earlier vision for improving SIMD (Single Instruction, Multiple Data) programming in Rust. Although there has been some progress, writing SIMD in Rust remains challenging. The need for SIMD is highlighted by new projects using CPU/GPU hybrid rendering techniques.\n\nA key issue is that SIMD intrinsics in Rust are marked as unsafe due to the varying support across CPUs. This means developers must ensure the CPU can handle SIMD instructions, which complicates code safety.\n\nLevien provides examples of computing a sigmoid function using SIMD, showcasing the complexity of writing safe and efficient SIMD code. He discusses multiversioning, which allows the same code to run optimally on different CPU architectures, but notes that Rust lacks robust solutions compared to libraries like Highway in C++.\n\nThe article also touches on the trends in SIMD, such as the growing use of smaller scalar types like FP16 for better performance, and mentions upcoming features in Intel's AVX10. Additionally, he discusses the ongoing development of the `std::simd` library, though he expresses concerns about its focus on portability over performance optimization.\n\nLevien emphasizes the need for Rust to improve its SIMD support, making it safer and more ergonomic, and encourages community discussion on how to achieve this. He believes that enhancing SIMD capabilities in Rust is crucial for the language's performance and usability in future projects.",
      "ko": "2025ë…„ 3ì›”, ë˜í”„ ë ˆë¹„ì—”ì€ ëŸ¬ìŠ¤íŠ¸ì—ì„œ SIMD(ë‹¨ì¼ ëª…ë ¹, ë‹¤ì¤‘ ë°ì´í„°) í”„ë¡œê·¸ë˜ë°ì„ ê°œì„ í•˜ê¸° ìœ„í•œ ìì‹ ì˜ ì´ˆê¸° ë¹„ì „ì„ ë‹¤ì‹œ ì‚´í´ë´…ë‹ˆë‹¤. ì¼ë¶€ ì§„ì „ì´ ìˆì—ˆì§€ë§Œ, ëŸ¬ìŠ¤íŠ¸ì—ì„œ SIMDë¥¼ ì‘ì„±í•˜ëŠ” ê²ƒì€ ì—¬ì „íˆ ì–´ë ¤ìš´ ê³¼ì œë¡œ ë‚¨ì•„ ìˆìŠµë‹ˆë‹¤. CPUì™€ GPUë¥¼ í˜¼í•©í•œ ë Œë”ë§ ê¸°ìˆ ì„ ì‚¬ìš©í•˜ëŠ” ìƒˆë¡œìš´ í”„ë¡œì íŠ¸ë“¤ì´ ë“±ì¥í•˜ë©´ì„œ SIMDì˜ í•„ìš”ì„±ì´ ë”ìš± ë¶€ê°ë˜ê³  ìˆìŠµë‹ˆë‹¤.\n\nì£¼ìš” ë¬¸ì œ ì¤‘ í•˜ë‚˜ëŠ” ëŸ¬ìŠ¤íŠ¸ì˜ SIMD ë‚´ì¥ í•¨ìˆ˜ê°€ CPUë§ˆë‹¤ ì§€ì›ì´ ë‹¤ë¥´ê¸° ë•Œë¬¸ì— ì•ˆì „í•˜ì§€ ì•Šì€ ê²ƒìœ¼ë¡œ í‘œì‹œëœë‹¤ëŠ” ì ì…ë‹ˆë‹¤. ì´ëŠ” ê°œë°œìê°€ CPUê°€ SIMD ëª…ë ¹ì–´ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ”ì§€ í™•ì¸í•´ì•¼ í•¨ì„ ì˜ë¯¸í•˜ë©°, ì½”ë“œì˜ ì•ˆì „ì„±ì„ ë³µì¡í•˜ê²Œ ë§Œë“­ë‹ˆë‹¤.\n\në ˆë¹„ì—”ì€ SIMDë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜ë¥¼ ê³„ì‚°í•˜ëŠ” ì˜ˆë¥¼ ì œê³µí•˜ë©°, ì•ˆì „í•˜ê³  íš¨ìœ¨ì ì¸ SIMD ì½”ë“œë¥¼ ì‘ì„±í•˜ëŠ” ë³µì¡ì„±ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ê·¸ëŠ” ë©€í‹°ë²„ì „í™”ì— ëŒ€í•´ ë…¼ì˜í•˜ë©°, ë™ì¼í•œ ì½”ë“œê°€ ë‹¤ì–‘í•œ CPU ì•„í‚¤í…ì²˜ì—ì„œ ìµœì ì˜ ì„±ëŠ¥ì„ ë°œíœ˜í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ë°©ë²•ì„ ì„¤ëª…í•˜ì§€ë§Œ, ëŸ¬ìŠ¤íŠ¸ëŠ” C++ì˜ í•˜ì´ì›¨ì´ì™€ ê°™ì€ ë¼ì´ë¸ŒëŸ¬ë¦¬ì— ë¹„í•´ ê°•ë ¥í•œ ì†”ë£¨ì…˜ì´ ë¶€ì¡±í•˜ë‹¤ê³  ì§€ì í•©ë‹ˆë‹¤.\n\nì´ ê¸€ì€ ë˜í•œ SIMDì˜ íŠ¸ë Œë“œì— ëŒ€í•´ ë‹¤ë£¨ë©°, ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•´ FP16ê³¼ ê°™ì€ ë” ì‘ì€ ìŠ¤ì¹¼ë¼ íƒ€ì…ì˜ ì‚¬ìš©ì´ ì¦ê°€í•˜ê³  ìˆìŒì„ ì–¸ê¸‰í•˜ê³ , ì¸í…”ì˜ AVX10ì—ì„œ ê³§ ì¶œì‹œë  ê¸°ëŠ¥ì— ëŒ€í•´ì„œë„ ì´ì•¼ê¸°í•©ë‹ˆë‹¤. ë”ë¶ˆì–´ `std::simd` ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ì§€ì†ì ì¸ ê°œë°œì— ëŒ€í•´ì„œë„ ë…¼ì˜í•˜ì§€ë§Œ, ì„±ëŠ¥ ìµœì í™”ë³´ë‹¤ ì´ì‹ì„±ì— ì¤‘ì ì„ ë‘ê³  ìˆëŠ” ì ì— ëŒ€í•œ ìš°ë ¤ë¥¼ í‘œëª…í•©ë‹ˆë‹¤.\n\në ˆë¹„ì—”ì€ ëŸ¬ìŠ¤íŠ¸ê°€ SIMD ì§€ì›ì„ ê°œì„ í•˜ì—¬ ë” ì•ˆì „í•˜ê³  ì‚¬ìš©í•˜ê¸° í¸ë¦¬í•˜ê²Œ ë§Œë“¤ì–´ì•¼ í•œë‹¤ê³  ê°•ì¡°í•˜ë©°, ì´ë¥¼ ë‹¬ì„±í•˜ê¸° ìœ„í•œ ì»¤ë®¤ë‹ˆí‹°ì˜ ë…¼ì˜ë¥¼ ì´‰êµ¬í•©ë‹ˆë‹¤. ê·¸ëŠ” ëŸ¬ìŠ¤íŠ¸ì—ì„œ SIMD ê¸°ëŠ¥ì„ ê°•í™”í•˜ëŠ” ê²ƒì´ í–¥í›„ í”„ë¡œì íŠ¸ì˜ ì„±ëŠ¥ê³¼ ì‚¬ìš©ì„±ì„ ìœ„í•´ ë§¤ìš° ì¤‘ìš”í•˜ë‹¤ê³  ë¯¿ê³  ìˆìŠµë‹ˆë‹¤.",
      "ja": "2025å¹´3æœˆã€ãƒ©ãƒ•ãƒ»ãƒ¬ãƒ“ã‚¨ãƒ³ã¯ã€Rustã«ãŠã‘ã‚‹SIMDï¼ˆå˜ä¸€å‘½ä»¤ãƒ»è¤‡æ•°ãƒ‡ãƒ¼ã‚¿ï¼‰ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã®æ”¹å–„ã«é–¢ã™ã‚‹ä»¥å‰ã®ãƒ“ã‚¸ãƒ§ãƒ³ã‚’å†æ¤œè¨ã—ã¾ã—ãŸã€‚é€²å±•ã¯ã‚ã£ãŸã‚‚ã®ã®ã€Rustã§ã®SIMDã®è¨˜è¿°ã¯ä¾ç„¶ã¨ã—ã¦é›£ã—ã„ã¾ã¾ã§ã™ã€‚SIMDã®å¿…è¦æ€§ã¯ã€CPUã¨GPUã‚’çµ„ã¿åˆã‚ã›ãŸãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°æŠ€è¡“ã‚’ä½¿ç”¨ã™ã‚‹æ–°ã—ã„ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«ã‚ˆã£ã¦å¼·èª¿ã•ã‚Œã¦ã„ã¾ã™ã€‚\n\né‡è¦ãªå•é¡Œã®ä¸€ã¤ã¯ã€Rustã®SIMDå‘½ä»¤ãŒCPUã«ã‚ˆã£ã¦ç•°ãªã‚‹ã‚µãƒãƒ¼ãƒˆçŠ¶æ³ã®ãŸã‚ã«ã€Œunsafeã€ã¨ãƒãƒ¼ã‚¯ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã§ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€é–‹ç™ºè€…ã¯CPUãŒSIMDå‘½ä»¤ã‚’å‡¦ç†ã§ãã‚‹ã“ã¨ã‚’ç¢ºèªã™ã‚‹å¿…è¦ãŒã‚ã‚Šã€ã‚³ãƒ¼ãƒ‰ã®å®‰å…¨æ€§ãŒè¤‡é›‘ã«ãªã‚Šã¾ã™ã€‚\n\nãƒ¬ãƒ“ã‚¨ãƒ³ã¯ã€SIMDã‚’ä½¿ç”¨ã—ã¦ã‚·ã‚°ãƒ¢ã‚¤ãƒ‰é–¢æ•°ã‚’è¨ˆç®—ã™ã‚‹ä¾‹ã‚’ç¤ºã—ã€å®‰å…¨ã§åŠ¹ç‡çš„ãªSIMDã‚³ãƒ¼ãƒ‰ã‚’æ›¸ãã“ã¨ã®è¤‡é›‘ã•ã‚’æµ®ãå½«ã‚Šã«ã—ã¦ã„ã¾ã™ã€‚ã¾ãŸã€ç•°ãªã‚‹CPUã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§åŒã˜ã‚³ãƒ¼ãƒ‰ãŒæœ€é©ã«å‹•ä½œã™ã‚‹ã‚ˆã†ã«ã™ã‚‹ã€Œãƒãƒ«ãƒãƒãƒ¼ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°ã€ã«ã¤ã„ã¦ã‚‚è¨€åŠã—ã¦ã„ã¾ã™ãŒã€Rustã¯C++ã®Highwayã®ã‚ˆã†ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã«æ¯”ã¹ã¦å …ç‰¢ãªè§£æ±ºç­–ãŒä¸è¶³ã—ã¦ã„ã‚‹ã¨æŒ‡æ‘˜ã—ã¦ã„ã¾ã™ã€‚\n\nè¨˜äº‹ã§ã¯ã€FP16ã®ã‚ˆã†ãªå°ã•ãªã‚¹ã‚«ãƒ©ãƒ¼å‹ã®ä½¿ç”¨ãŒå¢—ãˆã¦ã„ã‚‹ã“ã¨ã‚„ã€Intelã®AVX10ã«é–¢ã™ã‚‹ä»Šå¾Œã®æ©Ÿèƒ½ã«ã¤ã„ã¦ã‚‚è§¦ã‚Œã¦ã„ã¾ã™ã€‚ã•ã‚‰ã«ã€`std::simd`ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®é–‹ç™ºãŒé€²è¡Œä¸­ã§ã‚ã‚‹ã“ã¨ã‚’è¿°ã¹ã¤ã¤ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã‚ˆã‚Šã‚‚ãƒãƒ¼ã‚¿ãƒ“ãƒªãƒ†ã‚£ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ã‚‹ã“ã¨ã«æ‡¸å¿µã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚\n\nãƒ¬ãƒ“ã‚¨ãƒ³ã¯ã€RustãŒSIMDã‚µãƒãƒ¼ãƒˆã‚’æ”¹å–„ã—ã€å®‰å…¨ã§ä½¿ã„ã‚„ã™ãã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã¨å¼·èª¿ã—ã€ã“ã‚Œã‚’é”æˆã™ã‚‹ãŸã‚ã®ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã®è­°è«–ã‚’ä¿ƒã—ã¦ã„ã¾ã™ã€‚å½¼ã¯ã€Rustã«ãŠã‘ã‚‹SIMDæ©Ÿèƒ½ã®å¼·åŒ–ãŒã€å°†æ¥ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«ãŠã‘ã‚‹è¨€èªã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨ä½¿ã„ã‚„ã™ã•ã«ã¨ã£ã¦é‡è¦ã§ã‚ã‚‹ã¨è€ƒãˆã¦ã„ã¾ã™ã€‚"
    }
  },
  {
    "id": "a9c10bd2b59ddc15",
    "title": {
      "en": "Atop 2.11 heap problems",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://openwall.com/lists/oss-security/2025/03/29/1",
    "score": 93,
    "by": "baggy_trough",
    "time": 1743281022,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "845551732f95874d",
    "title": {
      "en": "Commercials that David Lynch directed (2018)",
      "ko": "ë¦°ì¹˜ì˜ ê´‘ê³  ì„¸ê³„",
      "ja": "ãƒªãƒ³ãƒã®CMé›†"
    },
    "type": "story",
    "url": "https://www.openculture.com/2018/07/watch-commercials-david-lynch-directed-big-30-minute-compilation.html",
    "score": 95,
    "by": "bookofjoe",
    "time": 1743280281,
    "content": "Some filmÂ­makÂ­ers start in comÂ­merÂ­cials, honÂ­ing their chops in anticÂ­iÂ­paÂ­tion of makÂ­ing perÂ­sonÂ­al projects latÂ­er. A select few go in the othÂ­er direcÂ­tion, realÂ­izÂ­ing their disÂ­tincÂ­tive vision before fieldÂ­ing offers from comÂ­paÂ­nies who want a piece of that visionâ€™s culÂ­turÂ­al curÂ­renÂ­cy. AnyÂ­one whoâ€™s seen David Lynchâ€™s most acclaimed workwill susÂ­pect, corÂ­rectÂ­ly, that Lynch belongs in the latÂ­ter group. With 1977â€™s cult hitEraserÂ­head, he showed cinÂ­eÂ­ma what it means to be LynchiÂ­an. This brought him the attenÂ­tion of HolÂ­lyÂ­wood, leadÂ­ing to the respectable sucÂ­cess ofThe EleÂ­phant Manandthe disÂ­asÂ­ter that wasDune. Only in 1986, withBlue VelÂ­vet, could Lynch make a truÂ­ly, even trouÂ­blingÂ­ly perÂ­sonÂ­al film that hit the zeitÂ­geist at just the right moment.\nNatÂ­uÂ­ralÂ­ly, MadiÂ­son Avenue came callÂ­ing soon thereÂ­after. â€œWith the smash Blue VelÂ­vet, a Palme dâ€™or at Cannes for Wild at Heart, and then the nationÂ­al pheÂ­nomÂ­eÂ­non of Twin Peaksâ€™ first seaÂ­son, David Lynch clearÂ­ly estabÂ­lished himÂ­self as the U.S.A.â€˜s foreÂ­most comÂ­merÂ­cialÂ­ly viable avant-garde-â€˜offbeatâ€™ direcÂ­tor,â€ wrote David FosÂ­ter WalÂ­lace in a 1997 piece on the filmÂ­makÂ­er.\n\nâ€œFor a while there it looked like he might be able to sinÂ­gle-handÂ­edÂ­ly broÂ­ker a new marÂ­riage between art and comÂ­merce in U.S. movies, openÂ­ing forÂ­muÂ­la-frozen HolÂ­lyÂ­wood to some of the eccenÂ­tricÂ­iÂ­ty and vigÂ­or of art film.â€Lynchâ€™s fans in teleÂ­viÂ­sion adverÂ­tisÂ­ing must have imagÂ­ined that he could do the same for their indusÂ­try, and you can watch the fruits of that hunch in the half-hour comÂ­piÂ­laÂ­tion of Lynch-directÂ­ed comÂ­merÂ­cials above.\nLynch has worked for some starÂ­tlingÂ­ly big brands, beginÂ­ning with Calvin Klein: his trio of spots for the fraÂ­granceObsesÂ­sion take as their basis the writÂ­ing of F. Scott FitzgerÂ­ald, Ernest HemÂ­ingÂ­way, and D.H. Lawrence. A few years latÂ­er he directÂ­ed a humorÂ­ous mini-seaÂ­son of Twin Peaks to proÂ­mote GeorÂ­gia CofÂ­fee, one of the top brands of canned cofÂ­fee in theLynch-lovÂ­ing counÂ­try ofJapan. The New York DepartÂ­ment of SanÂ­iÂ­taÂ­tion engaged Lynchâ€™s serÂ­vices to imbue their anti-litÂ­terÂ­ing camÂ­paign with his sigÂ­naÂ­ture high-conÂ­trast omiÂ­nousÂ­ness, a mood also sought by fashÂ­ion-indusÂ­try titans like Armani, Yves Saint LauÂ­rent, GucÂ­ci, and Dior. The marÂ­keters of humÂ­bler goods like Alka-Seltzer, BarÂ­ilÂ­la PasÂ­ta (a seemÂ­ingÂ­ly auteur-aware brand that has also hired Wim WenÂ­ders and FelliÂ­ni), and Clear Blue Easy home pregÂ­nanÂ­cy tests have also gone in for a touch of the LynchiÂ­an.\nQuite a few of these comÂ­merÂ­cials origÂ­iÂ­nalÂ­ly aired only outÂ­side AmerÂ­iÂ­ca, which may reflect the supÂ­posÂ­edÂ­ly more endurÂ­ing appreÂ­ciÂ­aÂ­tion of Lynchâ€™s work that exists in Europe and Asia. But for all Lynchâ€™s artisÂ­tic darÂ­ing, the man himÂ­self has always come off as an enthuÂ­siÂ­ast of unreÂ­conÂ­structÂ­ed AmerÂ­iÂ­can pleaÂ­sures. To this day he remains a steadÂ­fast smokÂ­er, and in 1998 brought that perÂ­sonÂ­al credÂ­iÂ­bilÂ­iÂ­ty to the Swiss cigÂ­aÂ­rette brand ParisiÂ­enne. The resultÂ­ing spot feaÂ­tures men in ties, showÂ­ers of sparks, dead fish, backÂ­wards talkÂ­ing, a forÂ­bidÂ­dingÂ­ly illuÂ­miÂ­natÂ­ed shack, and apocÂ­aÂ­lypÂ­tic flames:ParisiÂ­enne, in othÂ­er words, must have got exactÂ­ly what they paid for.\nRelatÂ­ed ConÂ­tent:\nWhat Makes a David Lynch Film LynchiÂ­an: A Video Essay\nDavid Lynch Made a DisÂ­turbÂ­ing Web SitÂ­com Called â€œRabÂ­bitsâ€: Itâ€™s Now Used by PsyÂ­cholÂ­oÂ­gists to Induce a Sense of ExisÂ­tenÂ­tial CriÂ­sis in Research SubÂ­jects\nThe SurÂ­reÂ­al FilmÂ­makÂ­ing of David Lynch Explained in 9 Video Essays\nWim WenÂ­ders CreÂ­ates Ads to Sell Beer (StelÂ­la Artois), PasÂ­ta (BarÂ­ilÂ­la), and More Beer (CarÂ­ling)\nSpike Jonzeâ€™s ImagÂ­iÂ­naÂ­tive TV Ads\nFelliniâ€™s FanÂ­tasÂ­tic TV ComÂ­merÂ­cials\nIngÂ­mar Bergmanâ€™s 1950s Soap ComÂ­merÂ­cials Wash Away the ExisÂ­tenÂ­tial Despair\nBased in Seoul,ColÂ­in MarÂ­shallwrites and broadÂ­castson cities and culÂ­ture.His projects include the bookThe StateÂ­less City: a Walk through 21st-CenÂ­tuÂ­ry Los AngeÂ­lesand the video seriesThe City in CinÂ­eÂ­ma. FolÂ­low him on TwitÂ­ter at@colinmarshallor onFaceÂ­book.",
    "summary": {
      "en": "Some filmmakers start by making commercials before moving on to personal projects, while others, like David Lynch, gain recognition through their unique artistic visions early on. Lynch became famous with his 1977 film \"Eraserhead,\" which led to Hollywood opportunities, including the successful \"The Elephant Man\" and the less successful \"Dune.\" His 1986 film \"Blue Velvet\" was a personal success that resonated with audiences, and soon after, he was sought after for commercials.\n\nLynch worked with major brands like Calvin Klein, directing ads that drew from classic literature, and created a humorous mini-series of \"Twin Peaks\" to promote Georgia Coffee in Japan. He also collaborated on campaigns for the New York Department of Sanitation and high-end fashion brands like Armani and Dior. Many of his commercials aired primarily outside the U.S., reflecting his broader appeal in Europe and Asia.\n\nDespite his artistic edge, Lynch enjoys classic American pleasures, as shown in his 1998 ad for a Swiss cigarette brand, which featured his signature surreal style.",
      "ko": "ì¼ë¶€ ì˜í™” ì œì‘ìë“¤ì€ ê°œì¸ í”„ë¡œì íŠ¸ë¡œ ë„˜ì–´ê°€ê¸° ì „ì— ê´‘ê³ ë¥¼ ì œì‘í•˜ëŠ” ê²ƒìœ¼ë¡œ ì‹œì‘í•©ë‹ˆë‹¤. ë°˜ë©´, ë°ì´ë¹„ë“œ ë¦°ì¹˜ì™€ ê°™ì€ ì´ë“¤ì€ ë…íŠ¹í•œ ì˜ˆìˆ ì  ë¹„ì „ì„ í†µí•´ ì¼ì°ì´ ì¸ì •ì„ ë°›ìŠµë‹ˆë‹¤. ë¦°ì¹˜ëŠ” 1977ë…„ ì˜í™” \"ì´ë ˆì´ì €í—¤ë“œ\"ë¡œ ìœ ëª…í•´ì¡Œê³ , ì´ ì˜í™”ëŠ” í• ë¦¬ìš°ë“œì—ì„œì˜ ê¸°íšŒë¥¼ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤. ê·¸ëŠ” ì„±ê³µì ì¸ \"ì—˜ë¦¬í€íŠ¸ ë§¨\"ê³¼ ëœ ì„±ê³µì ì¸ \"ë“„\"ê³¼ ê°™ì€ ì‘í’ˆì„ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤. 1986ë…„ì˜ \"ë¸”ë£¨ ë²¨ë²³\"ì€ ê´€ê°ë“¤ì—ê²Œ í° í˜¸ì‘ì„ ì–»ìœ¼ë©° ê°œì¸ì ì¸ ì„±ê³µì„ ê±°ë‘ì—ˆê³ , ì´í›„ ê´‘ê³  ì œì‘ ìš”ì²­ì´ ì´ì–´ì¡ŒìŠµë‹ˆë‹¤.\n\në¦°ì¹˜ëŠ” ì¹¼ë¹ˆ í´ë¼ì¸ê³¼ ê°™ì€ ì£¼ìš” ë¸Œëœë“œì™€ í˜‘ë ¥í•˜ì—¬ ê³ ì „ ë¬¸í•™ì—ì„œ ì˜ê°ì„ ë°›ì€ ê´‘ê³ ë¥¼ ê°ë…í–ˆìŠµë‹ˆë‹¤. ê·¸ëŠ” ì¼ë³¸ì—ì„œ ì¡°ì§€ì•„ ì»¤í”¼ë¥¼ í™ë³´í•˜ê¸° ìœ„í•´ ìœ ë¨¸ëŸ¬ìŠ¤í•œ ë¯¸ë‹ˆ ì‹œë¦¬ì¦ˆ \"íŠ¸ìœˆ í”½ìŠ¤\"ë¥¼ ì œì‘í•˜ê¸°ë„ í–ˆìŠµë‹ˆë‹¤. ë˜í•œ ë‰´ìš• ìœ„ìƒêµ­ê³¼ ì•„ë¥´ë§ˆë‹ˆ, ë””ì˜¬ê³¼ ê°™ì€ ê³ ê¸‰ íŒ¨ì…˜ ë¸Œëœë“œì˜ ìº í˜ì¸ì—ë„ ì°¸ì—¬í–ˆìŠµë‹ˆë‹¤. ê·¸ì˜ ë§ì€ ê´‘ê³ ëŠ” ì£¼ë¡œ ë¯¸êµ­ ì™¸ì—ì„œ ë°©ì˜ë˜ì—ˆìœ¼ë©°, ì´ëŠ” ê·¸ê°€ ìœ ëŸ½ê³¼ ì•„ì‹œì•„ì—ì„œ ë” ë„“ì€ ë§¤ë ¥ì„ ê°€ì§€ê³  ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.\n\nì˜ˆìˆ ì ì¸ ê²½í–¥ì—ë„ ë¶ˆêµ¬í•˜ê³ , ë¦°ì¹˜ëŠ” ê³ ì „ì ì¸ ë¯¸êµ­ì˜ ì¦ê±°ì›€ì„ ì¦ê¹ë‹ˆë‹¤. 1998ë…„ ìŠ¤ìœ„ìŠ¤ ë‹´ë°° ë¸Œëœë“œë¥¼ ìœ„í•œ ê´‘ê³ ì—ì„œë„ ê·¸ì˜ ë…íŠ¹í•œ ì´ˆí˜„ì‹¤ì  ìŠ¤íƒ€ì¼ì´ ë“œëŸ¬ë‚¬ìŠµë‹ˆë‹¤.",
      "ja": "æ˜ ç”»è£½ä½œè€…ã®ä¸­ã«ã¯ã€æœ€åˆã«ã‚³ãƒãƒ¼ã‚·ãƒ£ãƒ«ã‚’åˆ¶ä½œã—ã¦ã‹ã‚‰å€‹äººãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«ç§»ã‚‹äººã‚‚ã„ã‚Œã°ã€ãƒ‡ãƒ´ã‚£ãƒƒãƒ‰ãƒ»ãƒªãƒ³ãƒã®ã‚ˆã†ã«ç‹¬è‡ªã®èŠ¸è¡“çš„ãƒ“ã‚¸ãƒ§ãƒ³ã§æ—©ãã‹ã‚‰æ³¨ç›®ã‚’æµ´ã³ã‚‹äººã‚‚ã„ã¾ã™ã€‚ãƒªãƒ³ãƒã¯1977å¹´ã®æ˜ ç”»ã€Œã‚¤ãƒ¬ã‚¤ã‚¶ãƒ¼ãƒ˜ãƒƒãƒ‰ã€ã§æœ‰åã«ãªã‚Šã€ãã®å¾Œãƒãƒªã‚¦ãƒƒãƒ‰ã§ã®æ©Ÿä¼šã‚’å¾—ã¾ã—ãŸã€‚æˆåŠŸã‚’åã‚ãŸã€Œã‚¨ãƒ¬ãƒ•ã‚¡ãƒ³ãƒˆãƒ»ãƒãƒ³ã€ã‚„ã€ã‚ã¾ã‚ŠæˆåŠŸã—ãªã‹ã£ãŸã€Œãƒ‡ãƒ¥ãƒ¼ãƒ³ã€ãªã©ãŒãã®ä¾‹ã§ã™ã€‚1986å¹´ã®æ˜ ç”»ã€Œãƒ–ãƒ«ãƒ¼ãƒ´ã‚§ãƒ«ãƒ™ãƒƒãƒˆã€ã¯å½¼ã«ã¨ã£ã¦å€‹äººçš„ãªæˆåŠŸã‚’åã‚ã€è¦³å®¢ã«å¼·ãéŸ¿ãã¾ã—ãŸã€‚ãã®å¾Œã€å½¼ã¯ã‚³ãƒãƒ¼ã‚·ãƒ£ãƒ«ã®åˆ¶ä½œã«ã‚‚å¼•ã£å¼µã‚Šã ã“ã«ãªã‚Šã¾ã—ãŸã€‚\n\nãƒªãƒ³ãƒã¯ã‚«ãƒ«ãƒãƒ³ãƒ»ã‚¯ãƒ©ã‚¤ãƒ³ãªã©ã®å¤§æ‰‹ãƒ–ãƒ©ãƒ³ãƒ‰ã¨å”åŠ›ã—ã€å¤å…¸æ–‡å­¦ã‚’å–ã‚Šå…¥ã‚ŒãŸåºƒå‘Šã‚’åˆ¶ä½œã—ã¾ã—ãŸã€‚ã¾ãŸã€æ—¥æœ¬ã§ã¯ã‚¸ãƒ§ãƒ¼ã‚¸ã‚¢ã‚³ãƒ¼ãƒ’ãƒ¼ã®ãŸã‚ã«ã€Œãƒ„ã‚¤ãƒ³ãƒ»ãƒ”ãƒ¼ã‚¯ã‚¹ã€ã®ãƒ¦ãƒ¼ãƒ¢ãƒ©ã‚¹ãªãƒŸãƒ‹ã‚·ãƒªãƒ¼ã‚ºã‚’ä½œæˆã—ã¾ã—ãŸã€‚ã•ã‚‰ã«ã€ãƒ‹ãƒ¥ãƒ¼ãƒ¨ãƒ¼ã‚¯å¸‚ã®è¡›ç”Ÿå±€ã‚„ã‚¢ãƒ«ãƒãƒ¼ãƒ‹ã€ãƒ‡ã‚£ã‚ªãƒ¼ãƒ«ã¨ã„ã£ãŸé«˜ç´šãƒ•ã‚¡ãƒƒã‚·ãƒ§ãƒ³ãƒ–ãƒ©ãƒ³ãƒ‰ã®ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ã«ã‚‚å‚åŠ ã—ã¾ã—ãŸã€‚å½¼ã®ã‚³ãƒãƒ¼ã‚·ãƒ£ãƒ«ã®å¤šãã¯ä¸»ã«ã‚¢ãƒ¡ãƒªã‚«ä»¥å¤–ã§æ”¾é€ã•ã‚Œã€ãƒ¨ãƒ¼ãƒ­ãƒƒãƒ‘ã‚„ã‚¢ã‚¸ã‚¢ã§ã®åºƒã„äººæ°—ã‚’åæ˜ ã—ã¦ã„ã¾ã™ã€‚\n\nèŠ¸è¡“çš„ãªã‚»ãƒ³ã‚¹ã‚’æŒã¡ãªãŒã‚‰ã‚‚ã€ãƒªãƒ³ãƒã¯ã‚¢ãƒ¡ãƒªã‚«ã®ã‚¯ãƒ©ã‚·ãƒƒã‚¯ãªæ¥½ã—ã¿ã‚’å¥½ã‚“ã§ã„ã¾ã™ã€‚1998å¹´ã«åˆ¶ä½œã—ãŸã‚¹ã‚¤ã‚¹ã®ã‚¿ãƒã‚³ãƒ–ãƒ©ãƒ³ãƒ‰ã®åºƒå‘Šã§ã¯ã€å½¼ã®ç‰¹å¾´çš„ãªã‚·ãƒ¥ãƒ¼ãƒ«ãªã‚¹ã‚¿ã‚¤ãƒ«ãŒè¡¨ç¾ã•ã‚Œã¦ã„ã¾ã™ã€‚"
    }
  },
  {
    "id": "d4ccda5cec78dfd4",
    "title": {
      "en": "Convert Linux to Windows",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://philipbohun.com/blog/0007.html",
    "score": 71,
    "by": "pbohun",
    "time": 1743284042,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "c3248b8e7af279fd",
    "title": {
      "en": "Accessible open textbooks in math-heavy disciplines",
      "ko": "ìˆ˜í•™ êµê³¼ì„œì˜ ì ‘ê·¼ì„±",
      "ja": "æ•°å­¦ã®ã‚ªãƒ¼ãƒ—ãƒ³æ•™ç§‘æ›¸"
    },
    "type": "story",
    "url": "https://richardzach.org/2025/03/accessible-open-textbooks-in-math-heavy-disciplines/",
    "score": 154,
    "by": "volemo",
    "time": 1743266281,
    "content": "2025-03-242025-03-26 rzach\n\n\t\tAccessible Open Textbooks in Math-Heavy Disciplines\n\nThe challenge\n\nThe authoring platform of choice in many math-heavy disciplines is LaTeX. It produces typeset documents of excellent quality and handles formulas and mathematical diagrams extremely well. Practically every researcher or instructor in mathematics, physics, and computer science is adept at using it, and it has a wide user base outside these core disciplines as well (e.g., philosophy and economics).\n\nUnfortunately, it only produces PDF output. PDF is not an accessible format: it does not scale well to display on tablets or phones, text does not reflow, it contains no semantic information (e.g., whatâ€™s a heading or whatâ€™s a list), images, formulas, and diagrams are only visually accessible. This creates difficulties for readers who rely on alternative presentations of material (in other colors, text sizes, fonts, or in non-visual formats, i.e., audio or Braille) or who simply want to access the material on a device not the size of a printed page (e.g., on a smartphone or small e-reader).\n\nA partial solution is to provide the content in HTML. HTML deals with accessibility much better than PDF, and technology that converts HTML to other formats is widely available. HTML is also accessible to screen reader software specifically designed for users with low or no vision, and simpler text-to-speech (TTS) software which many sighted users also rely on (e.g., those with dyslexia or ADHD). In math-heavy disciplines, the widespread reliance on LaTeX and PDF only for producing OERs poses a unique challenge (e.g., only about half of the textbooks on the American Institute for Mathematics list are provided in HTML).\n\nThe availability of material in HTML format to ensure accessibility is a desideratum for all OER. For math-heavy disciplines, the presentation of mathematical formulas in an HTML version of the material poses a second and difficult challenge. Mathematical formulas have long caused problems for display on web pages. Early solutions included displaying pictures or recreating formulas as text with special formatting and fonts. The modern solution is MathML, a special format for representing mathematical formulas that can be included in HTML documents. MathML is not universally supported by web browsers. The most widespread solution is for a webpage to include the polyfill browser extension MathJax in the webpage, which displays MathML to the user. MathML is a low-level format and not a suitable format for humans to write formulas in. However, good conversion utilities from LaTeX formula notation to MathML exist, and MathJax can also directly display LaTeX formulas embedded in webpages. For instance, the code \\int_{x=0}^\\infty \\frac{1}{x^2} dx produces: $$\\int_{x=0}^\\infty \\frac{1}{x^2}$$ whereas the MathML representation is unintelligble (right-click on the formula, select â€œShow Math As > MathML Codeâ€ to see it). MathJax can display the formulas itself, display the LaTeX code used to generate it, or produce code in some other format that it lets the browser render (e.g., MathML, HTML, or SVG; right-click on the formula, select â€œMath Settings > Math Rendererâ€ to see the differences).\n\nAlternatives to LaTeX\n\nOne option is to avoid LaTeX as the authoring platform from the start, or to convert existing LaTeX code to a format that is itself more easily converted into HTML. The following are three options, which all allow the use of LaTeX notation for entering mathematical symbols and formulas.\n\nPressbooks is a web-based authoring and publishing tool for OERs, which supports LaTeX formulas and support for export to PDF for printing. It is built on top of WordPress, so in a sense it is web-first. While it is possible to use mathematical formulas in a Pressbooks project, it is not a popular option for math-heavy disciplines. Example: A Concise Introduction to Logic (note that formal proofs are displayed as images, images have no ALT tags, and stand-alone formulas donâ€™t use MathML or even unicode characters, e.g., the logical and symbol is presented as a caret ^ and the logical or as the letter â€œvâ€).\n\nPreTeXt is a platform for authoring mathematics textbooks in XML, and converts the XML source to other formats (including LaTeX for printing, HTML for display on a web browser, and ePub for display on e-readers such as Kindle). PreTeXt is one of the oldest open publishing solutions and popular with with mathematicians. For open textbooks, free help for conversion to PreTeXt is available. Example: Abstract Algebra\n\nMarkdown is a simple markup language that can easily be converted to other formats (including HTML, LaTeX, PDF, and Word) using the pandoc package. R Markdown (and its extension/successor Quarto) and Bookdown are popular interfaces for authoring and publishing Markdown documents (and use pandoc and LaTeX â€œunder the hoodâ€). Mathematical formulas and symbols can be included using simplified LaTeX code. Because of the close connection to the statistics package R, this option is popular with statisticians, economists, psychologists, and data scientists. Examples, e.g.: Modern Statistical Methods for Psychology, Odds & Ends\n\nAll of the above come with advantages and drawbacks. Depending on the scope and complexity of the project, and the functionality required, converting an existing project to, e.g., Markdown or PreTeXt may be a viable option, and should be considered especially for new projects. A significant advantage of Markdown is that it can be easily converted to other formats (including LaTeX).\n\nAn obvious barrier to use of the above is that authors have to learn a new system and/or language and the use of unfamiliar tools. A more significant disadvantage is that the LaTeX ecosystem is huge. LaTeX (or at least its predecessor, TeX) has been around for almost half a century. There are numerous packages that aid in the production of documents, from sophisticated citation managers to packages for the production of specialized diagrams and complex layout of mathematical formulas. LaTeX is also easily extensible; authors can define their own macros quite easily. Very few of these features are available to documents authored in Markdown or PreTeXt, and almost none in Pressbooks. Converting an entire existing textbook will usually require a substantial amount of work, in part because many things that LaTeX does easily will have to be recreated from scratch.\n\nLaTeX to HTML conversion\n\nA second option is to use software to automatically convert a LaTeX project to HTML. Because of the complexity and variability of LaTeX projects, there are few good conversion utilities. The solution I prefer is LaTeXML. It is a reimplementation of LaTeX, but outputs to XML instead of to PDF, and can compile mathematical formulas to MathML. LaTeXML is what ar5iv uses: a project to compile everything on the arXiv to HTML.\n\nBecause LaTeXML simulates what LaTeX is actually doing, it can (to a large extent) deal with packages and LaTeX programming directly. It does natively support a large number of popular packages and classes, but packages it does not support can be loaded and â€œcompiledâ€ using the --includestyles flag. This support is not perfect (e.g., many newer packages that rely in turn on the expl3 package cannot yet be compiled.) LaTeXML is under active development and is likely to keep improving and be supported for the foreseeable future. In any case, because many commonly used packages are supported already or work with the --includestyles flag, LaTeXML is probably the best candidate for a tool to convert an existing LaTeX project to HTML.\n\nThe output produced by LaTeXML directly is not terribly visually appealing. Since the HTML output will  not just be used by screen readers (where visual presentation is secondary), some effort is required to style the HTML produced by LaTeXML using CSS to produce webpages that look attractive and display well on a range of devices and browsers (i.e., responsive web pages).\n\nOne available and simple solution is BookML, developed by mathematician Vincenzo Mantova at the University of Leeds. BookML uses LaTeXML to produce webpages that use a style modified from that used by Bookdown. LaTeXML and BookML provide additional features to authors to provide different code depending on whether LaTeX is used to produce a PDF, or LaTeXML to produce HTML. BookML extends this capability, e.g., by adding the possibility of directly adding HTML code into the webpages produced, or adding alt text to images produced other than by LaTeXâ€™s \\includegraphics command. BookML also automatically produces a SCORM bundle of the project that can be uploaded to a learning management system (such as Brightspace, Canvas, or Moodle). This is especially useful for authors who donâ€™t have an easy way of hosting the resulting website on a server. LaTeXML (but not yet BookML) can also produce ePub.\n\nCase study: An open textbook on formal logic\n\nThe University of Calgary Department of Philosophy teaches symbolic logic in its PHIL 279 course to over 700 students (mainly Computer Science majors). With support from the Taylor Institute for teaching and Learning, we adapted the open textbook forall x by P.D. Magnus; the resulting open textbook forall x: Calgary has been in use in PHIL 279 since 2017. The Calgary version is now also widely adopted and has been translated to German and Portuguese.\n\nI converted this text to HTML in 2024 using LaTeXML and BookML. The basic (error-free) conversion to HTML was simple, and required about a day of work. It involved mainly changing bits of LaTeX code that LaTeXML couldnâ€™t handle. Approximately another week of work was required to fine-tune the LaTeX code and CSS so that it produced better HTML and visual output. E.g., markup to produce lists sometimes resulted in odd spacing on the resulting web page. LaTeXâ€™s mechanisms for producing links also sometimes didnâ€™t work (produced incorrect links or link text when run through LaTeXML). Many of these issues were caused by oddities of the legacy LaTeX code from which we started, and wouldnâ€™t be necessary for a LaTeX project with clean source code that uses standard packages.\n\nThe impetus for carrying out the conversion was a request from the University of Cincinnati Accessibility Center who needed to accommodate a blind student in a course using this textbook. I took this as an opportunity to make the HTML version as accessible as possible, specifically, to make it work well with screen readers.\n\nAdd ALT text to all diagrams and images.\n\nProvide accessible alternatives to some text elements (e.g., we use a long underline to indicate a blank in a sentence, but this long underline cannot be interpreted by screen readers).\n\nSwitch the language on foreign terms and names so that screen readers can pronounce them in the right voice.\n\nDevelop a non-visual representation of formal proofs and rewrite the code to produce them so that LaTeXML and BookML could a) display them on the HTML version cleanly using CSS and b) screen readers could provide the missing visual information in textual (i.e., auditory) form. The proofs in PDF are produced with the fitch package. When run through LaTeXML/BookML they are produced using fitchml.sty and styled with CSS with fitchml.css in the project source. The non-visual presentation is described in the accessibility notes for forall x. (Thanks to Patrick Girard and Audrey Yap for discussions on how to present proofs non-visually. The image at the top of this post is an example.)\n\nThere is still work to be done, and the results havenâ€™t been tested by actual students with low or no vision, on their own or in the context of using the materials in a course.\n\nPitfalls and tricks\n\nIt is difficult to test web versions of OER for accessibility. There are basic tools (e.g., WAVE) that automatically check for various things, e.g., that contrast and colors are suitable for colorblind readers, images have ALT tags, etc. Code produced by LaTeXML generally does well on everything that can be automatically checked (the developers have accessibility in mind), and anything the available resources for OER authors provide guidance on (e.g., the BCcampus Open Accessibility Toolkit). But detailed testing is a challenge for an author with no accessibility training or experience.\n\nWhat might work in the screen reader you have (say, VoiceOver on MacOS or Narrator on Windows) may not work with others, may work on one version but not others, and any hacks used to make it work might break on others. Testing on a wide range of assistive technologies for non-experts is near impossible: youâ€™d need several different computers and ability to install various assistive technologies on them, some of them are not free. Testing Braille requires at least knowledge of Braille if not separate hardware.\n\nThat said, itâ€™s usually best to use documented best practice. (E.g., I originally used the aria-label tag to provide explicit hints for how things should be pronounced. But support of aria-label is inconsistent.)\n\nI felt pulled in competing directions when fine-tuning code and deciding on various settings, between providing an optimal experience for readers using TTS extensions casually and not degrading the experience for users relying on true screen readers like JAWS and NVDA. TTS extensions tend to have poor support for pronouncing unicode characters, MathML with assistive alternative text, and tables. Dong things one way might get VoiceOver on Macs or Windows Narrator to read out formulas and special symbols, but then prevent NVDA from working properly. I also had a hard time maneuvering accessibility advice and was unable to obtain advice or support from on-campus sources like our accessibility service center.\n\nTricking screen readers into pronouncing things the right way is in any case a foolâ€™s errand and may have unintended side effects. (See The Curious Case of â€œiffâ€ and Overriding Screenreader Pronunciations by Ben Myers). Itâ€™s usually best to â€œleave things beâ€ but provide guidance in a page on accessibility (here is the one for forall x). Screen reader users are accustomed to changing the settings of their preferred software to fix things. You can help by letting them know what to watch for. A good screen reader can replace text with other text that produces better pronunciation. E.g., depending on the voice synthesizer, the letter â€œAâ€ in a formula might be pronounces as a schwa (i.e., like â€œuhâ€). MathJax will tell the screen reader to read a symbol â€œAâ€ as â€œupper Aâ€, and the user can replace this everywhere with â€œupper Ehâ€.\n\nLinks\n\nAccessible Mathematics\n\nConverting LaTeX to HTML: technical notes\n\nTeaching logic to blind students\n\nSample output of forall x with screen readers:\n\nNVDA\n\nWindows Narrator\n\nShare this:Click to share on Mastodon (Opens in new window)Click to share on Facebook (Opens in new window)Click to share on Reddit (Opens in new window)Click to share on Pocket (Opens in new window)Click to share on Twitter (Opens in new window)Click to email a link to a friend (Opens in new window)Click to print (Opens in new window)\n\n\t\tPosted in Progress, Uncategorized2 Comments",
    "summary": {
      "en": "**Summary: Accessible Open Textbooks in Math-Heavy Disciplines**\n\nThe main issue is that LaTeX, a popular tool for creating high-quality documents in math-heavy fields, only outputs in PDF format, which is not accessible for many users. PDFs canâ€™t be easily adjusted for different devices or formats, and they don't provide necessary semantic information for screen readers.\n\nA better solution is to use HTML, which is more accessible and works well with assistive technologies. However, displaying mathematical formulas in HTML can be challenging. MathML is a format designed for this purpose but isn't fully supported by all web browsers. MathJax can help display these formulas correctly on web pages.\n\nAlternatives to LaTeX include:\n\n1. **Pressbooks**: A web-based tool that supports LaTeX but is not widely used in math-heavy fields.\n2. **PreTeXt**: An XML-based platform that converts content into multiple formats, including HTML and LaTeX.\n3. **Markdown**: A simple markup language that can be easily converted to various formats and is popular in disciplines like statistics.\n\nEach alternative has pros and cons, especially concerning the complexity of existing LaTeX projects. A significant barrier is that authors need to learn new tools and languages, unlike LaTeX, which has a vast ecosystem of features.\n\nAnother option is to convert existing LaTeX documents to HTML using tools like LaTeXML, which is effective but requires additional work to make the output visually appealing. BookML can enhance this process by providing styling options and features for online learning systems.\n\nA case study from the University of Calgary shows how an open textbook was successfully adapted for accessibility, which involved converting LaTeX to HTML and ensuring compatibility with screen readers.\n\nTesting for accessibility can be difficult, and while many automated tools exist, thorough testing often requires expertise and resources. The author faced challenges in balancing accessibility features for different screen readers and user needs.\n\nOverall, the document emphasizes the importance of making math-heavy educational resources accessible and the challenges involved in achieving this goal.",
      "ko": "ì£¼ìš” ë¬¸ì œëŠ” ìˆ˜í•™ ì¤‘ì‹¬ ë¶„ì•¼ì—ì„œ ê³ í’ˆì§ˆ ë¬¸ì„œë¥¼ ë§Œë“œëŠ” ë° ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” LaTeXê°€ PDF í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥ëœë‹¤ëŠ” ì ì…ë‹ˆë‹¤. PDFëŠ” ë‹¤ì–‘í•œ ê¸°ê¸°ë‚˜ í˜•ì‹ì— ë§ê²Œ ì‰½ê²Œ ì¡°ì •í•  ìˆ˜ ì—†ìœ¼ë©°, í™”ë©´ ì½ê¸° í”„ë¡œê·¸ë¨ì„ ìœ„í•œ í•„ìˆ˜ì ì¸ ì˜ë¯¸ ì •ë³´ë¥¼ ì œê³µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n\në” ë‚˜ì€ í•´ê²°ì±…ì€ HTMLì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. HTMLì€ ì ‘ê·¼ì„±ì´ ë” ì¢‹ê³  ë³´ì¡° ê¸°ìˆ ê³¼ ì˜ ì‘ë™í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ HTMLì—ì„œ ìˆ˜í•™ ê³µì‹ì„ í‘œì‹œí•˜ëŠ” ê²ƒì€ ì–´ë ¤ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤. MathMLì€ ì´ë¥¼ ìœ„í•´ ì„¤ê³„ëœ í˜•ì‹ì´ì§€ë§Œ ëª¨ë“  ì›¹ ë¸Œë¼ìš°ì €ì—ì„œ ì™„ì „íˆ ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. MathJaxëŠ” ì›¹ í˜ì´ì§€ì—ì„œ ì´ëŸ¬í•œ ê³µì‹ì„ ì˜¬ë°”ë¥´ê²Œ í‘œì‹œí•˜ëŠ” ë° ë„ì›€ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nLaTeXì˜ ëŒ€ì•ˆìœ¼ë¡œëŠ” ë‹¤ìŒê³¼ ê°™ì€ ê²ƒë“¤ì´ ìˆìŠµë‹ˆë‹¤. PressbooksëŠ” LaTeXë¥¼ ì§€ì›í•˜ëŠ” ì›¹ ê¸°ë°˜ ë„êµ¬ì´ì§€ë§Œ ìˆ˜í•™ ì¤‘ì‹¬ ë¶„ì•¼ì—ì„œëŠ” ë„ë¦¬ ì‚¬ìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. PreTeXtëŠ” XML ê¸°ë°˜ í”Œë«í¼ìœ¼ë¡œ, ì½˜í…ì¸ ë¥¼ HTMLê³¼ LaTeXë¥¼ í¬í•¨í•œ ì—¬ëŸ¬ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. Markdownì€ ë‹¤ì–‘í•œ í˜•ì‹ìœ¼ë¡œ ì‰½ê²Œ ë³€í™˜í•  ìˆ˜ ìˆëŠ” ê°„ë‹¨í•œ ë§ˆí¬ì—… ì–¸ì–´ë¡œ, í†µê³„í•™ê³¼ ê°™ì€ ë¶„ì•¼ì—ì„œ ì¸ê¸°ê°€ ìˆìŠµë‹ˆë‹¤.\n\nê° ëŒ€ì•ˆì€ ì¥ë‹¨ì ì´ ìˆìœ¼ë©°, íŠ¹íˆ ê¸°ì¡´ LaTeX í”„ë¡œì íŠ¸ì˜ ë³µì¡ì„±ê³¼ ê´€ë ¨í•˜ì—¬ ì–´ë ¤ì›€ì´ ìˆìŠµë‹ˆë‹¤. ì €ìë“¤ì€ LaTeXì™€ ê°™ì€ ë°©ëŒ€í•œ ê¸°ëŠ¥ ìƒíƒœê³„ê°€ ì—†ëŠ” ìƒˆë¡œìš´ ë„êµ¬ì™€ ì–¸ì–´ë¥¼ ë°°ì›Œì•¼ í•˜ëŠ” í° ì¥ë²½ì— ì§ë©´í•´ ìˆìŠµë‹ˆë‹¤.\n\në˜ ë‹¤ë¥¸ ì˜µì…˜ì€ LaTeXMLê³¼ ê°™ì€ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ê¸°ì¡´ LaTeX ë¬¸ì„œë¥¼ HTMLë¡œ ë³€í™˜í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì´ ë°©ë²•ì€ íš¨ê³¼ì ì´ì§€ë§Œ ì¶œë ¥ë¬¼ì„ ì‹œê°ì ìœ¼ë¡œ ë§¤ë ¥ì ìœ¼ë¡œ ë§Œë“¤ê¸° ìœ„í•´ ì¶”ê°€ ì‘ì—…ì´ í•„ìš”í•©ë‹ˆë‹¤. BookMLì€ ì˜¨ë¼ì¸ í•™ìŠµ ì‹œìŠ¤í…œì„ ìœ„í•œ ìŠ¤íƒ€ì¼ ì˜µì…˜ê³¼ ê¸°ëŠ¥ì„ ì œê³µí•˜ì—¬ ì´ ê³¼ì •ì„ ê°œì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nìº˜ê±°ë¦¬ ëŒ€í•™êµì˜ ì‚¬ë¡€ ì—°êµ¬ì—ì„œëŠ” LaTeXë¥¼ HTMLë¡œ ë³€í™˜í•˜ê³  í™”ë©´ ì½ê¸° í”„ë¡œê·¸ë¨ê³¼ì˜ í˜¸í™˜ì„±ì„ ë³´ì¥í•˜ì—¬ ì ‘ê·¼ì„±ì„ ìœ„í•´ ì—´ë¦° êµê³¼ì„œë¥¼ ì„±ê³µì ìœ¼ë¡œ ì¡°ì •í•œ ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.\n\nì ‘ê·¼ì„± í…ŒìŠ¤íŠ¸ëŠ” ì–´ë ¤ìš¸ ìˆ˜ ìˆìœ¼ë©°, ë§ì€ ìë™í™” ë„êµ¬ê°€ ì¡´ì¬í•˜ì§€ë§Œ ì² ì €í•œ í…ŒìŠ¤íŠ¸ëŠ” ì¢…ì¢… ì „ë¬¸ ì§€ì‹ê³¼ ìì›ì„ ìš”êµ¬í•©ë‹ˆë‹¤. ì €ìëŠ” ë‹¤ì–‘í•œ í™”ë©´ ì½ê¸° í”„ë¡œê·¸ë¨ê³¼ ì‚¬ìš©ì ìš”êµ¬ì— ë§ì¶° ì ‘ê·¼ì„± ê¸°ëŠ¥ì˜ ê· í˜•ì„ ë§ì¶”ëŠ” ë° ì–´ë ¤ì›€ì„ ê²ªì—ˆìŠµë‹ˆë‹¤.\n\nì „ë°˜ì ìœ¼ë¡œ ì´ ë¬¸ì„œëŠ” ìˆ˜í•™ ì¤‘ì‹¬ êµìœ¡ ìë£Œì˜ ì ‘ê·¼ì„±ì„ ë†’ì´ëŠ” ê²ƒì˜ ì¤‘ìš”ì„±ê³¼ ì´ë¥¼ ë‹¬ì„±í•˜ëŠ” ë° ìˆ˜ë°˜ë˜ëŠ” ë„ì „ ê³¼ì œë¥¼ ê°•ì¡°í•©ë‹ˆë‹¤.",
      "ja": "ä¸»ãªå•é¡Œã¯ã€æ•°å­¦é–¢é€£ã®åˆ†é‡ã§é«˜å“è³ªãªæ–‡æ›¸ã‚’ä½œæˆã™ã‚‹ãŸã‚ã«åºƒãä½¿ã‚ã‚Œã¦ã„ã‚‹LaTeXãŒã€PDFå½¢å¼ã®ã¿ã§å‡ºåŠ›ã•ã‚Œã‚‹ã“ã¨ã§ã™ã€‚ã“ã®å½¢å¼ã¯å¤šãã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã¨ã£ã¦ã‚¢ã‚¯ã‚»ã‚¹ã—ã¥ã‚‰ãã€PDFã¯ç•°ãªã‚‹ãƒ‡ãƒã‚¤ã‚¹ã‚„ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«ç°¡å˜ã«èª¿æ•´ã§ããšã€ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ãƒªãƒ¼ãƒ€ãƒ¼ã«å¿…è¦ãªæ„å‘³æƒ…å ±ã‚‚æä¾›ã—ã¾ã›ã‚“ã€‚\n\nã‚ˆã‚Šè‰¯ã„è§£æ±ºç­–ã¯ã€HTMLã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ã™ã€‚HTMLã¯ã‚¢ã‚¯ã‚»ã‚¹ã—ã‚„ã™ãã€æ”¯æ´æŠ€è¡“ã¨ã‚‚ç›¸æ€§ãŒè‰¯ã„ã§ã™ãŒã€æ•°å­¦ã®æ•°å¼ã‚’HTMLã§è¡¨ç¤ºã™ã‚‹ã®ã¯é›£ã—ã„å ´åˆãŒã‚ã‚Šã¾ã™ã€‚MathMLã¯ã“ã®ç›®çš„ã®ãŸã‚ã«è¨­è¨ˆã•ã‚ŒãŸãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§ã™ãŒã€ã™ã¹ã¦ã®ã‚¦ã‚§ãƒ–ãƒ–ãƒ©ã‚¦ã‚¶ã§å®Œå…¨ã«ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ã‚ã‘ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚MathJaxã‚’ä½¿ã†ã“ã¨ã§ã€ã‚¦ã‚§ãƒ–ãƒšãƒ¼ã‚¸ä¸Šã§æ•°å¼ã‚’æ­£ã—ãè¡¨ç¤ºã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚\n\nLaTeXã®ä»£æ›¿æ‰‹æ®µã«ã¯ã€ã„ãã¤ã‹ã®ãƒ„ãƒ¼ãƒ«ãŒã‚ã‚Šã¾ã™ã€‚Pressbooksã¯ã‚¦ã‚§ãƒ–ãƒ™ãƒ¼ã‚¹ã®ãƒ„ãƒ¼ãƒ«ã§ã€LaTeXã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ãŒã€æ•°å­¦é–¢é€£ã®åˆ†é‡ã§ã¯ã‚ã¾ã‚Šæ™®åŠã—ã¦ã„ã¾ã›ã‚“ã€‚PreTeXtã¯XMLãƒ™ãƒ¼ã‚¹ã®ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã§ã€ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’HTMLã‚„LaTeXãªã©ã®è¤‡æ•°ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¤‰æ›ã§ãã¾ã™ã€‚Markdownã¯ã‚·ãƒ³ãƒ—ãƒ«ãªãƒãƒ¼ã‚¯ã‚¢ãƒƒãƒ—è¨€èªã§ã€ã•ã¾ã–ã¾ãªãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«ç°¡å˜ã«å¤‰æ›ã§ãã€çµ±è¨ˆå­¦ãªã©ã®åˆ†é‡ã§äººæ°—ãŒã‚ã‚Šã¾ã™ã€‚\n\nãã‚Œãã‚Œã®ä»£æ›¿æ‰‹æ®µã«ã¯åˆ©ç‚¹ã¨æ¬ ç‚¹ãŒã‚ã‚Šã€ç‰¹ã«æ—¢å­˜ã®LaTeXãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®è¤‡é›‘ã•ã«é–¢ã—ã¦ã¯èª²é¡ŒãŒã‚ã‚Šã¾ã™ã€‚è‘—è€…ã¯æ–°ã—ã„ãƒ„ãƒ¼ãƒ«ã‚„è¨€èªã‚’å­¦ã¶å¿…è¦ãŒã‚ã‚Šã€LaTeXã®åºƒç¯„ãªæ©Ÿèƒ½ã®ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ã¨ã¯ç•°ãªã‚Šã¾ã™ã€‚\n\nåˆ¥ã®é¸æŠè‚¢ã¨ã—ã¦ã€LaTeXæ–‡æ›¸ã‚’HTMLã«å¤‰æ›ã™ã‚‹ãƒ„ãƒ¼ãƒ«ã§ã‚ã‚‹LaTeXMLã‚’ä½¿ç”¨ã™ã‚‹æ–¹æ³•ãŒã‚ã‚Šã¾ã™ã€‚ã“ã‚Œã¯åŠ¹æœçš„ã§ã™ãŒã€å‡ºåŠ›ã‚’è¦–è¦šçš„ã«é­…åŠ›çš„ã«ã™ã‚‹ãŸã‚ã«ã¯è¿½åŠ ã®ä½œæ¥­ãŒå¿…è¦ã§ã™ã€‚BookMLã¯ã€ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ å‘ã‘ã«ã‚¹ã‚¿ã‚¤ãƒªãƒ³ã‚°ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚„æ©Ÿèƒ½ã‚’æä¾›ã™ã‚‹ã“ã¨ã§ã€ã“ã®ãƒ—ãƒ­ã‚»ã‚¹ã‚’å¼·åŒ–ã§ãã¾ã™ã€‚\n\nã‚«ãƒ«ã‚¬ãƒªãƒ¼å¤§å­¦ã®äº‹ä¾‹ç ”ç©¶ã§ã¯ã€ã‚ªãƒ¼ãƒ—ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒƒã‚¯ãŒã‚¢ã‚¯ã‚»ã‚·ãƒ“ãƒªãƒ†ã‚£ã®ãŸã‚ã«æˆåŠŸè£ã«é©å¿œã•ã‚ŒãŸæ–¹æ³•ãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚ã“ã‚Œã¯ã€LaTeXã‚’HTMLã«å¤‰æ›ã—ã€ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ãƒªãƒ¼ãƒ€ãƒ¼ã¨ã®äº’æ›æ€§ã‚’ç¢ºä¿ã™ã‚‹ã“ã¨ã‚’å«ã¿ã¾ã™ã€‚\n\nã‚¢ã‚¯ã‚»ã‚·ãƒ“ãƒªãƒ†ã‚£ã®ãƒ†ã‚¹ãƒˆã¯é›£ã—ã„å ´åˆãŒã‚ã‚Šã€å¤šãã®è‡ªå‹•åŒ–ãƒ„ãƒ¼ãƒ«ãŒå­˜åœ¨ã—ã¾ã™ãŒã€å¾¹åº•çš„ãªãƒ†ã‚¹ãƒˆã«ã¯å°‚é–€çŸ¥è­˜ã‚„ãƒªã‚½ãƒ¼ã‚¹ãŒå¿…è¦ã§ã™ã€‚è‘—è€…ã¯ã€ç•°ãªã‚‹ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ãƒªãƒ¼ãƒ€ãƒ¼ã‚„ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ‹ãƒ¼ã‚ºã«å¯¾ã—ã¦ã‚¢ã‚¯ã‚»ã‚·ãƒ“ãƒªãƒ†ã‚£æ©Ÿèƒ½ã®ãƒãƒ©ãƒ³ã‚¹ã‚’å–ã‚‹ã“ã¨ã«è‹¦åŠ´ã—ã¾ã—ãŸã€‚\n\nå…¨ä½“ã¨ã—ã¦ã€ã“ã®æ–‡æ›¸ã¯æ•°å­¦é–¢é€£ã®æ•™è‚²ãƒªã‚½ãƒ¼ã‚¹ã‚’ã‚¢ã‚¯ã‚»ã‚¹ã—ã‚„ã™ãã™ã‚‹ã“ã¨ã®é‡è¦æ€§ã¨ã€ãã®ç›®æ¨™ã‚’é”æˆã™ã‚‹ãŸã‚ã®èª²é¡Œã‚’å¼·èª¿ã—ã¦ã„ã¾ã™ã€‚"
    }
  },
  {
    "id": "9ccc844f2b8904d1",
    "title": {
      "en": "Why Apple's Severance gets edited over remote desktop software",
      "ko": "ì• í”Œì˜ í•´ê³ , ì›ê²© ì†Œí”„íŠ¸ì›¨ì–´ ë…¼ë€",
      "ja": "ã‚¢ãƒƒãƒ—ãƒ«ã®é€€è·é‡‘å•é¡Œ"
    },
    "type": "story",
    "url": "https://tedium.co/2025/03/29/severance-apple-remote-editing-weirdness/",
    "score": 353,
    "by": "shortformblog",
    "time": 1743271248,
    "content": "Severed Edits\n\n                    Whether it was trying to or not, Apple exposed a huge flaw with its pitch to professional video editors with a new Severance promotional video.\n\n                    By Ernie Smith â€¢\n                    March 29, 2025\n\n                    https://static.tedium.co/uploads/SeveranceEditor.gif\n\n                                    #remote editing\n\n                                    #remote desktop access\n\n                                    #video editing\n\n                                    #editing\n\n                                    #severance\n\n                                    #tv shows\n\n                                    #apple\n\n                                    #macos\n\n                                    #virtual machine\n\n                    When it comes to Appleâ€™s TV ambitions, it couldn't buy better marketing than the buzz around Severance. (Certainly beats talking about Apple Intelligence.)It is both Appleâ€™s most ambitious and (apologies to Ted Lasso) successful production, expanding the Apple brand by highlighting just how smart it is. At a time when HBO seems to want to be HBO less and less, Apple TV+ has certainly taken up the mantle and then some.But it of course raises the question: Do they make Appleâ€˜s shows on Macs? As the second season of Severance ended in dramatic fashion, Apple decided to answer that question, and the answer was â€¦ surprisingly confusing.lite-youtube {\n    background-color: #000;\n    position: relative;\n    display: block;\n    contain: content;\n    background-position: center center;\n    background-size: cover;\n    cursor: pointer;\n    max-width: 720px;\n}\n\n/* gradient */\nlite-youtube::before {\n    content: attr(data-title);\n    display: block;\n    position: absolute;\n    top: 0;\n    /* Pixel-perfect port of YT's gradient PNG, using https://github.com/bluesmoon/pngtocss plus optimizations */\n    background-image: linear-gradient(180deg, rgb(0 0 0 / 67%) 0%, rgb(0 0 0 / 54%) 14%, rgb(0 0 0 / 15%) 54%, rgb(0 0 0 / 5%) 72%, rgb(0 0 0 / 0%) 94%);\n    height: 99px;\n    width: 100%;\n    font-family: \"YouTube Noto\",Roboto,Arial,Helvetica,sans-serif;\n    color: hsl(0deg 0% 93.33%);\n    text-shadow: 0 0 2px rgba(0,0,0,.5);\n    font-size: 18px;\n    padding: 25px 20px;\n    overflow: hidden;\n    white-space: nowrap;\n    text-overflow: ellipsis;\n    box-sizing: border-box;\n}\n\nlite-youtube:hover::before {\n    color: white;\n}\n\n/* responsive iframe with a 16:9 aspect ratio\n    thanks https://css-tricks.com/responsive-iframes/\n*/\nlite-youtube::after {\n    content: \"\";\n    display: block;\n    padding-bottom: calc(100% / (16 / 9));\n}\nlite-youtube > iframe {\n    width: 100%;\n    height: 100%;\n    position: absolute;\n    top: 0;\n    left: 0;\n    border: 0;\n}\n\n/* play button */\nlite-youtube > .lty-playbtn {\n    display: block;\n    /* Make the button element cover the whole area for a large hover/click targetâ€¦ */\n    width: 100%;\n    height: 100%;\n    /* â€¦but visually it's still the same size */\n    background: no-repeat center/68px 48px;\n    /* YT's actual play button svg */\n    background-image: url('data:image/svg+xml;utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 68 48\"><path d=\"M66.52 7.74c-.78-2.93-2.49-5.41-5.42-6.19C55.79.13 34 0 34 0S12.21.13 6.9 1.55c-2.93.78-4.63 3.26-5.42 6.19C.06 13.05 0 24 0 24s.06 10.95 1.48 16.26c.78 2.93 2.49 5.41 5.42 6.19C12.21 47.87 34 48 34 48s21.79-.13 27.1-1.55c2.93-.78 4.64-3.26 5.42-6.19C67.94 34.95 68 24 68 24s-.06-10.95-1.48-16.26z\" fill=\"red\"/><path d=\"M45 24 27 14v20\" fill=\"white\"/></svg>');\n    position: absolute;\n    cursor: pointer;\n    z-index: 1;\n    filter: grayscale(100%);\n    transition: filter .1s cubic-bezier(0, 0, 0.2, 1);\n    border: 0;\n}\n\nlite-youtube:hover > .lty-playbtn,\nlite-youtube .lty-playbtn:focus {\n    filter: none;\n}\n\n/* Post-click styles */\nlite-youtube.lyt-activated {\n    cursor: unset;\n}\nlite-youtube.lyt-activated::before,\nlite-youtube.lyt-activated > .lty-playbtn {\n    opacity: 0;\n    pointer-events: none;\n}\n\n.lyt-visually-hidden {\n    clip: rect(0 0 0 0);\n    clip-path: inset(50%);\n    height: 1px;\n    overflow: hidden;\n    position: absolute;\n    white-space: nowrap;\n    width: 1px;\n  }\n\n/**\n * A lightweight youtube embed. Still should feel the same to the user, just MUCH faster to initialize and paint.\n *\n * Thx to these as the inspiration\n *   https://storage.googleapis.com/amp-vs-non-amp/youtube-lazy.html\n *   https://autoplay-youtube-player.glitch.me/\n *\n * Once built it, I also found these:\n *   https://github.com/ampproject/amphtml/blob/master/extensions/amp-youtube (ğŸ‘ğŸ‘)\n *   https://github.com/Daugilas/lazyYT\n *   https://github.com/vb/lazyframe\n */\nclass LiteYTEmbed extends HTMLElement {\n    connectedCallback() {\n        this.videoId = this.getAttribute('videoid');\n\n        let playBtnEl = this.querySelector('.lty-playbtn');\n        // A label for the button takes priority over a [playlabel] attribute on the custom-element\n        this.playLabel = (playBtnEl && playBtnEl.textContent.trim()) || this.getAttribute('playlabel') || 'Play';\n\n        this.dataset.title = this.getAttribute('title') || \"\";\n\n        /**\n         * Lo, the youtube poster image!  (aka the thumbnail, image placeholder, etc)\n         *\n         * See https://github.com/paulirish/lite-youtube-embed/blob/master/youtube-thumbnail-urls.md\n         */\n        if (!this.style.backgroundImage) {\n          this.style.backgroundImage = `url(\"https://i.ytimg.com/vi/${this.videoId}/hqdefault.jpg\")`;\n          this.upgradePosterImage();\n        }\n\n        // Set up play button, and its visually hidden label\n        if (!playBtnEl) {\n            playBtnEl = document.createElement('button');\n            playBtnEl.type = 'button';\n            playBtnEl.classList.add('lty-playbtn');\n            this.append(playBtnEl);\n        }\n        if (!playBtnEl.textContent) {\n            const playBtnLabelEl = document.createElement('span');\n            playBtnLabelEl.className = 'lyt-visually-hidden';\n            playBtnLabelEl.textContent = this.playLabel;\n            playBtnEl.append(playBtnLabelEl);\n        }\n\n        this.addNoscriptIframe();\n\n        // for the PE pattern, change anchor's semantics to button\n        if(playBtnEl.nodeName === 'A'){\n            playBtnEl.removeAttribute('href');\n            playBtnEl.setAttribute('tabindex', '0');\n            playBtnEl.setAttribute('role', 'button');\n            // fake button needs keyboard help\n            playBtnEl.addEventListener('keydown', e => {\n                if( e.key === 'Enter' || e.key === ' ' ){\n                    e.preventDefault();\n                    this.activate();\n                }\n            });\n        }\n\n        // On hover (or tap), warm up the TCP connections we're (likely) about to use.\n        this.addEventListener('pointerover', LiteYTEmbed.warmConnections, {once: true});\n        this.addEventListener('focusin', LiteYTEmbed.warmConnections, {once: true});\n\n        // Once the user clicks, add the real iframe and drop our play button\n        // TODO: In the future we could be like amp-youtube and silently swap in the iframe during idle time\n        //   We'd want to only do this for in-viewport or near-viewport ones: https://github.com/ampproject/amphtml/pull/5003\n        this.addEventListener('click', this.activate);\n\n        // Chrome & Edge desktop have no problem with the basic YouTube Embed with ?autoplay=1\n        // However Safari desktop and most/all mobile browsers do not successfully track the user gesture of clicking through the creation/loading of the iframe,\n        // so they don't autoplay automatically. Instead we must load an additional 2 sequential JS files (1KB + 165KB) (un-br) for the YT Player API\n        // TODO: Try loading the the YT API in parallel with our iframe and then attaching/playing it. #82\n        this.needsYTApi = this.hasAttribute(\"js-api\") || navigator.vendor.includes('Apple') || navigator.userAgent.includes('Mobi');\n    }\n\n    /**\n     * Add a <link rel={preload | preconnect} ...> to the head\n     */\n    static addPrefetch(kind, url, as) {\n        const linkEl = document.createElement('link');\n        linkEl.rel = kind;\n        linkEl.href = url;\n        if (as) {\n            linkEl.as = as;\n        }\n        document.head.append(linkEl);\n    }\n\n    /**\n     * Begin pre-connecting to warm up the iframe load\n     * Since the embed's network requests load within its iframe,\n     *   preload/prefetch'ing them outside the iframe will only cause double-downloads.\n     * So, the best we can do is warm up a few connections to origins that are in the critical path.\n     *\n     * Maybe `<link rel=preload as=document>` would work, but it's unsupported: http://crbug.com/593267\n     * But TBH, I don't think it'll happen soon with Site Isolation and split caches adding serious complexity.\n     */\n    static warmConnections() {\n        if (LiteYTEmbed.preconnected) return;\n\n        // The iframe document and most of its subresources come right off youtube.com\n        LiteYTEmbed.addPrefetch('preconnect', 'https://www.youtube-nocookie.com');\n        // The botguard script is fetched off from google.com\n        LiteYTEmbed.addPrefetch('preconnect', 'https://www.google.com');\n\n        // Not certain if these ad related domains are in the critical path. Could verify with domain-specific throttling.\n        LiteYTEmbed.addPrefetch('preconnect', 'https://googleads.g.doubleclick.net');\n        LiteYTEmbed.addPrefetch('preconnect', 'https://static.doubleclick.net');\n\n        LiteYTEmbed.preconnected = true;\n    }\n\n    fetchYTPlayerApi() {\n        if (window.YT || (window.YT && window.YT.Player)) return;\n\n        this.ytApiPromise = new Promise((res, rej) => {\n            var el = document.createElement('script');\n            el.src = 'https://www.youtube.com/iframe_api';\n            el.async = true;\n            el.onload = _ => {\n                YT.ready(res);\n            };\n            el.onerror = rej;\n            this.append(el);\n        });\n    }\n\n    /** Return the YT Player API instance. (Public L-YT-E API) */\n    async getYTPlayer() {\n        if(!this.playerPromise) {\n            await this.activate();\n        }\n\n        return this.playerPromise;\n    }\n\n    async addYTPlayerIframe() {\n        this.fetchYTPlayerApi();\n        await this.ytApiPromise;\n\n        const videoPlaceholderEl = document.createElement('div')\n        this.append(videoPlaceholderEl);\n\n        const paramsObj = Object.fromEntries(this.getParams().entries());\n\n        this.playerPromise = new Promise(resolve => {\n            let player = new YT.Player(videoPlaceholderEl, {\n                width: '100%',\n                videoId: this.videoId,\n                playerVars: paramsObj,\n                events: {\n                    'onReady': event => {\n                        event.target.playVideo();\n                        resolve(player);\n                    }\n                }\n            });\n        });\n    }\n\n    // Add the iframe within <noscript> for indexability discoverability. See https://github.com/paulirish/lite-youtube-embed/issues/105\n    addNoscriptIframe() {\n        const iframeEl = this.createBasicIframe();\n        const noscriptEl = document.createElement('noscript');\n        // Appending into noscript isn't equivalant for mysterious reasons: https://html.spec.whatwg.org/multipage/scripting.html#the-noscript-element\n        noscriptEl.innerHTML = iframeEl.outerHTML;\n        this.append(noscriptEl);\n    }\n\n    getParams() {\n        const params = new URLSearchParams(this.getAttribute('params') || []);\n        params.append('autoplay', '1');\n        params.append('playsinline', '1');\n        return params;\n    }\n\n    async activate(){\n        if (this.classList.contains('lyt-activated')) return;\n        this.classList.add('lyt-activated');\n\n        if (this.needsYTApi) {\n            return this.addYTPlayerIframe(this.getParams());\n        }\n\n        const iframeEl = this.createBasicIframe();\n        this.append(iframeEl);\n\n        // Set focus for a11y\n        iframeEl.focus();\n    }\n\n    createBasicIframe(){\n        const iframeEl = document.createElement('iframe');\n        iframeEl.width = 560;\n        iframeEl.height = 315;\n        // No encoding necessary as [title] is safe. https://cheatsheetseries.owasp.org/cheatsheets/Cross_Site_Scripting_Prevention_Cheat_Sheet.html#:~:text=Safe%20HTML%20Attributes%20include\n        iframeEl.title = this.playLabel;\n        iframeEl.allow = 'accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture';\n        iframeEl.allowFullscreen = true;\n        // AFAIK, the encoding here isn't necessary for XSS, but we'll do it only because this is a URL\n        // https://stackoverflow.com/q/64959723/89484\n        iframeEl.src = `https://www.youtube-nocookie.com/embed/${encodeURIComponent(this.videoId)}?${this.getParams().toString()}`;\n        return iframeEl;\n    }\n\n    /**\n     * In the spirit of the `lowsrc` attribute and progressive JPEGs, we'll upgrade the reliable\n     * poster image to a higher resolution one, if it's available.\n     * Interestingly this sddefault webp is often smaller in filesize, but we will still attempt it second\n     * because getting _an_ image in front of the user if our first priority.\n     *\n     * See https://github.com/paulirish/lite-youtube-embed/blob/master/youtube-thumbnail-urls.md for more details\n     */\n    upgradePosterImage() {\n         // Defer to reduce network contention.\n        setTimeout(() => {\n            const webpUrl = `https://i.ytimg.com/vi_webp/${this.videoId}/sddefault.webp`;\n            const img = new Image();\n            img.fetchPriority = 'low'; // low priority to reduce network contention\n            img.referrerpolicy = 'origin'; // Not 100% sure it's needed, but https://github.com/ampproject/amphtml/pull/3940\n            img.src = webpUrl;\n            img.onload = e => {\n                // A pretty ugly hack since onerror won't fire on YouTube image 404. This is (probably) due to\n                // Youtube's style of returning data even with a 404 status. That data is a 120x90 placeholder image.\n                // â€¦ per \"annoying yt 404 behavior\" in the .md\n                const noAvailablePoster = e.target.naturalHeight == 90 && e.target.naturalWidth == 120;\n                if (noAvailablePoster) return;\n\n                this.style.backgroundImage = `url(\"${webpUrl}\")`;\n            }\n        }, 100);\n    }\n}\n// Register custom element\ncustomElements.define('lite-youtube', LiteYTEmbed);\n\n.eleventy-plugin-youtube-embed lite-youtube {max-width:100%}\nPlay<iframe width=\"560\" height=\"315\" title=\"Play\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen=\"\" src=\"https://www.youtube-nocookie.com/embed/TXNQ01Sy6Xw?modestbranding=1&amp;autoplay=1&amp;playsinline=1\"></iframe>In the video Apple released, which highlights the Mac-driven editing process that Ben Stiller's team is using, something stood out to me: Wait, the video is super-jitteryâ€”this makes the Mac Mini look rough. What's going on?Then, after about 10 minutes of watching, I saw it: The showâ€™s lead editor, Geoffrey Richman, was working on a remote Mac through Jump Desktop, a screen sharing tool known for its high-speed â€œfluid remote desktopâ€ feature. Iâ€™ve used this tool. Though Iâ€™m not really rocking a Mac these days, Iâ€™m a fan.Hereâ€™s the exact moment it hit me, carefully cropped to avoid spoilers:In other words, little of the horsepower being used in this editing process is actually coming from the Mac Mini on this guyâ€™s desk. Instead, itâ€™s being driven by another Mac on the other side of a speedy internet connection. Given that the Jump Desktop app window was hidden away in an earlier part of the clip, Iâ€™m not entirely sure we were supposed to see that, but there it is. Oops.(To be fair, the promotional materials do not hide that this is a remote process, but they do not mention the use of Jump Desktop, which seems like a missed opportunity to promote a small-scale Mac developer. Câ€™mon Apple, do better.)So here's a challenge about video production that is unique to the film and television mediums: There is a genuine risk of stuff getting pirated before it's ready. Beyond tethering everyone to NDAs, some of this can be avoided by having the editors work in a centralized place, avoiding networked access to the video files. After all, if an editor goes rogue, you can just take away their key card. There are even standards, produced by the Content Delivery and Security Association, on how film studios can protect their works mid-edit.One problem: COVID-19 made the prior strategy of localizing the editors in the same place untenable. Sponsored By TLDR Want a byte-sized version of Hacker News? Try TLDRâ€™s free daily newsletter.TLDR covers the most interesting tech, science, and coding news in just 5 minutes.No sports, politics, or weather.Subscribe for free!This means that a new normal in the video production realm is the rise of â€œremote editing,â€ in which editors use remote access software to do the editing on a virtual machine or office workstation. High speed connections are necessary to make this work on both endsâ€”meaning Starbucks is off the tableâ€”but it's more than possible. Jump Desktop is a good option for this, but Parsec is arguably an even better one.This also has other benefits. For one thing, high-end video production is quite storage-intensive, which is why your favorite YouTuber constantly talks about their editing rigs and network-attached storage. By putting this stuff offsite, they can put all this data on a real server.To me, though, it highlights a huge issue with Appleâ€™s current professional offerings. They are built to work on a single machine. At least for high-end use cases, the remote workflow threatens to cut them out of the equation entirely, as cloud devices with access to nearly unlimited resources gradually outpace individual machines. In fact, there is a version of the editor he was using, Avid Media Composer, that is cloud-based and built specifically for this very use case.The astounding part of this editing process, which Apple wanted to highlight so much that they shot an entire film about it, is that the Macs are honestly the least important part of the workflow. If Jump Desktop made a Chromebook version of its app, the Mac on Richmanâ€™s desk wouldn't even be necessary. Not that he would want to, but he could do this on a Chromebook.Put another way, if Stiller's team was building this for Amazon or Netflix, would that be a Mac Mini on Richmanâ€™s desk, or an HP or Lenovo box? Why even use a Mac in this editing process at all, when other companies offer access to better GPUs anyway?See, one issue with the way Apple sells its machines at the enterprise level is that they basically have no traditional server offerings, despite that being the norm elsewhere. If you want to run a Mac in the cloud, it has to be a full machine in most cases. Worse, it canâ€™t be split up into a bunch of virtual machines, thanks to requirements in its EULA that seem designed to protect its hardware business above all else.At the enterprise or cloud level, where VMs are quite common, this is hugely inefficient. Often large companies will buy the most powerful servers they can and parse them out into smaller pieces. Appleâ€™s end-user license agreement for MacOS Sequoia specifically limits the upside of such an approach:Virtualization. For each copy of the Apple Software subject to a lease under this Section 3, either a Lessor or a Lessee (but not both) may install, use and run additional copies or instances of the Apple Software within virtual operating system environments in accordance with Section 2B (iii), provided that a Lessor may only virtualize a single instance or copy of the Apple Software as a provisioning tool for the purpose of providing a Lessee with access to and use of the Apple Software pursuant to this Section 3.Apple used to serve this market with a device called Xserve, but it essentially gave it up about 15 years ago. Almost unwittingly, this video highlights the folly of that decision, which became more obvious thanks to COVID-19 and the rise of remote work.Itâ€™s not quite accurate to say that the Mac Mini is just for show, but itâ€™s less necessary for making this setup work than it appears at first glance.These editors aren't working on Macs, per se. They're working around them. Sure, there's an Apple logo in the top-left corner (two, actually), but it feels superfluous, knowing that the software isnâ€™t directly on the machine and it just as easily be running on a Windows or Linux box a thousand miles away. There are way more efficient ways to do this, and Apple doesn't offer them. Instead it relies on cloud providers like MacStadium, or localized IT teams, to work around their convoluted rules around VMs. Meanwhile, Microsoftâ€™s emphasis on VMs, as highlighted by its Windows 365 offering, tee them up for a future of scaleable remote editing.Hence why this editor is using a remote access tool by a tiny company to help produce Appleâ€™s most important TV show. If I were Apple, I would ask my software team why they've saddled their most significant and influential high-end users with such a weird-ass setup.Then I would figure out how to fix it.Unsevered LinksSpeaking of Apple, I agree with this guy.Itâ€™s hard to find a modern vehicle without a giant infotainment screen inside of it, but it turns out that the screens are surprisingly unpopular with drivers, per Gizmodo.Play<iframe width=\"560\" height=\"315\" title=\"Play\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen=\"\" src=\"https://www.youtube-nocookie.com/embed/aaNdMAGEsqk?modestbranding=1&amp;autoplay=1&amp;playsinline=1\"></iframe>Jesse Welles made his national television debut the other night, playing for Jimmy Kimmelâ€™s audience. Also, he released an album of all of his YouTube performances, and the reason he did so, according to Saving Country Music, is super-interesting and surprisingly technical.--Find this one an interesting read? Share it with a pal! And back at it in a couple of days with a fresh one.",
    "summary": {
      "en": "Apple's recent promotional video for the TV show *Severance* unintentionally revealed a significant flaw in its appeal to professional video editors. The video showcased the editing process using a Mac, but it became clear that the editing was actually done remotely via a screen-sharing tool called Jump Desktop. This means that the powerful editing capabilities were not coming from the Mac Mini on screen, but from another Mac located elsewhere.\n\nThis highlights a critical issue: Appleâ€™s professional offerings are designed for single machines, which can be a disadvantage in the growing field of remote editing. Many editors are now using cloud-based tools, which could potentially outperform individual Macs. Apple's lack of traditional server options and limitations on virtual machine use make it less competitive in this area.\n\nAs remote editing becomes more common, especially post-COVID, Apple may need to rethink its approach to better serve high-end users. The video inadvertently shows that while the Macs featured are present, they are not central to the editing process, suggesting that Apple's offerings could be outpaced by competitors who focus on cloud services and virtual machines.",
      "ko": "ì• í”Œì˜ ìµœê·¼ TV í”„ë¡œê·¸ë¨ *Severance* í™ë³´ ì˜ìƒì€ ì „ë¬¸ ë¹„ë””ì˜¤ í¸ì§‘ìë“¤ì—ê²Œ ì¤‘ìš”í•œ ê²°ì ì„ ë“œëŸ¬ëƒˆë‹¤. ì´ ì˜ìƒì€ ë§¥ì„ ì‚¬ìš©í•œ í¸ì§‘ ê³¼ì •ì„ ë³´ì—¬ì£¼ì—ˆì§€ë§Œ, ì‹¤ì œë¡œëŠ” Jump Desktopì´ë¼ëŠ” í™”ë©´ ê³µìœ  ë„êµ¬ë¥¼ í†µí•´ ì›ê²©ìœ¼ë¡œ í¸ì§‘ì´ ì´ë£¨ì–´ì¡Œë‹¤ëŠ” ì‚¬ì‹¤ì´ ë“œëŸ¬ë‚¬ë‹¤. ì¦‰, í™”ë©´ì— ë³´ì´ëŠ” ë§¥ ë¯¸ë‹ˆì˜ ê°•ë ¥í•œ í¸ì§‘ ê¸°ëŠ¥ì€ ë‹¤ë¥¸ ì¥ì†Œì— ìˆëŠ” ë§¥ì—ì„œ ì œê³µëœ ê²ƒì´ì—ˆë‹¤.\n\nì´ë¡œ ì¸í•´ ì¤‘ìš”í•œ ë¬¸ì œê°€ ë¶€ê°ëœë‹¤. ì• í”Œì˜ ì „ë¬¸ ì œí’ˆì€ ë‹¨ì¼ ê¸°ê¸°ë¥¼ ìœ„í•´ ì„¤ê³„ë˜ì—ˆê¸° ë•Œë¬¸ì— ì›ê²© í¸ì§‘ì´ ì¦ê°€í•˜ëŠ” ìƒí™©ì—ì„œëŠ” ë¶ˆë¦¬í•  ìˆ˜ ìˆë‹¤. ë§ì€ í¸ì§‘ìë“¤ì´ ì´ì œ í´ë¼ìš°ë“œ ê¸°ë°˜ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ê³  ìˆìœ¼ë©°, ì´ëŠ” ê°œë³„ ë§¥ë³´ë‹¤ ë” ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë°œíœ˜í•  ê°€ëŠ¥ì„±ì´ ìˆë‹¤. ì• í”Œì€ ì „í†µì ì¸ ì„œë²„ ì˜µì…˜ì´ ë¶€ì¡±í•˜ê³  ê°€ìƒ ë¨¸ì‹  ì‚¬ìš©ì— ì œí•œì´ ìˆì–´ ì´ ë¶„ì•¼ì—ì„œ ê²½ìŸë ¥ì´ ë–¨ì–´ì§„ë‹¤.\n\níŠ¹íˆ COVID-19 ì´í›„ ì›ê²© í¸ì§‘ì´ ë³´í¸í™”ë¨ì— ë”°ë¼, ì• í”Œì€ ê³ ê¸‰ ì‚¬ìš©ìì—ê²Œ ë” ë‚˜ì€ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•˜ê¸° ìœ„í•´ ì ‘ê·¼ ë°©ì‹ì„ ì¬ê³ í•  í•„ìš”ê°€ ìˆì„ ê²ƒì´ë‹¤. ì´ ì˜ìƒì€ ë§¥ì´ ì¡´ì¬í•˜ì§€ë§Œ í¸ì§‘ ê³¼ì •ì˜ ì¤‘ì‹¬ì´ ì•„ë‹ˆë¼ëŠ” ì ì„ ë³´ì—¬ì£¼ë©°, í´ë¼ìš°ë“œ ì„œë¹„ìŠ¤ì™€ ê°€ìƒ ë¨¸ì‹ ì— ì§‘ì¤‘í•˜ëŠ” ê²½ìŸìë“¤ì—ê²Œ ì• í”Œì˜ ì œí’ˆì´ ë’¤ì²˜ì§ˆ ìˆ˜ ìˆìŒì„ ì‹œì‚¬í•œë‹¤.",
      "ja": "AppleãŒæœ€è¿‘å…¬é–‹ã—ãŸãƒ†ãƒ¬ãƒ“ç•ªçµ„ã€ã‚»ãƒ´ã‚¡ãƒ©ãƒ³ã‚¹ã€ã®ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ãƒ“ãƒ‡ã‚ªã¯ã€ãƒ—ãƒ­ã®ãƒ“ãƒ‡ã‚ªç·¨é›†è€…ã«å¯¾ã™ã‚‹ã‚¢ãƒ”ãƒ¼ãƒ«ã«ãŠã„ã¦é‡è¦ãªæ¬ é™¥ã‚’ç„¡æ„è­˜ã®ã†ã¡ã«æ˜ã‚‰ã‹ã«ã—ã¾ã—ãŸã€‚ã“ã®ãƒ“ãƒ‡ã‚ªã§ã¯Macã‚’ä½¿ã£ãŸç·¨é›†ãƒ—ãƒ­ã‚»ã‚¹ãŒç´¹ä»‹ã•ã‚Œã¾ã—ãŸãŒã€å®Ÿéš›ã«ã¯Jump Desktopã¨ã„ã†ç”»é¢å…±æœ‰ãƒ„ãƒ¼ãƒ«ã‚’é€šã˜ã¦ãƒªãƒ¢ãƒ¼ãƒˆã§ç·¨é›†ãŒè¡Œã‚ã‚Œã¦ã„ã‚‹ã“ã¨ãŒåˆ†ã‹ã‚Šã¾ã—ãŸã€‚ã¤ã¾ã‚Šã€ç”»é¢ä¸Šã®Mac Miniã‹ã‚‰ã§ã¯ãªãã€åˆ¥ã®å ´æ‰€ã«ã‚ã‚‹Macã‹ã‚‰å¼·åŠ›ãªç·¨é›†æ©Ÿèƒ½ãŒæä¾›ã•ã‚Œã¦ã„ãŸã®ã§ã™ã€‚\n\nã“ã‚Œã¯é‡è¦ãªå•é¡Œã‚’æµ®ãå½«ã‚Šã«ã—ã¦ã„ã¾ã™ã€‚Appleã®ãƒ—ãƒ­å‘ã‘è£½å“ã¯å˜ä¸€ã®ãƒã‚·ãƒ³å‘ã‘ã«è¨­è¨ˆã•ã‚Œã¦ãŠã‚Šã€ãƒªãƒ¢ãƒ¼ãƒˆç·¨é›†ãŒæ™®åŠã™ã‚‹ä¸­ã§ä¸åˆ©ã«ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚å¤šãã®ç·¨é›†è€…ã¯ç¾åœ¨ã€ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ™ãƒ¼ã‚¹ã®ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¦ãŠã‚Šã€ã“ã‚Œã‚‰ã¯å€‹ã€…ã®Macã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç™ºæ®ã™ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚Appleã¯å¾“æ¥ã®ã‚µãƒ¼ãƒãƒ¼ã‚ªãƒ—ã‚·ãƒ§ãƒ³ãŒä¸è¶³ã—ã¦ãŠã‚Šã€ä»®æƒ³ãƒã‚·ãƒ³ã®ä½¿ç”¨ã«ã‚‚åˆ¶é™ãŒã‚ã‚‹ãŸã‚ã€ã“ã®åˆ†é‡ã§ã®ç«¶äº‰åŠ›ãŒä½ä¸‹ã—ã¦ã„ã¾ã™ã€‚\n\nç‰¹ã«COVIDä»¥é™ã€ãƒªãƒ¢ãƒ¼ãƒˆç·¨é›†ãŒä¸€èˆ¬çš„ã«ãªã‚‹ä¸­ã§ã€Appleã¯é«˜ç´šãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã‚Šè‰¯ã„ã‚µãƒ¼ãƒ“ã‚¹ã‚’æä¾›ã™ã‚‹ãŸã‚ã«ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’è¦‹ç›´ã™å¿…è¦ãŒã‚ã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚ã“ã®ãƒ“ãƒ‡ã‚ªã¯ã€MacãŒç™»å ´ã—ã¦ã„ã‚‹ã‚‚ã®ã®ã€ç·¨é›†ãƒ—ãƒ­ã‚»ã‚¹ã®ä¸­å¿ƒã§ã¯ãªã„ã“ã¨ã‚’ç¤ºã—ã¦ãŠã‚Šã€ã‚¯ãƒ©ã‚¦ãƒ‰ã‚µãƒ¼ãƒ“ã‚¹ã‚„ä»®æƒ³ãƒã‚·ãƒ³ã«ç„¦ç‚¹ã‚’å½“ã¦ã‚‹ç«¶åˆä»–ç¤¾ã«è¿½ã„æŠœã‹ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã“ã¨ã‚’ç¤ºå”†ã—ã¦ã„ã¾ã™ã€‚"
    }
  },
  {
    "id": "0f4766ce7f9c48be",
    "title": {
      "en": "Utah becomes first US state to ban fluoride in its water",
      "ko": "ìœ íƒ€, ë¯¸êµ­ ìµœì´ˆ ë¶ˆì†Œ ê¸ˆì§€",
      "ja": "ãƒ¦ã‚¿å·ã€ãƒ•ãƒƒç´ ç¦æ­¢ï¼"
    },
    "type": "story",
    "url": "https://www.bbc.com/news/articles/c4gmggp2y99o",
    "score": 69,
    "by": "Jimmc414",
    "time": 1743275945,
    "content": "Utah becomes first US state to ban fluoride in its water10 hours agoShareSaveNadine YousifBBC NewsShareSaveGetty ImagesUtah governor Spencer Cox signed the fluoride ban into law this weekUtah has become the first US state to ban the use of fluoride in its public water, following concerns raised by health secretary Robert F Kennedy that the mineral poses potential health risks.Governor Spencer Cox signed the ban into law this week, which will go into effect on 7 May. Other states, including Florida and Ohio, are weighing similar legislation.Fluoride has been added to US drinking water since 1945 to prevent cavities.Utah's move to remove the mineral has been criticised by experts, who worry it will have consequences for oral health, especially for children.The bill, signed by Cox on Thursday, prohibits communities from adding fluoride to their public water supplies.The law does not mention any public health concerns related to the mineral, but Republican state lawmaker Stephanie Gricius - who introduced the bill in the state legislature - has argued that there is research suggesting fluoride could have possible cognitive effects in children.Gricius has said that her bill would give citizens a choice whether they want to consume fluoride or not.This concern over fluoride was previously raised by Kennedy, the US health secretary, who said in November that \"the Trump White House will advise all US water systems to remove fluoride from public water\".He alleged the chemical found in toothpaste and regularly used by dentists \"is an industrial waste associated with arthritis, bone fractures, bone cancer, IQ loss, neurodevelopmental disorders, and thyroid disease\".Most public health experts have rejected these claims and alleged that Kennedy had cited data from studies conducted in countries with far higher levels of fluoride in their water systems than the US has. The American Dental Association sharply criticised Utah for its decision, saying that it shows \"wanton disregard for the oral health and well-being of their constituents\".\"It is disheartening to see that a proven, public health policy, which exists for the greater good of an entire community's oral health, has been dismantled based on distorted pseudoscience,\" the association's president, Denver dentist Brett Kessler, said in a statement.Many public health groups, including the American Academy of Pediatrics and the Centers for Disease Control and Prevention, have long supported adding small amounts of fluoride to drinking water. The US Public Health Service reduced the amount of fluoride it recommended adding to water in 2015, but the federal government has encouraged states since the 1960s to add small amounts of the chemical to water to help prevent cavities and aid oral health.Recent court rulings have led to the reduction of fluoride in US water, and some experts have questioned the continued need for it in water systems given its wide availability in toothpaste and other dental products.Most of western Europe does not add fluoride to its water. In England, about one in 10 people has fluoridated drinking water, though a programme has since been introduced to fluoridate water for 1.6 million people in north-east England.By contrast, around 63% of the US population have fluoridated water.Experts who support putting fluoride in water says studies show that community water fluoridation prevents at least 25% of tooth decay in children and adults.\"The scientific weight of sound evidence around the benefit of community water fluoridation is clear and compelling,\" the American Dental Association said in October of last year.Prof Avijit Banerjee, chair of cariology and operative dentistry at King's College London, previously told the BBC that \"the potential harmful effects of fluoride cited have not been associated with the very low levels of fluoride used in water fluoridation programmes\".What RFK Jr could do on US vaccines, fluoride and drugsFact-checking RFK Jr's views on health policyCalls for fluoride in water to combat child tooth decayWater fluoridation expansion plans confirmedUS politicsUnited StatesUtahRobert F Kennedy Jr",
    "summary": {
      "en": "Utah has become the first state in the U.S. to ban fluoride in public drinking water, with the law signed by Governor Spencer Cox taking effect on May 7. This decision follows concerns from health officials, including Robert F. Kennedy Jr., who suggested that fluoride may have health risks, particularly for children. Critics, including dental health experts, argue that removing fluoride could harm oral health, as it has been used since 1945 to prevent cavities.\n\nThe new law prohibits communities from adding fluoride to their water supplies, and supporters of the ban argue it gives people the choice to consume fluoride or not. However, many public health organizations, including the American Dental Association and the Centers for Disease Control and Prevention, advocate for fluoride in water, citing its benefits in reducing tooth decay. They argue that the potential risks associated with fluoride are not supported by evidence from the low levels used in water systems. \n\nWhile some other states like Florida and Ohio are considering similar bans, experts warn that Utah's decision could negatively impact public health, especially for children.",
      "ko": "ìœ íƒ€ì£¼ê°€ ë¯¸êµ­ì—ì„œ ê³µê³µ ìŒìš©ìˆ˜ì— ë¶ˆì†Œë¥¼ ê¸ˆì§€í•œ ì²« ë²ˆì§¸ ì£¼ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤. ìŠ¤íœì„œ ì½•ìŠ¤ ì£¼ì§€ì‚¬ê°€ ì„œëª…í•œ ì´ ë²•ì•ˆì€ 5ì›” 7ì¼ë¶€í„° ì‹œí–‰ë©ë‹ˆë‹¤. ì´ ê²°ì •ì€ ë¡œë²„íŠ¸ F. ì¼€ë„¤ë”” ì£¼ë‹ˆì–´ë¥¼ í¬í•¨í•œ ë³´ê±´ ë‹¹êµ­ìë“¤ì˜ ìš°ë ¤ì— ë”°ë¥¸ ê²ƒìœ¼ë¡œ, ë¶ˆì†Œê°€ íŠ¹íˆ ì–´ë¦°ì´ì—ê²Œ ê±´ê°• ìœ„í—˜ì„ ì´ˆë˜í•  ìˆ˜ ìˆë‹¤ê³  ì œê¸°ë˜ì—ˆìŠµë‹ˆë‹¤. ë°˜ë©´, ì¹˜ê³¼ ê±´ê°• ì „ë¬¸ê°€ë“¤ì€ ë¶ˆì†Œë¥¼ ì œê±°í•˜ë©´ êµ¬ê°• ê±´ê°•ì— í•´ë¡œìš¸ ìˆ˜ ìˆë‹¤ê³  ì£¼ì¥í•˜ë©°, ë¶ˆì†ŒëŠ” 1945ë…„ë¶€í„° ì¶©ì¹˜ë¥¼ ì˜ˆë°©í•˜ëŠ” ë° ì‚¬ìš©ë˜ì–´ ì™”ìŠµë‹ˆë‹¤.\n\nìƒˆë¡œìš´ ë²•ì•ˆì€ ì§€ì—­ ì‚¬íšŒê°€ ìˆ˜ë—ë¬¼ì— ë¶ˆì†Œë¥¼ ì¶”ê°€í•˜ëŠ” ê²ƒì„ ê¸ˆì§€í•©ë‹ˆë‹¤. ì´ ê¸ˆì§€ ì¡°ì¹˜ë¥¼ ì§€ì§€í•˜ëŠ” ì‚¬ëŒë“¤ì€ ê°œì¸ì´ ë¶ˆì†Œë¥¼ ì„­ì·¨í• ì§€ ë§ì§€ë¥¼ ì„ íƒí•  ìˆ˜ ìˆëŠ” ê¶Œë¦¬ë¥¼ ì¤€ë‹¤ê³  ì£¼ì¥í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ë¯¸êµ­ì¹˜ê³¼í˜‘íšŒì™€ ì§ˆë³‘í†µì œì˜ˆë°©ì„¼í„°ë¥¼ í¬í•¨í•œ ë§ì€ ê³µê³µ ë³´ê±´ ë‹¨ì²´ë“¤ì€ ë¶ˆì†Œê°€ ì¶©ì¹˜ ì˜ˆë°©ì— ë„ì›€ì´ ëœë‹¤ê³  ì£¼ì¥í•˜ë©°, ë¬¼ ì‹œìŠ¤í…œì—ì„œ ì‚¬ìš©ë˜ëŠ” ë‚®ì€ ìˆ˜ì¤€ì˜ ë¶ˆì†Œì™€ ê´€ë ¨ëœ ì ì¬ì  ìœ„í—˜ì€ ì¦ê±°ë¡œ ë’·ë°›ì¹¨ë˜ì§€ ì•ŠëŠ”ë‹¤ê³  ë°˜ë°•í•©ë‹ˆë‹¤.\n\ní”Œë¡œë¦¬ë‹¤ì™€ ì˜¤í•˜ì´ì˜¤ì™€ ê°™ì€ ë‹¤ë¥¸ ì£¼ë“¤ë„ ìœ ì‚¬í•œ ê¸ˆì§€ë¥¼ ê³ ë ¤í•˜ê³  ìˆì§€ë§Œ, ì „ë¬¸ê°€ë“¤ì€ ìœ íƒ€ì˜ ê²°ì •ì´ íŠ¹íˆ ì–´ë¦°ì´ì˜ ê³µê³µ ê±´ê°•ì— ë¶€ì •ì ì¸ ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆë‹¤ê³  ê²½ê³ í•˜ê³  ìˆìŠµë‹ˆë‹¤.",
      "ja": "ãƒ¦ã‚¿å·ã¯ã€ã‚¢ãƒ¡ãƒªã‚«ã§åˆã‚ã¦å…¬å…±ã®é£²æ–™æ°´ã«ãƒ•ãƒƒç´ ã‚’æ·»åŠ ã™ã‚‹ã“ã¨ã‚’ç¦æ­¢ã™ã‚‹æ³•å¾‹ã‚’åˆ¶å®šã—ã¾ã—ãŸã€‚ã“ã®æ³•å¾‹ã¯ã€ã‚¹ãºãƒ³ã‚µãƒ¼ãƒ»ã‚³ãƒƒã‚¯ã‚¹çŸ¥äº‹ã«ã‚ˆã£ã¦ç½²åã•ã‚Œã€5æœˆ7æ—¥ã«æ–½è¡Œã•ã‚Œã¾ã™ã€‚ã“ã®æ±ºå®šã¯ã€ãƒ­ãƒãƒ¼ãƒˆãƒ»Fãƒ»ã‚±ãƒãƒ‡ã‚£ãƒ»ã‚¸ãƒ¥ãƒ‹ã‚¢ã‚’å«ã‚€å¥åº·å°‚é–€å®¶ã®æ‡¸å¿µã‚’å—ã‘ãŸã‚‚ã®ã§ã€ãƒ•ãƒƒç´ ãŒç‰¹ã«å­ä¾›ã«å¯¾ã—ã¦å¥åº·ãƒªã‚¹ã‚¯ã‚’ã‚‚ãŸã‚‰ã™å¯èƒ½æ€§ãŒã‚ã‚‹ã¨æŒ‡æ‘˜ã•ã‚Œã¦ã„ã¾ã™ã€‚ä¸€æ–¹ã§ã€æ­¯ç§‘åŒ»ç™‚ã®å°‚é–€å®¶ãŸã¡ã¯ã€ãƒ•ãƒƒç´ ã‚’å–ã‚Šé™¤ãã“ã¨ãŒå£è…”ã®å¥åº·ã«æ‚ªå½±éŸ¿ã‚’åŠã¼ã™å¯èƒ½æ€§ãŒã‚ã‚‹ã¨æ‰¹åˆ¤ã—ã¦ã„ã¾ã™ã€‚ãƒ•ãƒƒç´ ã¯1945å¹´ã‹ã‚‰è™«æ­¯äºˆé˜²ã«ä½¿ç”¨ã•ã‚Œã¦ãã¾ã—ãŸã€‚\n\næ–°ã—ã„æ³•å¾‹ã¯ã€åœ°åŸŸç¤¾ä¼šãŒæ°´é“æ°´ã«ãƒ•ãƒƒç´ ã‚’æ·»åŠ ã™ã‚‹ã“ã¨ã‚’ç¦æ­¢ã—ã¦ã„ã¾ã™ã€‚ã“ã®ç¦æ­¢ã«è³›æˆã™ã‚‹äººã€…ã¯ã€ãƒ•ãƒƒç´ ã‚’æ‘‚å–ã™ã‚‹ã‹ã©ã†ã‹ã®é¸æŠè‚¢ã‚’äººã€…ã«ä¸ãˆã‚‹ã¨ä¸»å¼µã—ã¦ã„ã¾ã™ã€‚ã—ã‹ã—ã€ã‚¢ãƒ¡ãƒªã‚«æ­¯ç§‘åŒ»å¸«ä¼šã‚„ç–¾ç—…äºˆé˜²ç®¡ç†ã‚»ãƒ³ã‚¿ãƒ¼ãªã©ã€å¤šãã®å…¬è¡†è¡›ç”Ÿå›£ä½“ã¯ã€æ°´é“æ°´ã«ãƒ•ãƒƒç´ ã‚’å«ã‚ã‚‹ã“ã¨ã‚’æ”¯æŒã—ã¦ãŠã‚Šã€è™«æ­¯ã®äºˆé˜²ã«ãŠã‘ã‚‹ãã®åˆ©ç‚¹ã‚’æŒ™ã’ã¦ã„ã¾ã™ã€‚å½¼ã‚‰ã¯ã€æ°´é“ã‚·ã‚¹ãƒ†ãƒ ã§ä½¿ç”¨ã•ã‚Œã‚‹ä½æ¿ƒåº¦ã®ãƒ•ãƒƒç´ ã«é–¢ã™ã‚‹æ½œåœ¨çš„ãªãƒªã‚¹ã‚¯ã¯ã€è¨¼æ‹ ã«åŸºã¥ã„ã¦ã„ãªã„ã¨ä¸»å¼µã—ã¦ã„ã¾ã™ã€‚\n\nãƒ•ãƒ­ãƒªãƒ€å·ã‚„ã‚ªãƒã‚¤ã‚ªå·ãªã©ã€ä»–ã®å·ã§ã‚‚åŒæ§˜ã®ç¦æ­¢ã‚’æ¤œè¨ã—ã¦ã„ã‚‹ã¨ã“ã‚ãŒã‚ã‚Šã¾ã™ãŒã€å°‚é–€å®¶ãŸã¡ã¯ãƒ¦ã‚¿å·ã®æ±ºå®šãŒç‰¹ã«å­ä¾›ãŸã¡ã®å…¬è¡†è¡›ç”Ÿã«æ‚ªå½±éŸ¿ã‚’åŠã¼ã™å¯èƒ½æ€§ãŒã‚ã‚‹ã¨è­¦å‘Šã—ã¦ã„ã¾ã™ã€‚"
    }
  },
  {
    "id": "599bef1fb1033921",
    "title": {
      "en": "Paged Out #6 is out",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://pagedout.institute/?page=blog.php#entry-2025-03-29",
    "score": 178,
    "by": "pcfwik",
    "time": 1743271923,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "049c1756ef2992b1",
    "title": {
      "en": "The Mysterious Flow of Fluid in the Brain",
      "ko": "ë‡Œ ì† ì‹ ë¹„í•œ ìœ ë™",
      "ja": "è„³å†…ã®è¬ã®æµã‚Œ"
    },
    "type": "story",
    "url": "https://www.quantamagazine.org/the-mysterious-flow-of-fluid-in-the-brain-20250326/",
    "score": 9,
    "by": "isaacfrond",
    "time": 1743000542,
    "content": "Quanta Homepage\n\n                                        Physics\n\n                                        Mathematics\n\n                                        Biology\n\n                                        Computer Science\n\n                                        Topics\n\n                                        Archive\n\n                                        Blog\n\n                                        Columns\n\n                                        Interviews\n\n                                        Podcasts\n\n                                        Puzzles\n\n                                        Multimedia\n\n                                        Videos\n\n                                        About Quanta\n\n                                    An editorially independent publication supported by the Simons Foundation.\n\n                                    Follow Quanta\n\n    Facebook\n\n        Youtube\n\n        Instagram\n\n    RSS\n\n                Newsletter\n\n                    Get the latest news delivered to your inbox.\n\n                            Email\n\n                        Subscribe\n\n                        Recent newsletters\n\n                                    Gift Store\n\n                                        Shop Quanta gear\n\nNewsletter\n\n                    Get the latest news delivered to your inbox.\n\n                            Email\n\n                        Subscribe\n\n                        Recent newsletters\n\nQuanta Homepage\n\n                                        Physics\n\n                                        Mathematics\n\n                                        Biology\n\n                                        Computer Science\n\n                                        Topics\n\n                                        Archive\n\n        Saved articles\n\n                    Saved Articles\n                                            Create a reading list by clicking the Read Later icon next to the articles you wish to save.\n\n                            See all saved articles\n\n        Login\n\n                    Log out\n\n                    Change password\n\n                                Search\n\nHome\n\n                The Mysterious Flow of Fluid in the Brain\n\n        Comment\n\n        Save Article\n\n                    Read Later\n\n                                                Share\n\n    Facebook\n\n                            Copied!\n\n    Copy link\n         (opens a new tab)\n\n    Email\n\n    Pocket\n\n    Reddit\n\n    Ycombinator\n\nphysiology\n    The Mysterious Flow of Fluid in the Brain\n\n        By\n\n                Veronique Greenwood\n\nMarch 26, 2025\n\n            A popular hypothesis for how the brain clears molecular waste, which may help explain why sleep feels refreshing, is a subject of debate.\n\n        Comment\n\n        Save Article\n\n                    Read Later\n\nphysiology\n    The Mysterious Flow of Fluid in the Brain\n\n        By\n\n                Veronique Greenwood\n\nMarch 26, 2025\n\n            A popular hypothesis for how the brain clears molecular waste, which may help explain why sleep feels refreshing, is a subject of debate.\n\n        Comment\n\n        Save Article\n\n                    Read Later\n\nNo one knows why cerebrospinal fluid circulates through and around our brains, or what directs its flow.\n\n    Chanelle Nibbelink forQuanta Magazine\n\nEncased in the skull, perched atop the spine, the brain has a carefully managed existence. It receives only certain nutrients, filtered through the blood-brain barrier; an elaborate system of protective membranes surrounds it. That privileged space contains a mystery. For more than a century, scientists have wondered: If itâ€™s so hard for anything to get into the brain, how does waste get out?\nThe brain has one of the highest metabolisms of any organ in the body, and that process must yield by-products that need to be removed. In the rest of the body, blood vessels are shadowed by a system of lymphatic vessels. Molecules that have served their purpose in the blood move into these fluid-filled tubes and are swept away to the lymph nodes for processing. But blood vessels in the brain have no such outlet. Several hundred kilometers of them, all told, seem to thread their way through this dense, busily working tissue without a matching waste system.\nHowever, the brainâ€™s blood vessels are surrounded by open, fluid-filled spaces. In recent decades, the cerebrospinal fluid, or CSF, in those spaces has drawn a great deal of interest. â€œMaybe the CSF can be a highway, in a way, for the flow or exchange of different things within the brain,â€ said Steven Proulx, who studies the CSF system at the University of Bern.\nA recent paper in Cell contains a new report about what is going on around the brain (opens a new tab) and in its hidden cavities. A team at the University of Rochester led by the neurologist Maiken Nedergaard (opens a new tab) asked whether the slow pumping of the brainâ€™s blood vessels might be able to push the fluid around, among, and in some cases through cells, to potentially drive a system of drainage. In a mouse model, researchers injected a glowing dye into CSF, manipulated the blood vessel walls to trigger a pumping action, and saw the dye concentration increase in the brain soon after. They concluded that the movement of blood vessels might be enough to move CSF, and possibly the brainâ€™s waste, over long distances.\nThe team took a further step in their interpretation. Because this kind of pumping â€” distinct from the familiar pulse from the heart â€” is regularly observed during sleep, they suggest that perhaps their observations can help explain why sleep feels refreshing. But itâ€™s a hypothesis that not everyone agrees is well founded (opens a new tab). When it comes to ascribing purpose to the fluid moving through the brain, many researchers believe that the truth is still elusive.\nBrain Drain\nAt the center of the brain are flooded caverns, like great cisterns shrouded in darkness, called ventricles. Cerebrospinal fluid seeps from the ventricle walls and then moves. Under pressure, it emerges elsewhere within the skull, flows down the neck and enters the spine.\n\nThe neurologist Maiken Nedergaardâ€™s â€œglymphatic hypothesisâ€ proposes that cerebrospinal fluid helps drain waste from the brain during sleep. Her evidence is highly debated.\n\n    Adam Fenster, University of Rochester\n\nScientists have known for more than a century that, at the moment of death (opens a new tab), CSF flows from the spine into the brain. This suggests that the living brain somehow keeps the stuff moving, but no one knows exactly how or where it flows. Any arrows drawn on diagrams of the brain and skull to show its movement should not be taken as the complete truth.\nâ€œEveryone accepts that there must be some kind of flow here,â€ said Christer Betsholtz (opens a new tab), a professor of vascular biology at the Karolinska Institute in Sweden. â€œAbout half a liter of CSF is produced in the ventricles every day, and it has to get out. People are still fighting about where the cerebrospinal fluid gets out.â€\n\nAlso under discussion is whether it picks up waste on the way out of the brain and, crucially, how. There is good evidence that small molecules, at least, can diffuse through the spaces between cells, make their way to the CSF, and ride it out of the brain (opens a new tab). In fact, some researchers believe that the entire system works by way of passive diffusion.\nIn 2012, results from Nedergaardâ€™s lab suggested a more active process. Nedergaard, along with the neurologist Jeffrey Iliff (opens a new tab), then a postdoc in her lab, and their colleagues, injected a tracer into cerebrospinal fluid (opens a new tab) and watched it quickly arrive elsewhere. How did it get from one place to another? They proposed that the spaces around blood vessels commune with even smaller spaces deep in the brain, between individual cells. They also suggested that CSF moves through brain cells called astrocytes into those spaces. There, the fluid might drop off some molecules and pick up others; it may then wend its way back out to the spaces around blood vessels, and thence move waste out of the brain. All of this would have to be driven by a flow of uncertain mechanism.\nIt was a striking idea. Nedergaard, who is the senior author of the new paper, and colleagues soon made it more striking by linking it to another mystery: why sleep seems to be beneficial. In a 2013 paper, her team wrote that there was more movement of cerebrospinal fluid (opens a new tab) in sleeping and anesthetized mice than in waking ones â€” and that perhaps during sleep CSF sweeps waste out of the brain. Maybe this â€œbrainwashing,â€ as headlines described it, could provide one reason why sleep is necessary (opens a new tab), and explain how much better we feel after a good night of it.\n\nMark Belan/Quanta Magazine\n\nâ€œIâ€™m of the strong belief that the restorative part of sleep is not memory consolidation,â€ Nedergaard said. â€œMaybe it is partly. But it is really the housekeeping function of sleep that is important.â€\nIn the years since those initial studies, a large number of papers (opens a new tab) referencing this brain-drainage theory, called the glymphatic hypothesis, have been published. Itâ€™s a catchy idea, but parts of the story raise red flags (opens a new tab) to some researchers who study the brainâ€™s vasculature.\nAlan Verkman (opens a new tab), a professor emeritus at the University of California, San Francisco who studies fluid flow in the body, has argued that some aspects of the theory are physically implausible â€” for instance, the channels said to let the fluid in cannot actually play the role demanded of them. According to Betsholtz, there is no evidence that fluid is moving into the spaces around blood vessels that leave the brain.\nBut many other researchers appear to have accepted the glymphatic hypothesis. Thatâ€™s because it fills a hole in our understanding of the brain, said Donald McDonald (opens a new tab), who studies blood and lymph vessels at the UCSF School of Medicine. Personally, he doesnâ€™t feel that the theory holds water, but he acknowledges its popularity. It fits comfortably in the space where there is a mystery.\nEbb and Flow\n\n            Any arrows drawn on diagrams of the brain and skull to show the fluidâ€™s movement should not be taken as the complete truth.\n\nImagine a sealed bottle of water. To study that fluid in its natural state, you have to cut a hole in the bottle. This is the difficulty that scientists studying CSF flow have to deal with. â€œIf you are studying a fluid and you put a hole in the system, you really change it,â€ said Laura Lewis (opens a new tab), a professor of neuroscience at the Massachusetts Institute of Technology. â€œFluid dynamics are really easily disturbed by invasive procedures.â€ Further, so many behaviors that living animals perform, such as breathing and having a heartbeat, directly affect the fluid.\nBuilding a case for a new hypothesis in this area, then, is tricky. In the Nedergaard groupâ€™s recent Cell paper, the team wanted to explore an intriguing connection (opens a new tab) that would not only explain how CSF could be pumped between brain cells, but also link that process to sleep.\nFor the study, mice underwent surgery to have sensors, wires and tubes implanted within the brain â€” one way to study the bottle of water. The researchersâ€™ goal was to inject tracer dye into CSF at one point in the brain and then track its oscillations and dynamics while the mice slept.\nThe data showed that, while mice were in their nonâ€“rapid eye movement (NREM) phase of sleep, the concentration of tracer moved rhythmically. From a sensor perched above the brain surface, the researchers saw a pattern of increases and decreases, according to first author Natalie Haugland. â€œIt had this wave pattern.â€\nWhat could be driving this rhythmic flow? The researchers thought of the neurotransmitter norepinephrine, which causes blood vessels to constrict. â€œNorepinephrine is very well known for controlling blood flow,â€ Nedergaard said. Itâ€™s possible, they thought, that vessels constricting and relaxing could put enough force on the surrounding cerebrospinal fluid to push it through the brainâ€™s tissues.\n\nResearch led by Natalie Haugland suggests that pulses of norepinephrine help pump cerebrospinal fluid through the brain during non-REM sleep.\n\n    BjÃ¶rn Sigurdsson\n\nWhatâ€™s more, during NREM sleep norepinephrine levels change rhythmically. This neurotransmitter could help tie together their hypotheses â€” the physical movement of CSF through brain tissues and the â€œbrainwashingâ€ occurring during sleep.\nThe team engineered mice in which they could switch the production of the neurotransmitter on and off. When norepinephrine levels went up, the volume of CSF in the brain went up, they saw, suggesting that it was somehow altering the fluidâ€™s flow.\n\n            All of this would have to be driven by a flow of uncertain mechanism.\n\nThen, to test whether the pumping of blood vessels could move CSF, the team engineered mice with blood vessel walls they could manipulate directly. Instead of pumping the vessels slowly, as happens naturally, they moved the walls quickly â€” once every 10 seconds rather than once every 50. â€œWhen we did this, we increased CSF flow on one side of the brainâ€ in a very small area where they were pumping, Haugland said. â€œIt was very local. â€¦ Everywhere else in the brain it was the same.â€\nFor Nedergaard, Haugland and their collaborators, the findings tie together norepinephrine, the physical movement of blood vessels, and the flow of CSF in the brain. Nedergaard also asserts that the results are consistent with her groupâ€™s earlier finding that there is more brain drainage during sleep than during wakefulness.\nâ€œWe have been searching for why the glymphatic [system] primarily works when we sleep for a long time,â€ Nedergaard said. â€œThe paper is really about: Now weâ€™ve found the motor or the driver of how we wash the brain when we sleep.â€\nHowever, to critics of the theory, there are still too many open spaces.\nUnder Pressure\n\nMcDonald, of the UCSF School of Medicine, pointed out that the work is complex and requires many intricate methods. However, heâ€™s concerned that Nedergaard is working backward: seeking an explanation for her hypothesis rather than trying to find out how the system actually works. â€œIn this paper, itâ€™s unclear what is interpretation and what is data,â€ he said. â€œVery early on, their interpretation gets substituted for what actually are the data.â€ He pointed to schematics showing flow dynamics that he doesnâ€™t see supported, for instance.\nProulx questioned whether the tracer dye moved via an active force at all. The molecule is so small that it could be traveling by diffusion, he said. He imagines an experiment, using techniques Nedergaardâ€™s lab has used before, where a large molecule is infused into the CSF. If the rhythmic releases of norepinephrine correlate with the arrival of a larger tracer at a sensor on the brainâ€™s surface, that would be a fascinating finding. â€œThatâ€™s what I would have liked to have seen,â€ he said. To his eye, it would make a clearer connection between fluid flow and norepinephrine than the labâ€™s work has shown thus far.\nThe critiques of Nedergaardâ€™s work come on strong in part because this idea is currently the most prominent hypothesis of CSF flow in the brain. That may change if other researchers can introduce other ideas that can be tested. Another wrinkle is that not everyone means the same thing when they talk about the glymphatic system. â€œSome people use â€˜glymphaticsâ€™ to mean â€˜waste transport system of the brain.â€™ Other people use it to mean a really specific mechanistic model,â€ Lewis said. â€œItâ€™s clear that the brain has and needs a waste clearance system. â€¦ Itâ€™s really interesting to explore what that is and how that works.â€\n\n                Related:\n\n                                    How the Brain Protects Itself From Blood-Borne Threats\n\n                                    Sleep Evolved Before Brains. Hydras Are Living Proof.\n\n                                    Why Do We Die Without Sleep?\n\nHaugland, now a postdoc at the University of Oxford, is aware of the controversy about the glymphatic hypothesis. â€œThere is critique of it. Iâ€™m also not sure that we understand it in the right way,â€ she said. â€œThe more people who are actually working on finding out how it works, no matter what their hypothesis is â€” all that will help drive the field forward and give us more knowledge.\nâ€œThe results are what they are. They show something about the biology,â€ she continued. â€œWe are trying to ask a lot of questions and weâ€™re not, maybe, all the time very good at it because we donâ€™t know how it works â€” the big picture.â€\nâ€œNobody has the truth,â€ Proulx said, about what the brain is doing up there, in our skulls, to rid itself of its waste. â€œSome people think they know. But I think we donâ€™t know.â€\n\nBy Veronique Greenwood\n                Contributing Writer\n\n                March 26, 2025\n\n                    View PDF/Print Mode\n\n                            biology\n\n                            brains\n\n                            explainers\n\n                            metabolism\n\n                            neuroscience\n\n                            physiology\n\n                            sleep\n\n                    All topics\n\n     (opens a new tab)\n\nShare this article\n\n    Facebook\n\n                            Copied!\n\n    Copy link\n         (opens a new tab)\n\n    Email\n\n    Pocket\n\n    Reddit\n\n    Ycombinator\n\n                    Newsletter\n\n                    Get Quanta Magazine delivered to your inbox\n\n                    Subscribe now\n\n                    Recent newsletters\n\n             (opens a new tab)\n\nThe Quanta Newsletter\n\n                    Get highlights of the most important news delivered to your email inbox\n\n                            Email\n\n                        Subscribe\n\n                        Recent newsletters\n                                             (opens a new tab)\n\nAlso in Biology\n\n                    How Metabolism Can Shape Cellsâ€™ Destinies\n\n                developmental biology\n\n                    How Metabolism Can Shape Cellsâ€™ Destinies\n\n        By\n\n                Viviane Callier\n\n            March 21, 2025\n\n        Comment\n\n        Save Article\n\n                    Read Later\n\n                    How Did Multicellular Life Evolve?\n\n                The Joy of Why\n\n                    How Did Multicellular Life Evolve?\n\n        By\n\n                    Janna Levin\n\n                 +1 authors\n\n                        Steven Strogatz\n\n            March 20, 2025\n\n        Comment\n\n        Save Article\n\n                    Read Later\n\n                    A New, Chemical View of Ecosystems\n\n                ecology\n\n                    A New, Chemical View of Ecosystems\n\n        By\n\n                Molly Herring\n\n            March 5, 2025\n\n        Comment\n\n        Save Article\n\n                    Read Later\n\nComment on this article\n\n                    Quanta Magazine moderates comments tofacilitate an informed, substantive, civil conversation. Abusive, profane, self-promotional, misleading, incoherent or off-topic comments will be rejected. Moderators are staffed during regular business hours (New York time) and can only accept comments written in English.\n\n        Show comments\n\nNext article\n                Three Hundred Years Later, a Tool from Isaac Newton Gets an Update\n\nQuanta Homepage\n\n    Facebook\n\n        Youtube\n\n        Instagram\n\n                                        About Quanta\n\n                                        Archive\n\n                                        Contact Us\n\n                                        Terms & Conditions\n\n                                        Privacy Policy\n\n                        All Rights Reserved Â© 2025\n\n                    An editorially independent publication supported by the Simons Foundation.\n\n                        Simons Foundation\n\nQuanta Homepage\n\n    Facebook\n\n        Youtube\n\n        Instagram\n\nAbout Quanta\n\n                                        Archive\n\n                                        Contact Us\n\n                                        Terms & Conditions\n\n                                        Privacy Policy\n\nAll Rights Reserved Â© 2025\n\n                    An editorially independent publication supported by the Simons Foundation.\n\n                        Simons Foundation\n\nClose\n\n    Log in to Quanta\n\n            Use your social network\n\n                        Facebook                        Connect with Facebook\n\n                                                Connect with Google\n\n            or\n\n                    email\n\n                    password\n\n                    Remember me\n\n                        Forgot your password ?\n\n    Don't have an account yet?\n         Sign up\n\nClose\n\n        Forgot your password?\n        Weâ€™ll email you instructions to reset your password\n\n                email\n\nClose\n\n        Change your password\n        Enter your new password\n\n                Password\n\n                Retype new password\n\nClose\n\n        Sign Up\n\n                    First Name\n\n                    Last Name\n\n                    Email\n\n                    Password\n\n                    Retype Password\n\n            Creating an account means you accept Quanta Magazine's\n\n            Terms & Conditions and Privacy Policy",
    "summary": {
      "en": "The article discusses the mysterious flow of cerebrospinal fluid (CSF) in the brain and its potential role in waste removal, particularly during sleep. Researchers have debated how the brain clears waste since it lacks a traditional drainage system like the rest of the body. \n\nRecent studies suggest that the pumping action of blood vessels may help move CSF, which could assist in eliminating waste. A prominent theory called the \"glymphatic hypothesis\" proposes that this process is most effective during sleep, making sleep feel refreshing. However, this hypothesis is contested by some scientists who question the mechanisms proposed.\n\nA new study from the University of Rochester used mice to explore how CSF flows during sleep and implicated a neurotransmitter, norepinephrine, in driving this fluid movement. While some researchers support the glymphatic hypothesis, others express skepticism and emphasize the need for further investigation to fully understand how waste is cleared from the brain.\n\nOverall, the flow of CSF and its connection to sleep and brain health remains a complex and actively researched topic.",
      "ko": "ì´ ê¸°ì‚¬ëŠ” ë‡Œì—ì„œì˜ ë‡Œì²™ìˆ˜ì•¡(CSF)ì˜ ì‹ ë¹„ë¡œìš´ íë¦„ê³¼ íŠ¹íˆ ìˆ˜ë©´ ì¤‘ì— ë…¸íë¬¼ ì œê±°ì— ë¯¸ì¹˜ëŠ” ì ì¬ì  ì—­í• ì— ëŒ€í•´ ë‹¤ë£¹ë‹ˆë‹¤. ì—°êµ¬ìë“¤ì€ ë‡Œê°€ ì „í†µì ì¸ ë°°ìˆ˜ ì‹œìŠ¤í…œì´ ì—†ê¸° ë•Œë¬¸ì— ì–´ë–»ê²Œ ë…¸íë¬¼ì„ ì œê±°í•˜ëŠ”ì§€ì— ëŒ€í•´ ë…¼ì˜í•´ì™”ìŠµë‹ˆë‹¤.\n\nìµœê·¼ ì—°êµ¬ë“¤ì€ í˜ˆê´€ì˜ íŒí•‘ ì‘ìš©ì´ CSFì˜ íë¦„ì„ ë„ì™€ ë…¸íë¬¼ ì œê±°ì— ê¸°ì—¬í•  ìˆ˜ ìˆë‹¤ëŠ” ì ì„ ì œì‹œí•©ë‹ˆë‹¤. \"ê¸€ë¦¼í”„í‹± ê°€ì„¤\"ì´ë¼ëŠ” ì£¼ìš” ì´ë¡ ì€ ì´ ê³¼ì •ì´ ìˆ˜ë©´ ì¤‘ì— ê°€ì¥ íš¨ê³¼ì ì´ë¼ê³  ì£¼ì¥í•˜ë©°, ì´ë¡œ ì¸í•´ ìˆ˜ë©´ì´ ìƒì¾Œí•˜ê²Œ ëŠê»´ì§„ë‹¤ê³  ì„¤ëª…í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ ê°€ì„¤ì— ëŒ€í•´ ì¼ë¶€ ê³¼í•™ìë“¤ì€ ì œì•ˆëœ ë©”ì»¤ë‹ˆì¦˜ì— ì˜ë¬¸ì„ ì œê¸°í•˜ë©° ë°˜ëŒ€ ì˜ê²¬ì„ ë‚´ê³  ìˆìŠµë‹ˆë‹¤.\n\në¡œì²´ìŠ¤í„° ëŒ€í•™êµì˜ ìƒˆë¡œìš´ ì—°êµ¬ëŠ” ì¥ë¥¼ ì‚¬ìš©í•˜ì—¬ ìˆ˜ë©´ ì¤‘ CSFì˜ íë¦„ì„ ì¡°ì‚¬í•˜ì˜€ê³ , ì´ ì•¡ì²´ì˜ ì›€ì§ì„ì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ì‹ ê²½ì „ë‹¬ë¬¼ì§ˆì¸ ë…¸ë¥´ì—í”¼ë„¤í”„ë¦°ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ì¼ë¶€ ì—°êµ¬ìë“¤ì€ ê¸€ë¦¼í”„í‹± ê°€ì„¤ì„ ì§€ì§€í•˜ì§€ë§Œ, ë‹¤ë¥¸ ì—°êµ¬ìë“¤ì€ íšŒì˜ì ì¸ ì…ì¥ì„ ë³´ì´ë©° ë‡Œì—ì„œ ë…¸íë¬¼ì´ ì–´ë–»ê²Œ ì œê±°ë˜ëŠ”ì§€ë¥¼ ì™„ì „íˆ ì´í•´í•˜ê¸° ìœ„í•´ ì¶”ê°€ ì—°êµ¬ê°€ í•„ìš”í•˜ë‹¤ê³  ê°•ì¡°í•©ë‹ˆë‹¤.\n\nì „ë°˜ì ìœ¼ë¡œ CSFì˜ íë¦„ê³¼ ìˆ˜ë©´, ë‡Œ ê±´ê°• ê°„ì˜ ê´€ê³„ëŠ” ì—¬ì „íˆ ë³µì¡í•˜ê³  í™œë°œíˆ ì—°êµ¬ë˜ê³  ìˆëŠ” ì£¼ì œì…ë‹ˆë‹¤.",
      "ja": "ã“ã®è¨˜äº‹ã§ã¯ã€è„³å†…ã®è„Šé«„æ¶²ï¼ˆCSFï¼‰ã®ç¥ç§˜çš„ãªæµã‚Œã¨ã€ç‰¹ã«ç¡çœ ä¸­ã®å»ƒæ£„ç‰©é™¤å»ã«ãŠã‘ã‚‹å½¹å‰²ã«ã¤ã„ã¦è€ƒå¯Ÿã—ã¦ã„ã¾ã™ã€‚è„³ã«ã¯ä½“ã®ä»–ã®éƒ¨åˆ†ã®ã‚ˆã†ãªä¼çµ±çš„ãªæ’æ°´ã‚·ã‚¹ãƒ†ãƒ ãŒãªã„ãŸã‚ã€ç ”ç©¶è€…ãŸã¡ã¯è„³ãŒã©ã®ã‚ˆã†ã«å»ƒæ£„ç‰©ã‚’æ’é™¤ã™ã‚‹ã®ã‹ã«ã¤ã„ã¦è­°è«–ã‚’é‡ã­ã¦ãã¾ã—ãŸã€‚\n\næœ€è¿‘ã®ç ”ç©¶ã§ã¯ã€è¡€ç®¡ã®ãƒãƒ³ãƒ—ä½œç”¨ãŒCSFã®ç§»å‹•ã‚’åŠ©ã‘ã€å»ƒæ£„ç‰©ã®é™¤å»ã«å¯„ä¸ã™ã‚‹å¯èƒ½æ€§ãŒç¤ºå”†ã•ã‚Œã¦ã„ã¾ã™ã€‚ã€Œã‚°ãƒªãƒ³ãƒ•ã‚¡ãƒ†ã‚£ãƒƒã‚¯ä»®èª¬ã€ã¨å‘¼ã°ã‚Œã‚‹æœ‰åŠ›ãªç†è«–ã¯ã€ã“ã®ãƒ—ãƒ­ã‚»ã‚¹ãŒç¡çœ ä¸­ã«æœ€ã‚‚åŠ¹æœçš„ã§ã‚ã‚‹ãŸã‚ã€ç¡çœ ãŒãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥æ„Ÿã‚’ã‚‚ãŸã‚‰ã™ã¨æå”±ã—ã¦ã„ã¾ã™ã€‚ã—ã‹ã—ã€ã“ã®ä»®èª¬ã«ã¯ç•°è«–ã‚’å”±ãˆã‚‹ç§‘å­¦è€…ã‚‚ãŠã‚Šã€ææ¡ˆã•ã‚ŒãŸãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã«ç–‘å•ã‚’æŒã£ã¦ã„ã¾ã™ã€‚\n\nãƒ­ãƒã‚§ã‚¹ã‚¿ãƒ¼å¤§å­¦ã®æ–°ã—ã„ç ”ç©¶ã§ã¯ã€ãƒã‚¦ã‚¹ã‚’ä½¿ã£ã¦ç¡çœ ä¸­ã®CSFã®æµã‚Œã‚’èª¿æŸ»ã—ã€ç¥çµŒä¼é”ç‰©è³ªã§ã‚ã‚‹ãƒãƒ«ã‚¨ãƒ”ãƒãƒ•ãƒªãƒ³ãŒã“ã®æ¶²ä½“ã®å‹•ãã‚’ä¿ƒé€²ã™ã‚‹å½¹å‰²ã‚’æœãŸã—ã¦ã„ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚ä¸€éƒ¨ã®ç ”ç©¶è€…ã¯ã‚°ãƒªãƒ³ãƒ•ã‚¡ãƒ†ã‚£ãƒƒã‚¯ä»®èª¬ã‚’æ”¯æŒã—ã¦ã„ã¾ã™ãŒã€ä»–ã®ç ”ç©¶è€…ã¯æ‡ç–‘çš„ã§ã‚ã‚Šã€è„³ã‹ã‚‰ã®å»ƒæ£„ç‰©é™¤å»ã®ä»•çµ„ã¿ã‚’å®Œå…¨ã«ç†è§£ã™ã‚‹ãŸã‚ã«ã¯ã•ã‚‰ãªã‚‹èª¿æŸ»ãŒå¿…è¦ã ã¨å¼·èª¿ã—ã¦ã„ã¾ã™ã€‚\n\nå…¨ä½“ã¨ã—ã¦ã€CSFã®æµã‚Œã¨ç¡çœ ã€è„³ã®å¥åº·ã¨ã®é–¢é€£ã¯ã€è¤‡é›‘ã§æ´»ç™ºã«ç ”ç©¶ã•ã‚Œã¦ã„ã‚‹ãƒ†ãƒ¼ãƒã§ã™ã€‚"
    }
  },
  {
    "id": "fa0111a566ae5eea",
    "title": {
      "en": "Msgpack23 â€“ A modern, header-only C++ library for MessagePack (de)serialization",
      "ko": "ë©”ì‹œì§€íŒ©23: C++ë¡œ ê°„í¸í•˜ê²Œ!",
      "ja": "Msgpack23: C++ã§ç°¡å˜ã«ãƒ‡ãƒ¼ã‚¿å‡¦ç†"
    },
    "type": "story",
    "url": "https://github.com/rwindegger/msgpack23",
    "score": 13,
    "by": "gjvc",
    "time": 1743293747,
    "content": "msgpack23\nA modern, header-only C++ library for MessagePack serialization and deserialization.\nOverview\nmsgpack23 is a lightweight library that provides a straightforward approach to serializing and deserializing C++ data structures into the MessagePack format. It is written in modern C++ (targeting C++20 and beyond) and leverages templates and type traits to provide a flexible, zero-dependency solution for packing and unpacking various data types.\nKey Features\n\nHeader-only: Simply include the header and start using itâ€”no additional build steps or dependencies.\nModern C++: Uses C++ features like concepts to handle containers, maps, enums, time points, and user-defined types.\nExtensible: Allows you to define custom types by implementing pack and unpack member functions, automatically integrating them into the serialization pipeline.\nCollection and Map Support: Automatically detects and serializes STL containers (e.g., std::vector, std::map) without extra work.\nTime Point Support: Native support for serializing std::chrono::time_point objects.\nVariety of Primitive Types: Integers (signed/unsigned), booleans, floating-point, std::string, byte arrays, and nullptr are all supported out-of-the-box.\nEndian-Aware: Properly handles endianness using std::endian and std::byteswap to ensure portability.\n\nGetting Started\n\nClone the Repository\ngit clone https://github.com/rwindegger/msgpack23.git\n\nInclude the Header\nSince this is a header-only library, just include the main header in your project:\n#include \"msgpack23.hpp\"\n\nPack and Unpack\n#include <iostream>\n#include <map>\n#include \"msgpack23.hpp\"\n\nint main() {\n    // Create a map of some data\n    std::map<std::string, int> original {{\"apple\", 1}, {\"banana\", 2}};\n\n    // 1) Pack into a vector of std::byte\n    msgpack23::Packer packer;\n    auto packedData = packer(original);\n\n    // 2) Unpack back into a map\n    std::map<std::string, int> unpacked;\n    msgpack23::Unpacker unpacker(packedData);\n    unpacker(unpacked);\n\n    // Verify the result\n    for (auto const& [key, value] : unpacked) {\n        std::cout << key << \": \" << value << \"\\n\";\n    }\n    return 0;\n}\n\nCustom Types\nTo serialize your own types, define a pack and unpack function. The pack should accept a T & and the unpack should accept a T &.\nstruct MyData {\n   int64_t my_integer;\n   std::string my_string;\n\n   template<typename T>\n   std::vector<std::byte> pack(T &packer) const {\n      return packer(my_integer, my_string);\n   }\n\n   template<typename T>\n   void unpack(T &unpacker) {\n      unpacker(my_integer, my_string);\n   }\n};\n\nNow you can use MyData with msgpack23 just like any built-in type:\nMyData const my_data {42, \"Hello\" };\nauto const data = msgpack23::pack(my_data);\nauto obj = msgpack23::unpack<MyData>(data);\n\nWhy msgpack23?\n\nSimplicity: A single header with clearly structured pack/unpack logic.\nPerformance: Minimal overhead by using direct memory operations and compile-time type deductions.\nFlexibility: From primitive types and STL containers to custom structures, everything can be serialized with minimal boilerplate.\n\nContributing\nContributions, bug reports, and feature requests are welcome! Feel free to open an issue or submit a pull request.\n\nFork it!\nCreate your feature branch: git checkout -b feature/my-new-feature\nCommit your changes: git commit -am 'Add some feature'\nPush to the branch: git push origin feature/my-new-feature\nSubmit a pull request\n\nLicense\nThis project is licensed under the MIT License.\n\nHappy packing (and unpacking)! If you have any questions or feedback, please open an issue or start a discussion.",
    "summary": {
      "en": "**Summary of msgpack23**\n\nmsgpack23 is a modern, header-only C++ library designed for easy serialization and deserialization of C++ data into the MessagePack format. Here are the key points:\n\n- **Lightweight and Easy to Use**: Simply include a single header file and you can start using the library with no extra dependencies.\n\n- **Modern C++ Features**: Supports C++20 features, making it flexible for various data types including containers, maps, enums, and user-defined types.\n\n- **Custom Type Support**: You can create your own types by implementing packing and unpacking functions, which integrate seamlessly into the library.\n\n- **Built-in Support for Collections**: Automatically serializes standard containers like `std::vector` and `std::map`.\n\n- **Time Point Serialization**: Handles `std::chrono::time_point` objects natively.\n\n- **Variety of Data Types**: Supports multiple primitive types, including integers, booleans, floating-point numbers, strings, and byte arrays.\n\n- **Portability**: Manages endianness to ensure compatibility across different systems.\n\n**Getting Started**:\n1. Clone the repository using Git.\n2. Include the main header in your project.\n3. Use the provided examples to pack and unpack data.\n\n**Custom Types Example**:\nTo serialize your custom structures, define pack and unpack functions within the structure.\n\n**Why Choose msgpack23?**:\n- **Simplicity**: Easy to understand and use with a single header.\n- **Performance**: Efficient memory operations and compile-time type handling.\n- **Flexibility**: Can handle a wide range of data types with little extra code.\n\n**Contribution**: Contributions are encouraged! You can report bugs or submit new features through GitHub.\n\n**License**: The library is licensed under the MIT License. \n\nOverall, msgpack23 offers a simple and efficient way to work with MessagePack serialization in C++.",
      "ko": "msgpack23ëŠ” C++ ë°ì´í„°ë¥¼ MessagePack í˜•ì‹ìœ¼ë¡œ ì‰½ê²Œ ì§ë ¬í™”í•˜ê³  ì—­ì§ë ¬í™”í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„ëœ í˜„ëŒ€ì ì¸ í—¤ë” ì „ìš© C++ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤. ì´ ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” ê°€ë³ê³  ì‚¬ìš©í•˜ê¸° ì‰¬ìš°ë©°, ì¶”ê°€ì ì¸ ì˜ì¡´ì„± ì—†ì´ ë‹¨ì¼ í—¤ë” íŒŒì¼ë§Œ í¬í•¨í•˜ë©´ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nmsgpack23ëŠ” C++20 ê¸°ëŠ¥ì„ ì§€ì›í•˜ì—¬ ë‹¤ì–‘í•œ ë°ì´í„° ìœ í˜•, ì¦‰ ì»¨í…Œì´ë„ˆ, ë§µ, ì—´ê±°í˜•, ì‚¬ìš©ì ì •ì˜ ìœ í˜• ë“±ì„ ìœ ì—°í•˜ê²Œ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‚¬ìš©ìëŠ” íŒ¨í‚¹ê³¼ ì–¸íŒ¨í‚¹ í•¨ìˆ˜ë¥¼ êµ¬í˜„í•˜ì—¬ ìì‹ ë§Œì˜ ìœ í˜•ì„ ë§Œë“¤ ìˆ˜ ìˆìœ¼ë©°, ì´ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ì— ì›í™œí•˜ê²Œ í†µí•©ë©ë‹ˆë‹¤. ë˜í•œ, í‘œì¤€ ì»¨í…Œì´ë„ˆì¸ `std::vector`ì™€ `std::map`ì„ ìë™ìœ¼ë¡œ ì§ë ¬í™”í•˜ëŠ” ê¸°ëŠ¥ë„ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. \n\nì‹œê°„ ê´€ë ¨ ê°ì²´ì¸ `std::chrono::time_point`ë„ ê¸°ë³¸ì ìœ¼ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆìœ¼ë©°, ì •ìˆ˜, ë¶ˆë¦¬ì–¸, ë¶€ë™ ì†Œìˆ˜ì  ìˆ«ì, ë¬¸ìì—´, ë°”ì´íŠ¸ ë°°ì—´ ë“± ë‹¤ì–‘í•œ ì›ì‹œ ë°ì´í„° ìœ í˜•ì„ ì§€ì›í•©ë‹ˆë‹¤. ì´ ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” ì—”ë””ì•ˆ ë¬¸ì œë¥¼ ê´€ë¦¬í•˜ì—¬ ì„œë¡œ ë‹¤ë¥¸ ì‹œìŠ¤í…œ ê°„ì˜ í˜¸í™˜ì„±ì„ ë³´ì¥í•©ë‹ˆë‹¤.\n\nì‹œì‘í•˜ë ¤ë©´ Gitì„ ì‚¬ìš©í•´ ì €ì¥ì†Œë¥¼ ë³µì œí•˜ê³ , í”„ë¡œì íŠ¸ì— ì£¼ìš” í—¤ë”ë¥¼ í¬í•¨í•œ í›„ ì œê³µëœ ì˜ˆì œë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë¥¼ íŒ¨í‚¹í•˜ê³  ì–¸íŒ¨í‚¹í•˜ë©´ ë©ë‹ˆë‹¤. ì‚¬ìš©ì ì •ì˜ êµ¬ì¡°ì²´ë¥¼ ì§ë ¬í™”í•˜ë ¤ë©´ êµ¬ì¡°ì²´ ë‚´ì— íŒ¨í‚¹ ë° ì–¸íŒ¨í‚¹ í•¨ìˆ˜ë¥¼ ì •ì˜í•˜ë©´ ë©ë‹ˆë‹¤.\n\nmsgpack23ë¥¼ ì„ íƒí•´ì•¼ í•˜ëŠ” ì´ìœ ëŠ” ê°„ë‹¨í•¨, ì„±ëŠ¥, ìœ ì—°ì„±ì…ë‹ˆë‹¤. ë‹¨ì¼ í—¤ë”ë¡œ ì‰½ê²Œ ì´í•´í•˜ê³  ì‚¬ìš©í•  ìˆ˜ ìˆìœ¼ë©°, ë©”ëª¨ë¦¬ ì‘ì—…ì´ íš¨ìœ¨ì ì´ê³  ì»´íŒŒì¼ ì‹œê°„ì— ìœ í˜•ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, ë‹¤ì–‘í•œ ë°ì´í„° ìœ í˜•ì„ ì ì€ ì½”ë“œë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ìœ ì—°ì„±ì„ ì œê³µí•©ë‹ˆë‹¤.\n\nê¸°ì—¬ë„ í™˜ì˜í•©ë‹ˆë‹¤! ë²„ê·¸ë¥¼ ë³´ê³ í•˜ê±°ë‚˜ ìƒˆë¡œìš´ ê¸°ëŠ¥ì„ GitHubë¥¼ í†µí•´ ì œì¶œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” MIT ë¼ì´ì„ ìŠ¤ í•˜ì— ë°°í¬ë©ë‹ˆë‹¤. ì „ë°˜ì ìœ¼ë¡œ msgpack23ì€ C++ì—ì„œ MessagePack ì§ë ¬í™”ë¥¼ ê°„ë‹¨í•˜ê³  íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ë°©ë²•ì„ ì œê³µí•©ë‹ˆë‹¤.",
      "ja": "msgpack23ã¯ã€C++ãƒ‡ãƒ¼ã‚¿ã‚’MessagePackå½¢å¼ã«ç°¡å˜ã«ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºãŠã‚ˆã³ãƒ‡ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºã™ã‚‹ãŸã‚ã«è¨­è¨ˆã•ã‚ŒãŸã€ãƒ¢ãƒ€ãƒ³ãªãƒ˜ãƒƒãƒ€ãƒ¼ã‚ªãƒ³ãƒªãƒ¼ã®C++ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã™ã€‚ã“ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ä¸»ãªç‰¹å¾´ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ã€‚\n\nè»½é‡ã§ä½¿ã„ã‚„ã™ãã€å˜ä¸€ã®ãƒ˜ãƒƒãƒ€ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¤ãƒ³ã‚¯ãƒ«ãƒ¼ãƒ‰ã™ã‚‹ã ã‘ã§ã€è¿½åŠ ã®ä¾å­˜é–¢ä¿‚ãªã—ã«ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’åˆ©ç”¨ã§ãã¾ã™ã€‚ã¾ãŸã€C++20ã®æ©Ÿèƒ½ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ãŠã‚Šã€ã‚³ãƒ³ãƒ†ãƒŠã€ãƒãƒƒãƒ—ã€åˆ—æŒ™å‹ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼å®šç¾©å‹ãªã©ã€ã•ã¾ã–ã¾ãªãƒ‡ãƒ¼ã‚¿å‹ã«æŸ”è»Ÿã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚ç‹¬è‡ªã®å‹ã‚’ä½œæˆã™ã‚‹ã“ã¨ã‚‚å¯èƒ½ã§ã€ãƒ‘ãƒƒã‚­ãƒ³ã‚°ã¨ã‚¢ãƒ³ãƒ‘ãƒƒã‚­ãƒ³ã‚°ã®é–¢æ•°ã‚’å®Ÿè£…ã™ã‚‹ã“ã¨ã§ã€ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã«ã‚·ãƒ¼ãƒ ãƒ¬ã‚¹ã«çµ±åˆã§ãã¾ã™ã€‚\n\næ¨™æº–ã‚³ãƒ³ãƒ†ãƒŠã§ã‚ã‚‹`std::vector`ã‚„`std::map`ã®è‡ªå‹•ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ãŠã‚Šã€`std::chrono::time_point`ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚‚ãƒã‚¤ãƒ†ã‚£ãƒ–ã«æ‰±ãˆã¾ã™ã€‚æ•´æ•°ã€ãƒ–ãƒ¼ãƒ«å€¤ã€æµ®å‹•å°æ•°ç‚¹æ•°ã€æ–‡å­—åˆ—ã€ãƒã‚¤ãƒˆé…åˆ—ãªã©ã€ã•ã¾ã–ã¾ãªåŸºæœ¬ãƒ‡ãƒ¼ã‚¿å‹ã«ã‚‚å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚ã‚¨ãƒ³ãƒ‡ã‚£ã‚¢ãƒ³ãƒã‚¹ã‚’ç®¡ç†ã™ã‚‹ã“ã¨ã§ã€ç•°ãªã‚‹ã‚·ã‚¹ãƒ†ãƒ é–“ã§ã®äº’æ›æ€§ã‚‚ç¢ºä¿ã•ã‚Œã¦ã„ã¾ã™ã€‚\n\nä½¿ã„å§‹ã‚ã‚‹ã«ã¯ã€ã¾ãšGitã‚’ä½¿ã£ã¦ãƒªãƒã‚¸ãƒˆãƒªã‚’ã‚¯ãƒ­ãƒ¼ãƒ³ã—ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«ãƒ¡ã‚¤ãƒ³ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’å«ã‚ã¾ã™ã€‚æä¾›ã•ã‚Œã¦ã„ã‚‹ä¾‹ã‚’å‚è€ƒã«ã—ã¦ã€ãƒ‡ãƒ¼ã‚¿ã®ãƒ‘ãƒƒã‚¯ã¨ã‚¢ãƒ³ãƒ‘ãƒƒã‚¯ã‚’è¡Œã†ã“ã¨ãŒã§ãã¾ã™ã€‚ã‚«ã‚¹ã‚¿ãƒ æ§‹é€ ä½“ã‚’ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºã™ã‚‹å ´åˆã¯ã€æ§‹é€ ä½“å†…ã«ãƒ‘ãƒƒã‚¯ã¨ã‚¢ãƒ³ãƒ‘ãƒƒã‚¯ã®é–¢æ•°ã‚’å®šç¾©ã—ã¾ã™ã€‚\n\nmsgpack23ã‚’é¸ã¶ç†ç”±ã¯ã€ã‚·ãƒ³ãƒ—ãƒ«ã•ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã€æŸ”è»Ÿæ€§ã§ã™ã€‚å˜ä¸€ã®ãƒ˜ãƒƒãƒ€ãƒ¼ã§ç†è§£ã—ã‚„ã™ãã€åŠ¹ç‡çš„ãªãƒ¡ãƒ¢ãƒªæ“ä½œã¨ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ™‚ã®å‹å‡¦ç†ã‚’æä¾›ã—ã¾ã™ã€‚ã¾ãŸã€å°‘ãªã„è¿½åŠ ã‚³ãƒ¼ãƒ‰ã§å¹…åºƒã„ãƒ‡ãƒ¼ã‚¿å‹ã‚’æ‰±ã†ã“ã¨ãŒã§ãã¾ã™ã€‚\n\nè²¢çŒ®ã‚‚æ­“è¿ã•ã‚Œã¦ãŠã‚Šã€ãƒã‚°ã®å ±å‘Šã‚„æ–°æ©Ÿèƒ½ã®ææ¡ˆã¯GitHubã‚’é€šã˜ã¦è¡Œãˆã¾ã™ã€‚ã“ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¯MITãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã®ä¸‹ã§æä¾›ã•ã‚Œã¦ã„ã¾ã™ã€‚å…¨ä½“ã¨ã—ã¦ã€msgpack23ã¯C++ã§MessagePackã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºã‚’æ‰±ã†ãŸã‚ã®ã‚·ãƒ³ãƒ—ãƒ«ã§åŠ¹ç‡çš„ãªæ–¹æ³•ã‚’æä¾›ã—ã¾ã™ã€‚"
    }
  },
  {
    "id": "60401c8ca984b57b",
    "title": {
      "en": "A timeline of IBM keyboard history",
      "ko": "IBM í‚¤ë³´ë“œ ì—°ëŒ€ê¸°",
      "ja": "IBMã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ã®æ­´å²"
    },
    "type": "story",
    "url": "https://sharktastica.co.uk/wip/timeline",
    "score": 4,
    "by": "tart-lemonade",
    "time": 1743297324,
    "content": "â–²A timeline of IBM keyboard history<div class=\"notice block\" id=\"noscript\"><span data-nosnippet=\"true\"><p><strong>JavaScript disabled or not supported</strong></p><p>It appears you have prevented JavaScript from running in your web browser or are using a web browser that does not support JavaScript. Admiral Shark's Keyboards presently requires JavaScript for quality-of-life features like switching between light/dark mode, navigating via title or image and copying search query links, and is necessary for the keyboard matrix simulators, keyboard property modals, interactable slideshows and image size optimisation. Please consider enabling JavaScript or using a web browser that supports it for a fully-featured and correctly working experience. If you have suggestions for reducing JavaScript dependency, feel free to let me know.</p></span></div>This is a preview of upcoming Admiral Shark's Keyboards content. This page is considered work-in-progress and should be treated as such.The IBM and family keyboard timeline is an illustrated overview of some of the most important events affecting IBM, Lexmark, Unicomp, Lenovo and Toshiba Global Commerce Solutions keyboards. This includes notable keyboard releases and withdrawals, corporate history like company founding, divestures and change in OEMs, and patents. Due to their relationship and impact on the keyboards around them, host devices such as personal computers, terminals, consoles and typewriters also appear throughout the timeline. 111 events have been recorded for the \"show all\" versions of the timeline.Show all (default)Show all (quick read)Show all (tabular)Show keyboards & hosts onlyShow companies & factories onlyShow patents only1890s1900s1910s1920s1930s1940s1950s1960s1970s1980s1990s2000s2010s2020sSources1896Herman Hollerith, a pioneer of punched card technology, founds the Tabulating Machine Company to market his inventions. Their equipment quickly gained ground in being uses for censuses of many companies, including the 1900 U.S. census.17thMay1901[ASK]Herman Hollerith patents the first keypunch (apparatus for perforating record-cards). This patent was implemented as the Hollerith 001 Mechanical Card Punch, which upon IBM's founding, became the IBM 001 Mechanical Card Punch and their first product.16thJune1911Computing-Tabulating-Recording Company (CTR) is founded by Charles R. Flint upon consolidating Herman Hollerith's The Tabulating Machine Company with Bundy Manufacturing Company, International Time Recording Company and the Computing Scale Company of America. CTR specialises in recording-keeping and measuring systems.14thFebruary1924The Computing-Tabulating-Recording Company is renamed the International Business Machines (IBM) Corporation under the presidency of Thomas J. Watson Sr.1933IBM acquires Electromatic Typewriters, Inc. to gain a head start with their typewriter ambitions, gaining Electromatic's patents, production facilities and tooling. IBM will invest $1 million in redesigning their product and improve support infrastructure for them.1935[1]IBM introduces its first family of electric typewriters. IBM invested heavily in the technology acquired from Electromatic, introducing the IBM Model 01 Electric Typewriter (pictured) from it. 01 would be joined by 02 through 10 within a decade's time.1948[2]The IBM Model A electric typewriter family is introduced.July1949[3]IBM introduces the 024 Card Punch and 026 Printing Card Punch, both BCDIC electric keypunches with a choice of a 21-key numeric keyboard or a 45-key combination keyboard (pictured). These keyboards are technically discrete and electrically separable, so they are also considered to be IBM's first generation of keyboards under the modern sense of what a keyboard is. They use a contact-bail system for keystroke sensing called a Keyboard Permutation Unit.1953IBM Canada opens the 844 Don Mills Road, Toronto, Ontario plant (plant 91). This plant would go on to play a minor role in Model M production and assembly, as IBM 4680 POS Alphanumeric Keyboards have been observed with its plant code in their serial/ID numbers, implying a \"location of control\" or \"location of manufacture\" relationship. As such keyboards' complete sub-assemblies were made by IBM Netherlands' Amsterdam plant (plant 58), it's likely the Don Mills plant only produced their cover sets and electronics and completed their final assembly.1954[4]The IBM Model B electric typewriter family is introduced.1954IBM United Kingdom opens the Greenock, Scotland plant (plant 55). Greenock became a major hub for manufacturing keyboards, personal computers, printers, terminals and typewriters destined to be sold in Europe, Middle East, and Africa (EMEA). It would go on to produce Model B, Model F and Model M keyboards and IBM ThinkPad notebook computers.1956IBM United States opens the Lexington, Kentucky plant (plant 11). This plant became associated with the IBM Information Products Division and was a known major producer of IBM typewriters and keyboards for the North American market.2ndSeptember1958The IBM 7150 Console Typewriter & Operating Keyboard (pictured) and 7900 Inquiry Station Typewriter Keyboard are introduced. They are the earliest known forms of IBM printer-keyboards, which are considered to be IBM's second generation of keyboards.1959[5]The IBM Model C electric typewriter family is introduced.1960IBM Netherlands opens its second Amsterdam, North Holland, the Netherlands plant (plant 58). This plant served a major manufacturer of IBM Office Products Division products such as electric typewriters, producing two million of such by 1980. In the '80s, the plant diversified to produce electronic typewriters and keyboards including in the Model F and Model M families.1967[6]The IBM Model D electric typewriter family is introduced. This is IBM's last non-Selectric typewriter.30thJuly1969IBM introduces its first named keyswitch design - the IBM elastic diaphragm - with the IBM 5475 Data Entry Keyboard. Elastic diaphragm encoded keyboards become IBM's third generation of keyboards.6thMay1971[7]The IBM 3270 Information Display System debuts as a family of coaxial cabled terminals originally intended for IBM System/360 or System/370 mainframe computers. At launch, the 3270 series included the IBM 3275 and 3277 Display Stations. The first keyboards of the 3270 family were the Micro Switch SW-based 66-key (pictured) and 78-key IBM 3275 and 3277 Display Station Type A Keyboards. These \"Type A\" keyboards would be replaced with Model B-based \"Type B\" keyboards within 2 years of launch.21stMay1971Richard Hunter Harris invents and patents the buckling spring (catastrophically buckling compression column switch and actuator). This keyswitch actuator is comprised of a metal coil spring that characteristically buckles into a kink instead of compressing in a straight column, which pivots something that can be registered by some sort of sensor. The exact design is not solidified yet, and IBM would later patent two marketable derivatives in 1977 and 1983.24thSeptember1971[ASK]Richard Hunter Harris and Robert John Wolfram invent and patent the beam spring (switch button with snap mechanism) keyswitch. The design has a leaf spring that rests at a downwards bent position, which when force is applied, snaps to an inverted position. The movement lifts a capacitive fly plate away from a pad card sensor, which is interpreted as a key press.2ndAugust1972[8]The IBM Model B (beam spring) keyboard family is introduced with the IBM 3158 66-key Display Console Keyboard as IBM's fourth generation of keyboards.April1977[9]The IBM 5250 Information Display System debuts alongside the IBM System/34 midrange computer they were supposed to operate with as a family of twinaxial cabled terminals. At launch, the 5250 series included the IBM 5251 Display Station and 5252 Dual Display Station. The first keyboards of the 5250 family were the Model B-based 66-key and 83-key (pictured) IBM 5251 and 5252 Display Station Keyboards. The 83-key physical layout would later serve as the basis for the IBM System/23 Datamaster and Personal Computer Keyboards.May1977[10]The IBM Base Keyboard debuted in the form of the Model B-based 75-key and 87-key (pictured) IBM 3276 and 3278 Display Station Keyboards. The Base Keyboard was considered by IBM to be the direct predecessor to the Converged Keyboard design. The Base layout became somewhat of a standard for IBM, though perhaps competed with the IBM 5251/5252 layouts.August1977[ASK]Richard Hunter Harris patents the capacitive implementation of buckling springs.1978IBM begins developing the IBM System/23 Datamaster, and with it, the first Model F-based keyboard assembly.1978IBM United States opens the Charlotte, North Carolina plant and laboratory (plant 41). This plant became associated with the IBM Information Products Division and was known to manufacturer printers. From 1993, it likely had a peripheral involvement with the Model M keyboard family as many Model M-based IBM POS keyboards such as RPOS and MPOS will have Charlotte's plant code in their serial/ID numbers, implying at least a \"location of control\" relationship.17thJune1980[11]IBM announces the Displaywriter System, a modular diskette-based word processing system. At its core is the 6580 Displaywriter Display Station with its Displaywriter Display Station Keyboard Module (630X type Model B). The keyboard design is recycled from the IBM 5253/5254 Display Station, inheriting its internal speaker and likewise is available in either a 92 or 96 character variant.August1980After concluding the IBM System/23 Datamaster's development, IBM begins work on the IBM Personal Computer. This includes its keyboard, which was derived from the then-still-unreleased Model F-based IBM System/23 Datamaster Keyboard Assembly.July1981The IBM Model F (capacitive buckling spring) keyboard family is introduced with the IBM 5322 System/23 Datamaster's Keyboard Assembly as IBM's fifth generation of keyboards.12thAugust1981IBM launched the original Personal Computer, along with it, the IBM Personal Computer Keyboard. Also known as the \"Model F/XT\", the IBM PC Keyboard is the most common Model F keyboard variant.October1982[12]IBM launched the IBM 4700 Finance Communication System and notably its 4704 Display Station, debuting with a 50-key (472X-100 type Model F) keyboard at launch. This was followed by the 62-key (472X-200) (pictured) and 77-key (472X-300) keyboards in December 1982, and the 107-key (470X-400) keyboard in December 1983. In particular, the 62-key keyboard is notable as an early example of the now-popular 60% keyboard and Tsangan bottom row.8thMarch1983[13]IBM introduces the 3290 Information Panel, a 3270-family plasma screen terminal. The IBM Converged Keyboard debuts in the form of its \"unsaver\" Model F-based typewriter keyboard. They began to unify what were various fractured terminal keyboard lineages into a common platform, bringing their layouts a major step closer to modern ones.3rdOctober1983[ASK]Edwin T. Coleman, III patents the membrane implementation of buckling springs.18thOctober1983[14]IBM introduces the 4980 Display Station, a terminal for IBM Series/1 minicomputers with similar functionality to the earlier 4978. Its Model F-based 127-key keyboard was the first \"battleship\"-style IBM Converged Keyboard to become available.Q11984[15]The IBM 3270 Personal Computer becomes available. The 3270 PC is essentially an IBM Personal Computer XT with additional hardware and software to emulate an IBM 3270 terminal. The Model F-based IBM 3270 Personal Computer Converged Keyboard was IBM's first 122-key Converged Keyboard design and IBM's earliest host-connected keyboard.March1984[16]IBM introduces the PCjr, a small, low-cost PC designed for \"home and educational environments and for personal productivity applications.\" Its keyboard, the PCjr Cordless Keyboard, has 62 \"chiclet\" style keys, rubber-dome keyswitches and infrared connectivity. The PCjr would turn out to not be very successful, and its original keyboard design considered to be one of IBM's worst.14thAugust1984[ASK]IBM launched the Personal Computer AT (PC/AT), along with it, the IBM Personal Computer AT Keyboard. Also known as the \"Model F/AT\", this would be the last entirely new Model F keyboard design.September1984IBM introduces the revised PCjr Cordless Keyboard to address major complaints regarding the original \"chiclet\" style design. It still has 62 keys and infrared connectivity, but it now has more traditional style keys and nomenclature is printed on the keys instead of an overlay surrounding them.16thOctober1984[ASK]IBM announces the Wheelwriter 3, Wheelwriter 5 (pictured, keyboard of), and Quietwriter 7 electronic typewriters under the moniker IBM Selectric System/2000. Via their keyboard assembly designs, the IBM Model M (then-only membrane buckling spring) keyboard family debuts as IBM's sixth generation of keyboards.21stMay1985[17]IBM announces the PC/AT-based 7531 and 7532 Industrial Computers. The IBM Enhanced Keyboard via the IBM 7531/7532 Industrial Computer Keyboard makes its first official appearance. The Enhanced Keyboard introduces the full-size/100% form-factor and the basis of the ANSI and ISO physical layouts that remain the standard today.18thJune1985[18]IBM announces the 3161 and 3163 ASCII Display Stations, serial-based terminals in the IBM 3101 lineage that were capable of emulating various third-party terminals. They sported the first terminal-specific IBM Enhanced Keyboards, which typically have an extra key over ANSI and ISO PC-style Enhanced Keyboards, and ASCII-style ones like 316X's often uniquely have line drawing symbols on their numeric keypads.September1985[ASK]The first 122-key Model M Converged Keyboard (also known as the IBM Model 1A) becomes available as an option for the IBM 3205 Color Display Console. This continues the Converged Keyboard line from the Model F era, eventually bringing the form-factor to many existing and new IBM Display Stations, consoles, and even host-connected PCs. Five unique types will be introduced by the 2000s.Q41985[19]IBM introduces the 6770 Wheelwriter System and 6780 Quietwriter System electronic typewriters, both available in a Function Pack 20 (System/20) and Function Pack 40 (System/40) version. Both used a unique Movable Keyboard, a Model M-based keyboard with an AT-style physical layout, a removable 80-character LCD and sits in an adjustable cradle.1986[20]IBM Mexico opens the Guadalajara, Jalisco plant (plant 78 or \"IEP\"). This plant was specifically made for producing personal computers and related peripherals for the Latin American market. IBM Personal System/2 Enhanced Keyboards were produced there between 1987 and 1995, with such keyboards affectionately known as a \"Modelo M\", referencing their Spanish-language rear labels.8thJanuary1986[21]IBM announces the 4680 Store System, its first POS solution based around PC-based terminals. At launch, it included the 4683 POS Terminal, IBM 5170 Model 839 or 5170 Model 899 Personal Computer AT/Store Controller, and the 4680 50-Key Modifiable Keyboard (pictured). The keyboard is made by SMK and uses SMK discrete rubber dome keyswitches.October1986The IBM Space Saving Keyboard (SSK) debuted in the form of the IBM 3162 ASCII Display Station Short Keyboard. No modern photos of it are available but it has been described to be like SSKs that came later.16thDecember1986[22]IBM announces the Model M-based 4680 POS Alphanumeric Keyboard for the IBM 4683 and later 4684 POS Terminals. Its complete sub-assembly is based on the IBM 6770/6780's, but with a new cover set, POS-specific features and RS-485 electronics. It also has a more traditional AT-style layout, though with some added relegendable keys. It is the only buckling-spring IBM POS keyboard known.17thFebruary1987[23]The IBM Model 1B keyboard makes its original debute as an option for the IBM 3192 Display Station models C and D. Model 1Bs take on the same physical layout and form-factor as the 104-key Model F Converged Keyboards but they are not based on existing IBM keyboard technology, instead using Micro Switch ST series rubber dome keyswitches. It's believed the \"Quiet Touch Keyboard\" term originated as a name for 1Bs.April1987[ASK]IBM introduces the Personal Computer/2 (PS/2) series of PCs. With them, the IBM PS/2 Enhanced Keyboard that would become the most common buckling-spring Model M variant and possibly one of the most famous keyboards of all time.June1987[ASK]IBM introduces the 3151 ASCII Display Station, a cheaper follow-up to the IBM 316X series and likewise an IBM 3101 lineage terminal capable of emulating various third-party terminals. 3151 received an Enhanced Keyboard variant similar to the 316X keyboard but with updated branding and cable.August1987[ASK]IBM brought its Model M Space Saving Keyboard design to the IBM Personal System/2 family, starting with the IBM PS/2 Model 25 models 001 and 004. The PS/2 SSK is the first modern PC tenkeyless keyboard and used a layout based on the Enhanced layout but with a numeric keypad overlaid across various alphanumeric keys.31stDecember1987[ASK]IBM introduces the 4680 POS Matrix Keyboard for 4683 and 4684 POS Terminals. It is one of IBM's most functional keyboards, purposely designed for \"applications requiring a large number of pre-defined keys.\" It has a manger's keylock and 139 keys, of which 126 comprise its main relegendable area. It is made by Key Tronic and uses Key Tronic capacitive foam and foil (tactile variant) keyswitches.18thMarch1988[ASK]IBM introduces the Personal System/2 Screen Reader as the inaugural product of the IBM Independence Series range, and was a pioneering screen reader system designed to help people with hard or lack of sight access a PC. The IBM Screen Reader Keypad (SRK) is also introduced as the peripheral component for this system.20thJune1989[24]IBM introduces the first InfoWindow Display Station types, 3471 and 3476. The IBM InfoWindow Display Station family further converges the 3270 and 5250 terminal families under more unified branding and outwardly design language despite their inherit cabling, protocol and layout nomenclature differences.29thDecember1989[25]IBM introduces the 4680 50-Key Modifiable Keyboard/Operator Display for 4683 and 4684 POS Terminals. It is based on the existing IBM 4680 50-Key Modifiable Keyboard, likewise made by SMK and using SMK discrete rubber dome keyswitches but now sporting a tilting LCD.28thAugust1990[26]IBM announces the Personal System/1 (PS/1) series of PCs, intended as more affordable and easier to use alternatives to IBM PS/2s. With them, the first IBM Selectric Touch Keyboards (Model M2) become available. M2 is a lower-cost, lower-profile and lightweight alternative to the IBM Enhanced Keyboard.28thSeptember1990[27]IBM introduces the 4680 ANPOS Keyboard for 4683 and 4684 POS Terminals. It has 115 keys and an integrated manager's keylock. Like previous 4680 keyboards, it is made by SMK and uses SMK discrete rubber dome keyswitches.9thOctober1990[28]Joseph E. Jasinski, Charles H. Lingle, Richard F. Pollitt and David W. Shuman patents a combined, reversible ball mouse and trackball device ultimately used for the IBM Personal System/2 L40 SX notebook computer. This device was marketed the original IBM TrackPoint.29thNovember1990[ASK]Edwin J. Selker and Joseph D. Rutledge patent the concept of a pointing stick, which would eventually be implemented on IBM products as the TrackPoint II, III and IV pointing sticks and become a hallmark feature of ThinkPad laptops.26thMarch1991[29]The IBM Model M keyboard family is expanded to include IBM buckling sleeve based keyboards upon the introduction of the IBM Personal System/2 Model L40 SX notebook computer and its Model M3 keyboard assembly and optional numeric keypad. Also available for L40 SX as an option was the original IBM TrackPoint design (combined mouse and trackball).27thMarch1991IBM Information Products Corporation is divested to form Lexmark International. Lexmark inherited IBM United States' keyboard, printer and typewriter manufacturing operations and facilities in Boulder, Colorado and Lexington, Kentucky (plant 11).11thJune1991IBM announces the Select-a-Keyboard scheme as a way of allowing IBM PC customers to change the bundled keyboard at the time of purchase for no additional charge. The options available under this scheme were mostly from the Model M family.Q41991[ASK]The IBM Space Saver Keyboard (Model M4) enters production around this time. It is essentially just an IBM Personal System/2 L40 SX Keyboard Assembly (M3) placed in its own cover set with a PS/2 controller card. It is notable for being the first desktop keyboard with IBM buckling sleeves.February1992[ASK]The Lexmark Classic Touch Keyboard with 16mm Trackball (Model M5-1) and Classic Touch Keyboard with 25mm Trackball (Model M5-2, pictured) begin appearing in magazines. Model M5s are variants of the Lexmark Classic Touch Keyboard and IBM Enhanced Keyboard with an integrated trackball assembly and at least four mouse buttons (a pair of standard click buttons and a pair of stepped-click buttons). M5-1 has a 16mm trackball positioned above the keyboard's arrow keys, but M5-2 has a 25mm trackball above the LED lock-light overlay. IBM-branded versions will appear later.25thFebruary1992[30]IBM introduces the Personal System/2 CL57 SX notebook computer, IBM's first laptop to have a colour display. It also introduces the buckling-sleeve Model M6 keyboard (the original Type 1 variant), an evolution of the earlier IBM PS/2 L40 SX's M3 with an updated actuation method and easier keycap removal.March1992[ASK]Lexmark introduces the AR10 series of notebook computers for ODM purposes and eventually for their own Lexbook brand. They all sport the Lexmark Notebook Keyboard with 16mm Trackball, a Type 2 buckling-sleeve Model M6 keyboard with an integrated trackball in the bottom-right and two mouse buttons inserted in between Ctrl and Alt. Type 2 M6s are notable for introducing a 7-row physical layout to the Model M family, which would soon be refined and popularised by the then-upcoming ThinkPads as the classic ThinkPad layout.16thOctober1992[ASK]IBM introduces the ThinkPad 700 series notebook computers, typically considered to be the first 'true' ThinkPad (a black, bento-box styled laptop with a red pointing stick). In particular, the 700 series introduces the Type 3 variant of the buckling-sleeve Model M6 keyboard and the TrackPoint II pointing stick.1stJune1993[31]IBM announces the 4693 and 4694 POS Terminals. To go with them, IBM also introduces the Retail POS (RPOS) series of buckling-sleeve Model Ms (M7, M7-1, M8, M9 and M11). RPOS keyboards are derived from a common platform and usually made by a single OEM at a given time, which contrasts the IBM 4680 era's fractured keyboard ecosystem made by IBM itself, SMK or Key Tronic.30thJune1993[32]IBM introduces the Personal System/2 E (PS/2 E), the first Energy Star-compliant PC. To go with it, the pearl-white IBM Quiet Touch Keyboard with TrackPoint II (Model M4-1, also known as IBM Space Saver Keyboard with TrackPoint II) is also introduced. M4-1 is an extension of M4, but with an integrated TrackPoint II pointing stick, and was in fact the first non-laptop IBM keyboard with such a device. A raven black version called the IBM ThinkPad Space Saver Keyboard with TrackPoint II would later be introduced.Q31993[33]The IBM Easy OPTIONS 101-Key Extended Keyboard (Model M1, KB570) begins appearing in marketing. M1 is a variant of the M2 Selectric Touch Keyboard with an AT-style DIN plug that was sold as a standalone product rather than being bundled with a system.15thJuly1993[30]IBM introduces the ThinkPad 500 series monochrome subnotebooks. 500 in turn introduces the Type 4 variant of the buckling-sleeve Model M6-1 keyboard, which compared to all most other M6/M6-1 types had a much compressed layout, smaller key unit sizes, and (on average) lower-gauge sleeves to suit the 500-series' very small size.8thSeptember1993[34]IBM introduces the IBM ThinkPad 750 series notebook computers. 750 series in turn introduces the Type 5 variant of the buckling-sleeve Model M6-1 keyboard, a revision of the Type 3 design that most notably sports an outer frame and hinges to allow them to mount to the host laptop to act as its inner cover and lifts to provide access to major system components.November1993[ASK]The Lexmark Classic Touch Keyboard with Integrated Pointing Stick, the first of the Model M13s, begins appearing in Lexmark's marketing in magazines. M13s are variants of the Lexmark Classic Touch Keyboard and IBM Enhanced Keyboard with an integrated pointing stick and two mouse buttons. Lexmark self-branded M13s use an FSR-based pointing stick, whereas IBM's usually use TrackPoint II.28thFebruary1994[26]IBM announces the OPTIONS by IBM brand to offer \"hundreds of peripheral add-ons, add-ins and system enhancements for both IBM and non-IBM industry standard systems, to satisfy a wide variety of personal computing needs.\" Upon launch, the brand included a version of the Model M PS/2 Enhanced Keyboard and Model M13 TrackPoint II Keyboard.May1994[ASK]The Winbook XP series of notebooks begins appearing in marketing. They sported Lexmark-produced keyboards, which happen to be the earliest known examples of the Type 6 buckling-sleeve Model M6-1 variant. Type 6s are similar to Type 4 in that they are more compacted than the other types, but Type 6 retains standard sleeve gauges and key unit sizes and makes less layout compromises.3rdOctober1994Robert C. Barrett, Robert S. Olyha, Jr. and Joseph D. Rutledge patents a formula for a negative inertia transfer function that can be used to help pointing sticks to counteract the feeling of sluggishness (i.e., having inertia). It was implemented in TrackPoint III's and TrackPoint IV's firmware, making them more performant with modern, high-resolution displays compared to TrackPoint II. For ThinkPads, it first appeared on the IBM ThinkPad 755CD.15thNovember1994[35]IBM introduces the Adjustable Keyboard and optional numeric keypad attachment (Model M15) under the OPTIONS by IBM brand. It is unique for being an IBM keyboard that is a split ergonomic design with extensive form customisability thanks to its elaborate feet. Lexmark also introduced a self-branded version called the Select-Ease Keyboard at some point. M15 was also the last numbered Model M variant to be introduced.30thNovember1994[ASK]IBM introduces the TrackPoint II Keyboard (Black) (Model M13) under the OPTIONS by IBM brand. Whilst it is only a visual (raven black) variant of the existing IBM-branded M13, it will still become one of IBM's most iconic specific Model M variants.6thMarch1995[36]IBM introduces the ThinkPad 701C and 701Cs notebook computers, IBM's novel solution to reducing a laptop's overall footprint in an era of typical only small displays available. Its integrated IBM TrackWrite Keyboard (also known as the \"butterfly keyboard\") is able to slide so it can compact itself when the laptop is closed and expand when it is opened. The keyboard overall resembles a Model M6 or M6-1, but it is produced by Key Tronic using their own flavour of buckling-sleeve keyswitches. The 701C series went on to win many design awards.4thDecember1995Lexmark announces it will be ending its keyboard manufacturing business by April 1996 to focus on printers. IBM agreed to purchase from Lexmark $6.5 million worth of \"certain keyboard assets, tooling, equipment, manufacturing information and licenses.\" Maxi Switch bought from Lexmark some manufacturing rights for IBM keyboards, patents (including one related to buckling springs), and assets for Lexmark Select-Ease Keyboards (Model M15) and rubber dome keyboards.Q11996[ASK]Apple introduces the Newton OS 2.0 for its Newton MessagePad series personal digital assistants that promises better handwriting recognition and supports an external keyboard. The Apple Newton MessagePad Keyboard (model X0044) is launched to coincide with this, but it is especially interesting since it is derived from the IBM ThinkPad 500's Type 4 Model M6-1 buckling-sleeve keyboard assembly and is presently the only known Apple-branded Model M.April1996Lexmark exits the keyboard business. This resulted in the late Neil Muyskens (a former IBM and Lexmark engineer) founding Unicomp as Lexmark's keyboard business successor, continuing to produce various Model M variants in Kentucky, USA to this day, originally at 510 Henry Clay Blvd, Lexington, Kentucky 40505.5thNovember1999[31]IBM introduces the 4820 SurePoint Solution Flat Panel Display, an attachment originally for IBM 4694 POS Terminals. The display in turn could support a 32-key keypad attachment that was originally called the IBM SurePoint 4820 Monitor Keypad and MSR Extension. This keypad is considered to be the beginning of the Pre-Modular POS (PMPOS) series of buckling-sleeve Model Ms. 4 types of 4820-style keypads would eventually be introduced.2000IBM relinquishes its in-house keyboard production capability after IBM United Kingdom's Greenock, Scotland plant (plant 55) stops producing Model M keyboards.November2000[ASK]Unicomp introduces the EnduraPro, a modification of the IBM Japanese Keyboard/TrackPoint II (model 5576-C01) that supports the ANSI layout and the ISO layout, removes its large rotating foot and makes use of the Lexmark-Unicomp FSR pointing stick.2002[37]IBM introduces the original Compact ANPOS Keyboard (CANPOS). It is a 133/134-key keyboard with an integrated pointing device and optionally an MSR that manages to pack all this functionality into a form-factor that is roughly as wide as a TKL. It is considered to be within the PMPOS series of buckling-sleeve Model Ms.March2003[ASK]IBM introduces the first SK-8835 (USB Keyboard with UltraNav, pictured) and SK-8845 (USB Travel Keyboard with UltraNav) releases, in turn the first models of the SK-8835/SK-8840/SK-8845 family of discrete keyboards with a classic ThinkPad layout and a Synaptic TouchStyk pointing stick.October2003[ASK]IBM introduces the 3494 Track Pointer Keyboard for the TotalStorage 3494 Enterprise Automated Tape Library. It is a variant of the Unicomp On-The-Stick (Model M13) that replaces an earlier Model M5-2 3494 Track Ball Keyboard. Because of its Unicomp base, it is the only known IBM-branded M13 to use an FSR-based pointing stick instead of a TrackPoint. It is the latest known IBM-branded buckling spring keyboard to be introduced.2004Brandon Ermita begins ClickyKeyboards (ClickyKeyboards.com) as a way of preparing for upcoming online academic database projects for Princeton University by documenting Model M keyboards. This will soon grow into a passion and business for restoring and selling Model M keyboards that is still going today, having since sold thousands of keyboards and became the most well-known of such businesses.10thMarch2004[ASK]IBM introduces the SK-8840 (IBM PS/2 Travel Keyboard with UltraNav), a new PS/2 member for the SK-8835/SK-8840/SK-8845 family based on the existing SK-8845.1stMay2005Lenovo acquires IBM Personal Computing Division, gaining its ThinkPad brand, access to the SK-8835/SK-8840/SK-8845 keyboard family, various other relevant IP and personnel.November2006Unicomp introduces the SpaceSaver, a variant of the Model M-based EnduraPro without a pointing stick and two mouse buttons.29thAugust2008IBM introduces the Modular POS (MPOS) series of buckling-sleeve Model Ms as successors to RPOS, finally shaking up IBM POS keyboard design for the first time since 1993. MPOS at this point includes the IBM Modular 67-Key POS Keyboard, IBM MANPOS Keyboard and IBM MCANPOS Keyboard. The \"modular\" in their names refers to how some of the keyboard's extra functionality is user removable and replaceable.April2011[38]Unicomp introduces the SpaceSaver M, an Apple Mac OS X (now simply macOS) centric version of the Model M-based SpaceSaver. The original SpaceSaver is renamed \"SpaceSaver PC\".22ndApril2011[ASK]Soarer's Converter firmware debuts when Soarer starts a geekhack thread on the subject. Originally for Teensy-based microcontroller units, it makes using IBM PC/XT and terminal compatible keyboards much easier than before. When eventually paired with Pro Micros and custom solutions such as orihalcon's and tinkerBOY's cables became available, it became the most popular of such firmware. It will go on to win \"best input device mod\" in Deskthority Awards 2012.23rdAugust2011[39]Lenovo introduces the Android-based ThinkPad Tablet (types 1838 and 1839). To go with it, the Lenovo ThinkPad Tablet Keyboard Folio Case (model 0B33533) is also introduced and is the first device with an Optical TrackPoint.27thSeptember2011[ASK]The IBM Modular 67-Key POS Keyboard with LCD Display is introduced as the fourth and final member of the MPOS series of buckling-sleeve Model Ms, replacing the RPOS-era Model M8 and thus sometimes known as the \"M8-e\". It is presently the latest known IBM buckling sleeve keyboard design.April2012[ASK]Unicomp renames the Model M-based SpaceSaver PC to its current name Ultra Classic.June2012[ASK]Lenovo makes the Precision Keyboard the standard keyboard design for Lenovo ThinkPads going forward, starting with the xx30 generation. Precision (also known as the \"chiclet-style\" or 6-row keyboard) is a derivative of AccuType Keyboard that was previously tested on some specific ThinkPads before now mostly laying to rest the 7-row keyboard classic ThinkPad layout across the board.1stAugust2012Toshiba TEC acquires IBM Retail Store Solutions, creating Toshiba Global Commerce Solutions (TGCS). TGCS inherited IBM's last remaining portion of the Model M keyboard family and now remains the only company marketing IBM buckling sleeve keyboards.2013[ASK]IBM introduces the SK-8845CR variant of the SK-8835/SK-8840/SK-8845 family of ThinkPad-style discrete keyboards, uniquely omitting a TouchPad compared to the previous variants. This is the latest known keyboard release with a classic ThinkPad layout.1stOctober2014Lenovo acquires IBM x86 Server Business, receiving IBM's System x, BladeCenter and Flex System blade servers and switches, x86-based Flex integrated systems, NeXtScale and iDataPlex servers and associated software, blade networking and maintenance operations.February2015Unicomp introduces the Sun Unix SpaceSaver, a version of the Model M-based Ultra Classic and SpaceSaver M with a layout tailored to Sun Unix usage.1stJuly2015[ASK]Joe Strandberg (known as Ellipse on deskthority and geekhack) founds Model F Labs and begins the Brand New Model F Keyboards project. The original goal is to recreate the capacitive buckling spring and the 472X-200 type and 472X-300 type Model Fs with modernised electronics and available at an affordable price. By the mid 2020s, the project will expand to include reproduction beam spring keyboards and Model M-inspired reproduction Model F keyboards.23rdOctober2017Unicomp is acquired by Video Display Corporation (VDC) as an \"opportunity to develop, market and sell Tempest keyboards for its cyber security division\".16thJanuary2018Unicomp is reincorporated from \"Unicomp, Inc.\" to \"Unicomp GA, LLC\" following its purchase by VDC.29thMarch2020[ASK]Unicomp introduces the New Model M, the first entirely new buckling-spring Model M variant since the '90s. Whilst it doesn't revolutionise the typical Model M internal mechanical and electronical design, its cover set is produced with new tooling and represents an upward shift in quality over other contemporary Unicomp keyboards.September2020Demolition of IBM United Kingdom's former Greenock, Scotland plant (plant 55) is completed.24thFebruary2021[ASK]Unicomp introduces the Mini Model M, a tenkeyless counterpart to the New Model M. Its cover set is likewise produced with new tooling, but it also sports new membrane assembly design that allows larger key combinations in various scenarios and controller card design that sports a lockable USB port.November2022[40]Lenovo introduces the ThinkPad X1 Fold 16 Gen 1 foldable computer and its optional Bluetooth TrackPoint Keyboard and Stand (model TKBBTDU811). TKBBTDU811 is the first Lenovo removable keyboard with an integrated Sensel haptic trackpad.24thApril2024Unicomp completes a factory move from 510 Henry Clay Blvd, Lexington, Kentucky 40505 to 550 W 4th St #125, Lexington, Kentucky 40508.SourcesASK. Admiral Shark's Keyboards original content. License/note: CC BY-NC-SA 4.0.Mr. Haelscheir - donated photo.Flygvapenmuseum - File:IBM Model A typewriter (1).jpg [accessed 2024-08-01]. License/note: CC BY-SA 4.0 (cropped).IBM - IBM 024 Card Punch 026 Printing Card Punch Customer Engineering Manual of Instruction (#22-8319-0) [accessed 2025-03-29]. License/note: photos used under fair dealing.Norsk Teknisk Museum - File:IBM Model B typewriter (1).jpg [accessed 2024-08-01]. License/note: CC BY-SA 4.0 (cropped).Tekniska museet - File:IBM Model C Executive (1).jpg [accessed 2024-08-01]. License/note: CC BY-SA 4.0 (cropped).Norsk Teknisk Museum - File:IBM Model D Executive (1) (cropped).jpg [accessed 2024-08-01]. License/note: CC BY-SA 4.0 (cropped).snuci - File:IBM 3277 typewriter keyboard - keyboard top.JPG [accessed 2022-12-07]. License/note: public domain.ã†ãƒãé‡éƒ - File:IBM System370 model 138.jpg [accessed 2023-12-09]. License/note: CC BY-SA 4.0 (cropped). Museo de InformÃ¡tica - R/EvoluciÃ³n 2010 | Equipos expuestos en UTN [accessed 2023-01-19]. License/note: CC BY-SA 3.0.TheMK#1822 - donated photos. License/note: CC-BY-NC-SA 4.0.IBM - IBM Displaywriter System General Information Manual (#G544-0851-5) [accessed 2023-12-06]. License/note: document archived by bitsavers.webwit - Index of /input/ibm_misc [accessed 2023-01-06]. License/note: public domain.Computerworld - 18 Apr 1983 [accessed 2023-08-05]. License/note: accessed via Google Books, photo used under fair dealing.Wazrach @ deskthority - IBM 4980 Model F Battleship (DONE) [accessed 2023-08-03]. License/note: permission to use photos requested and given via DMs.IBM - An Introduction to the IBM 8100 Information System (#GA27-2875-7) [accessed 2023-01-16]. License/note: document archived by bitsavers, photos used under fair dealing.Rik Myslewski - . License/note: public domain.email donations - donated photo.Wyatt8740  - File:Ibm3161 1.jpg [accessed 2023-01-23]. License/note: public domain.Recycled Goods, Inc. - IBM 6770 Wheelwriter System/40 Typewriter F.P. 40 - Word Processor *NO RIBBON* [accessed 2023-02-26]. License/note: used under fair dealing.eBay - photos saved from past listings & used under fair dealing.ASK Keyboard Archive Photos - P/N 4783896 (198X, SMK) [accessed 2025-03-28]. License/note: photos archived from Recycled Goods, used under fair dealing.taylorswiftttttt - IBM Model M AT - 76X0035 - POS Keyboard [accessed 2022-04-09]. License/note: permission requested and explicitly given via direct correspondence.snuci - File:IBM 73x3832 Unsaver keyboard front.jpg [accessed 2024-10-02]. License/note: public domain.WorthPoint - Vintage IBM InfoWindow 3476 Display Station Monitor w/ Keyboard *See Desc* [accessed 2023-09-25]. License/note: photos saved from WorthPoint, used under fair dealing.IBM - IBM 4693/4694 Store Systems Hardware Service Manual for Point-of-Sale Input/Output Devices [accessed 2022-04-24].Brandon @ clickykeyboards.com - photo used with attribution [accessed 2024-04-21]. License/note: https://deskthority.net/wiki/Help:Contents#Copyright.themk - donated photo. License/note: CC BY-NC-SA 4.0.IBM - Combined mouse and trackball [accessed 2025-03-21]. License/note: figures used under fair dealing.D. E. Larsso - File:IBM PS2 L40SX.jpg [accessed 2021-12-04]. License/note: CC BY-SA 4.0.Jack @ laptop.pics - donated photos.IBM - ftp://public.dhe.ibm.com [accessed 2025-03-05]. License/note: archived from IBM public FTP & used under fair dealing.Brandon @ clickykeyboards.com - 1997 IBM model M4-1 keyboard with trackpoint (84H8470) 18-JUL-1997 and external numpad (84H8537) + spare keyboard assembly [accessed 2022-08-20]. License/note: https://deskthority.net/wiki/Help:Contents#Copyright.WorthPoint - 1994 IBM Easy Options M1 Computer Keyboard 60G3570 WP1 M Clicky Buckling PC PS2 [accessed 2024-05-07]. License/note: photos saved from WorthPoint, used under fair dealing.ASK Keyboard Archive - P/N 66G0121 (1994, Lexmark) [accessed 2023-06-04]. License/note: photos saved from volatile eBay listing, used under fair dealing.P. Zwettler - M15 - IBM 13H6689 [accessed 2024-09-19]. License/note: All Rites Reversed.Richard Sapper - ThinkPad 701 [accessed 2025-03-25]. License/note: copyright of Richard Sapper, used under fair dealing.doomsday_device - donated photos.Unicomp - SpaceSaver M (Mac or Apple) [accessed 2022-11-08]. License/note: retrieved via Wayback Machine (2011-07-22 capture).DZ-World @ AliExpress - ThinkPad Tablet 1838 1839 Booklet Keyboard Leather Folio Case w/ US English keyboard USB Port 00HM470 SM10E37708 03X6354 04W2157 [accessed 2024-02-18]. License/note: photos saved from AliExpress listing, used under fair dealing, retrieved via Wayback Machine (2024-02-18 snapshot).Lenovo - Parts - X1 Fold 16 Gen 1 (Type 21ES, 21ET) Laptop (ThinkPad) - Type 21ES [accessed 2023-11-08]. License/note: photos used under fair dealing.Admiral Shark's Keyboards logoAdmiral Shark's KeyboardsHomeSitemapTerms of Use, Use of JavaScript & DisclaimersOriginal text & images licensed under CC BY-NC-SA 4.0Support ASK on Ko-fiDeveloped in WalesPowered by Debian",
    "summary": {
      "en": "The text provides a detailed timeline of IBM's keyboard history, highlighting key developments from the 1890s to the present. Here are the main points:\n\n1. **Origins and Early Innovations**: The timeline begins with Herman Hollerith's founding of the Tabulating Machine Company in the 1890s and his patent for the first keypunch in 1901. This laid the groundwork for IBM's future keyboard innovations.\n\n2. **Company Evolution**: IBM was formed in 1924 from the merger of several companies, becoming a leader in typewriters and keyboards. Over the decades, IBM acquired other companies and introduced various keyboard technologies.\n\n3. **Key Releases**: Significant milestones include:\n   - The introduction of electric typewriters in the 1930s.\n   - The development of the first generation of keyboards in 1949.\n   - The launch of the Model F and Model M keyboards in the 1980s, which became iconic for their design and functionality.\n\n4. **Technological Advancements**: Various keyboard types were developed, including capacitive buckling spring designs and membrane keyboards. Innovations like the TrackPoint pointing stick were introduced in ThinkPad laptops.\n\n5. **Corporate Changes**: In the 1990s, IBM divested its keyboard manufacturing to Lexmark, which later transitioned to Unicomp, continuing to produce Model M keyboards.\n\n6. **Recent Developments**: The timeline concludes with Unicomp's introduction of new keyboard models in the 2020s and Lenovo's continuing evolution of keyboard designs in its ThinkPad series.\n\nOverall, the timeline captures IBM's significant influence on keyboard technology and design over the past century.",
      "ko": "IBMì˜ í‚¤ë³´ë“œ ì—­ì‚¬ë¥¼ ë‹¤ë£¬ ì´ í…ìŠ¤íŠ¸ëŠ” 1890ë…„ëŒ€ë¶€í„° í˜„ì¬ê¹Œì§€ì˜ ì£¼ìš” ë°œì „ ê³¼ì •ì„ ìì„¸íˆ ì„¤ëª…í•˜ê³  ìˆìŠµë‹ˆë‹¤. \n\në¨¼ì €, ì´ íƒ€ì„ë¼ì¸ì€ 1890ë…„ëŒ€ì— í—ˆë¨¼ í™€ëŸ¬ë¦¬ìŠ¤ê°€ í‘œ ê³„ì‚° ê¸°ê³„ íšŒì‚¬ë¥¼ ì„¤ë¦½í•˜ê³  1901ë…„ì— ìµœì´ˆì˜ í‚¤í€ì¹˜ì— ëŒ€í•œ íŠ¹í—ˆë¥¼ ë°›ì€ ê²ƒìœ¼ë¡œ ì‹œì‘ë©ë‹ˆë‹¤. ì´ëŠ” IBMì˜ ë¯¸ë˜ í‚¤ë³´ë“œ í˜ì‹ ì˜ ê¸°ì´ˆê°€ ë˜ì—ˆìŠµë‹ˆë‹¤. \n\nIBMì€ 1924ë…„ì— ì—¬ëŸ¬ íšŒì‚¬ì˜ í•©ë³‘ìœ¼ë¡œ ì„¤ë¦½ë˜ì–´ íƒ€ìê¸°ì™€ í‚¤ë³´ë“œ ë¶„ì•¼ì˜ ì„ ë‘ì£¼ìê°€ ë˜ì—ˆìŠµë‹ˆë‹¤. ì´í›„ ìˆ˜ì‹­ ë…„ ë™ì•ˆ IBMì€ ë‹¤ë¥¸ íšŒì‚¬ë¥¼ ì¸ìˆ˜í•˜ê³  ë‹¤ì–‘í•œ í‚¤ë³´ë“œ ê¸°ìˆ ì„ ë„ì…í–ˆìŠµë‹ˆë‹¤. \n\nì¤‘ìš”í•œ ì´ì •í‘œë¡œëŠ” 1930ë…„ëŒ€ ì „ê¸° íƒ€ìê¸°ì˜ ë„ì…, 1949ë…„ ì²« ë²ˆì§¸ ì„¸ëŒ€ í‚¤ë³´ë“œì˜ ê°œë°œ, 1980ë…„ëŒ€ì— ëª¨ë¸ Fì™€ ëª¨ë¸ M í‚¤ë³´ë“œì˜ ì¶œì‹œê°€ ìˆìŠµë‹ˆë‹¤. ì´ í‚¤ë³´ë“œë“¤ì€ ë””ìì¸ê³¼ ê¸°ëŠ¥ì„±ìœ¼ë¡œ ì•„ì´ì½”ë‹‰í•œ ì¡´ì¬ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤. \n\nê¸°ìˆ  ë°œì „ ì¸¡ë©´ì—ì„œëŠ” ì •ì „ ìš©ëŸ‰ ë°©ì‹ì˜ ë²„í´ë§ ìŠ¤í”„ë§ ë””ìì¸ê³¼ ë©¤ë¸Œë ˆì¸ í‚¤ë³´ë“œ ë“± ë‹¤ì–‘í•œ í‚¤ë³´ë“œ ìœ í˜•ì´ ê°œë°œë˜ì—ˆìŠµë‹ˆë‹¤. ë˜í•œ, ThinkPad ë…¸íŠ¸ë¶ì—ëŠ” íŠ¸ë™í¬ì¸íŠ¸ í¬ì¸íŒ… ìŠ¤í‹±ê³¼ ê°™ì€ í˜ì‹ ì ì¸ ê¸°ëŠ¥ì´ ë„ì…ë˜ì—ˆìŠµë‹ˆë‹¤. \n\n1990ë…„ëŒ€ì—ëŠ” IBMì´ í‚¤ë³´ë“œ ì œì¡°ë¥¼ ë ‰ìŠ¤ë§ˆí¬ì— ë§¤ê°í•˜ì˜€ê³ , ì´í›„ ìœ ë‹ˆì»´í”„ê°€ ì´ë¥¼ ì¸ìˆ˜í•˜ì—¬ ëª¨ë¸ M í‚¤ë³´ë“œë¥¼ ê³„ì† ìƒì‚°í•˜ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. \n\nìµœê·¼ì—ëŠ” 2020ë…„ëŒ€ì— ìœ ë‹ˆì»´í”„ê°€ ìƒˆë¡œìš´ í‚¤ë³´ë“œ ëª¨ë¸ì„ ì¶œì‹œí•˜ê³ , ë ˆë…¸ë²„ê°€ ThinkPad ì‹œë¦¬ì¦ˆì˜ í‚¤ë³´ë“œ ë””ìì¸ì„ ì§€ì†ì ìœ¼ë¡œ ë°œì „ì‹œí‚¤ê³  ìˆìŠµë‹ˆë‹¤. \n\nì´ íƒ€ì„ë¼ì¸ì€ ì§€ë‚œ ì„¸ê¸° ë™ì•ˆ IBMì´ í‚¤ë³´ë“œ ê¸°ìˆ ê³¼ ë””ìì¸ì— ë¯¸ì¹œ ì¤‘ìš”í•œ ì˜í–¥ì„ ì˜ ë³´ì—¬ì¤ë‹ˆë‹¤.",
      "ja": "ã“ã®ãƒ†ã‚­ã‚¹ãƒˆã¯ã€IBMã®ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ã®æ­´å²ã‚’è©³ç´°ã«ç¤ºã—ãŸã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ã§ã€1890å¹´ä»£ã‹ã‚‰ç¾åœ¨ã¾ã§ã®é‡è¦ãªç™ºå±•ã‚’å¼·èª¿ã—ã¦ã„ã¾ã™ã€‚\n\nã¾ãšã€1890å¹´ä»£ã«ãƒãƒ¼ãƒãƒ³ãƒ»ãƒ›ãƒ¬ãƒªã‚¹ãŒé›†è¨ˆæ©Ÿæ¢°ä¼šç¤¾ã‚’è¨­ç«‹ã—ã€1901å¹´ã«æœ€åˆã®ã‚­ãƒ¼ãƒ‘ãƒ³ãƒã®ç‰¹è¨±ã‚’å–å¾—ã—ãŸã“ã¨ãŒç´¹ä»‹ã•ã‚Œã¦ã„ã¾ã™ã€‚ã“ã‚ŒãŒIBMã®ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰é©æ–°ã®åŸºç›¤ã¨ãªã‚Šã¾ã—ãŸã€‚\n\nIBMã¯1924å¹´ã«ã„ãã¤ã‹ã®ä¼šç¤¾ãŒåˆä½µã—ã¦è¨­ç«‹ã•ã‚Œã€ã‚¿ã‚¤ãƒ—ãƒ©ã‚¤ã‚¿ãƒ¼ã‚„ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ã®ãƒªãƒ¼ãƒ€ãƒ¼ã¨ãªã‚Šã¾ã—ãŸã€‚æ•°åå¹´ã®é–“ã«ã€IBMã¯ä»–ã®ä¼æ¥­ã‚’è²·åã—ã€ã•ã¾ã–ã¾ãªã‚­ãƒ¼ãƒœãƒ¼ãƒ‰æŠ€è¡“ã‚’å°å…¥ã—ã¾ã—ãŸã€‚\n\né‡è¦ãªãƒªãƒªãƒ¼ã‚¹ã¨ã—ã¦ã¯ã€1930å¹´ä»£ã«é›»å‹•ã‚¿ã‚¤ãƒ—ãƒ©ã‚¤ã‚¿ãƒ¼ãŒå°å…¥ã•ã‚ŒãŸã“ã¨ã€1949å¹´ã«æœ€åˆã®ä¸–ä»£ã®ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ãŒé–‹ç™ºã•ã‚ŒãŸã“ã¨ã€1980å¹´ä»£ã«ãƒ¢ãƒ‡ãƒ«Fã¨ãƒ¢ãƒ‡ãƒ«Mã®ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ãŒç™ºå£²ã•ã‚Œã€ãƒ‡ã‚¶ã‚¤ãƒ³ã¨æ©Ÿèƒ½æ€§ã§ã‚¢ã‚¤ã‚³ãƒ‹ãƒƒã‚¯ãªå­˜åœ¨ã¨ãªã£ãŸã“ã¨ãŒæŒ™ã’ã‚‰ã‚Œã¾ã™ã€‚\n\nã•ã¾ã–ã¾ãªã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ—ã‚‚é–‹ç™ºã•ã‚Œã€ã‚­ãƒ£ãƒ‘ã‚·ãƒ†ã‚£ãƒ–ãƒãƒƒã‚­ãƒ³ã‚°ã‚¹ãƒ—ãƒªãƒ³ã‚°ãƒ‡ã‚¶ã‚¤ãƒ³ã‚„ãƒ¡ãƒ³ãƒ–ãƒ¬ãƒ³ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ãŒç™»å ´ã—ã¾ã—ãŸã€‚ã¾ãŸã€ThinkPadãƒãƒ¼ãƒˆãƒ‘ã‚½ã‚³ãƒ³ã«ã¯ãƒˆãƒ©ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã¨ã„ã†ãƒã‚¤ãƒ³ãƒ†ã‚£ãƒ³ã‚°ã‚¹ãƒ†ã‚£ãƒƒã‚¯ãŒå°å…¥ã•ã‚Œã¾ã—ãŸã€‚\n\n1990å¹´ä»£ã«ã¯ã€IBMãŒã‚­ãƒ¼ãƒœãƒ¼ãƒ‰è£½é€ ã‚’ãƒ¬ãƒƒã‚¯ã‚¹ãƒãƒ¼ã‚¯ã«è­²æ¸¡ã—ã€ãã®å¾Œãƒ¦ãƒ‹ã‚³ãƒ³ãƒ—ã«ç§»è¡Œã—ã¾ã—ãŸã€‚ãƒ¦ãƒ‹ã‚³ãƒ³ãƒ—ã¯ãƒ¢ãƒ‡ãƒ«Mã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ã®ç”Ÿç”£ã‚’ç¶šã‘ã¦ã„ã¾ã™ã€‚\n\næœ€è¿‘ã®ç™ºå±•ã¨ã—ã¦ã¯ã€2020å¹´ä»£ã«ãƒ¦ãƒ‹ã‚³ãƒ³ãƒ—ãŒæ–°ã—ã„ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ãƒ¢ãƒ‡ãƒ«ã‚’å°å…¥ã—ã€ãƒ¬ãƒãƒœãŒThinkPadã‚·ãƒªãƒ¼ã‚ºã®ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ãƒ‡ã‚¶ã‚¤ãƒ³ã‚’é€²åŒ–ã•ã›ç¶šã‘ã¦ã„ã‚‹ã“ã¨ãŒæŒ™ã’ã‚‰ã‚Œã¾ã™ã€‚\n\nå…¨ä½“ã¨ã—ã¦ã€ã“ã®ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ã¯éå»100å¹´ã«ã‚ãŸã‚‹IBMã®ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰æŠ€è¡“ã¨ãƒ‡ã‚¶ã‚¤ãƒ³ã¸ã®é‡è¦ãªå½±éŸ¿ã‚’æ‰ãˆã¦ã„ã¾ã™ã€‚"
    }
  },
  {
    "id": "06ff5d440ab48a59",
    "title": {
      "en": "XAN: A Modern CSV-Centric Data Manipulation Toolkit for the Terminal",
      "ko": "XAN: í„°ë¯¸ë„ ë°ì´í„° í˜ì‹ ",
      "ja": "XAN: ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã®ãƒ‡ãƒ¼ã‚¿é©å‘½"
    },
    "type": "story",
    "url": "https://github.com/medialab/xan",
    "score": 48,
    "by": "Yomguithereal",
    "time": 1743090608,
    "content": "xan, the CSV magician\nxan is a command line tool that can be used to process CSV files directly from the shell.\nIt has been written in Rust to be as fast as possible, use as little memory as possible, and can easily handle very large CSV files (Gigabytes). It is also able to leverage parallelism (through multithreading) to make some tasks complete as fast as your computer can allow.\nIt can easily preview, filter, slice, aggregate, sort, join CSV files, and exposes a large collection of composable commands that can be chained together to perform a wide variety of typical tasks.\nxan also leverages its own expression language so you can perform complex tasks that cannot be done by relying on the simplest commands. This minimalistic language has been tailored for CSV data and is faster than evaluating typical dynamically-typed languages such as Python, Lua, JavaScript etc.\nNote that this tool is originally a fork of BurntSushi's xsv, but has been nearly entirely rewritten at that point, to fit SciencesPo's mÃ©dialab use-cases, rooted in web data collection and analysis geared towards social sciences (you might think CSV is outdated by now, but read our love letter to the format before judging too quickly). xan therefore goes beyond typical data manipulation and expose utilities related to lexicometry, graph theory and even scraping.\nFinally, xan can be used to display CSV files in the terminal, for easy exploration, and can even be used to draw basic data visualisations:\n\nview command\nflatten command\n\ncategorical histogram\nscatterplot\n\ncategorical scatterplot\nhistograms\n\nparallel processing\ntime series\n\nsmall multiples (facet grid)\ngrouped view\n\ncorrelation matrix heatmap\nheatmap\n\nSummary\n\nHow to install\n\nCargo\nHomebrew (macOS)\nArch Linux\nNix\nPre-built binaries\nInstalling completions\n\nQuick tour\nAvailable commands\nGeneral flags and IO model\nExpression language reference\nCookbook\nNews\nFrequently Asked Questions\n\nHow to install\nCargo\nxan can be installed using cargo (it usually comes with Rust):\ncargo install xan\n\nYou can also tweak the build flags to make sure the Rust compiler is able to leverage all your CPU's features:\nCARGO_BUILD_RUSTFLAGS='-C target-cpu=native' cargo install xan\n\nYou can also install the latest dev version thusly:\ncargo install --git https://github.com/medialab/xan\n\nHomebrew (macOS)\nxan can be installed with Homebrew on macOS thusly:\nbrew install xan\n\nArch Linux\nYou can install xan from the extra repository using pacman:\nsudo pacman -S xan\n\nNix\nxan is packaged for Nix, and is available in Nixpkgs as of 25.05 release. To\ninstall it, you may add it to your environment.systemPackages as pkgs.xan or\nuse nix-shell to enter an ephemeral shell.\nnix-shell -p xan\n\nPre-built binaries\nPre-built binaries can be found attached to every GitHub releases.\nCurrently supported targets include:\n\nx86_64-unknown-linux-musl\nx86_64-pc-windows-gnu\n\nFeel free to open a PR to improve the CI by adding relevant targets.\nInstalling completions\nNote that xan also exposes handy automatic completions for command and header/column names that you can install through the xan completions command.\nRun the following command to understand how to install those completions:\nxan completions -h\n\nQuick tour\nLet's learn about the most commonly used xan commands by exploring a corpus of French medias:\nDownloading the corpus\ncurl -LO https://github.com/medialab/corpora/raw/master/polarisation/medias.csv\n\nDisplaying the file's headers\nxan headers medias.csv\n\n0   webentity_id\n1   name\n2   prefixes\n3   home_page\n4   start_pages\n5   indegree\n6   hyphe_creation_timestamp\n7   hyphe_last_modification_timestamp\n8   outreach\n9   foundation_year\n10  batch\n11  edito\n12  parody\n13  origin\n14  digital_native\n15  mediacloud_ids\n16  wheel_category\n17  wheel_subcategory\n18  has_paywall\n19  inactive\n\nCounting the number of rows\nxan count medias.csv\n\n478\n\nPreviewing the file in the terminal\nxan view medias.csv\n\nDisplaying 5/20 cols from 10 first rows of medias.csv\nâ”Œâ”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ - â”‚ name          â”‚ prefixes      â”‚ home_page  â”‚ â€¦ â”‚ has_paywall â”‚ inactive â”‚\nâ”œâ”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ 0 â”‚ Acrimed.org   â”‚ http://acrimâ€¦ â”‚ http://wwâ€¦ â”‚ â€¦ â”‚ false       â”‚ <empty>  â”‚\nâ”‚ 1 â”‚ 24matins.fr   â”‚ http://24matâ€¦ â”‚ https://wâ€¦ â”‚ â€¦ â”‚ false       â”‚ <empty>  â”‚\nâ”‚ 2 â”‚ Actumag.info  â”‚ http://actumâ€¦ â”‚ https://aâ€¦ â”‚ â€¦ â”‚ false       â”‚ <empty>  â”‚\nâ”‚ 3 â”‚ 2012un-Nouveâ€¦ â”‚ http://2012uâ€¦ â”‚ http://wwâ€¦ â”‚ â€¦ â”‚ false       â”‚ <empty>  â”‚\nâ”‚ 4 â”‚ 24heuresactuâ€¦ â”‚ http://24heuâ€¦ â”‚ http://24â€¦ â”‚ â€¦ â”‚ false       â”‚ <empty>  â”‚\nâ”‚ 5 â”‚ AgoraVox      â”‚ http://agoraâ€¦ â”‚ http://wwâ€¦ â”‚ â€¦ â”‚ false       â”‚ <empty>  â”‚\nâ”‚ 6 â”‚ Al-Kanz.org   â”‚ http://al-kaâ€¦ â”‚ https://wâ€¦ â”‚ â€¦ â”‚ false       â”‚ <empty>  â”‚\nâ”‚ 7 â”‚ Alalumiereduâ€¦ â”‚ http://alaluâ€¦ â”‚ http://alâ€¦ â”‚ â€¦ â”‚ false       â”‚ <empty>  â”‚\nâ”‚ 8 â”‚ Allodocteursâ€¦ â”‚ http://allodâ€¦ â”‚ https://wâ€¦ â”‚ â€¦ â”‚ false       â”‚ <empty>  â”‚\nâ”‚ 9 â”‚ Alterinfo.net â”‚ http://alterâ€¦ â”‚ http://wwâ€¦ â”‚ â€¦ â”‚ <empty>     â”‚ true     â”‚\nâ”‚ â€¦ â”‚ â€¦             â”‚ â€¦             â”‚ â€¦          â”‚ â€¦ â”‚ â€¦           â”‚ â€¦        â”‚\nâ””â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\nOn unix, don't hesitate to use the -p flag to automagically forward the full output to an appropriate pager and skim through all the columns.\nReading a flattened representation of the first row\n# NOTE: drop -c to avoid truncating the values\nxan flatten -c medias.csv\n\nRow nÂ°0\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nwebentity_id                      1\nname                              Acrimed.org\nprefixes                          http://acrimed.org|http://acrimed69.blogspotâ€¦\nhome_page                         http://www.acrimed.org\nstart_pages                       http://acrimed.org|http://acrimed69.blogspotâ€¦\nindegree                          61\nhyphe_creation_timestamp          1560347020330\nhyphe_last_modification_timestamp 1560526005389\noutreach                          nationale\nfoundation_year                   2002\nbatch                             1\nedito                             media\nparody                            false\norigin                            france\ndigital_native                    true\nmediacloud_ids                    258269\nwheel_category                    Opinion Journalism\nwheel_subcategory                 Left Wing\nhas_paywall                       false\ninactive                          <empty>\n\nRow nÂ°1\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nwebentity_id                      2\n...\n\nSearching for rows\nxan search -s outreach internationale medias.csv | xan view\n\nDisplaying 4/20 cols from 10 first rows of <stdin>\nâ”Œâ”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ - â”‚ webentity_id â”‚ name               â”‚ â€¦ â”‚ has_paywall â”‚ inactive â”‚\nâ”œâ”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ 0 â”‚ 25           â”‚ Businessinsider.fr â”‚ â€¦ â”‚ false       â”‚ <empty>  â”‚\nâ”‚ 1 â”‚ 59           â”‚ Europe-Israel.org  â”‚ â€¦ â”‚ false       â”‚ <empty>  â”‚\nâ”‚ 2 â”‚ 66           â”‚ France 24          â”‚ â€¦ â”‚ false       â”‚ <empty>  â”‚\nâ”‚ 3 â”‚ 220          â”‚ RFI                â”‚ â€¦ â”‚ false       â”‚ <empty>  â”‚\nâ”‚ 4 â”‚ 231          â”‚ fr.Sott.net        â”‚ â€¦ â”‚ false       â”‚ <empty>  â”‚\nâ”‚ 5 â”‚ 246          â”‚ Voltairenet.org    â”‚ â€¦ â”‚ true        â”‚ <empty>  â”‚\nâ”‚ 6 â”‚ 254          â”‚ Afp.com /fr        â”‚ â€¦ â”‚ false       â”‚ <empty>  â”‚\nâ”‚ 7 â”‚ 265          â”‚ Euronews FR        â”‚ â€¦ â”‚ false       â”‚ <empty>  â”‚\nâ”‚ 8 â”‚ 333          â”‚ Arte.tv            â”‚ â€¦ â”‚ false       â”‚ <empty>  â”‚\nâ”‚ 9 â”‚ 341          â”‚ I24News.tv         â”‚ â€¦ â”‚ false       â”‚ <empty>  â”‚\nâ”‚ â€¦ â”‚ â€¦            â”‚ â€¦                  â”‚ â€¦ â”‚ â€¦           â”‚ â€¦        â”‚\nâ””â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\nSelecting some columns\nxan select foundation_year,name medias.csv | xan view\n\nDisplaying 2 cols from 10 first rows of <stdin>\nâ”Œâ”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ - â”‚ foundation_year â”‚ name                                  â”‚\nâ”œâ”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ 0 â”‚ 2002            â”‚ Acrimed.org                           â”‚\nâ”‚ 1 â”‚ 2006            â”‚ 24matins.fr                           â”‚\nâ”‚ 2 â”‚ 2013            â”‚ Actumag.info                          â”‚\nâ”‚ 3 â”‚ 2012            â”‚ 2012un-Nouveau-Paradigme.com          â”‚\nâ”‚ 4 â”‚ 2010            â”‚ 24heuresactu.com                      â”‚\nâ”‚ 5 â”‚ 2005            â”‚ AgoraVox                              â”‚\nâ”‚ 6 â”‚ 2008            â”‚ Al-Kanz.org                           â”‚\nâ”‚ 7 â”‚ 2012            â”‚ Alalumieredunouveaumonde.blogspot.com â”‚\nâ”‚ 8 â”‚ 2005            â”‚ Allodocteurs.fr                       â”‚\nâ”‚ 9 â”‚ 2005            â”‚ Alterinfo.net                         â”‚\nâ”‚ â€¦ â”‚ â€¦               â”‚ â€¦                                     â”‚\nâ””â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\nSorting the file\nxan sort -s foundation_year medias.csv | xan view -s name,foundation_year\n\nDisplaying 2 cols from 10 first rows of <stdin>\nâ”Œâ”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ - â”‚ name                               â”‚ foundation_year â”‚\nâ”œâ”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ 0 â”‚ Le Monde NumÃ©rique (Ouest France)  â”‚ <empty>         â”‚\nâ”‚ 1 â”‚ Le Figaro                          â”‚ 1826            â”‚\nâ”‚ 2 â”‚ Le journal de SaÃ´ne-et-Loire       â”‚ 1826            â”‚\nâ”‚ 3 â”‚ L'IndÃ©pendant                      â”‚ 1846            â”‚\nâ”‚ 4 â”‚ Le ProgrÃ¨s                         â”‚ 1859            â”‚\nâ”‚ 5 â”‚ La DÃ©pÃªche du Midi                 â”‚ 1870            â”‚\nâ”‚ 6 â”‚ Le PÃ©lerin                         â”‚ 1873            â”‚\nâ”‚ 7 â”‚ DerniÃ¨res Nouvelles d'Alsace (DNA) â”‚ 1877            â”‚\nâ”‚ 8 â”‚ La Croix                           â”‚ 1883            â”‚\nâ”‚ 9 â”‚ Le Chasseur Francais               â”‚ 1885            â”‚\nâ”‚ â€¦ â”‚ â€¦                                  â”‚ â€¦               â”‚\nâ””â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\nDeduplicating the file on some column\n# Some medias of our corpus have the same ids on mediacloud.org\nxan dedup -s mediacloud_ids medias.csv | xan count && xan count medias.csv\n\n457\n478\n\nDeduplicating can also be done while sorting:\nxan sort -s mediacloud_ids -u medias.csv\n\nComputing frequency tables\nxan frequency -s edito medias.csv | xan view\n\nDisplaying 3 cols from 5 rows of <stdin>\nâ”Œâ”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ - â”‚ field â”‚ value      â”‚ count â”‚\nâ”œâ”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ 0 â”‚ edito â”‚ media      â”‚ 423   â”‚\nâ”‚ 1 â”‚ edito â”‚ individu   â”‚ 30    â”‚\nâ”‚ 2 â”‚ edito â”‚ plateforme â”‚ 14    â”‚\nâ”‚ 3 â”‚ edito â”‚ agrÃ©gateur â”‚ 10    â”‚\nâ”‚ 4 â”‚ edito â”‚ agence     â”‚ 1     â”‚\nâ””â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜\n\nPrinting a histogram\nxan frequency -s edito medias.csv | xan hist\n\nHistogram for edito (bars: 5, sum: 478, max: 423):\n\nmedia      |423  88.49%|â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”|\nindividu   | 30   6.28%|â”â”â”â•¸                                                  |\nplateforme | 14   2.93%|â”â•¸                                                    |\nagrÃ©gateur | 10   2.09%|â”â•¸                                                    |\nagence     |  1   0.21%|â•¸                                                     |\n\nComputing descriptive statistics\nxan stats -s indegree,edito medias.csv | xan transpose | xan view -I\n\nDisplaying 2 cols from 14 rows of <stdin>\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ field       â”‚ indegree          â”‚ edito      â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ count       â”‚ 463               â”‚ 478        â”‚\nâ”‚ count_empty â”‚ 15                â”‚ 0          â”‚\nâ”‚ type        â”‚ int               â”‚ string     â”‚\nâ”‚ types       â”‚ int|empty         â”‚ string     â”‚\nâ”‚ sum         â”‚ 25987             â”‚ <empty>    â”‚\nâ”‚ mean        â”‚ 56.12742980561554 â”‚ <empty>    â”‚\nâ”‚ variance    â”‚ 4234.530197929737 â”‚ <empty>    â”‚\nâ”‚ stddev      â”‚ 65.07326792108829 â”‚ <empty>    â”‚\nâ”‚ min         â”‚ 0                 â”‚ <empty>    â”‚\nâ”‚ max         â”‚ 424               â”‚ <empty>    â”‚\nâ”‚ lex_first   â”‚ 0                 â”‚ agence     â”‚\nâ”‚ lex_last    â”‚ 99                â”‚ plateforme â”‚\nâ”‚ min_length  â”‚ 0                 â”‚ 5          â”‚\nâ”‚ max_length  â”‚ 3                 â”‚ 11         â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\nEvaluating an expression to filter a file\nxan filter 'batch > 1' medias.csv | xan count\n\n130\n\nTo access the expression language's cheatsheet, run xan help cheatsheet. To display the full list of available functions, run xan help functions.\nEvaluating an expression to create a new column based on other ones\nxan map 'fmt(\"{} ({})\", name, foundation_year)' key medias.csv | xan select key | xan slice -l 10\n\nkey\nAcrimed.org (2002)\n24matins.fr (2006)\nActumag.info (2013)\n2012un-Nouveau-Paradigme.com (2012)\n24heuresactu.com (2010)\nAgoraVox (2005)\nAl-Kanz.org (2008)\nAlalumieredunouveaumonde.blogspot.com (2012)\nAllodocteurs.fr (2005)\nAlterinfo.net (2005)\n\nTo access the expression language's cheatsheet, run xan help cheatsheet. To display the full list of available functions, run xan help functions.\nTransform a column by evaluating an expression\nxan transform name 'split(name, \".\") | first | upper' medias.csv | xan select name | xan slice -l 10\n\nname\nACRIMED\n24MATINS\nACTUMAG\n2012UN-NOUVEAU-PARADIGME\n24HEURESACTU\nAGORAVOX\nAL-KANZ\nALALUMIEREDUNOUVEAUMONDE\nALLODOCTEURS\nALTERINFO\n\nTo access the expression language's cheatsheet, run xan help cheatsheet. To display the full list of available functions, run xan help functions.\nPerforming custom aggregation\nxan agg 'sum(indegree) as total_indegree, mean(indegree) as mean_indegree' medias.csv | xan view -I\n\nDisplaying 1 col from 1 rows of <stdin>\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ total_indegree â”‚ mean_indegree     â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ 25987          â”‚ 56.12742980561554 â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\nTo access the expression language's cheatsheet, run xan help cheatsheet. To display the full list of available functions, run xan help functions. Finally, to display the list of available aggregation functions, run xan help aggs.\nGrouping rows and performing per-group aggregation\nxan groupby edito 'sum(indegree) as indegree' medias.csv | xan view -I\n\nDisplaying 1 col from 5 rows of <stdin>\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ edito      â”‚ indegree â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ agence     â”‚ 50       â”‚\nâ”‚ agrÃ©gateur â”‚ 459      â”‚\nâ”‚ plateforme â”‚ 658      â”‚\nâ”‚ media      â”‚ 24161    â”‚\nâ”‚ individu   â”‚ 659      â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\nTo access the expression language's cheatsheet, run xan help cheatsheet. To display the full list of available functions, run xan help functions. Finally, to display the list of available aggregation functions, run xan help aggs.\nAvailable commands\n\nhelp: Get help regarding the expression language\n\nExplore & visualize\n\ncount (c): Count rows in file\nheaders (h): Show header names\nview (v): Preview a CSV file in a human-friendly way\nflatten: Display a flattened version of each row of a file\nhist: Print a histogram with rows of CSV file as bars\nplot: Draw a scatter plot or line chart\nheatmap: Draw a heatmap of a CSV matrix\nprogress: Display a progress bar while reading CSV data\n\nSearch & filter\n\nsearch: Search for patterns in CSV data\nfilter: Only keep some CSV rows based on an evaluated expression\nslice: Slice rows of CSV file\ntop: Find top rows of a CSV file according to some column\nsample: Randomly sample CSV data\n\nSort & deduplicate\n\nsort: Sort CSV data\ndedup: Deduplicate a CSV file\nshuffle: Shuffle CSV data\n\nAggregate\n\nfrequency (freq): Show frequency tables\ngroupby: Aggregate data by groups of a CSV file\nstats: Compute basic statistics\nagg: Aggregate data from CSV file\nbins: Dispatch numeric columns into bins\n\nCombine multiple CSV files\n\ncat: Concatenate by row or column\njoin: Join CSV files\nregex-join: Fuzzy join CSV files using regex patterns\nurl-join: Join CSV files on url prefixes\nmerge: Merge multiple similar already sorted CSV files\n\nAdd, transform, drop and move columns\n\nselect: Select columns from a CSV file\ndrop: Drop columns from a CSV file\nmap: Create a new column by evaluating an expression on each CSV row\ntransform: Transform a column by evaluating an expression on each CSV row\nenum: Enumerate CSV file by preprending an index column\nflatmap: Emit one row per value yielded by an expression evaluated for each CSV row\nfill: Fill empty cells\nblank: Blank down contiguous identical cell values\n\nFormat, convert & recombobulate\n\nbehead: Drop header from CSV file\nrename: Rename columns of a CSV file\ninput: Read unusually formatted CSV data\nfixlengths: Makes all rows have same length\nfmt: Format CSV output (change field delimiter)\nexplode: Explode rows based on some column separator\nimplode: Collapse consecutive identical rows based on a diverging column\nfrom: Convert a variety of formats to CSV\nto: Convert a CSV file to a variety of data formats\nscrape: Scrape HTML into CSV data\nreverse: Reverse rows of CSV data\ntranspose (t): Transpose CSV file\n\nSplit a CSV file into multiple\n\nsplit: Split CSV data into chunks\npartition: Partition CSV data based on a column value\n\nParallel operation over multiple CSV files\n\nparallel (p): Map-reduce-like parallel computation over multiple CSV files\n\nGenerate CSV files\n\nrange: Create a CSV file from a numerical range\n\nPerform side-effects\n\neval: Evaluate/debug a single expression\nforeach: Loop over a CSV file to perform side effects\n\nLexicometry & fuzzy matching\n\ntokenize: Tokenize a text column\nvocab: Build a vocabulary over tokenized documents\ncluster: Cluster CSV data to find near-duplicates\n\nMatrix & network-related commands\n\nmatrix: Convert CSV data to matrix data\nnetwork: Convert CSV data to network data\n\nGeneral flags and IO model\nGetting help\nIf you ever feel lost, each command has a -h/--help flag that will print the related documentation.\nIf you need help about the expression language, check out the help command itself:\n# Help about help ;)\nxan help --help\n\nRegarding input & output formats\nAll xan commands expect a \"standard\" CSV file, e.g. comma-delimited, with proper double-quote escaping. This said, xan is also perfectly able to infer the delimiter from typical file extensions such as .tsv or .tab.\nIf you need to process a file with a custom delimiter, you can either use the xan input command or use the -d/--delimiter flag available with all commands.\nIf you need to output a custom CSV dialect (e.g. using ; delimiters), feel free to use the xan fmt command.\nFinally, even if most xan commands won't even need to decode the file's bytes, some might still need to. In this case, xan will expect correctly formatted UTF-8 text. Please use iconv or other utils if you need to process other encodings such as latin1 ahead of xan.\nWorking with headless CSV file\nEven if this is good practice to name your columns, some CSV file simply don't have headers. Most commands are able to deal with those file if you give the -n/--no-headers flag.\nNote that this flag always relates to the input, not the output. If for some reason you want to drop a CSV output's header row, use the xan behead command.\nRegarding stdin\nBy default, all commands will try to read from stdin when the file path is not specified. This makes piping easy and comfortable as it respects typical unix standards. Some commands may have multiple inputs (xan join, for instance), in which case stdin is usually specifiable using the - character:\n# First file given to join will be read from stdin\ncat file1.csv | xan join col1 - col2 file2.csv\n\nNote that the command will also warn you when stdin cannot be read, in case you forgot to indicate the file's path.\nRegarding stdout\nBy default, all commands will print their output to stdout (note that this output is usually buffered for performance reasons).\nIn addition, all commands expose a -o/--output flag that can be use to specify where to write the output. This can be useful if you do not want to or cannot use > (typically in some Windows shells). In which case, - as a output path will mean forwarding to stdout also. This can be useful when scripting sometimes.\nGzipped files\nxan is able to read gzipped files (having a .gz extension) out of the box.\nExpression language reference\n\nCheatsheet\nComprehensive list of functions & operators\nComprehensive list of aggregation functions\nScraping DSL\n\nCookbook\n\nMerging frequency tables, three ways\nParsing and visualizing dates with xan\nJoining files by URL prefixes\nMiscellaneous\n\nNews\nFor news about the tool's evolutions feel free to read:\n\nthe changelog\nthe xan zines\n\nFrequently Asked Questions\nHow to display a vertical bar chart?\nRotate your screen ;)",
    "summary": {
      "en": "**Summary of xan: The CSV Magician**\n\nxan is a powerful command-line tool designed for processing CSV files quickly and efficiently. Developed in Rust, it can handle large CSV files and uses multithreading for faster performance. Key features include:\n\n- **Data Manipulation**: Preview, filter, slice, aggregate, sort, and join CSV files with ease.\n- **Expression Language**: A custom language for complex operations on CSV data, which performs faster than typical scripting languages.\n- **Visualization**: Display CSV data in the terminal and create basic visualizations like histograms and scatterplots.\n\n**Installation Options**:\n- **Cargo**: Install using `cargo install xan`.\n- **Homebrew**: For macOS users, run `brew install xan`.\n- **Other package managers**: Available for Arch Linux, Nix, and pre-built binaries for various systems.\n\n**Common Commands**:\n- **Viewing and Previewing**: `xan view`, `xan headers`, `xan flatten`.\n- **Data Analysis**: `xan count`, `xan sort`, `xan dedup`, `xan frequency`.\n- **Transformations**: `xan map`, `xan transform`, `xan agg`.\n- **Visualization**: `xan hist`, `xan plot`.\n\nxan is tailored for social sciences, offering additional utilities for lexicometry and graph theory. It combines ease of use with powerful capabilities for data analysis and visualization. \n\nFor more details, users can explore the quick tour, command references, and FAQs provided with the tool.",
      "ko": "xanì€ CSV íŒŒì¼ì„ ë¹ ë¥´ê³  íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ ì„¤ê³„ëœ ê°•ë ¥í•œ ëª…ë ¹ì¤„ ë„êµ¬ì…ë‹ˆë‹¤. Rustë¡œ ê°œë°œë˜ì–´ ëŒ€ìš©ëŸ‰ CSV íŒŒì¼ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆìœ¼ë©°, ë©€í‹°ìŠ¤ë ˆë”©ì„ í†µí•´ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ì£¼ìš” ê¸°ëŠ¥ìœ¼ë¡œëŠ” ë°ì´í„° ì¡°ì‘, í‘œí˜„ ì–¸ì–´, ì‹œê°í™”ê°€ ìˆìŠµë‹ˆë‹¤.\n\në°ì´í„° ì¡°ì‘ ê¸°ëŠ¥ì„ í†µí•´ ì‚¬ìš©ìëŠ” CSV íŒŒì¼ì„ ì‰½ê²Œ ë¯¸ë¦¬ ë³´ê³ , í•„í„°ë§í•˜ê³ , ìŠ¬ë¼ì´ìŠ¤í•˜ë©°, ì§‘ê³„í•˜ê³ , ì •ë ¬í•˜ê³ , ì¡°ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í‘œí˜„ ì–¸ì–´ëŠ” CSV ë°ì´í„°ì— ëŒ€í•œ ë³µì¡í•œ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” ë§ì¶¤í˜• ì–¸ì–´ë¡œ, ì¼ë°˜ì ì¸ ìŠ¤í¬ë¦½íŠ¸ ì–¸ì–´ë³´ë‹¤ ë¹ ë¥¸ ì„±ëŠ¥ì„ ìë‘í•©ë‹ˆë‹¤. ë˜í•œ, CSV ë°ì´í„°ë¥¼ í„°ë¯¸ë„ì—ì„œ í‘œì‹œí•˜ê³  íˆìŠ¤í† ê·¸ë¨ì´ë‚˜ ì‚°ì ë„ì™€ ê°™ì€ ê¸°ë³¸ì ì¸ ì‹œê°í™”ë¥¼ ìƒì„±í•  ìˆ˜ ìˆëŠ” ê¸°ëŠ¥ë„ ì œê³µí•©ë‹ˆë‹¤.\n\nì„¤ì¹˜ ë°©ë²•ì€ ì—¬ëŸ¬ ê°€ì§€ê°€ ìˆìŠµë‹ˆë‹¤. Cargoë¥¼ ì´ìš©í•´ `cargo install xan` ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•  ìˆ˜ ìˆìœ¼ë©°, macOS ì‚¬ìš©ìëŠ” `brew install xan` ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ë©´ ë©ë‹ˆë‹¤. Arch Linux, Nixì™€ ê°™ì€ ë‹¤ë¥¸ íŒ¨í‚¤ì§€ ê´€ë¦¬ìì—ì„œë„ ì‚¬ìš©í•  ìˆ˜ ìˆìœ¼ë©°, ë‹¤ì–‘í•œ ì‹œìŠ¤í…œì— ë§ì¶˜ ë¯¸ë¦¬ ë¹Œë“œëœ ë°”ì´ë„ˆë¦¬ë„ ì œê³µë©ë‹ˆë‹¤.\n\nì¼ë°˜ì ì¸ ëª…ë ¹ì–´ë¡œëŠ” CSV íŒŒì¼ì„ ë³´ê³  ë¯¸ë¦¬ ë³´ëŠ” `xan view`, í—¤ë”ë¥¼ í™•ì¸í•˜ëŠ” `xan headers`, ë°ì´í„°ë¥¼ í‰íƒ„í™”í•˜ëŠ” `xan flatten` ë“±ì´ ìˆìŠµë‹ˆë‹¤. ë°ì´í„° ë¶„ì„ì„ ìœ„í•œ ëª…ë ¹ì–´ë¡œëŠ” `xan count`, `xan sort`, `xan dedup`, `xan frequency`ê°€ ìˆìœ¼ë©°, ë³€í™˜ ì‘ì—…ì„ ìœ„í•´ì„œëŠ” `xan map`, `xan transform`, `xan agg`ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‹œê°í™” ê´€ë ¨ ëª…ë ¹ì–´ë¡œëŠ” `xan hist`, `xan plot`ì´ ìˆìŠµë‹ˆë‹¤.\n\nxanì€ ì‚¬íšŒ ê³¼í•™ ë¶„ì•¼ì— ë§ì¶° ì„¤ê³„ë˜ì–´ ìˆìœ¼ë©°, ì–´íœ˜ ì¸¡ì • ë° ê·¸ë˜í”„ ì´ë¡ ì„ ìœ„í•œ ì¶”ê°€ ìœ í‹¸ë¦¬í‹°ë„ ì œê³µí•©ë‹ˆë‹¤. ì‚¬ìš©ì˜ ìš©ì´ì„±ê³¼ ê°•ë ¥í•œ ë°ì´í„° ë¶„ì„ ë° ì‹œê°í™” ê¸°ëŠ¥ì„ ê²°í•©í•œ ë„êµ¬ì…ë‹ˆë‹¤. ë” ë§ì€ ì •ë³´ëŠ” ì œê³µëœ í€µ íˆ¬ì–´, ëª…ë ¹ì–´ ì°¸ì¡° ë° FAQë¥¼ í†µí•´ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
      "ja": "xanã¯ã€CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¿…é€Ÿã‹ã¤åŠ¹ç‡çš„ã«å‡¦ç†ã™ã‚‹ãŸã‚ã«è¨­è¨ˆã•ã‚ŒãŸå¼·åŠ›ãªã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ãƒ„ãƒ¼ãƒ«ã§ã™ã€‚Rustã§é–‹ç™ºã•ã‚Œã¦ãŠã‚Šã€å¤§ããªCSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ‰±ã†ã“ã¨ãŒã§ãã€ãƒãƒ«ãƒã‚¹ãƒ¬ãƒƒãƒ‰ã‚’åˆ©ç”¨ã—ã¦ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã¦ã„ã¾ã™ã€‚ä¸»ãªæ©Ÿèƒ½ã«ã¯ã€ãƒ‡ãƒ¼ã‚¿æ“ä½œã€è¡¨ç¾è¨€èªã€è¦–è¦šåŒ–ãŒã‚ã‚Šã¾ã™ã€‚\n\nãƒ‡ãƒ¼ã‚¿æ“ä½œã§ã¯ã€CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã€ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã€ã‚¹ãƒ©ã‚¤ã‚¹ã€é›†è¨ˆã€ã‚½ãƒ¼ãƒˆã€çµåˆã‚’ç°¡å˜ã«è¡Œã†ã“ã¨ãŒã§ãã¾ã™ã€‚è¡¨ç¾è¨€èªã¯ã€CSVãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹è¤‡é›‘ãªæ“ä½œã‚’è¡Œã†ãŸã‚ã®ã‚«ã‚¹ã‚¿ãƒ è¨€èªã§ã€ä¸€èˆ¬çš„ãªã‚¹ã‚¯ãƒªãƒ—ãƒˆè¨€èªã‚ˆã‚Šã‚‚é«˜é€Ÿã«å‹•ä½œã—ã¾ã™ã€‚è¦–è¦šåŒ–æ©Ÿèƒ½ã§ã¯ã€ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ä¸Šã§CSVãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤ºã—ã€ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã‚„æ•£å¸ƒå›³ãªã©ã®åŸºæœ¬çš„ãªè¦–è¦šåŒ–ã‚’ä½œæˆã§ãã¾ã™ã€‚\n\nã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ–¹æ³•ã¯è¤‡æ•°ã‚ã‚Šã¾ã™ã€‚Cargoã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã¯ã€Œcargo install xanã€ã¨å…¥åŠ›ã—ã¾ã™ã€‚macOSãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ã€Œbrew install xanã€ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚ã¾ãŸã€Arch Linuxã‚„Nixå‘ã‘ã®ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã‚„ã€ã•ã¾ã–ã¾ãªã‚·ã‚¹ãƒ†ãƒ å‘ã‘ã®äº‹å‰ãƒ“ãƒ«ãƒ‰ã•ã‚ŒãŸãƒã‚¤ãƒŠãƒªã‚‚åˆ©ç”¨å¯èƒ½ã§ã™ã€‚\n\nä¸€èˆ¬çš„ãªã‚³ãƒãƒ³ãƒ‰ã«ã¯ã€ãƒ‡ãƒ¼ã‚¿ã®è¡¨ç¤ºã‚„ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’è¡Œã†ã€Œxan viewã€ã€ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’è¡¨ç¤ºã™ã‚‹ã€Œxan headersã€ã€ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ãƒ©ãƒƒãƒˆåŒ–ã™ã‚‹ã€Œxan flattenã€ãŒã‚ã‚Šã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿åˆ†æã«ã¯ã€Œxan countã€ã€ã€Œxan sortã€ã€ã€Œxan dedupã€ã€ã€Œxan frequencyã€ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã®å¤‰æ›ã«ã¯ã€Œxan mapã€ã€ã€Œxan transformã€ã€ã€Œxan aggã€ãŒã‚ã‚Šã€è¦–è¦šåŒ–ã«ã¯ã€Œxan histã€ã€ã€Œxan plotã€ãŒã‚ã‚Šã¾ã™ã€‚\n\nxanã¯ç¤¾ä¼šç§‘å­¦å‘ã‘ã«ç‰¹åŒ–ã—ã¦ãŠã‚Šã€èªå½™è¨ˆé‡å­¦ã‚„ã‚°ãƒ©ãƒ•ç†è«–ã«é–¢ã™ã‚‹è¿½åŠ ã®ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚‚æä¾›ã—ã¦ã„ã¾ã™ã€‚ä½¿ã„ã‚„ã™ã•ã¨å¼·åŠ›ãªãƒ‡ãƒ¼ã‚¿åˆ†æãƒ»è¦–è¦šåŒ–æ©Ÿèƒ½ã‚’å…¼ã­å‚™ãˆã¦ã„ã¾ã™ã€‚è©³ç´°ã«ã¤ã„ã¦ã¯ã€ãƒ„ãƒ¼ãƒ«ã«ä»˜å±ã®ã‚¯ã‚¤ãƒƒã‚¯ãƒ„ã‚¢ãƒ¼ã‚„ã‚³ãƒãƒ³ãƒ‰ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ã€FAQã‚’å‚ç…§ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚"
    }
  },
  {
    "id": "9ebd854186f36f8f",
    "title": {
      "en": "The disappearance of Gaia, ESA spacecraft will be turned off on 27 March 2025",
      "ko": "ê°€ì´ì•„, 2025ë…„ 3ì›” 27ì¼ ì¢…ë£Œ!",
      "ja": "ã‚¬ã‚¤ã‚¢æ¶ˆå¤±ã€2025å¹´3æœˆ27æ—¥åœæ­¢"
    },
    "type": "story",
    "url": "https://www.cosmos.esa.int/web/gaia/news",
    "score": 57,
    "by": "croes",
    "time": 1743015060,
    "content": "Athena\n\n                                                        3\n                                                        future\n\n                                                        0\n\nLISA\n\n                                                        2\n                                                        development\n\n                                                        0\n\nARIEL\n\n                                                        2\n                                                        development\n\n                                                        0\n\nProba-3\n\n                                                        2\n                                                        development\n\n                                                        0\n\nSMILE\n\n                                                        2\n                                                        development\n\n                                                        0\n\nExoMars RFM 2028\n\n                                                        2\n                                                        development\n\n                                                        0\n\nEnVision\n\n                                                        2\n                                                        development\n\n                                                        0\n\nACES\n\n                                                        2\n                                                        development\n\n                                                        0\n\nEinstein Probe\n\n                                                        2\n                                                        development\n\n                                                        0\n\nPLATO\n\n                                                        2\n                                                        development\n\n                                                        0\n\nComet Interceptor\n\n                                                        2\n                                                        development\n\n                                                        0\n\nJUICE\n\n                                                        1\n                                                        (post-) operational\n\n                                                        0\n\nMars Express\n\n                                                        1\n                                                        (post-) operational\n\n                                                        0\n\nEuclid\n\n                                                        1\n                                                        (post-) operational\n\n                                                        0\n\nINTEGRAL\n\n                                                        1\n                                                        (post-) operational\n\n                                                        0\n\nCHEOPS\n\n                                                        1\n                                                        (post-) operational\n\n                                                        0\n\nGaia\n\n                                                        1\n                                                        (post-) operational\n\n                                                        0\n\nExoMars 2016\n\n                                                        1\n                                                        (post-) operational\n\n                                                        0\n\nBepiColombo\n\n                                                        1\n                                                        (post-) operational\n\n                                                        0\n\nCluster\n\n                                                        1\n                                                        (post-) operational\n\n                                                        0\n\nXMM-Newton\n\n                                                        1\n                                                        (post-) operational\n\n                                                        0\n\nSolar Orbiter\n\n                                                        1\n                                                        (post-) operational\n\n                                                        0\n\nSOHO\n\n                                                        1\n                                                        (post-) operational\n\n                                                        0\n\nJWST\n\n                                                        1\n                                                        (post-) operational\n\n                                                        0\n\nProba-2\n\n                                                        1\n                                                        (post-) operational\n\n                                                        0\n\nCassini Huygens\n\n                                                        4\n                                                        collaborative\n\n                                                        0\n\nHinode\n\n                                                        4\n                                                        collaborative\n\n                                                        0\n\nXRISM\n\n                                                        4\n                                                        collaborative\n\n                                                        0\n\nAKARI\n\n                                                        4\n                                                        collaborative\n\n                                                        0\n\nDouble Star\n\n                                                        4\n                                                        collaborative\n\n                                                        0\n\nSuzaku\n\n                                                        4\n                                                        collaborative\n\n                                                        0\n\nCoRoT\n\n                                                        4\n                                                        collaborative\n\n                                                        0\n\nMicroscope\n\n                                                        4\n                                                        collaborative\n\n                                                        0\n\nIRIS\n\n                                                        4\n                                                        collaborative\n\n                                                        0\n\nChang'E\n\n                                                        4\n                                                        collaborative\n\n                                                        0\n\nHubble\n\n                                                        4\n                                                        collaborative\n\n                                                        0\n\nChandrayaan-1\n\n                                                        4\n                                                        collaborative\n\n                                                        0\n\nHitomi\n\n                                                        4\n                                                        collaborative\n\n                                                        0\n\nHipparcos\n\n                                                        5\n                                                        completed\n\n                                                        0\n\nLISA Pathfinder\n\n                                                        5\n                                                        completed\n\n                                                        0\n\nGiotto\n\n                                                        5\n                                                        completed\n\n                                                        0\n\nHerschel\n\n                                                        5\n                                                        completed\n\n                                                        0\n\nEXOSAT\n\n                                                        5\n                                                        completed\n\n                                                        0\n\nUlysses\n\n                                                        5\n                                                        completed\n\n                                                        0\n\nCOS-B\n\n                                                        5\n                                                        completed\n\n                                                        0\n\nSMART-1\n\n                                                        5\n                                                        completed\n\n                                                        0\n\nVenus Express\n\n                                                        5\n                                                        completed\n\n                                                        0\n\nIUE\n\n                                                        5\n                                                        completed\n\n                                                        0\n\nRosetta\n\n                                                        5\n                                                        completed\n\n                                                        0\n\nISO\n\n                                                        5\n                                                        completed\n\n                                                        0\n\nPlanck\n\n                                                        5\n                                                        completed\n\n                                                        0\n\nSign in\n\n                    Science Missions\n\n             The European Space Agency\n\n                 Science & Technology\n\ngaia\n\nNavigation\n\n                        Home\n\n                        Data\n\n        Data access\n\n        Gaia ESA Archive\n\n        Gaia Partner Data Centres\n\n        Gaia Affliate Data Centres\n\n        Gaia data citation guidelines\n\n        FAQ on Gaia Archive and Data\n\n        Tutorials\n\n        Data Release 4\n\n        Gaia DR4 overview\n\n        Gaia DR4 content\n\n        Gaia DR4 papers\n\n        Gaia DR4 previews\n\n        Focused Product Release\n\n        Gaia FPR overview\n\n        Gaia FPR content\n\n        Gaia FPR papers\n\n        Gaia FPR Documentation\n\n        Gaia FPR known issues\n\n        Gaia FPR events\n\n        Gaia FPR stories\n\n        Updated orbits for solar system objects\n\n        Diffuse Interstellar Bands from RVS spectra\n\n        Search for gravitational lenses with Gaia\n\n        Radial velocity time series for LPVs\n\n        Long Period Variables Application\n\n        Additional data from engineering images in omega Centauri\n\n        Data Release 3\n\n        Gaia DR3 overview\n\n        Gaia DR3 content\n\n        Gaia DR3 papers\n\n        Gaia DR3 documentation\n\n        Gaia DR3 known issues\n\n        Gaia DR3 auxiliary data\n\n        Gaia DR3 software tools\n\n        GaiaXPy\n\n        Bolometric Correction Tool\n\n        GSPPhot-metallicity calibration\n\n        GSPSpec metallicity/logg calibration\n\n        OA self-organising map tool\n\n        Extinction as function of l-b\n\n        Extinction coefficients in various passbands\n\n        Fitted dr3 photometric uncertainties tool\n\n        NSS Tools\n\n        Gaia DR3 events\n\n        Gaia DR3 stories\n\n        Where are the stars?\n\n        How far away are the stars?\n\n        How bright are the stars?\n\n        What colour do they have?\n\n        Where do the stars go or come from?\n\n        Do they approach us or move away?\n\n        What is in between the stars?\n\n        Do they go boom?\n\n        What are they made of?\n\n        How big or warm or old are the stars?\n\n        Is it a double star?\n\n        Is it a galaxy?\n\n        Is it a quasar?\n\n        Is it a Solar System object?\n\n        Where is the DR3 data?\n\n        How did you produce the data for this star?\n\n        Who produced the data?\n\n        How do they blink?\n\n        Did something move in front?\n\n        Can I use the DR3 data with data from other missions or observatories\n\n        Gaia DR3 previews\n\n        Early Data Release 3\n\n        Gaia EDR3 overview\n\n        Gaia EDR3 content\n\n        Gaia EDR3 papers\n\n        Gaia EDR3 documentation\n\n        Gaia EDR3 known issues\n\n        Gaia (E)DR3 passbands\n\n        Gaia EDR3 auxiliary data\n\n        Gaia EDR3 Python code\n\n        Gaia EDR3 events\n\n        Gaia EDR3 Stories\n\n        Gaia EDR3 - DPAC\n\n        Gaia EDR3 - Galactic anticentre\n\n        Gaia EDR3 - Coordination Unit 5\n\n        Gaia EDR3 - Star Trails\n\n        Gaia EDR3 - Coordination Unit 3\n\n        Gaia EDR3 - Acceleration of the solar system\n\n        Gaia EDR3 - Gaia Catalogue of Nearby Stars\n\n        Gaia EDR3 - Structure of the Magellanic Clouds\n\n        Gaia EDR3 - Gaia EDR3 vs Gaia DR2\n\n        Gaia EDR3 - Questions and Answers\n\n        Data Release 2\n\n        Gaia DR2 overview\n\n        Gaia DR2 content\n\n        Gaia DR2 papers\n\n        Gaia DR2 documentation\n\n        Gaia DR2 known issues\n\n        Gaia DR2 primer\n\n        Gaia DR2 passbands\n\n        Gaia DR2 auxiliary data\n\n        Gaia DR2 data\n\n        Gaia DR2 stories\n\n        Data Release 1\n\n        Gaia DR1 overview\n\n        Gaia DR1 content\n\n        Gaia DR1 papers\n\n        Gaia DR1 documentation\n\n        Gaia DR1 known issues\n\n        Pre-launch passbands\n\n        Gaia DR1  auxiliary data\n\n        Data Release Schedule\n\n        Gaia Alerts\n\n        Gaia Photometric Science Alerts\n\n        Gaia Follow-Up Network for Solar System Objects\n\n        Gaia Auxiliary Data\n\n        Gaia (E)DR3  auxiliary data\n\n        Gaia DR2 auxiliary data\n\n        Gaia DR1 auxiliary data\n\n        General auxiliary data\n\n        Gaia Tools\n\n        Gaia BH3 tools\n\n        Gaia DR3 software tools\n\n        Gaia Community Tools\n\n        Gaia Observation Forecast Tool\n\n        Gaia Sky\n\n        Gaia-GOSA service\n\n                        Mission\n\n        Mission status\n\n        Science\n\n        Science Objectives\n\n        Science Performance\n\n        Transmission Profiles of all Instruments\n\n        Dispersion of the Photometric Instrument\n\n        Sky Variations\n\n        Science Topics - Information Sheets\n\n        Spacecraft & Instruments\n\n        Instruments\n\n        Astrometric Instrument\n\n        Photometric Instrument\n\n        Spectroscopic Instrument\n\n        Payload Module\n\n        Focal Plane\n\n        Launch\n\n        Launch sequence\n\n        Gaia's 4th launch anniversary\n\n        Gaia's launch anniversary - 10 years in space\n\n        Operations\n\n        Mission Operations (ESOC)\n\n        Science Operations (ESAC)\n\n        Scanning Law\n\n        Lagrange Point L2\n\n        Gaia end of observations\n\n        Technology tests\n\n        Observe Gaia from the ground\n\n        Gaia spacecraft observations 2025\n\n        Spacecraft passivation\n\n        Data Processing\n\n                        People & Institutes\n\n        Data Processing and Analysis Consortium\n\n        Gaia DPAC Executive\n\n        Project Office\n\n        Coordination Units\n\n        System architecture\n\n        Data simulations\n\n        Core processing\n\n        Object processing\n\n        Photometric processing\n\n        Spectroscopic reduction\n\n        Variability processing\n\n        Astrophysical parameters\n\n        Catalogue access\n\n        Data Processing Centres\n\n        List of Institutes involved in DPAC\n\n        DPAC Newsletter\n\n        DPAC Code of Conduct\n\n        Gaia People\n\n        Gaia Science Team\n\n        ESA teams\n\n        Industry involvement\n\n        Vacancies\n\n                        News & stories\n\n        News\n\n        Stories\n\n        Image of the week\n\n        Gaia on ESA Science & Technology\n\n        Gaia on ESA.int\n\n        ESA Gaia blog\n\n        Calendar / Conferences\n\n        Gaia Bulletin\n\n        Subscribe\n\n        Gaia Bulletin Archive\n\n        Gaia Newsletter (discontinued)\n\n        Gaia Newsletter Archive\n\n        Gaia in the Media\n\n        Vacancies\n\n                        Science Results\n\n        Gaia Publications in Peer-Reviewed Journals\n\n        Publishing guidelines\n\n        Communicating your results\n\n        Gaia's impact on science\n\n        Highlights of Gaia DR3\n\n        Highlights of Gaia EDR3\n\n        Highlights of Gaia DR2\n\n        Highlights of Gaia DR1\n\n        Milky Way\n\n                        Resources\n\n        Images\n\n        Videos\n\n        Brochures\n\n        Education Materials\n\n        Gaia Public Documents\n\n        Presentations\n\n        Gaia Applications\n\n        DPAC Outreach\n\n        Posters & Flyers\n\n        Selected Reports and Conference Proceedings\n\n        Phd Theses\n\n        Links\n\n                        Questions\n\n        Gaia Helpdesk\n\n        Archive Help\n\n        FAQs on Gaia Mission\n\n        FAQ on Gaia Archive and Data\n\n        Privacy Settings\n\nGaia Mission News - Gaia\n\n    Gaia News\n\n    2025-03-21 The disappearance of Gaia\n\nOn 4 March, astronomer Zhuo-Xiao Wang captured this view of the sudden disappearance of ESAâ€™s Gaia spacecraft. After more than 11 years in space mapping the motions and properties of billions of stars, the spacecraftâ€™s operations are coming to an end. Gaia will be switched off on 27 March 2025. During a series of final test operations, flight controllers at ESAâ€™s ESOC mission control centre rotated Gaia, causing its sunshield to reflect more light towards Earth. As a result, Gaia appeared much brighter than usual and was observed by several citizen astronomers around the world. Gaia is seen here moving across the sky, initially brightening before vanishing as the spacecraft quickly rotates back to its typical orientation. This was the final time that Gaia will appear so bright to astronomers on Earth. The spacecraft will now remain â€˜darkâ€™ forever. The Gaia mission, however, will continue and culminate in two major data releases that are in preparation for 2026 and 2030.\n\nLast observations of the Gaia spacecraft from Beijing, China on 4 March 2026. Observations were performed using an 11-inch telescope. Credits: Zhuoxiao Wang - CC BY-SA 3.0 IGO.\n\nThe Gaia team is showcasing observations of the spacecraft at: https://www.cosmos.esa.int/web/gaia/ground-based-observations-of-gaia-spacecraft-2025\n\n    2025-02-21 Opening for a Gaia-related postdoc position in Leiden\n\nApplications are invited for a postdoctoral position at Leiden Observatory to work on (spectro-)photometric data processing for the Gaia mission in preparation for Gaia DR5. The tasks foreseen include: quality assessment of the calibration of the BP/RP spectra and the integrated photometry obtained from these spectra; studying and developing improvements to the removal of sky background, stray light, and effects of neighbouring sources from the raw BP/RP spectra; study and develop improvements to the flux and line spread function calibration for the BP/RP spectra.\n\nThe successful candidate will work under supervision of Anthony Brown and join the Gaia Data Processing and Analysis Consortium (DPAC). The\nwork will be embedded in Coordination Unit 5 (CU5, photometry) of DPAC, where close collaboration with the group at the Data Processing Center\nat the Institute of Astronomy in Cambridge is foreseen, as well as interaction with the other DPAC coordination units. In addition a fraction of the time will be spent on supporting the catalogue validation activities of the Gaia group at Groningen University.\n\nFull application details at: https://local.strw.leidenuniv.nl/jobs/brown_pd.php\n\n    2025-02-21 Gaia spacecraft passivation on 27 March\n\nOn 27 March 2025, the Gaia spacecraft will be passivated. While the Gaia spacecraft will enjoy its well-deserved retirement, the Gaia mission is far from over. The Gaia Data Processing and Analysis Consortium and ESA's Gaia science operations team is hard at work preparing Gaia's Data Release 4 (expected ~2026) and Gaia Data Release 5 (expected ~2030), with twice as many data products as Gaia's data release 3.\n\nA webpage has just been published on the Gaia passivation. More information on this milestone will be shared on this page around 27th of March.\n\n    2025-02-21 Another follow-up opportunity on 4 March to observe Gaia\n\nThe schedule on the page with information on how to observe Gaia has been updated. There will be another opportunity to observe Gaia on 4 March when the spacecraft will be shortly visible at its peak brightness of approximately 15th magnitude. Find observations made across the world here.\n\n    2025-02-11 Follow-up campaign to observe the Gaia spacecraft\n\nMany citizen astronomers have observed the Gaia spacecraft while it is more easily visible in the night sky and shared their observations with us. A dedicated webpage to cover this follow-up campaign has just been published and can be found here: https://www.cosmos.esa.int/web/gaia/ground-based-observations-of-gaia-spacecraft-2025.\n\nThe schedule indicating an approximate brightness for Gaia over the coming weeks has been updated as well and Gaia will still be visible for a little while longer. Find all details on how to observe the Gaia spacecraft from the ground here: https://www.cosmos.esa.int/web/gaia/observe-gaia.\n\n    2025-02-06 Gaia symposium at European Astronomical Society annual meeting in June\n\nIn June 2025, the European Astronomical Society will meet for its annual meeting. A symposium related to the Gaia mission is planned, Symposium S1 \"The (TWO) Billion Star Galaxy Census: Anticipating the Leap in Understanding of Planets, Stars, the Milky Way with Gaia DR4\".\n\nThe symposium now welcomes abstract submissions here. Abstract submission closes on 3 March 2025.\n\n    2025-02-05 Wobbling stars reveal hidden companions in Gaia data\n\nToday a story was published on esa.int/gaia on the discovery of an exoplanet Gaia-4b, which was hinted to exist purely from Gaia astrometric data. Find the full story here: Wobbling stars reveal hidden companions in Gaia data.\n\n    2025-01-23 Gaia's schedule for tests has changed\n\nThe schedule of the Gaia tests has changed. Gaia is remaining at maximum brightness for longer than initially planned. The Gaia ephemeris service remains valid and should be used for planning ground-based observations.The schedule will be updated here as soon as possible.\n\n    2025-01-19 Follow-up opportunities for Gaia\n\nThough Gaia stopped taking science observations, it is hard at work to perform a set of technology tests. As part of these tests, Gaia's angle with respect to the Sun will change, and the Gaia spacecraft's brightness is gradually increasing at the moment. While Gaia was a faint object in the sky during its science observation phase, it could potentially reach a 14 magnitude in the coming days. More details on Gaia's webpage to observe Gaia. Amateur astronomers & ground observatories are invited to observe Gaia's final moments before passivation.\n\n    2025-01-15 So long and thanks for all the fish! Last stars observed by Gaia this morning\n\nToday marks the end of Gaia's science observation phase. A story was published: \"Last starlight for ground-breaking Gaia\" on ESA's website, along with brand new visuals of our Milky Way (face-on) as well as edge-on. All visuals can be found from The Milky Way page on Gaia Cosmos along with a new animation featuring the Milky Way.\n\nHigh-contrast face-on impression of the Milky Way. By clicking the image, a higher-resolution version opens. Credits: ESA/Gaia/DPAC, Stefan Payne-Wardenaar - CC BY-SA 3.0 IGO. Find all versions from this page.\n\nAn infographic was created for this purpose as well: \"Sky-scanning complete for Gaia\".\n\n    2025-01-13 Self-registration is working again\n\nThe issue with the self-registration has been fixed now.\n\n    2024-12-20 Self-registration portlet is not working properly\n\nFollowing the migration of our web portal on Monday 16 December, some of our portlets are not yet fully functioning. The self-registration portlet, used for registering an account with our Gaia Archive, is currently having issues, not allowing all steps for the registration to be taken. Our apologies for the inconvenience. Our IT teams have indicated that it will take until early January before this issue can be fixed.\n\n    2024-12-03 New updates to the Gaia Community Tools\n\nWithin the astronomical community, many very useful tools are available for use with Gaia data. A non-exhaustive list is given on our Gaia Community Tools webpage. Several new updates were published recently to the page.\n\n    2024-11-29 New members of the Gaia Science Team\n\nA new group picture has been posted following the arrival of new members in the Gaia Science Team. Rodolfo Smiljanic from Warsaw, Poland and Johannes Sahlmann from ESAC (new Gaia Project Scientist since this year) now appear in the picture as well. We thank Timo Prusti for his contribution to the Gaia mission as project scientist. He was active as Gaia Science Team chair since 2007 and will retire from this duty end December 2024.\n\nFind the list of Gaia Science Team members here, with the new group picture as well.\n\n    2024-11-04 Pre-release of Gaia DR4 astrometric parameters for a star to be occulted by Uranus\nOn 12 November 2024 the star Gaia DR3 56716009513720320 will be occulted by the Solar System planet Uranus, which offers a rare opportunity to study the ring system and atmosphere of the planet. To allow for the best-possible planning for the ground-based occultation observing campaigns, we make the preliminary Gaia Data Release 4 (Gaia DR4) single-star astrometric solution parameters for this star public:\n\n      Object to be observed\n      Parameter name\n      Star occulted by Uranus\n\n      Date of occulation event\n\n      12 November 2024\n\n      Gaia DR4 source ID\n\n      56716009513720320\n\n      Epoch / Reference frame\n\n      2017.5 / ICRF\n\n      Right Ascension (RA) [degrees]\n      ra\n      52.79021223",
    "summary": {
      "en": "The text provides a summary of various space missions managed by the European Space Agency (ESA), categorizing them by their current status: \n\n1. **Future Missions**: Several missions are in development, including Athena, LISA, and ExoMars RFM 2028, among others.\n\n2. **Operational Missions**: Missions currently in operation include JUICE, Mars Express, and the James Webb Space Telescope (JWST).\n\n3. **Collaborative Missions**: There are multiple missions that are collaborative efforts, such as Hubble and Chandrayaan-1.\n\n4. **Completed Missions**: A list of completed missions includes Hipparcos, Giotto, and Rosetta.\n\nAdditionally, there is a focus on the Gaia mission, which has been mapping stars for over 11 years. Its operations will conclude on March 27, 2025, but data processing will continue, with major releases planned for 2026 and 2030. The text also mentions ongoing opportunities for citizen astronomers to observe Gaia as it brightens before its retirement.",
      "ko": "ìœ ëŸ½ìš°ì£¼êµ­(ESA)ì´ ê´€ë¦¬í•˜ëŠ” ë‹¤ì–‘í•œ ìš°ì£¼ ì„ë¬´ì— ëŒ€í•œ ìš”ì•½ì´ ì œê³µëœë‹¤. í˜„ì¬ ìƒíƒœì— ë”°ë¼ ì„ë¬´ë¥¼ ë¶„ë¥˜í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.\n\në¨¼ì €, ë¯¸ë˜ ì„ë¬´ë¡œëŠ” ì•„í…Œë‚˜, ë¦¬ì‚¬, ì—‘ì†Œë§ˆë¥´ìŠ¤ RFM 2028 ë“± ì—¬ëŸ¬ ì„ë¬´ê°€ ê°œë°œ ì¤‘ì´ë‹¤. \n\nìš´ì˜ ì¤‘ì¸ ì„ë¬´ì—ëŠ” ì£¼ìŠ¤(JUICE), í™”ì„± íƒì‚¬ì„ (Mars Express), ì œì„ìŠ¤ ì›¹ ìš°ì£¼ ë§ì›ê²½(JWST) ë“±ì´ í¬í•¨ëœë‹¤. \n\ní˜‘ë ¥ ì„ë¬´ë¡œëŠ” í—ˆë¸”(Hubble)ê³¼ ì°¬ë“œë¼ì–€-1(Chandrayaan-1)ê³¼ ê°™ì€ ì—¬ëŸ¬ ê³µë™ í”„ë¡œì íŠ¸ê°€ ìˆë‹¤. \n\nì™„ë£Œëœ ì„ë¬´ ëª©ë¡ì—ëŠ” íˆíŒŒë¥´ì½”ìŠ¤(Hipparcos), ì§€ì˜¤í† (Giotto), ë¡œì œíƒ€(Rosetta)ê°€ í¬í•¨ëœë‹¤. \n\në˜í•œ, ê°€ì´ì•„(Gaia) ì„ë¬´ì— ëŒ€í•œ ì–¸ê¸‰ì´ ìˆë‹¤. ê°€ì´ì•„ëŠ” 11ë…„ ë„˜ê²Œ ë³„ì„ ì§€ë„í™”í•˜ê³  ìˆìœ¼ë©°, 2025ë…„ 3ì›” 27ì¼ì— ìš´ì˜ì´ ì¢…ë£Œë  ì˜ˆì •ì´ë‹¤. ê·¸ëŸ¬ë‚˜ ë°ì´í„° ì²˜ë¦¬ ì‘ì—…ì€ ê³„ì†ë˜ë©°, 2026ë…„ê³¼ 2030ë…„ì— ì£¼ìš” ë°ì´í„°ê°€ ê³µê°œë  ê³„íšì´ë‹¤. ì´ì™€ í•¨ê»˜ ì‹œë¯¼ ì²œë¬¸í•™ìë“¤ì´ ê°€ì´ì•„ê°€ í‡´ì—­í•˜ê¸° ì „ ë°ì•„ì§€ëŠ” ëª¨ìŠµì„ ê´€ì°°í•  ìˆ˜ ìˆëŠ” ê¸°íšŒë„ ê³„ì† ì œê³µëœë‹¤ê³  í•œë‹¤.",
      "ja": "æ¬§å·å®‡å®™æ©Ÿé–¢ï¼ˆESAï¼‰ãŒç®¡ç†ã™ã‚‹ã•ã¾ã–ã¾ãªå®‡å®™ãƒŸãƒƒã‚·ãƒ§ãƒ³ã®æ¦‚è¦ãŒã€ç¾åœ¨ã®çŠ¶æ³ã«å¿œã˜ã¦åˆ†é¡ã•ã‚Œã¦ã„ã¾ã™ã€‚\n\næœªæ¥ã®ãƒŸãƒƒã‚·ãƒ§ãƒ³ã¨ã—ã¦ã¯ã€ã‚¢ãƒ†ãƒŠã€LISAã€ã‚¨ã‚¯ã‚½ãƒãƒ¼ã‚ºRFM 2028ãªã©ã€ã„ãã¤ã‹ã®ãƒŸãƒƒã‚·ãƒ§ãƒ³ãŒé–‹ç™ºä¸­ã§ã™ã€‚é‹ç”¨ä¸­ã®ãƒŸãƒƒã‚·ãƒ§ãƒ³ã«ã¯ã€JUICEã€ãƒãƒ¼ã‚ºã‚¨ã‚¯ã‚¹ãƒ—ãƒ¬ã‚¹ã€ã‚¸ã‚§ãƒ¼ãƒ ã‚ºãƒ»ã‚¦ã‚§ãƒƒãƒ–å®‡å®™æœ›é é¡ï¼ˆJWSTï¼‰ãŒã‚ã‚Šã¾ã™ã€‚å…±åŒãƒŸãƒƒã‚·ãƒ§ãƒ³ã«ã¯ã€ãƒãƒƒãƒ–ãƒ«å®‡å®™æœ›é é¡ã‚„ãƒãƒ£ãƒ³ãƒ‰ãƒ©ãƒ¤ãƒ¼ãƒ³1å·ãªã©ã€è¤‡æ•°ã®å…±åŒãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚å®Œäº†ã—ãŸãƒŸãƒƒã‚·ãƒ§ãƒ³ã«ã¯ã€ãƒ’ãƒƒãƒ‘ãƒ«ã‚³ã‚¹ã€ã‚¸ã‚ªãƒƒãƒˆã€ãƒ­ã‚¼ãƒƒã‚¿ãªã©ãŒã‚ã‚Šã¾ã™ã€‚\n\nç‰¹ã«ã‚¬ã‚¤ã‚¢ãƒŸãƒƒã‚·ãƒ§ãƒ³ã«æ³¨ç›®ãŒé›†ã¾ã£ã¦ã„ã¾ã™ã€‚ã“ã®ãƒŸãƒƒã‚·ãƒ§ãƒ³ã¯11å¹´ä»¥ä¸Šã«ã‚ãŸã‚Šæ˜Ÿã®åœ°å›³ã‚’ä½œæˆã—ã¦ãã¾ã—ãŸãŒã€2025å¹´3æœˆ27æ—¥ã«é‹ç”¨ãŒçµ‚äº†ã—ã¾ã™ã€‚ãŸã ã—ã€ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã¯ç¶šãã€2026å¹´ã¨2030å¹´ã«ä¸»è¦ãªãƒ‡ãƒ¼ã‚¿ã®å…¬é–‹ãŒäºˆå®šã•ã‚Œã¦ã„ã¾ã™ã€‚ã¾ãŸã€ã‚¬ã‚¤ã‚¢ãŒé€€å½¹å‰ã«æ˜ã‚‹ããªã‚‹æ™‚æœŸã«ã€ä¸€èˆ¬å¸‚æ°‘ã®å¤©æ–‡å­¦è€…ãŒè¦³æ¸¬ã™ã‚‹æ©Ÿä¼šã‚‚æä¾›ã•ã‚Œã¦ã„ã¾ã™ã€‚"
    }
  },
  {
    "id": "c03c2fe6e243884a",
    "title": {
      "en": "Spark AI (YC W24) is hiring a full-stack engineer in San Francisco",
      "ko": "ìŠ¤íŒŒí¬AI, SFì—ì„œ í’€ìŠ¤íƒ ì—”ì§€ë‹ˆì–´ ì±„ìš©!",
      "ja": "ã‚µãƒ³ãƒ•ãƒ©ãƒ³ã‚·ã‚¹ã‚³ã§ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢å‹Ÿé›†ï¼"
    },
    "type": "job",
    "url": "https://www.ycombinator.com/companies/spark/jobs/kDeJlPK-software-engineer-full-stack",
    "score": 1,
    "by": "tk90",
    "time": 1743282035,
    "content": "About Spark\nSpark is building an advanced AI research tool that helps energy developers build solar farms and battery plants.\nOne of the biggest challenges in renewable energy is not construction â€” itâ€™s navigating local regulations. We build AI agents that help energy developers find and understand critical information to develop and invest in solar farms.\nIndustry leaders like Colliers Engineering & Design, Standard Solar, and Cypress Creek Renewables use Spark to inform their investment decisions. Our customersâ€™ energy pipelines will produce the equivalent of 60GW â€” enough to power tens of millions of households a year!\nIf you're interested in learning how the energy infrastructure works and how you can help accelerate a historical energy transition with AI and software, weâ€™d love to hear from you!\nThe Team\nWeâ€™re funded by top investors, including AI Grant (Nat Friedman and Daniel Gross), the founders of Brex, Plaid, Helioscope (acq. Aurora Solar), and more (to be announced).\nYouâ€™ll be part of a small and ambitious team that has led Engineering and Product at Tesla, Apple, Brex, and Google. As an early member of the team, youâ€™ll work closely with the founders and shape the engineering culture.\nWe are an in-person company in San Francisco, CA, and we are in the office 5 days a week.\nWe use Typescript, NextJS, NodeJS, and Postgres.\nResponsibilities\n\nDesign and build our core APIs, AI infrastructure, and data pipeline that scrapes millions of data points every week\nOwn features end-to-end from working on an idea with the founders to designing, testing, shipping to prod, and getting feedback from customers\nArchitect and build cutting-edge AI systems like agentic web browsing, RAG, and data extraction\nWrite both frontend and backend code\nWork closely with the founders to build the product roadmap\nTalk to customers and understand how the energy industry works to inform better product decisions\n\nYouâ€™re a great fit ifâ€¦\nYou have 3+ years of experience\nYou love writing code but also care about having a significant impact. Being an early engineer means making the right trade-offs between writing perfect code and â€œgood enoughâ€ for the situation.\nYou believe that everything can be figured out. You can take a fuzzy goal, work independently toward a solution, and communicate effectively along the way.\nYou want to be a founder one day. Youâ€™ll see what it's like to start a vertical AI company (in the energy space). If thereâ€™s anything about business or tech youâ€™re interested in, weâ€™ll teach you.\nYouâ€™re NOT a great fit ifâ€¦\nYou want to ship perfect code. Speed is one of our main advantages as a startup. We donâ€™t have the luxury of spending time on perfection, and we always try to do more with less.\nYou donâ€™t care about the business side of things. Our technical decisions and business strategy go hand in hand. Understanding how they influence each other helps us build the right things.",
    "summary": {
      "en": "**Summary of Spark**\n\nSpark is creating an AI research tool designed to assist energy developers in building solar farms and battery plants by simplifying the navigation of local regulations. Their AI agents help find and understand vital information for solar farm development. Major companies like Colliers Engineering & Design and Standard Solar utilize Spark's tools, potentially generating enough energy to power millions of homes.\n\nSpark's team consists of experienced professionals from top companies like Tesla and Google. They are based in San Francisco and work in-person five days a week, using technologies like Typescript and NodeJS.\n\n**Key Responsibilities:**\n- Develop core APIs and AI systems that analyze large data sets.\n- Manage features from initial ideas to customer feedback.\n- Collaborate with founders to shape the product.\n\n**Ideal Candidate:**\n- Has 3+ years of experience and is passionate about coding with a focus on impact.\n- Is proactive in problem-solving and interested in business aspects.\n- Aspires to start their own company.\n\n**Not a Good Fit If:**\n- You prioritize perfect code over speed.\n- You are not interested in the intersection of technical and business decisions.",
      "ko": "ìŠ¤íŒŒí¬ëŠ” ì—ë„ˆì§€ ê°œë°œìë“¤ì´ íƒœì–‘ê´‘ ë°œì „ì†Œì™€ ë°°í„°ë¦¬ ê³µì¥ì„ ê±´ì„¤í•˜ëŠ” ë° ë„ì›€ì„ ì£¼ê¸° ìœ„í•´ ì§€ì—­ ê·œì œë¥¼ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ë•ëŠ” AI ì—°êµ¬ ë„êµ¬ë¥¼ ê°œë°œí•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ë“¤ì˜ AI ì—ì´ì „íŠ¸ëŠ” íƒœì–‘ê´‘ ë°œì „ì†Œ ê°œë°œì— í•„ìš”í•œ ì¤‘ìš”í•œ ì •ë³´ë¥¼ ì°¾ê³  ì´í•´í•˜ëŠ” ë° ë„ì›€ì„ ì¤ë‹ˆë‹¤. ì½œë¦¬ì–´ìŠ¤ ì—”ì§€ë‹ˆì–´ë§ & ë””ìì¸, ìŠ¤íƒ ë‹¤ë“œ ì†”ë¼ì™€ ê°™ì€ ì£¼ìš” ê¸°ì—…ë“¤ì´ ìŠ¤íŒŒí¬ì˜ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ê³  ìˆìœ¼ë©°, ì´ë¥¼ í†µí•´ ìˆ˜ë°±ë§Œ ê°€êµ¬ì— ì „ë ¥ì„ ê³µê¸‰í•  ìˆ˜ ìˆëŠ” ì—ë„ˆì§€ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nìŠ¤íŒŒí¬ íŒ€ì€ í…ŒìŠ¬ë¼ì™€ êµ¬ê¸€ê³¼ ê°™ì€ ìœ ëª… ê¸°ì—…ì—ì„œ ê²½ë ¥ì„ ìŒ“ì€ ì „ë¬¸ê°€ë“¤ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì´ë“¤ì€ ìƒŒí”„ë€ì‹œìŠ¤ì½”ì— ë³¸ì‚¬ë¥¼ ë‘ê³  ìˆìœ¼ë©°, ì£¼ 5ì¼ ëŒ€ë©´ìœ¼ë¡œ ê·¼ë¬´í•˜ë©° Typescriptì™€ NodeJSì™€ ê°™ì€ ê¸°ìˆ ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n\nì£¼ìš” ì±…ì„ìœ¼ë¡œëŠ” ëŒ€ëŸ‰ì˜ ë°ì´í„° ì„¸íŠ¸ë¥¼ ë¶„ì„í•˜ëŠ” í•µì‹¬ APIì™€ AI ì‹œìŠ¤í…œì„ ê°œë°œí•˜ê³ , ì´ˆê¸° ì•„ì´ë””ì–´ì—ì„œ ê³ ê° í”¼ë“œë°±ê¹Œì§€ ê¸°ëŠ¥ì„ ê´€ë¦¬í•˜ë©°, ì°½ë¦½ìë“¤ê³¼ í˜‘ë ¥í•˜ì—¬ ì œí’ˆì„ í˜•ì„±í•˜ëŠ” ì¼ì´ í¬í•¨ë©ë‹ˆë‹¤.\n\nì´ìƒì ì¸ í›„ë³´ìëŠ” 3ë…„ ì´ìƒì˜ ê²½ë ¥ì„ ê°€ì§€ê³  ìˆìœ¼ë©°, ì˜í–¥ë ¥ì„ ì¤‘ì‹œí•˜ëŠ” ì½”ë”©ì— ì—´ì •ì„ ê°€ì§„ ì‚¬ëŒì…ë‹ˆë‹¤. ë¬¸ì œ í•´ê²°ì— ì ê·¹ì ì´ë©° ë¹„ì¦ˆë‹ˆìŠ¤ ì¸¡ë©´ì—ë„ ê´€ì‹¬ì´ ìˆëŠ” ì‚¬ëŒì„ ì°¾ê³  ìˆìŠµë‹ˆë‹¤. ë˜í•œ, ìì‹ ì˜ íšŒì‚¬ë¥¼ ì‹œì‘í•˜ê³ ì í•˜ëŠ” ì—´ë§ì´ ìˆëŠ” ì§€ì›ìë¥¼ ì›í•©ë‹ˆë‹¤.\n\nì í•©í•˜ì§€ ì•Šì€ í›„ë³´ìëŠ” ì™„ë²½í•œ ì½”ë“œë¥¼ ì†ë„ë³´ë‹¤ ìš°ì„ ì‹œí•˜ëŠ” ì‚¬ëŒì´ë‚˜ ê¸°ìˆ ì  ê²°ì •ê³¼ ë¹„ì¦ˆë‹ˆìŠ¤ ê²°ì •ì˜ êµì°¨ì ì— ê´€ì‹¬ì´ ì—†ëŠ” ì‚¬ëŒì…ë‹ˆë‹¤.",
      "ja": "Sparkã¯ã€ã‚¨ãƒãƒ«ã‚®ãƒ¼é–‹ç™ºè€…ãŒå¤ªé™½å…‰ç™ºé›»æ‰€ã‚„ãƒãƒƒãƒ†ãƒªãƒ¼å·¥å ´ã‚’å»ºè¨­ã™ã‚‹éš›ã«ã€åœ°åŸŸã®è¦åˆ¶ã‚’ç°¡å˜ã«ç†è§£ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹AIç ”ç©¶ãƒ„ãƒ¼ãƒ«ã‚’é–‹ç™ºã—ã¦ã„ã¾ã™ã€‚å½¼ã‚‰ã®AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯ã€å¤ªé™½å…‰ç™ºé›»æ‰€ã®é–‹ç™ºã«å¿…è¦ãªé‡è¦ãªæƒ…å ±ã‚’è¦‹ã¤ã‘ã€ç†è§£ã™ã‚‹æ‰‹åŠ©ã‘ã‚’ã—ã¾ã™ã€‚Colliers Engineering & Designã‚„Standard Solarã¨ã„ã£ãŸå¤§æ‰‹ä¼æ¥­ã‚‚Sparkã®ãƒ„ãƒ¼ãƒ«ã‚’åˆ©ç”¨ã—ã¦ãŠã‚Šã€ã“ã‚Œã«ã‚ˆã‚Šæ•°ç™¾ä¸‡ã®å®¶åº­ã«é›»åŠ›ã‚’ä¾›çµ¦ã§ãã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\n\nSparkã®ãƒãƒ¼ãƒ ã¯ã€Teslaã‚„Googleãªã©ã®å¤§æ‰‹ä¼æ¥­ã§ã®çµŒé¨“ã‚’æŒã¤å°‚é–€å®¶ã§æ§‹æˆã•ã‚Œã¦ã„ã¾ã™ã€‚ã‚µãƒ³ãƒ•ãƒ©ãƒ³ã‚·ã‚¹ã‚³ã«æ‹ ç‚¹ã‚’ç½®ãã€é€±5æ—¥å¯¾é¢ã§åƒã„ã¦ãŠã‚Šã€Typescriptã‚„NodeJSã¨ã„ã£ãŸæŠ€è¡“ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚\n\nä¸»ãªæ¥­å‹™å†…å®¹ã«ã¯ã€å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’åˆ†æã™ã‚‹ãŸã‚ã®ã‚³ã‚¢APIã‚„AIã‚·ã‚¹ãƒ†ãƒ ã®é–‹ç™ºã€åˆæœŸã‚¢ã‚¤ãƒ‡ã‚¢ã‹ã‚‰é¡§å®¢ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã¾ã§ã®æ©Ÿèƒ½ç®¡ç†ã€å‰µæ¥­è€…ã¨å”åŠ›ã—ã¦è£½å“ã‚’å½¢ä½œã‚‹ã“ã¨ãŒå«ã¾ã‚Œã¾ã™ã€‚\n\nç†æƒ³çš„ãªå€™è£œè€…ã¯ã€3å¹´ä»¥ä¸Šã®çµŒé¨“ãŒã‚ã‚Šã€å½±éŸ¿ã‚’ä¸ãˆã‚‹ã“ã¨ã«æƒ…ç†±ã‚’æŒã£ã¦ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã«å–ã‚Šçµ„ã‚€äººã§ã™ã€‚å•é¡Œè§£æ±ºã«ç©æ¥µçš„ã§ã€ãƒ“ã‚¸ãƒã‚¹é¢ã«ã‚‚èˆˆå‘³ã‚’æŒã£ã¦ã„ã‚‹ã“ã¨ãŒæ±‚ã‚ã‚‰ã‚Œã¾ã™ã€‚ã¾ãŸã€è‡ªåˆ†è‡ªèº«ã®ä¼šç¤¾ã‚’ç«‹ã¡ä¸Šã’ãŸã„ã¨è€ƒãˆã¦ã„ã‚‹äººãŒæœ›ã¾ã—ã„ã§ã™ã€‚\n\nã‚‚ã—ã€å®Œç’§ãªã‚³ãƒ¼ãƒ‰ã‚’å„ªå…ˆã—ã™ãã‚‹äººã‚„ã€æŠ€è¡“çš„ãªæ±ºå®šã¨ãƒ“ã‚¸ãƒã‚¹çš„ãªæ±ºå®šã®äº¤å·®ç‚¹ã«èˆˆå‘³ãŒãªã„äººã¯ã€é©ã—ã¦ã„ã¾ã›ã‚“ã€‚"
    }
  },
  {
    "id": "023e535f3c45aaf4",
    "title": {
      "en": "Breaking up with vibe coding",
      "ko": "ë°”ì´ë¸Œ ì½”ë”© íƒˆì¶œ",
      "ja": "ãƒã‚¤ãƒ–ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å’æ¥­"
    },
    "type": "story",
    "url": "https://www.lucasaguiar.xyz/posts/vibe-coding-pitfalls/",
    "score": 37,
    "by": "isfttr",
    "time": 1743293832,
    "content": "BlogWhy I'm Breaking Up With Vibe CodingBy Lucas Fernandes AguiarMarch 20, 2025Weâ€™ve all been there: headphones on, music pumping, fingers flying across the keyboard, lost in the â€œflowâ€ with your favorite AI agent. This, my friends, is vibe coding. Itâ€™s when youâ€™re in the zone, seemingly effortlessly producing code.Itâ€™s the idea that you can create great software simply by immersing yourself in the feeling of coding, trusting your intuition and riding the wave of inspiration. But lately, Iâ€™ve realized that for me, at least, the vibe isâ€¦off. Itâ€™s like Iâ€™m watching an AI agent code for me, occasionally chiming in with a suggestion or a correction, but often just observing the code unfold without fully grasping the intricacies of whatâ€™s happening can lead to wasting my time later.What is Vibe Coding Anyway?Vibe coding is less a methodology and more a state of mind. Itâ€™s about prioritizing the use of an AI agent over really thinking through the code implementation with structured planning and rigorous testing. Itâ€™s about chasing that dopamine hit of making progress, often without a clear roadmap. Itâ€™s seductive because it feels productive.Why the Vibe is Failing MeFor the last two months, Iâ€™ve been relying heavily on vibe coding, and the results havenâ€™t been pretty. Hereâ€™s why:First, I was initially drawn to AI agents like Cline, Roo Code, and then tried the Cursor editor because they promised to enhance my coding flow. I loved the idea of having an AI partner that could anticipate my needs and help me write code faster. However, I quickly realized that this approach was leading me astray.What I realized is that using the AI agent is fine for creating a mockup of what you want, but after that, the context windows and everything leads to more and more rework over time. This happens because in your frustration, the first thing that comes to mind is just explain to the model again, without even knowing what has been implemented in the first place. This is understandable since in a matter of minute, the agent could have written a thousand lines of code and, obviously, this is kind of insane.The greatest problems that I see in vibe coding are:It can be a huge time sink: in the beginning you seem to getting places, but since you have no structure, you are being led by what is appearing in the screen, and you become consumed by the next error or working feature that appears on the screen.It is expensive: this is a consequence of the first problem. As context windows grow, the requests get more expensive, and rapidly you can see numbers like 500k tokens sent, and a fraction of that received.In the end, it doesnâ€™t seem to be a huge timesaver for many tasks, if you begin a project with no structure, that is. The time you â€œsaveâ€ in the beginning, youâ€™ll have to use it later to rewrite the code to do what you intended in the first place.Flip side: an enthusiastâ€™s viewBut there are also many benefits, since I can at least understand more about the code with time. Beginning this journey, it was clear to me that it would take time and money for me to create worthwhile project. Something that initially can seem unreachable, after reading the code multiple times trying to understand errors, I have begun understand the structure and syntax of the language. In my case, I am focusing my efforts in learning Python, so most of the code that I am creating is in Python. With time I can understand better what is the error and can nudge the model towards the solution.Vibe Coding vs. AI Chat vs. Web SearchVibe Coding: Great for initial exploration and getting a feel for a problem, but terrible for structured development and complex projects.\nAI Chat (ChatGPT, etc.): Useful for generating boilerplate code and getting quick answers, but can lead to reliance on AI-generated solutions without fully understanding them. Requires careful verification and can suffer from â€œAI hallucinationsâ€.\nWeb Search (Google, etc.): Essential for finding specific solutions and understanding concepts, but can be overwhelming and time-consuming if you donâ€™t know what youâ€™re looking for.The balance seems to be on using tab completion inside the editor and using something like Gemini Code Assist. I am using the Gemini Code Assistant because it is free, but I am really liking it. I am using it in VS Code and recommend it. It is really good in creating unit tests, and while running tests it is fairly good in resolving the failures. As it is the first time that I am creating unit tests for my code, it is a bit confusing for me to understand what is going on, but with the assistance of Gemini it seems reachable.Another thing that I tried, but am leaning to the side of ditching it is using an agent like Roo Code or Cline. They can go on for a long time and consume loads of tokens with not guarantee of working in the end. So the problem becomes how to make this cheaper with time. GosuCoder is someone that I see testing various strategies on how to keep costs down, but the main bottleneck is the use of Claude. While it seems to be the only one with full support for everything, it is one of the most expensive models to run, and with the tendency to use tons of tokens, the costs becomes prohibitive for most people. If not for this, Gemini 2.0 and DeepSeek V3/Chat seem really good for most uses in coding (at least for me).Another strategy have been using Open WebUI, which I have been liking a lot. It has a ton of features and options, which gives a lot of control. What I like is to use custom models for different use cases of mine (coding, patents, phd, etc.). It is mostly inexpensive and when using Gemini it gives a really good context window to edit large files. What it seems to be really good use case is pasting text and rearranging it, removing spaces, displaying in tables, and things like that. The ability to do the custom prompts also gives the possibility to save money on tokens.Conclusion: Finding a Better BalanceIâ€™m not saying vibe coding is always bad. Thereâ€™s definitely value in letting your creativity flow and exploring ideas without rigid constraints. However, Iâ€™ve learned that itâ€™s not a sustainable approach for me, especially when deadlines loom and API costs mount. For me, Gemini Code Assist seem to be a great alternative, because it is free and has a great context window. Also, Open WebUI is great because of the control and customizability, and the costs are relatively low for everyday tasks.For me, this seems to be the best balance for now, but I am leaning to eventually pay for a chat app, like Perplexity (which has a good free tier and costs 20 dollars per month), since I am paying around 30 dollars/month for the last 2 months in API usage. In the future, maybe it will make sense to have a model running locally, but I think the costs for API usage will be lower as more efficient models are launched.You can reach out to contact me about this and other topics at my email lucas.fernandes.df@gmail.com or by filling the form below.\nSendform{display:block;grid-gap:10rem;text-align:center;padding:2rem 0;margin:0}form label{display:contents}form input[type=email],form textarea{width:100%}form button{font-family:inherit;font-size:inherit;border:1px solid;background:0 0;padding:.5rem;border-radius:10px}form textarea{resize:vertical}form button{justify-self:center;border-radius:10px}Related PostsThe AI Copy-Paste Problem: Killing Software Lock-In & Why Data Portability is KeyObsidian + Copilotartificial-intelligencecursorvibe codingclaude.bmc-btn svg {\n    height: 32px !important;\n    margin-bottom: 0px !important;\n    box-shadow: none !important;\n    border: none !important;\n    vertical-align: middle !important;\n    transform: scale(0.9);\n    flex-shrink: 0;\n}\n\n.bmc-btn {\n    min-width: 210px;\n    color: #000000;\n    background-color: #FFDD00 !important;\n    height: 60px;\n    border-radius: 12px;\n    font-size: 28px;\n    font-weight: Normal;\n    border: none;\n    padding: 0px 24px;\n    line-height: 27px;\n    text-decoration: none !important;\n    display: inline-flex !important;\n    align-items: center;\n    font-family: 'Cookie', cursive !important;\n    -webkit-box-sizing: border-box !important;\n    box-sizing: border-box !important;\n}\n\n.bmc-btn:hover, .bmc-btn:active, .bmc-btn:focus {\n    text-decoration: none !important;\n    cursor: pointer;\n}\n\n.bmc-btn-text {\n   text-align: left;\n   margin-left: 8px;\n   display: inline-block;\n   line-height: 0;\n   width: 100%;\n   flex-shrink: 0;\n   font-family: [FONT] !important;\n}\n\n.logo-outline {\n    fill: #000000;\n}\n\n.logo-coffee {\n    fill: #ffffff;\n}\n\nBuy me a coffee\nShare on\nFacebookTweetSubmit to RedditShare on LinkedInSend emailul.share-buttons{list-style:none;padding:0}ul.share-buttons li{display:inline}ul.share-buttons .sr-only{position:absolute;clip:rect(1px 1px 1px 1px);clip:rect(1px,1px,1px,1px);padding:0;border:0;height:1px;width:1px;overflow:hidden}(function(e,t,n){var s,o=e.getElementsByTagName(t)[0];if(e.getElementById(n))return;s=e.createElement(t),s.id=n,s.src=\"https://connect.facebook.net/en_US/sdk.js#xfbml=1&amp;version=v3.0\",o.parentNode.insertBefore(s,o)})(document,\"script\",\"facebook-jssdk\")lang:en_US\ndocument.getElementById(\"copy-link\").addEventListener(\"click\",function(){navigator.clipboard.writeText(window.location.href).then(function(){console.log(\"Link copied to clipboard!\")}).catch(function(e){console.error(\"Could not copy link: \",e)})})\nSendform{display:block;grid-gap:10rem;text-align:center;padding:2rem 0;margin:0}form label{display:contents}form input[type=email],form textarea{width:100%}form button{font-family:inherit;font-size:inherit;border:1px solid;background:0 0;padding:.5rem;border-radius:10px}form textarea{resize:vertical}form button{justify-self:center;border-radius:10px}",
    "summary": {
      "en": "In the blog post \"Why I'm Breaking Up With Vibe Coding,\" Lucas Fernandes Aguiar discusses his experience with \"vibe coding,\" which is the practice of coding while in a creative flow, often with the help of AI tools. Initially, he enjoyed vibe coding because it felt productive, but he later found that it led to confusion and inefficiencies in his coding process.\n\nKey points include:\n\n1. **Definition of Vibe Coding**: It's more about the mindset of coding with AI assistance rather than following structured planning and testing. It can feel productive but lacks clear direction.\n\n2. **Challenges Faced**: After two months of relying on vibe coding, Aguiar experienced significant issues:\n   - It became a time sink as he was distracted by on-screen errors and features.\n   - It turned out to be costly, as using AI tools generated a lot of code that required extensive rework later.\n\n3. **Comparison with Other Tools**: \n   - **AI Chat**: Helpful for quick answers and boilerplate code but can lead to dependency without understanding.\n   - **Web Search**: Useful for specific solutions but can be overwhelming.\n   - He found that tools like Gemini Code Assist and Open WebUI offered better balance, providing assistance without excessive costs.\n\n4. **Conclusion**: While vibe coding has its merits, especially for creativity, it's not sustainable for structured projects. Aguiar suggests using tools that offer better cost control and coding assistance, highlighting the importance of finding a balance between creativity and structured development.",
      "ko": "ë£¨ì¹´ìŠ¤ í˜ë¥´ë‚œë°ìŠ¤ ì•„ê¸°ì•„ë¥´ê°€ \"ì™œ ë‚˜ëŠ” ë°”ì´ë¸Œ ì½”ë”©ê³¼ ì´ë³„í•˜ëŠ”ê°€\"ë¼ëŠ” ë¸”ë¡œê·¸ ê¸€ì—ì„œ ìì‹ ì˜ ë°”ì´ë¸Œ ì½”ë”© ê²½í—˜ì— ëŒ€í•´ ì´ì•¼ê¸°í•©ë‹ˆë‹¤. ë°”ì´ë¸Œ ì½”ë”©ì€ ì°½ì˜ì ì¸ íë¦„ ì†ì—ì„œ ì½”ë”©í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ, ì¢…ì¢… AI ë„êµ¬ì˜ ë„ì›€ì„ ë°›ìŠµë‹ˆë‹¤. ì²˜ìŒì—ëŠ” ìƒì‚°ì ì¸ ëŠë‚Œì´ ë“¤ì–´ ì¦ê²¼ì§€ë§Œ, ë‚˜ì¤‘ì—ëŠ” í˜¼ë€ê³¼ ë¹„íš¨ìœ¨ì„±ì„ ì´ˆë˜í•œë‹¤ëŠ” ê²ƒì„ ì•Œê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.\n\në°”ì´ë¸Œ ì½”ë”©ì˜ ì •ì˜ëŠ” AIì˜ ë„ì›€ì„ ë°›ì•„ ì½”ë”©í•˜ëŠ” ë§ˆìŒê°€ì§ì— ë” ê°€ê¹ìŠµë‹ˆë‹¤. êµ¬ì¡°ì ì¸ ê³„íšì´ë‚˜ í…ŒìŠ¤íŠ¸ë¥¼ ë”°ë¥´ê¸°ë³´ë‹¤ëŠ” ì°½ì˜ì ì¸ íë¦„ì„ ì¤‘ì‹œí•©ë‹ˆë‹¤. ìƒì‚°ì ì¸ ëŠë‚Œì´ ë“¤ ìˆ˜ ìˆì§€ë§Œ, ëª…í™•í•œ ë°©í–¥ì„±ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.\n\në‘ ë‹¬ ë™ì•ˆ ë°”ì´ë¸Œ ì½”ë”©ì— ì˜ì¡´í•œ ê²°ê³¼, ì•„ê¸°ì•„ë¥´ëŠ” ì—¬ëŸ¬ ê°€ì§€ ë¬¸ì œë¥¼ ê²½í—˜í–ˆìŠµë‹ˆë‹¤. í™”ë©´ì˜ ì˜¤ë¥˜ì™€ ê¸°ëŠ¥ì— ë°©í•´ë°›ì•„ ì‹œê°„ì´ ë‚­ë¹„ë˜ì—ˆê³ , AI ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ë©´ì„œ ìƒì„±ëœ ì½”ë“œê°€ ë§ì•„ ë‚˜ì¤‘ì— ë§ì€ ìˆ˜ì •ì´ í•„ìš”í•´ ë¹„ìš©ì´ ë§ì´ ë“¤ì—ˆìŠµë‹ˆë‹¤.\n\në‹¤ë¥¸ ë„êµ¬ì™€ì˜ ë¹„êµë„ ìˆì—ˆìŠµë‹ˆë‹¤. AI ì±„íŒ…ì€ ë¹ ë¥¸ ë‹µë³€ê³¼ ê¸°ë³¸ ì½”ë“œ ì‘ì„±ì— ìœ ìš©í•˜ì§€ë§Œ, ì´í•´ ì—†ì´ ì˜ì¡´í•˜ê²Œ ë  ìœ„í—˜ì´ ìˆìŠµë‹ˆë‹¤. ì›¹ ê²€ìƒ‰ì€ íŠ¹ì • ì†”ë£¨ì…˜ì„ ì°¾ëŠ” ë° ìœ ìš©í•˜ì§€ë§Œ, ì •ë³´ê°€ ë„ˆë¬´ ë§ì•„ ì••ë„ë‹¹í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì•„ê¸°ì•„ë¥´ëŠ” ì œë¯¸ë‹ˆ ì½”ë“œ ì–´ì‹œìŠ¤íŠ¸ì™€ ì˜¤í”ˆ ì›¹ UIì™€ ê°™ì€ ë„êµ¬ë“¤ì´ ë” ë‚˜ì€ ê· í˜•ì„ ì œê³µí•˜ë©°, ê³¼ë„í•œ ë¹„ìš© ì—†ì´ ë„ì›€ì„ ì¤„ ìˆ˜ ìˆë‹¤ê³  ëŠê¼ˆìŠµë‹ˆë‹¤.\n\në°”ì´ë¸Œ ì½”ë”©ì€ ì°½ì˜ì„±ì—ëŠ” ì¥ì ì´ ìˆì§€ë§Œ, êµ¬ì¡°ì ì¸ í”„ë¡œì íŠ¸ì—ëŠ” ì§€ì† ê°€ëŠ¥í•˜ì§€ ì•Šë‹¤ê³  ê²°ë¡ ì§€ì—ˆìŠµë‹ˆë‹¤. ì•„ê¸°ì•„ë¥´ëŠ” ë¹„ìš© í†µì œê°€ ë” ì˜ ë˜ê³  ì½”ë”© ì§€ì›ì„ ì œê³µí•˜ëŠ” ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë‹¤ê³  ê°•ì¡°í•˜ë©°, ì°½ì˜ì„±ê³¼ êµ¬ì¡°ì  ê°œë°œ ì‚¬ì´ì˜ ê· í˜•ì„ ì°¾ëŠ” ê²ƒì´ í•„ìš”í•˜ë‹¤ê³  ì œì•ˆí•©ë‹ˆë‹¤.",
      "ja": "ãƒ–ãƒ­ã‚°è¨˜äº‹ã€Œãªãœç§ã¯ãƒã‚¤ãƒ–ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’ã‚„ã‚ã‚‹ã®ã‹ã€ã§ã€ãƒ«ãƒ¼ã‚«ã‚¹ãƒ»ãƒ•ã‚§ãƒ«ãƒŠãƒ³ãƒ‡ã‚¹ãƒ»ã‚¢ã‚®ã‚¢ãƒ¼ãƒ«ã¯ã€Œãƒã‚¤ãƒ–ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã€ã®ä½“é¨“ã«ã¤ã„ã¦èªã£ã¦ã„ã¾ã™ã€‚ãƒã‚¤ãƒ–ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã¨ã¯ã€ã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–ãªæµã‚Œã®ä¸­ã§ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’è¡Œã„ã€AIãƒ„ãƒ¼ãƒ«ã‚’æ´»ç”¨ã™ã‚‹ã“ã¨ã‚’æŒ‡ã—ã¾ã™ã€‚æœ€åˆã¯ç”Ÿç”£çš„ã«æ„Ÿã˜ã¦æ¥½ã—ã‚“ã§ã„ã¾ã—ãŸãŒã€å¾Œã«æ··ä¹±ã‚„éåŠ¹ç‡ã‚’æ‹›ãã“ã¨ã«æ°—ã¥ãã¾ã—ãŸã€‚\n\nãƒã‚¤ãƒ–ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®å®šç¾©ã¯ã€AIã®åŠ©ã‘ã‚’å€Ÿã‚Šã¦ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã™ã‚‹å¿ƒæ§‹ãˆã«é‡ãã‚’ç½®ã„ã¦ãŠã‚Šã€æ§‹é€ çš„ãªè¨ˆç”»ã‚„ãƒ†ã‚¹ãƒˆã«å¾“ã†ã“ã¨ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚ç”Ÿç”£çš„ã«æ„Ÿã˜ã‚‹ã“ã¨ã‚‚ã‚ã‚Šã¾ã™ãŒã€æ˜ç¢ºãªæ–¹å‘æ€§ãŒæ¬ ã‘ã¦ã„ã¾ã™ã€‚\n\nã‚¢ã‚®ã‚¢ãƒ¼ãƒ«ã¯ã€ãƒã‚¤ãƒ–ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã«é ¼ã£ã¦2ãƒ¶æœˆå¾Œã«å¤§ããªå•é¡Œã«ç›´é¢ã—ã¾ã—ãŸã€‚ç”»é¢ä¸Šã®ã‚¨ãƒ©ãƒ¼ã‚„æ©Ÿèƒ½ã«æ°—ã‚’å–ã‚‰ã‚Œã€æ™‚é–“ã‚’ç„¡é§„ã«ã™ã‚‹ã“ã¨ãŒå¤šããªã‚Šã¾ã—ãŸã€‚ã¾ãŸã€AIãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã†ã“ã¨ã§ç”Ÿæˆã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ãŒå¤šãã€å¾Œã§å¤§å¹…ãªæ‰‹ç›´ã—ãŒå¿…è¦ã«ãªã‚Šã€ã‚³ã‚¹ãƒˆã‚‚ã‹ã•ã¿ã¾ã—ãŸã€‚\n\nä»–ã®ãƒ„ãƒ¼ãƒ«ã¨ã®æ¯”è¼ƒã§ã¯ã€AIãƒãƒ£ãƒƒãƒˆã¯è¿…é€Ÿãªå›ç­”ã‚„å®šå‹ã‚³ãƒ¼ãƒ‰ã«ã¯å½¹ç«‹ã¡ã¾ã™ãŒã€ç†è§£ã›ãšã«ä¾å­˜ã™ã‚‹å±é™ºãŒã‚ã‚Šã¾ã™ã€‚ã‚¦ã‚§ãƒ–æ¤œç´¢ã¯ç‰¹å®šã®è§£æ±ºç­–ã«ã¯ä¾¿åˆ©ã§ã™ãŒã€æƒ…å ±ãŒå¤šã™ãã¦åœ§å€’ã•ã‚Œã‚‹ã“ã¨ã‚‚ã‚ã‚Šã¾ã™ã€‚ã‚¢ã‚®ã‚¢ãƒ¼ãƒ«ã¯ã€ã‚¸ã‚§ãƒŸãƒ‹ã‚³ãƒ¼ãƒ‰ã‚¢ã‚·ã‚¹ãƒˆã‚„ã‚ªãƒ¼ãƒ—ãƒ³ã‚¦ã‚§ãƒ–UIã®ã‚ˆã†ãªãƒ„ãƒ¼ãƒ«ãŒã€éå‰°ãªã‚³ã‚¹ãƒˆã‚’ã‹ã‘ãšã«æ”¯æ´ã‚’æä¾›ã™ã‚‹ãŸã‚ã€ã‚ˆã‚Šè‰¯ã„ãƒãƒ©ãƒ³ã‚¹ã‚’ã‚‚ãŸã‚‰ã™ã¨æ„Ÿã˜ã¾ã—ãŸã€‚\n\nãƒã‚¤ãƒ–ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã«ã¯å‰µé€ æ€§ã‚’å¼•ãå‡ºã™åˆ©ç‚¹ãŒã‚ã‚Šã¾ã™ãŒã€æ§‹é€ çš„ãªãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«ã¯æŒç¶šå¯èƒ½ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚ã‚¢ã‚®ã‚¢ãƒ¼ãƒ«ã¯ã€ã‚³ã‚¹ãƒˆç®¡ç†ã¨ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ”¯æ´ã‚’ã‚ˆã‚Šè‰¯ãæä¾›ã™ã‚‹ãƒ„ãƒ¼ãƒ«ã®ä½¿ç”¨ã‚’ææ¡ˆã—ã€å‰µé€ æ€§ã¨æ§‹é€ çš„é–‹ç™ºã®ãƒãƒ©ãƒ³ã‚¹ã‚’è¦‹ã¤ã‘ã‚‹é‡è¦æ€§ã‚’å¼·èª¿ã—ã¦ã„ã¾ã™ã€‚"
    }
  },
  {
    "id": "7c7620eb4213ad13",
    "title": {
      "en": "Matrix Calculus (For Machine Learning and Beyond)",
      "ko": "í–‰ë ¬ ë¯¸ì ë¶„ì˜ ëª¨ë“  ê²ƒ",
      "ja": "è¡Œåˆ—å¾®ç©åˆ†ã®æ–°å¸¸è­˜"
    },
    "type": "story",
    "url": "https://arxiv.org/abs/2501.14787",
    "score": 75,
    "by": "ibobev",
    "time": 1743278433,
    "content": "This course, intended for undergraduates familiar with elementary calculus and linear algebra, introduces the extension of differential calculus to functions on more general vector spaces, such as functions that take as input a matrix and return a matrix inverse or factorization, derivatives of ODE solutions, and even stochastic derivatives of random functions. It emphasizes practical computational applications, such as large-scale optimization and machine learning, where derivatives must be re-imagined in order to be propagated through complicated calculations. The class also discusses efficiency concerns leading to \"adjoint\" or \"reverse-mode\" differentiation (a.k.a. \"backpropagation\"), and gives a gentle introduction to modern automatic differentiation (AD) techniques.",
    "summary": {
      "en": "This course is designed for undergraduate students who know basic calculus and linear algebra. It teaches how to apply differential calculus to more complex functions, like those involving matrices and their inverses, solutions to ordinary differential equations (ODEs), and random functions. The focus is on practical uses, particularly in large-scale optimization and machine learning, where derivatives need to be adapted for complex calculations. The course also covers efficient methods like \"reverse-mode\" differentiation (also known as backpropagation) and introduces modern techniques for automatic differentiation.",
      "ko": "ì´ ê³¼ì •ì€ ê¸°ë³¸ ë¯¸ì ë¶„í•™ê³¼ ì„ í˜•ëŒ€ìˆ˜ë¥¼ ì•„ëŠ” í•™ë¶€ í•™ìƒë“¤ì„ ìœ„í•´ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. ë¯¸ë¶„ ê³„ì‚°ì„ í–‰ë ¬ê³¼ ê·¸ ì—­í–‰ë ¬, ì¼ë°˜ ë¯¸ë¶„ ë°©ì •ì‹(ODE)ì˜ í•´, ê·¸ë¦¬ê³  ëœë¤ í•¨ìˆ˜ì™€ ê°™ì€ ë” ë³µì¡í•œ í•¨ìˆ˜ì— ì ìš©í•˜ëŠ” ë°©ë²•ì„ ê°€ë¥´ì¹©ë‹ˆë‹¤. ì´ ê³¼ì •ì€ íŠ¹íˆ ëŒ€ê·œëª¨ ìµœì í™”ì™€ ë¨¸ì‹ ëŸ¬ë‹ì—ì„œì˜ ì‹¤ìš©ì ì¸ ì‚¬ìš©ì— ì¤‘ì ì„ ë‘ê³  ìˆìœ¼ë©°, ë³µì¡í•œ ê³„ì‚°ì„ ìœ„í•´ ë„í•¨ìˆ˜ë¥¼ ì¡°ì •í•˜ëŠ” ë°©ë²•ì„ ë‹¤ë£¹ë‹ˆë‹¤. ë˜í•œ \"ì—­ì „íŒŒ\"ë¡œ ì•Œë ¤ì§„ ì—­ëª¨ë“œ ë¯¸ë¶„ê³¼ ìë™ ë¯¸ë¶„ì„ ìœ„í•œ í˜„ëŒ€ì ì¸ ê¸°ë²•ë„ ì†Œê°œí•©ë‹ˆë‹¤.",
      "ja": "ã“ã®ã‚³ãƒ¼ã‚¹ã¯ã€åŸºæœ¬çš„ãªå¾®ç©åˆ†ã¨ç·šå½¢ä»£æ•°ã‚’ç†è§£ã—ã¦ã„ã‚‹å­¦éƒ¨ç”Ÿã‚’å¯¾è±¡ã¨ã—ã¦ã„ã¾ã™ã€‚å¾®åˆ†è¨ˆç®—ã‚’ã€è¡Œåˆ—ã‚„ãã®é€†è¡Œåˆ—ã‚’å«ã‚€è¤‡é›‘ãªé–¢æ•°ã€å¸¸å¾®åˆ†æ–¹ç¨‹å¼ï¼ˆODEï¼‰ã®è§£ã€ãƒ©ãƒ³ãƒ€ãƒ é–¢æ•°ãªã©ã«é©ç”¨ã™ã‚‹æ–¹æ³•ã‚’å­¦ã³ã¾ã™ã€‚ç‰¹ã«ã€å¤§è¦æ¨¡ãªæœ€é©åŒ–ã‚„æ©Ÿæ¢°å­¦ç¿’ã«ãŠã‘ã‚‹å®Ÿç”¨çš„ãªåˆ©ç”¨ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ãŠã‚Šã€è¤‡é›‘ãªè¨ˆç®—ã®ãŸã‚ã«å°é–¢æ•°ã‚’é©å¿œã•ã›ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ã¾ãŸã€ã€Œé€†ãƒ¢ãƒ¼ãƒ‰ã€å¾®åˆ†ï¼ˆãƒãƒƒã‚¯ãƒ—ãƒ­ãƒ‘ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ã¨ã‚‚å‘¼ã°ã‚Œã‚‹ï¼‰ãªã©ã®åŠ¹ç‡çš„ãªæ‰‹æ³•ã‚„ã€è‡ªå‹•å¾®åˆ†ã®ç¾ä»£çš„ãªæŠ€è¡“ã‚‚ç´¹ä»‹ã—ã¾ã™ã€‚"
    }
  },
  {
    "id": "94bc8940d3eca6bf",
    "title": {
      "en": "Lvgl: Embedded graphics library to create beautiful UIs",
      "ko": "Lvgl: ì•„ë¦„ë‹¤ìš´ UIì˜ ë¹„ë°€",
      "ja": "ç¾ã—ã„UIã‚’ä½œã‚‹Lvgl"
    },
    "type": "story",
    "url": "https://github.com/lvgl/lvgl",
    "score": 77,
    "by": "tosh",
    "time": 1743273763,
    "content": "English | ä¸­æ–‡ | PortuguÃªs do Brasil | æ—¥æœ¬èª\n\n Light and Versatile Graphics Library\n\nWebsite  |\nDocs |\nForum |\nDemos |\nServices\n\nğŸ“’ Overview\nMature and Well-known\nLVGL is the most popular free and open source embedded graphics library to create beautiful UIs for any MCU, MPU and display type. It's supported by industry leading vendors and projects like Arm, STM32, NXP, Espressif, Nuvoton, Arduino, RT-Thread, Zephyr, NuttX, Adafruit and many more.\nFeature Rich\nIt has all the features to create modern and beautiful GUIs: 30+ built-in widgets, a powerful style system, web inspired layout managers, and a typography system supporting many languages. To integrate LVGL into your platform, all you need is at least 32kB RAM and 128 kB Flash, a C compiler, a frame buffer, and at least an 1/10 screen sized buffer for rendering.\nServices\nOur team is ready to help you with graphics design, UI implementation and consulting services. Contact us if you need some support during the development of your next GUI project.\nğŸš€ Features\nFree and Portable\n\nA fully portable C (C++ compatible) library with no external dependencies.\nCan be compiled to any MCU or MPU, with any (RT)OS.\nSupports monochrome, ePaper, OLED or TFT displays, or even monitors. Displays\nDistributed under the MIT license, so you can easily use it in commercial projects too.\nNeeds only 32kB RAM and 128 kB Flash, a frame buffer, and at least an 1/10 screen sized buffer for rendering.\nOS, External memory and GPU are supported but not required.\n\nWidgets, Styles, Layouts and more\n\n30+ built-in Widgets: Button, Label, Slider, Chart, Keyboard, Meter, Arc, Table and many more.\nFlexible Style system with ~100 style properties to customize any part of the widgets in any state.\nFlexbox and Grid-like layouts engines to automatically size and position the widgets in a responsive way.\nTexts are rendered with UTF-8 encoding supporting CJK, Thai, Hindi, Arabic, Persian writing systems.\nWord wrapping, kerning, text scrolling, sub-pixel rendering, Pinyin-IME Chinese input, Emojis in texts.\nRendering engine supporting animations, anti-aliasing, opacity, smooth scrolling, shadows, image transformation, etc\nSupports Mouse, Touchpad, Keypad, Keyboard, External buttons, Encoder Input devices.\nMultiple display support.\n\nBinding and Build Support\n\nMicroPython Binding exposes LVGL API\nPikaScript Binding python on MCU lighter and easier.\nNo custom build system is used. You can build LVGL as you build the other files of your project.\nSupport for Make and CMake is included out of the box.\nDevelop on PC and use the same UI code on embedded hardware.\nConvert the C UI code to HTML file with our Emscripten port.\n\nDocs, Tools, and Services\n\nDetailed Documentation with 100+ simple examples\nServices such as User interface design, Implementation and Consulting to make UI development simpler and faster.\n\nâ¤ï¸ Sponsor\nIf LVGL saved you a lot of time and money or you just had fun using it, consider Supporting its Development.\nHow do we spend the donations?\nOur goal is to provide financial compensation for people who do the most for LVGL. It means not only the maintainers but anyone who implements a great feature should get a payment from the accumulated money. We use the donations to cover our operational costs like servers and related services.\nHow to donate?\nWe use GitHub Sponsors where you can easily send one time or recurring donations. You can also see all of our expenses  in a transparent way.\nHow to get paid for your contribution?\nIf someone implements or fixes an issue labeled as Sponsored he or she will get a payment for that work. We estimate the required time, complexity and importance of the issue and set a price accordingly. To jump in just comment on a Sponsored issue saying \"Hi, I'd like to deal with it. This is how I'm planning to fix/implement it...\". A work is considered ready when it's approved and merged by a maintainer. After that you can submit and expense at opencollective.com and you will receive the payment in a few days.\nOrganizations supporting LVGL\n\nIndividuals supporting LVGL\n\nğŸ“¦ Packages\nLVGL is available as:\n\nArduino library\nPlatformIO package\nZephyr library\nESP-IDF(ESP32) component\nNXP MCUXpresso component\nNuttX library\nRT-Thread RTOS\nCMSIS-Pack\nRIOT OS package\n\nğŸ¤– Examples\nSee some examples of creating widgets, using layouts and applying styles. You will find C and MicroPython code, and links to try out or edit the examples in an online MicroPython editor.\nFor more examples check out the Examples folder.\nHello world label\n\n  C code\n/*Change the active screen's background color*/\nlv_obj_set_style_bg_color(lv_screen_active(), lv_color_hex(0x003a57), LV_PART_MAIN);\n\n/*Create a white label, set its text and align it to the center*/\nlv_obj_t * label = lv_label_create(lv_screen_active());\nlv_label_set_text(label, \"Hello world\");\nlv_obj_set_style_text_color(label, lv_color_hex(0xffffff), LV_PART_MAIN);\nlv_obj_align(label, LV_ALIGN_CENTER, 0, 0);\n\n  MicroPython code | Online Simulator\n# Change the active screen's background color\nscr = lv.screen_active()\nscr.set_style_bg_color(lv.color_hex(0x003a57), lv.PART.MAIN)\n\n# Create a white label, set its text and align it to the center\nlabel = lv.label(lv.screen_active())\nlabel.set_text(\"Hello world\")\nlabel.set_style_text_color(lv.color_hex(0xffffff), lv.PART.MAIN)\nlabel.align(lv.ALIGN.CENTER, 0, 0)\n\nButton with Click Event\n\n  C code\nlv_obj_t * button = lv_button_create(lv_screen_active());          /*Add a button to the current screen*/\nlv_obj_center(button);                           /*Set its position*/\nlv_obj_set_size(button, 100, 50);                 /*Set its size*/\nlv_obj_add_event_cb(button, button_event_cb, LV_EVENT_CLICKED, NULL); /*Assign a callback to the button*/\n\nlv_obj_t * label = lv_label_create(button);            /*Add a label to the button*/\nlv_label_set_text(label, \"Button\");               /*Set the labels text*/\nlv_obj_center(label);                      /*Align the label to the center*/\n...\n\nvoid button_event_cb(lv_event_t * e)\n{\n printf(\"Clicked\\n\");\n}\n\n  MicroPython code | Online Simulator\ndef button_event_cb(e):\n print(\"Clicked\")\n\n# Create a Button and a Label\nbutton = lv.button(lv.screen_active())\nbutton.center()\nbutton.set_size(100, 50)\nbutton.add_event_cb(button_event_cb, lv.EVENT.CLICKED, None)\n\nlabel = lv.label(button)\nlabel.set_text(\"Button\")\nlabel.center()\n\nCheckboxes with Layout\n\n  C code\nlv_obj_set_flex_flow(lv_screen_active(), LV_FLEX_FLOW_COLUMN);\nlv_obj_set_flex_align(lv_screen_active(), LV_FLEX_ALIGN_CENTER, LV_FLEX_ALIGN_START, LV_FLEX_ALIGN_CENTER);\n\nlv_obj_t * cb;\ncb = lv_checkbox_create(lv_screen_active());\nlv_checkbox_set_text(cb, \"Apple\");\nlv_obj_add_event_cb(cb, event_handler, LV_EVENT_ALL, NULL);\n\ncb = lv_checkbox_create(lv_screen_active());\nlv_checkbox_set_text(cb, \"Banana\");\nlv_obj_add_state(cb, LV_STATE_CHECKED);\nlv_obj_add_event_cb(cb, event_handler, LV_EVENT_ALL, NULL);\n\ncb = lv_checkbox_create(lv_screen_active());\nlv_checkbox_set_text(cb, \"Lemon\");\nlv_obj_add_state(cb, LV_STATE_DISABLED);\nlv_obj_add_event_cb(cb, event_handler, LV_EVENT_ALL, NULL);\n\ncb = lv_checkbox_create(lv_screen_active());\nlv_obj_add_state(cb, LV_STATE_CHECKED | LV_STATE_DISABLED);\nlv_checkbox_set_text(cb, \"Melon\\nand a new line\");\nlv_obj_add_event_cb(cb, event_handler, LV_EVENT_ALL, NULL);\n\n  MicroPython code | Online Simulator\ndef event_handler(e):\n    code = e.get_code()\n    obj = e.get_target_obj()\n    if code == lv.EVENT.VALUE_CHANGED:\n        txt = obj.get_text()\n        if obj.get_state() & lv.STATE.CHECKED:\n            state = \"Checked\"\n        else:\n            state = \"Unchecked\"\n        print(txt + \":\" + state)\n\nlv.screen_active().set_flex_flow(lv.FLEX_FLOW.COLUMN)\nlv.screen_active().set_flex_align(lv.FLEX_ALIGN.CENTER, lv.FLEX_ALIGN.START, lv.FLEX_ALIGN.CENTER)\n\ncb = lv.checkbox(lv.screen_active())\ncb.set_text(\"Apple\")\ncb.add_event_cb(event_handler, lv.EVENT.ALL, None)\n\ncb = lv.checkbox(lv.screen_active())\ncb.set_text(\"Banana\")\ncb.add_state(lv.STATE.CHECKED)\ncb.add_event_cb(event_handler, lv.EVENT.ALL, None)\n\ncb = lv.checkbox(lv.screen_active())\ncb.set_text(\"Lemon\")\ncb.add_state(lv.STATE.DISABLED)\ncb.add_event_cb(event_handler, lv.EVENT.ALL, None)\n\ncb = lv.checkbox(lv.screen_active())\ncb.add_state(lv.STATE.CHECKED | lv.STATE.DISABLED)\ncb.set_text(\"Melon\")\ncb.add_event_cb(event_handler, lv.EVENT.ALL, None)\n\nStyling a Slider\n\n  C code\nlv_obj_t * slider = lv_slider_create(lv_screen_active());\nlv_slider_set_value(slider, 70, LV_ANIM_OFF);\nlv_obj_set_size(slider, 300, 20);\nlv_obj_center(slider);\n\n/*Add local styles to MAIN part (background rectangle)*/\nlv_obj_set_style_bg_color(slider, lv_color_hex(0x0F1215), LV_PART_MAIN);\nlv_obj_set_style_bg_opa(slider, 255, LV_PART_MAIN);\nlv_obj_set_style_border_color(slider, lv_color_hex(0x333943), LV_PART_MAIN);\nlv_obj_set_style_border_width(slider, 5, LV_PART_MAIN);\nlv_obj_set_style_pad_all(slider, 5, LV_PART_MAIN);\n\n/*Create a reusable style sheet for the INDICATOR part*/\nstatic lv_style_t style_indicator;\nlv_style_init(&style_indicator);\nlv_style_set_bg_color(&style_indicator, lv_color_hex(0x37B9F5));\nlv_style_set_bg_grad_color(&style_indicator, lv_color_hex(0x1464F0));\nlv_style_set_bg_grad_dir(&style_indicator, LV_GRAD_DIR_HOR);\nlv_style_set_shadow_color(&style_indicator, lv_color_hex(0x37B9F5));\nlv_style_set_shadow_width(&style_indicator, 15);\nlv_style_set_shadow_spread(&style_indicator, 5);\n4\n/*Add the style sheet to the slider's INDICATOR part*/\nlv_obj_add_style(slider, &style_indicator, LV_PART_INDICATOR);\n\n/*Add the same style to the KNOB part too and locally overwrite some properties*/\nlv_obj_add_style(slider, &style_indicator, LV_PART_KNOB);\n\nlv_obj_set_style_outline_color(slider, lv_color_hex(0x0096FF), LV_PART_KNOB);\nlv_obj_set_style_outline_width(slider, 3, LV_PART_KNOB);\nlv_obj_set_style_outline_pad(slider, -5, LV_PART_KNOB);\nlv_obj_set_style_shadow_spread(slider, 2, LV_PART_KNOB);\n\n  MicroPython code |\nOnline Simulator\n\n# Create a slider and add the style\nslider = lv.slider(lv.screen_active())\nslider.set_value(70, lv.ANIM.OFF)\nslider.set_size(300, 20)\nslider.center()\n\n# Add local styles to MAIN part (background rectangle)\nslider.set_style_bg_color(lv.color_hex(0x0F1215), lv.PART.MAIN)\nslider.set_style_bg_opa(255, lv.PART.MAIN)\nslider.set_style_border_color(lv.color_hex(0x333943), lv.PART.MAIN)\nslider.set_style_border_width(5, lv.PART.MAIN)\nslider.set_style_pad_all(5, lv.PART.MAIN)\n\n# Create a reusable style sheet for the INDICATOR part\nstyle_indicator = lv.style_t()\nstyle_indicator.init()\nstyle_indicator.set_bg_color(lv.color_hex(0x37B9F5))\nstyle_indicator.set_bg_grad_color(lv.color_hex(0x1464F0))\nstyle_indicator.set_bg_grad_dir(lv.GRAD_DIR.HOR)\nstyle_indicator.set_shadow_color(lv.color_hex(0x37B9F5))\nstyle_indicator.set_shadow_width(15)\nstyle_indicator.set_shadow_spread(5)\n\n# Add the style sheet to the slider's INDICATOR part\nslider.add_style(style_indicator, lv.PART.INDICATOR)\nslider.add_style(style_indicator, lv.PART.KNOB)\n\n# Add the same style to the KNOB part too and locally overwrite some properties\nslider.set_style_outline_color(lv.color_hex(0x0096FF), lv.PART.KNOB)\nslider.set_style_outline_width(3, lv.PART.KNOB)\nslider.set_style_outline_pad(-5, lv.PART.KNOB)\nslider.set_style_shadow_spread(2, lv.PART.KNOB)\n\nEnglish, Hebrew (mixed LTR-RTL) and Chinese texts\n\n  C code\nlv_obj_t * ltr_label = lv_label_create(lv_screen_active());\nlv_label_set_text(ltr_label, \"In modern terminology, a microcontroller is similar to a system on a chip (SoC).\");\nlv_obj_set_style_text_font(ltr_label, &lv_font_montserrat_16, 0);\nlv_obj_set_width(ltr_label, 310);\nlv_obj_align(ltr_label, LV_ALIGN_TOP_LEFT, 5, 5);\n\nlv_obj_t * rtl_label = lv_label_create(lv_screen_active());\nlv_label_set_text(rtl_label,\"××¢×‘×“, ××• ×‘×©××• ×”××œ× ×™×—×™×“×ª ×¢×™×‘×•×“ ××¨×›×–×™×ª (×‘×× ×’×œ×™×ª: CPU - Central Processing Unit).\");\nlv_obj_set_style_base_dir(rtl_label, LV_BASE_DIR_RTL, 0);\nlv_obj_set_style_text_font(rtl_label, &lv_font_dejavu_16_persian_hebrew, 0);\nlv_obj_set_width(rtl_label, 310);\nlv_obj_align(rtl_label, LV_ALIGN_LEFT_MID, 5, 0);\n\nlv_obj_t * cz_label = lv_label_create(lv_screen_active());\nlv_label_set_text(cz_label,\n                  \"åµŒå…¥å¼ç³»ç»Ÿï¼ˆEmbedded Systemï¼‰ï¼Œ\\næ˜¯ä¸€ç§åµŒå…¥æœºæ¢°æˆ–ç”µæ°”ç³»ç»Ÿå†…éƒ¨ã€å…·æœ‰ä¸“ä¸€åŠŸèƒ½å’Œå®æ—¶è®¡ç®—æ€§èƒ½çš„è®¡ç®—æœºç³»ç»Ÿã€‚\");\nlv_obj_set_style_text_font(cz_label, &lv_font_simsun_16_cjk, 0);\nlv_obj_set_width(cz_label, 310);\nlv_obj_align(cz_label, LV_ALIGN_BOTTOM_LEFT, 5, -5);\n\n  MicroPython code | Online Simulator\nltr_label = lv.label(lv.screen_active())\nltr_label.set_text(\"In modern terminology, a microcontroller is similar to a system on a chip (SoC).\")\nltr_label.set_style_text_font(lv.font_montserrat_16, 0);\n\nltr_label.set_width(310)\nltr_label.align(lv.ALIGN.TOP_LEFT, 5, 5)\n\nrtl_label = lv.label(lv.screen_active())\nrtl_label.set_text(\"××¢×‘×“, ××• ×‘×©××• ×”××œ× ×™×—×™×“×ª ×¢×™×‘×•×“ ××¨×›×–×™×ª (×‘×× ×’×œ×™×ª: CPU - Central Processing Unit).\")\nrtl_label.set_style_base_dir(lv.BASE_DIR.RTL, 0)\nrtl_label.set_style_text_font(lv.font_dejavu_16_persian_hebrew, 0)\nrtl_label.set_width(310)\nrtl_label.align(lv.ALIGN.LEFT_MID, 5, 0)\n\nfont_simsun_16_cjk = lv.font_load(\"S:../../assets/font/lv_font_simsun_16_cjk.fnt\")\n\ncz_label = lv.label(lv.screen_active())\ncz_label.set_style_text_font(font_simsun_16_cjk, 0)\ncz_label.set_text(\"åµŒå…¥å¼ç³»ç»Ÿï¼ˆEmbedded Systemï¼‰ï¼Œ\\næ˜¯ä¸€ç§åµŒå…¥æœºæ¢°æˆ–ç”µæ°”ç³»ç»Ÿå†…éƒ¨ã€å…·æœ‰ä¸“ä¸€åŠŸèƒ½å’Œå®æ—¶è®¡ç®—æ€§èƒ½çš„è®¡ç®—æœºç³»ç»Ÿã€‚\")\ncz_label.set_width(310)\ncz_label.align(lv.ALIGN.BOTTOM_LEFT, 5, -5)\n\nâ–¶ï¸ Get started\nThis list will guide you to get started with LVGL step-by-step.\nGet Familiar with LVGL\n\nCheck the Online demos to see LVGL in action (3 minutes).\nRead the Introduction page of the documentation (5 minutes).\nGet familiar with the basics on the Quick overview page (15 minutes).\n\nStart to Use LVGL\n\nSet up a Simulator (10 minutes).\nTry out some Examples.\nPort LVGL to a board. See the Porting guide or check out the ready-to-use Projects.\n\nBecome a Pro\n\nRead the Main-Modules page to get a better understanding of the library (2-3 hours)\nCheck the documentation of the Widgets to see their features and usage\n\nGet Help and Help Others\n\nIf you have questions go to the Forum\nRead the Contributing guide to see how you can help to improve LVGL (15 minutes)\n\nğŸ¤ Services\nLVGL LLC was established to provide a solid background for LVGL library and to offer several type of services to help you in UI development. With 15+ years of experience in the user interface and graphics industry we can help you the bring your UI to the next level.\n\nGraphics design Our in-house graphics designers are experts in creating beautiful modern designs which fit to your product and the resources of your hardware.\nUI implementation We can also implement your UI based on the design you or we have created. You can be sure that we will make the most out of your hardware and LVGL. If a feature or widget is missing from LVGL, don't worry, we will implement it for you.\nConsulting and Support We can support you with consulting as well to avoid pricey and time consuming mistakes during the UI development.\nBoard certification For companies who are offering development boards, or production ready kits we do board certification which shows how board can run LVGL.\n\nCheck out our Demos as reference. For more information take look at the Services page.\nContact us and tell how we can help.\nğŸŒŸ Contributing\nLVGL is an open project and contribution is very welcome. There are many ways to contribute from simply speaking about your project, through writing examples, improving the documentation, fixing bugs or even hosting your own project under the LVGL organization.\nFor a detailed description of contribution opportunities visit the Contributing section of the documentation.\nMore than 300 people already left their fingerprint in LVGL. Be one them! See you here! ğŸ™‚\n\n... and many other.",
    "summary": {
      "en": "**LVGL Overview**\n\nLVGL (Light and Versatile Graphics Library) is a popular, free, and open-source library for creating user interfaces on embedded systems. It supports various hardware platforms and is widely used by major tech companies like Arm, STM32, and Arduino.\n\n**Key Features:**\n- **Compatibility:** Works on any microcontroller or microprocessor with minimal requirements (32kB RAM and 128kB Flash).\n- **Rich Widgets:** Offers over 30 built-in widgets (e.g., buttons, labels, sliders) and a flexible styling system.\n- **Responsive Layouts:** Includes layout managers to organize widgets automatically.\n- **Multi-language Support:** Supports text rendering in various languages, including Chinese and Arabic.\n- **Input Device Support:** Compatible with mouse, touchpads, keyboards, and more.\n\n**Development Support:**\n- LVGL can be integrated easily into projects with existing build systems like Make and CMake.\n- Documentation is comprehensive, featuring over 100 examples for learning.\n- Development services are available for UI design, implementation, and consulting.\n\n**Contribution and Sponsorship:**\n- LVGL encourages community contributions and offers payment for implemented features through sponsorship.\n- Donations are used to support the development and operational costs of the library.\n\n**Getting Started:**\n- New users can explore online demos, set up a simulator, or check out example projects to start using LVGL.\n\n**Services Offered:**\n- LVGL LLC provides graphics design, UI implementation, consulting, and board certification services to enhance user interface development.\n\nFor more information, you can visit the LVGL website or their documentation.",
      "ko": "LVGL(ë¼ì´íŠ¸ ì•¤ë“œ ë²„ì„œíƒ€ì¼ ê·¸ë˜í”½ìŠ¤ ë¼ì´ë¸ŒëŸ¬ë¦¬)ëŠ” ì„ë² ë””ë“œ ì‹œìŠ¤í…œì—ì„œ ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ë¥¼ ë§Œë“¤ê¸° ìœ„í•œ ì¸ê¸° ìˆëŠ” ë¬´ë£Œ ì˜¤í”ˆì†ŒìŠ¤ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤. ì´ ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” ë‹¤ì–‘í•œ í•˜ë“œì›¨ì–´ í”Œë«í¼ì„ ì§€ì›í•˜ë©°, Arm, STM32, Arduinoì™€ ê°™ì€ ì£¼ìš” ê¸°ìˆ  íšŒì‚¬ë“¤ì— ì˜í•´ ë„ë¦¬ ì‚¬ìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤.\n\nLVGLì˜ ì£¼ìš” íŠ¹ì§•ìœ¼ë¡œëŠ” í˜¸í™˜ì„±ì´ ìˆìŠµë‹ˆë‹¤. ìµœì†Œí•œì˜ ìš”êµ¬ ì‚¬í•­ì¸ 32kB RAMê³¼ 128kB Flashë¥¼ ê°–ì¶˜ ëª¨ë“  ë§ˆì´í¬ë¡œì»¨íŠ¸ë¡¤ëŸ¬ë‚˜ ë§ˆì´í¬ë¡œí”„ë¡œì„¸ì„œì—ì„œ ì‘ë™í•©ë‹ˆë‹¤. ë˜í•œ 30ê°œ ì´ìƒì˜ ë‚´ì¥ ìœ„ì ¯(ë²„íŠ¼, ë ˆì´ë¸”, ìŠ¬ë¼ì´ë” ë“±)ê³¼ ìœ ì—°í•œ ìŠ¤íƒ€ì¼ë§ ì‹œìŠ¤í…œì„ ì œê³µí•˜ì—¬ í’ë¶€í•œ ìœ„ì ¯ì„ ì§€ì›í•©ë‹ˆë‹¤. ìë™ìœ¼ë¡œ ìœ„ì ¯ì„ ì •ë¦¬í•  ìˆ˜ ìˆëŠ” ë ˆì´ì•„ì›ƒ ê´€ë¦¬ìë¥¼ í¬í•¨í•˜ì—¬ ë°˜ì‘í˜• ë ˆì´ì•„ì›ƒì„ ì§€ì›í•©ë‹ˆë‹¤. ë‹¤ì–‘í•œ ì–¸ì–´ë¡œ í…ìŠ¤íŠ¸ ë Œë”ë§ì´ ê°€ëŠ¥í•˜ë©°, ì¤‘êµ­ì–´ì™€ ì•„ëì–´ë„ í¬í•¨ë©ë‹ˆë‹¤. ë§ˆìš°ìŠ¤, í„°ì¹˜íŒ¨ë“œ, í‚¤ë³´ë“œ ë“± ë‹¤ì–‘í•œ ì…ë ¥ ì¥ì¹˜ì™€ í˜¸í™˜ë©ë‹ˆë‹¤.\n\nê°œë°œ ì§€ì› ì¸¡ë©´ì—ì„œ LVGLì€ Makeì™€ CMakeì™€ ê°™ì€ ê¸°ì¡´ ë¹Œë“œ ì‹œìŠ¤í…œì— ì‰½ê²Œ í†µí•©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë¬¸ì„œí™”ê°€ ì˜ ë˜ì–´ ìˆì–´ í•™ìŠµì„ ìœ„í•œ 100ê°œ ì´ìƒì˜ ì˜ˆì œê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. UI ë””ìì¸, êµ¬í˜„ ë° ì»¨ì„¤íŒ…ì„ ìœ„í•œ ê°œë°œ ì„œë¹„ìŠ¤ë„ ì œê³µë©ë‹ˆë‹¤.\n\nLVGLì€ ì»¤ë®¤ë‹ˆí‹°ì˜ ê¸°ì—¬ë¥¼ ì¥ë ¤í•˜ë©°, êµ¬í˜„ëœ ê¸°ëŠ¥ì— ëŒ€í•´ í›„ì›ì„ í†µí•´ ë³´ìƒì„ ì œê³µí•©ë‹ˆë‹¤. ê¸°ë¶€ê¸ˆì€ ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ê°œë°œ ë° ìš´ì˜ ë¹„ìš©ì„ ì§€ì›í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.\n\nìƒˆë¡œìš´ ì‚¬ìš©ìëŠ” ì˜¨ë¼ì¸ ë°ëª¨ë¥¼ íƒìƒ‰í•˜ê±°ë‚˜ ì‹œë®¬ë ˆì´í„°ë¥¼ ì„¤ì •í•˜ê±°ë‚˜ ì˜ˆì œ í”„ë¡œì íŠ¸ë¥¼ í™•ì¸í•˜ì—¬ LVGLì„ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. LVGL LLCëŠ” ê·¸ë˜í”½ ë””ìì¸, UI êµ¬í˜„, ì»¨ì„¤íŒ… ë° ë³´ë“œ ì¸ì¦ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•˜ì—¬ ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ ê°œë°œì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.\n\në” ë§ì€ ì •ë³´ëŠ” LVGL ì›¹ì‚¬ì´íŠ¸ë‚˜ ë¬¸ì„œë¥¼ ë°©ë¬¸í•˜ì—¬ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
      "ja": "LVGLï¼ˆãƒ©ã‚¤ãƒˆã§å¤šç”¨é€”ãªã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚¹ãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼‰ã¯ã€çµ„ã¿è¾¼ã¿ã‚·ã‚¹ãƒ†ãƒ å‘ã‘ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’ä½œæˆã™ã‚‹ãŸã‚ã®äººæ°—ã®ã‚ã‚‹ç„¡æ–™ã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã™ã€‚ã“ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¯ã•ã¾ã–ã¾ãªãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã«å¯¾å¿œã—ã¦ãŠã‚Šã€Armã€STM32ã€Arduinoãªã©ã®å¤§æ‰‹ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ä¼æ¥­ã«åºƒãåˆ©ç”¨ã•ã‚Œã¦ã„ã¾ã™ã€‚\n\nLVGLã®ä¸»ãªç‰¹å¾´ã«ã¯ã€äº’æ›æ€§ãŒã‚ã‚Šã€æœ€å°é™ã®è¦ä»¶ï¼ˆ32kBã®RAMã¨128kBã®ãƒ•ãƒ©ãƒƒã‚·ãƒ¥ãƒ¡ãƒ¢ãƒªï¼‰ã§ã‚ã‚‰ã‚†ã‚‹ãƒã‚¤ã‚¯ãƒ­ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼ã‚„ãƒã‚¤ã‚¯ãƒ­ãƒ—ãƒ­ã‚»ãƒƒã‚µã§å‹•ä½œã™ã‚‹ã“ã¨ãŒå«ã¾ã‚Œã¾ã™ã€‚ã¾ãŸã€ãƒœã‚¿ãƒ³ã‚„ãƒ©ãƒ™ãƒ«ã€ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ãªã©30ä»¥ä¸Šã®çµ„ã¿è¾¼ã¿ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆã‚’æä¾›ã—ã€æŸ”è»Ÿãªã‚¹ã‚¿ã‚¤ãƒªãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ã‚‚å‚™ãˆã¦ã„ã¾ã™ã€‚ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆã‚’è‡ªå‹•çš„ã«æ•´ç†ã™ã‚‹ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã‚‚å«ã¾ã‚Œã¦ãŠã‚Šã€ã•ã¾ã–ã¾ãªè¨€èªï¼ˆä¸­å›½èªã‚„ã‚¢ãƒ©ãƒ“ã‚¢èªã‚’å«ã‚€ï¼‰ã§ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ã«ã‚‚å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚ã•ã‚‰ã«ã€ãƒã‚¦ã‚¹ã€ã‚¿ãƒƒãƒãƒ‘ãƒƒãƒ‰ã€ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ãªã©ã®å…¥åŠ›ãƒ‡ãƒã‚¤ã‚¹ã«ã‚‚å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚\n\né–‹ç™ºã®ã‚µãƒãƒ¼ãƒˆã¨ã—ã¦ã€LVGLã¯Makeã‚„CMakeãªã©ã®æ—¢å­˜ã®ãƒ“ãƒ«ãƒ‰ã‚·ã‚¹ãƒ†ãƒ ã«ç°¡å˜ã«çµ±åˆã§ãã€100ä»¥ä¸Šã®å­¦ç¿’ç”¨ä¾‹ã‚’å«ã‚€åŒ…æ‹¬çš„ãªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒç”¨æ„ã•ã‚Œã¦ã„ã¾ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã®ãƒ‡ã‚¶ã‚¤ãƒ³ã€å®Ÿè£…ã€ã‚³ãƒ³ã‚µãƒ«ãƒ†ã‚£ãƒ³ã‚°ã«é–¢ã™ã‚‹é–‹ç™ºã‚µãƒ¼ãƒ“ã‚¹ã‚‚æä¾›ã•ã‚Œã¦ã„ã¾ã™ã€‚\n\nLVGLã¯ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã‹ã‚‰ã®è²¢çŒ®ã‚’å¥¨åŠ±ã—ã¦ãŠã‚Šã€å®Ÿè£…ã•ã‚ŒãŸæ©Ÿèƒ½ã«å¯¾ã—ã¦ã‚¹ãƒãƒ³ã‚µãƒ¼ã‚·ãƒƒãƒ—ã‚’é€šã˜ã¦å ±é…¬ã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚å¯„ä»˜ã¯ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®é–‹ç™ºã‚„é‹å–¶è²»ç”¨ã®æ”¯æ´ã«ä½¿ç”¨ã•ã‚Œã¾ã™ã€‚\n\næ–°ã—ã„ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ã€ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ãƒ‡ãƒ¢ã‚’æ¢ç´¢ã—ãŸã‚Šã€ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼ã‚’è¨­å®šã—ãŸã‚Šã€ä¾‹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’ãƒã‚§ãƒƒã‚¯ã—ãŸã‚Šã—ã¦LVGLã®ä½¿ç”¨ã‚’é–‹å§‹ã§ãã¾ã™ã€‚\n\nLVGL LLCã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã®é–‹ç™ºã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã«ã€ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯ãƒ‡ã‚¶ã‚¤ãƒ³ã€UIå®Ÿè£…ã€ã‚³ãƒ³ã‚µãƒ«ãƒ†ã‚£ãƒ³ã‚°ã€ãƒœãƒ¼ãƒ‰èªè¨¼ã‚µãƒ¼ãƒ“ã‚¹ã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚è©³ç´°ã«ã¤ã„ã¦ã¯ã€LVGLã®ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆã‚„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’è¨ªã‚Œã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚"
    }
  },
  {
    "id": "6556a279fd54506e",
    "title": {
      "en": "Veloren â€“ voxel action-adventure role-playing",
      "ko": "ë²¨ë¡œë Œ: ë³µì…€ ëª¨í—˜ RPG",
      "ja": "ãƒ´ã‚§ãƒ­ãƒ¬ãƒ³ã®å†’é™º"
    },
    "type": "story",
    "url": "https://veloren.net/",
    "score": 263,
    "by": "tete",
    "time": 1743271508,
    "content": "Welcome to Veloren!Veloren is an action-adventure role-playing game set in a vast fantasy world.ğŸ•ï¸ Explore enormous mountains, arid deserts, dense jungles, and many more environmentsâš”ï¸ Discover many different weapons and play styles with dynamic and fast-paced combatğŸ  Interact with NPCs and craft equipment in towns to help you on your wayâ˜ ï¸ Encounter menacing bosses and fearsome monsters in dungeons and hideoutsğŸŒ Experience a complex and interconnected procedural world, fully simulated as you playâ›ï¸ Delve deep beneath the earth to mine ore and gems in sprawling cave networksğŸ Tame wild beasts as companions and mounts to aid you in your journeyğŸ«±ğŸ½â€ğŸ«²ğŸ¿ Adventure with friends on multiplayer servers, or host your own over LANğŸ› ï¸ Discover the source code and contribute to the project yourselfWhat are you waiting for?",
    "summary": {
      "en": "Welcome to Veloren! It's an action-adventure role-playing game in a large fantasy world. \n\n- **Explore** diverse environments like mountains, deserts, and jungles.\n- **Engage** in dynamic combat with various weapons and play styles.\n- **Interact** with NPCs and craft gear in towns.\n- **Face** tough bosses and monsters in dungeons.\n- **Experience** a detailed world that changes as you play.\n- **Mine** for resources in extensive cave systems.\n- **Tame** wild animals to accompany you.\n- **Play** with friends online or on local servers.\n- **Contribute** to the project by exploring the source code.\n\nDive into the adventure!",
      "ko": "ë²¨ë¡œë Œì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤! ì´ ê²Œì„ì€ ë„“ì€ íŒíƒ€ì§€ ì„¸ê³„ì—ì„œ í¼ì³ì§€ëŠ” ì•¡ì…˜ ì–´ë“œë²¤ì²˜ ë¡¤í”Œë ˆì‰ ê²Œì„ì…ë‹ˆë‹¤. \n\në‹¤ì–‘í•œ í™˜ê²½ì„ íƒí—˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‚°, ì‚¬ë§‰, ì •ê¸€ ë“± ì—¬ëŸ¬ ì¥ì†Œë¥¼ ê²½í—˜í•´ ë³´ì„¸ìš”. ë‹¤ì–‘í•œ ë¬´ê¸°ì™€ í”Œë ˆì´ ìŠ¤íƒ€ì¼ë¡œ ì—­ë™ì ì¸ ì „íˆ¬ì— ì°¸ì—¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë§ˆì„ì—ì„œëŠ” NPCì™€ ìƒí˜¸ì‘ìš©í•˜ê³  ì¥ë¹„ë¥¼ ì œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜ì „ì—ì„œëŠ” ê°•ë ¥í•œ ë³´ìŠ¤ì™€ ê´´ë¬¼ì— ë§ì„œ ì‹¸ì›Œì•¼ í•©ë‹ˆë‹¤. \n\nê²Œì„ì„ ì§„í–‰í•˜ë©´ì„œ ë³€í™”í•˜ëŠ” ì„¸ë°€í•œ ì„¸ê³„ë¥¼ ê²½í—˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê´‘ë²”ìœ„í•œ ë™êµ´ ì‹œìŠ¤í…œì—ì„œ ìì›ì„ ì±„êµ´í•  ìˆ˜ ìˆìœ¼ë©°, ì•¼ìƒ ë™ë¬¼ì„ ê¸¸ë“¤ì—¬ í•¨ê»˜ ëª¨í—˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¹œêµ¬ë“¤ê³¼ ì˜¨ë¼ì¸ ë˜ëŠ” ë¡œì»¬ ì„œë²„ì—ì„œ í•¨ê»˜ í”Œë ˆì´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, ì†ŒìŠ¤ ì½”ë“œë¥¼ íƒí—˜í•˜ë©° í”„ë¡œì íŠ¸ì— ê¸°ì—¬í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. \n\nëª¨í—˜ì— ë›°ì–´ë“¤ì–´ ë³´ì„¸ìš”!",
      "ja": "Velorenã¸ã‚ˆã†ã“ãï¼ã“ã‚Œã¯åºƒå¤§ãªãƒ•ã‚¡ãƒ³ã‚¿ã‚¸ãƒ¼ã®ä¸–ç•Œã§ç¹°ã‚Šåºƒã’ã‚‰ã‚Œã‚‹ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ãƒ‰ãƒ™ãƒ³ãƒãƒ£ãƒ¼RPGã§ã™ã€‚\n\nã•ã¾ã–ã¾ãªç’°å¢ƒã‚’æ¢ç´¢ã§ãã¾ã™ã€‚å±±ã‚„ç ‚æ¼ ã€ã‚¸ãƒ£ãƒ³ã‚°ãƒ«ãªã©ã€å¤šæ§˜ãªæ™¯è‰²ãŒåºƒãŒã£ã¦ã„ã¾ã™ã€‚æˆ¦é—˜ã¯ãƒ€ã‚¤ãƒŠãƒŸãƒƒã‚¯ã§ã€ã•ã¾ã–ã¾ãªæ­¦å™¨ã‚„ãƒ—ãƒ¬ã‚¤ã‚¹ã‚¿ã‚¤ãƒ«ã‚’é§†ä½¿ã—ã¦æŒ‘ã‚€ã“ã¨ãŒã§ãã¾ã™ã€‚ç”ºã§ã¯NPCã¨äº¤æµã—ã€è£…å‚™ã‚’ä½œæˆã™ã‚‹ã“ã¨ã‚‚å¯èƒ½ã§ã™ã€‚\n\nãƒ€ãƒ³ã‚¸ãƒ§ãƒ³ã§ã¯ã€å¼·åŠ›ãªãƒœã‚¹ã‚„ãƒ¢ãƒ³ã‚¹ã‚¿ãƒ¼ã¨å¯¾å³™ã—ã¾ã™ã€‚ãƒ—ãƒ¬ã‚¤ã™ã‚‹ã«ã¤ã‚Œã¦å¤‰åŒ–ã™ã‚‹è©³ç´°ãªä¸–ç•Œã‚’ä½“é¨“ã§ãã‚‹ã®ã‚‚é­…åŠ›ã§ã™ã€‚åºƒå¤§ãªæ´çªŸã‚·ã‚¹ãƒ†ãƒ ã§ã¯è³‡æºã‚’æ¡æ˜ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚é‡ç”Ÿã®å‹•ç‰©ã‚’é£¼ã„ãªã‚‰ã—ã¦ã€ä¸€ç·’ã«å†’é™ºã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚\n\nå‹é”ã¨ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã‚„ãƒ­ãƒ¼ã‚«ãƒ«ã‚µãƒ¼ãƒãƒ¼ã§ä¸€ç·’ã«éŠã¶ã“ã¨ã‚‚ã§ãã¾ã™ã€‚ã¾ãŸã€ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã‚’æ¢ç´¢ã™ã‚‹ã“ã¨ã§ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«è²¢çŒ®ã™ã‚‹ã“ã¨ã‚‚å¯èƒ½ã§ã™ã€‚\n\nã•ã‚ã€å†’é™ºã«é£›ã³è¾¼ã‚“ã§ã¿ã¾ã—ã‚‡ã†ï¼"
    }
  },
  {
    "id": "f8db0cbcb8af5b9b",
    "title": {
      "en": "The Candid Naivety of Geeks",
      "ko": "ê¸°ë°œí•œ ìˆœìˆ˜í•¨",
      "ja": "ã‚ªã‚¿ã‚¯ã®ç´”çœŸã•"
    },
    "type": "story",
    "url": "https://ploum.net/2025-03-28-geeks-naivety.html",
    "score": 111,
    "by": "SlackingOff123",
    "time": 1743277546,
    "content": "The candid naivety of geeks\nby Ploum on 2025-03-28\nI mean, come on!\nAmazon recently announced that, from now on, everything you say to Alexa will be sent to their server.\n\nPluralistic: Amazon annihilates Alexa privacy settings, turns on continuous, nonconsensual audio uploading (15 Mar 2025) (pluralistic.net)\n\nWhat surprised me the most with this announcement is how it was met with surprise and harsh reactions. People felt betrayed.\nI mean, come on!\nDid you really think that Amazon was not listening to you before that? Did you really buy an Alexa trusting Amazon to \"protect your privacy\"?\nRecently, I came across a comment on Hacker News where the poster defended Apple as protecting privacy of its users because \"They market their product as protecting our privacy\".\nI mean, once again, come on!\nDid you really think that \"marketing\" is telling the truth? Are you a freshly debarked Thermian? (In case you missed it, this is a Galaxy Quest reference.)\nThe whole point of marketing is to lie, lie and lie again.\nWhat is the purpose of that gadget?\nThe whole point of the whole Amazon Alexa tech stack is to send information to Amazon. Thatâ€™s the main goal of the thing. The fact that it is sometimes useful to you is a direct consequence of the thing sending information to Amazon. Just like Facebook linking you with friends is a consequence of you giving your information to Meta. Usefulness is only a byproduct of privacy invasion.\nHaving a fine-grained setting enabling \"do not send all information to Amazon please\" is, at best, wishful thinking. We had the same in the browser (\"do-not-track\"). It didnâ€™t work.\nIâ€™ve always been convinced that the tech geeks who bought an Amazon Alexa perfectly knew what they were doing. One of my friends has a Google Echo and justify it with \"Google already knows everything about our family through our phones, so Iâ€™m trading only a bit more of our privacy for convenience\". I donâ€™t agree with him but, at the very least, itâ€™s a logical opinion.\nWe all know that what can be done with a tool will be done eventually. And you should prepare for it. On a side note, I also postulate that the reason Amazon removed that setting is because they were already gathering too much data to justify its existence in case thereâ€™s a complaint or an investigation in the future.\"How did you manage to get those data while your product says it will not send data?\".\nBut, once again, any tech person knows that pushing a button in an interface is not a proof of anything in the underlying software.\nPlease stop being naive about Apple\nThatâ€™s also the point with Apple: Apple is such a big company that the right hand has no idea about what the left hand is doing. Some privacy people are working at Apple and doing good job. But their work is continuously diluted through the interests of quick and cheap production, marketing, release, new features, gathering data for advertising purpose. Apple is not a privacy company and has never been: it is an opportunistic company which advertise privacy when it feels it could help sell more iPhones. But deeply inside, they absolutely donâ€™t care and they will absolutely trade the (very little) privacy they have if it means selling more.\nSometimes, geek naivety is embarrassingly stupid. Like \"brand loyalty\". Marketing lies to you. As a rule of thumb, the bigger the company, the bigger the lie. In tech, thereâ€™s no way for a big company to not lie because marketers have no real understanding of they are selling. Do you really think that people who chose to advertise \"privacy\" at Apple have any strong knowledge about \"privacy\"? That they could simply give you a definition of \"privacy\"?\nI know that intelligent people go to great intellectual contortions to justify buying the latest overpriced spying shiny coloured screen with an apple logo. It looks like most humans actively look to see their freedom restricted. Seirdy calls it \"the domestication of users\".\n\nWhatsApp and the domestication of users (seirdy.one)\n\nAnd thatâ€™s why I see Apple as a cult: most tech people cannot be reasoned about it.\n\nThe Cost of Being Convinced (ploum.net)\n\nYou canâ€™t find a technical solution to a lie\nBill Cole, contributor to Spamassassin, recently posted on Mastodon that the whole DNS stack to protect spammers was not working.\n spammers are more consistent at making SPF, DKIM, and DMARC correct than are legitimate senders.\n\nğŸ†˜Bill Cole ğŸ‡ºğŸ‡¦: \"@jwz@mastodon.social The stats we collect for theâ€¦\" (toad.social)\n\nIt is, once again, a naive approach to spam. The whole stack was designed with the mindset \"bad spammers will try to hide themselves\". But was is happening in your inbox, really?\nMost spam is not \"black hat spam\". It is what I call \"white-collar spam\": perfectly legitimate company, sending you emails from legitimate address. You slept in a hotel during a business trip? Now you will receive weekly emails about our hotel for the rest of your life. And it is the same for any shop, any outlet, anything you have done. Your inbox is filled with \"white-collar\" junk. And they know this perfectly well.\nIn Europe, we have a rule, the RGPD, which forbid businesses to keep your data without your express consent. I did the experiment for several months to send a legal threat to every single white-collar spam I received. Guess what: they always replied that it was a mistake, that I was now removed, that it should not have happened, that I checked the box (which was false but how could I prove it?) or even, on one occasion, that they restored a backup containing my email before I unsubscribed (I unsubscribed from that one 10 years before, which makes it very unlikely).\nIn short, they lied. All of them. All of them are spammers and they lie pretending that \"they thought you were interested\".\nIn one notable case, they told me that they had erased all my data while, still having the cookie on my laptop, I could see and use my account. Thirty days later, I was still connected and I figured that they simply managed to change my user id from \"ploum\" to \"deleted_ploum\" in the database. While answering me straight in the face that they had no information about me in their database.\nCorporations are lying. You must treat every corporate word as a straight lie until proved otherwise.\nBut Ploum, if all marketing is a lie, why trusting Signal?\nIf you canâ€™t trust marketing, why do Iâ€¯use Signal and Protonmail?\nFirst of all, Signal is open source. And, yes, Iâ€™ve read some of the source code for some feature I was interested in. Iâ€™ve also read through some very deep audit of Signal source code.\n\nReviewing the Cryptography Used by Signal (soatok.blog)\n\nIâ€™m also trusting the people behind Signal. Iâ€™m trusting people who recommend Signal. Iâ€™m trusting the way Signal is built.\nBut most importantly, Signal sole existence is to protect privacy of its users. Itâ€™s not even a corporation and, yes, this is important.\nYes, they could lie in their marketing. Like Telegram did (and still does AFAIK). But this would undermine their sole reason to exist.\nI donâ€™t say that Signal is perfect: I say I trust them to believe themselves what they announce. For now.\nWhat about Protonmail?\nFor the same reasons, Protonmail can, to some extent, be trusted. Technically, they can access most of the emails of their customers (because those emails arrive unencrypted to PMâ€™s servers). But I trust Protonmail not to sell any data because if thereâ€™s any doubt that they do it, the whole business will crumble. They have a strong commercial incentive to do everything they can to protect my data. I pay them for that. Itâ€™s not a \"checkbox\" they could remove, itâ€™s their whole raison dâ€™Ãªtre.\nThis is also why I pay for Kagi as my search engine: their business incentive is to provide me the best search results with less slop, less advertising. As soon as they start doing some kind of advertising, I will stop paying them and they know it. Or if Kagi starts becoming to AI centric for my taste, like they did for Lori:\n\nWhy I Lost Faith in Kagi (d-shoot.net)\n\nI donâ€™t blindly trust companies. Paying them is not a commitment to obey them, au contraire. Every relation with a commercial entity is, by essence, temporary. I pay for a service with strings attached. If the service degrade, if my conditions are not respected, I stop paying. If Iâ€™m not convinced they can be trusted, I stop paying them. I know I can pay and still be the product. If I have any doubt, I donâ€™t pay. I try to find an alternative and migrate to it. Email being critical to me, I always have two accounts on two different trustable providers with an easy migrating path (which boils down to changing my DNS config).\nFighting the Androidification\nCory Doctorow speaks a lot about enshitification. Where users are more and more exploited. But one key component of a good enshitification is what I call \"Androidification\".\nAndroidification is not about degrading the user experience. Itâ€™s about closing doors, removing special use cases, being less and less transparent. Itâ€™s about taking open source software and frog boiling it to a full closed proprietary state while killing all the competition in the process.\nAndroid was, at first, an Open Source project. With each release, it became more closed, more proprietary. As I explain in my \"20 years of Linux on the Desktop\" essay, I believe it has always been part of the plan. Besides the Linux kernel, Google was always wary not to include any GPL or LGPL licensed library in Android.\n\n20 years of Linux on the Desktop (part 3) (ploum.net)\n\nIt took them 15 years but they finally achieved killing the Android Open Source Project:\n\nGoogle will develop the Android OS fully in private, here's why (www.androidauthority.com)\n\nThis is why Iâ€™m deeply concerned by the motivation of Canonical to switch Ubuntuâ€™s coreutils to an MIT licensed version.\n\nUbuntu 25.10 plans to swap GNU coreutils for Rust (go.theregister.com)\n\nThis is why Iâ€™m deeply concerned that Protonmail quietly removed the issue tracker from its Protonmail Bridge Github page (making the development completely opaque for what is an essential tool for technical Protonmail users).\nI mean, commons!\nThis whole naivety is also why Iâ€™m deeply concerned by very intelligent and smart tech people not understanding what \"copyleft\" is, why it is different from \"open source\" and why they should care.\n\nWe need more of Richard Stallman, not less (ploum.net)\n\nCorporations are not your friend. They never were. They lie. The only possible relationship with them is an opportunistic one. And if you want to build commons that they cannot steal, you need strong copyleft.\n\nOn Open Source and the Sustainability of the Commons (ploum.net)\n\nBut firstly, my fellow geeks, you need to lose your candid naivety.\nI mean, come on, letâ€™s build the commons!\n\nIâ€™m Ploum, a writer and an engineer. I like to explore how technology impacts society. You can subscribe by email or by rss. I value privacy and never share your adress.\nI write science-fiction novels in French. For Bikepunk, my new post-apocalyptic-cyclist book, my publisher is looking for contacts in other countries to distribute it in languages other than French. If you can help, contact me!",
    "summary": {
      "en": "The article discusses the naivety of tech enthusiasts regarding privacy and corporate practices, particularly in relation to Amazon's Alexa and Apple. \n\nKey points include:\n\n1. **Privacy Betrayal**: Amazon's decision to continuously send audio to its servers surprised many, but the author argues that users should have expected this, as the primary goal of such devices is data collection.\n\n2. **Marketing Misinformation**: The author criticizes the belief that companies like Apple genuinely protect user privacy, suggesting that marketing often misrepresents reality. He believes big companies prioritize profit over user privacy.\n\n3. **Spamming and Data Misuse**: The article highlights how legitimate companies often contribute to spam by misusing customer data and lying about consent, emphasizing the need for skepticism towards corporate claims.\n\n4. **Trust in Alternatives**: The author trusts services like Signal and Protonmail because they are built to protect user privacy and have strong incentives to do so, unlike larger corporations.\n\n5. **Corporate Relationships**: The relationship with companies should be viewed as opportunistic, and users should be prepared to switch services if they feel their privacy is compromised.\n\n6. **Concerns about Open Source**: The author warns against the \"Androidification\" of open-source projects, where transparency and user control are gradually reduced.\n\nUltimately, the author urges tech enthusiasts to be more critical of companies and their practices, advocating for stronger protections of user data and promoting the idea of building a commons that cannot be exploited by corporations.",
      "ko": "ì´ ê¸°ì‚¬ëŠ” ê¸°ìˆ  ì• í˜¸ê°€ë“¤ì´ ê°œì¸ ì •ë³´ ë³´í˜¸ì™€ ê¸°ì—… ê´€í–‰ì— ëŒ€í•´ ì–¼ë§ˆë‚˜ ìˆœì§„í•œì§€ë¥¼ ë‹¤ë£¨ê³  ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ ì•„ë§ˆì¡´ì˜ ì•Œë ‰ì‚¬ì™€ ì• í”Œì— ëŒ€í•œ ë‚´ìš©ì´ ì¤‘ì‹¬ì…ë‹ˆë‹¤.\n\nì²« ë²ˆì§¸ë¡œ, ì•„ë§ˆì¡´ì´ ì§€ì†ì ìœ¼ë¡œ ìŒì„±ì„ ì„œë²„ë¡œ ì „ì†¡í•˜ê¸°ë¡œ í•œ ê²°ì •ì€ ë§ì€ ì‚¬ëŒë“¤ì„ ë†€ë¼ê²Œ í–ˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ì €ìëŠ” ì´ëŸ¬í•œ ì¥ì¹˜ì˜ ì£¼ëœ ëª©ì ì´ ë°ì´í„° ìˆ˜ì§‘ì´ë¼ëŠ” ì ì—ì„œ ì‚¬ìš©ìë“¤ì´ ì´ë¥¼ ì˜ˆìƒí–ˆì–´ì•¼ í•œë‹¤ê³  ì£¼ì¥í•©ë‹ˆë‹¤.\n\në‘ ë²ˆì§¸ë¡œ, ì €ìëŠ” ì• í”Œê³¼ ê°™ì€ ê¸°ì—…ë“¤ì´ ì§„ì •ìœ¼ë¡œ ì‚¬ìš©ì ê°œì¸ ì •ë³´ë¥¼ ë³´í˜¸í•œë‹¤ê³  ë¯¿ëŠ” ê²ƒì— ëŒ€í•´ ë¹„íŒí•©ë‹ˆë‹¤. ê·¸ëŠ” ë§ˆì¼€íŒ…ì´ í˜„ì‹¤ì„ ì™œê³¡í•˜ëŠ” ê²½ìš°ê°€ ë§ë‹¤ê³  ì§€ì í•˜ë©°, ëŒ€ê¸°ì—…ë“¤ì´ ì‚¬ìš©ì ê°œì¸ ì •ë³´ë³´ë‹¤ ì´ìµì„ ìš°ì„ ì‹œí•œë‹¤ê³  ë¯¿ê³  ìˆìŠµë‹ˆë‹¤.\n\nì„¸ ë²ˆì§¸ë¡œ, ê¸°ì‚¬ëŠ” í•©ë²•ì ì¸ ê¸°ì—…ë“¤ì´ ê³ ê° ë°ì´í„°ë¥¼ ì˜ëª» ì‚¬ìš©í•˜ê³  ë™ì˜ì— ëŒ€í•´ ê±°ì§“ë§ì„ í•˜ë©´ì„œ ìŠ¤íŒ¸ì„ ìœ ë°œí•˜ëŠ” ê²½ìš°ê°€ ë§ë‹¤ê³  ê°•ì¡°í•©ë‹ˆë‹¤. ë”°ë¼ì„œ ê¸°ì—…ì˜ ì£¼ì¥ì— ëŒ€í•´ íšŒì˜ì ì¸ ì‹œê°ì„ ê°€ì ¸ì•¼ í•œë‹¤ê³  ë§í•©ë‹ˆë‹¤.\n\në„¤ ë²ˆì§¸ë¡œ, ì €ìëŠ” ì‹œê·¸ë„ê³¼ í”„ë¡œí†¤ë©”ì¼ê³¼ ê°™ì€ ì„œë¹„ìŠ¤ì— ì‹ ë¢°ë¥¼ ë‘ê³  ìˆìŠµë‹ˆë‹¤. ì´ë“¤ ì„œë¹„ìŠ¤ëŠ” ì‚¬ìš©ì ê°œì¸ ì •ë³´ë¥¼ ë³´í˜¸í•˜ê¸° ìœ„í•´ ì„¤ê³„ë˜ì—ˆìœ¼ë©°, ëŒ€ê¸°ì—…ê³¼ëŠ” ë‹¬ë¦¬ ì´ë¥¼ ìœ„í•œ ê°•ë ¥í•œ ìœ ì¸ì´ ìˆë‹¤ê³  ì„¤ëª…í•©ë‹ˆë‹¤.\n\në‹¤ì„¯ ë²ˆì§¸ë¡œ, ê¸°ì—…ê³¼ì˜ ê´€ê³„ëŠ” ê¸°íšŒì£¼ì˜ì ìœ¼ë¡œ ë°”ë¼ë´ì•¼ í•˜ë©°, ì‚¬ìš©ìëŠ” ê°œì¸ ì •ë³´ê°€ ì¹¨í•´ë‹¹í•œë‹¤ê³  ëŠë‚„ ê²½ìš° ì„œë¹„ìŠ¤ë¥¼ ë³€ê²½í•  ì¤€ë¹„ë¥¼ í•´ì•¼ í•œë‹¤ê³  ê°•ì¡°í•©ë‹ˆë‹¤.\n\në§ˆì§€ë§‰ìœ¼ë¡œ, ì €ìëŠ” ì˜¤í”ˆ ì†ŒìŠ¤ í”„ë¡œì íŠ¸ì˜ \"ì•ˆë“œë¡œì´ë“œí™”\"ì— ëŒ€í•´ ê²½ê³ í•©ë‹ˆë‹¤. ì´ëŠ” íˆ¬ëª…ì„±ê³¼ ì‚¬ìš©ì í†µì œê°€ ì ì°¨ ì¤„ì–´ë“œëŠ” í˜„ìƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.\n\nê²°êµ­ ì €ìëŠ” ê¸°ìˆ  ì• í˜¸ê°€ë“¤ì´ ê¸°ì—…ê³¼ ê·¸ë“¤ì˜ ê´€í–‰ì— ëŒ€í•´ ë” ë¹„íŒì ìœ¼ë¡œ ì ‘ê·¼í•  ê²ƒì„ ì´‰êµ¬í•˜ë©°, ì‚¬ìš©ì ë°ì´í„° ë³´í˜¸ë¥¼ ê°•í™”í•˜ê³  ê¸°ì—…ì´ ì°©ì·¨í•  ìˆ˜ ì—†ëŠ” ê³µê³µ ìì›ì„ êµ¬ì¶•í•  í•„ìš”ì„±ì„ ê°•ì¡°í•©ë‹ˆë‹¤.",
      "ja": "ã“ã®è¨˜äº‹ã§ã¯ã€ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼æ„›å¥½è€…ãŒãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ã‚„ä¼æ¥­ã®å®Ÿæ…‹ã«ã¤ã„ã¦æŠ±ãç„¡é‚ªæ°—ã•ã«ã¤ã„ã¦è«–ã˜ã¦ã„ã¾ã™ã€‚ç‰¹ã«ã€Amazonã®Alexaã‚„Appleã«é–¢é€£ã™ã‚‹å†…å®¹ãŒå–ã‚Šä¸Šã’ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚\n\nã¾ãšã€AmazonãŒéŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å¸¸ã«ã‚µãƒ¼ãƒãƒ¼ã«é€ä¿¡ã™ã‚‹æ±ºå®šã«ã¤ã„ã¦ã€å¤šãã®äººãŒé©šã„ãŸã¨è¿°ã¹ã¦ã„ã¾ã™ã€‚ã—ã‹ã—ã€è‘—è€…ã¯ã“ã†ã—ãŸãƒ‡ãƒã‚¤ã‚¹ã®ä¸»ãªç›®çš„ãŒãƒ‡ãƒ¼ã‚¿åé›†ã§ã‚ã‚‹ãŸã‚ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ã“ã®äº‹å®Ÿã‚’äºˆæƒ³ã™ã¹ãã ã£ãŸã¨ä¸»å¼µã—ã¦ã„ã¾ã™ã€‚\n\næ¬¡ã«ã€è‘—è€…ã¯Appleã®ã‚ˆã†ãªä¼æ¥­ãŒæœ¬å½“ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ã‚’å®ˆã£ã¦ã„ã‚‹ã¨ã„ã†ä¿¡å¿µã‚’æ‰¹åˆ¤ã—ã¦ã„ã¾ã™ã€‚ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ãŒç¾å®Ÿã‚’èª¤è§£ã•ã›ã‚‹ã“ã¨ãŒå¤šãã€å¤§ä¼æ¥­ã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ã‚ˆã‚Šã‚‚åˆ©ç›Šã‚’å„ªå…ˆã—ã¦ã„ã‚‹ã¨è€ƒãˆã¦ã„ã¾ã™ã€‚\n\nã¾ãŸã€æ­£å½“ãªä¼æ¥­ãŒé¡§å®¢ãƒ‡ãƒ¼ã‚¿ã‚’æ‚ªç”¨ã—ã€åŒæ„ã«ã¤ã„ã¦å˜˜ã‚’ã¤ãã“ã¨ã§ã‚¹ãƒ‘ãƒ ã‚’åŠ©é•·ã—ã¦ã„ã‚‹ã“ã¨ã‚‚æŒ‡æ‘˜ã•ã‚Œã¦ã„ã¾ã™ã€‚ä¼æ¥­ã®ä¸»å¼µã«å¯¾ã—ã¦ã¯æ‡ç–‘çš„ã§ã‚ã‚‹ã¹ãã ã¨å¼·èª¿ã—ã¦ã„ã¾ã™ã€‚\n\nè‘—è€…ã¯ã€Signalã‚„Protonmailã®ã‚ˆã†ãªã‚µãƒ¼ãƒ“ã‚¹ã‚’ä¿¡é ¼ã—ã¦ã„ã¾ã™ã€‚ã“ã‚Œã‚‰ã®ã‚µãƒ¼ãƒ“ã‚¹ã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ã‚’å®ˆã‚‹ãŸã‚ã«è¨­è¨ˆã•ã‚Œã¦ãŠã‚Šã€å¤§ä¼æ¥­ã¨ã¯ç•°ãªã‚Šã€ãã®ãŸã‚ã®å¼·ã„ã‚¤ãƒ³ã‚»ãƒ³ãƒ†ã‚£ãƒ–ãŒã‚ã‚Šã¾ã™ã€‚\n\nä¼æ¥­ã¨ã®é–¢ä¿‚ã¯æ©Ÿä¼šä¸»ç¾©çš„ã«æ‰ãˆã‚‹ã¹ãã§ã‚ã‚Šã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãŒä¾µå®³ã•ã‚Œã¦ã„ã‚‹ã¨æ„Ÿã˜ãŸå ´åˆã«ã¯ã‚µãƒ¼ãƒ“ã‚¹ã‚’åˆ‡ã‚Šæ›¿ãˆã‚‹æº–å‚™ã‚’ã—ã¦ãŠãã¹ãã ã¨è¿°ã¹ã¦ã„ã¾ã™ã€‚\n\næœ€å¾Œã«ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ã€ŒAndroidåŒ–ã€ã«ã¤ã„ã¦è­¦å‘Šã—ã¦ã„ã¾ã™ã€‚ã“ã‚Œã¯é€æ˜æ€§ã‚„ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ãŒå¾ã€…ã«æ¸›å°‘ã™ã‚‹ã“ã¨ã‚’æ„å‘³ã—ã¾ã™ã€‚\n\nè‘—è€…ã¯ã€ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼æ„›å¥½è€…ã«å¯¾ã—ã¦ä¼æ¥­ã‚„ãã®å®Ÿæ…‹ã«å¯¾ã—ã¦ã‚‚ã£ã¨æ‰¹åˆ¤çš„ã«ãªã‚‹ã‚ˆã†ä¿ƒã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿ã®ä¿è­·ã‚’å¼·åŒ–ã—ã€ä¼æ¥­ã«åˆ©ç”¨ã•ã‚Œãªã„å…±é€šã®å ´ã‚’ç¯‰ãã“ã¨ã‚’æå”±ã—ã¦ã„ã¾ã™ã€‚"
    }
  },
  {
    "id": "795871cb15efbc39",
    "title": {
      "en": "Koto Programming Language",
      "ko": "ì½”í†  í”„ë¡œê·¸ë˜ë°",
      "ja": "ã‚³ãƒˆãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°"
    },
    "type": "story",
    "url": "https://koto.dev/",
    "score": 140,
    "by": "virtualritz",
    "time": 1743250488,
    "content": "A lightweight scripting language for Rust applications.\n\n    About\n\n    Docs\n\n    Install\n\n    Playground",
    "summary": {
      "en": "This text introduces a lightweight scripting language designed for Rust applications. It includes sections for more information, documentation, installation instructions, and a playground for trying out the language.",
      "ko": "ì´ í…ìŠ¤íŠ¸ëŠ” Rust ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ìœ„í•´ ì„¤ê³„ëœ ê²½ëŸ‰ ìŠ¤í¬ë¦½íŒ… ì–¸ì–´ë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. ì´ ì–¸ì–´ì— ëŒ€í•œ ì¶”ê°€ ì •ë³´, ë¬¸ì„œ, ì„¤ì¹˜ ë°©ë²•, ê·¸ë¦¬ê³  ì–¸ì–´ë¥¼ ì‹¤í—˜í•´ë³¼ ìˆ˜ ìˆëŠ” ë†€ì´í„° ì„¹ì…˜ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.",
      "ja": "ã“ã®ãƒ†ã‚­ã‚¹ãƒˆã§ã¯ã€Rustã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å‘ã‘ã«è¨­è¨ˆã•ã‚ŒãŸè»½é‡ã‚¹ã‚¯ãƒªãƒ—ãƒˆè¨€èªã«ã¤ã„ã¦ç´¹ä»‹ã—ã¦ã„ã¾ã™ã€‚è©³ç´°æƒ…å ±ã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã€ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ‰‹é †ã€ãã—ã¦è¨€èªã‚’è©¦ã™ãŸã‚ã®ãƒ—ãƒ¬ã‚¤ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚"
    }
  },
  {
    "id": "5a1d47062f052f14",
    "title": {
      "en": "OSS-SEC: Three bypasses of Ubuntu's unprivileged user namespace restrictions",
      "ko": "ìš°ë¶„íˆ¬ ì‚¬ìš©ì ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ìš°íšŒë²• 3ê°€ì§€",
      "ja": "Ubuntuã®è„†å¼±æ€§ç™ºè¦‹"
    },
    "type": "story",
    "url": "https://seclists.org/oss-sec/2025/q1/253",
    "score": 43,
    "by": "birdculture",
    "time": 1743275264,
    "content": "oss-sec\nmailing list archives\n\nBy Date\n\nBy Thread\n\nThree bypasses of Ubuntu's unprivileged user namespace restrictions\n\nFrom: Qualys Security Advisory <qsa () qualys com>\n\nDate: Thu, 27 Mar 2025 17:44:15 +0000\n\nQualys Security Advisory\n\nThree bypasses of Ubuntu's unprivileged user namespace restrictions\n\n========================================================================\nContents\n========================================================================\n\nSummary\nBypass via aa-exec\nBypass via busybox\nBypass via LD_PRELOAD\nAcknowledgments\nTimeline (advisory sent to the Ubuntu Security Team on January 15, 2025)\n\n------------------------------------------------------------------------\n  Prologue, from https://grsecurity.net/10_years_of_linux_security.pdf:\n\n    + February 2013 (v3.8) - Unprivileged User Namespace support added\n      - Greatly increased kernel attack surface, exposed many interfaces\n        that previously saw little security scrutiny\n\n    + Attack surface exposed by unprivileged user namespaces isn't\n      decreasing anytime soon\n      - Even more functionality being exposed\n------------------------------------------------------------------------\n\n========================================================================\nSummary\n========================================================================\n\nUbuntu 23.10 introduced unprivileged user namespace restrictions (the\nsysctl kernel.apparmor_restrict_unprivileged_userns) and Ubuntu 24.04\nenabled them by default. From Alex Murray's excellent blog post at\nhttps://ubuntu.com/blog/whats-new-in-security-for-ubuntu-24-04-lts:\n\n  \"Unprivileged user namespaces are a widely used feature of the Linux\n  kernel, providing additional security isolation for applications, and\n  are often employed as part of a sandbox environment. However, [...]\n  unprivileged user namespaces also expose additional attack surfaces\n  within the Linux kernel. There has been a long history of (ab)use of\n  unprivileged user namespaces to exploit various kernel\n  vulnerabilities.\n\n  For Ubuntu 24.04 LTS, the use of unprivileged user namespaces is then\n  allowed for all applications but access to any additional permissions\n  within the namespace are denied. This allows more applications to more\n  gracefully handle this default restriction whilst still protecting\n  against the abuse of user namespaces to gain access to additional\n  attack surfaces within the Linux kernel.\"\n\nUnfortunately, we discovered three different bypasses of these\nunprivileged user namespace restrictions; each bypass allows a local\nattacker to create user namespaces with full administrator capabilities,\nand therefore to still exploit vulnerabilities in kernel components that\nrequire capabilities such as CAP_SYS_ADMIN or CAP_NET_ADMIN:\n\n- An unprivileged local attacker can simply use the aa-exec tool (which\n  is installed by default on Ubuntu) to transition to one of the many\n  pre-configured AppArmor profiles that do allow the creation of user\n  namespaces with full capabilities (for example, the chrome, flatpak,\n  or trinity profile).\n\n- An unprivileged local attacker can first execute a busybox shell,\n  which is installed by default on Ubuntu, and is one of the programs\n  whose pre-configured AppArmor profile does allow the creation of user\n  namespaces with full capabilities.\n\n- An unprivileged local attacker can LD_PRELOAD a shell into one of the\n  programs whose pre-configured AppArmor profile does allow the creation\n  of user namespaces with full capabilities (for example, nautilus is\n  installed by default on Ubuntu Desktop).\n\nClarification: such a bypass allows an unprivileged user to obtain full\ncapabilities *inside* a namespace, not on the host outside a namespace;\nfor comparison, a bypass is not even needed on most Linux distributions,\nbecause they allow unprivileged users to obtain full capabilities inside\nnamespaces by default (and therefore to exploit CAP_SYS_ADMIN kernel\nvulnerabilities for example), without any restriction at all.\n\nFor more information on these bypasses and user namespace restrictions,\nplease refer to Ubuntu's post at:\n\n  https://discourse.ubuntu.com/t/understanding-apparmor-user-namespace-restriction\n\n========================================================================\nBypass via aa-exec\n========================================================================\n\n    Are we all just algorithms doing what we're supposed to do or can we\n    escape our programming?\n        -- Jude, The Matrix Resurrections\n\nWhile working on needrestart, particularly on commit e17b564 (\"core: fix\nregression of false positives for processes running in chroot or mountns\n(#317)\"), we tried to experiment with user and mount namespaces, but to\nour great surprise we were barred from creating them as an unprivileged\nuser on Ubuntu 24.04 (although kernel.unprivileged_userns_clone is\nenabled by default):\n\n------------------------------------------------------------------------\n$ id\nuid=1001(tiffany) gid=1001(tiffany) groups=1001(tiffany),100(users)\n\n$ unshare -U -r -m /bin/sh\nunshare: write failed /proc/self/uid_map: Operation not permitted\n------------------------------------------------------------------------\n\nThis error message looked very suspicious to us, so we decided to try\nthe userns_child_exec tool (from man user_namespaces) instead of the\npre-installed unshare tool:\n\n------------------------------------------------------------------------\n$ ./userns_child_exec -U -z -m /bin/sh\n\n# id\nuid=0(root) gid=0(root) groups=0(root),65534(nogroup)\n\n# mount --bind /etc/passwd /etc/passwd\nmount: /etc/passwd: bind /etc/passwd failed.\n       dmesg(1) may have more information after failed mount system call.\n------------------------------------------------------------------------\n\nThis time we were able to create a user and mount namespace, but to our\ngrowing surprise we were barred from using any administrator capability\ninside this namespace (our mount command failed). Puzzled, we eventually\nfound out that these restrictions were introduced in Ubuntu 23.10, and\nenabled by default in Ubuntu 24.04, to prevent unprivileged local\nattackers from exploiting kernel vulnerabilities that require\ncapabilities (CAP_SYS_ADMIN, CAP_NET_ADMIN, etc):\n\n  https://discourse.ubuntu.com/t/spec-unprivileged-user-namespace-restrictions-via-apparmor-in-ubuntu-23-10\n\nTo bypass these restrictions, we immediately tried to run unshare\nthrough aa-exec, to transition to one of Ubuntu's many AppArmor profiles\nthat do allow the creation of user namespaces with full capabilities;\nfor example, the trinity profile:\n\n------------------------------------------------------------------------\n$ grep userns /etc/apparmor.d/trinity\n  userns,\n\n$ aa-exec -p trinity -- unshare -U -r -m /bin/sh\n\n# mount --bind /etc/passwd /etc/passwd\n\n# mount\n...\n/dev/sda2 on /etc/passwd type ext4 (rw,relatime)\n------------------------------------------------------------------------\n\nAt last, we were able to create a user namespace with full capabilities\n(our mount command succeeded). We later noticed that a quick fix to this\nparticular bypass was already mentioned on Ubuntu's excellent security\npodcast in October 2023, but unfortunately it was never enabled by\ndefault; from https://ubuntusecuritypodcast.org/episode-211/:\n\n  \"From a defensive security point of view, also is useful to enable an\n  additional sysctl to ensure that anything which is unconfined can't\n  just abuse these profiles by aa-exec'ing themselves via that profile -\n  so then also need to enable the\n  kernel.apparmor_restrict_unprivileged_unconfined = 1 sysctl too\"\n\n========================================================================\nBypass via busybox\n========================================================================\n\n    I'm living inside a computer-generated reality that has imprisoned\n    me... again.\n        -- Thomas, The Matrix Resurrections\n\nLet us now suppose that our bypass via aa-exec is fixed (i.e.,\nkernel.apparmor_restrict_unprivileged_unconfined is enabled): can we\nfind another way to bypass Ubuntu's unprivileged user namespace\nrestrictions?\n\nThe only program that is installed by default on both Ubuntu Server and\nUbuntu Desktop, and whose pre-configured AppArmor profile does allow the\ncreation of user namespaces with full capabilities, is busybox.\n\nWe therefore simply tried to execute unshare through busybox's built-in\nshell, and lo and behold, we were again able to create a user namespace\nwith full capabilities (our mount command succeeded):\n\n------------------------------------------------------------------------\n$ grep userns /etc/apparmor.d/busybox\n  userns,\n\n$ busybox sh\n\n~ $ /usr/bin/unshare -U -r -m /bin/sh\n\n# mount --bind /etc/passwd /etc/passwd\n\n# mount\n...\n/dev/sda2 on /etc/passwd type ext4 (rw,relatime)\n------------------------------------------------------------------------\n\n========================================================================\nBypass via LD_PRELOAD\n========================================================================\n\n    You're going to imprison me after I just got free?\n        -- Neo, The Matrix Resurrections\n\nLet us now suppose that our bypasses via aa-exec and busybox are both\nfixed: can we find another way to bypass Ubuntu's unprivileged user\nnamespace restrictions?\n\nBesides busybox, the only other program that is installed by default on\nUbuntu Desktop, and whose pre-configured AppArmor profile does allow the\ncreation of user namespaces with full capabilities, is nautilus.\n\nAlthough nautilus may or may not provide a shell functionality like\nbusybox, we can actually take a more general approach: we can simply\nLD_PRELOAD a small library into nautilus, which then executes a shell.\nAnd again, we are able to create a user namespace with full capabilities\n(our mount command succeeds):\n\n------------------------------------------------------------------------\n$ grep userns /etc/apparmor.d/nautilus\n  userns,\n\n$ cat > shell.c << \"EOF\"\n#include <unistd.h>\nstatic void __attribute__ ((constructor)) _init (void) {\n    static char * const argv[] = { \"/bin/sh\", NULL };\n    static char * const envp[] = { NULL };\n    execve(*argv, argv, envp);\n    _exit(__LINE__);\n}\nEOF\n\n$ gcc -fpic -shared -o shell.so shell.c\n\n$ LD_PRELOAD=./shell.so /usr/bin/nautilus\n\n$ unshare -U -r -m /bin/sh\n\n# mount --bind /etc/passwd /etc/passwd\n\n# mount\n...\n/dev/sda2 on /etc/passwd type ext4 (rw,relatime)\n------------------------------------------------------------------------\n\n========================================================================\nAcknowledgments\n========================================================================\n\nWe thank the Ubuntu Security Team for their work on this coordinated\nrelease.\n\n========================================================================\nTimeline\n========================================================================\n\n2025-01-15: We sent our advisory to the Ubuntu Security Team.\n\n2025-03-21: We noticed that @roddux (on X/Twitter) independently\ndiscovered and published the busybox bypass.\n\n2025-03-27: Coordinated release.\n\nBy Date\n\nBy Thread\n\nCurrent thread:\n\nThree bypasses of Ubuntu's unprivileged user namespace restrictions Qualys Security Advisory (Mar 27)",
    "summary": {
      "en": "**Summary of Ubuntu's User Namespace Bypasses**\n\nQualys Security Advisory reported three methods to bypass Ubuntu's restrictions on unprivileged user namespaces, which were introduced to enhance security in Ubuntu 23.10 and enabled by default in Ubuntu 24.04. These restrictions aim to prevent unprivileged users from exploiting kernel vulnerabilities.\n\n1. **Bypass via aa-exec**: An attacker can use the `aa-exec` tool to switch to certain AppArmor profiles (like chrome or flatpak) that allow full capabilities, enabling the creation of user namespaces.\n\n2. **Bypass via BusyBox**: The BusyBox shell, which is installed by default, also allows the creation of user namespaces with full capabilities. An attacker can access it to bypass the restrictions.\n\n3. **Bypass via LD_PRELOAD**: By using the LD_PRELOAD mechanism with the Nautilus program, another default application, an attacker can execute a shell that creates user namespaces with full capabilities.\n\nThese bypasses effectively grant unprivileged users administrative capabilities within user namespaces, which can lead to exploitation of kernel vulnerabilities. For more technical details, refer to Ubuntu's discussions on the topic. \n\nThe advisory was sent to the Ubuntu Security Team on January 15, 2025, and a coordinated release of information occurred on March 27, 2025.",
      "ko": "Qualys ë³´ì•ˆ ìë¬¸ì—ì„œëŠ” Ubuntu 23.10ì—ì„œ ë„ì…ëœ ë¹„íŠ¹ê¶Œ ì‚¬ìš©ì ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì— ëŒ€í•œ ì œí•œì„ ìš°íšŒí•  ìˆ˜ ìˆëŠ” ì„¸ ê°€ì§€ ë°©ë²•ì„ ë³´ê³ í–ˆìŠµë‹ˆë‹¤. ì´ ì œí•œì€ Ubuntu 24.04ì—ì„œ ê¸°ë³¸ì ìœ¼ë¡œ í™œì„±í™”ë˜ì–´ ìˆìœ¼ë©°, ë¹„íŠ¹ê¶Œ ì‚¬ìš©ìê°€ ì»¤ë„ ì·¨ì•½ì ì„ ì•…ìš©í•˜ëŠ” ê²ƒì„ ë°©ì§€í•˜ê¸° ìœ„í•´ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.\n\nì²« ë²ˆì§¸ ë°©ë²•ì€ `aa-exec` ë„êµ¬ë¥¼ ì´ìš©í•œ ìš°íšŒì…ë‹ˆë‹¤. ê³µê²©ìëŠ” íŠ¹ì • AppArmor í”„ë¡œí•„(ì˜ˆ: chrome ë˜ëŠ” flatpak)ë¡œ ì „í™˜í•˜ì—¬ ì „ì²´ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ ë˜ì–´ ì‚¬ìš©ì ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\në‘ ë²ˆì§¸ ë°©ë²•ì€ ê¸°ë³¸ì ìœ¼ë¡œ ì„¤ì¹˜ëœ BusyBox ì…¸ì„ ì´ìš©í•œ ìš°íšŒì…ë‹ˆë‹¤. ì´ ì…¸ì€ ì „ì²´ ê¸°ëŠ¥ì„ ê°€ì§„ ì‚¬ìš©ì ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ìƒì„±ì„ í—ˆìš©í•˜ë©°, ê³µê²©ìëŠ” ì´ë¥¼ í†µí•´ ì œí•œì„ ìš°íšŒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nì„¸ ë²ˆì§¸ ë°©ë²•ì€ LD_PRELOAD ë©”ì»¤ë‹ˆì¦˜ì„ Nautilus í”„ë¡œê·¸ë¨ê³¼ í•¨ê»˜ ì‚¬ìš©í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. NautilusëŠ” ë˜ ë‹¤ë¥¸ ê¸°ë³¸ ì• í”Œë¦¬ì¼€ì´ì…˜ìœ¼ë¡œ, ê³µê²©ìëŠ” ì´ë¥¼ í†µí•´ ì „ì²´ ê¸°ëŠ¥ì„ ê°€ì§„ ì‚¬ìš©ì ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë¥¼ ìƒì„±í•˜ëŠ” ì…¸ì„ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nì´ëŸ¬í•œ ìš°íšŒ ë°©ë²•ì€ ë¹„íŠ¹ê¶Œ ì‚¬ìš©ìì—ê²Œ ì‚¬ìš©ì ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ë‚´ì—ì„œ ê´€ë¦¬ ê¶Œí•œì„ ë¶€ì—¬í•˜ê²Œ ë˜ì–´ ì»¤ë„ ì·¨ì•½ì ì„ ì•…ìš©í•  ìˆ˜ ìˆëŠ” ê°€ëŠ¥ì„±ì„ ë†’ì…ë‹ˆë‹¤. ë” ìì„¸í•œ ê¸°ìˆ ì  ë‚´ìš©ì€ Ubuntuì˜ ê´€ë ¨ ë…¼ì˜ë¥¼ ì°¸ê³ í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n\nì´ ìë¬¸ì€ 2025ë…„ 1ì›” 15ì¼ Ubuntu ë³´ì•ˆ íŒ€ì— ì „ë‹¬ë˜ì—ˆìœ¼ë©°, 2025ë…„ 3ì›” 27ì¼ì— ì •ë³´ê°€ ì¡°ì •ë˜ì–´ ê³µê°œë˜ì—ˆìŠµë‹ˆë‹¤.",
      "ja": "Qualys Security Advisoryã¯ã€Ubuntuã®åˆ¶é™ã‚’å›é¿ã™ã‚‹ãŸã‚ã®3ã¤ã®æ–¹æ³•ã‚’å ±å‘Šã—ã¾ã—ãŸã€‚ã“ã‚Œã‚‰ã®åˆ¶é™ã¯ã€Ubuntu 23.10ã§å°å…¥ã•ã‚Œã€Ubuntu 24.04ã§ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§æœ‰åŠ¹ã«ãªã£ã¦ã„ã¾ã™ã€‚ç›®çš„ã¯ã€ç‰¹æ¨©ã®ãªã„ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã‚«ãƒ¼ãƒãƒ«ã®è„†å¼±æ€§ã‚’æ‚ªç”¨ã™ã‚‹ã®ã‚’é˜²ãã“ã¨ã§ã™ã€‚\n\næœ€åˆã®æ–¹æ³•ã¯ã€`aa-exec`ãƒ„ãƒ¼ãƒ«ã‚’åˆ©ç”¨ã™ã‚‹ã‚‚ã®ã§ã™ã€‚æ”»æ’ƒè€…ã¯ç‰¹å®šã®AppArmorãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆä¾‹ãˆã°ã€chromeã‚„flatpakï¼‰ã«åˆ‡ã‚Šæ›¿ãˆã‚‹ã“ã¨ã§ã€å®Œå…¨ãªæ©Ÿèƒ½ã‚’æŒã¤ãƒ¦ãƒ¼ã‚¶ãƒ¼åå‰ç©ºé–“ã‚’ä½œæˆã§ãã¾ã™ã€‚\n\næ¬¡ã«ã€BusyBoxã‚’åˆ©ç”¨ã™ã‚‹æ–¹æ³•ãŒã‚ã‚Šã¾ã™ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹BusyBoxã‚·ã‚§ãƒ«ã‚‚ã€å®Œå…¨ãªæ©Ÿèƒ½ã‚’æŒã¤ãƒ¦ãƒ¼ã‚¶ãƒ¼åå‰ç©ºé–“ã‚’ä½œæˆã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚æ”»æ’ƒè€…ã¯ã“ã‚Œã«ã‚¢ã‚¯ã‚»ã‚¹ã—ã¦åˆ¶é™ã‚’å›é¿ã§ãã¾ã™ã€‚\n\næœ€å¾Œã®æ–¹æ³•ã¯ã€LD_PRELOADãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’ä½¿ç”¨ã—ã¦Nautilusãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’åˆ©ç”¨ã™ã‚‹ã‚‚ã®ã§ã™ã€‚ã“ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ãŠã‚Šã€æ”»æ’ƒè€…ã¯å®Œå…¨ãªæ©Ÿèƒ½ã‚’æŒã¤ãƒ¦ãƒ¼ã‚¶ãƒ¼åå‰ç©ºé–“ã‚’ä½œæˆã™ã‚‹ã‚·ã‚§ãƒ«ã‚’å®Ÿè¡Œã§ãã¾ã™ã€‚\n\nã“ã‚Œã‚‰ã®å›é¿ç­–ã«ã‚ˆã‚Šã€ç‰¹æ¨©ã®ãªã„ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒãƒ¦ãƒ¼ã‚¶ãƒ¼åå‰ç©ºé–“å†…ã§ç®¡ç†è€…ã®æ¨©é™ã‚’æŒã¤ã“ã¨ãŒã§ãã€ã‚«ãƒ¼ãƒãƒ«ã®è„†å¼±æ€§ã‚’æ‚ªç”¨ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚è©³ç´°ãªæŠ€è¡“æƒ…å ±ã«ã¤ã„ã¦ã¯ã€Ubuntuã®é–¢é€£ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚\n\nã“ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒªãƒ¼ã¯2025å¹´1æœˆ15æ—¥ã«Ubuntuã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒãƒ¼ãƒ ã«é€ä¿¡ã•ã‚Œã€2025å¹´3æœˆ27æ—¥ã«æƒ…å ±ãŒå…±åŒã§å…¬é–‹ã•ã‚Œã¾ã—ãŸã€‚"
    }
  },
  {
    "id": "660830ccbaefe1c9",
    "title": {
      "en": "Vramfs: Vram Based Filesystem for Linux",
      "ko": "ë¸Œë¨FS: ë¦¬ëˆ…ìŠ¤ìš© VRAM íŒŒì¼ ì‹œìŠ¤í…œ",
      "ja": "Vramfs: Linuxã®æ–°ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ "
    },
    "type": "story",
    "url": "https://github.com/Overv/vramfs",
    "score": 86,
    "by": "signa11",
    "time": 1743270672,
    "content": "vramfs\nUnused RAM is wasted RAM, so why not put some of that VRAM in your graphics card\nto work?\nvramfs is a utility that uses the FUSE library\nto create a file system in VRAM. The idea is pretty much the same as a ramdisk,\nexcept that it uses the video RAM of a discrete graphics card to store\nfiles. It is not intented for serious use, but it does actually work fairly\nwell, especially since consumer GPUs with 4GB or more VRAM are now available.\nOn the developer's system, the continuous read performance is ~2.4 GB/s and\nwrite performance 2.0 GB/s, which is about 1/3 of what is achievable with a\nramdisk. That is already decent enough for a device not designed for large data\ntransfers to the host, but future development should aim to get closer to the\nPCI-e bandwidth limits. See the benchmarks section for more info.\nRequirements\n\nLinux with kernel 2.6+\nFUSE development files\nA graphics card with support for OpenCL 1.2\n\nBuilding\nFirst, install the OpenCL driver for your graphics card and verify that it's\nrecognized as an OpenCL device by running clinfo. Then install the libfuse3-dev\npackage or build it from source. You will also need pkg-config and OpenCL\ndevelopment files, (opencl-dev, opencl-clhpp-headers package or equivalent),\nwith version 1.2 of the OpenCL headers at least.\nJust run make to build vramfs.\nIf you want to debug with valgrind, you should compile with the minimal fake\nOpenCL implementation to avoid filling your screen with warnings caused by the\nOpenCL driver:\n\nvalgrind: make DEBUG=1\n\nMounting\nMount a disk by running bin/vramfs <mountdir> <size>. The mountdir can be\nany empty directory. The size is the disk size in bytes. For more information,\nrun bin/vramfs without arguments.\nThe recommended maximum size of a vramdisk is 50% of your VRAM. If you go over\nthat, your driver or system may become unstable because it has to start\nswapping. For example, webpages in Chrome will stop rendering properly.\nIf the disk has been inactive for a while, the graphics card will likely lower\nits memory clock, which means it'll take a second to get up to speed again.\nImplementation\nThe FUSE library is used to implement vramfs as a user space file system. This\neases development and makes working with APIs such as OpenCL straightforward.\nBasic architecture\n\nWhen the program is started, it checks for an OpenCL capable GPU and attempts to\nallocate the specified amount of memory. Once the memory has been allocated, the\nroot entry object is created and a global reference to it is stored.\nFUSE then forwards calls like stat, readdir and write to the file system\nfunctions. These will then locate the entry through the root entry using the\nspecified path. The required operations will then be performed on the entry\nobject. If the entry is a file object, the operation may lead to OpenCL\ncvEnqueueReadBuffer or cvEnqueueWriteBuffer calls to manipulate the data.\nWhen a file is created or opened, a file_session object is created to store\nthe reference to the file object and any other data that is persistent between\nan fopen and fclose call.\nVRAM block allocation\nOpenCL is used to allocate blocks of memory on the graphics card by creating\nbuffer objects. When a new disk is mounted, a pool of disk size / block size\nbuffers is created and initialised with zeros. That is not just a good practice,\nbut it's also required with some OpenCL drivers to check if the VRAM required\nfor the block is actually available. Unfortunately Nvidia cards don't support\nOpenCL 1.2, which means the cvEnqueueFillBuffer call has to be simulated by\ncopying from a preallocated buffer filled with zeros. Somewhat interestingly, it\ndoesn't seem to make a difference in performance on cards that support both.\nWrites to blocks are generally asynchronous, whereas reads are synchronous.\nLuckily, OpenCL guarantees in-order execution of commands by default, which\nmeans reads of a block will wait for the writes to complete. OpenCL 1.1 is\ncompletely thread safe, so no special care is required when sending commands.\nBlock objects are managed using a shared_ptr so that they can automatically\nreinsert themselves into the pool on deconstruction.\nFile system\nThe file system is a tree of entry_t objects with members for attributes like\nthe parent directory, mode and access time. Each type of entry has its own\nsubclass that derives from it: file_t, dir_t and symlink_t. The main file\nthat implements all of the FUSE callbacks has a permanent reference to the root\ndirectory entry.\nThe file_t class contains extra write, read and size methods and manages\nthe blocks to store the file data.\nThe dir_t class has an extra unordered_map that maps names to entry_t\nreferences for quick child lookup using its member function find.\nFinally, the symlink_t class has an extra target string member that stores\nthe pointer of the symlink.\nAll of the entry objects are also managed using shared_ptr so that an object\nand its data (e.g. file blocks) are automatically deallocated when they're\nunlinked and no process holds a file handle to them anymore. This can also be\nused to easily implement hard links later on.\nThe classes use getter/setter functions to automatically update the access,\nmodification and change times at the appropriate moment. For example, calling\nthe children member function of dir_t changes the access time and change\ntime of the directory.\nThread safety\nUnfortunately most of the operations are not thread safe, so all of the FUSE\ncallbacks share a mutex to ensure that only one thread is mutating the file\nsystem at a time. The exceptions are read and write, which will temporarily\nrelease the lock while waiting for a read or write to complete.\nBenchmarks\nThe system used for testing has the following specifications:\n\nOS: Ubuntu 14.04.01 LTS (64 bit)\nCPU: Intel Core i5-2500K @ 4.0 Ghz\nRAM: 8GB DDR3-1600\nGPU: AMD R9 290 4GB (Sapphire Tri-X)\n\nPerformance of continuous read, write and write+sync has been measured for\ndifferent block allocation sizes by creating a new 2GiB disk for each new size\nand reading/writing a 2GiB file.\nThe disk is created using:\nbin/vramfs /tmp/vram 2G\n\nAnd the file is written and read using the dd command:\n# write\ndd if=/dev/zero of=/tmp/vram/test bs=128K count=16000\n\n# write+sync\ndd if=/dev/zero of=/tmp/vram/test bs=128K count=16000 conv=fdatasync\n\n# read\ndd if=/tmp/vram/test of=/dev/null bs=128K count=16000\n\nThese commands were repeated 5 times for each block size and then averaged to\nproduce the results shown in the graph. No block sizes lower than 32KiB could\nbe tested because the driver would fail to allocate that many OpenCL buffers.\nThis may be solved in the future by using subbuffers.\n\nAlthough 128KiB blocks offers the highest performance, 64KiB may be preferable\nbecause of the lower space overhead.\nFuture ideas\n\nImplement RAID-0 for SLI/Crossfire setups\n\nLicense\nThe MIT License (MIT)\n\nCopyright (c) 2014 Alexander Overvoorde\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to\ndeal in the Software without restriction, including without limitation the\nrights to use, copy, modify, merge, publish, distribute, sublicense, and/or\nsell copies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\nFROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\nIN THE SOFTWARE.",
    "summary": {
      "en": "**Summary of vramfs**\n\nvramfs is a utility that allows you to use some of the unused VRAM (Video RAM) on your graphics card as a temporary file storage system, similar to a ramdisk but specifically for VRAM. It is a proof-of-concept tool and works well with modern graphics cards that have 4GB or more VRAM.\n\n**Key Features:**\n- **Performance:** It offers decent read speeds (~2.4 GB/s) and write speeds (2.0 GB/s), though these are lower than traditional ramdisks.\n- **System Requirements:** It runs on Linux with kernel 2.6 or higher, needs FUSE development files, and a GPU that supports OpenCL 1.2.\n- **Installation:** Requires installation of OpenCL drivers, libfuse3-dev, and other development files. You can build it by running `make`.\n- **Usage:** You can mount a VRAM disk with a command that specifies the mount directory and size. A recommended maximum size is 50% of your total VRAM to avoid system instability.\n\n**Implementation Details:**\n- Uses the FUSE library to create a user-space file system, making it easier to work with OpenCL.\n- Allocates memory on the GPU to create a disk and manages files as entry objects, allowing for basic file operations.\n- Not fully thread-safe, but read and write operations temporarily release locks to prevent blocking.\n\n**Performance Testing:**\n- Benchmarks show that 128KB block sizes yield the best performance, while 64KB blocks may be more efficient due to lower overhead.\n\n**Future Development:**\n- Plans to implement RAID-0 for systems with multiple GPUs.\n\n**License:** The software is released under the MIT License, allowing free use and modification. \n\nOverall, vramfs is a novel way to utilize VRAM for file storage, though it is primarily a developmental tool rather than for serious data transfer needs.",
      "ko": "vramfsëŠ” ê·¸ë˜í”½ ì¹´ë“œì˜ ì‚¬ìš©ë˜ì§€ ì•ŠëŠ” VRAM(ë¹„ë””ì˜¤ RAM)ì„ ì„ì‹œ íŒŒì¼ ì €ì¥ ì‹œìŠ¤í…œìœ¼ë¡œ í™œìš©í•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” ìœ í‹¸ë¦¬í‹°ì…ë‹ˆë‹¤. ì´ëŠ” ë¨ë””ìŠ¤í¬ì™€ ìœ ì‚¬í•˜ì§€ë§Œ VRAMì— íŠ¹í™”ëœ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤. ì´ ë„êµ¬ëŠ” ê°œë… ì¦ëª…ìš©ìœ¼ë¡œ ê°œë°œë˜ì—ˆìœ¼ë©°, 4GB ì´ìƒì˜ VRAMì„ ê°€ì§„ ìµœì‹  ê·¸ë˜í”½ ì¹´ë“œì—ì„œ ì˜ ì‘ë™í•©ë‹ˆë‹¤.\n\nì£¼ìš” íŠ¹ì§•ìœ¼ë¡œëŠ” ì„±ëŠ¥ì´ ìˆìŠµë‹ˆë‹¤. ì½ê¸° ì†ë„ëŠ” ì•½ 2.4GB/s, ì“°ê¸° ì†ë„ëŠ” 2.0GB/së¡œ, ì „í†µì ì¸ ë¨ë””ìŠ¤í¬ë³´ë‹¤ëŠ” ë‚®ì§€ë§Œ ê´œì°®ì€ ìˆ˜ì¤€ì…ë‹ˆë‹¤. ì‹œìŠ¤í…œ ìš”êµ¬ ì‚¬í•­ìœ¼ë¡œëŠ” ë¦¬ëˆ…ìŠ¤ ì»¤ë„ 2.6 ì´ìƒì—ì„œ ì‹¤í–‰ë˜ë©°, FUSE ê°œë°œ íŒŒì¼ê³¼ OpenCL 1.2ë¥¼ ì§€ì›í•˜ëŠ” GPUê°€ í•„ìš”í•©ë‹ˆë‹¤. ì„¤ì¹˜ë¥¼ ìœ„í•´ì„œëŠ” OpenCL ë“œë¼ì´ë²„, libfuse3-dev ë° ê¸°íƒ€ ê°œë°œ íŒŒì¼ì„ ì„¤ì¹˜í•´ì•¼ í•˜ë©°, `make` ëª…ë ¹ì–´ë¡œ ë¹Œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. VRAM ë””ìŠ¤í¬ë¥¼ ë§ˆìš´íŠ¸í•  ë•ŒëŠ” ë§ˆìš´íŠ¸í•  ë””ë ‰í† ë¦¬ì™€ í¬ê¸°ë¥¼ ì§€ì •í•˜ëŠ” ëª…ë ¹ì–´ë¥¼ ì‚¬ìš©í•˜ë©°, ì‹œìŠ¤í…œ ë¶ˆì•ˆì •ì„ í”¼í•˜ê¸° ìœ„í•´ ìµœëŒ€ í¬ê¸°ëŠ” ì´ VRAMì˜ 50%ë¡œ ê¶Œì¥ë©ë‹ˆë‹¤.\n\nêµ¬í˜„ ì„¸ë¶€ ì‚¬í•­ìœ¼ë¡œëŠ” FUSE ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ì ê³µê°„ íŒŒì¼ ì‹œìŠ¤í…œì„ ìƒì„±í•˜ê³  OpenCLê³¼ì˜ ì‘ì—…ì„ ìš©ì´í•˜ê²Œ í•©ë‹ˆë‹¤. GPUì—ì„œ ë©”ëª¨ë¦¬ë¥¼ í• ë‹¹í•˜ì—¬ ë””ìŠ¤í¬ë¥¼ ìƒì„±í•˜ê³ , íŒŒì¼ì„ ì—”íŠ¸ë¦¬ ê°ì²´ë¡œ ê´€ë¦¬í•˜ì—¬ ê¸°ë³¸ì ì¸ íŒŒì¼ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì™„ì „íˆ ìŠ¤ë ˆë“œ ì•ˆì „í•˜ì§€ëŠ” ì•Šì§€ë§Œ, ì½ê¸° ë° ì“°ê¸° ì‘ì—… ì‹œ ì ê¸ˆì„ ì¼ì‹œì ìœ¼ë¡œ í•´ì œí•˜ì—¬ ë¸”ë¡œí‚¹ì„ ë°©ì§€í•©ë‹ˆë‹¤.\n\nì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ê²°ê³¼, 128KB ë¸”ë¡ í¬ê¸°ê°€ ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì´ë©°, 64KB ë¸”ë¡ì´ ë” ë‚®ì€ ì˜¤ë²„í—¤ë“œë¡œ ì¸í•´ ë” íš¨ìœ¨ì ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. í–¥í›„ ê°œë°œ ê³„íšìœ¼ë¡œëŠ” ì—¬ëŸ¬ GPUë¥¼ ê°€ì§„ ì‹œìŠ¤í…œì„ ìœ„í•œ RAID-0 êµ¬í˜„ì´ ìˆìŠµë‹ˆë‹¤.\n\nì´ ì†Œí”„íŠ¸ì›¨ì–´ëŠ” MIT ë¼ì´ì„ ìŠ¤ í•˜ì— ë°°í¬ë˜ì–´ ììœ ë¡­ê²Œ ì‚¬ìš©í•˜ê³  ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì „ë°˜ì ìœ¼ë¡œ vramfsëŠ” VRAMì„ íŒŒì¼ ì €ì¥ì— í™œìš©í•˜ëŠ” ìƒˆë¡œìš´ ë°©ë²•ì´ì§€ë§Œ, ì£¼ë¡œ ê°œë°œ ë„êµ¬ë¡œì„œ ì‹¬ê°í•œ ë°ì´í„° ì „ì†¡ í•„ìš”ì—ëŠ” ì í•©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.",
      "ja": "vramfsã¯ã€ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚«ãƒ¼ãƒ‰ã®æœªä½¿ç”¨ã®VRAMï¼ˆãƒ“ãƒ‡ã‚ªRAMï¼‰ã‚’ä¸€æ™‚çš„ãªãƒ•ã‚¡ã‚¤ãƒ«ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚·ã‚¹ãƒ†ãƒ ã¨ã—ã¦åˆ©ç”¨ã§ãã‚‹ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã§ã™ã€‚ã“ã‚Œã¯ã€ramdiskã«ä¼¼ã¦ã„ã¾ã™ãŒã€ç‰¹ã«VRAMç”¨ã«è¨­è¨ˆã•ã‚Œã¦ã„ã¾ã™ã€‚ã“ã®ãƒ„ãƒ¼ãƒ«ã¯æ¦‚å¿µå®Ÿè¨¼ã®ã‚‚ã®ã§ã€4GBä»¥ä¸Šã®VRAMã‚’æŒã¤æœ€æ–°ã®ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚«ãƒ¼ãƒ‰ã§ã†ã¾ãæ©Ÿèƒ½ã—ã¾ã™ã€‚\n\nä¸»ãªç‰¹å¾´ã¨ã—ã¦ã¯ã€ã¾ãšãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒã‚ã‚Šã¾ã™ã€‚èª­ã¿å–ã‚Šé€Ÿåº¦ã¯ç´„2.4GB/sã€æ›¸ãè¾¼ã¿é€Ÿåº¦ã¯2.0GB/sã§ã€å¾“æ¥ã®ramdiskã‚ˆã‚Šã¯åŠ£ã‚Šã¾ã™ãŒã€ã¾ãšã¾ãšã®é€Ÿåº¦ã§ã™ã€‚ã‚·ã‚¹ãƒ†ãƒ è¦ä»¶ã¨ã—ã¦ã¯ã€Linuxã®ã‚«ãƒ¼ãƒãƒ«2.6ä»¥ä¸ŠãŒå¿…è¦ã§ã€FUSEã®é–‹ç™ºãƒ•ã‚¡ã‚¤ãƒ«ã¨OpenCL 1.2ã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹GPUãŒæ±‚ã‚ã‚‰ã‚Œã¾ã™ã€‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã«ã¯OpenCLãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã€libfuse3-devã€ãã®ä»–ã®é–‹ç™ºãƒ•ã‚¡ã‚¤ãƒ«ãŒå¿…è¦ã§ã€`make`ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã™ã‚‹ã“ã¨ã§ãƒ“ãƒ«ãƒ‰ã§ãã¾ã™ã€‚ä½¿ç”¨æ–¹æ³•ã¯ã€ãƒã‚¦ãƒ³ãƒˆã™ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¨ã‚µã‚¤ã‚ºã‚’æŒ‡å®šã™ã‚‹ã‚³ãƒãƒ³ãƒ‰ã‚’ä½¿ã£ã¦VRAMãƒ‡ã‚£ã‚¹ã‚¯ã‚’ãƒã‚¦ãƒ³ãƒˆã—ã¾ã™ã€‚ã‚·ã‚¹ãƒ†ãƒ ã®å®‰å®šæ€§ã‚’ä¿ã¤ãŸã‚ã«ã€æ¨å¥¨ã•ã‚Œã‚‹æœ€å¤§ã‚µã‚¤ã‚ºã¯ç·VRAMã®50%ã§ã™ã€‚\n\nå®Ÿè£…ã®è©³ç´°ã¨ã—ã¦ã¯ã€FUSEãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ã—ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¹ãƒšãƒ¼ã‚¹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã‚’ä½œæˆã—ã€OpenCLã¨ã®é€£æºã‚’å®¹æ˜“ã«ã—ã¦ã„ã¾ã™ã€‚GPUä¸Šã«ãƒ¡ãƒ¢ãƒªã‚’å‰²ã‚Šå½“ã¦ã¦ãƒ‡ã‚£ã‚¹ã‚¯ã‚’ä½œæˆã—ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¨ãƒ³ãƒˆãƒªã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¨ã—ã¦ç®¡ç†ã™ã‚‹ã“ã¨ã§ã€åŸºæœ¬çš„ãªãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œãŒå¯èƒ½ã§ã™ã€‚å®Œå…¨ã«ã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•ã§ã¯ã‚ã‚Šã¾ã›ã‚“ãŒã€èª­ã¿å–ã‚ŠãŠã‚ˆã³æ›¸ãè¾¼ã¿æ“ä½œä¸­ã«ä¸€æ™‚çš„ã«ãƒ­ãƒƒã‚¯ã‚’è§£é™¤ã™ã‚‹ã“ã¨ã§ãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°ã‚’é˜²ã„ã§ã„ã¾ã™ã€‚\n\nãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆã§ã¯ã€128KBã®ãƒ–ãƒ­ãƒƒã‚¯ã‚µã‚¤ã‚ºãŒæœ€ã‚‚è‰¯ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã€64KBã®ãƒ–ãƒ­ãƒƒã‚¯ã¯ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ãŒå°‘ãªã„ãŸã‚ã€ã‚ˆã‚ŠåŠ¹ç‡çš„ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚\n\nä»Šå¾Œã®é–‹ç™ºè¨ˆç”»ã¨ã—ã¦ã¯ã€è¤‡æ•°ã®GPUã‚’æŒã¤ã‚·ã‚¹ãƒ†ãƒ å‘ã‘ã«RAID-0ã®å®Ÿè£…ãŒäºˆå®šã•ã‚Œã¦ã„ã¾ã™ã€‚\n\nãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯MITãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã®ã‚‚ã¨ã§å…¬é–‹ã•ã‚Œã¦ãŠã‚Šã€è‡ªç”±ã«ä½¿ç”¨ã‚„æ”¹å¤‰ãŒå¯èƒ½ã§ã™ã€‚å…¨ä½“ã¨ã—ã¦ã€vramfsã¯VRAMã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã¨ã—ã¦æ´»ç”¨ã™ã‚‹æ–°ã—ã„æ–¹æ³•ã§ã™ãŒã€ä¸»ã«é–‹ç™ºãƒ„ãƒ¼ãƒ«ã¨ã—ã¦ã®ä½ç½®ã¥ã‘ã§ã‚ã‚Šã€çœŸå‰£ãªãƒ‡ãƒ¼ã‚¿è»¢é€ãƒ‹ãƒ¼ã‚ºã«ã¯å‘ã„ã¦ã„ã¾ã›ã‚“ã€‚"
    }
  },
  {
    "id": "71dfc352216f3af1",
    "title": {
      "en": "Show HN: Physical Pomodoro Timer with ESP32 and e-paper screen",
      "ko": "ESP32 ì „ì íƒ€ì´ë¨¸",
      "ja": "ESP32ã§ä½œã‚‹ï¼ç‰©ç†ãƒãƒ¢ãƒ‰ãƒ¼ãƒ­ã‚¿ã‚¤ãƒãƒ¼"
    },
    "type": "story",
    "url": "https://github.com/Rukenshia/pomodoro",
    "score": 279,
    "by": "rukenshia",
    "time": 1743244946,
    "content": "This is the repository for an ESP32 based focus timer. It uses an ePaper display and a rotary dial for input.\nThe code in this repository will not be ready-to-use, as some assets and fonts have been removed. However, if you really want to you should be able to adapt the code to your needs.\nParts List\n\nESP32 (I used an AZDelivery ESP32 NodeMCU)\nWaveShare 4.26inch e-Paper display HAT, 800x480 (link)\nKY-040 rotary encoder with button\nA single WS2812 LED (could be replaced with a simple RGB LED)A\nA USB-C connector (like this one)\n3d printed case (onshape file)\nSome resistors and 0.1uF capacitors\n\nProject Origin\nI love trying out different productivity techniques - some say that the quest to optimize your productivity is the ultimate procrastination method, so maybe that is what drove me to this project. I also have a habit of committing time (around a month of work outside my normal job) once a year to a project that benefits someone else. Last year, I bought a 3D printer (BambuLab X1C) and wanted to put it to good use. I have previously finished an apprenticeship as an electronics\nengineer before pivoting to software engineering, so I also wanted to come back to my roots and build something physical.\nMy friend struggles with time management throughout the day sometimes - lots of different tasks to organize, and little focus. So I thought to myself: Why not make them a focus timer? So, I set out with a few goals:\n\nIt should be a physical device\nIt should be fun\nIt should be intuitive to use\n\nThere are some cool projects out there (arguably much cooler than this, for example the Focus Dial by Salim Benbouziyane), but I wanted to build something from scratch. I also\nnever built something with an ePaper display and thought it might be a good fit for something that is mostly idling and doesn't require a backlight.\nWhy these parts?\nThis was my second dive back into building things with microcontrollers in a long time. I knew ESP32 well enough to feel comfortable diving back in, so that was the main choice here. I did some research before to see what kinds of displays would be supported.\nePaper Display\nI needed some sort of display, or at least I wanted some sort of display. One of the main motivations for this project was that it should be out of your way - until it is time to finish your current focus and move on. For me, this meant that I wanted a display without any backlight.\nThe display should also be large enough that you can put the whole device somewhere on your desk and still be able to read it. After ordering and playing around with a few WaveShare ePaper displays, I settled on the 4.26\" variant for multiple reasons:\n\nGreat resolution (which seems to be really hard to find for \"hobbyist\" displays)\nThe size felt right\nThe display supports partial refreshes (0.3s, no distracting \"black and white flashes\" while refreshing)\n\nInitially, I really wanted to use a black/white/red display and found one that I liked, but the refresh time\nwas a whopping 16 seconds with no support for partial refreshes which was a dealbreaker for me.\nThe final bonus feature: it won't work at night. If your desk is not bright enough, you won't be able to read the display. This is a feature, not a bug. Too dark outside? Stop working already!\nRotary Encoder\nFrom the start, I knew that I wanted some sort of dial as an input - it made the most sense to me. This came at the cost of some complexity when designing the menus, and you really need to make sure that you debounce the input correctly. I also added .1uF capacitors to the CLK and DT pins to help with smoothing out the signal.\nLED\nIn the first few iterations, there was no plan for an LED. My genius plan of having a display without backlight came at a cost: it could be too subtle when your current focus time ended. I experimented with a few different ideas:\n\nA buzzer: this would just make you jump. A truly horrible experience\nSpeakers: I don't know why, but speakers felt hard. So much noise and whining with the setup I tried, but I will blame this on a skill issue\nLED: I had some WS2812 LEDs lying around and thought they might be a good fit. You can animate them with the NeoPixel library, and they are really easy to use. The additional benefit of not needing to commit many more output pins was also a big plus\n\nThe LED ended up working great, allowing me to display different states. It might be subtle, but I also added a little shroud to the case and added a diffusion layer in front of the LED to make it look nicer.\nBuilding the Case\nThe case comes in two parts: the base and a lid. One unfortunate design choice I made is that the display frame is printed as one piece as part of the base, so the top edge tends to warp a little bit during printing. Since CAD (or product design) isn't my strongest suit, there will certainly be better choices to design this for a better final look.\nOne thing that I wished I learned earlier is that it might not have been the best idea to put the dial in the front: because the print and electronics are so lightweight, pressing the switch on the dial will tend to just slide the whole device back. Luckily, I could solve this by adding some rubber feet and weights (the ones usually used to balance tires) to the bottom of the case. This worked out great, and I am happy with how it turned out.\nSoftware\nThe software is written in C++ and uses the Arduino framework. I used PlatformIO to manage the project (at least that is what seemed to be a popular choice, but I am not so sure about that anymore). This project relies heavily\non the GxEPD2 library for the display. I won't lie, the code in this repository is a bit of a mess - I had to get things done in time, which led to quite a bit of copy and pasting and not revisiting earlier parts of the code.\nSome parts were generated by AI (Claude, for the most part) to help me finish the project in the deadline I set myself.\n\nSince this was a project for my friend, I also wanted to include some easter eggs and fun. You would think that adding some random facts while you are supposed to be focused would be a bad idea, but I think it is a fun little addition.\nUsing the Device\nWhen the device starts up, you can either change some settings or go into preset selection mode. From there, you can choose one of three presets:\n\nThe timer will then start and let you know once the time is up (by flashing the LED and displaying a message on the screen). You can keep working (not recommended, but necessary if you want to finish something) and then start the break.\n\nDuring the pause, you can view some statistics. Every few iterations (4 by default), your pause will be longer to give you some time to recover.\n\nDevelopment\nPin Mapping\nRotary Encoder (KY-040)\n\nPIN\n#\n\nCLK\n32\n\nDT\n21\n\nSW\n14\n\nePaper Display (GxEPD2_426_GDEQ0426T82, WaveShare 4.26\" b/w)\n\nPIN\n#\n\nBUSY\n4\n\nRST\n16\n\nDC\n17\n\nCS\n5\n\nCLK\n18\n\nDIN\n23\n\nLED (WS2812)\n\nPIN\n#\n\nDIN\n25",
    "summary": {
      "en": "This project is about creating a focus timer using an ESP32 microcontroller, an ePaper display, and a rotary dial. The code provided is not fully ready to use, as some components and fonts are missing, but it can be adapted for personal needs.\n\n### Key Components:\n- **ESP32 Microcontroller**: The main component used.\n- **ePaper Display**: A 4.26-inch screen chosen for its good resolution and low power consumption, which refreshes quickly.\n- **Rotary Encoder**: Used for input, allowing easy navigation through the timer settings.\n- **LED**: A WS2812 LED is included to signal when focus time ends, providing a subtle alert.\n- **USB-C Connector**: For power.\n- **3D Printed Case**: Designed to house all components.\n\n### Project Motivation:\nThe creator wanted to help a friend with time management by building an intuitive, physical focus timer. This project combines a love for productivity, electronics, and software engineering.\n\n### Design Considerations:\n- The display is designed to be visible only in bright light to encourage breaks when itâ€™s dark.\n- The rotary dial adds complexity but makes the device user-friendly.\n- The LED provides visual feedback without being disruptive.\n- The case was designed to be functional, though some adjustments were made for usability.\n\n### Software:\nThe code is written in C++ using the Arduino framework, utilizing the GxEPD2 library for the display. The software includes settings for different timer presets and some fun features like random facts.\n\n### Usage:\nUpon startup, users can select a preset timer. The device notifies when time is up with a flashing LED and a message. A break follows, during which users can view statistics.\n\n### Conclusion:\nThis project blends hardware and software to create a unique focus timer, aiming to enhance productivity in a fun and user-friendly way.",
      "ko": "ì´ í”„ë¡œì íŠ¸ëŠ” ESP32 ë§ˆì´í¬ë¡œì»¨íŠ¸ë¡¤ëŸ¬, ePaper ë””ìŠ¤í”Œë ˆì´, íšŒì „ ë‹¤ì´ì–¼ì„ ì‚¬ìš©í•˜ì—¬ ì§‘ì¤‘ íƒ€ì´ë¨¸ë¥¼ ë§Œë“œëŠ” ê²ƒì…ë‹ˆë‹¤. ì œê³µëœ ì½”ë“œëŠ” ì™„ì „íˆ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ìƒíƒœëŠ” ì•„ë‹ˆë©°, ì¼ë¶€ êµ¬ì„± ìš”ì†Œì™€ ê¸€ê¼´ì´ ëˆ„ë½ë˜ì–´ ìˆì§€ë§Œ ê°œì¸ì˜ í•„ìš”ì— ë§ê²Œ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nì£¼ìš” êµ¬ì„± ìš”ì†Œë¡œëŠ” ESP32 ë§ˆì´í¬ë¡œì»¨íŠ¸ë¡¤ëŸ¬ê°€ ìˆìœ¼ë©°, ì´ëŠ” ì´ í”„ë¡œì íŠ¸ì˜ í•µì‹¬ ë¶€í’ˆì…ë‹ˆë‹¤. ePaper ë””ìŠ¤í”Œë ˆì´ëŠ” í•´ìƒë„ê°€ ì¢‹ê³  ì „ë ¥ ì†Œëª¨ê°€ ì ìœ¼ë©° ë¹ ë¥´ê²Œ ìƒˆë¡œ ê³ ì¹¨ë˜ëŠ” 4.26ì¸ì¹˜ í™”ë©´ìœ¼ë¡œ ì„ íƒë˜ì—ˆìŠµë‹ˆë‹¤. íšŒì „ ì¸ì½”ë”ëŠ” ì…ë ¥ ì¥ì¹˜ë¡œ ì‚¬ìš©ë˜ì–´ íƒ€ì´ë¨¸ ì„¤ì •ì„ ì‰½ê²Œ íƒìƒ‰í•  ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤. WS2812 LEDê°€ í¬í•¨ë˜ì–´ ìˆì–´ ì§‘ì¤‘ ì‹œê°„ì´ ëë‚¬ì„ ë•Œ ë¯¸ì„¸í•œ ì•Œë¦¼ì„ ì œê³µí•©ë‹ˆë‹¤. USB-C ì»¤ë„¥í„°ëŠ” ì „ì› ê³µê¸‰ì„ ìœ„í•´ ì‚¬ìš©ë˜ë©°, ëª¨ë“  êµ¬ì„± ìš”ì†Œë¥¼ ìˆ˜ë‚©í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„ëœ 3D í”„ë¦°íŠ¸ ì¼€ì´ìŠ¤ë„ ìˆìŠµë‹ˆë‹¤.\n\ní”„ë¡œì íŠ¸ì˜ ë™ê¸°ëŠ” ì°½ì‘ìê°€ ì¹œêµ¬ì˜ ì‹œê°„ ê´€ë¦¬ë¥¼ ë•ê¸° ìœ„í•´ ì§ê´€ì ì¸ ë¬¼ë¦¬ì  ì§‘ì¤‘ íƒ€ì´ë¨¸ë¥¼ ë§Œë“¤ê³ ì í–ˆìŠµë‹ˆë‹¤. ì´ í”„ë¡œì íŠ¸ëŠ” ìƒì‚°ì„±, ì „ìê¸°ê¸°, ì†Œí”„íŠ¸ì›¨ì–´ ê³µí•™ì— ëŒ€í•œ ì‚¬ë‘ì„ ê²°í•©í•œ ê²ƒì…ë‹ˆë‹¤.\n\në””ìì¸ ì¸¡ë©´ì—ì„œëŠ” ë””ìŠ¤í”Œë ˆì´ê°€ ë°ì€ ë¹›ì—ì„œë§Œ ë³´ì´ë„ë¡ ì„¤ê³„ë˜ì–´ ì–´ë‘ìš´ ê³³ì—ì„œëŠ” íœ´ì‹ì„ ìœ ë„í•©ë‹ˆë‹¤. íšŒì „ ë‹¤ì´ì–¼ì€ ë³µì¡ì„±ì„ ë”í•˜ì§€ë§Œ ì‚¬ìš©ì ì¹œí™”ì ì¸ ì¥ì¹˜ë¡œ ë§Œë“­ë‹ˆë‹¤. LEDëŠ” ë°©í•´ê°€ ë˜ì§€ ì•Šìœ¼ë©´ì„œ ì‹œê°ì ì¸ í”¼ë“œë°±ì„ ì œê³µí•©ë‹ˆë‹¤. ì¼€ì´ìŠ¤ëŠ” ê¸°ëŠ¥ì„±ì„ ê³ ë ¤í•˜ì—¬ ì„¤ê³„ë˜ì—ˆì§€ë§Œ ì‚¬ìš©ì„±ì„ ìœ„í•´ ì¼ë¶€ ì¡°ì •ì´ ì´ë£¨ì–´ì¡ŒìŠµë‹ˆë‹¤.\n\nì†Œí”„íŠ¸ì›¨ì–´ëŠ” C++ë¡œ ì‘ì„±ë˜ì—ˆìœ¼ë©° Arduino í”„ë ˆì„ì›Œí¬ë¥¼ ì‚¬ìš©í•˜ê³ , ë””ìŠ¤í”Œë ˆì´ë¥¼ ìœ„í•´ GxEPD2 ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í™œìš©í•©ë‹ˆë‹¤. ì†Œí”„íŠ¸ì›¨ì–´ì—ëŠ” ë‹¤ì–‘í•œ íƒ€ì´ë¨¸ í”„ë¦¬ì…‹ ì„¤ì •ê³¼ ì¬ë¯¸ìˆëŠ” ê¸°ëŠ¥ì¸ ëœë¤ íŒ©íŠ¸ë„ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n\nì‚¬ìš©ìëŠ” ê¸°ê¸°ë¥¼ ì¼œë©´ ë¯¸ë¦¬ ì„¤ì •ëœ íƒ€ì´ë¨¸ë¥¼ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‹œê°„ì´ ë‹¤ ë˜ë©´ ê¸°ê¸°ê°€ ê¹œë°•ì´ëŠ” LEDì™€ ë©”ì‹œì§€ë¡œ ì•Œë¦¼ì„ ì œê³µí•©ë‹ˆë‹¤. ì´í›„ì—ëŠ” í†µê³„ë¥¼ ë³¼ ìˆ˜ ìˆëŠ” íœ´ì‹ ì‹œê°„ì´ ì£¼ì–´ì§‘ë‹ˆë‹¤.",
      "ja": "ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ã€ESP32ãƒã‚¤ã‚¯ãƒ­ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼ã€ePaperãƒ‡ã‚£ã‚¹ãƒ—ãƒ¬ã‚¤ã€å›è»¢ãƒ€ã‚¤ãƒ¤ãƒ«ã‚’ä½¿ã£ã¦ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ã‚¿ã‚¤ãƒãƒ¼ã‚’ä½œæˆã™ã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã—ã¦ã„ã¾ã™ã€‚æä¾›ã•ã‚Œã¦ã„ã‚‹ã‚³ãƒ¼ãƒ‰ã¯å®Œå…¨ã«ä½¿ç”¨ã§ãã‚‹çŠ¶æ…‹ã§ã¯ãªãã€ä¸€éƒ¨ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚„ãƒ•ã‚©ãƒ³ãƒˆãŒæ¬ ã‘ã¦ã„ã¾ã™ãŒã€å€‹ã€…ã®ãƒ‹ãƒ¼ã‚ºã«åˆã‚ã›ã¦èª¿æ•´å¯èƒ½ã§ã™ã€‚\n\nä¸»è¦ãªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã«ã¯ã€ESP32ãƒã‚¤ã‚¯ãƒ­ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚ã“ã‚Œã¯ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ä¸­å¿ƒçš„ãªéƒ¨å“ã§ã™ã€‚æ¬¡ã«ã€è§£åƒåº¦ãŒè‰¯ãã€æ¶ˆè²»é›»åŠ›ãŒä½ã„4.26ã‚¤ãƒ³ãƒã®ePaperãƒ‡ã‚£ã‚¹ãƒ—ãƒ¬ã‚¤ãŒé¸ã°ã‚Œã¦ã„ã¾ã™ã€‚ã“ã®ãƒ‡ã‚£ã‚¹ãƒ—ãƒ¬ã‚¤ã¯ç´ æ—©ãæ›´æ–°ã•ã‚Œã¾ã™ã€‚ã¾ãŸã€å…¥åŠ›ç”¨ã«å›è»¢ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ãŒä½¿ã‚ã‚Œã¦ãŠã‚Šã€ã‚¿ã‚¤ãƒãƒ¼è¨­å®šã‚’ç°¡å˜ã«ãƒŠãƒ“ã‚²ãƒ¼ãƒˆã§ãã¾ã™ã€‚ã•ã‚‰ã«ã€WS2812 LEDãŒå«ã¾ã‚Œã¦ãŠã‚Šã€ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ã‚¿ã‚¤ãƒ ãŒçµ‚äº†ã—ãŸéš›ã«å¾®ã‹ãªã‚¢ãƒ©ãƒ¼ãƒˆã‚’æä¾›ã—ã¾ã™ã€‚é›»æºã«ã¯USB-Cã‚³ãƒã‚¯ã‚¿ãŒä½¿ç”¨ã•ã‚Œã€ã™ã¹ã¦ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’åã‚ã‚‹ãŸã‚ã®3Dãƒ—ãƒªãƒ³ãƒˆã‚±ãƒ¼ã‚¹ã‚‚è¨­è¨ˆã•ã‚Œã¦ã„ã¾ã™ã€‚\n\nã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®å‹•æ©Ÿã¯ã€å‹äººã®æ™‚é–“ç®¡ç†ã‚’åŠ©ã‘ã‚‹ãŸã‚ã«ç›´æ„Ÿçš„ã§ç‰©ç†çš„ãªãƒ•ã‚©ãƒ¼ã‚«ã‚¹ã‚¿ã‚¤ãƒãƒ¼ã‚’ä½œã‚‹ã“ã¨ã§ã—ãŸã€‚ç”Ÿç”£æ€§ã€é›»å­å·¥å­¦ã€ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢å·¥å­¦ã¸ã®æ„›ãŒã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«çµé›†ã•ã‚Œã¦ã„ã¾ã™ã€‚\n\nãƒ‡ã‚¶ã‚¤ãƒ³ã«é–¢ã™ã‚‹è€ƒæ…®ç‚¹ã¨ã—ã¦ã€ãƒ‡ã‚£ã‚¹ãƒ—ãƒ¬ã‚¤ã¯æ˜ã‚‹ã„å…‰ã®ä¸‹ã§ã®ã¿è¦‹ãˆã‚‹ã‚ˆã†ã«è¨­è¨ˆã•ã‚Œã¦ãŠã‚Šã€æš—ã„æ™‚ã«ã¯ä¼‘æ†©ã‚’ä¿ƒã—ã¾ã™ã€‚å›è»¢ãƒ€ã‚¤ãƒ¤ãƒ«ã¯è¤‡é›‘ã•ã‚’åŠ ãˆã¾ã™ãŒã€ä½¿ã„ã‚„ã™ã•ã‚’å‘ä¸Šã•ã›ã¦ã„ã¾ã™ã€‚LEDã¯è¦–è¦šçš„ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’æä¾›ã—ã¤ã¤ã€æ°—ã‚’æ•£ã‚‰ã•ãªã„ã‚ˆã†ã«é…æ…®ã•ã‚Œã¦ã„ã¾ã™ã€‚ã‚±ãƒ¼ã‚¹ã¯æ©Ÿèƒ½çš„ã«è¨­è¨ˆã•ã‚Œã¦ã„ã¾ã™ãŒã€ä½¿ã„ã‚„ã™ã•ã®ãŸã‚ã«ã„ãã¤ã‹ã®èª¿æ•´ãŒè¡Œã‚ã‚Œã¾ã—ãŸã€‚\n\nã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã¯C++ã§æ›¸ã‹ã‚Œã¦ãŠã‚Šã€Arduinoãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚ãƒ‡ã‚£ã‚¹ãƒ—ãƒ¬ã‚¤ã«ã¯GxEPD2ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒåˆ©ç”¨ã•ã‚Œã¦ã„ã¾ã™ã€‚ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã«ã¯ç•°ãªã‚‹ã‚¿ã‚¤ãƒãƒ¼ãƒ—ãƒªã‚»ãƒƒãƒˆã®è¨­å®šã‚„ã€ãƒ©ãƒ³ãƒ€ãƒ ãªè±†çŸ¥è­˜ãªã©ã®æ¥½ã—ã„æ©Ÿèƒ½ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚\n\nèµ·å‹•æ™‚ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ãƒ—ãƒªã‚»ãƒƒãƒˆã‚¿ã‚¤ãƒãƒ¼ã‚’é¸æŠã§ãã¾ã™ã€‚ã‚¿ã‚¤ãƒãƒ¼ãŒçµ‚äº†ã™ã‚‹ã¨ã€LEDãŒç‚¹æ»…ã—ã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§é€šçŸ¥ã•ã‚Œã¾ã™ã€‚ãã®å¾Œã€ä¼‘æ†©æ™‚é–“ãŒã‚ã‚Šã€ãã®é–“ã«çµ±è¨ˆæƒ…å ±ã‚’ç¢ºèªã§ãã¾ã™ã€‚ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã¨ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚’èåˆã•ã›ã€æ¥½ã—ãä½¿ã„ã‚„ã™ã„æ–¹æ³•ã§ç”Ÿç”£æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¦ã„ã¾ã™ã€‚"
    }
  },
  {
    "id": "f6d8d29a0fe76c74",
    "title": {
      "en": "\"Moonshots\" Initiative to Secure the Future of RISC OS",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://www.riscosopen.org/news/articles/2025/03/28/moonshots-initiative-to-secure-the-future-of-the-os",
    "score": 20,
    "by": "kaycebasques",
    "time": 1743285522,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "cf78df02a2c8e9c0",
    "title": {
      "en": "Real Time Chess â€“ A physical chess board without the concept of turns",
      "ko": "ì¦‰ì‹œ ì²´ìŠ¤: í„´ ì—†ëŠ” ì²´ìŠ¤íŒ",
      "ja": "ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒã‚§ã‚¹"
    },
    "type": "story",
    "url": "https://github.com/misprit7/real-time-chess",
    "score": 200,
    "by": "dschuessler",
    "time": 1743248514,
    "content": "Real Time Chess\n\n  A physical chess board without the concept of turns\n\n  Video explanation: https://youtu.be/y7VtSK23_Jg\n\nPitch\nChess is boring. I'm boring too so I enjoy it anyways, but I can't help but think \"I could design it better.\" Normally in chess players move sequentially in turns, but this introduces a huge latency bug that the developers of chess forgot to patch: you spend literally half the time waiting for your opponent!\nThe obvious solution is just get rid of the concept of turns in chess altogether and let players move whenever they want. Real time strategy games like StarCraft and Age of Empires are much more fun and spectator friendly than chess, so this should be a pretty uncontroversial minor rules update that can be implemented before the next world championship. To prevent things from getting too chaotic over the board each piece has an individual cooldown, so once it's been moved it can't move for a fixed period afterwards.\nHowever there's an unfortunate roadblock to the widespread adoption of real time chess: as the Niemann controversy has made all too clear, chess is not immune from accusations of cheating through spectator assistance or outside analisys tools. Trying to have players self enforce these piece cooldowns is impossible. However where the intrinsic goodness of the human psyche fails, engineering is always ready to step in. This project is a physical chess board that keeps track and displays the cooldown remaining for each piece, and even physically holds them in place so no accidental cheating can occur.\nDesign Files\nThe firmware and pcb kicad files are in this repo. For the physical design, see the design on OnShape. Other than those parts that were cnced, here were the off the shelf components used:\n\nInsulating washers: One under each electromagnet, to keep them isolated from the casing\nPlastic screws: To attach electromagnets to base, plastic to prevent electrical connection\nThese and these screws: to attach the internal supports and squares respectively\nSpacers: For an offset between the decorative and functional pcbs\nElectromagnets: Most expensive part other than the machining, ~$600 per board. Could probably get them cheaper from China or something but for low quantities this was easiest\n\nKnown Issues\n\nPower distribution: Traces on the pcbs are way undersized given there are many amps running through them, so there are large voltage drops when many pieces are on cooldown simultaneously. To solve this these traces should be much wider\nTolerances: The pcbs have extremely tight tolerances which makes assmbling the board extremely annoying. The edges and holes should probably have more room\nPin heights: The height of the pins for the banana connectors are taller than the mechanical design allows for, these are fairly easy to shorten using a dremel but probably something that should be fixed\nCorner screws: Given the order of assembly, it's impossible to insert/fasten the 4 corner screws",
    "summary": {
      "en": "**Real Time Chess Summary**\n\nReal Time Chess is a new concept that eliminates turns in traditional chess, allowing players to make moves whenever they want. This change aims to make the game more exciting and engaging, similar to real-time strategy games like StarCraft.\n\nKey Features:\n- Players can move pieces at any time, reducing waiting periods during a game.\n- To maintain order, each chess piece has a cooldown period after being moved.\n- A special physical chess board tracks and displays these cooldowns, preventing cheating by holding pieces in place.\n\nChallenges:\n- Accusations of cheating in chess, highlighted by the Niemann controversy, pose a barrier to this new format.\n- The design faces some technical issues, including:\n  - **Power Distribution**: The circuit board traces are too small, causing voltage drops when many pieces are in cooldown.\n  - **Assembly Tolerances**: The tight tolerances make assembly difficult.\n  - **Pin Heights**: The pins for connectors are too tall for the design.\n  - **Corner Screws**: The assembly order makes it hard to fasten corner screws.\n\nOverall, Real Time Chess seeks to modernize the game while addressing technical challenges to ensure fair play.",
      "ko": "ì‹¤ì‹œê°„ ì²´ìŠ¤ëŠ” ì „í†µì ì¸ ì²´ìŠ¤ì˜ í„´ ë°©ì‹ì„ ì—†ì• ê³  í”Œë ˆì´ì–´ê°€ ì›í•˜ëŠ” ë•Œì— ì–¸ì œë“ ì§€ ìˆ˜ë¥¼ ë‘˜ ìˆ˜ ìˆëŠ” ìƒˆë¡œìš´ ê°œë…ì…ë‹ˆë‹¤. ì´ëŸ¬í•œ ë³€í™”ëŠ” ìŠ¤íƒ€í¬ë˜í”„íŠ¸ì™€ ê°™ì€ ì‹¤ì‹œê°„ ì „ëµ ê²Œì„ì²˜ëŸ¼ ê²Œì„ì„ ë” í¥ë¯¸ë¡­ê³  ëª°ì…ê° ìˆê²Œ ë§Œë“¤ê¸° ìœ„í•œ ê²ƒì…ë‹ˆë‹¤.\n\nì£¼ìš” íŠ¹ì§•ìœ¼ë¡œëŠ” í”Œë ˆì´ì–´ê°€ ì–¸ì œë“ ì§€ ë§ì„ ì›€ì§ì¼ ìˆ˜ ìˆì–´ ê²Œì„ ì¤‘ ëŒ€ê¸° ì‹œê°„ì„ ì¤„ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì§ˆì„œë¥¼ ìœ ì§€í•˜ê¸° ìœ„í•´ ê° ì²´ìŠ¤ ë§ì€ ì´ë™ í›„ ì¿¨ë‹¤ìš´ ì‹œê°„ì´ í•„ìš”í•©ë‹ˆë‹¤. íŠ¹ë³„í•œ ë¬¼ë¦¬ì  ì²´ìŠ¤íŒì´ ì´ëŸ¬í•œ ì¿¨ë‹¤ìš´ ì‹œê°„ì„ ì¶”ì í•˜ê³  í‘œì‹œí•˜ì—¬, ë§ì„ ê³ ì •ì‹œí‚´ìœ¼ë¡œì¨ ë¶€ì •í–‰ìœ„ë¥¼ ë°©ì§€í•©ë‹ˆë‹¤.\n\ní•˜ì§€ë§Œ ì´ ìƒˆë¡œìš´ í˜•ì‹ì—ëŠ” ëª‡ ê°€ì§€ ë„ì „ ê³¼ì œê°€ ìˆìŠµë‹ˆë‹¤. ë‹ˆë¨¼ ë…¼ë€ê³¼ ê°™ì€ ì²´ìŠ¤ì—ì„œì˜ ë¶€ì •í–‰ìœ„ ì˜í˜¹ì´ ì´ í˜•ì‹ì˜ ë„ì…ì— ì¥ì• ê°€ ë˜ê³  ìˆìŠµë‹ˆë‹¤. ë˜í•œ ë””ìì¸ì—ëŠ” ëª‡ ê°€ì§€ ê¸°ìˆ ì  ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ì²«ì§¸, ì „ì› ë¶„ë°° ë¬¸ì œë¡œ íšŒë¡œ ê¸°íŒì˜ ì„ ì´ ë„ˆë¬´ ì‘ì•„ ë§ì€ ë§ì´ ì¿¨ë‹¤ìš´ ìƒíƒœì¼ ë•Œ ì „ì•• ê°•í•˜ê°€ ë°œìƒí•©ë‹ˆë‹¤. ë‘˜ì§¸, ì¡°ë¦½ ê³µì°¨ê°€ ë„ˆë¬´ ì¢ì•„ ì¡°ë¦½ì´ ì–´ë µìŠµë‹ˆë‹¤. ì…‹ì§¸, ì»¤ë„¥í„°ì˜ í•€ ë†’ì´ê°€ ë””ìì¸ì— ë¹„í•´ ë„ˆë¬´ ë†’ìŠµë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ, ì¡°ë¦½ ìˆœì„œ ë•Œë¬¸ì— ì½”ë„ˆ ë‚˜ì‚¬ë¥¼ ì¡°ì´ê¸°ê°€ ì–´ë µìŠµë‹ˆë‹¤.\n\nì „ë°˜ì ìœ¼ë¡œ ì‹¤ì‹œê°„ ì²´ìŠ¤ëŠ” ê²Œì„ì„ í˜„ëŒ€í™”í•˜ê³  ê³µì •í•œ í”Œë ˆì´ë¥¼ ë³´ì¥í•˜ê¸° ìœ„í•´ ê¸°ìˆ ì  ë¬¸ì œë¥¼ í•´ê²°í•˜ê³ ì í•©ë‹ˆë‹¤.",
      "ja": "ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒã‚§ã‚¹ã¯ã€å¾“æ¥ã®ãƒã‚§ã‚¹ã®ã‚¿ãƒ¼ãƒ³åˆ¶ã‚’æ’é™¤ã—ã€ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ãŒå¥½ããªæ™‚ã«é§’ã‚’å‹•ã‹ã›ã‚‹æ–°ã—ã„ã‚³ãƒ³ã‚»ãƒ—ãƒˆã§ã™ã€‚ã“ã®å¤‰æ›´ã«ã‚ˆã‚Šã€ã‚²ãƒ¼ãƒ ã¯ã‚ˆã‚Šåˆºæ¿€çš„ã§é­…åŠ›çš„ã«ãªã‚Šã€ã‚¹ã‚¿ãƒ¼ã‚¯ãƒ©ãƒ•ãƒˆã®ã‚ˆã†ãªãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¹ãƒˆãƒ©ãƒ†ã‚¸ãƒ¼ã‚²ãƒ¼ãƒ ã«è¿‘ã¥ãã“ã¨ã‚’ç›®æŒ‡ã—ã¦ã„ã¾ã™ã€‚\n\nã“ã®ã‚²ãƒ¼ãƒ ã®ä¸»ãªç‰¹å¾´ã¯ã€ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ãŒã„ã¤ã§ã‚‚é§’ã‚’å‹•ã‹ã›ã‚‹ãŸã‚ã€ã‚²ãƒ¼ãƒ ä¸­ã®å¾…æ©Ÿæ™‚é–“ãŒçŸ­ç¸®ã•ã‚Œã‚‹ã“ã¨ã§ã™ã€‚ãŸã ã—ã€ç§©åºã‚’ä¿ã¤ãŸã‚ã«ã€å„é§’ã«ã¯ç§»å‹•å¾Œã®ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³æœŸé–“ãŒè¨­ã‘ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚ã¾ãŸã€ç‰¹åˆ¥ãªç‰©ç†çš„ãƒã‚§ã‚¹ãƒœãƒ¼ãƒ‰ãŒã“ã®ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ã‚’è¿½è·¡ã—è¡¨ç¤ºã™ã‚‹ã“ã¨ã§ã€é§’ã‚’å‹•ã‹ã•ãšã«ä¿æŒã™ã‚‹ã“ã¨ã«ã‚ˆã‚‹ä¸æ­£è¡Œç‚ºã‚’é˜²ãã¾ã™ã€‚\n\nã—ã‹ã—ã€ã“ã®æ–°ã—ã„å½¢å¼ã«ã¯ã„ãã¤ã‹ã®èª²é¡ŒãŒã‚ã‚Šã¾ã™ã€‚ãƒ‹ãƒ¼ãƒãƒ³ã®è«–äº‰ã«è¦‹ã‚‰ã‚Œã‚‹ã‚ˆã†ã«ã€ãƒã‚§ã‚¹ã«ãŠã‘ã‚‹ä¸æ­£è¡Œç‚ºã®ç–‘æƒ‘ãŒã“ã®å½¢å¼ã®æ™®åŠã®éšœå®³ã¨ãªã£ã¦ã„ã¾ã™ã€‚ã¾ãŸã€ãƒ‡ã‚¶ã‚¤ãƒ³ã«ã¯ã„ãã¤ã‹ã®æŠ€è¡“çš„ãªå•é¡Œã‚‚ã‚ã‚Šã¾ã™ã€‚ä¾‹ãˆã°ã€å›è·¯åŸºæ¿ã®ãƒˆãƒ¬ãƒ¼ã‚¹ãŒå°ã•ã™ãã¦ã€å¤šãã®é§’ãŒã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ä¸­ã«ãªã‚‹ã¨é›»åœ§ãŒä½ä¸‹ã™ã‚‹ã“ã¨ã‚„ã€çµ„ã¿ç«‹ã¦ã®ç²¾åº¦ãŒå³ã—ã„ãŸã‚ã«çµ„ã¿ç«‹ã¦ãŒé›£ã—ã„ã“ã¨ã€ã‚³ãƒã‚¯ã‚¿ç”¨ã®ãƒ”ãƒ³ãŒãƒ‡ã‚¶ã‚¤ãƒ³ã«å¯¾ã—ã¦é«˜ã™ãã‚‹ã“ã¨ã€ãã—ã¦çµ„ã¿ç«‹ã¦é †åºã®ãŸã‚ã«ã‚³ãƒ¼ãƒŠãƒ¼ã‚¹ã‚¯ãƒªãƒ¥ãƒ¼ã‚’ç· ã‚ã‚‹ã®ãŒé›£ã—ã„ã“ã¨ãªã©ã§ã™ã€‚\n\nå…¨ä½“ã¨ã—ã¦ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒã‚§ã‚¹ã¯ã‚²ãƒ¼ãƒ ã‚’ç¾ä»£åŒ–ã—ã¤ã¤ã€æŠ€è¡“çš„ãªèª²é¡Œã«å¯¾å‡¦ã—ã¦å…¬æ­£ãªãƒ—ãƒ¬ã‚¤ã‚’ç¢ºä¿ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¦ã„ã¾ã™ã€‚"
    }
  },
  {
    "id": "21cb1fbcb3976c27",
    "title": {
      "en": "Show HN: Appear as anyone in video calls like zoom or Google meets",
      "ko": "ì˜ìƒí†µí™” ë³€ì‹ !",
      "ja": "èª°ã§ã‚‚å¤‰èº«ï¼ãƒ“ãƒ‡ã‚ªé€šè©±é©å‘½"
    },
    "type": "story",
    "url": "https://www.phazr.ai/",
    "score": 56,
    "by": "michaelphi",
    "time": 1743273889,
    "content": "Appear as any character in your next video callWith a single reference photo, you can become your favorite anime character, meme, celebrity, or even your own unique creation. Runs locally on your device for complete privacy. Works on Zoom, Google Meet, Slack, Twitch, Discord, and other video apps.Download for LinuxWindows and Mac versions coming soonRequest early access\n\nRequest Early AccessWindows and Mac versions are coming soon. Sign up to be notified when your preferred platform is available.Request AccessWindowsMacWe'll notify you when it's ready.\n\nSystem Requirementsâ€¢ Ubuntu 22.04 or newer / Debian-based distributionâ€¢ 8GB RAM (16GB recommended)â€¢ NVIDIA GPU with CUDA supportCompatible GPUs:â€¢ NVIDIA RTX 4090, 4080, 4070 TIâ€¢ NVIDIA RTX 3090, 3080 TIâ€¢ NVIDIA RTX 5090, 5080, 5070, 5060Note: AMD GPUs are not supported at this time.Email addressDownload for LinuxAfter downloading:chmod +x ./phazr-Linux-*.AppImage./phazr-Linux-*.AppImage",
    "summary": {
      "en": "You can now appear as any character in your video calls using just one photo. This feature lets you transform into your favorite anime character, meme, celebrity, or create a unique version of yourself. It works on various video apps like Zoom, Google Meet, Slack, Twitch, and Discord, and runs locally on your device for privacy.\n\nCurrently, it's available for Linux, with Windows and Mac versions coming soon. You can sign up to get notified when those versions are ready.\n\n**System Requirements for Linux:**\n- Ubuntu 22.04 or newer\n- At least 8GB RAM (16GB recommended)\n- NVIDIA GPU with CUDA support (specific models listed)\n\nNote: AMD GPUs are not supported at this time.",
      "ko": "ì´ì œ ë‹¨ í•œ ì¥ì˜ ì‚¬ì§„ìœ¼ë¡œ ë¹„ë””ì˜¤ í†µí™”ì—ì„œ ì›í•˜ëŠ” ìºë¦­í„°ë¡œ ë³€ì‹ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ê¸°ëŠ¥ì„ í†µí•´ ì¢‹ì•„í•˜ëŠ” ì• ë‹ˆë©”ì´ì…˜ ìºë¦­í„°, ì¸í„°ë„· ë°ˆ, ìœ ëª…ì¸ì‚¬ ë˜ëŠ” ìì‹ ë§Œì˜ ë…íŠ¹í•œ ë²„ì „ìœ¼ë¡œ ë³€ì‹ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ê¸°ëŠ¥ì€ Zoom, Google Meet, Slack, Twitch, Discordì™€ ê°™ì€ ë‹¤ì–‘í•œ ë¹„ë””ì˜¤ ì•±ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆìœ¼ë©°, ê°œì¸ ì •ë³´ ë³´í˜¸ë¥¼ ìœ„í•´ ê¸°ê¸°ì—ì„œ ë¡œì»¬ë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.\n\ní˜„ì¬ ì´ ê¸°ëŠ¥ì€ ë¦¬ëˆ…ìŠ¤ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆìœ¼ë©°, ìœˆë„ìš°ì™€ ë§¥ ë²„ì „ë„ ê³§ ì¶œì‹œë  ì˜ˆì •ì…ë‹ˆë‹¤. ì´ ë²„ì „ì´ ì¤€ë¹„ë˜ë©´ ì•Œë¦¼ì„ ë°›ì„ ìˆ˜ ìˆë„ë¡ ê°€ì…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\në¦¬ëˆ…ìŠ¤ ì‹œìŠ¤í…œ ìš”êµ¬ ì‚¬í•­ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. \n- ìš°ë¶„íˆ¬ 22.04 ì´ìƒ\n- ìµœì†Œ 8GB RAM (16GB ê¶Œì¥)\n- CUDA ì§€ì› NVIDIA GPU (íŠ¹ì • ëª¨ë¸ ëª©ë¡ ì œê³µ)\n\nì°¸ê³ ë¡œ í˜„ì¬ AMD GPUëŠ” ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.",
      "ja": "ãƒ“ãƒ‡ã‚ªé€šè©±ã§å¥½ããªã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã«å¤‰èº«ã§ãã‚‹æ–°æ©Ÿèƒ½ãŒç™»å ´ã—ã¾ã—ãŸã€‚ã“ã®æ©Ÿèƒ½ã‚’ä½¿ãˆã°ã€ãŠæ°—ã«å…¥ã‚Šã®ã‚¢ãƒ‹ãƒ¡ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã‚„ãƒŸãƒ¼ãƒ ã€æœ‰åäººã€ã•ã‚‰ã«ã¯è‡ªåˆ†è‡ªèº«ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«å¤‰ã‚ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚Zoomã€Google Meetã€Slackã€Twitchã€Discordãªã©ã€ã•ã¾ã–ã¾ãªãƒ“ãƒ‡ã‚ªã‚¢ãƒ—ãƒªã§åˆ©ç”¨ã§ãã€ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ã‚’å®ˆã‚‹ãŸã‚ã«ãƒ‡ãƒã‚¤ã‚¹ä¸Šã§å‹•ä½œã—ã¾ã™ã€‚\n\nç¾åœ¨ã€ã“ã®æ©Ÿèƒ½ã¯Linuxå‘ã‘ã«æä¾›ã•ã‚Œã¦ã„ã¾ã™ãŒã€Windowsã¨Macã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚‚è¿‘æ—¥ä¸­ã«ç™»å ´äºˆå®šã§ã™ã€‚ã“ã‚Œã‚‰ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãŒæº–å‚™ã§ããŸéš›ã«é€šçŸ¥ã‚’å—ã‘å–ã‚‹ãŸã‚ã®ã‚µã‚¤ãƒ³ã‚¢ãƒƒãƒ—ãŒå¯èƒ½ã§ã™ã€‚\n\nLinuxã®ã‚·ã‚¹ãƒ†ãƒ è¦ä»¶ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ã€‚Ubuntu 22.04ä»¥ä¸ŠãŒå¿…è¦ã§ã€æœ€ä½ã§ã‚‚8GBã®RAMãŒå¿…è¦ã§ã™ãŒã€16GBã‚’æ¨å¥¨ã—ã¾ã™ã€‚ã¾ãŸã€CUDAã‚µãƒãƒ¼ãƒˆã®ã‚ã‚‹NVIDIA GPUãŒå¿…è¦ã§ã™ã€‚å…·ä½“çš„ãªãƒ¢ãƒ‡ãƒ«ã«ã¤ã„ã¦ã¯ãƒªã‚¹ãƒˆãŒæä¾›ã•ã‚Œã¦ã„ã¾ã™ã€‚\n\nãªãŠã€ç¾æ™‚ç‚¹ã§ã¯AMDã®GPUã¯ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"
    }
  },
  {
    "id": "437a116b548cbbd0",
    "title": {
      "en": "Medical Benchmarks and the Myth of the Universal Patient",
      "ko": "ì˜ë£Œ ê¸°ì¤€ê³¼ í™˜ìì˜ ì‹ í™”",
      "ja": "åŒ»ç™‚åŸºæº–ã¨æ‚£è€…ç¥è©±"
    },
    "type": "story",
    "url": "https://www.newyorker.com/magazine/2025/03/31/medical-benchmarks-and-the-myth-of-the-universal-patient",
    "score": 6,
    "by": "pseudolus",
    "time": 1743038039,
    "content": "Annals of InquiryMedical Benchmarks and the Myth of the Universal PatientFrom growth charts to anemia thresholds, clinical standards assume a single human prototype. Why are we still using one-size-fits-all health metrics?By Manvir SinghMarch 24, 2025FacebookXEmailPrintSave StoryUniversal health standards inform the way we define malnutrition, obesity, growth abnormalities, and more, underpinning broad statistical claims. But they donâ€™t account for human diversity.Illustration by David PlunkertSave this storySave this storySave this storySave this storyWhen my daughter was ten and a half months old, she qualified as â€œwasted,â€ which UNICEF describes as â€œthe most immediate, visible and life-threatening form of malnutrition.â€ My wife and I had been trying hard to keep her weight up, and the classification felt like a pronouncement of failure. Her birth weight had been on the lower end of the scale but nothing alarming: six pounds, two ounces. She appeared as a dot on a chart in which colored curves traced optimal growth; fifteenth percentile, we were told. She took well to breast-feeding and, within a month, had jumped to the twentieth percentile, then to the twenty-sixth. We proudly anticipated that her numbers would steadily climb. Then she fell behind again. At four months, she was in the twelfth percentile. At nine and a half, she was below the fifth.Our pediatrician was worried. Ease off the lentils and vegetable smoothies, we were warned; we needed to get more calories into our babe. Ghee, peanut butterâ€”we were to drench her food in these and other fats and wash them down with breast milk and formula. And thatâ€™s what we did. When we came back a month later, though, we learned that she had dropped furtherâ€”and crossed into â€œwastedâ€ territory.Was this what malnutrition looked like? She seemed to be flourishing. She was happy, adventurous, and exuberantly social, babbling incessantly and forever engaging strangers with flirtatious stares. She had cheeks as plump as the juicy clementines that she loved to eat with full-fat yogurt. Although slow to hands-and-knees crawlingâ€”scooting was her preferred means of locomotionâ€”she was hitting most of her other milestones. She was also growing longer and longer, shooting from the twelfth percentile at birth to the thirty-sixth at ten months.In â€œAdaptable: How Your Unique Body Really Works and Why Our Biology Unites Usâ€ (Avery), Herman Pontzer, an evolutionary anthropologist at Duke University, recounts facing a similar conundrum. While Pontzer was visiting a semidesert village in northern Kenya to study the Daasanach pastoralists, a German charity representative told him that the community was being devastated by malnutrition. Charity workers had plotted the heights and weights of Daasanach children on World Health Organization chartsâ€”the same ones our pediatrician used to monitor my daughterâ€™s growthâ€”and determined that more than two-thirds of the kids were malnourished. As a result, families were enrolled in a nutrition program and provided with high-calorie, industrially processed supplements. Yet, as with my daughter, the numbers didnâ€™t align with ordinary observation.â€œEverywhere we went, children were running, playing, and laughing,â€ Pontzer writes. â€œKids being kids. They didnâ€™t seem low on energy, nor did they seem particularly short, or â€˜stunted.â€™â€ He saw no other signs of chronic starvation, such as bloated bellies or reduced fertility among adult women. The kids were slim, but in the lanky way typical of so many East African pastoralists.When Pontzer and his team tracked the growth of Daasanach children, they uncovered patterns that sharply diverged from the W.H.O. curves. At around age two, these kids gain height at rates seldom seen elsewhere in the world. At five, they stand taller, on average, than well-fed kids in Europe and North America. At the same time, they put on weight more slowly, developing lean physiques that are optimal for heat dissipation. Where the German charity diagnosed deficiency, Pontzer saw adaptation.â€œAdaptableâ€ offers an engrossing, richly informative exploration of human biological diversity. By revealing how our variable bodies respond to a wide range of environments, it challenges us to rethink universal health benchmarks. These standards inform everything from how we define malnutrition and micronutrient deficiencies to how we estimate the risks of growth abnormalities, metabolic disorders, and cardiovascular dysfunction. They drive global funding priorities, shape international aid programs, and inform social policies. They guide individual clinical assessments, like my daughterâ€™s, and underpin broad statistical claims: seventeen per cent of humans are zinc-deficient; nearly a quarter of Asian-Pacific children are stunted. Yet these benchmarks rest on a monolithic image of human healthâ€”a prototypical Homo sapiens whose vulnerabilities remain unchanged across climates and genetic histories. Weâ€™ve entered the age of neurodiversity, precision medicine, and â€œbio-individuality,â€ but we still assume that malnutrition looks the same in Cologne as it does in rural Kenya. Is it time to move beyond the model of the universal patient?For decades, pediatricians relied on growth charts for infants and young toddlers which were wildly and obviously flawed. The W.H.O. had endorsed standards developed by the U.S. National Center for Health Statistics based on data from a single American communityâ€”Yellow Springs, Ohio. There were questions about their relevance for children elsewhere in the country, let alone the world. But when the W.H.O. released new child-growth standards, in 2006, it appeared that we at last had a truly global benchmark, drawn from studies of children across five continents.The coÃ¶rdinating team recruited participants from six far-flung locations: Oslo, Norway; Muscat, Oman; Pelotas, Brazil; New Delhi, India; Accra, Ghana; and, as it happens, the city where I live, Davis, California. The researchers maintained strict inclusion criteriaâ€”tracking only breast-fed children born to well-off, nonsmoking mothers. The resulting charts gained remarkable traction. By April, 2011, a hundred and twenty-five countries had adopted them, and the United Nations treated them as the new gold standard. Implementation was costly, often requiring countries to overhaul child-health records, retrain medical personnel, and acquire new measurement equipment.These standards seemed authoritative in part because of their vaunted universality. As the project coÃ¶rdinators wrote in 2006, the standards could be used â€œto assess children everywhere, regardless of ethnicity, socioeconomic status and type of feeding.â€ The coÃ¶rdinators also noted a â€œstriking similarityâ€ in the data collected among the six sites, which, given the â€œbuilt-in ethnic or genetic variability,â€ affirmed â€œthe standardsâ€™ universal applicability.â€Yet how much variability was there, really? The W.H.O. didnâ€™t publish detailed ethnicity information, but, at the time the data were collected, most residents of Oslo, Pelotas, and Davis were of European ancestry. Africa, with more genetic diversity than any other continent, was characterized by a single site. Pacific Islanders, Indigenous Americans, and, most glaringly, East and Southeast Asians were not represented.The claim of â€œstriking similarityâ€ was also tenuous. The team based its claim on the fact that, at every age, the average height of children at each site was within half a standard deviation of the over-all average. But by that reasoning, as the Indian pediatrician Harshpal Singh Sachdev recently observed in The American Journal of Clinical Nutrition, two sites could differ by as much as a standard deviation and still be considered equivalent. Thatâ€™s like saying that the mean adult heights in Denmark and Taiwan exhibit â€œstriking similarityâ€ despite differing by more than six centimetres. Among low-income families in urban India, Sachdev noted, ambitious interventions targeting health, sanitation, nutrition, and psychosocial support have failed to increase stature by half a standard deviation, suggesting that differences among sites may reflect disparate physiological baselines.Beyond height, no cross-site comparisons have ever been published for other measurements, including weight-for-height and weight-for-age metrics and head circumference. Nevertheless, these metrics are regularly used for clinical and cross-national purposes, and treated as if they were universally applicable. When the W.H.O. reports that nearly one in six African children is underweightâ€”or when the Global Nutrition Report states that 45.4 million children under the age of five are wastedâ€”public-health policies are guided by untested assumptions.My wife and I didnâ€™t know any of this when our daughter was first flagged for being underweight. But we had suspicions that her size might not have been as atypical as the charts implied. My wifeâ€™s family, like mine, emigrated from India. Asking around, we learned that many parents of South Asian ancestry had exceptionally small children. On Reddit forums such as r/india and r/ABCDesis, we discovered parents worrying about the same issue. Two of my wifeâ€™s cousins had been born smaller than our daughter.It turned out that credible research corroborated our suspicions. A series of Stanford-led studies had analyzed millions of births in the U.S. and documented a â€œdual paradoxâ€: U.S.-born women of Mexican parentage, despite having higher risk profiles than U.S.-born women of Indian ancestry, are less likely to have babies with low birth weights. Thatâ€™s one of many inconsistencies pertaining to size and nutrition. Take the so-called South Asian Enigma: India, Bangladesh, and Nepal exceed most sub-Saharan African countries on key health and development indicators, but their populations still fail to measure up (literally) to those in sub-Saharan Africa or the African diaspora. For instance, Haitiâ€™s infant-mortality rate is almost twice that of Indiaâ€™s, and its per-capita G.D.P. is thirty per cent lower, yet only six per cent of Haitian children are assessed as severely stunted, compared with fourteen per cent of Indian children. You find similar disparities between affluent nations in East Asia and those in northern Europe. Japan and the Netherlands are among the wealthiest countries in the world, with first-rate health care and low disease burdens, but some seven per cent of Japanese children qualify as stunted, compared with only about one per cent in the Netherlands.The obvious takeaway is that factors aside from living standardsâ€”including biological inheritanceâ€”are the reason that Dutch and Haitian kids tower over their Japanese and Nepali peers. Yet many researchers have been wary of considering the possibility. In their efforts to resolve the South Asian Enigma, for example, they have busily investigated the effects of open-air defecation, maternal nutrition, and a preference for firstborn sons on the subcontinent. A team of economists examined whether the number of low-weight infants in sub-Saharan Africa who die skews height statistics.According to Daniel Hruschka, an anthropologist at Arizona State University, none of these theories explain away the discrepancies. Hruschka has long had a personal interest in body measurements. â€œI consider myself pretty healthy, but if you use B.M.I. guidelines I am obese, and Iâ€™ve always wondered, What does that mean for my health?â€ he told me. The question inspired him to spend more than a decade dissecting anthropometric data, resulting in a slew of revealing findings. In research published in the twenty-tens, he confirmed that a single B.M.I. cutoff for distinguishing normal from obese body weight overestimates obesity, as defined by body fat, in populations with stockier bodies (Pacific Islanders, say) and underestimates it in leaner peoples (South Asians). Whatâ€™s more, patterns in slenderness, such as similarities between closely related groups and between children and adults in the same group, strongly suggest that genetics plays a major role. In 2016, Hruschka and the anthropologist Craig Hadley, at Emory University, estimated that the standard B.M.I. cutoff misses roughly half a billion overweight people, including some two hundred and fifty million in South Asia alone.After studying obesity, Hruschka turned his attention to height. In one of his most ambitious projects, published in 2020, he and his former student Joseph Hackman, now at the University of Utah, analyzed measurements from 1.5 million children across seventy countries. Using data on wealth, hygiene, nutrition, and infectious-disease exposure, they calculated each countryâ€™s â€œbasalâ€ height-for-age indexâ€”the starting height of children living under comparable environmental conditions. If the W.H.O. had been right to assume that childrenâ€™s potential height is the same everywhere, basal height-for-age measurements should be consistent across populations.<img alt=\"Drummer leading medieval soldiers into battle.\" class=\"ResponsiveImageContainer-eybHBd fptoWY responsive-image__image\" src=\"https://media.newyorker.com/cartoons/67d9cb0f38fb0d49d0f9dfb4/master/w_1600%2Cc_limit/a26178.jpg\" srcSet=\"https://media.newyorker.com/cartoons/67d9cb0f38fb0d49d0f9dfb4/master/w_120,c_limit/a26178.jpg 120w, https://media.newyorker.com/cartoons/67d9cb0f38fb0d49d0f9dfb4/master/w_240,c_limit/a26178.jpg 240w, https://media.newyorker.com/cartoons/67d9cb0f38fb0d49d0f9dfb4/master/w_320,c_limit/a26178.jpg 320w, https://media.newyorker.com/cartoons/67d9cb0f38fb0d49d0f9dfb4/master/w_640,c_limit/a26178.jpg 640w, https://media.newyorker.com/cartoons/67d9cb0f38fb0d49d0f9dfb4/master/w_960,c_limit/a26178.jpg 960w, https://media.newyorker.com/cartoons/67d9cb0f38fb0d49d0f9dfb4/master/w_1280,c_limit/a26178.jpg 1280w, https://media.newyorker.com/cartoons/67d9cb0f38fb0d49d0f9dfb4/master/w_1600,c_limit/a26178.jpg 1600w\" sizes=\"100vw\"/>â€œHey, I canâ€™t murder people to jazz triplets.â€Cartoon by Will McPhailCopy link to cartoonCopy link to cartoonLink copiedShopShopThey werenâ€™t. For instance, the basal heights of children in India differed by more than a standard deviation from those of children in Haiti. Even when reared in identical environments, an Indian two-year-old would be expected to be three centimetres shorter than a Haitian two-year-old. When Hruschka and Hackman recalculated rates of severe stunting based on these findings, the estimated prevalence in Haiti more than tripled, from six per cent to twenty per cent. Similarly dramatic increases were observed in West and Central Africa. The reliance on growth charts, it seems, has hidden millions of severe stunting cases in parts of Africa.These calculations raise another troubling possibility: estimates of stunting in other regions might be exaggerated, leading to ill-advised nutritional interventions. A 2021 study by Sachdev found that more than half of Indian children aged five to nineteen classified as â€œmalnourishedâ€ by W.H.O. standards actually show biomarkers of obesity. â€œMetabolically, they are even overnourished,â€ Sachdev told me. Where pediatricians would normally recommend cutting back on high-calorie food for such children, â€œhere we are pushing it,â€ he said.This blindness to human variation affects children in wealthy countries, too. Though the W.H.O. charts are meant to spot â€œabnormal growth,â€ they regularly miss growth disorders in European children. It canâ€™t help that the charts for five- to nineteen-year-olds still draw on decades-old data from the United States. In the Netherlands and Sweden, the W.H.O. charts catch only about seventy per cent of children over the age of five with growth-hormone deficiency; country-specific charts spot around ninety-five per cent. In a 2016 study of nine European nations, the W.H.O. standards consistently failed to outperform local referencesâ€”except in France, which hadnâ€™t updated its growth charts since1979.So charts meant to protect childrenâ€™s health may be failing them across the globe, missing growth disorders in tall populations while pathologizing normal development in shorter ones. Parents in Mumbai, Manila, and Minneapolis alike must navigate a medical system built on standards that donâ€™t reflect their childrenâ€™s physiological realities. Some children who need care may be overlooked; others are subjected to unnecessary and potentially harmful interventions.â€œOur differences are obvious, even on the surface,â€ Pontzer observes in â€œAdaptable.â€ â€œWhy should our insides be any less diverse?â€ Itâ€™s a reasonable question. We regularly confront the fact that different environments have the power to change us. We know that people who train at high altitudes develop greater aerobic capacity and that populations long exposed to more UV radiation develop darker skin. Pontzer catalogues a great many such examples, from East African hunter-gatherers whose life styles shield them from cardiovascular disease to Southeast Asian sea nomads with genetic adaptations that let them spend hours a day underwater. Yet international organizations continue to operate on the assumption of a universal human physiologyâ€”one that, in practice, corresponds strikingly with a Euro-American model.Take anemia, a condition in which the bloodâ€™s ability to carry oxygen is diminished. The W.H.O. first proposed diagnostic cutoffs in a 1959 report. These measures of hemoglobin concentration, a subsequent scientific group admitted, â€œwere chosen arbitrarily,â€ so new thresholds were introduced after the group reviewed five studiesâ€”on American infants, pregnant Canadian women, Norwegian adolescent males, British adults in a mining valley, and, apparently, Swedes. (Thereâ€™s some uncertainty because the final set of observations was not released.) The revised cutoffs, presented in 1968, were still â€œsomewhat arbitrary,â€ the authors conceded, but lines had to be drawn. More than fifty years later, these remain the W.H.O.â€™s guidelines, with only slight modifications for children and pregnant women. A 2023 paper in The Lancet Haematology that announced that nearly two billion people were anemic relied on versions of the 1968 cutoffs.Untold other benchmarks have similar stories. Criteria for zinc deficiency, as defined by the International Zinc Nutrition Consultative Group, are based on data collected in the United States between 1976 and 1980. Bear that in mind when you hear claims that more than a billion people are zinc-deficient. The threshold for Vitamin D deficiency is also based mostly on research involving Europeans and North Americans, leading to the claim that ninety per cent of Indians lack sufficient Vitamin D, despite the subcontinentâ€™s abundant sunlight.Why insist on a universal standard? In part, it has been a matter of practicality. For decades, establishing population-specific benchmarks required extensive data collection, statistical modelling, and clinical validationâ€”efforts too costly for most countries to undertake. International organizations like the W.H.O. provided usable, if imperfect, alternatives. But these constraints are disappearing. With vast survey data sets and advanced analytical tools, studies such as those by Hruschka and Hackman reveal population-level patterns that can inform more tailored benchmarks. Meanwhile, scientists in low- and middle-income countries are testing whether inherited global cutoffs line up with local realities. As the barriers to measuring human variation fall, so does the rationale for a one-size-fits-all model.Even with these advances, Pontzer suspects another reason for the reluctance to discuss biological variation: â€œDifferences are dangerous.â€ Throughout history, claims of inherent disparities have fuelled oppression, from the justification of slavery to the forced sterilization of the poor. Well-intentioned efforts to account for variation have sometimes harmed marginalized groups. Beginning in 1999, a standard equation for measuring kidney function included a â€œrace coefficient,â€ which systematically overestimated kidney health in Black patients. As a result, many Black people were referred to specialists belatedly or deemed ineligible for treatments like kidney transplants. In 2021, when the National Kidney Foundation and the American Society of Nephrology recommended removing race from these calculations, more than a million Black Americans were immediately reclassified into more severe stages of kidney disease.The failures of race-based medicine arenâ€™t an argument for ignoring physiological diversity. Pretending that differences donâ€™t exist doesnâ€™t make them disappear; it only drives practitioners to rely on flawed intuitions. Familiar racial categories do a poor job of tracking ancestry and genetic variation. Yoruba people, in Nigeria, and Bench people, in Ethiopia, both qualify as Black, yet genetically they are further apart than an English person is from a Tamil. Instead of clinging to dubious classifications that obscure variation, we would be better served by developing methods that account for peopleâ€™s distinctive ancestry and lived environment.In January, we celebrated our daughterâ€™s first birthday. For reasons of happenstance, we were seeing a new pediatrician for her twelve-month visit. We felt confident. We had ramped up feeding efforts, watching with satisfaction as our daughterâ€™s thighs plumped and her round belly spilled over the waistband of her diaper. Admittedly, every previous visit to the pediatricianâ€™s office had begun with the same sense of achievementâ€”only to be deflated by troubling percentiles. But this time she looked particularly pudgy.â€œSeventeen,â€ my wife whispered, stealing my guess.â€œSixteen pounds, seven ounces,â€ the nurse read, squinting at the scale. Not bad, I thought.When the pediatrician entered, he handed us printouts of familiar curves, each marked with a dot representing our daughter: sixth percentile for both weight-for-age and weight-for-height. He asked how these numbers compared with her previous measurements. As we answered him, he stared at the charts, seemingly wrestling with the severity of the situation. Then he said that he was referring us to a dietitian.Despite ordering a weight check in six weeks and several blood tests, though, he didnâ€™t appear to be visibly troubled. It was as if he, like us, saw two versions of our daughterâ€”the one sitting before him, gleeful and energetic, and the other on the chart, abstractly a cause for concern. Not knowing which to trust, he deferred the verdict to someone else.Such uncertainty is inherent to medical inference. A heavy baby might just be big-boned; a small one, slim but robust. Yet the reliance on universal benchmarks has widened the disconnect between bodies and their measurements. Resistant to acknowledging population differences, these standards often flag healthy bodies as worrisome and look past malnourished ones. As a result, hundreds of millions of peopleâ€”often in the poorest countriesâ€”are mislabelled, while tools like the W.H.O.â€™s growth standards, stretched to fit all of humanity, prove less effective than local alternatives. Paradoxically, these efforts sometimes undermine their own goals, concealing, and at times exacerbating, the afflictions of the most vulnerable.In mid-February, we met virtually with the dietitian. She asked about our feeding routineâ€”which foods, when, how much breast-feedingâ€”and watched as our daughter clambered from my wifeâ€™s lap onto the table, reaching for the computer. The dietitian didnâ€™t refer us to another specialist or dwell on percentiles. Instead, she assured us that our daughter was O.K. Petite, yes, but â€œholding her own.â€ Besides, she confirmed, many Indian children tend to be smaller. Still, she advised us to keep feeding her well and often, to add butter and the like whenever we could, to stay vigilant.Maybe in a decade, the one-size-fits-all curves will give way to standards that recognize the different shapes of different populations, and the advice will shift to match. But, for now, we live in the space between two realitiesâ€”the numbers on a spreadsheet and the child in our arms.â™¦",
    "summary": {
      "en": "The article discusses the limitations of universal health benchmarks in assessing child growth and nutrition, highlighting the need for more individualized standards that account for human diversity. \n\nKey points include:\n\n1. **Universal Health Standards**: Current health metrics, like growth charts, assume a one-size-fits-all model for defining malnutrition and growth abnormalities, ignoring the diversity in human biology and environmental adaptation.\n\n2. **Personal Experience**: The author shares their experience with their daughter, who was classified as \"wasted\" despite being healthy and active, illustrating the disconnect between clinical assessments and individual health.\n\n3. **Global Health Data Issues**: Studies indicate that global health metrics often rely on data from specific populations (mainly Western) and can misrepresent the health of diverse groups, leading to inappropriate health interventions.\n\n4. **The South Asian Enigma**: Research shows that populations from South Asia often appear smaller in standard health metrics but may not be unhealthy, contradicting the assumptions made by universal standards.\n\n5. **Call for Change**: The article advocates for developing health metrics that reflect local populations and conditions instead of imposing universal standards that may mislabel healthy individuals as malnourished.\n\n6. **Conclusion**: The reliance on outdated and broad health benchmarks can lead to misdiagnoses and ineffective public health policies. A shift towards acknowledging individual and population differences in health assessments is essential for better health outcomes.",
      "ko": "ì´ ê¸°ì‚¬ëŠ” ì•„ë™ ì„±ì¥ê³¼ ì˜ì–‘ì„ í‰ê°€í•˜ëŠ” ë° ìˆì–´ ë³´í¸ì ì¸ ê±´ê°• ê¸°ì¤€ì˜ í•œê³„ë¥¼ ë‹¤ë£¨ê³  ìˆìœ¼ë©°, ì¸ê°„ì˜ ë‹¤ì–‘ì„±ì„ ë°˜ì˜í•œ ë³´ë‹¤ ê°œì¸í™”ëœ ê¸°ì¤€ì˜ í•„ìš”ì„±ì„ ê°•ì¡°í•©ë‹ˆë‹¤.\n\ní˜„ì¬ì˜ ê±´ê°• ì§€í‘œ, ì˜ˆë¥¼ ë“¤ì–´ ì„±ì¥ ì°¨íŠ¸ëŠ” ì˜ì–‘ ë¶€ì¡±ê³¼ ì„±ì¥ ì´ìƒì„ ì •ì˜í•  ë•Œ ëª¨ë“  ì‚¬ëŒì—ê²Œ ë™ì¼í•˜ê²Œ ì ìš©ë˜ëŠ” ëª¨ë¸ì„ ê°€ì •í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ì¸ê°„ ìƒë¬¼í•™ì˜ ë‹¤ì–‘ì„±ê³¼ í™˜ê²½ ì ì‘ì„ ë¬´ì‹œí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. \n\nì €ìëŠ” ìì‹ ì˜ ë”¸ì— ëŒ€í•œ ê²½í—˜ì„ ê³µìœ í•˜ë©°, ë”¸ì´ ê±´ê°•í•˜ê³  í™œë™ì ì„ì—ë„ ë¶ˆêµ¬í•˜ê³  \"ì˜ì–‘ì‹¤ì¡°\"ë¡œ ë¶„ë¥˜ëœ ì‚¬ë¡€ë¥¼ í†µí•´ ì„ìƒ í‰ê°€ì™€ ê°œì¸ ê±´ê°• ê°„ì˜ ê´´ë¦¬ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. \n\nì—°êµ¬ì— ë”°ë¥´ë©´, ì „ ì„¸ê³„ ê±´ê°• ì§€í‘œëŠ” ì£¼ë¡œ íŠ¹ì • ì¸êµ¬(ì£¼ë¡œ ì„œêµ¬ êµ­ê°€)ì˜ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ë©°, ë‹¤ì–‘í•œ ì§‘ë‹¨ì˜ ê±´ê°•ì„ ì˜ëª» í‘œí˜„í•  ìˆ˜ ìˆì–´ ë¶€ì ì ˆí•œ ê±´ê°• ê°œì…ìœ¼ë¡œ ì´ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n\në‚¨ì•„ì‹œì•„ ì¸êµ¬ëŠ” í‘œì¤€ ê±´ê°• ì§€í‘œì—ì„œ ì¢…ì¢… ë” ì‘ê²Œ ë‚˜íƒ€ë‚˜ì§€ë§Œ, ì´ëŠ” ë°˜ë“œì‹œ ê±´ê°•í•˜ì§€ ì•Šë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•˜ì§€ ì•Šìœ¼ë©°, ë³´í¸ì ì¸ ê¸°ì¤€ì´ ê°€ì§„ ê°€ì •ê³¼ ëª¨ìˆœë©ë‹ˆë‹¤. \n\nì´ ê¸°ì‚¬ëŠ” ê±´ê°• ì§€í‘œê°€ ì§€ì—­ ì¸êµ¬ì™€ ì¡°ê±´ì„ ë°˜ì˜í•˜ë„ë¡ ê°œë°œë˜ì–´ì•¼ í•œë‹¤ê³  ì£¼ì¥í•©ë‹ˆë‹¤. ë³´í¸ì ì¸ ê¸°ì¤€ì„ ê°•ìš”í•˜ëŠ” ëŒ€ì‹ , ê±´ê°•í•œ ê°œì¸ì´ ì˜ì–‘ ë¶€ì¡±ìœ¼ë¡œ ì˜ëª» ë¶„ë¥˜ë˜ëŠ” ê²ƒì„ ë°©ì§€í•´ì•¼ í•©ë‹ˆë‹¤. \n\nêµ¬ì‹ì˜ ê´‘ë²”ìœ„í•œ ê±´ê°• ê¸°ì¤€ì— ì˜ì¡´í•˜ëŠ” ê²ƒì€ ì˜ëª»ëœ ì§„ë‹¨ê³¼ ë¹„íš¨ìœ¨ì ì¸ ê³µê³µ ê±´ê°• ì •ì±…ìœ¼ë¡œ ì´ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê±´ê°• í‰ê°€ì—ì„œ ê°œì¸ê³¼ ì§‘ë‹¨ì˜ ì°¨ì´ë¥¼ ì¸ì •í•˜ëŠ” ë°©í–¥ìœ¼ë¡œì˜ ì „í™˜ì´ ë” ë‚˜ì€ ê±´ê°• ê²°ê³¼ë¥¼ ìœ„í•´ í•„ìˆ˜ì ì…ë‹ˆë‹¤.",
      "ja": "ã“ã®è¨˜äº‹ã§ã¯ã€å­ã©ã‚‚ã®æˆé•·ã‚„æ „é¤Šã‚’è©•ä¾¡ã™ã‚‹éš›ã®æ™®éçš„ãªå¥åº·åŸºæº–ã®é™ç•Œã«ã¤ã„ã¦è¿°ã¹ã¦ãŠã‚Šã€äººé–“ã®å¤šæ§˜æ€§ã‚’è€ƒæ…®ã—ãŸã‚ˆã‚Šå€‹åˆ¥åŒ–ã•ã‚ŒãŸåŸºæº–ã®å¿…è¦æ€§ãŒå¼·èª¿ã•ã‚Œã¦ã„ã¾ã™ã€‚\n\nç¾åœ¨ã®å¥åº·æŒ‡æ¨™ã€ä¾‹ãˆã°æˆé•·æ›²ç·šã¯ã€æ „é¤Šå¤±èª¿ã‚„æˆé•·ç•°å¸¸ã‚’å®šç¾©ã™ã‚‹éš›ã«ä¸€å¾‹ã®ãƒ¢ãƒ‡ãƒ«ã‚’å‰æã¨ã—ã¦ãŠã‚Šã€äººé–“ã®ç”Ÿç‰©å­¦çš„å¤šæ§˜æ€§ã‚„ç’°å¢ƒã¸ã®é©å¿œã‚’ç„¡è¦–ã—ã¦ã„ã¾ã™ã€‚è‘—è€…ã¯ã€è‡ªèº«ã®å¨˜ãŒå¥åº·ã§æ´»å‹•çš„ã§ã‚ã‚‹ã«ã‚‚ã‹ã‹ã‚ã‚‰ãšã€Œã‚„ã›å‹ã€ã¨åˆ†é¡ã•ã‚ŒãŸçµŒé¨“ã‚’å…±æœ‰ã—ã€è‡¨åºŠè©•ä¾¡ã¨å€‹ã€…ã®å¥åº·ã¨ã®é–“ã«ã‚ã‚‹ã‚®ãƒ£ãƒƒãƒ—ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚\n\nç ”ç©¶ã«ã‚ˆã‚‹ã¨ã€ä¸–ç•Œã®å¥åº·æŒ‡æ¨™ã¯ç‰¹å®šã®é›†å›£ï¼ˆä¸»ã«è¥¿æ´‹ï¼‰ã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿ã«ä¾å­˜ã—ã¦ã„ã‚‹ã“ã¨ãŒå¤šãã€å¤šæ§˜ãªã‚°ãƒ«ãƒ¼ãƒ—ã®å¥åº·ã‚’èª¤ã£ã¦è¡¨ç¾ã™ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ä¸é©åˆ‡ãªå¥åº·ä»‹å…¥ãŒè¡Œã‚ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚å—ã‚¢ã‚¸ã‚¢ã®äººã€…ã¯ã€æ¨™æº–çš„ãªå¥åº·æŒ‡æ¨™ã§ã¯å°æŸ„ã«è¦‹ãˆã‚‹ã“ã¨ãŒå¤šã„ã§ã™ãŒã€å¿…ãšã—ã‚‚ä¸å¥åº·ã§ã‚ã‚‹ã‚ã‘ã§ã¯ãªã„ã¨ã„ã†ç ”ç©¶çµæœã‚‚ã‚ã‚Šã€æ™®éçš„ãªåŸºæº–ã®å‰æã«çŸ›ç›¾ã—ã¦ã„ã¾ã™ã€‚\n\nã“ã®è¨˜äº‹ã¯ã€åœ°åŸŸã®äººå£ã‚„æ¡ä»¶ã‚’åæ˜ ã—ãŸå¥åº·æŒ‡æ¨™ã®é–‹ç™ºã‚’æ±‚ã‚ã¦ãŠã‚Šã€å¥åº·ãªå€‹äººã‚’æ „é¤Šå¤±èª¿ã¨èª¤ã£ã¦ãƒ©ãƒ™ãƒªãƒ³ã‚°ã™ã‚‹ã‚ˆã†ãªæ™®éçš„åŸºæº–ã‚’æŠ¼ã—ä»˜ã‘ã‚‹ã®ã§ã¯ãªãã€å€‹åˆ¥ã®ãƒ‹ãƒ¼ã‚ºã«å¿œã˜ãŸè©•ä¾¡ãŒå¿…è¦ã§ã‚ã‚‹ã¨è¨´ãˆã¦ã„ã¾ã™ã€‚å¤ã„åºƒç¯„ãªå¥åº·åŸºæº–ã«ä¾å­˜ã™ã‚‹ã“ã¨ã¯ã€èª¤è¨ºã‚„åŠ¹æœçš„ã§ãªã„å…¬è¡†è¡›ç”Ÿæ”¿ç­–ã‚’æ‹›ãå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚å¥åº·è©•ä¾¡ã«ãŠã„ã¦å€‹äººã‚„é›†å›£ã®é•ã„ã‚’èªè­˜ã™ã‚‹ã“ã¨ãŒã€ã‚ˆã‚Šè‰¯ã„å¥åº·çµæœã‚’å¾—ã‚‹ãŸã‚ã«ã¯ä¸å¯æ¬ ã§ã™ã€‚"
    }
  },
  {
    "id": "783456a1fffac035",
    "title": {
      "en": "MS-DOS and Windows 3.11 still run train dashboards at German railway (Jan'24)",
      "ko": "ë…ì¼ ê¸°ì°¨, MS-DOSë¡œ ìš´í–‰!",
      "ja": "ãƒ‰ã‚¤ãƒ„é‰„é“ã®ãƒ¬ãƒˆãƒ­æŠ€è¡“"
    },
    "type": "story",
    "url": "https://www.tomshardware.com/software/windows/ms-dos-and-windows-311-still-run-train-dashboards-at-german-railway-company-listed-admin-job-for-30-year-old-operating-system",
    "score": 23,
    "by": "wojtczyk",
    "time": 1743294115,
    "content": "Software\n\nOperating Systems\n\nWindows\n\nMS-DOS and Windows 3.11 still run train dashboards at German railway â€” company listed admin job for 30-year-old operating system\n\nNews\n\nBy\nMark Tyson\n\npublished\nJanuary 29, 2024\n\nMany with the requisite experience might already have retired.\n\nComments (41)\n\nWhen you purchase through links on our site, we may earn an affiliate commission. Hereâ€™s how it works.\n\nwindow.vanilla.infiniteArticlesData = [];\n\n(Image credit: Microsoft / Archive.org)\n\nA German railway firm posted a vacancy for a Windows 3.11 Administrator just before the weekend. In addition to skills in wrangling Windows for Workgroups on the 30-year-old operating system, the recruiter would look upon a candidate more fondly for possessing MS-DOS experience. The admin would purportedly oversee systems with 166MHz processors and a whopping 8MB of RAM. It might seem slightly worrying that modern railways are still running on such ancient systems, but mission-critical systems often adhere to the \"if it ain't broke, don't fix it\" philosophy.Silicon lover Konkretor highlighted the above vacancy on Twitter / X and explained that the hiring company was responsible for \"railway display boards for almost all of Germany.\" These systems obviously rely in some part on old MS-DOS and Windows 3.11 applications.The job listing, which we saw yesterday, seems to have been taken down today. It mentions that the appointee will maintain and update the old systems that are still pivotal to railway operations. In further detail, we learn that this software is responsible for \"the driver's cab display system on high-speed and regional trains [which] shows the driver the most important technical data in real-time.\"Latest Videos From Tom's HardwareTom's Hardware(Image credit: Future)Seeing such old legacy OSes being relied upon for delivering important real-time data is somewhat worrying, but it isn't uncommon to find old mission-critical systems run by old software. Additionally, the display might only provide data for information, not critical safety systems.Windows 3.1X was notable for being the first version of Microsoftâ€™s GUI-based operating system with integrated networking and introduced a 386-protected mode networking stack. Microsoft launched this network-friendly OS back in 1992 and ended support for it on December 31, 2001. Did the German rail company miss the memo?According to some chit-chat on the Hacker News forum, the above-mentioned legacy system is currently in use on Germanyâ€™s ICE 1 and ICE 2 trains. If true, the software that's reliant on MS-DOS and Win 3.11 might be required until 2030 or later. Another interesting titbit was the assertion that one of the railway systems running Win 3.11 has a BIOS dating from 1996 and features a 166MHz processor plus 8MB of RAM.Ancient hardware and software keep turning up in the most unexpected places. Only yesterday, we reported on Japanâ€™s mandarins finally being weaned off their addiction to floppy disks. Meanwhile, enthusiasts still purchase computers based around Intelâ€™s ancient 8088 CPU and dabble in overclocking ISA bus graphics cards.\n    window.sliceComponents = window.sliceComponents || {};\n\n    externalsScriptLoaded.then(() => {\n        window.reliablePageLoad.then(() => {\n            var componentContainer = document.querySelector(\"#slice-container-newsletterForm-articleInbodyContent-6EUoMxv6HkgrQXtdpZFVQj\");\n\n            if (componentContainer) {\n                var data = {\"layout\":\"inbodyContent\",\"header\":\"Stay On the Cutting Edge: Get the Tom's Hardware Newsletter\",\"tagline\":\"Get Tom's Hardware's best news and in-depth reviews, straight to your inbox.\",\"formFooterText\":\"By submitting your information you agree to the <a href=\\\"https:\\/\\/futureplc.com\\/terms-conditions\\/\\\" target=\\\"_blank\\\">Terms & Conditions<\\/a> and <a href=\\\"https:\\/\\/futureplc.com\\/privacy-policy\\/\\\" target=\\\"_blank\\\">Privacy Policy<\\/a> and are aged 16 or over.\",\"successMessage\":{\"body\":\"Thank you for signing up. You will receive a confirmation email shortly.\"},\"failureMessage\":\"There was a problem. Please refresh the page and try again.\",\"method\":\"POST\",\"inputs\":[{\"type\":\"hidden\",\"name\":\"NAME\"},{\"type\":\"email\",\"name\":\"MAIL\",\"placeholder\":\"Your Email Address\",\"required\":true},{\"type\":\"hidden\",\"name\":\"NEWSLETTER_CODE\",\"value\":\"XTH-X\"},{\"type\":\"hidden\",\"name\":\"LANG\",\"value\":\"EN\"},{\"type\":\"hidden\",\"name\":\"SOURCE\",\"value\":\"60\"},{\"type\":\"hidden\",\"name\":\"COUNTRY\"},{\"type\":\"checkbox\",\"name\":\"CONTACT_OTHER_BRANDS\",\"label\":{\"text\":\"Contact me with news and offers from other Future brands\"}},{\"type\":\"checkbox\",\"name\":\"CONTACT_PARTNERS\",\"label\":{\"text\":\"Receive email from us on behalf of our trusted partners or sponsors\"}},{\"type\":\"submit\",\"value\":\"Sign me up\",\"required\":true}],\"endpoint\":\"https:\\/\\/newsletter-subscribe.futureplc.com\\/v2\\/submission\\/submit\",\"analytics\":[{\"analyticsType\":\"widgetViewed\"}],\"ariaLabels\":{}};\n\n                var triggerHydrate = function() {\n                    window.sliceComponents.newsletterForm.hydrate(data, componentContainer);\n                }\n\n                if (window.lazyObserveElement) {\n                    window.lazyObserveElement(componentContainer, triggerHydrate);\n                } else {\n                    triggerHydrate();\n                }\n            }\n        }).catch(err => console.error('%c FTE ','background: #9306F9; color: #ffffff','Hydration Script has failed for newsletterForm-articleInbodyContent-6EUoMxv6HkgrQXtdpZFVQj Slice', err));\n    }).catch(err => console.error('%c FTE ','background: #9306F9; color: #ffffff','Externals script failed to load', err));\nStay On the Cutting Edge: Get the Tom's Hardware NewsletterGet Tom's Hardware's best news and in-depth reviews, straight to your inbox.Contact me with news and offers from other Future brandsReceive email from us on behalf of our trusted partners or sponsorsBy submitting your information you agree to the Terms & Conditions and Privacy Policy and are aged 16 or over.\n\nSee all comments (41)\n\nMark TysonSocial Links NavigationNews EditorMark Tyson is a news editor at Tom's Hardware. He enjoys covering the full breadth of PC tech; from business and semiconductor design to products approaching the edge of reason.\n\nLatest in Windows\n\nNew Windows file system option supports up to 35 petabyte volumes â€” ReFS appears in latest Insider build\n\n<a style=\"position: relative!important;\" href=\"SPONSORED_LINK_URL\">\n<picture>\n<source srcset=\"SPONSORED_IMAGE_URL.webp\" type=\"image/webp\" />\n<img src=\"SPONSORED_IMAGE_URL\" alt=\"SPONSORED_HEADLINE\" loading=\"lazy\"/>\n</picture>\n<span class=\"text-base text-black font-bold mx-0 my-2.5 p-0\">SPONSORED_HEADLINE</span>\n</a>\n\nHow to Zoom in and Out in Windows 11 or 10\n\n<a style=\"position: relative!important;\" href=\"SPONSORED_LINK_URL\">\n<picture>\n<source srcset=\"SPONSORED_IMAGE_URL.webp\" type=\"image/webp\" />\n<img src=\"SPONSORED_IMAGE_URL\" alt=\"SPONSORED_HEADLINE\" loading=\"lazy\"/>\n</picture>\n<span class=\"text-base text-black font-bold mx-0 my-2.5 p-0\">SPONSORED_HEADLINE</span>\n</a>\n\nWindows 11 Insider builds offer FAQs based on your PC's specs\n\n<a style=\"position: relative!important;\" href=\"SPONSORED_LINK_URL\">\n<picture>\n<source srcset=\"SPONSORED_IMAGE_URL.webp\" type=\"image/webp\" />\n<img src=\"SPONSORED_IMAGE_URL\" alt=\"SPONSORED_HEADLINE\" loading=\"lazy\"/>\n</picture>\n<span class=\"text-base text-black font-bold mx-0 my-2.5 p-0\">SPONSORED_HEADLINE</span>\n</a>\n\nHow to Restart Windows Explorer in Windows 11\n\n<a style=\"position: relative!important;\" href=\"SPONSORED_LINK_URL\">\n<picture>\n<source srcset=\"SPONSORED_IMAGE_URL.webp\" type=\"image/webp\" />\n<img src=\"SPONSORED_IMAGE_URL\" alt=\"SPONSORED_HEADLINE\" loading=\"lazy\"/>\n</picture>\n<span class=\"text-base text-black font-bold mx-0 my-2.5 p-0\">SPONSORED_HEADLINE</span>\n</a>\n\nMicrosoft updates Windows 11 CPU support for OEM systems to include 8th to 10th Gen Intel CPUs\n\n<a style=\"position: relative!important;\" href=\"SPONSORED_LINK_URL\">\n<picture>\n<source srcset=\"SPONSORED_IMAGE_URL.webp\" type=\"image/webp\" />\n<img src=\"SPONSORED_IMAGE_URL\" alt=\"SPONSORED_HEADLINE\" loading=\"lazy\"/>\n</picture>\n<span class=\"text-base text-black font-bold mx-0 my-2.5 p-0\">SPONSORED_HEADLINE</span>\n</a>\n\nWindows 11 Task Manager update will show accurate CPU utilization, align with industry standards\n\n<a style=\"position: relative!important;\" href=\"SPONSORED_LINK_URL\">\n<picture>\n<source srcset=\"SPONSORED_IMAGE_URL.webp\" type=\"image/webp\" />\n<img src=\"SPONSORED_IMAGE_URL\" alt=\"SPONSORED_HEADLINE\" loading=\"lazy\"/>\n</picture>\n<span class=\"text-base text-black font-bold mx-0 my-2.5 p-0\">SPONSORED_HEADLINE</span>\n</a>\n\nLatest in News\n\nIntel and SK hynix close NAND business deal: Intel gets $1.9 billion, SK hynix gets IP and employees\n\n<a style=\"position: relative!important;\" href=\"SPONSORED_LINK_URL\">\n<picture>\n<source srcset=\"SPONSORED_IMAGE_URL.webp\" type=\"image/webp\" />\n<img src=\"SPONSORED_IMAGE_URL\" alt=\"SPONSORED_HEADLINE\" loading=\"lazy\"/>\n</picture>\n<span class=\"text-base text-black font-bold mx-0 my-2.5 p-0\">SPONSORED_HEADLINE</span>\n</a>\n\nZotac RTX 5090 GPUs with missing ROPs sold at premium price by German retailer\n\n<a style=\"position: relative!important;\" href=\"SPONSORED_LINK_URL\">\n<picture>\n<source srcset=\"SPONSORED_IMAGE_URL.webp\" type=\"image/webp\" />\n<img src=\"SPONSORED_IMAGE_URL\" alt=\"SPONSORED_HEADLINE\" loading=\"lazy\"/>\n</picture>\n<span class=\"text-base text-black font-bold mx-0 my-2.5 p-0\">SPONSORED_HEADLINE</span>\n</a>\n\nTaiwanese authorities accuse SMIC and allies of poaching engineers\n\n<a style=\"position: relative!important;\" href=\"SPONSORED_LINK_URL\">\n<picture>\n<source srcset=\"SPONSORED_IMAGE_URL.webp\" type=\"image/webp\" />\n<img src=\"SPONSORED_IMAGE_URL\" alt=\"SPONSORED_HEADLINE\" loading=\"lazy\"/>\n</picture>\n<span class=\"text-base text-black font-bold mx-0 my-2.5 p-0\">SPONSORED_HEADLINE</span>\n</a>\n\n$3,700 RTX 5090 GPUs have found new homes after sitting on US retailer's shelves\n\n<a style=\"position: relative!important;\" href=\"SPONSORED_LINK_URL\">\n<picture>\n<source srcset=\"SPONSORED_IMAGE_URL.webp\" type=\"image/webp\" />\n<img src=\"SPONSORED_IMAGE_URL\" alt=\"SPONSORED_HEADLINE\" loading=\"lazy\"/>\n</picture>\n<span class=\"text-base text-black font-bold mx-0 my-2.5 p-0\">SPONSORED_HEADLINE</span>\n</a>\n\nNvidia's 50-series laptop launch looks bumpy: slipping ship dates, game crashes, and delayed review units\n\n<a style=\"position: relative!important;\" href=\"SPONSORED_LINK_URL\">\n<picture>\n<source srcset=\"SPONSORED_IMAGE_URL.webp\" type=\"image/webp\" />\n<img src=\"SPONSORED_IMAGE_URL\" alt=\"SPONSORED_HEADLINE\" loading=\"lazy\"/>\n</picture>\n<span class=\"text-base text-black font-bold mx-0 my-2.5 p-0\">SPONSORED_HEADLINE</span>\n</a>\n\nIntel's board gets industry-focused as three directors will not seek re-election â€” badly needed shift to deeper tech experience\n\n<a style=\"position: relative!important;\" href=\"SPONSORED_LINK_URL\">\n<picture>\n<source srcset=\"SPONSORED_IMAGE_URL.webp\" type=\"image/webp\" />\n<img src=\"SPONSORED_IMAGE_URL\" alt=\"SPONSORED_HEADLINE\" loading=\"lazy\"/>\n</picture>\n<span class=\"text-base text-black font-bold mx-0 my-2.5 p-0\">SPONSORED_HEADLINE</span>\n</a>\n\nMore about windows\n\nNew Windows file system option supports up to 35 petabyte volumes â€” ReFS appears in latest Insider build\n\nHow to Zoom in and Out in Windows 11 or 10\n\nLatest\n\nBest Graphics Cards for Gaming in 2025\n\nSee more latest\n\n41 Comments\n\nComment from the forums\n\nwarezme\n\nI used to like MS-DOS and WIndows 3.11. This is quick OS on a 166 to 200Mhz CPU. It's probably a simple program designed to display data from some serial or RS232 connected sensors on the train. Quick efficient and simple. As cheap as all that is it would be simple to make is super redundant and shock and weather proof. Nothing wrong with any of that. You don't need a super CPU with tons of memory to do any of that unless you are redesigning the whole train with new displays and camera monitoring.\n\nReply\n\nOpcod\n\nOh interesting.. So having a stable system means ... stable. And now they push update every 5 min and other update to fix what is broken.. Moving forward is not always the best.\n\nReply\n\nCOLGeek\n\nI would imagine this is a very closed, tightly controlled environment, with minimal external risk. Assuming that is true, I don't see an issue here for the purpose being met.\n\nDefinitely a novel thing to read about.\n\nReply\n\nDr3ams\n\nI live in Germany and could admin Windows 3.11 and DOS. But I'm happily retired. :cool:\n\nI do have Windows 3.11 and Dos 6.22 installed in a virtual machine though...just to tinker with.\n\nReply\n\nekio\n\nDeutsch qualitatâ€¦\n\nReply\n\nBlastomonas\n\nSimple and reliable. The more complexity introduced, the more unreliable things seem to become.\n\nReply\n\nJeffreyP55\n\nAdmin said:A German railway firm posted a vacancy for a Windows 3.11 Administrator just ahead of the weekend. In addition to possessing skills in wrangling Windows for Workgroups, the recruiter wants a candidate with MS-DOS experience.\n\nMS-DOS and Windows 3.11 still run train dashboards at German railway â€” company listed admin job for 30-year-old operating system : Read moreOooo, with 32bit extensions! That was a weird modification.\n\nReply\n\nbigdragon\n\nSimple, understood, and reliable -- why wouldn't you use an old OS or custom OS to manage a train system? As long as the control interface isn't on the internet there shouldn't be a problem. Modern OS implementations have a penchant for interrupting, suggesting distractions, or buried bugs.\n\nReply\n\nDarkoverlordofdata\n\nLegacy hardware means legacy software - often custom. It probably costs more than their budget to replace it with modern railyard software.\n\nReply\n\nMrcreosote\n\nMaybe 10 years ago, I fired up a 3.11 PC and the damn thing was FAST. Booted much quicker than my XP and later stuff. Worked well, but my NEC CPM Z80A PC worked like a sewing machine.\n\nReply\n\nView All 41 Comments\n\nShow more comments\n\nMost Popular\n\nZotac RTX 5090 GPUs with missing ROPs sold at premium price by German retailer\n\nIntel and SK hynix close NAND business deal: Intel gets $1.9 billion, SK hynix gets IP and employees\n\nTaiwanese authorities accuse SMIC and allies of poaching engineers\n\nNvidia's 50-series laptop launch looks bumpy: slipping ship dates, game crashes, and delayed review units\n\n$3,700 RTX 5090 GPUs have found new homes after sitting on US retailer's shelves\n\nIntel's board gets industry-focused as three directors will not seek re-election â€” badly needed shift to deeper tech experience\n\nChina's AI data center boom goes bust: Rush leaves billions of dollars in idle infrastructure\n\nTSMC to reportedly speed up fab building in the US, third fab to begin construction this year\n\nEx-Intel CEO Gelsinger warns TSMC's $165B investment will not restore U.S. semiconductor leadership\n\nMicrosoft updates the Windows Game Bar to be more user friendly with PC Handhelds\n\nif(FUTR && FUTR.Connect){\n//Init Connect article History\nclass userNav {\nconstructor(key = 'connect_articles_history') {\nthis.key = key;\nthis.flushKey = `${key}_flush`;\nthis.propsKey = `${key}_props`;\nthis.store();\nconsole.info(\"FUTR.Connect.userNav - Init - Start - Using reduxStore\");\n}\nstore() {\nconst isArticle = window?.reduxStore?.getState()?.vanilla?.isArticle;\nif (typeof isArticle !== 'undefined' && isArticle && FUTR && FUTR.Connect) {\ntry {\nconst month = `${new Date().getFullYear()}-${new Date().getMonth()}`;\n//flush monthly\nif (localStorage.getItem(this.flushKey) !== month) {\nlocalStorage.setItem(this.key, btoa('[]'));\nlocalStorage.setItem(this.propsKey, []);\nlocalStorage.setItem(this.flushKey, month);\n}\nconst currentUrl = location.pathname;\nconst urls = JSON.parse(atob(localStorage.getItem(this.key) || btoa('[]')));\nconst props = JSON.parse(localStorage.getItem(this.propsKey)|| '[]');\nif (!urls.includes(currentUrl) && this.getProps().length < 20 || this.getProps().length <1) {\nurls.push(currentUrl);\nif (window.ffte && window.ffte.properties) {\nprops.push(window.ffte.properties);\nconsole.log(\"props push\", props)\n}\nlocalStorage.setItem(this.key, btoa(JSON.stringify(urls)));\nlocalStorage.setItem(this.propsKey, JSON.stringify(props));\n}\nconsole.info(\"FUTR.Connect.userNav - Urls Stored\");\n} catch (e) {\nconsole.warn('userNav:', e);\n}\n}\n}\ngetHistory() {\ntry {\nreturn JSON.parse(atob(localStorage.getItem(this.key) || btoa('[]')));\n} catch {\nreturn [];\n}\n}\ngetProps() {\ntry {\nreturn JSON.parse(localStorage.getItem(this.propsKey) || '[]');\n} catch {\nreturn [];\n}\n}\n};\nFUTR.Connect.userNav = new userNav();\nconsole.info(\"FUTR.Connect.userNav - Init - Done\", FUTR.Connect.userNav);\n}",
    "summary": {
      "en": "A German railway company recently advertised a job for a Windows 3.11 Administrator, needing someone experienced with this 30-year-old operating system and MS-DOS. The job involves managing systems with very old hardwareâ€”specifically, 166MHz processors and 8MB of RAM. These outdated systems are still crucial for operating display boards on trains, showing real-time technical data to drivers. While it may seem concerning that modern railways rely on such ancient software, many critical systems stay with older technology because they are deemed reliable. The job listing was quickly removed, but it indicates that these legacy systems may remain in use until at least 2030.",
      "ko": "ìµœê·¼ ë…ì¼ì˜ í•œ ì² ë„ íšŒì‚¬ê°€ 30ë…„ ëœ ìš´ì˜ ì²´ì œì¸ ìœˆë„ìš° 3.11ê³¼ MS-DOSì— ëŒ€í•œ ê²½í—˜ì´ ìˆëŠ” ê´€ë¦¬ìë¥¼ êµ¬í•˜ëŠ” ì±„ìš© ê³µê³ ë¥¼ ëƒˆë‹¤. ì´ ì§ë¬´ëŠ” 166MHz í”„ë¡œì„¸ì„œì™€ 8MB RAMì„ ê°–ì¶˜ ë§¤ìš° ì˜¤ë˜ëœ í•˜ë“œì›¨ì–´ë¥¼ ê´€ë¦¬í•˜ëŠ” ì¼ì„ í¬í•¨í•œë‹¤. ì´ëŸ¬í•œ êµ¬ì‹ ì‹œìŠ¤í…œì€ ê¸°ì°¨ì˜ ë””ìŠ¤í”Œë ˆì´ ë³´ë“œë¥¼ ìš´ì˜í•˜ëŠ” ë° ì—¬ì „íˆ ì¤‘ìš”í•˜ë©°, ìš´ì „ì‚¬ì—ê²Œ ì‹¤ì‹œê°„ ê¸°ìˆ  ë°ì´í„°ë¥¼ ì œê³µí•œë‹¤. í˜„ëŒ€ì˜ ì² ë„ ì‹œìŠ¤í…œì´ ì´ë ‡ê²Œ ì˜¤ë˜ëœ ì†Œí”„íŠ¸ì›¨ì–´ì— ì˜ì¡´í•˜ê³  ìˆë‹¤ëŠ” ì‚¬ì‹¤ì€ ë‹¤ì†Œ ìš°ë ¤ìŠ¤ëŸ¬ìš¸ ìˆ˜ ìˆì§€ë§Œ, ë§ì€ ì¤‘ìš”í•œ ì‹œìŠ¤í…œì€ ì‹ ë¢°ì„±ì´ ë†’ë‹¤ê³  í‰ê°€ë°›ì•„ êµ¬í˜• ê¸°ìˆ ì„ ê³„ì† ì‚¬ìš©í•˜ê³  ìˆë‹¤. ì´ ì±„ìš© ê³µê³ ëŠ” ë¹ ë¥´ê²Œ ì‚­ì œë˜ì—ˆì§€ë§Œ, ì´ëŸ¬í•œ ë ˆê±°ì‹œ ì‹œìŠ¤í…œì´ ìµœì†Œí•œ 2030ë…„ê¹Œì§€ëŠ” ê³„ì† ì‚¬ìš©ë  ê°€ëŠ¥ì„±ì´ ìˆìŒì„ ì‹œì‚¬í•œë‹¤.",
      "ja": "ãƒ‰ã‚¤ãƒ„ã®é‰„é“ä¼šç¤¾ãŒæœ€è¿‘ã€Windows 3.11ã®ç®¡ç†è€…ã‚’å‹Ÿé›†ã—ã¾ã—ãŸã€‚ã“ã®ã‚ªãƒšãƒ¬ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ã¯30å¹´å‰ã®ã‚‚ã®ã§ã€MS-DOSã®çµŒé¨“ã‚‚æ±‚ã‚ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚ä»•äº‹å†…å®¹ã¯ã€166MHzã®ãƒ—ãƒ­ã‚»ãƒƒã‚µã¨8MBã®RAMã‚’æ­è¼‰ã—ãŸéå¸¸ã«å¤ã„ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã‚’ç®¡ç†ã™ã‚‹ã“ã¨ã§ã™ã€‚ã“ã‚Œã‚‰ã®æ—§å¼ã®ã‚·ã‚¹ãƒ†ãƒ ã¯ã€åˆ—è»Šã®è¡¨ç¤ºæ¿ã‚’æ“ä½œã™ã‚‹ãŸã‚ã«é‡è¦ã§ã€é‹è»¢å£«ã«ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã®æŠ€è¡“ãƒ‡ãƒ¼ã‚¿ã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚ç¾ä»£ã®é‰„é“ãŒã“ã®ã‚ˆã†ãªå¤ã„ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã«ä¾å­˜ã—ã¦ã„ã‚‹ã“ã¨ã¯å¿ƒé…ã«æ€ãˆã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ãŒã€å¤šãã®é‡è¦ãªã‚·ã‚¹ãƒ†ãƒ ã¯ä¿¡é ¼æ€§ãŒé«˜ã„ãŸã‚ã€å¤ã„æŠ€è¡“ã‚’ä½¿ã„ç¶šã‘ã¦ã„ã¾ã™ã€‚ã“ã®æ±‚äººã¯ã™ãã«å‰Šé™¤ã•ã‚Œã¾ã—ãŸãŒã€ã“ã‚Œã‚‰ã®ãƒ¬ã‚¬ã‚·ãƒ¼ã‚·ã‚¹ãƒ†ãƒ ã¯å°‘ãªãã¨ã‚‚2030å¹´ã¾ã§ä½¿ç”¨ã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚"
    }
  },
  {
    "id": "d427bd25f1a033c7",
    "title": {
      "en": "Postgres Language Server: Initial Release",
      "ko": "í¬ìŠ¤íŠ¸ê·¸ë ˆìŠ¤ ì–¸ì–´ ì„œë²„ ì¶œì‹œ",
      "ja": "Postgresè¨€èªã‚µãƒ¼ãƒãƒ¼ç™»å ´"
    },
    "type": "story",
    "url": "https://github.com/supabase-community/postgres-language-server",
    "score": 294,
    "by": "steinroe",
    "time": 1743239623,
    "content": "Postgres Language Server\nA collection of language tools and a Language Server Protocol (LSP) implementation for Postgres, focusing on developer experience and reliable SQL tooling.\nDocs: pgtools.dev\nInstall: instructions\n\nCLI releases\nVSCode\nNeovim\n\nOverview\n\nLSP Demo\nCLI Demo\n\nThis project provides a toolchain for Postgres development, built on Postgres' own parser libpg_query to ensure 100% syntax compatibility. It is built on a Server-Client architecture with a transport-agnostic design. This means all features can be accessed not only through the Language Server Protocol, but also through other interfaces like a CLI, HTTP APIs, or a WebAssembly module. The goal is to make all the great Postgres tooling out there as accessible as possible, and to build anything that is missing ourselves.\nThe following features are implemented:\n\nAutocompletion\nSyntax Error Highlighting\nType-checking (via EXPLAIN error insights)\nLinter, inspired by Squawk\n\nOur current focus is on refining and enhancing these core features while building a robust and easily accessible infrastructure. For future plans and opportunities to contribute, please check out the issues and discussions. Any contributions are welcome!\nContributors\n\npsteinroe\njuleswritescode\n\nAcknowledgements\nA big thanks to the following projects, without which this project wouldn't have been possible:\n\nlibpg_query: For extracting the Postgres' parser\nBiome: For implementing a toolchain infrastructure we could copy from\nSquawk: For the linter inspiration",
    "summary": {
      "en": "**Postgres Language Server Summary**\n\nThe Postgres Language Server is a set of development tools for Postgres that enhances the SQL programming experience. It uses Postgres' own parser to ensure accurate syntax checking. The server can be accessed in various ways, including a command-line interface (CLI), HTTP APIs, and WebAssembly.\n\n**Key Features:**\n- Autocompletion\n- Syntax Error Highlighting\n- Type-checking using EXPLAIN error insights\n- Linter inspired by the tool Squawk\n\nThe project aims to improve these features and create a user-friendly infrastructure. Contributions are encouraged, and more information can be found in their discussions and issues.\n\n**Contributors:**\n- psteinroe\n- juleswritescode\n\n**Acknowledgements:**\nThanks to libpg_query, Biome, and Squawk for their support in developing this project.",
      "ko": "Postgres ì–¸ì–´ ì„œë²„ëŠ” Postgresë¥¼ ìœ„í•œ ê°œë°œ ë„êµ¬ ëª¨ìŒìœ¼ë¡œ, SQL í”„ë¡œê·¸ë˜ë° ê²½í—˜ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ì´ ì„œë²„ëŠ” Postgresì˜ ìì²´ íŒŒì„œë¥¼ ì‚¬ìš©í•˜ì—¬ ì •í™•í•œ êµ¬ë¬¸ ê²€ì‚¬ë¥¼ ë³´ì¥í•©ë‹ˆë‹¤. ì„œë²„ëŠ” ëª…ë ¹ì¤„ ì¸í„°í˜ì´ìŠ¤(CLI), HTTP API, WebAssembly ë“± ë‹¤ì–‘í•œ ë°©ë²•ìœ¼ë¡œ ì ‘ê·¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nì£¼ìš” ê¸°ëŠ¥ìœ¼ë¡œëŠ” ìë™ ì™„ì„±, êµ¬ë¬¸ ì˜¤ë¥˜ ê°•ì¡°, EXPLAIN ì˜¤ë¥˜ í†µì°°ë ¥ì„ í™œìš©í•œ íƒ€ì… ê²€ì‚¬, Squawk ë„êµ¬ì—ì„œ ì˜ê°ì„ ë°›ì€ ë¦°í„°ê°€ ìˆìŠµë‹ˆë‹¤. ì´ í”„ë¡œì íŠ¸ëŠ” ì´ëŸ¬í•œ ê¸°ëŠ¥ì„ ê°œì„ í•˜ê³  ì‚¬ìš©ì ì¹œí™”ì ì¸ ì¸í”„ë¼ë¥¼ ë§Œë“œëŠ” ê²ƒì„ ëª©í‘œë¡œ í•˜ê³  ìˆìŠµë‹ˆë‹¤. ê¸°ì—¬ë¥¼ í™˜ì˜í•˜ë©°, ë” ë§ì€ ì •ë³´ëŠ” ë…¼ì˜ ë° ì´ìŠˆì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nê¸°ì—¬ìì—ëŠ” psteinroeì™€ juleswritescodeê°€ ìˆìŠµë‹ˆë‹¤. ì´ í”„ë¡œì íŠ¸ ê°œë°œì„ ì§€ì›í•´ ì¤€ libpg_query, Biome, Squawkì— ê°ì‚¬ë“œë¦½ë‹ˆë‹¤.",
      "ja": "Postgres Language Serverã¯ã€Postgresç”¨ã®é–‹ç™ºãƒ„ãƒ¼ãƒ«ã‚»ãƒƒãƒˆã§ã€SQLãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã®ä½“é¨“ã‚’å‘ä¸Šã•ã›ã¾ã™ã€‚ã“ã®ã‚µãƒ¼ãƒãƒ¼ã¯ã€Postgresç‹¬è‡ªã®ãƒ‘ãƒ¼ã‚µãƒ¼ã‚’ä½¿ç”¨ã—ã¦ã€æ­£ç¢ºãªæ§‹æ–‡ãƒã‚§ãƒƒã‚¯ã‚’è¡Œã„ã¾ã™ã€‚ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ï¼ˆCLIï¼‰ã€HTTP APIã€WebAssemblyãªã©ã€ã•ã¾ã–ã¾ãªæ–¹æ³•ã§ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã™ã€‚\n\nä¸»ãªæ©Ÿèƒ½ã«ã¯ã€ã‚ªãƒ¼ãƒˆã‚³ãƒ³ãƒ—ãƒªãƒ¼ãƒˆã€æ§‹æ–‡ã‚¨ãƒ©ãƒ¼ã®ãƒã‚¤ãƒ©ã‚¤ãƒˆã€EXPLAINã‚¨ãƒ©ãƒ¼ã®æ´å¯Ÿã‚’åˆ©ç”¨ã—ãŸå‹ãƒã‚§ãƒƒã‚¯ã€ãƒ„ãƒ¼ãƒ«Squawkã«è§¦ç™ºã•ã‚ŒãŸãƒªãƒ³ã‚¿ãƒ¼ãŒã‚ã‚Šã¾ã™ã€‚ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ã€ã“ã‚Œã‚‰ã®æ©Ÿèƒ½ã‚’æ”¹å–„ã—ã€ä½¿ã„ã‚„ã™ã„ã‚¤ãƒ³ãƒ•ãƒ©ã‚’æ§‹ç¯‰ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¦ã„ã¾ã™ã€‚è²¢çŒ®ã‚’æ­“è¿ã—ã¦ãŠã‚Šã€è©³ç´°ã¯ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³ã‚„èª²é¡Œã§ç¢ºèªã§ãã¾ã™ã€‚\n\nè²¢çŒ®è€…ã«ã¯ã€psteinroeã•ã‚“ã¨juleswritescodeã•ã‚“ãŒã„ã¾ã™ã€‚ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®é–‹ç™ºã«ã‚ãŸã‚Šã€libpg_queryã€Biomeã€Squawkã«æ„Ÿè¬ã—ã¾ã™ã€‚"
    }
  },
  {
    "id": "0d83769ff3100414",
    "title": {
      "en": "Self-contained Python scripts with uv",
      "ko": "ë…ë¦½í˜• íŒŒì´ì¬ ìŠ¤í¬ë¦½íŠ¸",
      "ja": "è‡ªå·±å®Œçµå‹Pythonã‚¹ã‚¯ãƒªãƒ—ãƒˆ"
    },
    "type": "story",
    "url": "http://blog.dusktreader.dev/2025/03/29/self-contained-python-scripts-with-uv/",
    "score": 7,
    "by": "todsacerdoti",
    "time": 1743290578,
    "content": "Python\n\n        uv\n\nSelf-contained Python scripts with uv\n\nTLDR\nYou can add uv into the shebang line for a Python script to make it a self-contained executable.\n\nI am working on a Go project to better learn the language. It's a simple API backed by a postgres database.\nWhen I need to test out an endpoint, I prefer to use the httpx python package inside an\nipython REPL over making curl requests. It's nice to be able to introspect responses and easily\npackage payloads with dicts instead of writing out JSON.\nAnyway, I decided to write a script to upsert some user data so that I can beat on my /users endpoint.\n\nMy jam_users.py script looks like this:\nimport httpx\nimport IPython\nfrom loguru import logger\n\nusers = [\n    dict(name=\"The Dude\", email=\"the.dude@abides.com\", password=\"thedudeabides\"),\n    dict(name=\"Walter Sobchak\", email=\"walter@sobchak-security.com\", password=\"vietnamvet\"),\n    dict(name=\"Donnie\", email=\"donniesurfs@yahoo.com\", password=\"iamthewalrus\"),\n    dict(name=\"Maude\", email=\"mauddie@avant-guard.com\", password=\"goodmanandthorough\"),\n]\n\nr = httpx.get(\"http://localhost:4000/v1/users\")\nr.raise_for_status()\n\nfor user in r.json()[\"users\"]:\n    logger.info(f\"Deleting: {user['name']}\")\n    r = httpx.delete(f\"http://localhost:4000/v1/users/{user['id']}\")\n    r.raise_for_status()\n\nfor user in users:\n    r = httpx.post(\"http://localhost:4000/v1/users\", json=user)\n    r.raise_for_status()\n    logger.info(f\"Created: {r.json()}\")\n\nIPython.embed()\n\nThis is really straight-forward. It will clear out any existing users and then insert these test users. Right after\nthat, I get dropped into an ipython repl to do what I need for testing. All I have to do is run:\npython jam_users.py\n\nHowever, if I want to run the script as-is, I will need to choose one of these approaches:\n\nInstall the dependencies httpx, IPython, and loguru globally in my system python\nCreate a virtual environment, activate it, install deps, and run my script while the venv is activated\n\nThese are both not great options in my opinion. These approaches also rely on having a system python installed that is\ncompatible with these packages. This isn't as big of a problem, but something to consider anyway.\nI've been using uv a lot lately, and I'm becoming quite enamoured with its usefulness\nas a package manager, efficiency as a pip replacement, and abilities for isolated python executables. One thing that I\nhaven't used much yet are the special # /// script tags in a python script.\nWhen I first read about this functionality, I was pretty skeptical. I'm not particularly keen on embedding syntax into\ncomments. However, this seemed like the perfect application. So, updated my script to include the deps in the script\nheader like so:\n# /// script\n# dependencies = [\"ipython\", \"httpx\", \"loguru\"]\n# ///\nimport httpx\nimport IPython\nfrom loguru import logger\n\n...\n\nWith this added, now I can run the script really easily with uv:\nuv run jam_users.py\n\nGreat! Now, uv will create an isolated virtual environment for the script, download the dependencies and install them,\nand then run my script in the context of that venv! I don't have to manage the virtual environment myself nor worry\nabout cluttering my system python with packages that I will invariably forget to remove later.\nOne nice thing about a regular Python script, though, is that you can make it executable with a shebang line:\n#!/usr/bin/env python\n...\n\nNow, if I make the script executable (chmod +x jam_users.py), I can invoke it directly as an executable script!\nHowever, this won't take advantage of the uv script header because Python itself will just ignore the comment.\nSo, I did some digging and found out that you can actually embed the invocation of the uv command right in the shebang\nline like so:\n#!/usr/bin/env -S uv run --script\n# /// script\n# dependencies = [\"ipython\", \"httpx\", \"loguru\"]\n# ///\nimport httpx\nimport IPython\nfrom loguru import logger\n\n...\n\nThis works because the -S flag tells the system to split everything after it into separate arguments before passing it\nto the system's env.\nNow (after chmod +x jam_users.py, of course), I can execute my script directly:\n./jam_users.py\n\nThat's it! What's even better is that I can run this script on any (Unix) system that has uv installed without needing\nto do ANY dependency or virtual environment management.\nNow, this script itself is really trivial and not much more than a toy example. However, in my past I have written\nrather complex scripts that I needed to hand off to other users to run. Of course, this always came with a long\nexplanation of how to prepare their system just to run the script. This approach solves that problem instantly and\npainlessly (as long as they have uv installed).\nTake it for a spin, and let me know your thoughts.\nThanks for reading!\n\n  Comments\n\n    var giscus = document.querySelector(\"script[src*=giscus]\")\n\n    // Set palette on initial load\n    var palette = __md_get(\"__palette\")\n    if (palette && typeof palette.color === \"object\") {\n      var theme = palette.color.scheme === \"slate\"\n        ? \"transparent_dark\"\n        : \"light\"\n\n      // Instruct Giscus to set theme\n      giscus.setAttribute(\"data-theme\", theme)\n    }\n\n    // Register event handlers after documented loaded\n    document.addEventListener(\"DOMContentLoaded\", function() {\n      var ref = document.querySelector(\"[data-md-component=palette]\")\n      ref.addEventListener(\"change\", function() {\n        var palette = __md_get(\"__palette\")\n        if (palette && typeof palette.color === \"object\") {\n          var theme = palette.color.scheme === \"slate\"\n            ? \"transparent_dark\"\n            : \"light\"\n\n          // Instruct Giscus to change theme\n          var frame = document.querySelector(\".giscus-frame\")\n          frame.contentWindow.postMessage(\n            { giscus: { setConfig: { theme } } },\n            \"https://giscus.app\"\n          )\n        }\n      })\n    })",
    "summary": {
      "en": "**Summary:**\n\nThe author describes how to create a self-contained executable Python script using the `uv` package. They have a script called `jam_users.py` that manages user data in a local API. Traditionally, running this script required setting up dependencies in a global Python environment or a virtual environment, which can be cumbersome.\n\nTo simplify this, the author uses `uv`, which allows embedding dependencies directly in the script header. By adding a special comment at the top of the script, they can run it using `uv` without manually managing dependencies or environments.\n\nThe author enhances the script's shebang line to allow it to be executed directly, making it easier to run on any Unix system with `uv` installed. This method eliminates the need for users to prepare their systems, streamlining the process of running Python scripts.\n\nOverall, this approach makes it easier to share and run Python scripts without worrying about dependency management.",
      "ko": "ì €ìëŠ” `uv` íŒ¨í‚¤ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ ë…ë¦½ ì‹¤í–‰í˜• Python ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë§Œë“œëŠ” ë°©ë²•ì„ ì„¤ëª…í•©ë‹ˆë‹¤. ê·¸ë“¤ì€ ë¡œì»¬ APIì—ì„œ ì‚¬ìš©ì ë°ì´í„°ë¥¼ ê´€ë¦¬í•˜ëŠ” `jam_users.py`ë¼ëŠ” ìŠ¤í¬ë¦½íŠ¸ë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ì „í†µì ìœ¼ë¡œ ì´ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ë ¤ë©´ ì „ì—­ Python í™˜ê²½ì´ë‚˜ ê°€ìƒ í™˜ê²½ì—ì„œ ì˜ì¡´ì„±ì„ ì„¤ì •í•´ì•¼ í–ˆëŠ”ë°, ì´ëŠ” ë²ˆê±°ë¡œìš´ ì‘ì—…ì´ì—ˆìŠµë‹ˆë‹¤.\n\nì´ë¥¼ ê°„ì†Œí™”í•˜ê¸° ìœ„í•´ ì €ìëŠ” `uv`ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. `uv`ëŠ” ìŠ¤í¬ë¦½íŠ¸ í—¤ë”ì— ì˜ì¡´ì„±ì„ ì§ì ‘ í¬í•¨í•  ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤. ìŠ¤í¬ë¦½íŠ¸ ìƒë‹¨ì— íŠ¹ë³„í•œ ì£¼ì„ì„ ì¶”ê°€í•¨ìœ¼ë¡œì¨, ì˜ì¡´ì„±ì´ë‚˜ í™˜ê²½ì„ ìˆ˜ë™ìœ¼ë¡œ ê´€ë¦¬í•˜ì§€ ì•Šê³ ë„ `uv`ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nì €ìëŠ” ìŠ¤í¬ë¦½íŠ¸ì˜ shebang ë¼ì¸ì„ ê°œì„ í•˜ì—¬ ì§ì ‘ ì‹¤í–‰í•  ìˆ˜ ìˆë„ë¡ í•˜ì—¬, `uv`ê°€ ì„¤ì¹˜ëœ ëª¨ë“  ìœ ë‹‰ìŠ¤ ì‹œìŠ¤í…œì—ì„œ ì‰½ê²Œ ì‹¤í–‰í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤. ì´ ë°©ë²•ì€ ì‚¬ìš©ìê°€ ì‹œìŠ¤í…œì„ ì¤€ë¹„í•  í•„ìš”ë¥¼ ì—†ì• ì£¼ì–´ Python ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ëŠ” ê³¼ì •ì„ ê°„ì†Œí™”í•©ë‹ˆë‹¤.\n\nì „ë°˜ì ìœ¼ë¡œ ì´ ì ‘ê·¼ ë°©ì‹ì€ ì˜ì¡´ì„± ê´€ë¦¬ì— ëŒ€í•œ ê±±ì • ì—†ì´ Python ìŠ¤í¬ë¦½íŠ¸ë¥¼ ê³µìœ í•˜ê³  ì‹¤í–‰í•˜ëŠ” ê²ƒì„ ë” ì‰½ê²Œ ë§Œë“¤ì–´ ì¤ë‹ˆë‹¤.",
      "ja": "è‘—è€…ã¯ã€`uv`ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ä½¿ç”¨ã—ã¦è‡ªå·±å®Œçµå‹ã®å®Ÿè¡Œå¯èƒ½ãªPythonã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ä½œæˆã™ã‚‹æ–¹æ³•ã‚’èª¬æ˜ã—ã¦ã„ã¾ã™ã€‚å½¼ã‚‰ã¯ã€ãƒ­ãƒ¼ã‚«ãƒ«APIã§ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’ç®¡ç†ã™ã‚‹`jam_users.py`ã¨ã„ã†ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’æŒã£ã¦ã„ã¾ã™ã€‚å¾“æ¥ã€ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œã™ã‚‹ã«ã¯ã€ã‚°ãƒ­ãƒ¼ãƒãƒ«ãªPythonç’°å¢ƒã‚„ä»®æƒ³ç’°å¢ƒã§ä¾å­˜é–¢ä¿‚ã‚’è¨­å®šã™ã‚‹å¿…è¦ãŒã‚ã‚Šã€æ‰‹é–“ãŒã‹ã‹ã‚Šã¾ã—ãŸã€‚\n\nã“ã‚Œã‚’ç°¡ç´ åŒ–ã™ã‚‹ãŸã‚ã«ã€è‘—è€…ã¯`uv`ã‚’åˆ©ç”¨ã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ä¾å­˜é–¢ä¿‚ã‚’ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ãƒ˜ãƒƒãƒ€ãƒ¼ã«ç›´æ¥åŸ‹ã‚è¾¼ã‚€ã“ã¨ãŒã§ãã¾ã™ã€‚ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®å…ˆé ­ã«ç‰¹åˆ¥ãªã‚³ãƒ¡ãƒ³ãƒˆã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã§ã€æ‰‹å‹•ã§ä¾å­˜é–¢ä¿‚ã‚„ç’°å¢ƒã‚’ç®¡ç†ã™ã‚‹ã“ã¨ãªãã€`uv`ã‚’ä½¿ã£ã¦å®Ÿè¡Œã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚\n\nè‘—è€…ã¯ã€ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ã‚·ã‚§ãƒãƒ³è¡Œã‚’å¼·åŒ–ã—ã€ç›´æ¥å®Ÿè¡Œã§ãã‚‹ã‚ˆã†ã«ã—ã¾ã—ãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€`uv`ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚ŒãŸä»»æ„ã®Unixã‚·ã‚¹ãƒ†ãƒ ã§ç°¡å˜ã«å®Ÿè¡Œã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚ã“ã®æ–¹æ³•ã«ã‚ˆã‚Šã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã‚·ã‚¹ãƒ†ãƒ ã‚’æº–å‚™ã™ã‚‹å¿…è¦ãŒãªããªã‚Šã€Pythonã‚¹ã‚¯ãƒªãƒ—ãƒˆã®å®Ÿè¡Œãƒ—ãƒ­ã‚»ã‚¹ãŒç°¡ç´ åŒ–ã•ã‚Œã¾ã™ã€‚\n\nå…¨ä½“ã¨ã—ã¦ã€ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯ä¾å­˜é–¢ä¿‚ã®ç®¡ç†ã‚’æ°—ã«ã›ãšã«Pythonã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å…±æœ‰ã—ã€å®Ÿè¡Œã™ã‚‹ã“ã¨ã‚’å®¹æ˜“ã«ã—ã¾ã™ã€‚"
    }
  },
  {
    "id": "c07a2f6dab748318",
    "title": {
      "en": "How the Queen of England Beat Everyone to the Internet",
      "ko": "ì˜êµ­ ì—¬ì™•ì˜ ì¸í„°ë„· ìŠ¹ë¦¬",
      "ja": "å¥³ç‹ã®ãƒãƒƒãƒˆåˆ¶è¦‡"
    },
    "type": "story",
    "url": "https://www.wired.com/2012/12/queen-and-the-internet/",
    "score": 22,
    "by": "rbanffy",
    "time": 1743079903,
    "content": "Cade MetzBusinessDec 25, 2012 6:30 AMHow the Queen of England Beat Everyone to the InternetPeter Kirstein is the man who put the Queen of England on the internet. In 1976.Queen Elizabeth II, on the internet, in 1976.Photo: Peter KirsteinSave this storySaveSave this storySavePeter Kirstein is the man who put the Queen of England on the internet. In 1976.That's Her Majesty in the photo above, and if the year isn't immediately obvious from the computer terminal she's typing on -- or from her attire -- you can find it on the wall, just to her left, printed on one of the signs trumpeting the arrival of the ARPANET.The date was March 26, 1976, and the ARPANET -- the computer network that eventually morphed into the internet -- had just come to the Royal Signals and Radar Establishment, a telecommunications research center in Malvern, England. The Queen was on hand to christen the connection, and in the process, she became one of the first heads of state to send an e-mail.It was Peter Kirstein who set up her mail account, choosing the username \"HME2.\" That's Her Majesty, Elizabeth II. \"All she had to do was press a couple of buttons,\" he remembers, \"and her message was sent.\"Kirstein's role in the first royal e-mail was only appropriate. He's also the man who first brought the ARPANET to Great Britain, setting up a network node at the University of London in 1973. Throughout the '70s and on into the '80s, he would oversee Britain's presence on ARPANET and help push this sprawling research network onto the all-important TCP/IP protocols that gave rise to the worldwide internet as we know it today.This past April, in recognition of his dogged pursuit of internetworking in Great Britain -- if not his deft choice of royal usernames -- Kirstein was inducted into the Internet Society's (ISOC) Internet Hall of Fame. Part of the hall's inaugural class, he was joined by such names as Vint Cerf, Bob Kahn and Tim Berners-Lee.Kirstein grew up in Britain. He studied mathematics and engineering at Cambridge and the University of London. And after completing his PhD, he was a researcher with General Electric in Zurich, Switzerland. But over the years, he also spent quite a bit of time at Stanford University and the University of California, Los Angeles (UCLA) in the States.In the 60s, at UCLA, he met Vint Cerf -- who would one day help create the TCP/IP protocols -- and as the 70s rolled around and he settled into professorship at the University of London, he had developed relationships with various other researchers who had recently spread the ARPANET across various U.S. research operations, including Larry Roberts, the man who originally designed the thing for the U.S. Department of Defense.When Roberts decided that the ARPAnet should stretch from the U.S. to Norway and Britain via an existing trans-Atlantic telecommunications link, Kirstein was chosen to facilitate the British connection. The original idea was to connect the ARPANET to the network built by Britain's National Physical Laboratory and Donald Davies -- who coined the term network packet and played a role in the early design of the ARPANET -- but according to Kirstein, a link to the NPL was ruled out because of political reasons. The UK was working to get into the European Economic Community, and apparently, Europe would frown on that sort of direct cooperation between the NPL and the U.S. Defense Department. So the task fell to Kirstein instead.Most PopularPoliticsDOGE Plans to Rebuild SSA Code Base in Months, Risking Benefits and System CollapseBy Makena KellyThe Big StoryIf Anthropic Succeeds, a Nation of Benevolent AI Geniuses Could Be BornBy Steven LevySecurityEven More Venmo Accounts Tied to Trump Officials in Signal Group Chat Left Data PublicBy Dhruv MehrotraSecurity NewsMike Waltz Left His Venmo Friends List PublicBy Dhruv MehrotraWith a year's worth of funding from the British Post Office for the link between Norway and Britain (the trans-Atlantic connection went to Norway first) and an additional 5,000 pounds from Davies and the NPL, Kirsten set up his ARPANET node at the University of London.Peter Kirstein.\nPhoto: Internet Hall of FameHe would take the network to other parts of Great Britain -- including the Royal Signals and Radar Establishment -- but he also helped hook the ARPANET into SATNET, a satellite network that could connect various other European countries. Kirstein was on the other end of the line in November 1977, when researchers riding across Northern California in a bread truck first used TCP/IP to send data across three separate networks: a packet radio wireless network, the ARPANET, and SATNET. The message bounced from San Francisco to Norway and Britain and back again in an demonstration of what Vint Cerf calls \"true inter-networking.\"By 1983, TCP/IP was officially rolled out across the ARPANET, and as other networks adopted the protocols in the coming years, the internet was born.It was revolution in digital communication. But to the Queen, it was old hat. She could even say that the first message she sent across the ARPANET in 1976 wasn't without some real hacker cred. The Royal Signals and Radar Establishment has developed a programming language called Coral 66 -- it's also mentioned on the wall, just to her left -- and this was the subject of her missive.â€œThis message to all ARPANET users announces the availability on ARPANET of the Coral 66 compiler provided by the GEC 4080 computer at the Royal Signals and Radar Establishment, Malvern, England,\" the message read. \"Coral 66 is the standard real-time high level language adopted by the Ministry of Defence.\"",
    "summary": {
      "en": "In 1976, Peter Kirstein helped connect Queen Elizabeth II to the internet by setting up her email account at the Royal Signals and Radar Establishment in England. This event marked her as one of the first world leaders to send an email. The Queen's username was \"HME2,\" and her first message announced the availability of a programming language called Coral 66 on the ARPANET, the precursor to the internet.\n\nKirstein played a crucial role in bringing the ARPANET to the UK, establishing a connection at the University of London in 1973 and later expanding it to other locations. He facilitated this connection despite initial plans being hindered by political issues. His work contributed to the development of TCP/IP protocols, which led to the creation of the modern internet. In recognition of his contributions, Kirstein was inducted into the Internet Hall of Fame in 2012.",
      "ko": "1976ë…„, í”¼í„° ì»¤ìŠ¤í‹´ì€ ì˜êµ­ì˜ ë¡œì—´ ì‹œê·¸ë„ìŠ¤ ë° ë ˆì´ë” ì—°êµ¬ì†Œì—ì„œ ì—˜ë¦¬ìë² ìŠ¤ 2ì„¸ ì—¬ì™•ì˜ ì´ë©”ì¼ ê³„ì •ì„ ì„¤ì •í•˜ì—¬ ì—¬ì™•ì´ ì¸í„°ë„·ì— ì—°ê²°ë˜ë„ë¡ ë„ì™”ìŠµë‹ˆë‹¤. ì´ ì‚¬ê±´ì€ ì—¬ì™•ì´ ì´ë©”ì¼ì„ ë³´ë‚¸ ì„¸ê³„ ì§€ë„ì ì¤‘ í•œ ëª…ìœ¼ë¡œ ê¸°ë¡ë˜ëŠ” ê³„ê¸°ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤. ì—¬ì™•ì˜ ì‚¬ìš©ì ì´ë¦„ì€ \"HME2\"ì˜€ìœ¼ë©°, ê·¸ë…€ì˜ ì²« ë²ˆì§¸ ë©”ì‹œì§€ëŠ” ARPANETì—ì„œ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì¸ ì½”ë„ 66ì˜ ì‚¬ìš© ê°€ëŠ¥ì„±ì„ ì•Œë¦¬ëŠ” ë‚´ìš©ì´ì—ˆìŠµë‹ˆë‹¤. \n\nì»¤ìŠ¤í‹´ì€ ARPANETì„ ì˜êµ­ì— ë„ì…í•˜ëŠ” ë° ì¤‘ìš”í•œ ì—­í• ì„ í–ˆìŠµë‹ˆë‹¤. ê·¸ëŠ” 1973ë…„ ëŸ°ë˜ ëŒ€í•™êµì—ì„œ ì—°ê²°ì„ ì„¤ì •í•˜ê³ , ì´í›„ ë‹¤ë¥¸ ì¥ì†Œë¡œë„ í™•ì¥í–ˆìŠµë‹ˆë‹¤. ì´ˆê¸° ê³„íšì´ ì •ì¹˜ì  ë¬¸ì œë¡œ ì§€ì—°ë˜ì—ˆìŒì—ë„ ë¶ˆêµ¬í•˜ê³  ê·¸ëŠ” ì´ ì—°ê²°ì„ ê°€ëŠ¥í•˜ê²Œ í–ˆìŠµë‹ˆë‹¤. ê·¸ì˜ ë…¸ë ¥ì€ TCP/IP í”„ë¡œí† ì½œ ê°œë°œì— ê¸°ì—¬í•˜ì˜€ê³ , ì´ëŠ” í˜„ëŒ€ ì¸í„°ë„·ì˜ íƒ„ìƒìœ¼ë¡œ ì´ì–´ì¡ŒìŠµë‹ˆë‹¤. ê·¸ì˜ ê³µë¡œë¥¼ ì¸ì •ë°›ì•„ ì»¤ìŠ¤í‹´ì€ 2012ë…„ ì¸í„°ë„· ëª…ì˜ˆì˜ ì „ë‹¹ì— í—Œì•¡ë˜ì—ˆìŠµë‹ˆë‹¤.",
      "ja": "1976å¹´ã€ãƒ”ãƒ¼ã‚¿ãƒ¼ãƒ»ã‚«ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ³ã¯ã‚¨ãƒªã‚¶ãƒ™ã‚¹2ä¸–å¥³ç‹ã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šã‚’æ‰‹åŠ©ã‘ã—ã€ã‚¤ã‚®ãƒªã‚¹ã®ãƒ­ã‚¤ãƒ¤ãƒ«ãƒ»ã‚·ã‚°ãƒŠãƒ«ã‚ºãƒ»ã‚¢ãƒ³ãƒ‰ãƒ»ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒ»ã‚¨ã‚¹ã‚¿ãƒ–ãƒªãƒƒã‚·ãƒ¥ãƒ¡ãƒ³ãƒˆã§å½¼å¥³ã®ãƒ¡ãƒ¼ãƒ«ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’è¨­å®šã—ã¾ã—ãŸã€‚ã“ã®å‡ºæ¥äº‹ã«ã‚ˆã‚Šã€å¥³ç‹ã¯ãƒ¡ãƒ¼ãƒ«ã‚’é€ä¿¡ã—ãŸæœ€åˆã®ä¸–ç•Œã®æŒ‡å°è€…ã®ä¸€äººã¨ãªã‚Šã¾ã—ãŸã€‚å¥³ç‹ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼åã¯ã€ŒHME2ã€ã§ã€æœ€åˆã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§ã¯ARPANETä¸Šã§ã€Œã‚³ãƒ¼ãƒ©ãƒ«66ã€ã¨ã„ã†ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªãŒåˆ©ç”¨å¯èƒ½ã«ãªã£ãŸã“ã¨ã‚’çŸ¥ã‚‰ã›ã¾ã—ãŸã€‚ARPANETã¯ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆã®å‰èº«ã§ã™ã€‚\n\nã‚«ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ³ã¯ARPANETã‚’ã‚¤ã‚®ãƒªã‚¹ã«å°å…¥ã™ã‚‹é‡è¦ãªå½¹å‰²ã‚’æœãŸã—ã¾ã—ãŸã€‚1973å¹´ã«ãƒ­ãƒ³ãƒ‰ãƒ³å¤§å­¦ã§æ¥ç¶šã‚’ç¢ºç«‹ã—ã€ãã®å¾Œä»–ã®å ´æ‰€ã«ã‚‚æ‹¡å¤§ã—ã¾ã—ãŸã€‚æœ€åˆã®è¨ˆç”»ã¯æ”¿æ²»çš„ãªå•é¡Œã§å¦¨ã’ã‚‰ã‚Œã¾ã—ãŸãŒã€å½¼ã¯ãã®æ¥ç¶šã‚’å®Ÿç¾ã—ã¾ã—ãŸã€‚å½¼ã®æ¥­ç¸¾ã¯ã€ç¾ä»£ã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆã‚’ä½œã‚Šä¸Šã’ã‚‹ã“ã¨ã«ã¤ãªãŒã‚‹TCP/IPãƒ—ãƒ­ãƒˆã‚³ãƒ«ã®é–‹ç™ºã«å¯„ä¸ã—ã¾ã—ãŸã€‚å½¼ã®è²¢çŒ®ãŒè©•ä¾¡ã•ã‚Œã€2012å¹´ã«ã¯ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆã®æ®¿å ‚å…¥ã‚Šã‚’æœãŸã—ã¾ã—ãŸã€‚"
    }
  },
  {
    "id": "148908385d3e8e2d",
    "title": {
      "en": "Typed Japanese",
      "ko": "íƒ€ì´í•‘ ì¼ë³¸ì–´",
      "ja": "ã‚¿ã‚¤ãƒ”ãƒ³ã‚°æ—¥æœ¬èª"
    },
    "type": "story",
    "url": "https://github.com/typedgrammar/typed-japanese",
    "score": 82,
    "by": "Philpax",
    "time": 1743255374,
    "content": "ğŸŒ¸ Typed Japanese\nIf you can write TypeScript, you can understand Japanese!\n\nTyped Japanese is a TypeScript type-level library that enables the expression of complete Japanese sentences through the type system. It creates a domain-specific language (DSL) based on Japanese grammar rules, allowing a subset of grammatically correct natural language to be written and verified using TypeScript's compiler.\nThis project also explores an intermediate format for AI in language learning. For example, LLMs could return grammar analysis of Japanese sentences using this format instead of JSON, enabling verification through TypeScript's type checker to improve correctness.\n\nğŸ“– Want to learn more? Check out our detailed blog post which explains how the TypeScript type system can be used to learn Japanese grammar from the ground up. The article starts with basic programming concepts and gradually builds up to complex Japanese grammatical structures like conditional sentences and interrogative phrases.\n\n// Define the proper noun \"ãƒ’ãƒ³ãƒ¡ãƒ«\"\ntype ãƒ’ãƒ³ãƒ¡ãƒ« = ProperNoun<\"ãƒ’ãƒ³ãƒ¡ãƒ«\">;\n\n// Define ã™ã‚‹ verb\ntype ã™ã‚‹ = IrregularVerb & { dictionary: \"ã™ã‚‹\" };\n\n// Create the ãã†ã—ãŸ pattern (past form of ãã†ã™ã‚‹)\ntype ãã†ã—ãŸ = DemonstrativeAction<Demonstrative & \"ãã†\", ã™ã‚‹, \"ãŸå½¢\">;\n\n// Create the conditional phrase \"ãƒ’ãƒ³ãƒ¡ãƒ«ãªã‚‰ãã†ã—ãŸ\"\ntype ãƒ’ãƒ³ãƒ¡ãƒ«ãªã‚‰ãã†ã—ãŸ = ConditionalPhrase<ãƒ’ãƒ³ãƒ¡ãƒ«, \"ãªã‚‰\", ãã†ã—ãŸ>;\n\n// Type checking examples\nconst properExample: ãƒ’ãƒ³ãƒ¡ãƒ«ãªã‚‰ãã†ã—ãŸ = \"ãƒ’ãƒ³ãƒ¡ãƒ«ãªã‚‰ãã†ã—ãŸ\"; // \"If it were Himmel, he would do so\"\n// å¦‚æœæ˜¯è¾›ç¾å°”çš„è¯ï¼Œä»–ä¹Ÿä¼šè¿™ä¹ˆåšçš„\n\nğŸ¤– Verb System\nVerb Classes\nJapanese verbs are categorized into three main classes:\n\nGodan Verbs (äº”æ®µå‹•è©) - Also known as \"Group 1\" or \"u-verbs\"\n\nEndings: ã†, ã, ã, ã™, ã¤, ã¬, ã¶, ã‚€, ã‚‹\nExamples: è©±ã™ (hanasu - to speak), æ›¸ã (kaku - to write)\n\nIchidan Verbs (ä¸€æ®µå‹•è©) - Also known as \"Group 2\" or \"ru-verbs\"\n\nAlways end with ã‚‹\nExamples: é£Ÿã¹ã‚‹ (taberu - to eat), è¦‹ã‚‹ (miru - to see)\n\nIrregular Verbs (ä¸è¦å‰‡å‹•è©) - Only two main verbs\n\nã™ã‚‹ (suru - to do)\næ¥ã‚‹ (kuru - to come)\n\nVerb Conjugation Forms\nThe system supports these conjugation forms:\n\nè¾æ›¸å½¢ (Dictionary form)\nã¾ã™å½¢ (Polite form)\nã¦å½¢ (Te form)\nãŸå½¢ (Past form)\nãªã„å½¢ (Negative form)\nå¯èƒ½å½¢ (Potential form)\nå—èº«å½¢ (Passive form)\nä½¿å½¹å½¢ (Causative form)\næ„å‘å½¢ (Volitional form)\nå‘½ä»¤å½¢ (Imperative form)\næ¡ä»¶å½¢ (Conditional form)\nä»®å®šå½¢ (Hypothetical form)\n\ntype è²·ã† = GodanVerb & { stem: \"è²·\"; ending: \"ã†\" };\ntype è²·ã†ã¦å½¢ = ConjugateVerb<è²·ã†, \"ã¦å½¢\">; // è²·ã£ã¦\ntype è²·ã†ãŸå½¢ = ConjugateVerb<è²·ã†, \"ãŸå½¢\">; // è²·ã£ãŸ\n\ntype é£Ÿã¹ã‚‹ = IchidanVerb & { stem: \"é£Ÿã¹\"; ending: \"ã‚‹\" };\ntype é£Ÿã¹ã‚‹ã¦å½¢ = ConjugateVerb<é£Ÿã¹ã‚‹, \"ã¦å½¢\">; // é£Ÿã¹ã¦\ntype é£Ÿã¹ã‚‹ãŸå½¢ = ConjugateVerb<é£Ÿã¹ã‚‹, \"ãŸå½¢\">; // é£Ÿã¹ãŸ\n\nğŸ¨ Adjective System\nJapanese adjectives are categorized into two main classes:\n\nI-Adjectives (ã„å½¢å®¹è©) - End with ã„\n\nExamples: ã„ã„ (good), æ¥½ã—ã„ (fun), é«˜ã„ (expensive)\n\nNa-Adjectives (ãªå½¢å®¹è©) - Require ãª when modifying nouns\n\nExamples: ç¶ºéº— (pretty), é™ã‹ (quiet), å¥½ã (liked)\n\nAdjective Conjugation Forms\nThe system supports these conjugation forms for adjectives:\n\nåŸºæœ¬å½¢ (Basic form)\nä¸å¯§å½¢ (Polite form)\néå»å½¢ (Past form)\nå¦å®šå½¢ (Negative form)\n\ntype ã„ã„ = IAdjective & { stem: \"ã„\"; ending: \"ã„\"; irregular: true };\ntype ç¶ºéº— = NaAdjective & { stem: \"ç¶ºéº—\" };\n\nğŸ“š Phrase and Sentence Composition\nThe system now supports:\n\nAdjectives and verbs with particles\nConnecting phrases with Japanese punctuation\nBasic sentence structures\nConditional expressions with particles like ãªã‚‰\nDemonstrative forms with actions\n\nExample: Connecting simple adjective and imperative verb phrases\n// I-adjective \"ii\" (good) with irregular conjugation\n// Then add particle \"yo\" to basic form of \"ii\" -> \"ii yo\"\ntype ã„ã„ = IAdjective & { stem: \"ã„\"; ending: \"ã„\"; irregular: true };\ntype ã„ã„ã‚ˆ = PhraseWithParticle<ConjugateAdjective<ã„ã„, \"åŸºæœ¬å½¢\">, \"ã‚ˆ\">;\n\n// Irregular verb \"kuru\" (to come)\n// Then add particle \"yo\" to imperative form of \"kuru\" -> \"koi yo\"\ntype æ¥ã‚‹ = IrregularVerb & { dictionary: \"æ¥ã‚‹\" };\ntype æ¥ã„ã‚ˆ = PhraseWithParticle<ConjugateVerb<æ¥ã‚‹, \"å‘½ä»¤å½¢\">, \"ã‚ˆ\">;\n\n// Connect both phrases -> \"ii yo, koi yo\"\ntype ã„ã„ã‚ˆæ¥ã„ã‚ˆ = ConnectedPhrases<ã„ã„ã‚ˆ, æ¥ã„ã‚ˆ>;\n\n// Type checking examples\nconst correctPhrase1: ã„ã„ã‚ˆ = \"ã„ã„ã‚ˆ\"; // \"It's good!\" (114)\nconst correctPhrase2: æ¥ã„ã‚ˆ = \"æ¥ã„ã‚ˆ\"; // \"Come here!\" (514)\nconst correctFullPhrase: ã„ã„ã‚ˆæ¥ã„ã‚ˆ = \"ã„ã„ã‚ˆã€æ¥ã„ã‚ˆ\"; // \"It's good, come here!\"\n\nExample: More flexible component-based sentence construction\ntype SentenceParts = [\n  AdverbPart<\"ãªã‚“ã§\">, // \"Why\" - question adverb\n  IntensifierPart<\"ãã‚“ãªã«\">, // \"So much\" - intensifier\n  VerbPart<æ…£ã‚Œã‚‹, \"ã¦å½¢\">, // \"Get used to\" in te-form\n  ContractedPart<\"ã‚“\">, // Contraction of \"ã®\" - colloquial nominalizer\n  ParticlePart<\"ã \">, // Copula \"is\"\n  ParticlePart<\"ã‚ˆ\"> // Emphatic sentence-ending particle\n];\n\n// Combines all parts into a single string\ntype JoinedSentence = JoinPhrasePartsValue<SentenceParts>;\nconst joinedSentence: JoinedSentence = \"ãªã‚“ã§ãã‚“ãªã«æ…£ã‚Œã¦ã‚“ã ã‚ˆ\"; // \"Why are you so used to it?!\"\n// ä½ ä¸ºä»€ä¹ˆè¿™ä¹ˆç†Ÿç»ƒå•Šï¼Ÿ\n\nâš™ï¸ Technical Implementation\nThe system uses TypeScript's template literal types, conditional types, and mapped types to create a purely type-level representation of Japanese grammatical rules.\nKey components:\n\nType definitions for grammatical elements\nRule mapping via conditional types\nString literal manipulation for form generation\nType inference for grammatical validation\n\nğŸ’¡ Why Typed Japanese?\n\nEducational tool - Learn Japanese grammar through code\nAI-assisted learning - Provide structured formats for language analysis\nGrammar verification - Express and verify Japanese grammar in code\nIntegration potential - Basis for typed Japanese language tools\n\nâš ï¸ Limitations\n\nThis is a type-level system only - it doesn't provide runtime functionality\nThe system handles standard forms but doesn't account for linguistic nuances\nSome rare or archaic language patterns may not be accurately represented\n\nThis project is still in very early stages and heavily relies on LLM-generated grammar rules, which may occasionally contain hallucinations or inaccuracies. If you find any issue during actual use, please help by confirming and providing feedback.\nğŸ› ï¸ Development\nIf you're interested in contributing to or experimenting with Typed Japanese:\n\nEnsure you have Node.js and pnpm installed\nClone the repository\nInstall dependencies: pnpm install\nRun the tests: pnpm test\n\nThe tests validate that the type system functions correctly and all grammatical rules are properly implemented.\nWe welcome contributions! Feel free to open issues for bugs or feature requests, or submit pull requests with improvements.\nğŸ“¬ Contact\nFor sponsorship opportunities, research collaborations, or commercial inquiries, please reach out to contact@typedgrammar.com.\nâš–ï¸ License\nMIT\nCopyright (c) 2025-present, Yifeng Wang",
    "summary": {
      "en": "**Summary of Typed Japanese**\n\nTyped Japanese is a TypeScript library that allows you to express complete Japanese sentences using TypeScript's type system. By following Japanese grammar rules, it creates a specialized language that can be checked for correctness by the TypeScript compiler. This project also aims to enhance language learning by providing a structured format for AI to analyze Japanese grammar.\n\n### Key Features:\n- **Grammar Support**: The library supports Japanese verbs (Godan, Ichidan, and irregular verbs) and adjectives (I-adjectives and Na-adjectives), offering various conjugation forms.\n- **Phrase Construction**: Users can create sentences with verbs, adjectives, and particles, enabling flexible sentence structures.\n- **Educational Tool**: It serves as a way to learn Japanese grammar through coding, allowing users to express and verify grammatical rules.\n\n### Technical Aspects:\n- The library uses TypeScript's advanced type features to represent Japanese grammar purely at the type level.\n- It focuses on standard language forms, but may not cover all linguistic nuances.\n\n### Limitations:\n- The system is for type-level representation only and does not provide runtime functionality.\n- It may not accurately represent rare or archaic language patterns.\n\n### Development:\nTo contribute or experiment with Typed Japanese, users need Node.js and pnpm installed to run tests and validate the system.\n\nFor more information, check the detailed blog post or contact the developers at contact@typedgrammar.com. The project is open to contributions and feedback.",
      "ko": "íƒ€ì… ì¼ë³¸ì–´ëŠ” TypeScript ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ, TypeScriptì˜ íƒ€ì… ì‹œìŠ¤í…œì„ ì´ìš©í•´ ì™„ì „í•œ ì¼ë³¸ì–´ ë¬¸ì¥ì„ í‘œí˜„í•  ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤. ì¼ë³¸ì–´ ë¬¸ë²• ê·œì¹™ì„ ë”°ë¥´ë©°, TypeScript ì»´íŒŒì¼ëŸ¬ê°€ ì˜¬ë°”ë¥¸ì§€ ê²€ì¦í•  ìˆ˜ ìˆëŠ” ì „ë¬¸ ì–¸ì–´ë¥¼ ë§Œë“­ë‹ˆë‹¤. ì´ í”„ë¡œì íŠ¸ëŠ” AIê°€ ì¼ë³¸ì–´ ë¬¸ë²•ì„ ë¶„ì„í•  ìˆ˜ ìˆë„ë¡ êµ¬ì¡°í™”ëœ í˜•ì‹ì„ ì œê³µí•¨ìœ¼ë¡œì¨ ì–¸ì–´ í•™ìŠµì„ í–¥ìƒì‹œí‚¤ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n\nì´ ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ì£¼ìš” ê¸°ëŠ¥ ì¤‘ í•˜ë‚˜ëŠ” ì¼ë³¸ì–´ ë™ì‚¬(ê³ ë‹¨, ì´ì¹˜ë‹¨, ë¶ˆê·œì¹™ ë™ì‚¬)ì™€ í˜•ìš©ì‚¬(Ií˜• í˜•ìš©ì‚¬ì™€ ë‚˜í˜• í˜•ìš©ì‚¬)ë¥¼ ì§€ì›í•˜ë©°, ë‹¤ì–‘í•œ í™œìš© í˜•íƒœë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì‚¬ìš©ìëŠ” ë™ì‚¬, í˜•ìš©ì‚¬, ì¡°ì‚¬ ë“±ì„ ì‚¬ìš©í•´ ë¬¸ì¥ì„ ë§Œë“¤ ìˆ˜ ìˆì–´ ìœ ì—°í•œ ë¬¸ì¥ êµ¬ì¡°ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. ë˜í•œ, ì½”ë”©ì„ í†µí•´ ì¼ë³¸ì–´ ë¬¸ë²•ì„ ë°°ìš°ëŠ” ë„êµ¬ë¡œ í™œìš©ë˜ì–´ ì‚¬ìš©ìê°€ ë¬¸ë²• ê·œì¹™ì„ í‘œí˜„í•˜ê³  ê²€ì¦í•  ìˆ˜ ìˆë„ë¡ ë•ìŠµë‹ˆë‹¤.\n\nê¸°ìˆ ì ì¸ ì¸¡ë©´ì—ì„œ ì´ ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” TypeScriptì˜ ê³ ê¸‰ íƒ€ì… ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ì—¬ ì¼ë³¸ì–´ ë¬¸ë²•ì„ íƒ€ì… ìˆ˜ì¤€ì—ì„œ ìˆœìˆ˜í•˜ê²Œ í‘œí˜„í•©ë‹ˆë‹¤. í‘œì¤€ ì–¸ì–´ í˜•íƒœì— ì¤‘ì ì„ ë‘ì§€ë§Œ, ëª¨ë“  ì–¸ì–´ì  ë‰˜ì•™ìŠ¤ë¥¼ í¬ê´„í•˜ì§€ëŠ” ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nì œí•œ ì‚¬í•­ìœ¼ë¡œëŠ” ì´ ì‹œìŠ¤í…œì´ íƒ€ì… ìˆ˜ì¤€ í‘œí˜„ì—ë§Œ í•´ë‹¹í•˜ë©°, ëŸ°íƒ€ì„ ê¸°ëŠ¥ì„ ì œê³µí•˜ì§€ ì•ŠëŠ” ì ì´ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, ë“œë¬¼ê±°ë‚˜ ê³ í’ìŠ¤ëŸ¬ìš´ ì–¸ì–´ íŒ¨í„´ì„ ì •í™•í•˜ê²Œ í‘œí˜„í•˜ì§€ ëª»í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.\n\níƒ€ì… ì¼ë³¸ì–´ì— ê¸°ì—¬í•˜ê±°ë‚˜ ì‹¤í—˜í•˜ë ¤ë©´ Node.jsì™€ pnpmì´ ì„¤ì¹˜ë˜ì–´ ìˆì–´ì•¼ í•˜ë©°, ì´ë¥¼ í†µí•´ í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•˜ê³  ì‹œìŠ¤í…œì„ ê²€ì¦í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë” ë§ì€ ì •ë³´ëŠ” ìì„¸í•œ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ë¥¼ í™•ì¸í•˜ê±°ë‚˜ contact@typedgrammar.comìœ¼ë¡œ ê°œë°œìì—ê²Œ ë¬¸ì˜í•˜ë©´ ë©ë‹ˆë‹¤. ì´ í”„ë¡œì íŠ¸ëŠ” ê¸°ì—¬ì™€ í”¼ë“œë°±ì„ í™˜ì˜í•©ë‹ˆë‹¤.",
      "ja": "Typed Japaneseã¯ã€TypeScriptã®å‹ã‚·ã‚¹ãƒ†ãƒ ã‚’ä½¿ã£ã¦å®Œå…¨ãªæ—¥æœ¬èªã®æ–‡ã‚’è¡¨ç¾ã§ãã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã™ã€‚æ—¥æœ¬èªã®æ–‡æ³•ãƒ«ãƒ¼ãƒ«ã«å¾“ã†ã“ã¨ã§ã€TypeScriptã‚³ãƒ³ãƒ‘ã‚¤ãƒ©ã«ã‚ˆã£ã¦æ­£ã—ã•ã‚’ãƒã‚§ãƒƒã‚¯ã§ãã‚‹ç‰¹åŒ–ã—ãŸè¨€èªã‚’ä½œæˆã—ã¾ã™ã€‚ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ã€AIãŒæ—¥æœ¬èªã®æ–‡æ³•ã‚’åˆ†æã§ãã‚‹æ§‹é€ åŒ–ã•ã‚ŒãŸå½¢å¼ã‚’æä¾›ã™ã‚‹ã“ã¨ã§ã€è¨€èªå­¦ç¿’ã®å‘ä¸Šã‚‚ç›®æŒ‡ã—ã¦ã„ã¾ã™ã€‚\n\nã“ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ä¸»ãªç‰¹å¾´ã«ã¯ã€æ—¥æœ¬ã®å‹•è©ï¼ˆäº”æ®µå‹•è©ã€ä¸€æ®µå‹•è©ã€ä¸è¦å‰‡å‹•è©ï¼‰ã‚„å½¢å®¹è©ï¼ˆã„å½¢å®¹è©ã€ãªå½¢å®¹è©ï¼‰ã‚’ã‚µãƒãƒ¼ãƒˆã—ã€ã•ã¾ã–ã¾ãªæ´»ç”¨å½¢ã‚’æä¾›ã™ã‚‹ã“ã¨ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯å‹•è©ã€å½¢å®¹è©ã€åŠ©è©ã‚’ä½¿ã£ã¦æ–‡ã‚’ä½œæˆã§ãã€æŸ”è»Ÿãªæ–‡æ§‹é€ ã‚’å®Ÿç¾ã—ã¾ã™ã€‚ã¾ãŸã€ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’é€šã˜ã¦æ—¥æœ¬èªã®æ–‡æ³•ã‚’å­¦ã¶ãŸã‚ã®æ•™è‚²ãƒ„ãƒ¼ãƒ«ã¨ã—ã¦ã‚‚æ©Ÿèƒ½ã—ã¾ã™ã€‚\n\næŠ€è¡“çš„ã«ã¯ã€ã“ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¯TypeScriptã®é«˜åº¦ãªå‹æ©Ÿèƒ½ã‚’åˆ©ç”¨ã—ã¦ã€æ—¥æœ¬èªã®æ–‡æ³•ã‚’å‹ãƒ¬ãƒ™ãƒ«ã§ç´”ç²‹ã«è¡¨ç¾ã—ã¾ã™ã€‚æ¨™æº–çš„ãªè¨€èªå½¢å¼ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ã¾ã™ãŒã€ã™ã¹ã¦ã®è¨€èªã®ãƒ‹ãƒ¥ã‚¢ãƒ³ã‚¹ã‚’ã‚«ãƒãƒ¼ã—ã¦ã„ã‚‹ã‚ã‘ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚\n\nåˆ¶é™ã¨ã—ã¦ã¯ã€ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã¯å‹ãƒ¬ãƒ™ãƒ«ã®è¡¨ç¾ã®ã¿ã«å¯¾å¿œã—ã¦ãŠã‚Šã€å®Ÿè¡Œæ™‚ã®æ©Ÿèƒ½ã¯æä¾›ã—ã¦ã„ã¾ã›ã‚“ã€‚ã¾ãŸã€ç¨€ãªè¨€èªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚„å¤é¢¨ãªè¡¨ç¾ã‚’æ­£ç¢ºã«è¡¨ç¾ã§ããªã„å ´åˆãŒã‚ã‚Šã¾ã™ã€‚\n\nTyped Japaneseã«è²¢çŒ®ã—ãŸã‚Šå®Ÿé¨“ã—ãŸã‚Šã™ã‚‹ã«ã¯ã€Node.jsã¨pnpmã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œã—ã€ã‚·ã‚¹ãƒ†ãƒ ã‚’æ¤œè¨¼ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚è©³ç´°ã«ã¤ã„ã¦ã¯ã€ãƒ–ãƒ­ã‚°è¨˜äº‹ã‚’ç¢ºèªã™ã‚‹ã‹ã€é–‹ç™ºè€…ã«contact@typedgrammar.comã§é€£çµ¡ã—ã¦ãã ã•ã„ã€‚ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯è²¢çŒ®ã‚„ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’æ­“è¿ã—ã¦ã„ã¾ã™ã€‚"
    }
  },
  {
    "id": "02fad9a787dd30d7",
    "title": {
      "en": "Decline of cash credited for drop in surgery for children swallowing objects",
      "ko": "í˜„ê¸ˆ ê°ì†Œ, ì•„ë™ ìˆ˜ìˆ  ê°ì†Œ ì›ì¸",
      "ja": "ç¾é‡‘æ¸›å°‘ã§å­ä¾›ã®æ‰‹è¡“æ¸›å°‘"
    },
    "type": "story",
    "url": "https://www.theguardian.com/society/2025/mar/28/decline-of-cash-credited-for-drop-in-nhs-surgery-for-children-swallowing-objects",
    "score": 58,
    "by": "geox",
    "time": 1743278683,
    "content": "Historically, coins accounted for more than 75% of objects swallowed by children under six, the Royal College of Surgeons of England said. Photograph: fStop Images GmbH/AlamyView image in fullscreenHistorically, coins accounted for more than 75% of objects swallowed by children under six, the Royal College of Surgeons of England said. Photograph: fStop Images GmbH/AlamyChildrenDecline of cash credited for drop in NHS surgery for children swallowing objectsFigures reveal 29% fall in operations in England to remove foreign bodies from childrenâ€™s airways, noses and throatsDenis Campbell Health policy editorFri 28 Mar 2025 00.01 GMTShareCashless societies may be a sad fact of modern life for those with a nostalgic attachment to the pound in their pocket, but doctors have discovered one unexpected benefit of the decline of coins.Far fewer children are having surgery after swallowing small items that could choke or kill them, and the scarcity of loose change is likely to be the reason.The number of children in England needing an operation to remove a foreign body from their nose, throat or airway fell significantly between 2012 and 2022, NHS figures show.The fall has been greeted with relief by doctors and surgeons, who for years have been warning of the dangers posed by young children ingesting magnets, tiny batteries and other risky objects.How Covid changed children in BritainRead moreThe number of under-18s undergoing surgery on their nose, airway or throat for that reason has declined from 2,405 in 2012 to 1,716 in 2022 â€“ a fall of 29% or 689 cases in the year.The Royal College of Surgeons of England (RCSE), which obtained the figures, collated from hospital admission data, identified the rise of the cashless society as the main reason.â€œHistorically, coins accounted for over 75% of objects swallowed by children under six years old, and fewer coins in homes due to contactless payments have likely helped reduce the number of these procedures,â€ it said.For example, surgeons performed 484 (31%) fewer procedures to remove something from a childâ€™s nose in 2022 compared with 2012. There were 28% fewer on the digestive tract in the same age group and 8% fewer involving their airways.However, the RCSE said that, despite the drop, parents should still be alert to the risk of their child swallowing shiny objects that looked like coins, such as button batteries and magnets.â€œThese can cause deadly internal complications within hours of ingestion, leading to tragic consequences,â€ it added.This week, reports told how one-year-old Araya Whateley had to have her bowel removed after ingesting six metal balls from a toy belonging to her nine-year-old sister.skip past newsletter promotionSign up to First EditionFree daily newsletterOur morning email breaks down the key stories of the day, telling you whatâ€™s happening and why it mattersEnter your email address Sign upPrivacy Notice: Newsletters may contain info about charities, online ads, and content funded by outside parties. For more information see our Privacy Policy. We use Google reCaptcha to protect our website and the Google Privacy Policy and Terms of Service apply.after newsletter promotionRecord 4.5m children in poverty in UK as cuts condemned as â€˜morally repugnantâ€™Read moreParents who suspect their child may have ingested something dangerous should take them straight to hospital to get checked out, according to the body that represents Britainâ€™s A&E doctors.â€œIf any carer thinks a child has swallowed an item they shouldnâ€™t have, take them to A&E â€“ even if they have no symptoms. In cases like this, it really is better to be safe than sorry,â€ said Dr Adrian Boyle, the president of the Royal College of Emergency Medicine.â€œAs a parent, I know we all do our best to be vigilant as to what our children are putting in their mouths. But it is impossible to monitor them all the time.â€Prof Stephen Powis, NHS Englandâ€™s national medical director, said: â€œAt a time when demand on NHS services is so high, trends like this one which reduces hospital attendances is not only good for children, but also for our under-pressure staff.â€Explore more on these topicsChildrenHealthHospitalsNHSEnglandnewsShareReuse this content",
    "summary": {
      "en": "The decline in cash usage has led to fewer children swallowing dangerous objects, resulting in a significant drop in surgeries in England. Historically, over 75% of items swallowed by children under six were coins. Between 2012 and 2022, surgeries for removing foreign bodies from childrenâ€™s airways, noses, and throats decreased by 29%, from 2,405 to 1,716 cases. The Royal College of Surgeons attributes this decline to the reduced number of coins in homes due to the rise of contactless payments.\n\nWhile this trend is welcomed by doctors, they warn that parents should remain vigilant about other small, shiny objects like button batteries and magnets, which can also pose serious risks. If parents suspect their child has swallowed something harmful, they should take them to the hospital immediately. Overall, this decrease in surgeries not only benefits children's health but also eases pressure on NHS services.",
      "ko": "í˜„ê¸ˆ ì‚¬ìš©ì˜ ê°ì†ŒëŠ” ì–´ë¦°ì´ë“¤ì´ ìœ„í—˜í•œ ë¬¼ê±´ì„ ì‚¼í‚¤ëŠ” ì‚¬ë¡€ë¥¼ ì¤„ì—¬, ì˜êµ­ì—ì„œ ìˆ˜ìˆ  ê±´ìˆ˜ê°€ í¬ê²Œ ê°ì†Œí•˜ëŠ” ê²°ê³¼ë¥¼ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤. ì—­ì‚¬ì ìœ¼ë¡œ, ì—¬ì„¯ ì‚´ ì´í•˜ ì–´ë¦°ì´ë“¤ì´ ì‚¼í‚¨ ë¬¼ê±´ì˜ 75% ì´ìƒì´ ë™ì „ì´ì—ˆìŠµë‹ˆë‹¤. 2012ë…„ë¶€í„° 2022ë…„ ì‚¬ì´ì— ì–´ë¦°ì´ì˜ ê¸°ë„, ì½”, ëª©ì—ì„œ ì´ë¬¼ì§ˆì„ ì œê±°í•˜ëŠ” ìˆ˜ìˆ  ê±´ìˆ˜ëŠ” 29% ê°ì†Œí•˜ì—¬ 2,405ê±´ì—ì„œ 1,716ê±´ìœ¼ë¡œ ì¤„ì–´ë“¤ì—ˆìŠµë‹ˆë‹¤. ì˜êµ­ ì™¸ê³¼ ì˜ì‚¬ í˜‘íšŒëŠ” ì´ëŸ¬í•œ ê°ì†Œê°€ ë¹„ì ‘ì´‰ì‹ ê²°ì œì˜ ì¦ê°€ë¡œ ì¸í•´ ê°€ì •ì—ì„œ ë™ì „ì˜ ìˆ˜ê°€ ì¤„ì–´ë“  ê²ƒê³¼ ê´€ë ¨ì´ ìˆë‹¤ê³  ì„¤ëª…í–ˆìŠµë‹ˆë‹¤.\n\nì´ëŸ¬í•œ ì¶”ì„¸ëŠ” ì˜ì‚¬ë“¤ì—ê²Œ í™˜ì˜ë°›ê³  ìˆì§€ë§Œ, ë¶€ëª¨ë“¤ì€ ë²„íŠ¼ ë°°í„°ë¦¬ë‚˜ ìì„ê³¼ ê°™ì€ ë‹¤ë¥¸ ì‘ì€ ë°˜ì§ì´ëŠ” ë¬¼ê±´ì— ëŒ€í•´ì„œë„ ê²½ê°ì‹¬ì„ ê°€ì ¸ì•¼ í•œë‹¤ê³  ê²½ê³ í•©ë‹ˆë‹¤. ì´ë“¤ ë¬¼ê±´ ì—­ì‹œ ì‹¬ê°í•œ ìœ„í—˜ì„ ì´ˆë˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë§Œì•½ ë¶€ëª¨ê°€ ìë…€ê°€ í•´ë¡œìš´ ë¬¼ì§ˆì„ ì‚¼ì¼°ë‹¤ê³  ì˜ì‹¬ëœë‹¤ë©´, ì¦‰ì‹œ ë³‘ì›ìœ¼ë¡œ ë°ë ¤ê°€ì•¼ í•©ë‹ˆë‹¤. ì „ë°˜ì ìœ¼ë¡œ ìˆ˜ìˆ  ê±´ìˆ˜ì˜ ê°ì†ŒëŠ” ì–´ë¦°ì´ì˜ ê±´ê°•ì— ê¸ì •ì ì¸ ì˜í–¥ì„ ë¯¸ì¹  ë¿ë§Œ ì•„ë‹ˆë¼ NHS ì„œë¹„ìŠ¤ì— ëŒ€í•œ ë¶€ë‹´ë„ ëœì–´ì¤ë‹ˆë‹¤.",
      "ja": "ç¾é‡‘ã®ä½¿ç”¨ãŒæ¸›å°‘ã—ãŸã“ã¨ã§ã€å­ä¾›ãŒå±é™ºãªç‰©ã‚’é£²ã¿è¾¼ã‚€ã‚±ãƒ¼ã‚¹ãŒæ¸›ã‚Šã€ã‚¤ã‚®ãƒªã‚¹ã§ã¯æ‰‹è¡“ã®ä»¶æ•°ãŒå¤§å¹…ã«æ¸›å°‘ã—ã¦ã„ã¾ã™ã€‚éå»ã«ã¯ã€6æ­³æœªæº€ã®å­ä¾›ãŒé£²ã¿è¾¼ã‚€ç‰©ã®75%ä»¥ä¸ŠãŒç¡¬è²¨ã§ã—ãŸãŒã€2012å¹´ã‹ã‚‰2022å¹´ã®é–“ã«ã€å­ä¾›ã®æ°—é“ã‚„é¼»ã€å–‰ã‹ã‚‰ç•°ç‰©ã‚’å–ã‚Šé™¤ãæ‰‹è¡“ã®ä»¶æ•°ã¯29%æ¸›å°‘ã—ã€2,405ä»¶ã‹ã‚‰1,716ä»¶ã«ã¾ã§æ¸›ã‚Šã¾ã—ãŸã€‚å¤–ç§‘åŒ»ã®å­¦ä¼šã¯ã€ã“ã®æ¸›å°‘ã®åŸå› ã‚’ã€éæ¥è§¦å‹æ±ºæ¸ˆã®æ™®åŠã«ã‚ˆã‚‹å®¶åº­å†…ã®ç¡¬è²¨ã®æ¸›å°‘ã«ã‚ã‚‹ã¨ã—ã¦ã„ã¾ã™ã€‚\n\nã“ã®å‚¾å‘ã¯åŒ»å¸«ãŸã¡ã«æ­“è¿ã•ã‚Œã¦ã„ã¾ã™ãŒã€è¦ªã¯ãƒœã‚¿ãƒ³é›»æ± ã‚„ç£çŸ³ãªã©ã®å°ã•ãã¦å…‰ã‚‹ç‰©ã«ã‚‚æ³¨æ„ã‚’æ‰•ã†ã¹ãã ã¨è­¦å‘Šã—ã¦ã„ã¾ã™ã€‚ã“ã‚Œã‚‰ã‚‚ã¾ãŸã€æ·±åˆ»ãªå±é™ºã‚’ã‚‚ãŸã‚‰ã™å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ã‚‚ã—è¦ªãŒå­ä¾›ãŒæœ‰å®³ãªç‰©ã‚’é£²ã¿è¾¼ã‚“ã ã¨ç–‘ã£ãŸå ´åˆã¯ã€ã™ãã«ç—…é™¢ã«é€£ã‚Œã¦è¡Œãã¹ãã§ã™ã€‚å…¨ä½“ã¨ã—ã¦ã€æ‰‹è¡“ã®æ¸›å°‘ã¯å­ä¾›ã®å¥åº·ã«è‰¯ã„å½±éŸ¿ã‚’ä¸ãˆã‚‹ã ã‘ã§ãªãã€NHSã®ã‚µãƒ¼ãƒ“ã‚¹ã¸ã®è² æ‹…ã‚‚è»½æ¸›ã—ã¦ã„ã¾ã™ã€‚"
    }
  },
  {
    "id": "e1e3e76d805eb187",
    "title": {
      "en": "Plain â€“ a web framework for building products with Python",
      "ko": "í”Œë ˆì¸: íŒŒì´ì¬ìœ¼ë¡œ ì œí’ˆ ë§Œë“¤ê¸°",
      "ja": "ãƒ—ãƒ¬ãƒ¼ãƒ³ï¼šPythonè£½å“é–‹ç™ºãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯"
    },
    "type": "story",
    "url": "https://plainframework.com/",
    "score": 281,
    "by": "brylie",
    "time": 1743220502,
    "content": "Plain\n\n        A web framework for building products with Python.\n\n            Clone a starter kit â†’\n\n        Leverage the world's most popular programming language\n\n            Plain is a fork of Django,\n            bringing new ideas to established patterns in the Python landscape.\n            Build a new business, an internal tool, or something for yourself.\n\n            Entrepreneurial\n\n                Plain was forked inside of PullApprove â€” a revenue-generating SaaS with Fortune 500 customers.\n\n            End-to-end\n\n                Local development with a single command.\n                Go to production with dashboards, feature flags, and more.\n\n            Ecosystem\n\n                Plain is split into multiple first-party packages.\n                Major features are optional and new ideas can evolve independently.\n\n            Foundation Packages\n            Building blocks for products\n\n                    plain\n\n                        The foundations for shipping Python code to the web â€” urls, views, templates, forms, and more.\n\n                    plain.models\n\n                        Store your data in Postgres, MySQL, or SQLite with a tried and true ORM.\n\n                    plain.cache\n\n                        A caching solution designed just to work with your existing database.\n\n                    plain.email\n\n                        App-wide email configuration and sending, with templates and attachments.\n\n                    plain.sessions\n\n                        Read and write to database-backed sessions.\n\n                    plain.worker\n\n                        An official solution for background work, backed by the database you already have.\n\n                    plain.api\n\n                        Build JSON APIs with the same class-based view architecture you already know.\n\n                Browse source docs â†’\n\n            Auth Packages\n            Authentication you can trust (and host yourself)\n\n                    plain.auth\n\n                        The foundation for adding users to your app, authenticating them to requests and restricting views.\n\n                    plain.oauth\n\n                        A flexible OAuth solution to support modern social logins and API access.\n\n                    plain.passwords\n\n                        Password-based login that works like it always has, if you want it.\n\n                    plain.loginlink\n\n                        Send one-time login links to users, and let them log in without a password.\n\n                    plain.passkeys coming soon\n\n                        Passwordless login with passkeys.\n\n                Browse source docs â†’\n\n            Admin Packages\n            The backbone of your back office\n\n                    plain.admin\n\n                        An admin dashboard you can fully customize, and Plain packages know how to integrate with.\n\n                    plain.flags\n\n                        Database-backed feature flags to control who sees what and quietly deploy progress.\n\n                    plain.support\n\n                        Provide better customer support without the need for third-party services.\n\n                    plain.redirection\n\n                        Monitor 404s and manage redirects in the database.\n\n                    plain.pageviews\n\n                        See what users are looking at, and provide better support.\n\n                Browse source docs â†’\n\n            Dev Packages\n            A tailored local development experience\n\n                    plain.dev\n\n                        Fire up your local development environment with a single command.\n\n                    plain.pytest\n\n                        Write and run tests with one of Python's most popular testing libraries.\n\n                    plain.code\n\n                        Format and lint your Python code with opinionated defaults.\n\n                    plain.tunnel\n\n                        Expose your local app to the internet to build webhook integrations.\n\n                Browse source docs â†’\n\n            Frontend Packages\n            Modern tools for modern user interfaces\n\n                    plain.tailwind\n\n                        First-class integration for everyone's favorite CSS framework. Node.js not required.\n\n                    plain.htmx\n\n                        Build a modern user experience with the tools you already know.\n\n                    plain.elements\n\n                        A new paradigm for reusable components across your app's templates.\n\n                    plain.pages\n\n                        File-based routing for marketing sites and documentation, using HTML and Markdown.\n\n                    plain.esbuild\n\n                        A simplified build process for JavaScript that needs to be compiled.\n\n                    plain.vendor\n\n                        Download and self-host JavaScript and CSS assets without depending on a CDN.\n\n                Browse source docs â†’",
    "summary": {
      "en": "**Summary of Plain Web Framework**\n\nPlain is a web framework for building products using Python, designed as a fork of Django. It aims to introduce new ideas while following established patterns, making it ideal for creating businesses, internal tools, or personal projects.\n\n**Key Features:**\n\n- **Origin:** Developed within PullApprove, a successful SaaS company with major clients.\n- **Development:** Offers easy local development with a single command and supports production deployment with features like dashboards and feature flags.\n- **Modularity:** Plain consists of various packages that cover different functionalities, allowing for flexible use of major features.\n\n**Core Packages:**\n\n1. **Foundation Packages:** Basic tools for web development, including URL handling, data storage (with ORM), caching, email services, session management, and JSON API creation.\n   \n2. **Auth Packages:** Reliable authentication options, including user management, OAuth for social logins, traditional password logins, one-time login links, and upcoming passwordless login with passkeys.\n\n3. **Admin Packages:** Tools for building customizable admin dashboards, feature flags, customer support, redirect management, and user activity tracking.\n\n4. **Dev Packages:** Enhancements for local development, including environment setup, testing, code formatting, and tunneling for external access.\n\n5. **Frontend Packages:** Modern tools for user interfaces, featuring integration with popular CSS frameworks, reusable components, file-based routing, and simplified JavaScript building.\n\nPlain is designed to be user-friendly, making it a solid choice for developers looking to create web applications efficiently.",
      "ko": "Plainì€ íŒŒì´ì¬ì„ ì‚¬ìš©í•˜ì—¬ ì œí’ˆì„ êµ¬ì¶•í•˜ê¸° ìœ„í•œ ì›¹ í”„ë ˆì„ì›Œí¬ë¡œ, Djangoì—ì„œ íŒŒìƒëœ ê²ƒì…ë‹ˆë‹¤. ê¸°ì¡´ì˜ íŒ¨í„´ì„ ë”°ë¥´ë©´ì„œ ìƒˆë¡œìš´ ì•„ì´ë””ì–´ë¥¼ ë„ì…í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•˜ì—¬, ë¹„ì¦ˆë‹ˆìŠ¤, ë‚´ë¶€ ë„êµ¬ ë˜ëŠ” ê°œì¸ í”„ë¡œì íŠ¸ë¥¼ ë§Œë“œëŠ” ë° ì í•©í•©ë‹ˆë‹¤.\n\nPlainì˜ ì£¼ìš” íŠ¹ì§• ì¤‘ í•˜ë‚˜ëŠ” PullApproveë¼ëŠ” ì„±ê³µì ì¸ SaaS íšŒì‚¬ ë‚´ì—ì„œ ê°œë°œë˜ì—ˆë‹¤ëŠ” ì ì…ë‹ˆë‹¤. ì´ íšŒì‚¬ëŠ” ì£¼ìš” ê³ ê°ì„ ë³´ìœ í•˜ê³  ìˆìŠµë‹ˆë‹¤. Plainì€ ë‹¨ì¼ ëª…ë ¹ì–´ë¡œ ì‰½ê²Œ ë¡œì»¬ ê°œë°œì„ ì§€ì›í•˜ë©°, ëŒ€ì‹œë³´ë“œì™€ ê¸°ëŠ¥ í”Œë˜ê·¸ì™€ ê°™ì€ ê¸°ëŠ¥ì„ í†µí•´ í”„ë¡œë•ì…˜ ë°°í¬ë„ ì§€ì›í•©ë‹ˆë‹¤. ë˜í•œ, ë‹¤ì–‘í•œ íŒ¨í‚¤ì§€ë¡œ êµ¬ì„±ë˜ì–´ ìˆì–´ ì£¼ìš” ê¸°ëŠ¥ì„ ìœ ì—°í•˜ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ëª¨ë“ˆì„±ì„ ì œê³µí•©ë‹ˆë‹¤.\n\nPlainì˜ í•µì‹¬ íŒ¨í‚¤ì§€ì—ëŠ” ì—¬ëŸ¬ ê°€ì§€ê°€ ìˆìŠµë‹ˆë‹¤. ì²« ë²ˆì§¸ëŠ” ê¸°ë³¸ ì›¹ ê°œë°œ ë„êµ¬ë¥¼ í¬í•¨í•˜ëŠ” ê¸°ì´ˆ íŒ¨í‚¤ì§€ë¡œ, URL ì²˜ë¦¬, ë°ì´í„° ì €ì¥(ORM í¬í•¨), ìºì‹±, ì´ë©”ì¼ ì„œë¹„ìŠ¤, ì„¸ì…˜ ê´€ë¦¬, JSON API ìƒì„± ë“±ì„ ì œê³µí•©ë‹ˆë‹¤. ë‘ ë²ˆì§¸ëŠ” ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì¸ì¦ ì˜µì…˜ì„ ì œê³µí•˜ëŠ” ì¸ì¦ íŒ¨í‚¤ì§€ë¡œ, ì‚¬ìš©ì ê´€ë¦¬, ì†Œì…œ ë¡œê·¸ì¸ì„ ìœ„í•œ OAuth, ì „í†µì ì¸ ë¹„ë°€ë²ˆí˜¸ ë¡œê·¸ì¸, ì¼íšŒì„± ë¡œê·¸ì¸ ë§í¬, ê·¸ë¦¬ê³  ê³§ ì œê³µë  ë¹„ë°€ë²ˆí˜¸ ì—†ëŠ” ë¡œê·¸ì¸ ê¸°ëŠ¥ì¸ íŒ¨ìŠ¤í‚¤ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.\n\nì„¸ ë²ˆì§¸ëŠ” ì‚¬ìš©ì ì •ì˜ ê°€ëŠ¥í•œ ê´€ë¦¬ì ëŒ€ì‹œë³´ë“œë¥¼ êµ¬ì¶•í•  ìˆ˜ ìˆëŠ” ë„êµ¬ë¥¼ ì œê³µí•˜ëŠ” ê´€ë¦¬ì íŒ¨í‚¤ì§€ì…ë‹ˆë‹¤. ì—¬ê¸°ì—ëŠ” ê¸°ëŠ¥ í”Œë˜ê·¸, ê³ ê° ì§€ì›, ë¦¬ë””ë ‰ì…˜ ê´€ë¦¬, ì‚¬ìš©ì í™œë™ ì¶”ì  ê¸°ëŠ¥ì´ í¬í•¨ë©ë‹ˆë‹¤. ë„¤ ë²ˆì§¸ëŠ” ë¡œì»¬ ê°œë°œì„ ìœ„í•œ í–¥ìƒëœ ê¸°ëŠ¥ì„ ì œê³µí•˜ëŠ” ê°œë°œ íŒ¨í‚¤ì§€ë¡œ, í™˜ê²½ ì„¤ì •, í…ŒìŠ¤íŠ¸, ì½”ë“œ í¬ë§·íŒ…, ì™¸ë¶€ ì ‘ê·¼ì„ ìœ„í•œ í„°ë„ë§ ê¸°ëŠ¥ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ, ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ë¥¼ ìœ„í•œ í˜„ëŒ€ì ì¸ ë„êµ¬ë¥¼ ì œê³µí•˜ëŠ” í”„ë¡ íŠ¸ì—”ë“œ íŒ¨í‚¤ì§€ê°€ ìˆìœ¼ë©°, ì¸ê¸° ìˆëŠ” CSS í”„ë ˆì„ì›Œí¬ì™€ì˜ í†µí•©, ì¬ì‚¬ìš© ê°€ëŠ¥í•œ ì»´í¬ë„ŒíŠ¸, íŒŒì¼ ê¸°ë°˜ ë¼ìš°íŒ…, ê°„ì†Œí™”ëœ ìë°”ìŠ¤í¬ë¦½íŠ¸ ë¹Œë“œë¥¼ ì§€ì›í•©ë‹ˆë‹¤.\n\nPlainì€ ì‚¬ìš©ì ì¹œí™”ì ìœ¼ë¡œ ì„¤ê³„ë˜ì–´ ìˆì–´, íš¨ìœ¨ì ìœ¼ë¡œ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ë§Œë“¤ê³ ì í•˜ëŠ” ê°œë°œìë“¤ì—ê²Œ í›Œë¥­í•œ ì„ íƒì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
      "ja": "Plainã¯ã€Pythonã‚’ä½¿ç”¨ã—ã¦è£½å“ã‚’æ§‹ç¯‰ã™ã‚‹ãŸã‚ã®ã‚¦ã‚§ãƒ–ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã€Djangoã‚’åŸºã«ã—ãŸæ´¾ç”Ÿç‰ˆã§ã™ã€‚ç¢ºç«‹ã•ã‚ŒãŸãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¾“ã„ãªãŒã‚‰æ–°ã—ã„ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’å–ã‚Šå…¥ã‚Œã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¦ãŠã‚Šã€ãƒ“ã‚¸ãƒã‚¹ã‚„å†…éƒ¨ãƒ„ãƒ¼ãƒ«ã€å€‹äººãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ä½œæˆã«æœ€é©ã§ã™ã€‚\n\nPlainã®é–‹ç™ºã¯ã€ä¸»è¦ãªã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’æŒã¤æˆåŠŸã—ãŸSaaSä¼æ¥­ã§ã‚ã‚‹PullApproveå†…ã§è¡Œã‚ã‚Œã¾ã—ãŸã€‚ãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™ºã¯ç°¡å˜ãªã‚³ãƒãƒ³ãƒ‰ä¸€ã¤ã§è¡Œãˆã€ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚„æ©Ÿèƒ½ãƒ•ãƒ©ã‚°ãªã©ã®æ©Ÿèƒ½ã‚’ä½¿ã£ã¦æœ¬ç•ªç’°å¢ƒã¸ã®ãƒ‡ãƒ—ãƒ­ã‚¤ã‚‚ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚ã¾ãŸã€Plainã¯ã•ã¾ã–ã¾ãªæ©Ÿèƒ½ã‚’ã‚«ãƒãƒ¼ã™ã‚‹ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã§æ§‹æˆã•ã‚Œã¦ãŠã‚Šã€ä¸»è¦ãªæ©Ÿèƒ½ã‚’æŸ”è»Ÿã«åˆ©ç”¨ã§ãã‚‹ã‚ˆã†ã«ãªã£ã¦ã„ã¾ã™ã€‚\n\nPlainã®ã‚³ã‚¢ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã«ã¯ã€åŸºæœ¬çš„ãªã‚¦ã‚§ãƒ–é–‹ç™ºãƒ„ãƒ¼ãƒ«ã‚’æä¾›ã™ã‚‹ãƒ•ã‚¡ã‚¦ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ç®¡ç†ã‚„ã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒ­ã‚°ã‚¤ãƒ³ç”¨ã®OAuthã€å¾“æ¥ã®ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãƒ­ã‚°ã‚¤ãƒ³ã€ä¸€å›é™ã‚Šã®ãƒ­ã‚°ã‚¤ãƒ³ãƒªãƒ³ã‚¯ã€ä»Šå¾Œæä¾›äºˆå®šã®ãƒ‘ã‚¹ã‚­ãƒ¼ã‚’ä½¿ã£ãŸãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãƒ¬ã‚¹ãƒ­ã‚°ã‚¤ãƒ³ã‚’å«ã‚€ä¿¡é ¼æ€§ã®é«˜ã„èªè¨¼ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’æä¾›ã™ã‚‹èªè¨¼ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã€ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºå¯èƒ½ãªç®¡ç†ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚„æ©Ÿèƒ½ãƒ•ãƒ©ã‚°ã€é¡§å®¢ã‚µãƒãƒ¼ãƒˆã€ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆç®¡ç†ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼æ´»å‹•ã®è¿½è·¡ãƒ„ãƒ¼ãƒ«ã‚’å«ã‚€ç®¡ç†ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã€ç’°å¢ƒè¨­å®šã‚„ãƒ†ã‚¹ãƒˆã€ã‚³ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã€å¤–éƒ¨ã‚¢ã‚¯ã‚»ã‚¹ã®ãŸã‚ã®ãƒˆãƒ³ãƒãƒªãƒ³ã‚°ã‚’å«ã‚€ãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™ºã‚’å¼·åŒ–ã™ã‚‹é–‹ç™ºãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã€äººæ°—ã®CSSãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¨ã®çµ±åˆã‚„å†åˆ©ç”¨å¯èƒ½ãªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã€ãƒ•ã‚¡ã‚¤ãƒ«ãƒ™ãƒ¼ã‚¹ã®ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã€ç°¡ç´ åŒ–ã•ã‚ŒãŸJavaScriptãƒ“ãƒ«ãƒ‰ã‚’ç‰¹å¾´ã¨ã™ã‚‹ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒã‚ã‚Šã¾ã™ã€‚\n\nPlainã¯ä½¿ã„ã‚„ã™ã•ã‚’é‡è¦–ã—ã¦è¨­è¨ˆã•ã‚Œã¦ãŠã‚Šã€åŠ¹ç‡çš„ã«ã‚¦ã‚§ãƒ–ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä½œæˆã—ãŸã„é–‹ç™ºè€…ã«ã¨ã£ã¦ã€å …å®Ÿãªé¸æŠè‚¢ã¨ãªã£ã¦ã„ã¾ã™ã€‚"
    }
  },
  {
    "id": "bc5d315def688e93",
    "title": {
      "en": "The Wrong Way to Use a Signed Distance Function (SDF)",
      "ko": "SDF ì˜ëª» ì“°ê¸°",
      "ja": "SDFã®èª¤ç”¨æ³•"
    },
    "type": "story",
    "url": "https://winterbloed.be/the-wrong-way-to-use-a-signed-distance-function/",
    "score": 29,
    "by": "AnthonBerg",
    "time": 1743271807,
    "content": "The wrong way to use a signed distance function (sdf)\n\nDisclaimer: thereâ€™s nothing wrong with using a sdf this way.\n\nRecently, my good friend Mike Brondbjerg posted this on Twitter:\n\nDark Matter: 50,000 particles passing through a field until they hit a hidden sphere. By varying the distance travelled each step, the collisions are more / less accurate, so creating a nice fuzziness around the spheres. #generative #design #creativecommuting #creativecoding pic.twitter.com/gmFEV7fCwkâ€” Mike Brondbjerg (@mikebrondbjerg) January 15, 2020\n\nYou can follow along and see how this idea is evolving into the beautiful, elegant line drawings that are the hallmark of his style.\n\nDark Matter: random walk obstacle avoidanceâ€¦ nice random output. #creativecoding #generative #design #processing pic.twitter.com/DTzy7H2G6Zâ€” Mike Brondbjerg (@mikebrondbjerg) January 26, 2020\n Spheres\nMikeâ€™s post gave me an idea, a way to introduce a concept I like to use in some of my work: signed distance functions. Sdfs are more commonly associated with raytracing and shaders, and by far the best source to learn about them in that context is Inigo Quilez, of Shadertoy fame:  https://iquilezles.org/.\nBut there is a delightfully wrong way to use a sdf. Their primary use in raytracing and shaders is to define meshless geometry. For example, a way to draw smooth spheres without generating a ton of triangles. The use Iâ€™m showing here is the exact opposite: to generate geometry, point clouds in fact. Geometry that then needs to be processed in a conventional way before it can be rendered on the screen.\nLetâ€™s imagine we want to tackle something similar to the tweet: particles colliding with a sphere. One way to do this is by calculating the distance of the particle to the center of the sphere, letâ€™s keep it at the origin. For a particle  pâƒ— \\vec{p} p  at position (x,y,z)(x,y,z)(x,y,z) , this distance is given by: d(pâƒ—)=x.x+y.y+z.z {d( \\vec{p} )=\\sqrt{x.x+y.y+z.z}}d(p)=x.x+y.y+z.z. If that distance   ddd is larger than the radius  r rr  of the sphere, the particle is outside the sphere, if itâ€™s smaller then it is inside, if itâ€™s exactly the same then it is on the surface.\n\n{d(pâƒ—)<r,ifpâƒ—isinsided(pâƒ—)=r,ifpâƒ—isonsphered(pâƒ—)>r,ifpâƒ—isoutside\\begin{cases}  d( \\vec{p} )<r, & \\text{if }  \\vec{p}\\text{ is inside} \\\\  d( \\vec{p} )=r , & \\text{if }  \\vec{p}\\text{ is on sphere}\\\\  d( \\vec{p} )>r, & \\text{if }  \\vec{p}\\text{ is outside}  \\end{cases}â©âªâªâ¨âªâªâ§d(p)<r,d(p)=r,d(p)>r,ifpisinsideifpisonsphereifpisoutside\n\nUsing this, we can check the particles every step. As long as their distance to the sphere is larger than the radius, theyâ€™re fine. If a particle takes a step and its distance becomes smaller or equal, it has hit the sphere.\n\n A grid of particles flying into a sphere. Some have collided with the sphere, the rest is zooming off into infinity.\nIf the sphere is not in the origin but centered in a point câƒ—(cx,cy,cz) \\vec{c} (cx,cy,cz)  c(cx,cy,cz)  the distance function becomes  d(pâƒ—,câƒ—)=(xâˆ’cx).(xâˆ’cx)+(yâˆ’cy).(yâˆ’cy)+(zâˆ’cz).(zâˆ’cz) {d( \\vec{p} , \\vec{c} )=\\sqrt{(x-cx).(x-cx)+(y-cy).(y-cy)+(z-cz).(z-cz)}}d(p,c)=(xâˆ’cx).(xâˆ’cx)+(yâˆ’cy).(yâˆ’cy)+(zâˆ’cz).(zâˆ’cz). Typically, this is explained as the length of the vector going from  pâƒ— \\vec{p} p  to câƒ—  \\vec{c} c. Another way to see it, that will serve us well further on, is to imagine that we shift the sphere to the origin,   câƒ—â†’0âƒ— \\vec{c}\\to\\vec{0}   câ†’0, and the entire space moves with it . Our particle is then moved  pâƒ—â†’pâƒ—âˆ’câƒ—  \\vec{p}\\to\\vec{p}-\\vec{c} pâ†’pâˆ’c. Checking a particle at  pâƒ— \\vec{p} p  against a sphere in center  câƒ— \\vec{c} c  is the same as doing it for a particle at  pâƒ—âˆ’câƒ—  \\vec{p}-\\vec{c} pâˆ’c against a sphere in the origin.\nSince we can put the sphere wherever we want, we can add multiple spheres. Each particle is then tested against the different spheres one by one.\n\n A grid of particles flying into a bunch of spheres.\n\nDistance Fields\nIn creative coding, it is often useful to have several perspectives to look at things. The equations above can be refactored:\n\n{d(pâƒ—)âˆ’r<0,ifpâƒ—isinsided(pâƒ—)âˆ’r=0,ifpâƒ—isonsphered(pâƒ—)âˆ’r>0,ifpâƒ—isoutside\\begin{cases}  d( \\vec{p} )-r<0, & \\text{if }  \\vec{p}\\text{ is inside} \\\\  d( \\vec{p} )-r=0 , & \\text{if }  \\vec{p}\\text{ is on sphere}\\\\  d( \\vec{p} )-r>0, & \\text{if }  \\vec{p}\\text{ is outside}  \\end{cases}â©âªâªâ¨âªâªâ§d(p)âˆ’r<0,d(p)âˆ’r=0,d(p)âˆ’r>0,ifpisinsideifpisonsphereifpisoutside\n\nNothing has really changed, the equations are still the same. But what they describe is a function  d(pâƒ—)âˆ’r {d( \\vec{p} )-r}d(p)âˆ’r that separates space in three regions: one region outside the sphere, with positive values; one region inside the sphere, with negative values; and the surface of the sphere itself, where the function equals zero. This is the signed distance function of a sphere in the origin, with radius   r  r r .\nTesting the particles at each step is essentially the same evaluation: calculate the function at  pâƒ— \\vec{p} p and see how it classifies. The advantage of seeing it this way is that the signed distance function can be easily replaced, and suddenly weâ€™re checking collisions with a box, a torus, or any of the many shapes that have a well-defined sdf, like the list Inigo keeps.\n\n A grid of particles flying into a bunch of boxes.\nIn itself, thereâ€™s nothing stopping us from using the first approach to calculate the distance of a point to some specific geometry. But I find sdfs make it more intuitive, especially when we start modifying and combining them.\nNot every function is a signed distance function, there are certain requirements. Iâ€™m not going into the rigorous math details, mainly because Iâ€™m not qualified enough to pull that off. In essence, its rate of change has to correspond to what you expect for a distance. If we follow the slope of the function downwards, we expect to end up at the surface. If we take small steps towards it, the distance should decrease with small steps, not suddenly change slope or start increasing.\nAs a creative coder, one of the first things we think of is â€œadd noiseâ€, which is not a mathematically valid distance function. Adding noise to the sdf of a sphere doesnâ€™t give us the sdf of a noisy sphere. Fortunately, as creative coders, we can choose to forego the rigor and let the mayhem surprise us.\n\nNoise might not be a valid distance function, but itâ€™s still fun to use.\nTracer classes\nAlthough a lot of information and functions are available online, it might not be immediately clear how to use any of it in Processing. Typically, code is given in OpenGL Shading Language (GLSL) and the used functions arenâ€™t always obvious. GLSL is created to deal with numbers and vectors in a unified way. A function like max(v,0.0) looks familiar but in GLSL can also work component-wise on vectors, something that Processing doesnâ€™t handle. Transcribing sdf functions can be confusing when unfamiliar with GLSL.\nIn this section, weâ€™ll be creating the code used for the images above. In the end, we will have a rudimentary framework to build on for more complex pieces. Letâ€™s start with some convenience classes, Point and Vector.\n\nJava\n\n\t\t\tclass Point {\n  float x, y, z;\n  Point(float x, float y, float z) {\n    this.x=x;\n    this.y=y;\n    this.z=z;\n  }\n}\n\n1\n2\n3\n4\n5\n6\n7\n8\n\nclass Point {\n\nfloat x, y, z;\n\nPoint(float x, float y, float z) {\n\nthis.x=x;\n\nthis.y=y;\n\nthis.z=z;\n\n}\n\n}\n\nJava\n\n\t\t\tclass Vector {\n  float x, y, z;\n  Vector(float x, float y, float z) {\n    this.x=x;\n    this.y=y;\n    this.z=z;\n  }\n}\n\n1\n2\n3\n4\n5\n6\n7\n8\n\nclass Vector {\n\nfloat x, y, z;\n\nVector(float x, float y, float z) {\n\nthis.x=x;\n\nthis.y=y;\n\nthis.z=z;\n\n}\n\n}\n\nBoth are just containers for coordinates. There is no real reason why we canâ€™t use Processing PVector for this, or why we have both Point and Vector. But for this tutorial, it is easier to talk about points and vectors with as little abstraction as possible.\nAnother class that will come in handy is Ray, a half-line starting at a Point origin, the direction is given by the Vector direction. On creation, direction is normalized, its length is rescaled to 1.0. The function get(t) will return a new Point on the ray, a distance t from its origin.\n\nJava\n\n\t\t\tclass Ray {\n  Point origin;\n  Vector direction;\n\n  Ray(Point origin, Vector direction) {\n    this.origin=new Point(origin.x, origin.y, origin.z);\n    float mag=direction.x*direction.x+direction.y*direction.y+direction.z*direction.z;\n    assert(mag&gt;0.000001);\n    mag=1.0/sqrt(mag);\n    this.direction=new Vector(direction.x*mag, direction.y*mag, direction.z*mag);\n  }\n\n  //Get point on ray at distance t from origin\n  Point get(float t) {\n    return new Point(origin.x+t*direction.x, origin.y+t*direction.y, origin.z+t*direction.z);\n  }\n}\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\nclass Ray {\n\nPoint origin;\n\nVector direction;\n\nRay(Point origin, Vector direction) {\n\nthis.origin=new Point(origin.x, origin.y, origin.z);\n\nfloat mag=direction.x*direction.x+direction.y*direction.y+direction.z*direction.z;\n\nassert(mag&gt;0.000001);\n\nmag=1.0/sqrt(mag);\n\nthis.direction=new Vector(direction.x*mag, direction.y*mag, direction.z*mag);\n\n}\n\n//Get point on ray at distance t from origin\n\nPoint get(float t) {\n\nreturn new Point(origin.x+t*direction.x, origin.y+t*direction.y, origin.z+t*direction.z);\n\n}\n\n}\n\nFor our mini-framework, we need signed distance functions. We could hardwire the functions into a sdf(Point p) function and change that code every time. But, a bit of structure goes a long way to help exploration. First, we need to tell Processing/JAVA what a signed distance function is:\n\nJava\n\n\t\t\t//Interface that implements a signed distance function\ninterface SDF {\n  float signedDistance(Point p);\n}\n\n1\n2\n3\n4\n\n//Interface that implements a signed distance function\n\ninterface SDF {\n\nfloat signedDistance(Point p);\n\n}\n\nDonâ€™t worry if the details on what an interface is arenâ€™t clear. We can consider it a promise to Processing: everything we identify as a SDF will have this function signedDistance(Point p) that returns a float. It doesnâ€™t matter what class it is precisely, how we create objects of that class, how the object calculates the distance, as long as we tell Processing itâ€™s an SDF, it will be able to call that function. An interface can be used to define variables, to pass objects to functions, pretty much everywhere we can use a class. What we canâ€™t do, is create a new object with new SDF().\nWe already encountered one signed distance function, that of a sphere at the origin with radius r,  d(pâƒ—)âˆ’r {d( \\vec{p} )-r}d(p)âˆ’r. We can now implement a class that encapsulates this.\n\nJava\n\n\t\t\t/*\nGLSL code https://iquilezles.org/www/articles/distfunctions/distfunctions.htm\nfloat sdSphere( vec3 p, float s )\n{\n  return length(p)-s;\n}\n*/\n\nclass SphereSDF implements SDF {\n  float radius;\n\n  SphereSDF(float r) {\n    radius=r;\n  }\n\n  float signedDistance(Point p) {\n    return sqrt(sq(p.x)+sq(p.y)+sq(p.z))-radius;\n  }\n}\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n\n/*\nGLSL code https://iquilezles.org/www/articles/distfunctions/distfunctions.htm\nfloat sdSphere( vec3 p, float s )\n{\nreturn length(p)-s;\n}\n*/\n\nclass SphereSDF implements SDF {\n\nfloat radius;\n\nSphereSDF(float r) {\n\nradius=r;\n\n}\n\nfloat signedDistance(Point p) {\n\nreturn sqrt(sq(p.x)+sq(p.y)+sq(p.z))-radius;\n\n}\n\n}\n\nWe tell Processing that this class implements SDF. In return, we need to fulfill our promise and implement  signedDistance(Point p) . Everywhere Processing expects a SDF we can now pass a SphereSDF and it will work.\nSimilarly, we can define the sdf of a box at the origin of size X, Y, and Z.\n\nJava\n\n\t\t\t/*\nGLSL code https://iquilezles.org/www/articles/distfunctions/distfunctions.htm\nfloat sdBox( vec3 p, vec3 b )\n{\n  vec3 q = abs(p) - b;\n  return length(max(q,0.0)) + min(max(q.x,max(q.y,q.z)),0.0);\n}\n*/\n\nclass BoxSDF implements SDF {\n  float X, Y, Z;\n\n  BoxSDF(float x, float y, float z) {\n    X=x;\n    Y=y;\n    Z=z;\n  }\n\n  float signedDistance(Point p) {\n    float qx=abs(p.x)-X;\n    float qy=abs(p.y)-Y;\n    float qz=abs(p.z)-Z;\n    return sqrt(sq(max(qx,0.0))+sq(max(qy,0.0))+sq(max(qz,0.0)))+min(max(qx, qy, qz), 0.0);\n  }\n}\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n\n/*\nGLSL code https://iquilezles.org/www/articles/distfunctions/distfunctions.htm\nfloat sdBox( vec3 p, vec3 b )\n{\nvec3 q = abs(p) - b;\nreturn length(max(q,0.0)) + min(max(q.x,max(q.y,q.z)),0.0);\n}\n*/\n\nclass BoxSDF implements SDF {\n\nfloat X, Y, Z;\n\nBoxSDF(float x, float y, float z) {\n\nX=x;\n\nY=y;\n\nZ=z;\n\n}\n\nfloat signedDistance(Point p) {\n\nfloat qx=abs(p.x)-X;\n\nfloat qy=abs(p.y)-Y;\n\nfloat qz=abs(p.z)-Z;\n\nreturn sqrt(sq(max(qx,0.0))+sq(max(qy,0.0))+sq(max(qz,0.0)))+min(max(qx, qy, qz), 0.0);\n\n}\n\n}\n\nOne piece missing, the particles. Weâ€™re going to shoot particles, Tracers, into the scene along straight paths. When they hit something, they stop. Otherwise, they come to a stop after a certain distance. If our collision geometry would be defined by meshes, we could try to intersect the ray of the particles with the faces of the geometry. However, in this case, the whole point of this tutorial after all, we define the geometry by signed distance functions. So, we will be using another technique of finding collisions: sphere tracing.\nImagine we have an arbitrary collision geometry defined by a sdf and assume we have some particles starting outside this geometry. We know that in every point in space we can calculate the signed distance sdf(pâƒ—)  {sdf( \\vec{p} )} sdf(p).  That distance, letâ€™s call it  d d  d , tells us how close the geometry is to the point, but it doesnâ€™t give us a direction. The only thing we can say is that the particle can safely move in any direction over a distance  d d  d. In other words, we know that at that point we can put a sphere of radius   d d  d and know for sure that the geometry isnâ€™t in that sphere. In the extreme case, if the particle is moving straight towards the geometry, it might end up directly on the surface, but it will never cross it or go inside.\nTake the figure below. We start at  P0  P_{0} P0 and the chosen direction is along the blue line. The black triangle and rectangle are our collision geometry.  sdf(P0)  sdf( P_{0}) sdf(P0) tells us it that it is safe to move anywhere in the green circle centered on P0 P_{0} P0.\n\n https://demosceneacademy.wordpress.com/\nIf we take a big step, the maximum safe distance, along the blue line, we end up in  P1 P_{1}  P1.  sdf(P1)  sdf( P_{1}) sdf(P1) isnâ€™t zero. Our direction of movement wasnâ€™t the shortest path to the surface. We move on, this time a step of size  sdf(P1)  sdf( P_{1}) sdf(P1) and the particle ends up in   P2 P_{2}  P2. We can repeat this until the returned distance is close to zero, or if we never hit the surface, after we reach a cutoff distance. In the figure, the fourth step takes us to  P4 P_{4}  P4, on the surface.\nThe nice thing about this technique is that we donâ€™t have to guess step sizes. There is no risk of taking too many small steps and wasting time, or of taking too large steps and overshoot a collision. The sdf automatically takes care of this by dynamically adapting the step size.\nOur Tracer particle class looks like this:\n\nJava\n\n\t\t\tclass Tracer {\n  Ray ray;\n  float cutoff;\n  float precision;\n  float t;\n  float closestDistance;\n  int steps;\n  int MAXSTEPS=10000;\n  Point p;\n\n  Tracer(Point origin, Vector direction, float cutoff, float precision) {\n    ray=new Ray(origin, direction);\n    this.cutoff=cutoff;\n    this.precision=precision;\n    initialize();\n  }\n\n  void initialize(){\n    closestDistance= Float.POSITIVE_INFINITY;\n    t=0;\n    steps=0;\n    p=ray.get(0);\n  }\n\n  void trace(SDF sdf) {\n    p=null;\n    t=0.0;\n    steps=0;\n    do {\n      traceStep(sdf);\n      steps++;\n    } while (!onSurface() && t<cutoff && steps<MAXSTEPS);\n    if (t>cutoff) t=cutoff;\n    p=ray.get(t);\n  }\n\n  void traceStep(SDF sdf){\n    float d=sdf.signedDistance(ray.get(t));\n    if (d<closestDistance) closestDistance=d;\n    t+=d;\n  }\n\n  boolean onSurface(){\n    return closestDistance<=precision;\n  }\n\n  void reset() {\n    initialize();\n  }\n}\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n\nclass Tracer {\n\nRay ray;\n\nfloat cutoff;\n\nfloat precision;\n\nfloat t;\n\nfloat closestDistance;\n\nint steps;\n\nint MAXSTEPS=10000;\n\nPoint p;\n\nTracer(Point origin, Vector direction, float cutoff, float precision) {\n\nray=new Ray(origin, direction);\n\nthis.cutoff=cutoff;\n\nthis.precision=precision;\n\ninitialize();\n\n}\n\nvoid initialize(){\n\nclosestDistance= Float.POSITIVE_INFINITY;\n\nt=0;\n\nsteps=0;\n\np=ray.get(0);\n\n}\n\nvoid trace(SDF sdf) {\n\np=null;\n\nt=0.0;\n\nsteps=0;\n\ndo {\n\ntraceStep(sdf);\n\nsteps++;\n\n} while (!onSurface() && t<cutoff && steps<MAXSTEPS);\n\nif (t>cutoff) t=cutoff;\n\np=ray.get(t);\n\n}\n\nvoid traceStep(SDF sdf){\n\nfloat d=sdf.signedDistance(ray.get(t));\n\nif (d<closestDistance) closestDistance=d;\n\nt+=d;\n\n}\n\nboolean onSurface(){\n\nreturn closestDistance<=precision;\n\n}\n\nvoid reset() {\n\ninitialize();\n\n}\n\n}\n\nEach Tracer starts in a Point origin, along a Vector direction. Since our particles only move in a straight line, we store them as a Ray. We also need to define when we stop tracing the particles. Numerical roundoff makes it unlikely weâ€™ll get exactly 0.0 distance, so instead, we check if the distance becomes smaller than some value precison. If the tracer doesnâ€™t hit, we want to stop after a certain distance, called cutoff. Just to be safe, we limit the maximum number of steps our tracer can take, MAXSTEPS.\nThe current state of a Tracer is held in 4 variables:\n\nt: the current distance traveled along ray\n\nclosestDistance: the closest the particle has come to the surface so far\n\nsteps: the number of steps taken so far\n\np: the current position of the particle along the ray\n\nAt every step, the signed distance function is checked, and the particle is moved that distance forward along the ray. The tracing is stopped once one of three conditions is met:\n\nclosestDistance < precision: the particle has come closer to the surface than our precision threshold: collision.\n\nt>=cutoff: The distance traveled along the ray exceeds the cutoff distance: no collision.\n steps>=MAXSTEPS: The number of steps taken exceeds the maximum number allowed. This should only occur when weâ€™ve made a mistake in the code.\n\nIn any case, at the end of the trace, the particle is either on the surface or beyond our region of interest.\n Putting it all together\n\nTracer_2020 code\nTo reproduce this image, we need to create a sdf, create some particles, and run the traces. The script, including the classes can be found here.\n\nJava\n\n\t\t\tfloat emitterX, emitterY, emitterZ;\nArrayList<Tracer> tracers;\nSDF sdf;\n\nvoid setup() {\n  size(900, 900, P3D);\n  smooth(16);\n  noCursor();\n  createTracers();\n  createSDF();\n  trace();\n}\n\nvoid createTracers() {\n  tracers=new ArrayList<Tracer>();\n  float x, y;\n  emitterZ=500;\n  float cutoff=2*emitterZ;\n  int resX=50;\n  emitterX=600.0;\n  int resY=50;\n  emitterY=600.0;\n\n  for (int i=0; i<resX; i++) {\n    x=map(i, 0, resX-1, -emitterX*0.5, emitterX*0.5);\n    for (int j=0; j<resY; j++) {\n      y=map(j, 0, resY-1, -emitterY*0.5, emitterY*0.5);\n      tracers.add(new Tracer(new Point(x, y, emitterZ),new Vector( 0, 0, -1), cutoff, 0.1));\n    }\n  }\n}\n\nvoid createSDF() {\n  SphereSDF ssdf=new SphereSDF(120);\n  sdf=ssdf;\n}\n\nvoid trace(){\n  for (Tracer tracer : tracers) {\n    tracer.trace(sdf);\n  }\n}\n\nvoid draw() {\n  background(15);\n  //setup perspective\n  translate(width/2, height/2, 0);\n  rotateY(0.8*QUARTER_PI);\n  translate(0, 0, 200);\n\n  //draw sphere\n  fill(0);\n  noStroke();\n  sphere(119);\n\n  //draw limiting plane\n  pushMatrix();\n    translate(0, 0, -emitterZ-1.0);\n    rect(-emitterX*0.5, -emitterY*0.5, emitterX, emitterY);\n  popMatrix();\n\n  //draw tracers\n  strokeWeight(2);\n  stroke(240);\n  for (Tracer tracer : tracers) {\n    point(tracer.p.x, tracer.p.y, tracer.p.z);\n  }\n}\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n\nfloat emitterX, emitterY, emitterZ;\n\nArrayList<Tracer> tracers;\n\nSDF sdf;\n\nvoid setup() {\n\nsize(900, 900, P3D);\n\nsmooth(16);\n\nnoCursor();\n\ncreateTracers();\n\ncreateSDF();\n\ntrace();\n\n}\n\nvoid createTracers() {\n\ntracers=new ArrayList<Tracer>();\n\nfloat x, y;\n\nemitterZ=500;\n\nfloat cutoff=2*emitterZ;\n\nint resX=50;\n\nemitterX=600.0;\n\nint resY=50;\n\nemitterY=600.0;\n\nfor (int i=0; i<resX; i++) {\n\nx=map(i, 0, resX-1, -emitterX*0.5, emitterX*0.5);\n\nfor (int j=0; j<resY; j++) {\n\ny=map(j, 0, resY-1, -emitterY*0.5, emitterY*0.5);\n\ntracers.add(new Tracer(new Point(x, y, emitterZ),new Vector( 0, 0, -1), cutoff, 0.1));\n\n}\n\n}\n\n}\n\nvoid createSDF() {\n\nSphereSDF ssdf=new SphereSDF(120);\n\nsdf=ssdf;\n\n}\n\nvoid trace(){\n\nfor (Tracer tracer : tracers) {\n\ntracer.trace(sdf);\n\n}\n\n}\n\nvoid draw() {\n\nbackground(15);\n\n//setup perspective\n\ntranslate(width/2, height/2, 0);\n\nrotateY(0.8*QUARTER_PI);\n\ntranslate(0, 0, 200);\n\n//draw sphere\n\nfill(0);\n\nnoStroke();\n\nsphere(119);\n\n//draw limiting plane\n\npushMatrix();\n\ntranslate(0, 0, -emitterZ-1.0);\n\nrect(-emitterX*0.5, -emitterY*0.5, emitterX, emitterY);\n\npopMatrix();\n\n//draw tracers\n\nstrokeWeight(2);\n\nstroke(240);\n\nfor (Tracer tracer : tracers) {\n\npoint(tracer.p.x, tracer.p.y, tracer.p.z);\n\n}\n\n}\n\nTo setup the tracers, we create an emitter, a regular 600*600 square grid of 50Ã—50 points. This emitter is positioned somewhere â€œaboveâ€ the origin â€“ to the right in the image above. Each point defines a Tracer aimed along the negative Z-axis. The sdf in this example is a single sphere at the origin. To show the tracers missing the sphere, we draw a limiting plane at the cutoff distance.\nBeyond\nThis is just the start. In the next part, we will explore how we can extend the code to manipulate and combine signed distance functions.\nIn 2017, I create a series of images using different combinations of tracers, sdfs and shader effects, that shows just some of the possibilities.",
    "summary": {
      "en": "The text discusses the concept of using signed distance functions (SDFs) in creative coding, specifically in the context of particle collision simulation. Here are the key points simplified:\n\n1. **What is a Signed Distance Function (SDF)?**\n   - SDFs are mathematical functions that define the distance from a point to a surface. They are commonly used in graphics for rendering shapes without needing complex geometry.\n\n2. **Using SDFs in Particle Simulation:**\n   - The author explains how to use SDFs for simulating particles moving through space and colliding with objects like spheres. By calculating the distance from particles to a sphere, we can determine if they are inside, on the surface, or outside the sphere.\n\n3. **Collision Detection:**\n   - Particles are tested against the SDF to see if they hit the sphere. If their distance becomes smaller than the sphere's radius, they collide; otherwise, they continue moving.\n\n4. **Distance Fields:**\n   - The SDF separates space into regions: inside the sphere (negative values), on the surface (zero), and outside (positive values). This makes it easier to check for collisions with various shapes, not just spheres.\n\n5. **Creating Particles:**\n   - The text describes how to create a particle class (Tracer) that moves in straight lines and checks for collisions with the SDF. The tracer records its closest approach to the surface and stops when it either collides or reaches a maximum distance.\n\n6. **Implementing in Code:**\n   - The author provides Java code examples for creating point and vector classes, implementing the SDF, and creating the tracer class. The code demonstrates how to set up a scene with particles and a sphere using Processing, a programming environment for visual arts.\n\n7. **Future Exploration:**\n   - The author mentions plans to extend this work by manipulating and combining SDFs for more complex visuals. They reflect on previous projects that used different combinations of tracers and SDFs to create art.\n\nOverall, the text serves as a tutorial on using SDFs for creative coding in particle simulations, providing foundational knowledge and practical coding examples.",
      "ko": "ì´ ê¸€ì—ì„œëŠ” ì°½ì˜ì ì¸ ì½”ë”©ì—ì„œ ì„œëª… ê±°ë¦¬ í•¨ìˆ˜(SDF)ë¥¼ ì‚¬ìš©í•˜ëŠ” ê°œë…, íŠ¹íˆ ì…ì ì¶©ëŒ ì‹œë®¬ë ˆì´ì…˜ì— ëŒ€í•´ ì„¤ëª…í•©ë‹ˆë‹¤. ì£¼ìš” ë‚´ìš©ì„ ê°„ë‹¨íˆ ì •ë¦¬í•˜ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n\nì„œëª… ê±°ë¦¬ í•¨ìˆ˜(SDF)ëŠ” ì ê³¼ í‘œë©´ ì‚¬ì´ì˜ ê±°ë¦¬ë¥¼ ì •ì˜í•˜ëŠ” ìˆ˜í•™ì  í•¨ìˆ˜ì…ë‹ˆë‹¤. ë³µì¡í•œ ê¸°í•˜í•™ ì—†ì´ë„ í˜•íƒœë¥¼ ë Œë”ë§í•˜ëŠ” ë° ì£¼ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.\n\nì…ì ì‹œë®¬ë ˆì´ì…˜ì—ì„œ SDFë¥¼ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ ì„¤ëª…í•©ë‹ˆë‹¤. ì…ìê°€ ê³µê°„ì„ ì´ë™í•˜ë©° êµ¬ì²´ì™€ ì¶©ëŒí•˜ëŠ” ê³¼ì •ì„ ì‹œë®¬ë ˆì´ì…˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì…ìì™€ êµ¬ì²´ ì‚¬ì´ì˜ ê±°ë¦¬ë¥¼ ê³„ì‚°í•˜ì—¬ ì…ìê°€ êµ¬ì²´ ë‚´ë¶€ì— ìˆëŠ”ì§€, í‘œë©´ì— ìˆëŠ”ì§€, ì•„ë‹ˆë©´ ì™¸ë¶€ì— ìˆëŠ”ì§€ë¥¼ íŒë‹¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nì¶©ëŒ ê°ì§€ëŠ” ì…ìê°€ SDFì™€ ë¹„êµë˜ì–´ êµ¬ì²´ì— ì¶©ëŒí•˜ëŠ”ì§€ë¥¼ í™•ì¸í•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤. ì…ìì™€ êµ¬ì²´ ì‚¬ì´ì˜ ê±°ë¦¬ê°€ êµ¬ì²´ì˜ ë°˜ì§€ë¦„ë³´ë‹¤ ì‘ì•„ì§€ë©´ ì¶©ëŒì´ ë°œìƒí•˜ê³ , ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ ê³„ì† ì´ë™í•©ë‹ˆë‹¤.\n\nSDFëŠ” ê³µê°„ì„ ì—¬ëŸ¬ ì˜ì—­ìœ¼ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤. êµ¬ì²´ ë‚´ë¶€ëŠ” ìŒìˆ˜ ê°’, í‘œë©´ì€ 0, ì™¸ë¶€ëŠ” ì–‘ìˆ˜ ê°’ìœ¼ë¡œ í‘œì‹œë©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ êµ¬ì²´ë¿ë§Œ ì•„ë‹ˆë¼ ë‹¤ì–‘í•œ í˜•íƒœì™€ì˜ ì¶©ëŒì„ ì‰½ê²Œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nì…ìë¥¼ ìƒì„±í•˜ëŠ” ë°©ë²•ë„ ì„¤ëª…í•©ë‹ˆë‹¤. ì…ì í´ë˜ìŠ¤(Tracer)ë¥¼ ë§Œë“¤ì–´ ì§ì„ ìœ¼ë¡œ ì´ë™í•˜ë©° SDFì™€ ì¶©ëŒì„ ì²´í¬í•©ë‹ˆë‹¤. íŠ¸ë ˆì´ì„œëŠ” í‘œë©´ì— ê°€ì¥ ê°€ê¹Œìš´ ì§€ì ì„ ê¸°ë¡í•˜ê³  ì¶©ëŒí•˜ê±°ë‚˜ ìµœëŒ€ ê±°ë¦¬ì— ë„ë‹¬í•˜ë©´ ë©ˆì¶¥ë‹ˆë‹¤.\n\nì½”ë“œ êµ¬í˜„ì— ëŒ€í•œ ì˜ˆì‹œë„ ì œê³µë©ë‹ˆë‹¤. Java ì½”ë“œë¡œ ì ê³¼ ë²¡í„° í´ë˜ìŠ¤ë¥¼ ë§Œë“¤ê³  SDFë¥¼ êµ¬í˜„í•˜ë©° íŠ¸ë ˆì´ì„œ í´ë˜ìŠ¤ë¥¼ ìƒì„±í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ ì½”ë“œëŠ” Processingì´ë¼ëŠ” ì‹œê° ì˜ˆìˆ ì„ ìœ„í•œ í”„ë¡œê·¸ë˜ë° í™˜ê²½ì„ ì‚¬ìš©í•˜ì—¬ ì…ìì™€ êµ¬ì²´ê°€ ìˆëŠ” ì¥ë©´ì„ ì„¤ì •í•˜ëŠ” ë°©ë²•ì„ ì„¤ëª…í•©ë‹ˆë‹¤.\n\në¯¸ë˜ì˜ íƒìƒ‰ì— ëŒ€í•œ ê³„íšë„ ì–¸ê¸‰ë©ë‹ˆë‹¤. SDFë¥¼ ì¡°ì‘í•˜ê³  ê²°í•©í•˜ì—¬ ë” ë³µì¡í•œ ì‹œê° íš¨ê³¼ë¥¼ ë§Œë“œëŠ” ì‘ì—…ì„ í™•ì¥í•  ê³„íšì…ë‹ˆë‹¤. ì´ì „ í”„ë¡œì íŠ¸ì—ì„œ ë‹¤ì–‘í•œ íŠ¸ë ˆì´ì„œì™€ SDFì˜ ì¡°í•©ì„ ì‚¬ìš©í•˜ì—¬ ì˜ˆìˆ ì„ ì°½ì¡°í–ˆë˜ ê²½í—˜ì„ ë°˜ì˜í•©ë‹ˆë‹¤.\n\nì „ë°˜ì ìœ¼ë¡œ ì´ ê¸€ì€ ì…ì ì‹œë®¬ë ˆì´ì…˜ì—ì„œ SDFë¥¼ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì— ëŒ€í•œ íŠœí† ë¦¬ì–¼ë¡œ, ê¸°ì´ˆ ì§€ì‹ê³¼ ì‹¤ìš©ì ì¸ ì½”ë”© ì˜ˆì œë¥¼ ì œê³µí•©ë‹ˆë‹¤.",
      "ja": "ã‚µã‚¤ãƒ³è·é›¢é–¢æ•°ï¼ˆSDFï¼‰ã‚’ä½¿ã£ãŸã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã€ç‰¹ã«ç²’å­è¡çªã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã«ã¤ã„ã¦èª¬æ˜ã—ã¦ã„ã¾ã™ã€‚\n\nã‚µã‚¤ãƒ³è·é›¢é–¢æ•°ï¼ˆSDFï¼‰ã¨ã¯ã€ç‚¹ã‹ã‚‰è¡¨é¢ã¾ã§ã®è·é›¢ã‚’å®šç¾©ã™ã‚‹æ•°å­¦çš„ãªé–¢æ•°ã§ã™ã€‚è¤‡é›‘ãªå¹¾ä½•å­¦ã‚’å¿…è¦ã¨ã›ãšã«å½¢çŠ¶ã‚’æç”»ã™ã‚‹ãŸã‚ã«ã€ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã§ã‚ˆãä½¿ã‚ã‚Œã¦ã„ã¾ã™ã€‚\n\nSDFã‚’ä½¿ã£ãŸç²’å­ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯ã€ç²’å­ãŒç©ºé–“ã‚’ç§»å‹•ã—ã€çƒä½“ãªã©ã®ç‰©ä½“ã¨è¡çªã™ã‚‹æ§˜å­ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã—ã¾ã™ã€‚ç²’å­ã‹ã‚‰çƒä½“ã¾ã§ã®è·é›¢ã‚’è¨ˆç®—ã™ã‚‹ã“ã¨ã§ã€ç²’å­ãŒçƒä½“ã®å†…éƒ¨ã«ã„ã‚‹ã®ã‹ã€è¡¨é¢ã«ã„ã‚‹ã®ã‹ã€å¤–éƒ¨ã«ã„ã‚‹ã®ã‹ã‚’åˆ¤æ–­ã§ãã¾ã™ã€‚\n\nè¡çªæ¤œå‡ºã§ã¯ã€ç²’å­ãŒSDFã«å¯¾ã—ã¦ãƒ†ã‚¹ãƒˆã•ã‚Œã€çƒä½“ã«è¡çªã™ã‚‹ã‹ã©ã†ã‹ã‚’ç¢ºèªã—ã¾ã™ã€‚ç²’å­ã¨çƒä½“ã®è·é›¢ãŒçƒä½“ã®åŠå¾„ã‚ˆã‚Šå°ã•ããªã‚‹ã¨è¡çªãŒç™ºç”Ÿã—ã€ãã‚Œä»¥å¤–ã®å ´åˆã¯ç²’å­ã¯ãã®ã¾ã¾ç§»å‹•ã‚’ç¶šã‘ã¾ã™ã€‚\n\nSDFã¯ç©ºé–“ã‚’ã„ãã¤ã‹ã®é ˜åŸŸã«åˆ†ã‘ã¾ã™ã€‚çƒä½“ã®å†…éƒ¨ã¯è² ã®å€¤ã€è¡¨é¢ã¯ã‚¼ãƒ­ã€å¤–éƒ¨ã¯æ­£ã®å€¤ã§ã™ã€‚ã“ã®ä»•çµ„ã¿ã«ã‚ˆã‚Šã€çƒä½“ã ã‘ã§ãªãã•ã¾ã–ã¾ãªå½¢çŠ¶ã¨ã®è¡çªã‚’ãƒã‚§ãƒƒã‚¯ã—ã‚„ã™ããªã‚Šã¾ã™ã€‚\n\nç²’å­ã‚’ä½œæˆã™ã‚‹æ–¹æ³•ã¨ã—ã¦ã€ç›´ç·šçš„ã«ç§»å‹•ã—ã€SDFã¨ã®è¡çªã‚’ãƒã‚§ãƒƒã‚¯ã™ã‚‹ç²’å­ã‚¯ãƒ©ã‚¹ï¼ˆãƒˆãƒ¬ãƒ¼ã‚µãƒ¼ï¼‰ã‚’ä½œæˆã™ã‚‹ã“ã¨ãŒèª¬æ˜ã•ã‚Œã¦ã„ã¾ã™ã€‚ãƒˆãƒ¬ãƒ¼ã‚µãƒ¼ã¯è¡¨é¢ã¸ã®æœ€ã‚‚è¿‘ã„æ¥è¿‘ã‚’è¨˜éŒ²ã—ã€è¡çªã™ã‚‹ã‹æœ€å¤§è·é›¢ã«é”ã™ã‚‹ã¾ã§å‹•ãç¶šã‘ã¾ã™ã€‚\n\nã‚³ãƒ¼ãƒ‰ã®å®Ÿè£…ã«ã¤ã„ã¦ã¯ã€ãƒã‚¤ãƒ³ãƒˆã¨ãƒ™ã‚¯ãƒˆãƒ«ã®ã‚¯ãƒ©ã‚¹ã‚’ä½œæˆã—ã€SDFã‚’å®Ÿè£…ã—ã€ãƒˆãƒ¬ãƒ¼ã‚µãƒ¼ã‚¯ãƒ©ã‚¹ã‚’ä½œæˆã™ã‚‹ãŸã‚ã®Javaã‚³ãƒ¼ãƒ‰ã®ä¾‹ãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚ã“ã®ã‚³ãƒ¼ãƒ‰ã¯ã€Processingã¨ã„ã†è¦–è¦šèŠ¸è¡“ã®ãŸã‚ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ç’°å¢ƒã‚’ä½¿ã£ã¦ã€ç²’å­ã¨çƒä½“ã‚’ä½¿ã£ãŸã‚·ãƒ¼ãƒ³ã‚’è¨­å®šã™ã‚‹æ–¹æ³•ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚\n\nå°†æ¥çš„ã«ã¯ã€SDFã‚’æ“ä½œã—ãŸã‚Šçµ„ã¿åˆã‚ã›ãŸã‚Šã—ã¦ã€ã‚ˆã‚Šè¤‡é›‘ãªãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã‚’ä½œæˆã™ã‚‹è¨ˆç”»ãŒã‚ã‚‹ã¨è‘—è€…ã¯è¿°ã¹ã¦ã„ã¾ã™ã€‚éå»ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã¯ã€ç•°ãªã‚‹ãƒˆãƒ¬ãƒ¼ã‚µãƒ¼ã¨SDFã®çµ„ã¿åˆã‚ã›ã‚’ä½¿ã£ã¦ã‚¢ãƒ¼ãƒˆã‚’ä½œæˆã—ãŸã“ã¨ã‚’æŒ¯ã‚Šè¿”ã£ã¦ã„ã¾ã™ã€‚\n\nå…¨ä½“ã¨ã—ã¦ã€ã“ã®ãƒ†ã‚­ã‚¹ãƒˆã¯ç²’å­ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã«ãŠã‘ã‚‹SDFã®ä½¿ç”¨æ–¹æ³•ã«é–¢ã™ã‚‹ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã§ã‚ã‚Šã€åŸºç¤çŸ¥è­˜ã¨å®Ÿè·µçš„ãªã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ä¾‹ã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚"
    }
  },
  {
    "id": "2e66ac2f480270cc",
    "title": {
      "en": "Free Output â€“ AI output copyright status checker",
      "ko": "AI ì €ì‘ê¶Œ í™•ì¸ê¸°",
      "ja": "AIè‘—ä½œæ¨©ãƒã‚§ãƒƒã‚«ãƒ¼"
    },
    "type": "story",
    "url": "https://freeoutput.org/",
    "score": 24,
    "by": "knewter",
    "time": 1743273848,
    "content": "AI Output Copyright StatusDiscover which AI providers give you full copyright ownership of the generated content and which ones don't.Show Free Output OnlyOpenAIOpenAI is an AI research and deployment company, creator of ChatGPT and GPT models.Free OutputAnthropicAnthropic is an AI safety company that develops Claude, a conversational AI assistant.Restricted OutputGoogle (Gemini)Google's Gemini (formerly Bard) is a conversational AI service powered by Google's LLM models.Free OutputMidjourneyMidjourney is an AI image generation service accessible through Discord.Restricted OutputDeepSeekDeepSeek is a conversational AI service that provides Open Source models.Free OutputSuno AISuno is an AI music creation program designed to generate realistic songs.Restricted OutputMistral AIMistral is a French AI startup, specializing in open-weight LLMsFree Output",
    "summary": {
      "en": "This text discusses the copyright status of content generated by various AI providers. Here are the key points:\n\n- **OpenAI**: Full copyright ownership of generated content.\n- **Anthropic**: Develops Claude, a conversational AI with restricted output.\n- **Google (Gemini)**: Offers a conversational AI service with free output.\n- **Midjourney**: Generates images via Discord with free output.\n- **DeepSeek**: Provides a conversational AI with open-source models.\n- **Suno AI**: Creates realistic music but has restricted output.\n- **Mistral AI**: A French startup specializing in open-weight language models with restricted output.\n\nThe summary highlights which providers allow full ownership of the content they generate.",
      "ko": "ì´ í…ìŠ¤íŠ¸ëŠ” ë‹¤ì–‘í•œ AI ì œê³µì—…ì²´ê°€ ìƒì„±í•œ ì½˜í…ì¸ ì˜ ì €ì‘ê¶Œ ìƒíƒœì— ëŒ€í•´ ë‹¤ë£¨ê³  ìˆìŠµë‹ˆë‹¤. ì£¼ìš” ë‚´ìš©ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n\nOpenAIëŠ” ìƒì„±ëœ ì½˜í…ì¸ ì— ëŒ€í•œ ì™„ì „í•œ ì €ì‘ê¶Œ ì†Œìœ ê¶Œì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. Anthropicì€ ì œí•œëœ ì¶œë ¥ì„ ê°€ì§„ ëŒ€í™”í˜• AIì¸ Claudeë¥¼ ê°œë°œí•˜ê³  ìˆìŠµë‹ˆë‹¤. Googleì˜ GeminiëŠ” ë¬´ë£Œ ì¶œë ¥ì„ ì œê³µí•˜ëŠ” ëŒ€í™”í˜• AI ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤. MidjourneyëŠ” Discordë¥¼ í†µí•´ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ë©°, ì´ ë˜í•œ ë¬´ë£Œ ì¶œë ¥ì„ ì§€ì›í•©ë‹ˆë‹¤. DeepSeekëŠ” ì˜¤í”ˆ ì†ŒìŠ¤ ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ëŒ€í™”í˜• AIë¥¼ ì œê³µí•©ë‹ˆë‹¤. Suno AIëŠ” í˜„ì‹¤ê° ìˆëŠ” ìŒì•…ì„ ìƒì„±í•˜ì§€ë§Œ ì¶œë ¥ì— ì œí•œì´ ìˆìŠµë‹ˆë‹¤. Mistral AIëŠ” ì œí•œëœ ì¶œë ¥ì„ ê°€ì§„ ì˜¤í”ˆ ì›¨ì´íŠ¸ ì–¸ì–´ ëª¨ë¸ì— íŠ¹í™”ëœ í”„ë‘ìŠ¤ ìŠ¤íƒ€íŠ¸ì—…ì…ë‹ˆë‹¤.\n\nì´ ìš”ì•½ì€ ì–´ë–¤ ì œê³µì—…ì²´ê°€ ìƒì„±í•œ ì½˜í…ì¸ ì— ëŒ€í•œ ì™„ì „í•œ ì†Œìœ ê¶Œì„ í—ˆìš©í•˜ëŠ”ì§€ë¥¼ ê°•ì¡°í•©ë‹ˆë‹¤.",
      "ja": "ã“ã®ãƒ†ã‚­ã‚¹ãƒˆã¯ã€ã•ã¾ã–ã¾ãªAIãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ãŒç”Ÿæˆã™ã‚‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®è‘—ä½œæ¨©çŠ¶æ³ã«ã¤ã„ã¦èª¬æ˜ã—ã¦ã„ã¾ã™ã€‚ä¸»ãªãƒã‚¤ãƒ³ãƒˆã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ã€‚\n\nOpenAIã¯ã€ç”Ÿæˆã•ã‚ŒãŸã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã«å¯¾ã—ã¦å®Œå…¨ãªè‘—ä½œæ¨©ã‚’æ‰€æœ‰ã—ã¦ã„ã¾ã™ã€‚Anthropicã¯ã€åˆ¶é™ã•ã‚ŒãŸå‡ºåŠ›ã‚’æŒã¤ä¼šè©±å‹AIã€ŒClaudeã€ã‚’é–‹ç™ºã—ã¦ã„ã¾ã™ã€‚Googleã®Geminiã¯ã€è‡ªç”±ã«å‡ºåŠ›ã§ãã‚‹ä¼šè©±å‹AIã‚µãƒ¼ãƒ“ã‚¹ã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚Midjourneyã¯ã€Discordã‚’é€šã˜ã¦ç”»åƒã‚’ç”Ÿæˆã—ã€è‡ªç”±ã«å‡ºåŠ›ã§ãã¾ã™ã€‚DeepSeekã¯ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ãŸä¼šè©±å‹AIã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚Suno AIã¯ãƒªã‚¢ãƒ«ãªéŸ³æ¥½ã‚’ä½œæˆã—ã¾ã™ãŒã€å‡ºåŠ›ã«ã¯åˆ¶é™ãŒã‚ã‚Šã¾ã™ã€‚Mistral AIã¯ã€åˆ¶é™ã•ã‚ŒãŸå‡ºåŠ›ã‚’æŒã¤ã‚ªãƒ¼ãƒ—ãƒ³ã‚¦ã‚§ã‚¤ãƒˆã®è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’å°‚é–€ã¨ã™ã‚‹ãƒ•ãƒ©ãƒ³ã‚¹ã®ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—ã§ã™ã€‚\n\nã“ã®è¦ç´„ã¯ã€ã©ã®ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ãŒç”Ÿæˆã—ãŸã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å®Œå…¨ãªæ‰€æœ‰æ¨©ã‚’è¨±å¯ã—ã¦ã„ã‚‹ã‹ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚"
    }
  },
  {
    "id": "b52f13940fb4b58c",
    "title": {
      "en": "Beautiful and Minimalistic Chrome Extension",
      "ko": "ì•„ë¦„ë‹µê³  ê°„ê²°í•œ í¬ë¡¬ í™•ì¥ê¸°ëŠ¥",
      "ja": "ç¾ã—ããƒŸãƒ‹ãƒãƒ«æ‹¡å¼µ"
    },
    "type": "story",
    "url": "https://lofitab.com/",
    "score": 15,
    "by": "reynnan",
    "time": 1743275558,
    "content": "Lofi TabTransform your new tab into a productive and calming lofi experience with todos, weather, clock, and beautiful backgrounds.Add to Chrome Add to Edge Try without installing4.8 (20+ reviews)1,000+ usershttps://lofitab.com/try21:09SourceTodosAddAllActiveCompletedNo tasks to display\n\nFeaturesEverything you need to make your new tab productive and beautifulTodos âœï¸Keep track of your tasks directly from your new tab. Simple and effective todo management.AddAllActiveCompletedNo tasks to displayClock ğŸ•‘Always know the time with a customizable clock in either 12 or 24-hour format.21:09Weather ğŸŒ¤ï¸Get current weather information right on your new tab. No need to open another app.Lofi Backgrounds ğŸ–¼ï¸Choose from over 30 beautiful lofi backgrounds to customize your new tab experience.DynamicStaticLightweight âš¡Optimized for performance. Won't slow down your browser or consume excessive resources.Lightweight âš¡Lofi Tab800kb800kb - 95% smaller!Infinity New Tab5MBMomentum19MBLightweightMediumHeavy\n\nReady to transform your new tab?Add to Chrome Add to Edge",
    "summary": {
      "en": "Lofi Tab is a browser extension that enhances your new tab with a calming lofi theme. It includes features like:\n\n- **To-Do List**: Easily manage your tasks.\n- **Clock**: Displays time in 12 or 24-hour format.\n- **Weather**: Shows current weather updates.\n- **Beautiful Backgrounds**: Choose from over 30 lofi images.\n\nIt's designed to be lightweight, so it won't slow down your browser. The extension has a high rating and is used by over 1,000 people. You can try it without installing.",
      "ko": "Lofi Tabì€ ìƒˆë¡œìš´ íƒ­ì„ ì°¨ë¶„í•œ ë¡œíŒŒì´ í…Œë§ˆë¡œ ê¾¸ë©°ì£¼ëŠ” ë¸Œë¼ìš°ì € í™•ì¥ í”„ë¡œê·¸ë¨ì…ë‹ˆë‹¤. ì´ í™•ì¥ í”„ë¡œê·¸ë¨ì€ ì—¬ëŸ¬ ê°€ì§€ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤. \n\në¨¼ì €, í•  ì¼ ëª©ë¡ ê¸°ëŠ¥ì´ ìˆì–´ ì‰½ê²Œ ì‘ì—…ì„ ê´€ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, ì‹œê³„ ê¸°ëŠ¥ì´ í¬í•¨ë˜ì–´ ìˆì–´ 12ì‹œê°„ ë˜ëŠ” 24ì‹œê°„ í˜•ì‹ìœ¼ë¡œ ì‹œê°„ì„ í‘œì‹œí•©ë‹ˆë‹¤. í˜„ì¬ ë‚ ì”¨ë¥¼ ì•Œë ¤ì£¼ëŠ” ë‚ ì”¨ ê¸°ëŠ¥ë„ ì œê³µë˜ë©°, 30ê°œ ì´ìƒì˜ ì•„ë¦„ë‹¤ìš´ ë¡œíŒŒì´ ì´ë¯¸ì§€ë¥¼ ë°°ê²½ìœ¼ë¡œ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n\nì´ í™•ì¥ í”„ë¡œê·¸ë¨ì€ ê°€ë²¼ìš´ ì„¤ê³„ë¡œ ë˜ì–´ ìˆì–´ ë¸Œë¼ìš°ì € ì†ë„ë¥¼ ëŠë¦¬ê²Œ í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë†’ì€ í‰ê°€ë¥¼ ë°›ê³  ìˆìœ¼ë©°, 1,000ëª… ì´ìƒì˜ ì‚¬ìš©ìê°€ ìˆìŠµë‹ˆë‹¤. ì„¤ì¹˜ ì—†ì´ë„ ì‚¬ìš©í•´ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
      "ja": "Lofi Tabã¯ã€æ–°ã—ã„ã‚¿ãƒ–ã‚’è½ã¡ç€ã„ãŸãƒ­ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ†ãƒ¼ãƒã§å½©ã‚‹ãƒ–ãƒ©ã‚¦ã‚¶æ‹¡å¼µæ©Ÿèƒ½ã§ã™ã€‚ã“ã®æ‹¡å¼µæ©Ÿèƒ½ã«ã¯ã€ã„ãã¤ã‹ã®ä¾¿åˆ©ãªæ©Ÿèƒ½ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚ã¾ãšã€ã‚¿ã‚¹ã‚¯ã‚’ç°¡å˜ã«ç®¡ç†ã§ãã‚‹ã€ŒTo-Doãƒªã‚¹ãƒˆã€ãŒã‚ã‚Šã¾ã™ã€‚ã¾ãŸã€12æ™‚é–“ã¾ãŸã¯24æ™‚é–“å½¢å¼ã§æ™‚é–“ã‚’è¡¨ç¤ºã™ã‚‹ã€Œæ™‚è¨ˆã€æ©Ÿèƒ½ã‚‚æ­è¼‰ã•ã‚Œã¦ã„ã¾ã™ã€‚ã•ã‚‰ã«ã€ç¾åœ¨ã®å¤©æ°—ã‚’çŸ¥ã‚‰ã›ã‚‹ã€Œå¤©æ°—ã€æ©Ÿèƒ½ã‚„ã€30ç¨®é¡ä»¥ä¸Šã®ç¾ã—ã„ãƒ­ãƒ¼ãƒ•ã‚¡ã‚¤ç”»åƒã‹ã‚‰é¸ã¹ã‚‹ã€ŒèƒŒæ™¯ã€ã‚‚ç”¨æ„ã•ã‚Œã¦ã„ã¾ã™ã€‚\n\nLofi Tabã¯è»½é‡è¨­è¨ˆã«ãªã£ã¦ã„ã‚‹ãŸã‚ã€ãƒ–ãƒ©ã‚¦ã‚¶ã®å‹•ä½œã‚’é…ãã™ã‚‹ã“ã¨ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚ã“ã®æ‹¡å¼µæ©Ÿèƒ½ã¯é«˜è©•ä¾¡ã‚’å¾—ã¦ãŠã‚Šã€1,000äººä»¥ä¸Šã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«åˆ©ç”¨ã•ã‚Œã¦ã„ã¾ã™ã€‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã›ãšã«è©¦ã™ã“ã¨ã‚‚å¯èƒ½ã§ã™ã€‚"
    }
  },
  {
    "id": "ce575d67121969ff",
    "title": {
      "en": "Oracle Cloud Hacked Twice, Denied Thrice",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://www.reuters.com/technology/fbi-investigating-cyberattack-oracle-bloomberg-news-reports-2025-03-28/",
    "score": 30,
    "by": "dankotanko1599",
    "time": 1743288123,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "a78f47dfa65def19",
    "title": {
      "en": "Making of the New York and Erie Railroad Organizational Diagram",
      "ko": "ë‰´ìš• ì—ë¦¬ ì² ë„ ì¡°ì§ë„ ì œì‘",
      "ja": "ãƒ‹ãƒ¥ãƒ¼ãƒ¨ãƒ¼ã‚¯ãƒ»ã‚¨ãƒªãƒ¼é‰„é“å›³è§£"
    },
    "type": "story",
    "url": "https://www.c82.net/blog/?id=98",
    "score": 28,
    "by": "tobr",
    "time": 1743269548,
    "content": "Making of the New York and Erie Railroad organizational diagram\n\nBy Nicholas Rougeux, posted on March 29, 2025 in Art\n\n    Org charts tend to be a rather boring affairâ€”with their lists of names and who reports to whomâ€”but they didnâ€™t start out that way. One of the first in American business, is a stunning portrait of a classic institutionâ€”the New York and Erie Railroad. Drawn in 1855 and only rediscovered in recent decades, this diagram captured my attention and I finally took the time to recreate it from scratch as a fun technical exercise. What was unexpected was the depths I ended up going to in order to learn about its fascinating history.\n\nSource material\n\nUnlike my previous projects, the source one was not a lengthy book with hundreds of illustrations or scientific explanations, but a single image available at the Library of Congress.\n\n    Original New York and Erie Railroad diagram (top) and details (bottom). Source: Library of Congress\n\nThis sprawling diagram was designed by Daniel McCallum in 1855 shortly after he became general superintendent of the New York and Erie Railroad and drawn by Civil Engineer George Holt Henshaw. He created it as part of his efforts to improve accountability, operational efficiency, and lines of communications throughout the complex railroad system. Unfortunately, his insistence on enforcing rules he devised to govern all employees ultimately resulted in their resentment toward him, financial difficulties for the railroad as a whole, the first strike of railroad engineers in America, and his resignation. He was later appointed by President Lincoln to take charge of the United States Military Railroads due to his bridge and railroad expertise (Wrege et al., 2005). Despite its origins and the outcomes it precipitated, the diagram remains an impressive feat of design that up until just a few decades ago was relatively unknown.\nIn 1977, railroad and economic historian Alfred Chandler Jr. described the diagramâ€™s existence in his book, The Visible Hand: The Managerial Revolution in American Business by referencing other publications that covered it shortly after it was originally published. Among them was one of his own published in 1956 about his great grandfather, Henry Varnum Poor, editor of the American Railroad Journal during McCallumâ€™s tenure. In this book, Chandler described the diagram:\n\n    The design of the chart was a tree whose roots represented the president and the board of directors; the branches were the five operating divisions and the service departments, engine repairs, car bridge, telegraph, printing, and the treasurerâ€™s and secretaryâ€™s offices; while the leaves indicated the various local ticket, freight, and forwarding agents, subordinate superintendents, train crews, foreman, and so forth (Chandler, 1977, as cited in Wrege et al., 2005).\n\nChandler didnâ€™t include an image of the diagram in his book and it remained relatively unknown until 2005 when two researchers, Charles Wrege and Guideon Sorbo Jr. consulted with him for their article, A Bridge Builder Changes a Railroad: The Story of Daniel Craig McCallum in the 24th volume of Canal History and Technology Proceedings. In their article, they detailed Chandlerâ€™s descriptions of the diagram and included Poorâ€™s original description from the American Railroad Journal, in which he describes the diagram as â€œgot up in handsome styleâ€â€”a turn of phrase that I thoroughly enjoyed.\n\n    Image of Poorâ€™s article from the American Railroad Journal, 1865 (Wrege et al., 2005)\n\nWrege and Sorbo also described its resemblance to a tree, hypothesizing that the tree was chosen because of McCallumâ€™s history as a Freemason. However, they were disabused of this when a masonic representative stated, that\n\n    â€¦trees or horticultural metaphors-with the exception of the Acacia as a symbol of hope, rebirth or renewal-play no role in the teachings or rituals of Freemasonry. (Wrege et al., 2005).\n\nAfter much research, they proposed the idea that its organic design was based on the Salix caprea or goat willowâ€”a plant commonly found in the counties around the railroad. They support this notion by comparing drawings of the Salix capreaâ€™s stems and leaves to elements of the diagram and even overlaying a drawing of a Salix caprea directly on top of a mirrored version of the diagram, creating a rather messy, albeit apt comparison, noting:\n\n    The Salix capreaâ€™s fan-shaped appearance, rounded oval leaves, and specific shape of the branches compare favorably to similar elements of the Erie Plan.\n    â€¦one can readily see the close comparison of the distribution of the willow branches and leaves in the picture to the branches and leaves in the Erie Plan. The curvature of the branches and leaves in McCallumâ€™s design follows the typical weeping branches of the Salix caprea. The fact that railroad operations, while mechanized, require great flexibility on the part of the employee, also reinforces his use of the willow in symbolic form. Finally, in comparison to the narrow lanceolate leaves normally associated with willows, the oval leaves of the Salix caprea closely resemble McCallumâ€™s round leaves. (Wrege et al., 2005)\n\n    Salix caprea tree overlaid on a mirror image of the original diagram (left) and depictions of the planâ€™s various parts (right) (Wrege et al., 2005)\n\nWhile this sounded plausible, itâ€™s my amateur opinion that it was somewhat over-elegant because of its convenience. There are indeed similarities between the diagram and the Salix caprea but not enough evidence to draw a direct connection. I believe the diagram has an organic nature not because of a masonic history or connection to the local flora but because a tree-like branching diagram simply lends itself well to the hierarchical representation of the employees. Regardless, the diagram is a beautiful and functional artwork worthy of many kinds of analyses.\nA great piece of ephemera was included in Wrege and Sorboâ€™s article in the form of an advertisement for the diagram from July 14, 1856 that appeared in the American Railroad Journal stating that it could be purchased for $1 for thick map paper or $1.75 for it mounted on rollers (about $37â€“65 after inflation). The authors noted,\n\n    The number of copies of the Erie Plan sold is unknown. Considering the resignation of McCallum in 1857, and the failure of the Erie in 1857, the sales of a diagram of one of the greatest railroads in the world may have been disappointing, which may also be the reason for only one known copy existing today.\n\n    1856 advertisement for the original diagram (Wrege et al., 2005)\n\nViewing such a piece mounted on rollers would have been wonderful to see.\nIn 2013, their article was referenced in a sidebar of an article from McKinsey titled Big data in the age of the telegraph written by then Harvard-Newcomen postdoctoral fellow at the Harvard Business School, now Berkeley Associate Professor Caitlin Rosenthal. In it she discusses McCallumâ€™s diagram and its valuable lessons for leaders navigating large data landscapes. Some time between then and the writing of this post, it came across my radar and languished in the back of my mind ever since.\nWhen looking for a new project, I thought it would be something fun to explore, not knowing how much time I would spend researching its origins. The brief history above is only a portion of whatâ€™s available in the various publications I mentioned and all are worth a read. What follows is an account of my efforts to restore, recreate, and expand on the diagram using modern tools.\n\nTypography\n\nThe most appealing part of recreating the diagram was drawing the beautiful curved branches and watching the tree they represent come to life. However, before I could do that, I had to figure out if the building blocks that made it so interesting were even possibleâ€”chief among them, typography, which could be broken down into four parts: title, legend, labels, and credits.\n\n    Closeups of key typographical areas\n\nA wide variety of typographical styles were usedâ€”ranging from simple and geometric for labels, to ornate in the title. I knew finding the right modern equivalents was going to be a challenge but one I would enjoy. My research started by messaging the talented team at Fonts In Use, a wonderful site created to â€œdocument and examine graphic design with the goal of improving typographic literacy and appreciation.â€ I learned about in 2023 when they posted about the typography used on the newest Metra tickets I acquired. I asked if they could identify any of the typography in the diagram and they confirmed my suspicions that all lettering was engraved by hand and not based on specific fonts.\nI briefly entertained the idea of making my own fonts but I knew what went into designing one and wasnâ€™t ready to embark on such a lengthy journey for a few characters. Instead, I spent days sifting through the hundreds of fonts I collected over the years, libraries like Google Fonts and Adobe Fonts, and other font foundries to find ones that resembled those in the diagram as much as possible.\n\nTitle\n\nThe full text of the diagram is â€œNew York and Erie Railroad diagram representing a plan of organization: exhibiting the division of academic duties and showing the number and class of employÃ©s engaged in each department: from the returns of September 1855â€ and it comprised the most varied typographical collection with 11 fontsâ€”a different one each line and 2 used on the last. Some elegant filigree also decorated the main parts of the title.\n\n    Title of diagram comprising many styles of type\n\nFinding a modern equivalent for the first line, New York and Erie Railroad was a challenge because of its unique ornamental style. The three closest I could find were Hickory, Bruce Ornamented No. 881, and Dusty Circus Main. I chose the latter with some minor vertical stretching because it had roughly the same visual weight of the original. Normally, I loathe stretching a font but made some exceptions with this and a few other areas on the poster to meet space limitations.\n\n    The word Diagram deconstructed into its layers\n\nThe second line, Diagram, was written in old English style and while many fonts in that style are available, the three closest I could find were English Towne, Olde English, and Same Old English JNL. The title had the added feature of thin horizontal lines in the middle for shading and a kind of shadow on the upper right of each character. English Towne was the closest but didnâ€™t have the shading lines. To achieve these effects, I created four separate layers:\n\n    Outlined version of the original font with transparent middle parts\n    Duplicate of the second layer with a custom pattern of horizontal lines applied as a fill\n    Custom-drawn shapes as shadows\n\nRepresenting a Plan was another combination of several layers offset to give the appearance of text elevated off the background. The two closest fonts I found were Noto Serif and Libre Bodoniâ€”both freely available from Google Fonts. The thicker serifs on Noto Serif looked best.\nThe two smallest wordsâ€”of and andâ€”appeared to be the same style and the closest match I found was Bodoni Moda. I chose the bold italic style even though the original wasnâ€™t italicized to achieve the more decorative â€œfâ€ like the original.\nOrganization was another word written in an ornamental style and the two closest matches I could find were Rosewood and Alta Mesa Regular. Rosewood was too top heavy with shading and had shadows that were too deep while the latter was the closest match.\nLike with of and and, Bodoni Moda was also used for the text, Exhibiting the division of administrative duties, but with a little vertical stretching. Oranienbaum and Times NR Condensed were considered because of their condensed nature, but Bodoni Moda had more appropriate contrast between its horizontal and vertical strokes.\nTwo fonts immediately came to mind for the text, Showing the number and class of employÃ©s: DIN Condensed and Barlow Semi Condensed. Iâ€™ve had the DIN family installed for many years and often consider it for text in all caps due and used Barlow in a separate professional project in recent years. DIN Condensed had the closest fit.\nThe typography for Engaged in each department presented an interesting challenge because its text was italicized but leaning to the left, instead of the right, which is the norm. In my research, I learned this type of â€œreversed italicâ€ text is also called retalic text. It also looked like a form of script, which made finding a match extra challenging. Initially, I couldnâ€™t find any fonts that supported left-leaning text and I didnâ€™t want to manually skew the text because the results would look subpar at best, so I tried to find fonts with italic styles that matched the original diagram. The few I found were Imperial Script, MonteCarlo, Inglesa Variable, and Great Vibes, but none sat well with me. Fortunately, after digging through many fonts on Adobeâ€™s site, I found one a lone retalic style, Beverly Drive. By a stroke of luck, it was also a script that somewhat resembled the original diagram.\nThe penultimate line of text, from the returns of, was a thin slab serif and of the three closest I foundâ€”Halant, Glegoo, and Novecento Slabâ€”Glegoo was the closest at the small scale and had consistent width along all strokes.\nFinally, the date at the bottom, September 1855, was written in two stylesâ€”old English the month and another serifed one for the year. The three I considered for the month were English Towne (again), LTC Goudy Text Pro, and Amador, with the latter being used because it was a bit more legible, despite the tall x-height of the lowercase letters. Bodoni Moda was used once again for the year.\n\n    Recreated filigree with visible anchors\n\nAs a finishing touch, I reproduced the filigree decorating the first five lines of the title using simple curves with varying stroke widths. Most anchors were placed along horizontal and vertical tangent lines to ensure they were as smooth and clean as possibleâ€”a common technique and one I employed two years prior when recreating the title for The Color Printer. At the bottom below the title is a very tiny bit of filigree that was very rough in the original but I did my best to clean up what I thought was the original intent.\n\nThe final title was a fairly close replica and with the spirit of the original.\n\n    Recreated title\n\nLegend\n\nThe legend, or â€œexplanationsâ€ as it was labeled, filled in the large area in the lower right of the diagram and contained a brief explanation of McCallumâ€™s rules, an overview of the symbols sprinkled throughout, and a table of â€œemployÃ©sâ€ in different classes throughout the railroad.\n\n    Original legend\n\nA wealth of information was packed into that area, dominated by wide italicized handwriting that looked like a combination of print and script. The handwriting was used primarily in the explanation and interspersed with geometric print in the table of employees. The handwriting was a great style that didnâ€™t have a good modern parallel, or so I thought. I searched for typefaces that resembled nineteenth century text and found Madisonian but it felt too formal. I broadened my search to those with more stylistic italics like Magister, Libre Bodoni, and Bodoni Moda, but none felt quite right.\nThen I found Geographica and its italic style was nearly perfect. According to its description, it was â€œinspired by the neat, hand-lettered text on the 1700s maps of Thomas Jefferys, Geographer to King George IIIâ€ and had a style nearly identical to the text in the legend. Its x-height was taller than the original and was a little more spacious but these were fine compromises for my needs. As a bonus, it had a style of superscript with dots underneath for the few spots in the lower right portion of the table that needed them.\nThe headings for Explanations and Symbols were set in Scotch Modern, which was also used for station labels along the the five branches of the main diagram. Explanations was stretched and spaced out a bit.\nFor the geometric sans serif text used for the symbol labels and in the table, I considered using DIN or Barlow again and used the former for the table title, but their condensed styles were too narrow and their regular styles were too wide for text in the table. At smaller sizes, I couldnâ€™t find a weight that worked well. The legendâ€”as well as many of the labels in the main diagramâ€”also included many superscript letters with a dot underneathâ€”a style I fell in love with over the course of the project. The following section has more detail about reproducing them and how theyâ€™re used in the personnel labels. I found that Interstate set in bold worked great for text at tiny sizes, wasnâ€™t too wide or narrow, and the superscript size matched the original nicely.\nOnce again, Geographic was a great fit for the old style numbers for the number of personnel in each class and at each station.\n\n    Recreated legend\n\nLabels\n\nThe main diagram contained three types of labels: personnel, stations, and the distances between those stations. These labels are the heart of what gives the diagram its vintage identity when exploring up close.\n\n    Closeup of various labels at the Dunkirk station\n\nPersonnel labels were by far the most prevalent and written in uppercase with varying methods of abbreviating using superscript. Many also wound around groups of personnel, which added to the organic tree-like feel of the diagram. Like with the labels in the legend table, I used Interstate for each oneâ€”drawing the curves for the text to follow as close as possible to the original. Recreating the dots below the superscript letters proved to be more troublesome than I thought. I hoped I could use the dot diacritic but Interstate did not support it. I also tried using extreme negative tracking but could never get the dots to line up perfectly under their corresponding letters. Ultimately, I settled on using two layers for each label that required dotsâ€”one with the text and another just for dotsâ€”both aligned to the same curve.\n\n    Screenshot showing layers of the Susquhanna Division label flowing along a curve in Illustrator\n\n    Unusual labels with superscript characters and dots under them\n\nThis technique resulted in more tedious work but allowed me the flexibility to position them just the way I wanted by using spaces and tracking setting, especially when just one dot was occasionally used for two letters. Superscript letters were used more liberally in some areas than others, resulting in some very interesting-looking labels.\nThe labels for leadership positions (treasurer, land agent, auditor, etc.) and the different divisions emanating from the general superintendent role in the center were also set in Interstate. Some groups of personnel included numbers after the text that appeared to be in a different style and I started by setting my numbers in Bodoni Moda to match but they felt disjointed so I kept them in Interstate to feel more cohesive.\nThe label for the board of directors unlike all the others, which was appropriate because all the visual elements for them were unique. It sat in the curved space between the arrows connecting the 16 circles with inset stars to the president, alternating between or two letters between most arrows. It was also set in Bodoni Moda but with the same shading treatment as the word Diagram from the title.\n\n    Screenshot showing layers of the board of directors label in Illustrator\n\nAs previously mentioned, Scotch Modern was used for station names with varying degrees of stretching depending on space restrictions. Whenever space allowed, I tried to keep them the same style for consistency. Names of smaller stations are written in title case rather than uppercase. Between each pair of stations was a small number representing the miles between them. They varied in style and size more than I expected and except for a few tight areas, I made sure they were styled consistently with Glegoo.\n\n    Closeup of station and distance labels\n\nCredits\n\nAt the bottom of the diagram nestled between the board of directors, title, and legend were two sets of stylized credits for the diagramâ€™s creators: Daniel McCallum, the railroadâ€™s general superintendent and George Holt Henshaw, a civil engineer and draftsman.\n\n    Original credits\n\nThey each follow the same typographical usage:\n\n    Activity (Designed or Compiled and Drawn) set in Interstate bold\n    by set in Geographica regular\n    Job title set in Glegoo\n\nI also took the liberty of adding my own credit in the available space at the lower left of the title as a stamp of my authorship in restoring and recreating the diagram. This area was missing in the scan on the Library of Congressâ€™ site and without any indication that something was there originally, I felt that including my credit was acceptable.\n\n    Recreated credits including my own (right)\n\nIconography\n\nSprinkled along the straight lines representing the five major lines are four symbols representing the services or amenities at each station: a locomotive for machine shops, tools for repair shops, eating utensils for eateries or saloons, and a telegraph pole for telegraph capabilities.\n\n    Original symbols\n\nAs I worked my way through the diagram, I noticed that the locomotives were similar to each other but no two were the same. Six were drawn in total: one in the legend, which was the most detailed and five rougher versions at major stations or termina in the diagram. My naÃ¯ve idea of tracing one of them as an exact copy was significantly underwhelming. Attempts to automatically convert them to vector drawings in Illustrator were even more so. I searched through The Noun Project and Adobe Stock for better versionsâ€”trying to find a balance between hand-drawn and high-fidelity that would work at small sizes. After much trial and error, I settled on one from a set of old train icons that resembled the detailed one from the legend. As a bonus, a dark version was also available for the dark style of posters I planned to make.\n\n    Original locomotive symbols\n\n    Tests for new locomotive symbols\n\nThe symbols for saloons and repair shops were very rough due to their small size and I wanted to match the more polished nature of the locomotive symbol so I exercised some creative freedom and used icons from Adobe Stock with some modifications. The symbol for repair shops was a little cryptic, with what looks like a wrench and some other straight tool. I later learned as part of my extended research that it was intended to be a hammer (Wrege, et al., 2005). I chose a more standard-looking hammer and wrench. The most straightforward of these to recreate was the telegraph pole as it was a simple arrangement of lines with a dot on the top.\n\n    Original and new icons for saloons (top left), repair shops (top right), and telegraph stations (bottom)\n\nDiagram\n\nThe main diagram was created in several stages, starting at the bottom with the board of directors, working my way up through leadership in the center, then drawing each main branch, starting on the left side and moving clockwise to the right. I worked this way so I had an easier time keeping track of what I had done but this had the unexpected benefit of easing me into the more complicated areas in the middle instead of starting with them right away.\n\nLeadership\n\n    â€œBurstâ€ surrounding the board of directors comprising 1,582 hand drawn lines in progress (top) and final (bottom)\n\nThe first part I drew was what I referred to as the â€œburst,â€ or the lines that resembled rays of light surrounding the board of directors. In a futile attempt to create them efficiently, I tried to create evenly-spaced lines emanating from a central point and clipping paths for the jagged edges and cutouts but the results started to look too polished and the charm was lost. Instead, I bit the bullet and drew each of the 1,582 lines by hand to ensure an exact replica.\n\n    Comparison of the circles and arrows for the board of directors. Red shapes are spaced evenly and blue shapes are manually adjusted to match the original.\n\nThe stars representing the board of directors and arrows connecting them to the president looked like they were evenly spaced distributed around him but they werenâ€™t, so after starting with them as such, I manually shifted them to align them with the original. I also created a custom lined pattern for the shading in the circles that world be used for all others. This pattern is a simple set of tightly-spaced lines but always at a 45 degree angle.\n\n    The two areas of leadership\n\nThe larger circles for the president and general superintendent were the only two with layered stars. The 6 circles connected to the president representing others in charge of business affairs and 18 representing smaller divisions had decorative ribbons and labels on them. Again, these looked evenly-spaced but needed a manual touch to align them properly.\n\nPersonnel\n\nI developed a sequence of steps for drawing each branch so I could keep track of what I had done as I stopped and started over the weeks needed to complete them. Using the Western line as an example, these were the steps:\n\n    Portion of the â€œtrunksâ€ for the Western branch\n\nFirst, trace the â€œtrunks,â€ which were the winding and straight double lines connected to the division head. The winding trunks comprised thin and thick lines drawn with the paintbrush as closely as possible to the original with minimal smoothing, giving them a bit of dimension. The straight ones were double lines representing the five main train lines and the distances between stations.\n\n    Portion of the dots for the Western branch\n\nWith the trunks in place, I added the small rectangles for stations (when necessary) and the many circles for personnel, which I referred to simply as â€œdots.â€ There were two main sizes is these dotsâ€”the larger, indicating supervisors, and smaller for the lowest level of personnel. To ensure I didnâ€™t miss any, I always placed the dots in a clockwise order. A subset of the dots had small protrusions pointing in various directions indicating flagmen or switchmen.\n\n    Portion of curved branches for the Western branch\n\nNext were the thin curved branches connecting all the dots and the trunk. I enjoyed this the most even though it was the most tedious. With Illustratorâ€™s fidelity option turned up for the paintbrush tool, I was able to draw the best curves without worrying about precision. This was a lot faster than drawing with the pen tool and messing with bezier curves manually. Thicker versions of these branches were used for areas with many dots.\n\n    Extreme closeup of the branches for the clerks reporting to the auditor before polishing (red) and after (blue) overlaid on top of each other to highlight the subtle differences\n\nHowever, the positions of the endpoints needed polishing to line up perfectly, so after I drew them, I made a second pass to move each endpoint so it intersected precisely with a dot or connecting branch to ensure a smooth look. Again, I methodically drew each branch in a clockwise order and adjusted their endpoints on a second pass in the same order. These branches took the longest to create compared to all other parts of the restoration but the result was worth the effort.\n\n    Portion of labels for the Western branch\n\nFinally, I placed the labels and iconography, starting with station names along the straight trunks, followed by the distances between them, and ending with their services/amenities. Nearly every label for personnel groups was set along a curved line and no two were the same so each curve was manually adjusted to be as close to the original as possible. The text size varied a little in the original but I maintained a consistent size in my version consistently except for a few of the larger groups which warranted larger labels. I also took the liberty of correcting a few typos and personnel counts but the original had very few errors.\nThis process was completed for each major division. Below is a set of images showing the order in which each part was completed. Drag the slider to step through the various stages.\n\n        /* Making of collage */\n        .making { margin: 0 auto 1rem; text-align: center; }\n        #making-image { border: 1px solid #ddd; display: block; height: 80vh; margin: 0 auto 1rem; }\n\n        #making-slider {\n            -webkit-appearance: none;\n            background: var(--bg);\n            display: block;\n            margin: 0 auto 1em;\n            width: 50%;\n        }\n\n        #making-slider::-moz-range-thumb { background: #000; border-radius: 100%; height: 1rem; width: 1rem; }\n        #making-slider::-webkit-slider-thumb { -webkit-appearance: none; background: #000; border-radius: 100%; height: 1rem; margin-top: -10px; width: 1rem; }\n\n        #making-slider::-moz-range-track { background: rgba(0, 0, 0, 0.5); cursor: pointer; height: 2px; width: 100%; }\n        #making-slider::-webkit-slider-runnable-track { background: rgba(0, 0, 0, 0.5); cursor: pointer; height: 2px; width: 100%; }\n\n        $(document).on(\"input change\", \"#making-slider\", function() {\n            var v = $(this).val();\n            $(\"#making-image\").prop(\"src\", \"/images/blog/nyer-steps-\" + v + \".jpg\");\n        });\n\n        Drag slider to see the progress from start to finish.\n\nIn hindsight, creating the title and legend first, followed by the leadership areas was a wise choice because I was able to iron out many of the nuances and workflows before embarking on the long repetitive task of drawing all the branches. Keeping my file well organized and approaching it methodically meant I rarely had to redo anything and making mass adjustments was relatively simple.\n\nAt this point, the diagram was complete but I wasnâ€™t.\n\nColors\n\nAs with most my projects, I wanted to add my own spin on it and for this one, I chose to create new colorized versions. While recreating the diagram, I periodically experimented with different palettes on a small subset of representative shapes, starting with generic palettes I found on Pinterest inspired by the victorian era and a vintage map.\n\n    First few color schemes based on generic palettes from Pinterest (top and middle) and the proposed route map from 1834 (bottom)\n\nThese were fine but nothing special. They illustrated a key change I wanted to make, which was replacing the thin lines shading each circle with flat colors. I loved the shading lines from the original but wanted to make variations that were a more modern while still paying homage to the original. In an effort to give the colors more meaning, I discovered a map of the proposed route of the New York and Erie Railroad from 1834. This beautiful map of southern New York counties had a great set of colors but when applied to the small sample, they didnâ€™t have enough contrast for the wide variety of elements I wanted to color.\n\n    Advertisements for Erie Railway from 1874 in original colors (top) and restored (bottom)\n\nAfter some more digging through railway ephemera, I found a wonderful advertisement for the Erie Railway from 1874, promoting the stops along its route by way of named locomotives and train cars. The Amon Carter Museum of American Art has an original and I found a restored version on Etsy. The second I saw the latter, I knew it would be the perfect source of a palette. The bold red in the title and on the equipment worked so well with the bright yellow and subdued green for the landscape. My initial pass at a color palette used a few too many colors but I liked the general direction.\n\n    Closeup of branches and leaves on the light poster\n\nWhile experimenting with colors, I settled on the idea of using them to differentiate between structure and people. Most importantly, since the diagram had such a strong resemblance of a tree, I wanted to use shades of green for the people as leaves. A different shade of green was used for supervisors so their presence is more noticeable. The winding branches connecting them were colored brown. The tiny protrusions for flagmen and switchmen are a bright yellow as a nod to their job of keeping everyone safe and running smoothly along the tracks. Straight lines representing the physical lines and stations along them use shades of bright red. The colors of top leadership circle vary from shades of green to highlight their different roles: light blue for the primary leadership roles of president and general superintendent to which many others report and bright red for the board of directors that govern the activities.\n\n    Closeup of symbols on the dark poster\n\nColors from the Erie Railroad advertisement were also used for the other symbols representing station services and amenities. As an added bonus, I also created dark versions of the diagramâ€”one in black and white and another in full color. The addition of these rounded out the set of posters nicely and Iâ€™m thrilled with the final results. Seeing them in person and exploring all the details is quite fun.\n\n    Final posters in light and dark themes with closeups\n\nOrder posters\n\nMissing piece\n\n    Closeup of the missing part at the top center\n\nKeen-eyed readers may have noticed that my recreation differs from the original in a small but important way: the missing piece at the top center. The missing piece cut off the farthest part of the Susquehanna line and a few of the foremen and laborer dots from the Delaware line. In all my research this small part is only referenced once as a note on the Library of Congressâ€™ site as â€œmissing sections along the margins.â€\nThe lack of information nagged at me throughout the project and I spent weeks combing through maps, old books, and library records hoping to find a shred of information about what was once depicted there. I sent dozens of emails to anyone who might have had any information about it. I was only able to piece together part part of it. For the rest, I made educated guesses, calculated estimates, and exercised a little creative license.\nFirst, I listed the few things that had to be true given what was visible around it:\n\n    After Crosbyville, another station was 4.92 miles away.\n    A station past Crosbyville had a relatively long name ending in â€œLLE.â€\n    There wasnâ€™t enough room to have more than one or two stations beyond Crosbyville.\n\nMy first stop was Google maps to see what was 4.92 miles away from Crosbyville in New York by using its measure feature and drawing along existing rail lines. Canisteo was the only town and according to their Wikipedia page, they were indeed part of the Erie Railroad. Since Henshaw drew the stations at mostly accurate distances from each other, placing a station at 4.92 miles away from Crosbyville (now Adrian) left room for one more station to be named next to the â€œLLEâ€ that was above it.\n\n    Screenshots from Google maps showing distance between Adrian (formerly Crosbyville) and Canisteo (top) as well as between Canisteo and Hornell (bottom)\n\nFollowing the train line on Google Maps, the next town was Hornell, which was an appropriate distance away to line up with the visible â€œLLEâ€ text but â€œHornellâ€ was a much shorter name and didnâ€™t fit. Digging into the history of Hornell, I found a page on the Allegany County Historical Societyâ€™s site titled â€œErie Railroadâ€ and a line of text confirming that the station used to be named Hornellsville (emphasis mine):\n\n    The Susquehanna Divisionâ€™s portion of that mileage began at SR Tower, just west of Susquehanna station and ended just west of the Hornell station, no longer Hornellsvilleâ€¦\n\nThe City of Hornellâ€™s Wikipedia page also confirmed that it was surrounded by the Town of Hornellsville so that answered the question of the station ending in â€œLLE.â€ The next challenge was to determine the exact distance of the station from Canisteo. The first line of the diagramâ€™s explanation mentions that it was â€œcompiled from the September Reportsâ€ and as luck would have it, I found a publication on Google Books titled, Reports of the President and Superintendent of the New York and Erie Railroad to the Stockholders for the Year Ending September 30, 1855, which later research confirmed was the one mentioned. It contained, among other operational and financial details, the distances between stations in table Z on page 180, which listed Hornellsville as 4.21 miles from Canisteo.\n\n    Page 180 from an 1855 report with distance between Hornellsville and Canisteo highlighted\n\nHornellsville is also listed two more times on the diagram near the division heads for the Western and Buffalo lines. Both of those indicated that it had a telegraph station, saloon, and a repair shop. However, they both showed different amounts of employeesâ€”the one on the Western division with significantly more.\n\n    Close up of the other two  places Hornellsville is mentioned in the diagram\n\nGiven the number of services available at Hornellsville and the fact that they were represented as rectangles in the other area of the diagram, using a rectangle was a safe assumption. Half a small circle is visible at the bottom of the missing area, which is just about the same distance away from where a station and its agent would be for Canisteo when compared to others. Therefore, I added a rectangle for Canisteo, a larger circle, and the other half of the smaller one. I was pleased with my detective work.\n\n    Hornellsville and Canisteo stations filling in missing piece\n\nHowever, this was the end of what I could definitively determine based on existing information. I could not find any information on the number of employees at each station beyond a casual mention of a foreman, division inspectors, subordinates and a station agent in the 1855 report (see pages 38â€“43). This was useful information but not as reliable as a roster or a larger report about personnel.\nBelow are my other attempts to track down this information:\nI found a restored version of the diagram for sale on Etsy and reached out to the seller who told me that he consulted period maps and conducted his own research, later adding that he used the help of AI to reconstruct it.\nI contacted the Hornell Public Library asking for any information about Erie Railroad employees around 1855 and they quickly responded saying that while they had some information on the history of railroads, I should contact the Hornell Erie Depot Museum. At first, I considered myself extremely fortunate that there just happened to be a museum dedicated to the Erie Railroad in the very town for which I needed information. Unfortunately, despite repeated emails, phone calls, voicemails, and outreach on their Facebook page, I could not get in touch with a single person either at the museum or city hall, whose phone number was the one associated with the museum. I was surprised that ended up as a dead end because I thought if anyone would know anything about my question, they would. I plan to continue trying to get in touch with them.\nI broadened my search to the state level and chatted with a librarian from the New York Public Library (NYPL) who recommended I contact their Irma and Paul Milstein Division, which specializes in United States history, local history and genealogy. After doing so, they found four reports spanning 1833 to 1869 covering details about the railroadâ€™s operations. They werenâ€™t available remotely through their site but most were online at HathiTrust. After sifting through hundreds of pages, I couldnâ€™t find any new information. They also provided links to Archive Grid for archival collections in other institutions, New York State Archives (NYSA), and the Library of Congress for the bulk of the New York and Erie Railroad materials. Additionally, they found the same McKinsey article by Rosenthal that I referenced at the beginning of this post and specifically called out the footnote in the aside referencing the article by Wrege and Sorbo. Finally, they recommended contacting the National Canal Museum (NCM) and the Railway and Locomotive Historical Society (RLHS). They were truly a font of knowledge and gave me a lot of avenues to explore. Iâ€™m very grateful for their assistance.\nBetween sending my request to the NYPL and receiving their helpful response, I contacted the Steuben Historical Society (Hornell is in Steuben County) and piqued the interest of their director but he said they didnâ€™t have â€œsuch a thing in any comprehensive form.â€ He did say he would check with sources he knew about local history and would get back to me. I havenâ€™t heard back at the time of this writing.\nHeeding the advice of the NYPL, I contacted the NYSA, RLHS, and NCM. The NYSA referred me to a search on the New York State Libraryâ€™s catalog for reports and maps relating to the railroad. The membership secretary at RLHS commented that I was having a hard time because â€œno large railroads kept central records of all their workers.â€ I received no response from NCM. The New York State Library stated that they didnâ€™t have much information around railroad history and suggested I contact the Williamsburg Depot, the Railroad Museum of the Niagara Frontier, or their Manuscripts and Special Collections Unit but didnâ€™t sound hopeful that they would produce helpful results.\nThe mention of Wrege and Sorboâ€™s 2005 article in Rosenthalâ€™s footnote piqued my interest because it sounded like a fruitful avenue for finding information about the missing piece but also about the general history of the diagram and I was right. It reshaped my entire view of it but more on that later. With my interest elevated, I sought about finding their original article, which presented its own challenges. The NYPL mentioned that it was published in the 24th volume of the Canal History and Technology Proceedings. In trying to find that specific volume, I found records for nearly all other volumes on various sites but never the 24th. None of the the records I found for the other volumes were available for viewing online but at least there were records.\nThe lack of a response from the NCM is especially unfortunate because in a page on their site describing the annual symposium for which the proceedings were published, they stated,\n\n    All of the Symposium papers are available in PDF form from the Archives of the National Canal Museum/Delaware & Lehigh National Heritage Corridor.  Limited numbers of some complete volumes of the Proceedings are also available at $5 per copy by ordering through www.delawareandlehigh.org.\n\nHowever, there was no record of the papers for purchase on the site mentionedâ€”another dead end.\nFeeling rather defeated, I started writing this blog post and after a few pages, decided to try once again to find the now-fabled 24th volume and had another stroke of luck when I found a single record buried on the Penn State Universities Libraries site labeled as, Canal history and technology proceedings: volume XXIV March 19, 2005 / editor, Lance E. Metz. To say I was elated would be an understatement. This is the only record of that volume I found. After I chatted with one of their librarians about getting a copy of the article and they said I could request it as an interlibrary loan through my local library. I quickly did so and received a 38-page PDF of it a few days later after paying a minor $15 fee. I also was able to get the original book from which the article was scanned to see if there was any improvement in the image quality and after another few days and an additional $15 fee, I confirmed that they werenâ€™t any different in the book.\n\n    Pages from A Bridge Builder Changes a Railroad: The Story of Daniel Craig McCallum\n\nAfter becoming somewhat obsessed with this diagram, this article was a gold mine. The depth of research Wrege and Sorbo did to learn about its history was a joy to read. Ironically, thereâ€™s no mention of the missing part of the scan on the Library of Congressâ€™ site, which was a minor disappointment, but the knowledge I gained more than made up for that. Much of the introduction of this blog post was informed by its contents. The article was published in 2005 and therefore still under copyright so it cannot be freely posted here but I will send it to anyone interestedâ€”just contact me.\nSince I could find no other mention of the missing piece, I decided to start making educated guesses, estimates, and exercised some creative license to fill in the last piece of the puzzle: the employees. Circling back to square one, I started with the numbers in the legend, which stated that for the Susquehanna line, there were the following employees at the stations:\n\n    21 agents\n    15 clerks\n    55 warehousemen, watchmen, porters, etc.\n    22 switchmen and flagmen\n    2 train dispatchers\n    2 engine dispatchers\n    35 engine wipers\n\n    Original legend with Susquehanna personnel at stations highlighted\n\nIn counting the circles along the Susquehanna line, I found:\n\n    20 larger circles, probably indicating agents\n    1 labeled clerks connected to the general superintendent\n    No warehousemen, watchmen, or porters labeled\n    22 labeled switchmen and flagmen\n    No labeled train dispatchers\n    1 labeled engine dispatcher\n    26 labeled engine wipers\n    67 unlabeled small dots\n\nThe only number that lined up with the legend was for the switchmen and flagmen. However, this made some sense considering the first sentence of the explanation above the table states (emphasis mine):\n\n    This Diagram compiled from the September Reports, indicates about the average number of employeÃ©s of each class engaged in the Operating Department of the Roadâ€¦\n\nEven the September report which I found earlier doesnâ€™t have any definite numbers for the employees along each line. So if the numbers shown were averages and no other source had information, I made some estimates:\nCanisteo appeared to be a smaller town than Hornell but larger than Crosbyville so I decided to make its station a rectangle. Most stations represented as rectangles had a larger dot representing a station agent and a smaller one so created the same for Canisteo.\nHornellsville was represented two other times on the diagramâ€”once for the Western line and again for the Buffalo line. This made sense, considering Hornellsville was a fork to two destinations: Dunkirk and Buffalo according to an 1855 map on the Library of Congress. The Western line showed an engineer dispatcher with 10 wipers reporting to them and a large circle representing a supervisor with 19 employees reporting to themâ€”4 of which were flagmen or switchmen. The Buffalo line had fewer employees with two unlabeled small circles and one switchman of flagman because it was only a projection (Wrege, et al., 2005). Looking at all the other representations of engineer dispatchers throughout the diagram, they had an average of nine wipers reporting to them so I put one engineer dispatcher and nine wipers at Hornellsville on the Susquehanna line. A simple average of the four switchmen or flagmen on the Western line and the one on the Buffalo line produced three so I added three switchmen or flagmen to it as well. Finally, I added three unlabeled dots for an extra few personnel. Labels and connecting branches were drawn in the style of the rest of the diagram.\n\n    My reconstructed version of the missing piece based on estimations and best guesses.\n\nThis method of determining employees was rough but I didnâ€™t want to leave the spot empty or partially filled so this process felt appropriate given the limited information available. Port Jervis and Susquehanna are the other two examples of the same place shown in the diagram more than once with different personnel at each so this display was not without precedent.\nThe story almost ended hereâ€¦\nIn fact, I wrote most of this blog post assuming I had chased down all the leads and wasnâ€™t going to get any more information. That is, until I thought to email Caitlin Rosenthalâ€”the author of the McKinsey which sparked this entire endeavour. In her article, she mentioned that she located a second copy at St. Lawrence University in upstate New York. In all my research, I only came across variations of the scan at the Library of Congress. Even the file page on Wikipedia for the diagram and all pages referencing it donâ€™t include a mention of another copy. I asked her if she remembered anything about it and while she didnâ€™t, but she did point me to a listing of maps in the special collections department at the universityâ€™s Owen D. Young Library where the diagram was listed (fourth line from the bottom of the second page). That prompted me to leave voicemails and send emails to the team there asking if they knew about it and if they could send me a picture.\nTo my surprise, they sent me back two pictures of their copyâ€”beautifully intact and one of them contained the very piece I spent weeks trying to track down.\n\n    Top, bottom, and closeup of the second copy of McCallumâ€™s diagram held at the special collections department of the St. Lawrence Universityâ€™s Owen D. Young Library\n\nTo say I was excited would have been a great understatement. I was over-the-moon thrilled that I tracked down not only a second original copy, but that it also had the missing piece and I was able to get pictures of it so I could complete my restored diagram. To my knowledge, these pictures are the first to be shared online of this second copy. I acknowledge that could have saved myself a lot of work by emailing Caitlin in the first place but I wouldnâ€™t have learned as much as I did or developed an appreciation for the diagram and its history if I hadnâ€™t tracked down the original article and done all the extra research. The journey was the best part of this project.\n\n    My restored final version of the missing piece\n\nI was also pleasantly surprised to see that my reconstruction wasnâ€™t that far off base from the original. I correctly figured out the station names, distance between them, types of stations, and the fact that Hornellsville had an engine dispatcher with the nine wipers.\n\nFinal thoughts\n\nI adored working on this project. It was small, relaxing, surprisingly interesting, and had an incredibly satisfying ending. The posters only took a few weeks to create and I explored a lot of great typography in the process. The deep dive into its history was unexpectedly exhilarating. I spent more than twice the amount of time researching it than creating the posters and I learned more than I ever imagined. Finally filling in the missing piece felt like something out of a movie. Writing this blog post was a joy because I loved to piecing together all my research to share with others.\nI appreciate my friends and family enduring my rambling about my latest discoveries. My sincerest thanks goes out to the librarians who helped me with research and pointed me in new directions I would have otherwise never discovered. Librarians are truly the unsung heroes of many research projects.\nMy hope is that by publishing this blog post and offering my posters for sale is that I introduce this fascinating little slice of American history to others and fill in a very minor but long-standing gap for others doing research in the future.\n\nSee the final posters\n\nReferences\n\n    Chandler Jr., A. (1977). The Visible Hand: The Managerial Revolution in American Business.\n    Wrege, C., & Sorbo Jr., G. (2005). A Bridge Builder Changes a Railroad: The Story of Daniel Craig McCallum. Canal History and Technology Proceedings, XXIV, 183â€“218.\n\nÂ« Back to blog",
    "summary": {
      "en": "Nicholas Rougeux's article discusses his recreation of the historic organizational diagram of the New York and Erie Railroad, originally crafted in 1855 by Daniel McCallum. This diagram, once overlooked, is notable for its intricate design and historical significance. McCallum created it to enhance accountability and communication within the railroad, but his strict management style led to employee resentment and even the first strike of railroad engineers in America.\n\nRougeux explains that he started with a single image from the Library of Congress and delved into research to understand the diagram's background. He found that its tree-like structure symbolized the hierarchy of the railroad's operations and employees. Despite initial theories linking the design to Masonic symbols or local flora, Rougeux believes the tree shape was simply effective for visualizing organizational structure.\n\nThroughout the project, Rougeux focused on typography, painstakingly matching modern fonts to the original styles used in the diagram. He also recreated the legend and various labels, ensuring they maintained the vintage identity of the original.\n\nTo add a personal touch, Rougeux experimented with color schemes, ultimately deciding to use shades of green for personnel to reflect their resemblance to leaves, while using browns and reds for the structure of the diagram.\n\nA significant part of his journey involved tracking down a second original copy of the diagram at St. Lawrence University, which contained a missing section he had previously reconstructed based on estimates. This discovery completed his restoration project.\n\nRougeux expresses his enjoyment of the process, emphasizing the satisfaction gained from both the creative and research aspects. He hopes to share this piece of American history through his recreated posters and inspire others to explore its background.",
      "ko": "ë‹ˆì½œë¼ìŠ¤ ë£¨ì£¼ì˜ ê¸°ì‚¬ëŠ” 1855ë…„ ë‹¤ë‹ˆì—˜ ë§¥ì»¬ëŸ¼ì´ ì œì‘í•œ ë‰´ìš•ê³¼ ì—ë¦¬ ì² ë„ì˜ ì—­ì‚¬ì ì¸ ì¡°ì§ë„ë¥¼ ì¬í˜„í•œ ê³¼ì •ì„ ë‹¤ë£¹ë‹ˆë‹¤. ì´ ë„í‘œëŠ” í•œë•Œ ê°„ê³¼ë˜ì—ˆì§€ë§Œ, ë³µì¡í•œ ë””ìì¸ê³¼ ì—­ì‚¬ì  ì¤‘ìš”ì„±ìœ¼ë¡œ ì£¼ëª©ë°›ê³  ìˆìŠµë‹ˆë‹¤. ë§¥ì»¬ëŸ¼ì€ ì² ë„ ë‚´ì—ì„œ ì±…ì„ê°ê³¼ ì†Œí†µì„ ê°•í™”í•˜ê¸° ìœ„í•´ ì´ ë„í‘œë¥¼ ë§Œë“¤ì—ˆì§€ë§Œ, ê·¸ì˜ ì—„ê²©í•œ ê´€ë¦¬ ìŠ¤íƒ€ì¼ì€ ì§ì›ë“¤ì˜ ë°˜ê°ì„ ë¶ˆëŸ¬ì¼ìœ¼ì¼°ê³ , ê²°êµ­ ë¯¸êµ­ ì² ë„ ì—”ì§€ë‹ˆì–´ë“¤ì˜ ì²« íŒŒì—…ìœ¼ë¡œ ì´ì–´ì¡ŒìŠµë‹ˆë‹¤.\n\në£¨ì£¼ëŠ” ì˜íšŒ ë„ì„œê´€ì—ì„œ ë‹¨ í•˜ë‚˜ì˜ ì´ë¯¸ì§€ë¥¼ ì‹œì‘ìœ¼ë¡œ ì´ ë„í‘œì˜ ë°°ê²½ì„ ì´í•´í•˜ê¸° ìœ„í•œ ì—°êµ¬ì— ë“¤ì–´ê°”ìŠµë‹ˆë‹¤. ê·¸ëŠ” ì´ ë„í‘œì˜ ë‚˜ë¬´ ëª¨ì–‘ êµ¬ì¡°ê°€ ì² ë„ì˜ ìš´ì˜ê³¼ ì§ì›ë“¤ ê°„ì˜ ê³„ì¸µì„ ìƒì§•í•œë‹¤ê³  ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ì´ˆê¸° ì´ë¡ ë“¤ì€ ì´ ë””ìì¸ì´ í”„ë¦¬ë©”ì´ìŠ¨ ê¸°í˜¸ë‚˜ ì§€ì—­ ì‹ë¬¼ê³¼ ê´€ë ¨ì´ ìˆë‹¤ê³  ì£¼ì¥í–ˆì§€ë§Œ, ë£¨ì£¼ëŠ” ë‚˜ë¬´ í˜•íƒœê°€ ì¡°ì§ êµ¬ì¡°ë¥¼ ì‹œê°ì ìœ¼ë¡œ í‘œí˜„í•˜ëŠ” ë° íš¨ê³¼ì ì´ì—ˆë‹¤ê³  ë¯¿ê³  ìˆìŠµë‹ˆë‹¤.\n\ní”„ë¡œì íŠ¸ ì „ë°˜ì— ê±¸ì³ ë£¨ì£¼ëŠ” íƒ€ì´í¬ê·¸ë˜í”¼ì— ì§‘ì¤‘í•˜ë©°, í˜„ëŒ€ ê¸€ê¼´ì„ ì›ë˜ ë„í‘œì—ì„œ ì‚¬ìš©ëœ ìŠ¤íƒ€ì¼ê³¼ ì¼ì¹˜ì‹œí‚¤ê¸° ìœ„í•´ ë§ì€ ë…¸ë ¥ì„ ê¸°ìš¸ì˜€ìŠµë‹ˆë‹¤. ê·¸ëŠ” ë˜í•œ ì „ì„¤ê³¼ ë‹¤ì–‘í•œ ë ˆì´ë¸”ì„ ì¬í˜„í•˜ì—¬ ì›ë³¸ì˜ ë¹ˆí‹°ì§€ ì •ì²´ì„±ì„ ìœ ì§€í–ˆìŠµë‹ˆë‹¤.\n\nê°œì¸ì ì¸ í„°ì¹˜ë¥¼ ë”í•˜ê¸° ìœ„í•´ ë£¨ì£¼ëŠ” ìƒ‰ìƒ ì¡°í•©ì„ ì‹¤í—˜í–ˆìœ¼ë©°, ìµœì¢…ì ìœ¼ë¡œ ì¸ì‚¬ ê´€ë ¨ ë¶€ë¶„ì—ëŠ” ìì‚¬ê·€ë¥¼ ì—°ìƒì‹œí‚¤ëŠ” ë…¹ìƒ‰ ìŒì˜ì„ ì‚¬ìš©í•˜ê³ , ë„í‘œì˜ êµ¬ì¡°ì—ëŠ” ê°ˆìƒ‰ê³¼ ë¹¨ê°„ìƒ‰ì„ ì‚¬ìš©í•˜ê¸°ë¡œ ê²°ì •í–ˆìŠµë‹ˆë‹¤.\n\nê·¸ì˜ ì—¬ì •ì—ì„œ ì¤‘ìš”í•œ ë¶€ë¶„ì€ ì„¸ì¸íŠ¸ ë¡œë ŒìŠ¤ ëŒ€í•™êµì—ì„œ ë‘ ë²ˆì§¸ ì›ë³¸ ë„í‘œë¥¼ ì°¾ëŠ” ê²ƒì´ì—ˆìŠµë‹ˆë‹¤. ì´ ë„í‘œì—ëŠ” ê·¸ê°€ ì´ì „ì— ì¶”ì •ì— ê¸°ë°˜í•´ ì¬êµ¬ì„±í–ˆë˜ ëˆ„ë½ëœ ë¶€ë¶„ì´ í¬í•¨ë˜ì–´ ìˆì—ˆìŠµë‹ˆë‹¤. ì´ ë°œê²¬ì€ ê·¸ì˜ ë³µì› í”„ë¡œì íŠ¸ë¥¼ ì™„ì„±í•˜ëŠ” ë° í° ë„ì›€ì´ ë˜ì—ˆìŠµë‹ˆë‹¤.\n\në£¨ì£¼ëŠ” ì´ ê³¼ì •ì´ ì¦ê±°ì› ë‹¤ê³  í‘œí˜„í•˜ë©°, ì°½ì˜ì ì¸ ì‘ì—…ê³¼ ì—°êµ¬ì—ì„œ ì–»ì€ ë§Œì¡±ê°ì„ ê°•ì¡°í–ˆìŠµë‹ˆë‹¤. ê·¸ëŠ” ìì‹ ì˜ ì¬í˜„ í¬ìŠ¤í„°ë¥¼ í†µí•´ ì´ ë¯¸êµ­ ì—­ì‚¬ì˜ í•œ ì¡°ê°ì„ ê³µìœ í•˜ê³ , ë‹¤ë¥¸ ì‚¬ëŒë“¤ë„ ê·¸ ë°°ê²½ì„ íƒêµ¬í•˜ë„ë¡ ì˜ê°ì„ ì£¼ê¸°ë¥¼ í¬ë§í•˜ê³  ìˆìŠµë‹ˆë‹¤.",
      "ja": "ãƒ‹ã‚³ãƒ©ã‚¹ãƒ»ãƒ«ãƒ¼ã‚¸ãƒ¥ã¯ã€1855å¹´ã«ãƒ€ãƒ‹ã‚¨ãƒ«ãƒ»ãƒãƒƒã‚«ãƒ©ãƒ ã«ã‚ˆã£ã¦ä½œæˆã•ã‚ŒãŸãƒ‹ãƒ¥ãƒ¼ãƒ¨ãƒ¼ã‚¯ãƒ»ã‚¨ãƒªãƒ¼é‰„é“ã®æ­´å²çš„ãªçµ„ç¹”å›³ã®å†ç¾ã«ã¤ã„ã¦ã®è¨˜äº‹ã‚’ç™ºè¡¨ã—ã¾ã—ãŸã€‚ã“ã®å›³ã¯ã€ã‹ã¤ã¦ã¯æ³¨ç›®ã•ã‚Œã¦ã„ã¾ã›ã‚“ã§ã—ãŸãŒã€ãã®è¤‡é›‘ãªãƒ‡ã‚¶ã‚¤ãƒ³ã¨æ­´å²çš„ãªé‡è¦æ€§ã§çŸ¥ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚ãƒãƒƒã‚«ãƒ©ãƒ ã¯ã€é‰„é“å†…ã®è²¬ä»»æ„Ÿã¨ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã«ã“ã®å›³ã‚’ä½œæˆã—ã¾ã—ãŸãŒã€å½¼ã®å³æ ¼ãªç®¡ç†ã‚¹ã‚¿ã‚¤ãƒ«ã¯å¾“æ¥­å“¡ã®åæ„Ÿã‚’æ‹›ãã€ã‚¢ãƒ¡ãƒªã‚«ã§åˆã‚ã¦ã®é‰„é“æŠ€å¸«ã®ã‚¹ãƒˆãƒ©ã‚¤ã‚­ã‚’å¼•ãèµ·ã“ã—ã¾ã—ãŸã€‚\n\nãƒ«ãƒ¼ã‚¸ãƒ¥ã¯ã€ã‚¢ãƒ¡ãƒªã‚«è­°ä¼šå›³æ›¸é¤¨ã‹ã‚‰å¾—ãŸä¸€æšã®ç”»åƒã‚’åŸºã«ã€å›³ã®èƒŒæ™¯ã‚’ç†è§£ã™ã‚‹ãŸã‚ã®ç ”ç©¶ã‚’å§‹ã‚ã¾ã—ãŸã€‚å½¼ã¯ã€ã“ã®æœ¨ã®ã‚ˆã†ãªæ§‹é€ ãŒé‰„é“ã®é‹å–¶ã¨å¾“æ¥­å“¡ã®éšå±¤ã‚’è±¡å¾´ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç™ºè¦‹ã—ã¾ã—ãŸã€‚ãƒ‡ã‚¶ã‚¤ãƒ³ãŒãƒ•ãƒªãƒ¼ãƒ¡ã‚¤ã‚½ãƒ³ã®ã‚·ãƒ³ãƒœãƒ«ã‚„åœ°å…ƒã®æ¤ç‰©ã«é–¢é€£ã—ã¦ã„ã‚‹ã¨ã„ã†åˆæœŸã®ç†è«–ãŒã‚ã£ãŸã‚‚ã®ã®ã€ãƒ«ãƒ¼ã‚¸ãƒ¥ã¯æœ¨ã®å½¢ãŒçµ„ç¹”æ§‹é€ ã‚’è¦–è¦šåŒ–ã™ã‚‹ã®ã«åŠ¹æœçš„ã ã£ãŸã¨è€ƒãˆã¦ã„ã¾ã™ã€‚\n\nãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’é€šã˜ã¦ã€ãƒ«ãƒ¼ã‚¸ãƒ¥ã¯ã‚¿ã‚¤ãƒã‚°ãƒ©ãƒ•ã‚£ã«é‡ç‚¹ã‚’ç½®ãã€ç¾ä»£ã®ãƒ•ã‚©ãƒ³ãƒˆã‚’å…ƒã®ã‚¹ã‚¿ã‚¤ãƒ«ã«åˆã‚ã›ã‚‹ä½œæ¥­ã«å–ã‚Šçµ„ã¿ã¾ã—ãŸã€‚ã¾ãŸã€ä¼èª¬ã‚„ã•ã¾ã–ã¾ãªãƒ©ãƒ™ãƒ«ã‚’å†ç¾ã—ã€ã‚ªãƒªã‚¸ãƒŠãƒ«ã®ãƒ“ãƒ³ãƒ†ãƒ¼ã‚¸ãªã‚¢ã‚¤ãƒ‡ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚’ä¿ã¤ã‚ˆã†åŠªã‚ã¾ã—ãŸã€‚\n\nå€‹äººçš„ãªã‚¿ãƒƒãƒã‚’åŠ ãˆã‚‹ãŸã‚ã«ã€ãƒ«ãƒ¼ã‚¸ãƒ¥ã¯è‰²ã®é…è‰²ã‚’è©¦ã—ã€æœ€çµ‚çš„ã«äººå“¡ã«ã¯è‘‰ã«ä¼¼ãŸç·‘è‰²ã®è‰²åˆã„ã‚’ä½¿ç”¨ã—ã€å›³ã®æ§‹é€ ã«ã¯èŒ¶è‰²ã‚„èµ¤è‰²ã‚’ä½¿ã†ã“ã¨ã«æ±ºã‚ã¾ã—ãŸã€‚\n\nå½¼ã®æ—…ã®é‡è¦ãªéƒ¨åˆ†ã¯ã€ã‚»ãƒ³ãƒˆãƒ»ãƒ­ãƒ¼ãƒ¬ãƒ³ã‚¹å¤§å­¦ã§å›³ã®ç¬¬äºŒã®ã‚ªãƒªã‚¸ãƒŠãƒ«ã‚³ãƒ”ãƒ¼ã‚’è¦‹ã¤ã‘ã‚‹ã“ã¨ã§ã—ãŸã€‚ã“ã®ã‚³ãƒ”ãƒ¼ã«ã¯ã€å½¼ãŒä»¥å‰ã«æ¨æ¸¬ã«åŸºã¥ã„ã¦å†æ§‹ç¯‰ã—ãŸæ¬ è½éƒ¨åˆ†ãŒå«ã¾ã‚Œã¦ã„ã¾ã—ãŸã€‚ã“ã®ç™ºè¦‹ã«ã‚ˆã£ã¦ã€å½¼ã®å¾©å…ƒãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯å®Œæˆã—ã¾ã—ãŸã€‚\n\nãƒ«ãƒ¼ã‚¸ãƒ¥ã¯ã€ã“ã®ãƒ—ãƒ­ã‚»ã‚¹ã‚’æ¥½ã—ã‚“ã ã¨è¿°ã¹ã€å‰µé€ çš„ãªå´é¢ã¨ç ”ç©¶çš„ãªå´é¢ã®ä¸¡æ–¹ã‹ã‚‰å¾—ã‚‰ã‚Œã‚‹æº€è¶³æ„Ÿã‚’å¼·èª¿ã—ã¦ã„ã¾ã™ã€‚å½¼ã¯ã€è‡ªèº«ãŒå†ç¾ã—ãŸãƒã‚¹ã‚¿ãƒ¼ã‚’é€šã˜ã¦ã“ã®ã‚¢ãƒ¡ãƒªã‚«ã®æ­´å²ã‚’å…±æœ‰ã—ã€ä»–ã®äººã€…ã«ã‚‚ãã®èƒŒæ™¯ã‚’æ¢æ±‚ã™ã‚‹ã‚ˆã†ä¿ƒã—ãŸã„ã¨è€ƒãˆã¦ã„ã¾ã™ã€‚"
    }
  },
  {
    "id": "ab1f20b26e7cf831",
    "title": {
      "en": "Show HN: I implemented Snake in a tmux config file",
      "ko": "tmuxë¡œ ë±€ ê²Œì„ êµ¬í˜„!",
      "ja": "ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§ã‚¹ãƒãƒ¼ã‚¯ã‚²ãƒ¼ãƒ ï¼"
    },
    "type": "story",
    "url": "https://willhbr.net/2025/03/20/snakes-in-a-pane/",
    "score": 51,
    "by": "willhbr",
    "time": 1742976440,
    "content": "Snakes in a Pane: Building Snake Entirely Within a tmux Config File\n\n      March 20, 2025\n\n        â€¢\n\n        projects\n\n        tmux\n\n    Honestly Iâ€™d stop if I could, but I just get carried away. After making a compiler for tmux, then solving sudoku, then playing video I wasnâ€™t planning on making a game. These things just happen to you. Well maybe not to you, but they happen to me.\n\nUnlike the video player, this isnâ€™t just rendering Snake inside tmux. The entire gameâ€”input, game logic, and renderingâ€”is done using tmux config files. You just load tmux with this config, and youâ€™ll have Snake. Check out the code or have a look at me playing it in the video:\n\nThe display works the same as my video player. It uses many tested sessions to create a stack of status lines, each with enough windows to span the width of the screen. The â€œdisplayâ€ is updated by setting the style of the window to correspond with the window name, and then changing the name to the appropriate colour. In this case Iâ€™m only using two colours, whereas in the video I was using the full range of ANSI colours.\n\nThereâ€™s a big difference in how I initialise the screen, with the video player I used a recursive script to start all the nested tmux sessions, and since I knew the width upfront (it has to be static as the video needs to be scaled) I just generated the right number of new-window calls. Since I wanted this to be entirely tmux, I worked out a way of doing this without a shell script.\n\nInstead of recursively calling a shell script to fill the height, I set the default-command (run whenever you create a new window) to be:\n\nTMUX= tmux if-shell -F \"#{e|>:#{window_height},1}\" new-session\n\nEvery time a new session is created, if the height of the window in that session is more than one row, weâ€™ll create a new session. Once weâ€™ve filled the height, the command will exit without creating another session.\n\nTo fill each session with windows, I added a hook for session-created:\n\nset-hook -g session-created {\n  run -C \"set -g @width '#{e|/:#{window_width},2}'\"\n  run -d 1 -bC 'source-file create_windows.conf'\n}\n\nAfter a short delay, this will load create_windows.conf:\n\nif -F '#{e|<:#{session_windows},#{@width}}' {\n  new-window -b 'exit'\n  select-window -t '{last}'\n  source-file create_windows.conf\n} {\n  if -F '#{e|==:#{window_height},1}' {\n    source-file -t '$0' init.conf\n  }\n}\n\nThis script checks if thereâ€™s enough room for another window, and if so it creates one and loads itself again. Once weâ€™ve filled the width, I check if this is the final window to be created, and if so I load the main game logic in init.conf.\n\nInstead of recursively calling source-file, I could have done this with a recursive keybinding, but the end result is about the same. It might be faster to use keybindings, but youâ€™d have to worry about the keys getting sent to the right session which isnâ€™t something I have to do here.\n\nUnlike displaying the video, I would only need to change 1-2 pixels per update, instead of a whole frame worth. The only things that move are the head and tail of the snake and the location of the apple. Keeping track of this was a bit more challenging for the game logic, but for the display it just meant a few rename-window -t Y:=X commands.\n\nOne addition here is the ability to give the snake eyes, both because itâ€™s cute, as well as differentiating the head and tail:\n\nIsnâ€™t it adorable?\n\nThis could have been done just by changing the window-status-format of the window where the head was located, but I wanted to do this in a more tmux-y, declarative way. I ended up using the â€œmarked paneâ€ feature to do this. As the snake moved I would select the window that contained the head as the marked pane, and updated the format of each window to show eyes only if they were the marked window:\n\nset -g window-status-format '#[fg=colour0,bg=colour#{window_name}]#{?#{window_marked_flag},#{@eyes},  }'\n\nBefore I implemented this I thought I was going to need a complicated conditional to check the direction and swap between different eyes, but I realised that since the eyes will only change if the user gives input, I just need to set @eyes whenever the user presses a key that changes the direction.\n\nReading user input is something I knew would be easy, but even then I made it overly complicated. I used bind-key -n to add bindings that didnâ€™t require the prefix first, and set those up for Up, Down, Left, and Right. Originally I had these setting a variable for the direction we needed to face, which Iâ€™d then read during the update and change the position. This would have required a conditional for each direction which is messy. Thankfully I realised the much easier thing to do: the arrow keys set @x_change and @y_change to 1, 0, or -1 depending on the direction. Then every update I just add the change to the position.\n\nThis also made it easier to validate the inputâ€”you donâ€™t want to allow changing directly from left to right without first moving up or down. Thatâ€™s as simple as ensuring @x_change or @y_change is zero before setting it:\n\nbind -n Left {\n  if -F '#{@x_change}' { } {\n    set -g @new_eyes ' :'\n    set -g @x_change -1\n    set -g @y_change 0\n  }\n}\n\nThe final part is implementing the game logic. Just so weâ€™re super clear: the game logic is also just more tmux config. Thereâ€™s no little program working out where the snake should go, itâ€™s all done by tmux itself.\n\nI used the same approach I did for the sudoku solver: running send-keys to trigger keybindings back within tmux itself. In the end I only needed a single keybinding, which steps the game forward one iteration and schedules the next frame using run -d:\n\nbind G {\n  # game logic goes here!\n\n  run -C \"run -d '#{@speed}' -bC 'send-keys -t $0 C-b G'\"\n}\n\nBy setting the delay on run with a variable, I could easily increase the speed of the game as more apples were eaten. In theory any tmux session could handle the key bindingâ€”theyâ€™re all on the same serverâ€”but I decided to play it safe and always target the outermost session.\n\nOnce weâ€™ve got a function thatâ€™ll be called on each update, all we need to do is move the head of the snake in the right direction, move the end of the snake, and check whether weâ€™ve eaten an apple.\n\nset -Fg @head_x '#{e|%:#{e|+:#{@head_x},#{@x_change}},#{@width}}'\nset -Fg @head_y '#{e|%:#{e|+:#{@head_y},#{@y_change}},#{@height}}'\n\nif -F '#{e|<:#{@head_x},0}' {\n  set -Fg @head_x \"#{e|+:#{@head_x},#{@width}}\"\n}\nif -F '#{e|<:#{@head_y},0}' {\n  set -Fg @head_y \"#{e|+:#{@head_y},#{@height}}\"\n}\n\nThis first section moves the head, stored as a separate variable to the rest of the body so itâ€™s easier to keep track of and handle collisions. As I mentioned before the key inputs just set @x_change and @y_change so all I had to do here is add them to the head position. To allow wrapping around the screen I modulo them, which requires a second step as the modulo operator will leave negative numbers.\n\nIn order to support collisions (where the snake eats itself) I needed to keep track of the body positions. Itâ€™s difficult to get the name of a particular window, so I keep track of this separately to the actual display.\n\nWhat I really need is an array, but tmux doesnâ€™t have those. Instead, each segment is stored as a fixed-length string with known delimiters, so .12 :=5  . would correspond to row 12 and column 5.\n\nset -F @len \"#{e|*:#{@length},10}\"\nset -Fg @body '#{E:##{=#{@len}:@body#}}'\n# later we prepend the head position onto the body\nset -Fg @body '.#{p3:@head_y}:=#{p3:@head_x}.#{@body}'\n\nTo remove the last segment, I use the string length-limit operator and double-expand it to allow using a variable as the length. I store the number of segments in @length, and since the string for each segment is fixed length, I just need to multiply this by 10.\n\nThe delimiters are added on either side to make it easier to do a substring match without running into false positives. I build a string out of the @head_x and @head_y, and if thatâ€™s found in the @body then the snake has eaten itself, and the game is over.\n\nif -F '#{m:*.#{p3:@head_y}:=#{p3:@head_x}.*,#{@body}}' {\n  display-menu -x C -y C -c /dev/pts/0 \\\n    -T ' Game over! score: #{e|-:#{@length},3} ' \\\n    'quit' q {\n      kill-server\n    }\n}\n\n@body is convenient for collisions, but not for moving the tail of the snake. For that Iâ€”very wastefullyâ€”set a new variable that tells me which window needs to be reverted back to the default colour at which step. By keeping track of the length of the snake and how many iterations there have been, I just lookup what the position was N steps ago, and swap that square back.\n\nset -Fg @step \"#{e|+:#{@step},1}\"\nrun -C \"set -g '@body_#{@step}' '#{@head_y}:=#{@head_x}'\"\n\nThese variables are formatted as a window selectorâ€”with the := in the middleâ€”so they can be passed to rename-window with a double expansion to do the indirection:\n\nrun -C 'set @var \"@body_#{e|-:#{@step},#{@length}}\"'\nrun -C 'rename-window -t \"#{E:##{#{@var}#}}\" \"\"'\n\nDuring the update we need to toggle the colour for the head. This only needs to be done once as itâ€™ll remain the same colour until we toggle it back. For the eyes to show on the head, I set the same window as the marked pane. Only one pane can be marked at a time so I donâ€™t have to un-set this.\n\nrun -C \"rename-window -t #{@head_y}:=#{@head_x} 2\"\nrun -C \"select-pane -t #{@head_y}:=#{@head_x} -m\"\n\nHereâ€™s the important bit: checking whether weâ€™ve eaten an apple. A simple string match on the x/y-coordinates enough. Then increase the speed and length.\n\nI couldnâ€™t think of a proper random number generator within tmux, but thankfully there are plenty of variables in the FORMATS section thatâ€™ll give us some random-enough numbers, especially if we combine them with the current step number. I ended up going with client_written which I assume will increase somewhat regularly as escape sequences and whatnot are written to the terminal. From my play-testing this was good enough.\n\nif -F '#{&&:#{==:#{@apple_y},#{@head_y}},#{==:#{@apple_x},#{@head_x}}}' {\n  set -Fg @speed \"#{e|*|f|2:#{@speed},0.8}\"\n  set -Fg @length \"#{e|+:#{@length},1}\"\n\n  set -F @seed \"#{e|+:#{client_written},#{@step}}\"\n  set -F @var \"#{e|%:#{@seed},#{@width}}\"\n  set -Fg @apple_x '#{@var}'\n  set -F @var \"#{e|%:#{@seed},#{@height}}\"\n  set -Fg @apple_y '#{@var}'\n}\n\nThe last job of the update function is to schedule the next updateâ€”if we havenâ€™t ended the gameâ€”and then it all happens again. Unlike playing video, where you want as many updates per second as possible, tmux is able to keep up with this reasonably well.\n\nBelieve it or not, the entire implementation is written by hand, and is fewer lines than my actual real-world tmux configâ€”140 versus 192. All you need to play it is tmux, around version 3.4 or so. Grab the code from here and give it a go!",
    "summary": {
      "en": "**Summary: Building Snake in tmux Config File**\n\nOn March 20, 2025, a developer created a version of the Snake game entirely within a tmux configuration file, without using any external programs. This means you can simply load the configuration into tmux to play the game.\n\nKey Features:\n- The game includes all elements like input, logic, and display, handled through tmux's config files.\n- The display is managed using multiple tmux sessions that update based on window names and colors.\n- The developer used hooks and commands within tmux to create and manage game sessions and windows, allowing for dynamic resizing and game state updates.\n\nGame Mechanics:\n- The snake's head and tail are tracked separately, and players control movement using arrow keys.\n- The game logic, including collision detection and apple consumption, is also managed through tmux commands.\n- To enhance the game visually, the snake's head is given \"eyes\" for distinction, which updates based on user input.\n\nOverall, the implementation is compact, consisting of fewer lines than a typical tmux config, and can be played using tmux version 3.4 or later. The developer encourages others to try out the code.",
      "ko": "2025ë…„ 3ì›” 20ì¼, í•œ ê°œë°œìê°€ tmux ì„¤ì • íŒŒì¼ ë‚´ì—ì„œ ì™¸ë¶€ í”„ë¡œê·¸ë¨ ì—†ì´ ì™„ì „íˆ ë…ë¦½ì ì¸ ìŠ¤ë„¤ì´í¬ ê²Œì„ ë²„ì „ì„ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤. ì´ ì„¤ì • íŒŒì¼ì„ tmuxì— ë¡œë“œí•˜ê¸°ë§Œ í•˜ë©´ ê²Œì„ì„ ì¦ê¸¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nê²Œì„ì˜ ì£¼ìš” íŠ¹ì§•ì€ ì…ë ¥, ë¡œì§, ë””ìŠ¤í”Œë ˆì´ ë“± ëª¨ë“  ìš”ì†Œê°€ tmuxì˜ ì„¤ì • íŒŒì¼ì„ í†µí•´ ì²˜ë¦¬ëœë‹¤ëŠ” ì ì…ë‹ˆë‹¤. ë””ìŠ¤í”Œë ˆì´ëŠ” ì—¬ëŸ¬ tmux ì„¸ì…˜ì„ ì‚¬ìš©í•˜ì—¬ ê´€ë¦¬ë˜ë©°, ê° ì„¸ì…˜ì€ ì°½ ì´ë¦„ê³¼ ìƒ‰ìƒì— ë”°ë¼ ì—…ë°ì´íŠ¸ë©ë‹ˆë‹¤. ê°œë°œìëŠ” tmux ë‚´ì˜ í›…ê³¼ ëª…ë ¹ì–´ë¥¼ í™œìš©í•´ ê²Œì„ ì„¸ì…˜ê³¼ ì°½ì„ ìƒì„±í•˜ê³  ê´€ë¦¬í•˜ì—¬, ë™ì ìœ¼ë¡œ í¬ê¸°ë¥¼ ì¡°ì •í•˜ê³  ê²Œì„ ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸í•  ìˆ˜ ìˆë„ë¡ í–ˆìŠµë‹ˆë‹¤.\n\nê²Œì„ì˜ ë©”ì»¤ë‹ˆì¦˜ì€ ë±€ì˜ ë¨¸ë¦¬ì™€ ê¼¬ë¦¬ë¥¼ ê°ê° ì¶”ì í•˜ë©°, í”Œë ˆì´ì–´ëŠ” í™”ì‚´í‘œ í‚¤ë¥¼ ì‚¬ìš©í•´ ì›€ì§ì„ì„ ì¡°ì •í•©ë‹ˆë‹¤. ì¶©ëŒ ê°ì§€ì™€ ì‚¬ê³¼ ì†Œë¹„ë¥¼ í¬í•¨í•œ ê²Œì„ ë¡œì§ ì—­ì‹œ tmux ëª…ë ¹ì–´ë¥¼ í†µí•´ ê´€ë¦¬ë©ë‹ˆë‹¤. ì‹œê°ì ìœ¼ë¡œ ê²Œì„ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ ë±€ì˜ ë¨¸ë¦¬ì— \"ëˆˆ\"ì„ ì¶”ê°€í•˜ì—¬ êµ¬ë³„í•  ìˆ˜ ìˆë„ë¡ í–ˆìœ¼ë©°, ì´ëŠ” ì‚¬ìš©ì ì…ë ¥ì— ë”°ë¼ ì—…ë°ì´íŠ¸ë©ë‹ˆë‹¤.\n\nì „ì²´ì ìœ¼ë¡œ ì´ êµ¬í˜„ì€ ì¼ë°˜ì ì¸ tmux ì„¤ì •ë³´ë‹¤ ì ì€ ì¤„ë¡œ êµ¬ì„±ë˜ì–´ ìˆìœ¼ë©°, tmux ë²„ì „ 3.4 ì´ìƒì—ì„œ í”Œë ˆì´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê°œë°œìëŠ” ë‹¤ë¥¸ ì‚¬ëŒë“¤ë„ ì´ ì½”ë“œë¥¼ ì‹œë„í•´ ë³´ê¸°ë¥¼ ê¶Œì¥í•˜ê³  ìˆìŠµë‹ˆë‹¤.",
      "ja": "2025å¹´3æœˆ20æ—¥ã€ã‚ã‚‹é–‹ç™ºè€…ãŒtmuxã®è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«å†…ã§å®Œå…¨ã«å‹•ä½œã™ã‚‹ã‚¹ãƒãƒ¼ã‚¯ã‚²ãƒ¼ãƒ ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ä½œæˆã—ã¾ã—ãŸã€‚ã“ã®ã‚²ãƒ¼ãƒ ã¯å¤–éƒ¨ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’ä½¿ç”¨ã›ãšã€tmuxã®è¨­å®šã‚’èª­ã¿è¾¼ã‚€ã ã‘ã§ãƒ—ãƒ¬ã‚¤ã§ãã¾ã™ã€‚\n\nã“ã®ã‚²ãƒ¼ãƒ ã®ä¸»ãªç‰¹å¾´ã¯ã€å…¥åŠ›ã€ãƒ­ã‚¸ãƒƒã‚¯ã€è¡¨ç¤ºãªã©ã®ã™ã¹ã¦ã®è¦ç´ ãŒtmuxã®è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’é€šã˜ã¦å‡¦ç†ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã§ã™ã€‚è¡¨ç¤ºã¯ã€ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦åã‚„è‰²ã«åŸºã¥ã„ã¦æ›´æ–°ã•ã‚Œã‚‹è¤‡æ•°ã®tmuxã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä½¿ç”¨ã—ã¦ç®¡ç†ã•ã‚Œã¦ã„ã¾ã™ã€‚é–‹ç™ºè€…ã¯ã€ã‚²ãƒ¼ãƒ ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚„ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’ä½œæˆãƒ»ç®¡ç†ã™ã‚‹ãŸã‚ã«tmuxã®ãƒ•ãƒƒã‚¯ã‚„ã‚³ãƒãƒ³ãƒ‰ã‚’åˆ©ç”¨ã—ã€å‹•çš„ãªã‚µã‚¤ã‚ºå¤‰æ›´ã‚„ã‚²ãƒ¼ãƒ çŠ¶æ…‹ã®æ›´æ–°ã‚’å¯èƒ½ã«ã—ã¦ã„ã¾ã™ã€‚\n\nã‚²ãƒ¼ãƒ ã®ä»•çµ„ã¿ã¨ã—ã¦ã¯ã€ã‚¹ãƒãƒ¼ã‚¯ã®é ­ã¨å°¾ãŒåˆ¥ã€…ã«è¿½è·¡ã•ã‚Œã€ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã¯çŸ¢å°ã‚­ãƒ¼ã‚’ä½¿ã£ã¦ç§»å‹•ã‚’åˆ¶å¾¡ã—ã¾ã™ã€‚è¡çªæ¤œçŸ¥ã‚„ãƒªãƒ³ã‚´ã®æ¶ˆè²»ãªã©ã®ã‚²ãƒ¼ãƒ ãƒ­ã‚¸ãƒƒã‚¯ã‚‚tmuxã®ã‚³ãƒãƒ³ãƒ‰ã‚’é€šã˜ã¦ç®¡ç†ã•ã‚Œã¦ã„ã¾ã™ã€‚è¦–è¦šçš„ãªæ¥½ã—ã•ã‚’å¢—ã™ãŸã‚ã«ã€ã‚¹ãƒãƒ¼ã‚¯ã®é ­ã«ã¯ã€Œç›®ã€ãŒä»˜ã‘ã‚‰ã‚Œã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã«å¿œã˜ã¦æ›´æ–°ã•ã‚Œã¾ã™ã€‚\n\nå…¨ä½“çš„ã«ã€ã“ã®å®Ÿè£…ã¯ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆã§ã€é€šå¸¸ã®tmuxè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚ˆã‚Šã‚‚è¡Œæ•°ãŒå°‘ãªãã€tmuxã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³3.4ä»¥é™ã§ãƒ—ãƒ¬ã‚¤å¯èƒ½ã§ã™ã€‚é–‹ç™ºè€…ã¯ä»–ã®äººã«ã‚‚ã“ã®ã‚³ãƒ¼ãƒ‰ã‚’è©¦ã—ã¦ã¿ã‚‹ã‚ˆã†å‘¼ã³ã‹ã‘ã¦ã„ã¾ã™ã€‚"
    }
  },
  {
    "id": "bf46fb3faa61e34d",
    "title": {
      "en": "Apple losing over $1B a year on streaming service",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://www.reuters.com/technology/apple-losing-over-1-billion-year-streaming-service-information-reports-2025-03-20/",
    "score": 26,
    "by": "mgh2",
    "time": 1743289898,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "f1113cdf8736f233",
    "title": {
      "en": "Low responsiveness of ML models to critical or deteriorating health conditions",
      "ko": "ìœ„í—˜ ì‹ í˜¸ ë¬´ì‹œí•˜ëŠ” ML ëª¨ë¸",
      "ja": "å¥åº·å±æ©Ÿã«éˆæ„ŸãªMLãƒ¢ãƒ‡ãƒ«"
    },
    "type": "story",
    "url": "https://www.nature.com/articles/s43856-025-00775-0",
    "score": 82,
    "by": "PaulHoule",
    "time": 1743000217,
    "content": "Download PDF\n\n        Article\n\n            Open access\n\n                        Published: 11 March 2025\n\n                    Low responsiveness of machine learning models to critical or deteriorating health conditions\n                    Tanmoy Sarkar Pias1, Sharmin Afrose2, Moon Das Tuli3, Ipsita Hamid Trisha4,5, Xinwei Deng6, Charles B. Nemeroff7 & â€¦Danfeng Daphne Yao\n            ORCID: orcid.org/0000-0001-8969-27921Show authors\n\n    Communications Medicine\n\n                        volume5, Articlenumber:62 (2025)\n            Cite this article\n\n                        7580 Accesses\n\n                            394 Altmetric\n\n                    Metrics details\n\n            AbstractBackgroundMachine learning (ML) based mortality prediction models can be immensely useful in intensive care units. Such a model should generate warnings to alert physicians when a patientâ€™s condition rapidly deteriorates, or their vitals are in highly abnormal ranges. Before clinical deployment, it is important to comprehensively assess a modelâ€™s ability to recognize critical patient conditions.MethodsWe develop multiple medical ML testing approaches, including a gradient ascent method and neural activation map. We systematically assess these machine learning modelsâ€™ ability to respond to serious medical conditions using additional test cases, some of which are time series. Guided by medical doctors, our evaluation involves multiple machine learning models, resampling techniques, and four datasets for two clinical prediction tasks.ResultsWe identify serious deficiencies in the modelsâ€™ responsiveness, with the models being unable to recognize severely impaired medical conditions or rapidly deteriorating health. For in-hospital mortality prediction, the models tested using our synthesized cases fail to recognize 66% of the injuries. In some instances, the models fail to generate adequate mortality risk scores for all test cases. Our study identifies similar kinds of deficiencies in the responsiveness of 5-year breast and lung cancer prediction models.ConclusionsUsing generated test cases, we find that statistical machine-learning models trained solely from patient data are grossly insufficient and have many dangerous blind spots. Most of the ML models tested fail to respond adequately to critically ill patients. How to incorporate medical knowledge into clinical machine learning models is an important future research direction.Plain language summary\n\n              Computational models can be used to evaluate a patientâ€™s health condition and predict their risk of dying, for example, in the intensive care unit. These models could be useful to identify patients with worsening health conditions and alert doctors promptly. We test how well several computational models recognize patients with serious or worsening health conditions. We find most of the computational models evaluated cannot recognize critical health events in our tests, which is concerning. Our work highlights the importance of using medical knowledge guided testing to ensure models are suitable, as well as the need to incorporate fundamental medical knowledge into the design of such models.\n\n                Similar content being viewed by others\n\n                                        Using machine learning tools to predict outcomes for emergency department intensive care unit patients\n\n                                        Article\n                                         Open access\n                                         01 December 2020\n\n                                        Development of a machine learning-based clinical decision support system to predict clinical deterioration in patients visiting the emergency department\n\n                                        Article\n                                         Open access\n                                         26 May 2023\n\n                                        Mortality prediction of patients in intensive care units using machine learning algorithms based on electronic health records\n\n                                        Article\n                                         Open access\n                                         03 May 2022\n\n                window.dataLayer = window.dataLayer || [];\n                window.dataLayer.push({\n                    recommendations: {\n                        recommender: 'semantic',\n                        model: 'specter',\n                        policy_id: 'NA',\n                        timestamp: 1743298221,\n                        embedded_user: 'null'\n                    }\n                });\n\n                        IntroductionThe Food Drug Administration authorized the first autonomous artificial intelligence (AI) diagnostic system in 2018, which is for detecting diabetic retinopathy1. Since then, AI machine learning (ML) based predictive technologies are rapidly made available for incorporation into clinical workflows2, e.g., for early sepsis detection3 and predicting surgery time4. However, recent studies revealed problems of prediction models under various medical scenarios, e.g., missed detection in mortality prediction or cancer prognosis5, poor sepsis forecast by a popular U.S. electronic health record software system Epic6, and models creating incorrect predictive shortcuts for image-based skin cancer detection7.These findings point out the urgent need for systematic model evaluation before their clinical adoption to ensure trustworthiness8. For example, for in-hospital mortality (IHM) prediction, it is important to measure whether or not ML models can promptly respond to deteriorating patientsâ€™ conditions. However, due to the immense complexity of the input space, model evaluation is challenging. Exhaustive testing is both unnecessary and impossible in most medical AI applications.The current ML testing practice is very limited in terms of the coverage of disease conditions. Existing model testing is largely restricted to a small percentage (10-15%) of the existing dataset, i.e., test set, as the bulk of the data is reserved for training. Because data imbalance in medicine is common, a typical test set likely has a low coverage of various critical medical conditions and minority prediction class cases. For example, the minority prediction class (i.e., death class) only accounts for 13.5% of an IHM prediction dataset5. Even with cross-validation and bootstrapping, the test set is largely limited to the original data.As a result of the limited test sets, predictive models may be under-evaluated. How they respond to real-world scenarios may be insufficiently assessed. During clinical deployment, new patient conditions could occur out of the distribution of the test set, triggering unexpected failures, e.g., the model failing to produce high enough risk scores for critically ill patients. This issue may disproportionately impact the smaller prediction class, as a typical data-driven model aims to prioritize the accuracy of the majority class samples during training5. One approach for increasing test coverage is to use synthetic test samples. Recently, generative technologies have been proposed to produce curated manmade images for testing self-driving vehicles9,10. However, image-based solutions do not address the unique temporal challenge in medical time-series applications.In this work, we develop systematic approaches for generating new test cases beyond the original dataset to assess the responsiveness of ML models to critical health conditions that may occur in clinical settings. Our test case generation is guided by domain knowledge and medical experts. Our experiments involve binary classification tasks, including time-series-based IHM prediction and 5-year breast and lung cancer survivability (LCS) prognosis (Fig.1). We develop multiple methods for generating high-risk test cases that do not exist in the training data or are underrepresented in the training set. Our solutions can process time series data, which is pervasive in medicine. We also conduct interviews with medical experts to obtain their estimated risks on some of the generated test cases. Our work reveals alarming prediction deficiencies of ML models and points out that ML responsiveness is an important aspect of trustworthiness in digital health.Fig. 1: Number of generated test cases for evaluating models trained on in-hospital mortality risk prediction and 5-year cancer survivability prediction models.The left side illustrates the generated test case of each category for testing in-hospital mortality risk prediction models trained on MIMIC III or eICU dataset. The right side represents the generated test cases to test 5-year breast cancer survivability (BCS) prediction models. The SEER lung cancer survivability (LCS) models are tested similarly using the single-attribute test cases.Full size imageMethodsPrediction tasks, datasets, and model selectionOur work aims to test medical ML models for their binary classification accuracy under serious disease conditions. We focus on three binary prediction tasks, namely 48-h IHM risk prediction, 5-year breast cancer survivability (BCS) prediction, and 5-year LCS prediction.The datasets in our study include a 2019 benchmark11 based on the MIMIC III12,13 dataset, a 2020 benchmark14 based on the eICU15 dataset, and a 2018 reproducibility benchmark16 based on the Surveillance, Epidemiology, and End Results (SEER) (5-year breast and lung cancer) dataset16. The first two datasets contain patientsâ€™ 48-h time series data in critical care units (ICU). Our study excludes clinical free text notes. As with many medical datasets, the MIMIC-III dataset for IHM, containing 21,139 samples, is imbalanced, with 13.2% death cases (Class 1), and 86.8% non-death cases (Class 0). The eICU IHM benchmark dataset contains a total of 30,681 (88.5% for Class 0 and 11.5% for Class 1) samples with similar attributes and time lengths to the MIMIC III benchmark14. Supplementary Fig.S1 shows the distributions of key attributes of both MIMIC III and eICU datasets. The SEER BCS dataset contains 248,751 patient cases with 56 attributes (7 numerical and continuous features and 49 categorical). In the SEER BCS dataset, 12.7% of cases are death cases (Class 0); the rest are survived cases (Class 1). Supplementary Fig.S2 shows the distributions of key attributes. The SEER LCS dataset contains 205,555 cases with 47 features (7 numerical and continuous features and 40 categorical). 84% of patients died in the LCS dataset.The creation of the MIMIC-III dataset was approved by the Institutional Review Boards of Beth Israel Deaconess Medical Center (Boston, MA) and the Massachusetts Institute of Technology (Cambridge, MA). Because sensitive health information was de-identified and the dataset did not impact clinical care, the requirement for individual patient consent was waived. The eICU dataset creation is exempt from institutional review board approval due to the retrospective design, lack of direct patient intervention, and the security schema, for which the re-identification risk was certified as meeting safe harbor standards by an independent privacy expert (Privacert, Cambridge, MA) (Health Insurance Portability and Accountability Act Certification no. 1031219-2). The SEER Program dataset is managed and maintained by the National Cancer Institute (NCI) in the United States. The centralized data collection system enables central IRB submission and approval through reliance agreements with registries. The SEER data collected by registries under state public health reporting authority is HIPAA exempt. MIMIC III is freely available through a proper request to the data source (https://physionet.org/content/mimiciii/1.4/). It requires a license (PhysioNet Credentialed Health Data License 1.5.0), Data Use Agreement (PhysioNet Credentialed Health Data Use Agreement 1.5.0), a training (CITI Data or Specimens Only Research). The eICU dataset can also be accessed (https://physionet.org/content/eicu-crd/2.0/) by completing these mentioned steps. The SEER dataset is also freely available through a proper request to the data source (https://seer.cancer.gov/). It requires the Data Application Form, Data User Agreement, and Acknowledgment of Data Limitations (https://seer.cancer.gov/data/product-comparison.html). The data was accessed through an eRA Commons account, and the data cohort was selected using SEER*Stat software. We gained access to the datasets following the various routes described above. All these datasets are de-identified and public. Thus, an IRB approval is not required for this study, specifically the analysis of de-identified and publicly available data does not constitute human subjects research (U.S. Federal Regulations 45 CFR 46.102).We select ML models that are commonly used in the medical literature for these prediction tasks. Specifically, we select long short term memory (LSTM) as it is widely used for predicting mortality risk in a 48-h ICU time series datasetâ€”in recent literature5,17,18,19. Similarly, for cancer survivability prediction, we selected multi-layer perceptron (MLP), which was commonly used in analyzing SEER datasets5,16,20. In addition, we also evaluated general-purpose ML models commonly seen in medical literature, including XGBoost, AdaBoost, random forest, Gaussian Naive Bayes, and K-nearest Neighbor (KNN). For mortality prediction, we also include channel-wise long short term memory (CW-LSTM) and linear logistic regression (LR) models from the benchmark study11 and an advanced transformer model.Dataset preprocessingWe train ML models with benchmark datasets of MIMIC-III11, eICU14, and SEER breast and LCS studies16, following the conventional pre-training process",
    "summary": {
      "en": "The article discusses the effectiveness of machine learning (ML) models in predicting critical health conditions, particularly in intensive care units (ICUs). Researchers found that many existing ML models struggle to recognize deteriorating health situations, which is concerning for patient safety. \n\nKey points include:\n\n1. **Purpose of ML Models**: These models aim to predict patient mortality and alert healthcare providers when a patient's condition worsens.\n\n2. **Study Findings**: The study revealed that the models tested failed to identify 66% of critical injuries and often produced insufficient mortality risk scores. This indicates that many models have significant limitations in recognizing severe health crises.\n\n3. **Methodology**: The researchers developed various testing methods using synthetic test cases to evaluate the models better. They emphasized the importance of integrating medical expertise into the design of these models for more reliable predictions.\n\n4. **Conclusion**: The study highlights urgent needs for improved testing practices and better incorporation of medical knowledge into ML models to enhance their responsiveness to critical health conditions, ensuring they can effectively assist in clinical settings.",
      "ko": "ì´ ê¸°ì‚¬ëŠ” ì¤‘í™˜ìì‹¤ì—ì„œ ê¸°ê³„ í•™ìŠµ(ML) ëª¨ë¸ì´ ì¤‘ëŒ€í•œ ê±´ê°• ìƒíƒœë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë° ì–¼ë§ˆë‚˜ íš¨ê³¼ì ì¸ì§€ë¥¼ ë‹¤ë£¨ê³  ìˆìŠµë‹ˆë‹¤. ì—°êµ¬ìë“¤ì€ ë§ì€ ê¸°ì¡´ ML ëª¨ë¸ì´ ì•…í™”ë˜ëŠ” ê±´ê°• ìƒí™©ì„ ì¸ì‹í•˜ëŠ” ë° ì–´ë ¤ì›€ì„ ê²ªê³  ìˆì–´ í™˜ì ì•ˆì „ì— ëŒ€í•œ ìš°ë ¤ê°€ ì»¤ì§€ê³  ìˆë‹¤ê³  ë°í˜”ìŠµë‹ˆë‹¤.\n\nML ëª¨ë¸ì˜ ì£¼ìš” ëª©ì ì€ í™˜ìì˜ ì‚¬ë§ ê°€ëŠ¥ì„±ì„ ì˜ˆì¸¡í•˜ê³  í™˜ìì˜ ìƒíƒœê°€ ì•…í™”ë  ë•Œ ì˜ë£Œ ì œê³µìì—ê²Œ ê²½ê³ í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì—°êµ¬ ê²°ê³¼, í…ŒìŠ¤íŠ¸ëœ ëª¨ë¸ë“¤ì€ 66%ì˜ ì¤‘ëŒ€í•œ ë¶€ìƒì„ ì‹ë³„í•˜ì§€ ëª»í–ˆìœ¼ë©°, ì¢…ì¢… ë¶ˆì¶©ë¶„í•œ ì‚¬ë§ ìœ„í—˜ ì ìˆ˜ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤. ì´ëŠ” ë§ì€ ëª¨ë¸ì´ ì‹¬ê°í•œ ê±´ê°• ìœ„ê¸°ë¥¼ ì¸ì‹í•˜ëŠ” ë° ìƒë‹¹í•œ í•œê³„ë¥¼ ê°€ì§€ê³  ìˆìŒì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\n\nì—°êµ¬ìë“¤ì€ ëª¨ë¸ì„ ë” ì˜ í‰ê°€í•˜ê¸° ìœ„í•´ í•©ì„± í…ŒìŠ¤íŠ¸ ì‚¬ë¡€ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¤ì–‘í•œ í…ŒìŠ¤íŠ¸ ë°©ë²•ì„ ê°œë°œí–ˆìŠµë‹ˆë‹¤. ê·¸ë“¤ì€ ì´ëŸ¬í•œ ëª¨ë¸ì˜ ì„¤ê³„ì— ì˜ë£Œ ì „ë¬¸ ì§€ì‹ì„ í†µí•©í•˜ëŠ” ê²ƒì´ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì˜ˆì¸¡ì„ ìœ„í•´ ì¤‘ìš”í•˜ë‹¤ê³  ê°•ì¡°í–ˆìŠµë‹ˆë‹¤.\n\nì´ ì—°êµ¬ëŠ” ì¤‘ëŒ€í•œ ê±´ê°• ìƒíƒœì— ëŒ€í•œ ë°˜ì‘ì„±ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ ê°œì„ ëœ í…ŒìŠ¤íŠ¸ ê´€í–‰ê³¼ ì˜ë£Œ ì§€ì‹ì˜ ë” ë‚˜ì€ í†µí•©ì´ ì‹œê¸‰í•˜ë‹¤ëŠ” ì ì„ ê°•ì¡°í•©ë‹ˆë‹¤. ì´ëŠ” ì„ìƒ í™˜ê²½ì—ì„œ íš¨ê³¼ì ìœ¼ë¡œ ë„ì›€ì„ ì¤„ ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ë° í•„ìš”í•©ë‹ˆë‹¤.",
      "ja": "ã“ã®è¨˜äº‹ã§ã¯ã€æ©Ÿæ¢°å­¦ç¿’ï¼ˆMLï¼‰ãƒ¢ãƒ‡ãƒ«ãŒé›†ä¸­æ²»ç™‚å®¤ï¼ˆICUï¼‰ã«ãŠã‘ã‚‹é‡è¦ãªå¥åº·çŠ¶æ…‹ã®äºˆæ¸¬ã«ã©ã‚Œã»ã©åŠ¹æœçš„ã‹ã«ã¤ã„ã¦è­°è«–ã•ã‚Œã¦ã„ã¾ã™ã€‚ç ”ç©¶è€…ãŸã¡ã¯ã€å¤šãã®æ—¢å­˜ã®MLãƒ¢ãƒ‡ãƒ«ãŒå¥åº·çŠ¶æ…‹ã®æ‚ªåŒ–ã‚’èªè­˜ã™ã‚‹ã®ã«è‹¦åŠ´ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç™ºè¦‹ã—ã¾ã—ãŸã€‚ã“ã‚Œã¯æ‚£è€…ã®å®‰å…¨ã«ã¨ã£ã¦æ‡¸å¿µææ–™ã§ã™ã€‚\n\nMLãƒ¢ãƒ‡ãƒ«ã®ç›®çš„ã¯ã€æ‚£è€…ã®æ­»äº¡ãƒªã‚¹ã‚¯ã‚’äºˆæ¸¬ã—ã€æ‚£è€…ã®çŠ¶æ…‹ãŒæ‚ªåŒ–ã—ãŸéš›ã«åŒ»ç™‚æä¾›è€…ã«è­¦å‘Šã‚’ç™ºã™ã‚‹ã“ã¨ã§ã™ã€‚ç ”ç©¶ã®çµæœã€ãƒ†ã‚¹ãƒˆã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¯ã€é‡ç¯¤ãªå‚·å®³ã®66%ã‚’ç‰¹å®šã§ããšã€ã—ã°ã—ã°ä¸ååˆ†ãªæ­»äº¡ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã‚Šã¾ã—ãŸã€‚ã“ã‚Œã¯ã€å¤šãã®ãƒ¢ãƒ‡ãƒ«ãŒæ·±åˆ»ãªå¥åº·å±æ©Ÿã‚’èªè­˜ã™ã‚‹ä¸Šã§å¤§ããªé™ç•Œã‚’æŒã£ã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚\n\nç ”ç©¶è€…ãŸã¡ã¯ã€ãƒ¢ãƒ‡ãƒ«ã‚’ã‚ˆã‚Šè‰¯ãè©•ä¾¡ã™ã‚‹ãŸã‚ã«ã€åˆæˆãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã‚’ç”¨ã„ãŸã•ã¾ã–ã¾ãªãƒ†ã‚¹ãƒˆæ–¹æ³•ã‚’é–‹ç™ºã—ã¾ã—ãŸã€‚å½¼ã‚‰ã¯ã€ã‚ˆã‚Šä¿¡é ¼æ€§ã®é«˜ã„äºˆæ¸¬ã‚’è¡Œã†ãŸã‚ã«ã¯ã€ã“ã‚Œã‚‰ã®ãƒ¢ãƒ‡ãƒ«ã®è¨­è¨ˆã«åŒ»ç™‚ã®å°‚é–€çŸ¥è­˜ã‚’çµ±åˆã™ã‚‹ã“ã¨ãŒé‡è¦ã§ã‚ã‚‹ã¨å¼·èª¿ã—ã¦ã„ã¾ã™ã€‚\n\nã“ã®ç ”ç©¶ã¯ã€é‡è¦ãªå¥åº·çŠ¶æ…‹ã«å¯¾ã™ã‚‹å¿œç­”æ€§ã‚’é«˜ã‚ã‚‹ãŸã‚ã«ã€æ”¹å–„ã•ã‚ŒãŸãƒ†ã‚¹ãƒˆæ‰‹æ³•ã¨åŒ»ç™‚çŸ¥è­˜ã®ã‚ˆã‚Šè‰¯ã„çµ±åˆãŒæ€¥å‹™ã§ã‚ã‚‹ã“ã¨ã‚’æµ®ãå½«ã‚Šã«ã—ã¦ã„ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€è‡¨åºŠç¾å ´ã§åŠ¹æœçš„ã«æ”¯æ´ã§ãã‚‹ã‚ˆã†ã«ãªã‚‹ã“ã¨ãŒæœŸå¾…ã•ã‚Œã¦ã„ã¾ã™ã€‚"
    }
  },
  {
    "id": "9184928152a18da9",
    "title": {
      "en": "Kink and LGBT dating apps exposed 1.5M private user images online",
      "ko": "ì„±ì†Œìˆ˜ì ì•±, 150ë§Œ ì‚¬ìš©ì ì´ë¯¸ì§€ ìœ ì¶œ!",
      "ja": "LGBTã‚¢ãƒ—ãƒªæµå‡º1.5Mç”»åƒ"
    },
    "type": "story",
    "url": "https://www.bbc.com/news/articles/c05m5m5v327o",
    "score": 4,
    "by": "testrun",
    "time": 1743297091,
    "content": "Kink and LGBT dating apps exposed 1.5m private user images online2 hours agoShareSaveJoe TidyCyber correspondent, BBC World ServiceShareSaveChica AppSugar daddy dating app Chica is one of five apps with unprotected user images Researchers have discovered nearly 1.5 million pictures from specialist dating apps â€“ many of which are explicit â€“ being stored online without password protection, leaving them vulnerable to hackers and extortionists.Anyone with the link was able to view the private photos from five platforms developed by M.A.D Mobile: kink sites BDSM People and Chica, and LGBT apps Pink, Brish and Translove.These services are used by an estimated 800,000 to 900,000 people.M.A.D Mobile was first warned about the security flaw on 20th January but didn't take action until the BBC emailed on Friday.They have since fixed it but not said how it happened or why they failed to protect the sensitive images.This is one of the photos that anyone could have accessed. We have cropped the face and blurred it to enhance privacyEthical hacker Aras Nazarovas from Cybernews first alerted the firm about the security hole after finding the location of the online storage used by the apps by analysing the code that powers the services.He was shocked that he could access the unencrypted and unprotected photos without any password.\"The first app I investigated was BDSM People, and the first image in the folder was a naked man in his thirties,\" he said. \"As soon as I saw it I realised that this folder should not have been public.\"The images were not limited to those from profiles, he said â€“ they included pictures which had been sent privately in messages, and even some which had been removed by moderators.Hacking riskMr Nazarovas said the discovery of unprotected sensitive material comes with a significant risk for the platforms' users.Malicious hackers could have found the images and extorted individuals.There is also a risk to those who live in countries hostile to LGBT people.None of the text content of private messages was found to be stored in this way and the images are not labelled with user names or real names, which would make crafting targeted attacks at users more complex.In an email M.A.D Mobile said it was grateful to the researcher for uncovering the vulnerability in the apps to prevent a data breach from occurring. But there's no guarantee that Mr Nazarovas was the only hacker to have found the image stash.\"We appreciate their work and have already taken the necessary steps to address the issue,\" a M.A.D Mobile spokesperson said. \"An additional update for the apps will be released on the App Store in the coming days.\"The company did not respond to further questions about where the company is based and why it took months to address the issue after multiple warnings from researchers.Usually security researchers wait until a vulnerability is fixed before publishing an online report, in case it puts users at further risk of attack. But Mr Nazarovas and his team decided to raise the alarm on Thursday while the issue was still live as they were concerned the company was not doing anything to fix it.\"It's always a difficult decision but we think the public need to know to protect themselves,\" he said.In 2015 malicious hackers stole a large amount of customer data about users of Ashley Madison, a dating website for married people who wish to cheat on their spouse.Ashley Madison client data 'leaked'The hackers taking the bugs to the bank'Sensitive' army papers found scattered in streetDating appsLGBTOnline datingTechnology",
    "summary": {
      "en": "A recent investigation revealed that nearly 1.5 million private images from five dating apps, including kink and LGBT platforms, were stored online without password protection, making them accessible to anyone with the link. The apps involved are BDSM People, Chica, Pink, Brish, and Translove, which together serve around 800,000 to 900,000 users.\n\nThe issue was first reported to M.A.D Mobile, the developer, in January, but they did not act until alerted by the BBC. Although the security flaw has since been fixed, the company has not explained how it occurred. Ethical hacker Aras Nazarovas discovered the vulnerability while examining the apps' code and was alarmed by the lack of security protecting sensitive images.\n\nThe unprotected images included explicit photos and private messages, raising concerns about potential extortion and risks for users in countries where LGBT individuals face persecution. M.A.D Mobile acknowledged the issue and assured that they are taking steps to improve security. However, it remains unclear why they delayed action for months. The incident highlights the ongoing risks associated with online dating and data security.",
      "ko": "ìµœê·¼ ì¡°ì‚¬ì— ë”°ë¥´ë©´, BDSM People, Chica, Pink, Brish, Translove ë“± ë‹¤ì„¯ ê°œì˜ ë°ì´íŒ… ì•±ì—ì„œ ì•½ 150ë§Œ ê°œì˜ ê°œì¸ ì´ë¯¸ì§€ê°€ ë¹„ë°€ë²ˆí˜¸ ë³´í˜¸ ì—†ì´ ì˜¨ë¼ì¸ì— ì €ì¥ë˜ì–´ ìˆì–´, ë§í¬ë§Œ ìˆìœ¼ë©´ ëˆ„êµ¬ë‚˜ ì ‘ê·¼í•  ìˆ˜ ìˆëŠ” ìƒí™©ì´ì—ˆë‹¤. ì´ ì•±ë“¤ì€ ì´ 80ë§Œì—ì„œ 90ë§Œ ëª…ì˜ ì‚¬ìš©ìì—ê²Œ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•˜ê³  ìˆë‹¤.\n\nì´ ë¬¸ì œëŠ” 1ì›”ì— M.A.D Mobile ê°œë°œì‚¬ì— ì²˜ìŒ ë³´ê³ ë˜ì—ˆì§€ë§Œ, BBCì˜ ê²½ê³ ë¥¼ ë°›ì€ í›„ì—ì•¼ ì¡°ì¹˜ë¥¼ ì·¨í–ˆë‹¤. ë³´ì•ˆ ê²°í•¨ì€ ì´ë¯¸ ìˆ˜ì •ë˜ì—ˆì§€ë§Œ, íšŒì‚¬ëŠ” ì´ ë¬¸ì œê°€ ì–´ë–»ê²Œ ë°œìƒí–ˆëŠ”ì§€ì— ëŒ€í•œ ì„¤ëª…ì„ í•˜ì§€ ì•Šì•˜ë‹¤. ìœ¤ë¦¬ í•´ì»¤ì¸ ì•„ë¼ìŠ¤ ë‚˜ìë¡œë°”ìŠ¤ëŠ” ì•±ì˜ ì½”ë“œë¥¼ ê²€ì‚¬í•˜ë˜ ì¤‘ ì´ ì·¨ì•½ì ì„ ë°œê²¬í–ˆìœ¼ë©°, ë¯¼ê°í•œ ì´ë¯¸ì§€ë¥¼ ë³´í˜¸í•˜ëŠ” ë³´ì•ˆì´ ë¶€ì¡±í•œ ê²ƒì— ëŒ€í•´ ìš°ë ¤ë¥¼ í‘œí–ˆë‹¤.\n\në³´í˜¸ë˜ì§€ ì•Šì€ ì´ë¯¸ì§€ì—ëŠ” ë…¸ê³¨ì ì¸ ì‚¬ì§„ê³¼ ê°œì¸ ë©”ì‹œì§€ê°€ í¬í•¨ë˜ì–´ ìˆì–´, LGBT ê°œì¸ì´ ë°•í•´ë¥¼ ë°›ëŠ” êµ­ê°€ì—ì„œ ì‚¬ìš©ìë“¤ì´ ê²ªì„ ìˆ˜ ìˆëŠ” ì ì¬ì ì¸ ê°ˆì·¨ì™€ ìœ„í—˜ì— ëŒ€í•œ ìš°ë ¤ê°€ ì»¤ì§€ê³  ìˆë‹¤. M.A.D Mobileì€ ë¬¸ì œë¥¼ ì¸ì •í•˜ê³  ë³´ì•ˆ ê°œì„ ì„ ìœ„í•œ ì¡°ì¹˜ë¥¼ ì·¨í•˜ê³  ìˆë‹¤ê³  ë°í˜”ì§€ë§Œ, ì™œ ëª‡ ë‹¬ ë™ì•ˆ ì¡°ì¹˜ë¥¼ ë¯¸ë¤˜ëŠ”ì§€ëŠ” ì—¬ì „íˆ ë¶ˆí™•ì‹¤í•˜ë‹¤. ì´ë²ˆ ì‚¬ê±´ì€ ì˜¨ë¼ì¸ ë°ì´íŒ…ê³¼ ë°ì´í„° ë³´ì•ˆì— ê´€ë ¨ëœ ì§€ì†ì ì¸ ìœ„í—˜ì„ ë¶€ê°ì‹œí‚¤ê³  ìˆë‹¤.",
      "ja": "æœ€è¿‘ã®èª¿æŸ»ã«ã‚ˆã‚‹ã¨ã€BDSM Peopleã€Chicaã€Pinkã€Brishã€Transloveã®5ã¤ã®ãƒ‡ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚¢ãƒ—ãƒªã‹ã‚‰ã€ç´„150ä¸‡æšã®ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆç”»åƒãŒãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãªã—ã§ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã«ä¿å­˜ã•ã‚Œã¦ãŠã‚Šã€ãƒªãƒ³ã‚¯ã‚’çŸ¥ã£ã¦ã„ã‚‹äººãªã‚‰èª°ã§ã‚‚ã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹çŠ¶æ…‹ã§ã—ãŸã€‚ã“ã‚Œã‚‰ã®ã‚¢ãƒ—ãƒªã¯ã€ç´„80ä¸‡ã‹ã‚‰90ä¸‡äººã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«åˆ©ç”¨ã•ã‚Œã¦ã„ã¾ã™ã€‚\n\nã“ã®å•é¡Œã¯1æœˆã«ã‚¢ãƒ—ãƒªã®é–‹ç™ºè€…ã§ã‚ã‚‹M.A.D Mobileã«å ±å‘Šã•ã‚Œã¾ã—ãŸãŒã€BBCã‹ã‚‰ã®æŒ‡æ‘˜ãŒã‚ã‚‹ã¾ã§å¯¾å¿œãŒè¡Œã‚ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã®æ¬ é™¥ã¯ä¿®æ­£ã•ã‚ŒãŸã‚‚ã®ã®ã€ãã®åŸå› ã«ã¤ã„ã¦ã¯èª¬æ˜ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚å€«ç†çš„ãƒãƒƒã‚«ãƒ¼ã®ã‚¢ãƒ©ã‚¹ãƒ»ãƒŠã‚¶ãƒ­ãƒã‚¹ã¯ã€ã‚¢ãƒ—ãƒªã®ã‚³ãƒ¼ãƒ‰ã‚’èª¿æŸ»ã—ã¦ã„ã‚‹éš›ã«ã“ã®è„†å¼±æ€§ã‚’ç™ºè¦‹ã—ã€æ•æ„Ÿãªç”»åƒã‚’ä¿è­·ã™ã‚‹ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãŒæ¬ å¦‚ã—ã¦ã„ã‚‹ã“ã¨ã«é©šãã¾ã—ãŸã€‚\n\nç„¡é˜²å‚™ãªç”»åƒã«ã¯éœ²éª¨ãªå†™çœŸã‚„ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒå«ã¾ã‚Œã¦ãŠã‚Šã€LGBTã®äººã€…ãŒè¿«å®³ã‚’å—ã‘ã‚‹å›½ã€…ã«ãŠã‘ã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒªã‚¹ã‚¯ã‚„æå–ã®å¯èƒ½æ€§ã«ã¤ã„ã¦æ‡¸å¿µãŒé«˜ã¾ã£ã¦ã„ã¾ã™ã€‚M.A.D Mobileã¯å•é¡Œã‚’èªã‚ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å‘ä¸Šã«å‘ã‘ãŸå¯¾ç­–ã‚’è¬›ã˜ã¦ã„ã‚‹ã¨ã—ã¦ã„ã¾ã™ãŒã€ãªãœæ•°ãƒ¶æœˆã‚‚è¡Œå‹•ã‚’é…ã‚‰ã›ãŸã®ã‹ã¯ä¸æ˜ã§ã™ã€‚ã“ã®äº‹ä»¶ã¯ã€ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ãƒ‡ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã¨ãƒ‡ãƒ¼ã‚¿ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã«ä¼´ã†ãƒªã‚¹ã‚¯ãŒä¾ç„¶ã¨ã—ã¦å­˜åœ¨ã™ã‚‹ã“ã¨ã‚’æµ®ãå½«ã‚Šã«ã—ã¦ã„ã¾ã™ã€‚"
    }
  },
  {
    "id": "ad1f0993cd968b5c",
    "title": {
      "en": "U.S. Atari parts store still open after 41 years, spent $100K+ designing parts",
      "ko": "41ë…„ì§¸ ìš´ì˜ ì¤‘ì¸ ì•„íƒ€ë¦¬ ë¶€í’ˆ ê°€ê²Œ",
      "ja": "ã‚¢ãƒ¡ãƒªã‚«ã®ã‚¢ã‚¿ãƒªã€41å¹´ã®æ­´å²ï¼"
    },
    "type": "story",
    "url": "https://www.tomshardware.com/video-games/retro-gaming/u-s-atari-parts-store-still-open-after-41-years-has-spent-usd100k-designing-new-parts-last-original-atari-hardware-launched-32-years-ago",
    "score": 8,
    "by": "wojtczyk",
    "time": 1743294222,
    "content": "Video Games\n\nRetro Gaming\n\nU.S. Atari parts store still open after 41 years, has spent $100K+ designing new parts â€” last original Atari hardware launched 32 years ago\n\nNews\n\nBy\nMark Tyson\n\npublished\nMarch 16, 2025\n\nStocks go well beyond the 5,000+ 'popular items' the store lists for sale.\n\nComments (3)\n\nWhen you purchase through links on our site, we may earn an affiliate commission. Hereâ€™s how it works.\n\nwindow.vanilla.infiniteArticlesData = [];\n\n(Image credit: Best Electronics)\n\nAtari parts and accessories store Best Electronics stands bravely defiant against the march of time and technology, continuing to serve this increasingly niche retro hardware market â€” a whopping 41 years after it was set up.As well as supplying parts, the store continues to source and make new parts, provide support, hints, and tips, and claims to have spent $100,000+ in engineering development. In contrast, the iconic and innovative Atari Corp. behind all the firm's home computers, and advanced consoles like the Lynx and Jaguar, went bankrupt in 1996, almost 30 years ago.Many readers and writers here on Tom's Hardware will have grown up with Atari computers and consoles. Thus it's admirable to see exclusive new and upgraded parts like rubber domes for your ST / STE / Falcon computer keyboard and all Gold PCB boards for your CX series joysticks, plus lots of other parts, continue to be manufactured and supplied to Atari fans.\n\nYou may like\n\nCES 2025 is the 40th anniversary of the Commodore 128 â€” the last 8-bit PC first appeared at CES 1985\n\nMaker resurrects Toshiba T1000 with a Raspberry Pi 4 and a slew of upgrades\n\nThe retailer also stocks \"a lifetime supply\" of new-old products in some categories. Interestingly, it reveals many of these were warehoused from the \"thousands and thousands of pallets of Atari goods\" it bought when Atari Sunnyvale was liquidated.\n    if (window.sliceHydrationLazy) {\n        window.sliceHydrationLazy(\"imageGallery-FnMgufN6kTGV9FcM3gG2Pf-dhleXOFvXFKEpRhRqDjyJwxGD8sDWGuE\", \"imageGallery\", JSON.stringify({\"galleryData\":[{\"title\":\"\",\"description\":[],\"image\":{\"id\":\"UTiNNYXxefNJi6Lq79Ns7h\",\"name\":\"catalog-sample\",\"credit\":{\"text\":\"(Image credit: {subject})\",\"subject\":\"<a href=\\\"https:\\/\\/www.best-electronics-ca.com\\/\\\" target=\\\"_blank\\\">Best Electronics<\\/a>\"},\"src\":\"https:\\/\\/cdn.mos.cms.futurecdn.net\\/UTiNNYXxefNJi6Lq79Ns7h.png\",\"alt\":\"Atari parts and accessories store Best Electronics\",\"width\":1580,\"height\":1080,\"srcSetSizes\":[320,480,650,970,1024,1200],\"sizes\":{\"default\":\"calc(100vw - 40px)\",\"1000px\":\"970px\"},\"fullscreen\":false,\"lazyLoading\":true,\"addSEOMetaData\":false,\"removeNativeWidthRestriction\":false,\"dataBordeauxImageCheckAttr\":false,\"noCredit\":false}},{\"title\":\"\",\"description\":[],\"image\":{\"id\":\"FrsHcWTim2TvntUgFNEu7h\",\"name\":\"joysticks\",\"credit\":{\"text\":\"(Image credit: {subject})\",\"subject\":\"<a href=\\\"https:\\/\\/www.best-electronics-ca.com\\/\\\" target=\\\"_blank\\\">Best Electronics<\\/a>\"},\"src\":\"https:\\/\\/cdn.mos.cms.futurecdn.net\\/FrsHcWTim2TvntUgFNEu7h.jpg\",\"alt\":\"Atari parts and accessories store Best Electronics\",\"width\":835,\"height\":1081,\"srcSetSizes\":[320,480,650,970,1024,1200],\"sizes\":{\"default\":\"calc(100vw - 40px)\",\"1000px\":\"970px\"},\"fullscreen\":false,\"lazyLoading\":true,\"addSEOMetaData\":false,\"removeNativeWidthRestriction\":false,\"dataBordeauxImageCheckAttr\":false,\"noCredit\":false}},{\"title\":\"\",\"description\":[],\"image\":{\"id\":\"pKZsgG3mxi7GVM6ZyB2t9h\",\"name\":\"atari-compatible-site\",\"credit\":{\"text\":\"(Image credit: {subject})\",\"subject\":\"<a href=\\\"https:\\/\\/www.best-electronics-ca.com\\/\\\" target=\\\"_blank\\\">Best Electronics<\\/a>\"},\"src\":\"https:\\/\\/cdn.mos.cms.futurecdn.net\\/pKZsgG3mxi7GVM6ZyB2t9h.jpg\",\"alt\":\"Atari parts and accessories store Best Electronics\",\"width\":1532,\"height\":1025,\"srcSetSizes\":[320,480,650,970,1024,1200],\"sizes\":{\"default\":\"calc(100vw - 40px)\",\"1000px\":\"970px\"},\"fullscreen\":false,\"lazyLoading\":true,\"addSEOMetaData\":false,\"removeNativeWidthRestriction\":false,\"dataBordeauxImageCheckAttr\":false,\"noCredit\":false}}],\"progressText\":\"Image {currentSlide} of {totalSlides}\",\"viewOriginalText\":\"View Original\"}), \"https://slice.vanilla.futurecdn.net/13-2-0/js/imageGallery.js\");\n    } else {\n        console.error('%c FTE ','background: #9306F9; color: #ffffff','no lazy slice hydration function available');\n    }\nImage 1 of 3(Image credit: Best Electronics)(Image credit: Best Electronics)(Image credit: Best Electronics)As a previous owner of Atari ST, Falcon, Lynx and Jaguar hardware, looking through these products is like hunting through a treasure trove. Best Electronics says it lists 5,000+ Atari items on its site. But these are just the most popular items, so if you are after something that appears absent from the extensive parts and components lists, send the store an email to ask after it.Alternatively, go back in retail time by ordering the Best Rev. 10 All Atari catalog â€” a paper catalog of over 220 pages, making it about half an inch thick and 1.4 pounds in weight. Helpfully, the catalog includes 330 pictures of Atari bits, as well as extras like prototype information, repair tips and tricks, a complete list of Atari custom chips and replacement ICs, and more. Check out the two-page sample and more information on the Best Electronics site.\n    if (window.sliceHydrationLazy) {\n        window.sliceHydrationLazy(\"imageGallery-FnMgufN6kTGV9FcM3gG2Pf-zaHBNXFS3B4fVhENpYVb0VXmbRyNOb5T\", \"imageGallery\", JSON.stringify({\"galleryData\":[{\"title\":\"\",\"description\":[],\"image\":{\"id\":\"aQKig3xsSWWKyhZXRqsL6h\",\"name\":\"printer\",\"credit\":{\"text\":\"(Image credit: {subject})\",\"subject\":\"<a href=\\\"https:\\/\\/www.best-electronics-ca.com\\/\\\" target=\\\"_blank\\\">Best Electronics<\\/a>\"},\"src\":\"https:\\/\\/cdn.mos.cms.futurecdn.net\\/aQKig3xsSWWKyhZXRqsL6h.jpg\",\"alt\":\"Atari parts and accessories store Best Electronics\",\"width\":1517,\"height\":1080,\"srcSetSizes\":[320,480,650,970,1024,1200],\"sizes\":{\"default\":\"calc(100vw - 40px)\",\"1000px\":\"970px\"},\"fullscreen\":false,\"lazyLoading\":true,\"addSEOMetaData\":false,\"removeNativeWidthRestriction\":false,\"dataBordeauxImageCheckAttr\":false,\"noCredit\":false}},{\"title\":\"\",\"description\":[],\"image\":{\"id\":\"FFDzJheycXxERbpur52h4h\",\"name\":\"ST-HDDs\",\"credit\":{\"text\":\"(Image credit: {subject})\",\"subject\":\"<a href=\\\"https:\\/\\/www.best-electronics-ca.com\\/\\\" target=\\\"_blank\\\">Best Electronics<\\/a>\"},\"src\":\"https:\\/\\/cdn.mos.cms.futurecdn.net\\/FFDzJheycXxERbpur52h4h.jpg\",\"alt\":\"Atari parts and accessories store Best Electronics\",\"width\":1553,\"height\":991,\"srcSetSizes\":[320,480,650,970,1024,1200],\"sizes\":{\"default\":\"calc(100vw - 40px)\",\"1000px\":\"970px\"},\"fullscreen\":false,\"lazyLoading\":true,\"addSEOMetaData\":false,\"removeNativeWidthRestriction\":false,\"dataBordeauxImageCheckAttr\":false,\"noCredit\":false}}],\"progressText\":\"Image {currentSlide} of {totalSlides}\",\"viewOriginalText\":\"View Original\"}), \"https://slice.vanilla.futurecdn.net/13-2-0/js/imageGallery.js\");\n    } else {\n        console.error('%c FTE ','background: #9306F9; color: #ffffff','no lazy slice hydration function available');\n    }\nImage 1 of 2(Image credit: Best Electronics)(Image credit: Best Electronics)We've covered retro hardware holdouts before, with reports on the surprisingly recent demise of the floppy disk in Japan, German railway systems that still rely on MS-DOS and Windows 3.11, and even the Indiana bakery which still runs Commodore 64-powered cash registers. Nevertheless, Best Electronics dogged and extensive support for Atari fans still impresses.\n    window.sliceComponents = window.sliceComponents || {};\n\n    externalsScriptLoaded.then(() => {\n        window.reliablePageLoad.then(() => {\n            var componentContainer = document.querySelector(\"#slice-container-newsletterForm-articleInbodyContent-FnMgufN6kTGV9FcM3gG2Pf\");\n\n            if (componentContainer) {\n                var data = {\"layout\":\"inbodyContent\",\"header\":\"Stay On the Cutting Edge: Get the Tom's Hardware Newsletter\",\"tagline\":\"Get Tom's Hardware's best news and in-depth reviews, straight to your inbox.\",\"formFooterText\":\"By submitting your information you agree to the <a href=\\\"https:\\/\\/futureplc.com\\/terms-conditions\\/\\\" target=\\\"_blank\\\">Terms & Conditions<\\/a> and <a href=\\\"https:\\/\\/futureplc.com\\/privacy-policy\\/\\\" target=\\\"_blank\\\">Privacy Policy<\\/a> and are aged 16 or over.\",\"successMessage\":{\"body\":\"Thank you for signing up. You will receive a confirmation email shortly.\"},\"failureMessage\":\"There was a problem. Please refresh the page and try again.\",\"method\":\"POST\",\"inputs\":[{\"type\":\"hidden\",\"name\":\"NAME\"},{\"type\":\"email\",\"name\":\"MAIL\",\"placeholder\":\"Your Email Address\",\"required\":true},{\"type\":\"hidden\",\"name\":\"NEWSLETTER_CODE\",\"value\":\"XTH-X\"},{\"type\":\"hidden\",\"name\":\"LANG\",\"value\":\"EN\"},{\"type\":\"hidden\",\"name\":\"SOURCE\",\"value\":\"60\"},{\"type\":\"hidden\",\"name\":\"COUNTRY\"},{\"type\":\"checkbox\",\"name\":\"CONTACT_OTHER_BRANDS\",\"label\":{\"text\":\"Contact me with news and offers from other Future brands\"}},{\"type\":\"checkbox\",\"name\":\"CONTACT_PARTNERS\",\"label\":{\"text\":\"Receive email from us on behalf of our trusted partners or sponsors\"}},{\"type\":\"submit\",\"value\":\"Sign me up\",\"required\":true}],\"endpoint\":\"https:\\/\\/newsletter-subscribe.futureplc.com\\/v2\\/submission\\/submit\",\"analytics\":[{\"analyticsType\":\"widgetViewed\"}],\"ariaLabels\":{}};\n\n                var triggerHydrate = function() {\n                    window.sliceComponents.newsletterForm.hydrate(data, componentContainer);\n                }\n\n                if (window.lazyObserveElement) {\n                    window.lazyObserveElement(componentContainer, triggerHydrate);\n                } else {\n                    triggerHydrate();\n                }\n            }\n        }).catch(err => console.error('%c FTE ','background: #9306F9; color: #ffffff','Hydration Script has failed for newsletterForm-articleInbodyContent-FnMgufN6kTGV9FcM3gG2Pf Slice', err));\n    }).catch(err => console.error('%c FTE ','background: #9306F9; color: #ffffff','Externals script failed to load', err));\nStay On the Cutting Edge: Get the Tom's Hardware NewsletterGet Tom's Hardware's best news and in-depth reviews, straight to your inbox.Contact me with news and offers from other Future brandsReceive email from us on behalf of our trusted partners or sponsorsBy submitting your information you agree to the Terms & Conditions and Privacy Policy and are aged 16 or over.The last original hardware from Atari Corp. was the Jaguar console, introduced in 1993 and discontinued in 1996. That end date coincides with the filing for bankruptcy by the iconic firm. Sadly, the Atari branded products which arrived after this time were just rehashed and recycled wares designed to milk the firm's classic video games IP with minimal innovation.\n\nTOPICS\n\nAtari\n\nSee all comments (3)\n\nMark TysonSocial Links NavigationNews EditorMark Tyson is a news editor at Tom's Hardware. He enjoys covering the full breadth of PC tech; from business and semiconductor design to products approaching the edge of reason.\n\nRead more\n\nCES 2025 is the 40th anniversary of the Commodore 128 â€” the last 8-bit PC first appeared at CES 1985\n\n<a style=\"position: relative!important;\" href=\"SPONSORED_LINK_URL\">\n<picture>\n<source srcset=\"SPONSORED_IMAGE_URL.webp\" type=\"image/webp\" />\n<img src=\"SPONSORED_IMAGE_URL\" alt=\"SPONSORED_HEADLINE\" loading=\"lazy\"/>\n</picture>\n<span class=\"text-base text-black font-bold mx-0 my-2.5 p-0\">SPONSORED_HEADLINE</span>\n</a>\n\nMaker resurrects Toshiba T1000 with a Raspberry Pi 4 and a slew of upgrades\n\n<a style=\"position: relative!important;\" href=\"SPONSORED_LINK_URL\">\n<picture>\n<source srcset=\"SPONSORED_IMAGE_URL.webp\" type=\"image/webp\" />\n<img src=\"SPONSORED_IMAGE_URL\" alt=\"SPONSORED_HEADLINE\" loading=\"lazy\"/>\n</picture>\n<span class=\"text-base text-black font-bold mx-0 my-2.5 p-0\">SPONSORED_HEADLINE</span>\n</a>\n\nCommodore 64 gets a true Full-HD HDMI plus stereo sound daughterboard\n\n<a style=\"position: relative!important;\" href=\"SPONSORED_LINK_URL\">\n<picture>\n<source srcset=\"SPONSORED_IMAGE_URL.webp\" type=\"image/webp\" />\n<img src=\"SPONSORED_IMAGE_URL\" alt=\"SPONSORED_HEADLINE\" loading=\"lazy\"/>\n</picture>\n<span class=\"text-base text-black font-bold mx-0 my-2.5 p-0\">SPONSORED_HEADLINE</span>\n</a>\n\nAMD says Intel's 'horrible product' is causing Ryzen 7 9800X3D shortages\n\n<a style=\"position: relative!important;\" href=\"SPONSORED_LINK_URL\">\n<picture>\n<source srcset=\"SPONSORED_IMAGE_URL.webp\" type=\"image/webp\" />\n<img src=\"SPONSORED_IMAGE_URL\" alt=\"SPONSORED_HEADLINE\" loading=\"lazy\"/>\n</picture>\n<span class=\"text-base text-black font-bold mx-0 my-2.5 p-0\">SPONSORED_HEADLINE</span>\n</a>\n\nVendor rolls out two new decade-old Nvidia GT 730 GPUs â€” 2GB and 4GB models, starting at $45\n\n<a style=\"position: relative!important;\" href=\"SPONSORED_LINK_URL\">\n<picture>\n<source srcset=\"SPONSORED_IMAGE_URL.webp\" type=\"image/webp\" />\n<img src=\"SPONSORED_IMAGE_URL\" alt=\"SPONSORED_HEADLINE\" loading=\"lazy\"/>\n</picture>\n<span class=\"text-base text-black font-bold mx-0 my-2.5 p-0\">SPONSORED_HEADLINE</span>\n</a>\n\nRaspberry Pi Pico Spacewar controller brings vintage space combat to the 21st century\n\n<a style=\"position: relative!important;\" href=\"SPONSORED_LINK_URL\">\n<picture>\n<source srcset=\"SPONSORED_IMAGE_URL.webp\" type=\"image/webp\" />\n<img src=\"SPONSORED_IMAGE_URL\" alt=\"SPONSORED_HEADLINE\" loading=\"lazy\"/>\n</picture>\n<span class=\"text-base text-black font-bold mx-0 my-2.5 p-0\">SPONSORED_HEADLINE</span>\n</a>\n\nLatest in Retro Gaming\n\nU.S. Atari parts store still open after 41 years, has spent $100K+ designing new parts â€” last original Atari hardware launched 32 years ago\n\n<a style=\"position: relative!important;\" href=\"SPONSORED_LINK_URL\">\n<picture>\n<source srcset=\"SPONSORED_IMAGE_URL.webp\" type=\"image/webp\" />\n<img src=\"SPONSORED_IMAGE_URL\" alt=\"SPONSORED_HEADLINE\" loading=\"lazy\"/>\n</picture>\n<span class=\"text-base text-black font-bold mx-0 my-2.5 p-0\">SPONSORED_HEADLINE</span>\n</a>\n\nDoom ported to a standalone Microsoft Word document â€” plays well but there's no sound\n\n<a style=\"position: relative!important;\" href=\"SPONSORED_LINK_URL\">\n<picture>\n<source srcset=\"SPONSORED_IMAGE_URL.webp\" type=\"image/webp\" />\n<img src=\"SPONSORED_IMAGE_URL\" alt=\"SPONSORED_HEADLINE\" loading=\"lazy\"/>\n</picture>\n<span class=\"text-base text-black font-bold mx-0 my-2.5 p-0\">SPONSORED_HEADLINE</span>\n</a>\n\nCommodore 64 gets a true Full-HD HDMI plus stereo sound daughterboard\n\n<a style=\"position: relative!important;\" href=\"SPONSORED_LINK_URL\">\n<picture>\n<source srcset=\"SPONSORED_IMAGE_URL.webp\" type=\"image/webp\" />\n<img src=\"SPONSORED_IMAGE_URL\" alt=\"SPONSORED_HEADLINE\" loading=\"lazy\"/>\n</picture>\n<span class=\"text-base text-black font-bold mx-0 my-2.5 p-0\">SPONSORED_HEADLINE</span>\n</a>\n\nAfter 24 years of failure, The Legend of Zelda: Majora's Mask's blue dog has finally won a race\n\n<a style=\"position: relative!important;\" href=\"SPONSORED_LINK_URL\">\n<picture>\n<source srcset=\"SPONSORED_IMAGE_URL.webp\" type=\"image/webp\" />\n<img src=\"SPONSORED_IMAGE_URL\" alt=\"SPONSORED_HEADLINE\" loading=\"lazy\"/>\n</picture>\n<span class=\"text-base text-black font-bold mx-0 my-2.5 p-0\">SPONSORED_HEADLINE</span>\n</a>\n\nThe worldâ€™s smallest arcade machine fits in the palm of your hand â€” Arduino microcontroller powers tiny Pong arcade machine\n\n<a style=\"position: relative!important;\" href=\"SPONSORED_LINK_URL\">\n<picture>\n<source srcset=\"SPONSORED_IMAGE_URL.webp\" type=\"image/webp\" />\n<img src=\"SPONSORED_IMAGE_URL\" alt=\"SPONSORED_HEADLINE\" loading=\"lazy\"/>\n</picture>\n<span class=\"text-base text-black font-bold mx-0 my-2.5 p-0\">SPONSORED_HEADLINE</span>\n</a>\n\nAI-equipped light gun controller brings a retro title to the modern era â€” Play Time Crisis on modern TVs with low input latency\n\n<a style=\"position: relative!important;\" href=\"SPONSORED_LINK_URL\">\n<picture>\n<source srcset=\"SPONSORED_IMAGE_URL.webp\" type=\"image/webp\" />\n<img src=\"SPONSORED_IMAGE_URL\" alt=\"SPONSORED_HEADLINE\" loading=\"lazy\"/>\n</picture>\n<span class=\"text-base text-black font-bold mx-0 my-2.5 p-0\">SPONSORED_HEADLINE</span>\n</a>\n\nLatest in News\n\nIntel and SK hynix close NAND business deal: Intel gets $1.9 billion, SK hynix gets IP and employees\n\n<a style=\"position: relative!important;\" href=\"SPONSORED_LINK_URL\">\n<picture>\n<source srcset=\"SPONSORED_IMAGE_URL.webp\" type=\"image/webp\" />\n<img src=\"SPONSORED_IMAGE_URL\" alt=\"SPONSORED_HEADLINE\" loading=\"lazy\"/>\n</picture>\n<span class=\"text-base text-black font-bold mx-0 my-2.5 p-0\">SPONSORED_HEADLINE</span>\n</a>\n\nNvidia Breakfast Bytes are now available at Denny's if you want to experience the 'breakfast of geniuses'\n\n<a style=\"position: relative!important;\" href=\"SPONSORED_LINK_URL\">\n<picture>\n<source srcset=\"SPONSORED_IMAGE_URL.webp\" type=\"image/webp\" />\n<img src=\"SPONSORED_IMAGE_URL\" alt=\"SPONSORED_HEADLINE\" loading=\"lazy\"/>\n</picture>\n<span class=\"text-base text-black font-bold mx-0 my-2.5 p-0\">SPONSORED_HEADLINE</span>\n</a>\n\nZotac RTX 5090 GPUs with missing ROPs sold at premium price by German retailer\n\n<a style=\"position: relative!important;\" href=\"SPONSORED_LINK_URL\">\n<picture>\n<source srcset=\"SPONSORED_IMAGE_URL.webp\" type=\"image/webp\" />\n<img src=\"SPONSORED_IMAGE_URL\" alt=\"SPONSORED_HEADLINE\" loading=\"lazy\"/>\n</picture>\n<span class=\"text-base text-black font-bold mx-0 my-2.5 p-0\">SPONSORED_HEADLINE</span>\n</a>\n\nTaiwanese authorities accuse SMIC and allies of poaching engineers\n\n<a style=\"position: relative!important;\" href=\"SPONSORED_LINK_URL\">\n<picture>\n<source srcset=\"SPONSORED_IMAGE_URL.webp\" type=\"image/webp\" />\n<img src=\"SPONSORED_IMAGE_URL\" alt=\"SPONSORED_HEADLINE\" loading=\"lazy\"/>\n</picture>\n<span class=\"text-base text-black font-bold mx-0 my-2.5 p-0\">SPONSORED_HEADLINE</span>\n</a>\n\n$3,700 RTX 5090 GPUs have found new homes after sitting on US retailer's shelves\n\n<a style=\"position: relative!important;\" href=\"SPONSORED_LINK_URL\">\n<picture>\n<source srcset=\"SPONSORED_IMAGE_URL.webp\" type=\"image/webp\" />\n<img src=\"SPONSORED_IMAGE_URL\" alt=\"SPONSORED_HEADLINE\" loading=\"lazy\"/>\n</picture>\n<span class=\"text-base text-black font-bold mx-0 my-2.5 p-0\">SPONSORED_HEADLINE</span>\n</a>\n\nNvidia's 50-series laptop launch looks bumpy: slipping ship dates, game crashes, and delayed review units\n\n<a style=\"position: relative!important;\" href=\"SPONSORED_LINK_URL\">\n<picture>\n<source srcset=\"SPONSORED_IMAGE_URL.webp\" type=\"image/webp\" />\n<img src=\"SPONSORED_IMAGE_URL\" alt=\"SPONSORED_HEADLINE\" loading=\"lazy\"/>\n</picture>\n<span class=\"text-base text-black font-bold mx-0 my-2.5 p-0\">SPONSORED_HEADLINE</span>\n</a>\n\nMore about retro gaming\n\nDoom ported to a standalone Microsoft Word document â€” plays well but there's no sound\n\nCommodore 64 gets a true Full-HD HDMI plus stereo sound daughterboard\n\nLatest\n\nDell Pro 14 Plus (P1425) 14-inch portable monitor review: Long on performance, short on value\n\nSee more latest\n\n3 Comments\n\nComment from the forums\n\nJabberwocky79\n\nWhile I wouldn't be in the market for anything, the fact that this exists is dang cool.\n\nReply\n\nAkroZ\n\nIt's a litlle inacurate: Atari Corporation didn't fill for bankruptcy in 1996, they merged with JT Storage, Inc to form JTS Corporation.\nAtari have liquidity but not new product (Jaguar has failed), JTS have stock but issues with liquidity. The merge should have keep the two brands.\nBut just after the merge, JTS fired most Atari staff and selled all the stocks. This was not enought to save JTS as they filled for bankruptcy in 1998.\n\nReply\n\nex_bubblehead\n\nBrad's been a life saver over the years when my 130XE or Mega4 ST (both highly modded) have needed parts or accessories. I think he still has a majority of the stock he bought when Atari shuttered in addition to new products he's introduced over the years. The first printing (and I think the only one to date) of his catalog reads like the old Sears Christmas Wish Book.\n\nReply\n\nView All 3 Comments\n\nMost Popular\n\nNvidia Breakfast Bytes are now available at Denny's if you want to experience the 'breakfast of geniuses'\n\nZotac RTX 5090 GPUs with missing ROPs sold at premium price by German retailer\n\nIntel and SK hynix close NAND business deal: Intel gets $1.9 billion, SK hynix gets IP and employees\n\nTaiwanese authorities accuse SMIC and allies of poaching engineers\n\nNvidia's 50-series laptop launch looks bumpy: slipping ship dates, game crashes, and delayed review units\n\n$3,700 RTX 5090 GPUs have found new homes after sitting on US retailer's shelves\n\nIntel's board gets industry-focused as three directors will not seek re-election â€” badly needed shift to deeper tech experience\n\nChina's AI data center boom goes bust: Rush leaves billions of dollars in idle infrastructure\n\nTSMC to reportedly speed up fab building in the US, third fab to begin construction this year\n\nEx-Intel CEO Gelsinger warns TSMC's $165B investment will not restore U.S. semiconductor leadership\n\nif(FUTR && FUTR.Connect){\n//Init Connect article History\nclass userNav {\nconstructor(key = 'connect_articles_history') {\nthis.key = key;\nthis.flushKey = `${key}_flush`;\nthis.propsKey = `${key}_props`;\nthis.store();\nconsole.info(\"FUTR.Connect.userNav - Init - Start - Using reduxStore\");\n}\nstore() {\nconst isArticle = window?.reduxStore?.getState()?.vanilla?.isArticle;\nif (typeof isArticle !== 'undefined' && isArticle && FUTR && FUTR.Connect) {\ntry {\nconst month = `${new Date().getFullYear()}-${new Date().getMonth()}`;\n//flush monthly\nif (localStorage.getItem(this.flushKey) !== month) {\nlocalStorage.setItem(this.key, btoa('[]'));\nlocalStorage.setItem(this.propsKey, []);\nlocalStorage.setItem(this.flushKey, month);\n}\nconst currentUrl = location.pathname;\nconst urls = JSON.parse(atob(localStorage.getItem(this.key) || btoa('[]')));\nconst props = JSON.parse(localStorage.getItem(this.propsKey)|| '[]');\nif (!urls.includes(currentUrl) && this.getProps().length < 20 || this.getProps().length <1) {\nurls.push(currentUrl);\nif (window.ffte && window.ffte.properties) {\nprops.push(window.ffte.properties);\nconsole.log(\"props push\", props)\n}\nlocalStorage.setItem(this.key, btoa(JSON.stringify(urls)));\nlocalStorage.setItem(this.propsKey, JSON.stringify(props));\n}\nconsole.info(\"FUTR.Connect.userNav - Urls Stored\");\n} catch (e) {\nconsole.warn('userNav:', e);\n}\n}\n}\ngetHistory() {\ntry {\nreturn JSON.parse(atob(localStorage.getItem(this.key) || btoa('[]')));\n} catch {\nreturn [];\n}\n}\ngetProps() {\ntry {\nreturn JSON.parse(localStorage.getItem(this.propsKey) || '[]');\n} catch {\nreturn [];\n}\n}\n};\nFUTR.Connect.userNav = new userNav();\nconsole.info(\"FUTR.Connect.userNav - Init - Done\", FUTR.Connect.userNav);\n}",
    "summary": {
      "en": "**Summary:**\n\nBest Electronics, a U.S. store specializing in Atari parts and accessories, has been operational for 41 years, continuing to support retro gaming enthusiasts. Despite Atari's bankruptcy in 1996 and the last original hardware release being 32 years ago, the store has invested over $100,000 in designing new parts and maintains a stock of over 5,000 popular Atari items. They also have many old products stored from a large purchase made during Atari's liquidation. The store offers exclusive parts and a comprehensive catalog for Atari fans. Their ongoing commitment to retro gaming shows a strong dedication to preserving Atari's legacy.",
      "ko": "Best ElectronicsëŠ” ì•„íƒ€ë¦¬ ë¶€í’ˆê³¼ ì•¡ì„¸ì„œë¦¬ë¥¼ ì „ë¬¸ìœ¼ë¡œ í•˜ëŠ” ë¯¸êµ­ì˜ ìƒì ìœ¼ë¡œ, 41ë…„ ë™ì•ˆ ìš´ì˜ë˜ì–´ ì™”ìŠµë‹ˆë‹¤. ì´ ìƒì ì€ ë ˆíŠ¸ë¡œ ê²Œì„ì„ ì‚¬ë‘í•˜ëŠ” íŒ¬ë“¤ì„ ê³„ì† ì§€ì›í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì•„íƒ€ë¦¬ê°€ 1996ë…„ì— íŒŒì‚°í–ˆìœ¼ë©°, ë§ˆì§€ë§‰ ì›ì¡° í•˜ë“œì›¨ì–´ê°€ ì¶œì‹œëœ ì§€ 32ë…„ì´ ì§€ë‚¬ì§€ë§Œ, ì´ ìƒì ì€ ìƒˆë¡œìš´ ë¶€í’ˆ ì„¤ê³„ì— 10ë§Œ ë‹¬ëŸ¬ ì´ìƒì„ íˆ¬ìí–ˆìŠµë‹ˆë‹¤. í˜„ì¬ 5,000ê°œ ì´ìƒì˜ ì¸ê¸° ì•„íƒ€ë¦¬ ì œí’ˆì„ ë³´ìœ í•˜ê³  ìˆìŠµë‹ˆë‹¤. ë˜í•œ ì•„íƒ€ë¦¬ì˜ ì²­ì‚° ê³¼ì •ì—ì„œ ëŒ€ëŸ‰ìœ¼ë¡œ êµ¬ë§¤í•œ ì˜¤ë˜ëœ ì œí’ˆë“¤ë„ ë§ì´ ì €ì¥ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì´ ìƒì ì€ ì•„íƒ€ë¦¬ íŒ¬ë“¤ì„ ìœ„í•´ ë…ì  ë¶€í’ˆê³¼ í¬ê´„ì ì¸ ì¹´íƒˆë¡œê·¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ë ˆíŠ¸ë¡œ ê²Œì„ì— ëŒ€í•œ ì§€ì†ì ì¸ í—Œì‹ ì€ ì•„íƒ€ë¦¬ì˜ ìœ ì‚°ì„ ë³´ì¡´í•˜ë ¤ëŠ” ê°•í•œ ì˜ì§€ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.",
      "ja": "ã‚¢ãƒ¡ãƒªã‚«ã®ã€Œãƒ™ã‚¹ãƒˆã‚¨ãƒ¬ã‚¯ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹ã€ã¯ã€ã‚¢ã‚¿ãƒªã®éƒ¨å“ã‚„ã‚¢ã‚¯ã‚»ã‚µãƒªãƒ¼ã‚’å°‚é–€ã«æ‰±ã†åº—èˆ—ã§ã€41å¹´é–“ã«ã‚ãŸã‚Šãƒ¬ãƒˆãƒ­ã‚²ãƒ¼ãƒ æ„›å¥½è€…ã‚’æ”¯ãˆã¦ãã¾ã—ãŸã€‚ã‚¢ã‚¿ãƒªã¯1996å¹´ã«ç ´ç”£ã—ã€æœ€å¾Œã®ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã®ç™ºå£²ã‹ã‚‰ã¯32å¹´ãŒçµŒéã—ã¦ã„ã¾ã™ãŒã€ã“ã®åº—èˆ—ã¯æ–°ã—ã„éƒ¨å“ã®è¨­è¨ˆã«10ä¸‡ãƒ‰ãƒ«ä»¥ä¸Šã‚’æŠ•è³‡ã—ã€äººæ°—ã®ã‚ã‚‹ã‚¢ã‚¿ãƒªè£½å“ã‚’5,000ç‚¹ä»¥ä¸Šåœ¨åº«ã—ã¦ã„ã¾ã™ã€‚ã¾ãŸã€ã‚¢ã‚¿ãƒªã®æ¸…ç®—æ™‚ã«è¡Œã£ãŸå¤§è¦æ¨¡ãªè³¼å…¥ã‹ã‚‰ã€å¤šãã®å¤ã„è£½å“ã‚‚ä¿ç®¡ã—ã¦ã„ã¾ã™ã€‚åº—èˆ—ã§ã¯ã‚¢ã‚¿ãƒªãƒ•ã‚¡ãƒ³å‘ã‘ã«ç‹¬è‡ªã®éƒ¨å“ã‚„å……å®Ÿã—ãŸã‚«ã‚¿ãƒ­ã‚°ã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚ãƒ¬ãƒˆãƒ­ã‚²ãƒ¼ãƒ ã¸ã®ç¶™ç¶šçš„ãªå–ã‚Šçµ„ã¿ã¯ã€ã‚¢ã‚¿ãƒªã®éºç”£ã‚’å®ˆã‚‹å¼·ã„æ„å¿—ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚"
    }
  },
  {
    "id": "9a7899558aa612ed",
    "title": {
      "en": "WYGIWYH: A self-hosted simple but powerful finance tracker",
      "ko": "ë‚´ ì†ì•ˆì˜ ì¬ë¬´ ê´€ë¦¬",
      "ja": "è‡ªåˆ†ã§ç®¡ç†ã™ã‚‹å¼·åŠ›ãªå®¶è¨ˆç°¿"
    },
    "type": "story",
    "url": "https://github.com/eitchtee/WYGIWYH",
    "score": 12,
    "by": "indigodaddy",
    "time": 1743272195,
    "content": "WYGIWYH\n\nAn opinionated and powerful finance tracker.\n\n  Why â€¢\n  Features â€¢\n  Usage â€¢\n  How â€¢\n  Translate â€¢\n  Caveats and Warnings â€¢\n  Built with\n\nWYGIWYH (What You Get Is What You Have) is a powerful, principles-first finance tracker designed for people who prefer a no-budget, straightforward approach to managing their money. With features like multi-currency support, customizable transactions, and a built-in dollar-cost averaging tracker, WYGIWYH helps you take control of your finances with simplicity and flexibility.\n\nWhy WYGIWYH?\nManaging money can feel unnecessarily complex, but it doesnâ€™t have to be. WYGIWYH (pronounced \"wiggy-wih\") is based on a simple principle:\n\nUse what you earn this month for this month. Any savings are tracked but treated as untouchable for future months.\n\nBy sticking to this straightforward approach, you avoid dipping into your savings while still keeping tabs on where your money goes.\nWhile this philosophy is simple, finding tools to make it work wasnâ€™t. I initially used a spreadsheet, which served me well for yearsâ€”until it became unwieldy as I started managing multiple currencies, accounts, and investments. I tried various financial management apps, but none met my key requirements:\n\nMulti-currency support to track income and expenses in different currencies.\nNot a budgeting app â€” as I dislike budgeting constraints.\nWeb app usability (ideally with mobile support, though optional).\nAutomation-ready API to integrate with other tools and services.\nCustom transaction rules for credit card billing cycles or similar quirks.\n\nFrustrated by the lack of comprehensive options, I set out to build WYGIWYH â€” an opinionated yet powerful tool that I believe will resonate with like-minded users.\nKey Features\nWYGIWYH offers an array of features designed to simplify and streamline your personal finance tracking:\n\nUnified transaction tracking: Record all your income and expenses, organized in one place.\nMultiple accounts support: Keep track of where your money and assets are stored (banks, wallets, investments, etc.).\nOut-of-the-box multi-currency support: Dynamically manage transactions and balances in different currencies.\nCustom currencies: Create your own currencies for crypto, rewards points, or any other models.\nAutomated adjustments with rules: Automatically modify transactions using customizable rules.\nBuilt-in Dollar-Cost Average (DCA) tracker: Essential for tracking recurring investments, especially for crypto and stocks.\nAPI support for automation: Seamlessly integrate with existing services to synchronize transactions.\n\nHow To Use\nTo run this application, you'll need Docker with docker-compose.\nFrom your command line:\n# Create a folder for WYGIWYH (optional)\n$ mkdir WYGIWYH\n\n# Go into the folder\n$ cd WYGIWYH\n\n$ touch docker-compose.yml\n$ nano docker-compose.yml\n# Paste the contents of https://github.com/eitchtee/WYGIWYH/blob/main/docker-compose.prod.yml and edit according to your needs\n\n# Fill the .env file with your configurations\n$ touch .env\n$ nano .env # or any other editor you want to use\n# Paste the contents of https://github.com/eitchtee/WYGIWYH/blob/main/.env.example and edit accordingly\n\n# Run the app\n$ docker compose up -d\n\n# Create the first admin account\n$ docker compose exec -it web python manage.py createsuperuser\n\nNoteIf you're using Unraid, you don't need to follow these steps, use the app on the store. Make sure to read the Unraid section and Environment Variables for an explanation of all available variables\n\nRunning locally\nIf you want to run WYGIWYH locally, on your env file:\n\nRemove URL\nSet HTTPS_ENABLED to false\nLeave the default DJANGO_ALLOWED_HOSTS (localhost 127.0.0.1 [::1])\n\nYou can now access localhost:OUTBOUND_PORT\nNote\n\nIf you're planning on running this behind Tailscale or other similar service also add your machine given IP to DJANGO_ALLOWED_HOSTS\nIf you're going to use another IP that isn't localhost, add it to DJANGO_ALLOWED_HOSTS, without http://\n\nLatest changes\nFeatures are only added to main when ready, if you want to run the latest version, you must build from source or use the :nightly tag on docker. Keep in mind that there can be undocumented breaking changes.\nAll the required Dockerfiles are here.\nUnraid\nnwithan8 has kindly provided a Unraid template for WYGIWYH, have a look at the unraid_templates repo.\nWYGIWYH is available on the Unraid Store. You'll need to provision your own postgres (version 15 or up) database.\nTo create the first user, open the container's console using Unraid's UI, by clicking on WYGIWYH icon on the Docker page and selecting Console, then type python manage.py createsuperuser, you'll them be prompted to input your e-mail and password.\nEnvironment Variables\n\nvariable\ntype\ndefault\nexplanation\n\nDJANGO_ALLOWED_HOSTS\nstring\nlocalhost 127.0.0.1\nA list of space separated domains and IPs representing the host/domain names that WYGIWYH site can serve. Click here for more details\n\nHTTPS_ENABLED\ntrue|false\nfalse\nWhether to use secure cookies. If this is set to true, the cookie will be marked as â€œsecureâ€, which means browsers may ensure that the cookie is only sent under an HTTPS connection\n\nURL\nstring\nhttp://localhost http://127.0.0.1\nA list of space separated domains and IPs (with the protocol) representing the trusted origins for unsafe requests (e.g. POST). Click here for more details\n\nSECRET_KEY\nstring\n\"\"\nThis is used to provide cryptographic signing, and should be set to a unique, unpredictable value.\n\nDEBUG\ntrue|false\nfalse\nTurns DEBUG mode on or off, this is useful to gather more data about possible errors you're having. Don't use in production.\n\nSQL_DATABASE\nstring\nNone *required\nThe name of your postgres database\n\nSQL_USER\nstring\nuser\nThe username used to connect to your postgres database\n\nSQL_PASSWORD\nstring\npassword\nThe password used to connect to your postgres database\n\nSQL_HOST\nstring\nlocalhost\nThe address used to connect to your postgres database\n\nSQL_PORT\nstring\n5432\nThe port used to connect to your postgres database\n\nSESSION_EXPIRY_TIME\nint\n2678400 (31 days)\nThe age of session cookies, in seconds. E.g. how long you will stay logged in\n\nENABLE_SOFT_DELETE\ntrue|false\nfalse\nWhether to enable transactions soft delete, if enabled, deleted transactions will remain in the database. Useful for imports and avoiding duplicate entries.\n\nKEEP_DELETED_TRANSACTIONS_FOR\nint\n365\nTime in days to keep soft deleted transactions for. If 0, will keep all transactions indefinitely. Only works if ENABLE_SOFT_DELETE is true.\n\nTASK_WORKERS\nint\n1\nHow many workers to have for async tasks. One should be enough for most use cases\n\nHow it works\nCheck out our Wiki for more information.\nHelp us translate WYGIWYH!\n\nNoteLogin with your github account\n\nCaveats and Warnings\n\nI'm not an accountant, some terms and even calculations might be wrong. Make sure to open an issue if you see anything that could be improved.\nPretty much all calculations are done at run time, this can lead to some performance degradation. On my personal instance, I have 3000+ transactions over 4+ years and 4000+ exchange rates, and load times average at around 500ms for each page, not bad overall.\nThis isn't a budgeting or double-entry-accounting application, if you need those features there's a lot of options out there, if you really need them in WYGIWYH, open a discussion.\n\nBuilt with\nWYGIWYH is possible thanks to a lot of amazing open source tools, to name a few:\n\nDjango\nHTMX\n_hyperscript\nProcrastinate\nBootstrap\nTailwind\nWebpack\nPostgreSQL\nDjango REST framework\nAlpine.js",
    "summary": {
      "en": "**WYGIWYH Summary**\n\nWYGIWYH (What You Get Is What You Have) is a simple and effective finance tracker for people who want an easy way to manage their money without budgeting. It focuses on using your current month's earnings for expenses, treating any savings as untouchable for future use.\n\n**Key Features:**\n- **Unified Transaction Tracking:** Keep all income and expenses in one place.\n- **Multi-Account Support:** Track money across various accounts like banks and investments.\n- **Multi-Currency Management:** Handle transactions in different currencies easily.\n- **Custom Currencies:** Create currencies for rewards points or cryptocurrencies.\n- **Automated Adjustments:** Use rules to modify transactions automatically.\n- **Dollar-Cost Average Tracker:** Useful for tracking regular investments in stocks or crypto.\n- **API Support:** Integrate with other services for automation.\n\n**Usage Instructions:**\nTo use WYGIWYH, you need Docker. After setting up the necessary files and configurations, you can run the application and create an admin account.\n\n**Caveats:**\n- The creator is not a financial expert, so some calculations may be off.\n- The app is not designed for budgeting or double-entry accounting. \n\n**Built With:**\nWYGIWYH utilizes various open-source tools, including Django, PostgreSQL, and Bootstrap, to enhance its functionality.",
      "ko": "WYGIWYH(ë‹¹ì‹ ì´ ì–»ëŠ” ê²ƒì´ ë‹¹ì‹ ì´ ê°€ì§„ ê²ƒì´ë‹¤)ëŠ” ì˜ˆì‚° ì—†ì´ ì‰½ê²Œ ëˆì„ ê´€ë¦¬í•˜ê³  ì‹¶ì€ ì‚¬ëŒë“¤ì„ ìœ„í•œ ê°„ë‹¨í•˜ê³  íš¨ê³¼ì ì¸ ì¬ë¬´ ì¶”ì ê¸°ì…ë‹ˆë‹¤. ì´ ì•±ì€ í˜„ì¬ ë‹¬ì˜ ìˆ˜ì…ì„ ì§€ì¶œì— ì‚¬ìš©í•˜ëŠ” ë° ì¤‘ì ì„ ë‘ë©°, ì €ì¶•ì€ ë¯¸ë˜ ì‚¬ìš©ì„ ìœ„í•´ ì†ëŒ€ì§€ ì•ŠëŠ” ê²ƒìœ¼ë¡œ ê°„ì£¼í•©ë‹ˆë‹¤.\n\nì£¼ìš” ê¸°ëŠ¥ìœ¼ë¡œëŠ” ëª¨ë“  ìˆ˜ì…ê³¼ ì§€ì¶œì„ í•œ ê³³ì—ì„œ ê´€ë¦¬í•  ìˆ˜ ìˆëŠ” í†µí•© ê±°ë˜ ì¶”ì , ì€í–‰ ë° íˆ¬ìì™€ ê°™ì€ ë‹¤ì–‘í•œ ê³„ì¢Œì—ì„œ ëˆì„ ì¶”ì í•  ìˆ˜ ìˆëŠ” ë‹¤ì¤‘ ê³„ì¢Œ ì§€ì›, ì—¬ëŸ¬ í†µí™”ë¡œ ê±°ë˜ë¥¼ ì‰½ê²Œ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ë‹¤ì¤‘ í†µí™” ê´€ë¦¬, ë³´ìƒ í¬ì¸íŠ¸ë‚˜ ì•”í˜¸í™”íë¥¼ ìœ„í•œ ì‚¬ìš©ì ì •ì˜ í†µí™” ìƒì„±, ê·œì¹™ì„ ì‚¬ìš©í•´ ê±°ë˜ë¥¼ ìë™ìœ¼ë¡œ ìˆ˜ì •í•˜ëŠ” ìë™ ì¡°ì • ê¸°ëŠ¥, ì •ê¸°ì ì¸ ì£¼ì‹ì´ë‚˜ ì•”í˜¸í™”í íˆ¬ì ì¶”ì ì— ìœ ìš©í•œ ë‹¬ëŸ¬ ë¹„ìš© í‰ê·  ì¶”ì ê¸°, ë‹¤ë¥¸ ì„œë¹„ìŠ¤ì™€ì˜ í†µí•©ì„ ìœ„í•œ API ì§€ì›ì´ ìˆìŠµë‹ˆë‹¤.\n\nWYGIWYHë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ Dockerê°€ í•„ìš”í•©ë‹ˆë‹¤. í•„ìš”í•œ íŒŒì¼ê³¼ ì„¤ì •ì„ ë§ˆì¹œ í›„ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì‹¤í–‰í•˜ê³  ê´€ë¦¬ì ê³„ì •ì„ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nì£¼ì˜í•  ì ì€ ì´ ì•±ì˜ ì œì‘ìê°€ ê¸ˆìœµ ì „ë¬¸ê°€ê°€ ì•„ë‹ˆê¸° ë•Œë¬¸ì— ì¼ë¶€ ê³„ì‚°ì´ ì •í™•í•˜ì§€ ì•Šì„ ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤. ë˜í•œ ì´ ì•±ì€ ì˜ˆì‚° ê´€ë¦¬ë‚˜ ë³µì‹ ë¶€ê¸°ìš©ìœ¼ë¡œ ì„¤ê³„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n\nWYGIWYHëŠ” Django, PostgreSQL, Bootstrap ë“± ë‹¤ì–‘í•œ ì˜¤í”ˆ ì†ŒìŠ¤ ë„êµ¬ë¥¼ í™œìš©í•˜ì—¬ ê¸°ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê³  ìˆìŠµë‹ˆë‹¤.",
      "ja": "WYGIWYHï¼ˆãƒ¯ã‚¤ã‚®ãƒ¯ã‚¤ã‚¨ã‚¤ãƒï¼‰ã¯ã€äºˆç®—ã‚’ç«‹ã¦ãšã«ãŠé‡‘ã‚’ç®¡ç†ã—ãŸã„äººã®ãŸã‚ã®ã‚·ãƒ³ãƒ—ãƒ«ã§åŠ¹æœçš„ãªãƒ•ã‚¡ã‚¤ãƒŠãƒ³ã‚¹ãƒˆãƒ©ãƒƒã‚«ãƒ¼ã§ã™ã€‚ã“ã®ã‚¢ãƒ—ãƒªã¯ã€ä»Šæœˆã®åå…¥ã‚’ä½¿ã£ã¦æ”¯å‡ºã‚’ç®¡ç†ã—ã€è²¯è“„ã¯å°†æ¥ã®ãŸã‚ã«æ‰‹ã‚’ä»˜ã‘ãªã„ã‚‚ã®ã¨ã—ã¦æ‰±ã„ã¾ã™ã€‚\n\nä¸»ãªæ©Ÿèƒ½ã«ã¯ã€ã™ã¹ã¦ã®åå…¥ã¨æ”¯å‡ºã‚’ä¸€å…ƒç®¡ç†ã§ãã‚‹ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³è¿½è·¡ã€éŠ€è¡Œã‚„æŠ•è³‡ãªã©è¤‡æ•°ã®å£åº§ã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹æ©Ÿèƒ½ã€ç•°ãªã‚‹é€šè²¨ã§ã®å–å¼•ã‚’ç°¡å˜ã«æ‰±ãˆã‚‹ãƒãƒ«ãƒé€šè²¨ç®¡ç†ã€ãƒã‚¤ãƒ³ãƒˆã‚„æš—å·é€šè²¨ã®ãŸã‚ã®ã‚«ã‚¹ã‚¿ãƒ é€šè²¨ä½œæˆã€ãƒ«ãƒ¼ãƒ«ã‚’ä½¿ã£ã¦è‡ªå‹•çš„ã«ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã‚’èª¿æ•´ã™ã‚‹æ©Ÿèƒ½ã€å®šæœŸçš„ãªæ ªå¼ã‚„æš—å·é€šè²¨ã¸ã®æŠ•è³‡ã‚’è¿½è·¡ã™ã‚‹ãŸã‚ã®ãƒ‰ãƒ«ã‚³ã‚¹ãƒˆå¹³å‡è¿½è·¡æ©Ÿèƒ½ã€ä»–ã®ã‚µãƒ¼ãƒ“ã‚¹ã¨ã®çµ±åˆã‚’å¯èƒ½ã«ã™ã‚‹APIã‚µãƒãƒ¼ãƒˆãŒã‚ã‚Šã¾ã™ã€‚\n\nWYGIWYHã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯ã€DockerãŒå¿…è¦ã§ã™ã€‚å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã¨è¨­å®šã‚’æ•´ãˆãŸå¾Œã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œã—ã€ç®¡ç†è€…ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’ä½œæˆã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚\n\næ³¨æ„ç‚¹ã¨ã—ã¦ã€é–‹ç™ºè€…ã¯é‡‘èã®å°‚é–€å®¶ã§ã¯ãªã„ãŸã‚ã€è¨ˆç®—ã«èª¤ã‚ŠãŒã‚ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚ã¾ãŸã€ã“ã®ã‚¢ãƒ—ãƒªã¯äºˆç®—ç®¡ç†ã‚„è¤‡å¼ç°¿è¨˜ã«ã¯å¯¾å¿œã—ã¦ã„ã¾ã›ã‚“ã€‚\n\nWYGIWYHã¯ã€Djangoã€PostgreSQLã€Bootstrapãªã©ã®ã•ã¾ã–ã¾ãªã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ„ãƒ¼ãƒ«ã‚’æ´»ç”¨ã—ã¦æ©Ÿèƒ½ã‚’å‘ä¸Šã•ã›ã¦ã„ã¾ã™ã€‚"
    }
  },
  {
    "id": "dfcf703c332dca61",
    "title": {
      "en": "Mathematical Compact Models of Advanced Transistors [pdf]",
      "ko": "ì²¨ë‹¨ íŠ¸ëœì§€ìŠ¤í„° ìˆ˜í•™ ëª¨ë¸",
      "ja": "å…ˆé€²ãƒˆãƒ©ãƒ³ã‚¸ã‚¹ã‚¿ã®æ•°ç†ãƒ¢ãƒ‡ãƒ«"
    },
    "type": "story",
    "url": "https://www2.eecs.berkeley.edu/Pubs/TechRpts/2018/EECS-2018-24.pdf",
    "score": 79,
    "by": "nill0",
    "time": 1743231488,
    "content": "Mathematical Compact Models of Advanced Transistors for Numerical Simulation and Hardware Design  Juan Duarte Electrical Engineering and Computer Sciences University of California at Berkeley  Technical Report No. UCB/EECS-2018-24 http://www2.eecs.berkeley.edu/Pubs/TechRpts/2018/EECS-2018-24.html  May 2, 2018\n\nCopyright Â© 2018, by the author(s). All rights reserved.  Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission.\n\nMathematical Compact Models of Advanced Transistors for Numerical Simulation and Hardware Design  by Juan Pablo Duarte Sepulveda A dissertation submitted in partial satisfaction of the requirements for the degree of Doctor of Philosophy in Engineering - Electrical Engineering and Computer Sciences in the Graduate Division of the University of California, Berkeley Committee in charge: Dr. Chenming Hu, Chair Dr. Ali M. Niknejad Dr. Tarek Zohdi Spring 2018\n\nMathematical Compact Models of Advanced Transistors for Numerical Simulation and Hardware Design Copyright   c Â©   2018 by Juan Pablo Duarte Sepulveda\n\n1  Abstract  Mathematical Compact Models of Advanced Transistors for Numerical Simulation and Hardware Design by Juan Pablo Duarte Sepulveda Doctor of Philosophy in Engineering - Electrical Engineering and Computer Sciences University of California, Berkeley Dr. Chenming Hu, Chair Mathematical compact models play a key role in designing integrated circuits. They serve as a medium of information exchange between foundries and designers.   A compact model, which is a set of long mathematical equations based on the physics of each transistor, is capable of reproducing the very complex transistor characteristics in an accurately, fast, and robust manner. This dissertation presents the latest research on compact models for advanced transistor technologies: FinFETs, Ultra-thin body SOIs (UTBSOIs), Gate-All-Around (GAA) FETs, and Negative Capacitance (NC) FETs. Since traditional transistor scaling had reached limitations due short-channel effects and oxide tunneling, the introduction of FinFET and UTBSOIs in high-volume manufacturing at 20nm, 14nm and 10nm technology nodes had let the electronic industry to keep obtaining performance and density advantages in technology scaling. For smaller nodes such as 5nm, and 3nm, GAA FETs transistors are expected to replace traditional transistors.   Production ready compact model for current and future FinFETs are presented in this thesis. The Unified Compact Model can model FinFETs with realistic fin shapes including rectangle, triangle, circle and any shape in between. A new quantum effects model will also be presented, it enables accurate modeling of III-V FinFETs. Shape agnostic short-channel effect model for aggressive  L G   scaling and body bias model for FinFETs on bulk substrates are also included in this work.   This computationally efficient model is an ideal turn-key solution for simulation and design of future heterogeneous circuits. For extremely scaled technologies, NC-FETs are quickly emerging as preferred candidates for digital and analog applications. The recent discovery of ferroelectric (FE) materials using conventional CMOS fabrication technology has led to the first demonstrations of FE based NC-FETs. The ferroelectric material layer added over the transistor gate insulator help in several device aspects, it suppress short-channel effects, increase on-current due voltage amplification, increase output resistance in short-channel devices, etc.   These exciting characteristics has created an urgency\n\n2 for analysis and understanding of device operation and circuit performance, where numerical simulation and compact models are playing a key role. This thesis gives insights into the device physics and behavior of FE based nega- tive capacitance FinFETs (NC-FinFETs) by presenting numerical simulations, com- pact models, and circuit evaluation of these devices. NC-FinFETs may have a floating metal between FE and the dielectric layers, where a lumped charge model represents such a device.   For a NC-FinFET without a floating metal, the distributed charge model should be used, and at each point in the channel the FE layer will impact the local channel charge.   This distributed effect has important implications on device characteristics.   These device differences are explained using numerical simulation and correctly captured by the proposed compact models.   The presented compact models have been implemented in commercial circuit simulators for exploring circuits based on NC-FinFET technology.   Circuit simulations show that a quasi-adiabatic mechanism of the ferroelectric layer in the NC-FinFET recovers part of the energy during the switching process of transistors, helping to minimize the energy losses of the wasteful energy dissipation nature of conventional transistor circuits. As circuit load capacitances further increase,   V DD   scaling becomes more dominant on energy reduction of NC-FinFET based circuits.\n\ni To my family: Past, Present and Future.\n\nContents  Contents   ii List of Figures   v List of Tables   xvi 1   Introduction   1  1.1   Mathematical Models for FinFETs and UTBSOIs   . . . . . . . . . . .   3 1.2   Negative Capacitances FETs . . . . . . . . . . . . . . . . . . . . . . .   6  2   Model for Double-Gate FinFETs   10  2.1   Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   10 2.2   Model Derivation   . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   12 2.3   Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   18  3   Unified FinFET Compact Model   19  3.1   Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   19 3.2   Core Model   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   20 3.3   Global Scaling Model   . . . . . . . . . . . . . . . . . . . . . . . . . .   30 3.4   Speed Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   33 3.5   Benchmark Tests   . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   33 3.6   Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   33  4   Variability Modeling   38  4.1   Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   38 4.2   Description of the Unified Model   . . . . . . . . . . . . . . . . . . . .   39 4.3   Device Simulation and Model Parameter Set Up . . . . . . . . . . . .   41 4.4   10nm vs. 14nm Variability Using Predictive Modeling   . . . . . . . .   41 4.5   14nm Node SRAM Variability Evaluation   . . . . . . . . . . . . . . .   44 4.6   Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   45\n\niii  5   Model for Independent Gate MOSFETs   49  5.1   Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   49 5.2   Independent Multi-Gate MOSFETs . . . . . . . . . . . . . . . . . . .   50 5.3   Core Model   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   52 5.4   Initial Guess . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   55 5.5   Iteration Update   . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   59 5.6   Complete Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   63 5.7   Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   63  6   Model for Negative Capacitance FETs   67  6.1   Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   67 6.2   Unified Compact Model   . . . . . . . . . . . . . . . . . . . . . . . . .   67 6.3   Ferroelectric Material Model . . . . . . . . . . . . . . . . . . . . . . .   68 6.4   Lumped NC-FinFET Model   . . . . . . . . . . . . . . . . . . . . . . .   70 6.5   Distributed NC-FinFET Model   . . . . . . . . . . . . . . . . . . . . .   71 6.6   Lumped versus Distributed NC-FinFETs . . . . . . . . . . . . . . . .   76 6.7   Time-Dependent Ferroelectric Model   . . . . . . . . . . . . . . . . . .   76 6.8   Model Robustness . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   78 6.9   Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   78  7   Numerical Simulation of Negative Capacitance FETs   81  7.1   Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   81 7.2   Quasi 2-Dimensional NC-FET Simulation . . . . . . . . . . . . . . . .   82 7.3   NC-FET   L G   Scaling   . . . . . . . . . . . . . . . . . . . . . . . . . . .   83 7.4   NC-FET with Low Coercive Field: lowering effective EOT   . . . . . .   86  8   Energy Analysis of Negative Capacitance FETs   93  8.1   Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   93 8.2   SPICE Model for NCFETs . . . . . . . . . . . . . . . . . . . . . . . .   94 8.3   Single NC-FinFET Energy Simulation Analysis   . . . . . . . . . . . .   95 8.4   NC-FinFET Ring-Oscillator Analysis   . . . . . . . . . . . . . . . . . .   99 8.5   Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   104  9   Summary   106  9.1   Chapters Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . .   106 9.2   Future Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   107  A   1D Numerical Simulation of Symmetric FinFET   117 B   Explicit Surface Potential Model   121  B.1   Continuous Starting Function   . . . . . . . . . . . . . . . . . . . . . .   121 B.2   Quartic Modified Iteration: Implementation and Evaluation   . . . . .   124\n\niv  C   Unified Model Implementation in Verilog-A   130 D   1D Numerical Simulation for UTBSOIs   132 E   Energy Calculation with Hspice   137",
    "summary": {
      "en": "The dissertation \"Mathematical Compact Models of Advanced Transistors for Numerical Simulation and Hardware Design\" by Juan Duarte explores the development of compact models for advanced transistors used in integrated circuit design. These models are essential for communication between semiconductor manufacturers and circuit designers, facilitating the simulation of complex transistor behavior.\n\nKey points include:\n\n1. **Importance of Compact Models**: These mathematical models help accurately and efficiently simulate the characteristics of various types of advanced transistors, such as FinFETs, Ultra-thin body SOIs, and Negative Capacitance FETs.\n\n2. **Advancements in Transistor Technology**: As traditional transistors face limitations, new technologies like FinFETs and UTBSOIs are being used in manufacturing for smaller technology nodes (20nm, 14nm, 10nm). GAA FETs are anticipated to become the standard for even smaller nodes (5nm, 3nm).\n\n3. **Unified Compact Model**: The dissertation introduces a comprehensive model for FinFETs that accommodates various fin shapes and includes methods for accurately modeling quantum effects and short-channel behaviors.\n\n4. **Negative Capacitance FETs**: These emerging devices utilize ferroelectric materials to enhance performance, such as reducing short-channel effects and improving energy efficiency. The dissertation provides insights into the physics and simulation of these devices.\n\n5. **Numerical Simulations and Circuit Evaluations**: The proposed models have been implemented in commercial circuit simulators, demonstrating their potential to improve energy efficiency in circuits, particularly as device sizes decrease.\n\nOverall, the work aims to contribute to the understanding and application of advanced transistor technologies in future electronic designs.",
      "ko": "í›„ì•ˆ ë‘ì•„ë¥´íŠ¸ì˜ ë…¼ë¬¸ \"ìˆ˜ì¹˜ ì‹œë®¬ë ˆì´ì…˜ ë° í•˜ë“œì›¨ì–´ ì„¤ê³„ë¥¼ ìœ„í•œ ê³ ê¸‰ íŠ¸ëœì§€ìŠ¤í„°ì˜ ìˆ˜í•™ì  ì••ì¶• ëª¨ë¸\"ì€ ì§‘ì  íšŒë¡œ ì„¤ê³„ì— ì‚¬ìš©ë˜ëŠ” ê³ ê¸‰ íŠ¸ëœì§€ìŠ¤í„°ì˜ ì••ì¶• ëª¨ë¸ ê°œë°œì„ ë‹¤ë£¹ë‹ˆë‹¤. ì´ëŸ¬í•œ ëª¨ë¸ì€ ë°˜ë„ì²´ ì œì¡°ì—…ì²´ì™€ íšŒë¡œ ì„¤ê³„ì ê°„ì˜ ì›í™œí•œ ì†Œí†µì„ ìœ„í•´ í•„ìˆ˜ì ì´ë©°, ë³µì¡í•œ íŠ¸ëœì§€ìŠ¤í„° ë™ì‘ì„ ì‹œë®¬ë ˆì´ì…˜í•˜ëŠ” ë° ë„ì›€ì„ ì¤ë‹ˆë‹¤.\n\nì••ì¶• ëª¨ë¸ì˜ ì¤‘ìš”ì„±ì´ ê°•ì¡°ë©ë‹ˆë‹¤. ì´ëŸ¬í•œ ìˆ˜í•™ì  ëª¨ë¸ì€ FinFET, ì´ˆë°•í˜• SOI, ìŒì „í•˜ ì»¤íŒ¨ì‹œí„´ìŠ¤ FETì™€ ê°™ì€ ë‹¤ì–‘í•œ ê³ ê¸‰ íŠ¸ëœì§€ìŠ¤í„°ì˜ íŠ¹ì„±ì„ ì •í™•í•˜ê³  íš¨ìœ¨ì ìœ¼ë¡œ ì‹œë®¬ë ˆì´ì…˜í•˜ëŠ” ë° ê¸°ì—¬í•©ë‹ˆë‹¤. ì „í†µì ì¸ íŠ¸ëœì§€ìŠ¤í„°ê°€ í•œê³„ë¥¼ ê²ªê³  ìˆëŠ” ê°€ìš´ë°, FinFETì™€ UTBSOIì™€ ê°™ì€ ìƒˆë¡œìš´ ê¸°ìˆ ì´ ë” ì‘ì€ ê¸°ìˆ  ë…¸ë“œ(20nm, 14nm, 10nm) ì œì¡°ì— ì‚¬ìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤. GAA FETëŠ” ë” ì‘ì€ ë…¸ë“œ(5nm, 3nm)ì—ì„œ í‘œì¤€ì´ ë  ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤.\n\nì´ ë…¼ë¬¸ì€ ë‹¤ì–‘í•œ í•€ ëª¨ì–‘ì„ ìˆ˜ìš©í•  ìˆ˜ ìˆëŠ” FinFETì— ëŒ€í•œ í¬ê´„ì ì¸ ëª¨ë¸ì„ ì†Œê°œí•˜ë©°, ì–‘ì íš¨ê³¼ì™€ ì§§ì€ ì±„ë„ ë™ì‘ì„ ì •í™•í•˜ê²Œ ëª¨ë¸ë§í•˜ëŠ” ë°©ë²•ë„ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ìŒì „í•˜ ì»¤íŒ¨ì‹œí„´ìŠ¤ FETëŠ” ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ ê°•ìœ ì „ ë¬¼ì§ˆì„ í™œìš©í•˜ì—¬ ì§§ì€ ì±„ë„ íš¨ê³¼ë¥¼ ì¤„ì´ê³  ì—ë„ˆì§€ íš¨ìœ¨ì„±ì„ ê°œì„ í•©ë‹ˆë‹¤. ì´ ë…¼ë¬¸ì€ ì´ëŸ¬í•œ ì¥ì¹˜ì˜ ë¬¼ë¦¬í•™ê³¼ ì‹œë®¬ë ˆì´ì…˜ì— ëŒ€í•œ í†µì°°ì„ ì œê³µí•©ë‹ˆë‹¤.\n\nì œì•ˆëœ ëª¨ë¸ì€ ìƒìš© íšŒë¡œ ì‹œë®¬ë ˆì´í„°ì— êµ¬í˜„ë˜ì–´, ì¥ì¹˜ í¬ê¸°ê°€ ì¤„ì–´ë“¤ìˆ˜ë¡ íšŒë¡œì˜ ì—ë„ˆì§€ íš¨ìœ¨ì„±ì„ ê°œì„ í•  ìˆ˜ ìˆëŠ” ê°€ëŠ¥ì„±ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” í–¥í›„ ì „ì ì„¤ê³„ì—ì„œ ê³ ê¸‰ íŠ¸ëœì§€ìŠ¤í„° ê¸°ìˆ ì˜ ì´í•´ì™€ ì ìš©ì— ê¸°ì—¬í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•˜ê³  ìˆìŠµë‹ˆë‹¤.",
      "ja": "ãƒ•ã‚¢ãƒ³ãƒ»ãƒ‡ãƒ¥ã‚¢ãƒ«ãƒ†ã®è«–æ–‡ã€Œæ•°å€¤ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¨ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢è¨­è¨ˆã®ãŸã‚ã®å…ˆé€²ãƒˆãƒ©ãƒ³ã‚¸ã‚¹ã‚¿ã®æ•°å­¦çš„ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆãƒ¢ãƒ‡ãƒ«ã€ã§ã¯ã€é›†ç©å›è·¯è¨­è¨ˆã«ä½¿ç”¨ã•ã‚Œã‚‹å…ˆé€²ãƒˆãƒ©ãƒ³ã‚¸ã‚¹ã‚¿ã®ãŸã‚ã®ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆãƒ¢ãƒ‡ãƒ«ã®é–‹ç™ºã«ã¤ã„ã¦æ¢æ±‚ã—ã¦ã„ã¾ã™ã€‚ã“ã‚Œã‚‰ã®ãƒ¢ãƒ‡ãƒ«ã¯ã€åŠå°ä½“ãƒ¡ãƒ¼ã‚«ãƒ¼ã¨å›è·¯è¨­è¨ˆè€…ã®é–“ã®ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å††æ»‘ã«ã—ã€è¤‡é›‘ãªãƒˆãƒ©ãƒ³ã‚¸ã‚¹ã‚¿ã®æŒ™å‹•ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã™ã‚‹ãŸã‚ã«ä¸å¯æ¬ ã§ã™ã€‚\n\né‡è¦ãªãƒã‚¤ãƒ³ãƒˆã¨ã—ã¦ã€ã¾ãšã‚³ãƒ³ãƒ‘ã‚¯ãƒˆãƒ¢ãƒ‡ãƒ«ã®é‡è¦æ€§ãŒã‚ã‚Šã¾ã™ã€‚ã“ã‚Œã‚‰ã®æ•°å­¦çš„ãƒ¢ãƒ‡ãƒ«ã¯ã€FinFETã‚„è¶…è–„å‹ãƒœãƒ‡ã‚£SOIã€è² ã‚­ãƒ£ãƒ‘ã‚·ã‚¿ãƒ³ã‚¹FETãªã©ã€ã•ã¾ã–ã¾ãªã‚¿ã‚¤ãƒ—ã®å…ˆé€²ãƒˆãƒ©ãƒ³ã‚¸ã‚¹ã‚¿ã®ç‰¹æ€§ã‚’æ­£ç¢ºã‹ã¤åŠ¹ç‡çš„ã«ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã™ã‚‹ã®ã«å½¹ç«‹ã¡ã¾ã™ã€‚\n\næ¬¡ã«ã€ãƒˆãƒ©ãƒ³ã‚¸ã‚¹ã‚¿æŠ€è¡“ã®é€²å±•ã«ã¤ã„ã¦è§¦ã‚Œã¾ã™ã€‚å¾“æ¥ã®ãƒˆãƒ©ãƒ³ã‚¸ã‚¹ã‚¿ã«ã¯é™ç•ŒãŒã‚ã‚‹ãŸã‚ã€FinFETã‚„UTBSOIã®ã‚ˆã†ãªæ–°ã—ã„æŠ€è¡“ãŒã€20nmã€14nmã€10nmã¨ã„ã£ãŸå°ã•ãªæŠ€è¡“ãƒãƒ¼ãƒ‰ã®è£½é€ ã«ä½¿ç”¨ã•ã‚Œã¦ã„ã¾ã™ã€‚ã•ã‚‰ã«ã€GAA FETã¯ã€5nmã‚„3nmã¨ã„ã£ãŸã•ã‚‰ã«å°ã•ãªãƒãƒ¼ãƒ‰ã®æ¨™æº–ã«ãªã‚‹ã¨æœŸå¾…ã•ã‚Œã¦ã„ã¾ã™ã€‚\n\nè«–æ–‡ã§ã¯ã€ã•ã¾ã–ã¾ãªãƒ•ã‚£ãƒ³å½¢çŠ¶ã«å¯¾å¿œã—ãŸFinFETã®åŒ…æ‹¬çš„ãªãƒ¢ãƒ‡ãƒ«ãŒç´¹ä»‹ã•ã‚Œã¦ãŠã‚Šã€é‡å­åŠ¹æœã‚„çŸ­ãƒãƒ£ãƒãƒ«æŒ™å‹•ã‚’æ­£ç¢ºã«ãƒ¢ãƒ‡ãƒ«åŒ–ã™ã‚‹æ–¹æ³•ã‚‚å«ã¾ã‚Œã¦ã„ã¾ã™ã€‚\n\nè² ã‚­ãƒ£ãƒ‘ã‚·ã‚¿ãƒ³ã‚¹FETã«ã¤ã„ã¦ã‚‚è¨€åŠã•ã‚Œã¦ã„ã¾ã™ã€‚ã“ã‚Œã‚‰ã®æ–°ã—ã„ãƒ‡ãƒã‚¤ã‚¹ã¯ã€å¼·èª˜é›»ä½“ææ–™ã‚’åˆ©ç”¨ã—ã¦æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã€çŸ­ãƒãƒ£ãƒãƒ«åŠ¹æœã‚’è»½æ¸›ã—ã€ã‚¨ãƒãƒ«ã‚®ãƒ¼åŠ¹ç‡ã‚’æ”¹å–„ã—ã¾ã™ã€‚è«–æ–‡ã§ã¯ã€ã“ã‚Œã‚‰ã®ãƒ‡ãƒã‚¤ã‚¹ã®ç‰©ç†å­¦ã¨ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã«ã¤ã„ã¦ã®æ´å¯ŸãŒæä¾›ã•ã‚Œã¦ã„ã¾ã™ã€‚\n\næœ€å¾Œã«ã€ææ¡ˆã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¯å•†æ¥­ç”¨å›è·¯ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼ã«å®Ÿè£…ã•ã‚Œã¦ãŠã‚Šã€ç‰¹ã«ãƒ‡ãƒã‚¤ã‚¹ã‚µã‚¤ã‚ºãŒå°ã•ããªã‚‹ã«ã¤ã‚Œã¦ã€å›è·¯ã®ã‚¨ãƒãƒ«ã‚®ãƒ¼åŠ¹ç‡ã‚’å‘ä¸Šã•ã›ã‚‹å¯èƒ½æ€§ãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚ã“ã®ç ”ç©¶ã¯ã€å°†æ¥ã®é›»å­è¨­è¨ˆã«ãŠã‘ã‚‹å…ˆé€²ãƒˆãƒ©ãƒ³ã‚¸ã‚¹ã‚¿æŠ€è¡“ã®ç†è§£ã¨å¿œç”¨ã«è²¢çŒ®ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¦ã„ã¾ã™ã€‚"
    }
  },
  {
    "id": "8478d3ea38c43dc0",
    "title": {
      "en": "Playstation Mod Turns the PSOne into a Crustacean",
      "ko": "PSì›, ê°‘ê°ë¥˜ë¡œ ë³€ì‹ !",
      "ja": "PSOneãŒç”²æ®»é¡ã«ï¼"
    },
    "type": "story",
    "url": "https://gizmodo.com/the-carcinisation-of-playstation-is-complete-say-hello-to-playstacean-2000579934",
    "score": 101,
    "by": "ulrischa",
    "time": 1742905800,
    "content": "The Carcinisation of PlayStation Is Complete: Say Hello to â€˜Playstaceanâ€™\n\n        Playstacean is a moddified PSOne, and itâ€™s already clawing its way into our hearts.\n\n    By\n\n      Kyle Barr\n\n      Published March 25, 2025\n\n    |\n\n      Comments (5)\n\n      |\n\n    ğ•\n\n    Copied!\n\n                    Â© GingerOfOz\n\n              If you thought your PlayStation 5 already looks a little too animalistic with its massive whale fin-like console covers, perhaps you would enjoy a more explicitly aquatic Sony gaming machine. â€œPlaystaceanâ€ is more than a pun, itâ€™s a meme thatâ€™s transformed into an actual console, and it may be the cutest, working version of Sonyâ€™s long-defunct PSOne in the 25 years since its initial launch. Playstacean is, in essence, an all-in one console mod for the PSOne console thatâ€™s made to look like a crab. If you ever heard the memeified term â€œcarcinisation,â€ then this is the crabbiest version of a console weâ€™ve seen yet. Yes, it plays games, and you bet those crab claw controllers actually work. Just donâ€™t imagine you can hold each controller end for too long before your own hands feel like calcified pincers. <iframe title=\"I Built A &quot;Playstacean&quot;\" width=\"500\" height=\"281\" src=\"https://www.youtube.com/embed/dSBNs3TeINc?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n    (new Image()).src = 'https://capi.connatix.com/tr/si?token=92b7b46b-43ed-4e0e-b21b-2c999302d9d7&cid=872d12ce-453b-4870-845f-955919887e1b';  cnx.cmd.push(function() {    cnx({      playerId: \"92b7b46b-43ed-4e0e-b21b-2c999302d9d7\"    }).render(\"54612ab9a0fa4d14bdc41e22140d69fb\");  });\n  The design was based on the work of video game concept artist Anh Dang. While you may imagine the smooth curves and inward-sloped mandibles were designed off the original PlayStation console, itâ€™s actually formed from the PSOne, a more-compact version of Sonyâ€™s original console that first debuted in 2000 (after the launch of the PlayStation 2). Dang told GingerOfOz that her concept originally came from an old meme she saved to her hard drive years ago. The â€œPlaystaceanâ€ console is a meme built off a meme, built off a meme. In a video interview with Gizmodo, GingerofOz told us he had been planning this design after seeing a print of Dangâ€™s artwork late last year. According to the YouTuber, â€œ[Playstacean] is a really good pun. Plus Dang really nailed her original artwork. You could tell immediately that itâ€™s supposed to be a PSOne.â€ He added, â€œI think people like crabsâ€¦ the console hit this really cool niche.â€ The actual design process began in December, involving a fair bit of trial and error to make a solid and smooth print of the pun-consoleâ€™s shell. GingerOfOz started the design in CAD and then 3D printed the parts.\n\n  \t\t\t \t\t\t\t \t\t\t \t\t\t\t \t\t\t\tÂ© GingerOfOz \t\t\t\t \t\t\t \t\t\t\t \t\t\t \t\t\t\t \t\t\t\tÂ© GingerOfOz \t\t\t\t \t\t\t \t\t\t\t \t\t\t \t\t\t\t \t\t\t\tÂ© GingerOfOz \t\t\t\t \t\t\t \t\t\t\t \t\t\t \t\t\t\t \t\t\t\tÂ© GingerOfOz \t\t\t\t \t\t\t \t\t\t\t \t\t\t \t\t\t\t \t\t\t\tÂ© GingerOfOz \t\t\t\t \t\t\t \t\t\t\t \t\t\t \t\t\t\t \t\t\t\tÂ© GingerOfOz \t\t\t\t \t\t  Unlike some more dramatic mods like console-to-handheld DIY projects that require precise modifications to the motherboard, GingerofOz only needed to cut down the grounding (which normally protects components from unexpected electrical spikes that can damage the case)around the perimeter of the board to get it seated in the shallow base. While the board itself was relatively simple, he said one of the most-complicated aspects of the build was the work angling the front controller and memory card ports to mirror Dangâ€™s original design. That involved â€œa solid week and a half of workâ€ involving trial and error. The other struggle was with the controllers themselves. GingerofOz used a modified third-party PlayStation controller he bought off eBay, which resulted in some trial and error before he realized the controller would â€œfreak outâ€ when you detached the thumbsticks from the buttons. The two controllers speak to each other via a switcher soldered to the mainboard, allowing each end to act as one with practically no latency.\n\n GingerOfOz admitted the current iteration has flaws. While constructing the final build, the Playstacean designer had to add knobs to seat the disc drive to avoid any grinding when pressing on the lid. He also admitted his wiring through the controllers wasnâ€™t particularly stellar, but it was good enough to avoid any tangled cables when moving the joints of the crab claws around. Gizmodo asked if he plans to release his files so other modders could 3D print their own Playstacean, but he said heâ€™s not planning to share anything currently. He said the big hurdle is fixing up the current CAD files, and heâ€™s currently more keen to start work on future projects. He will be bringing Playstacean to the Midwest Gaming Classic in Milwaukee, Wisconsin April 4, if you happen to be in town. As for whatâ€™s next, he said he considered making a folding Nintendo Switch, though that may be on the backburner now that the Switch 2 is imminent. The modder also hinted heâ€™s working on another aquatic animal-themed console mod, this time for the Nintendo Gamecube. Perhaps we could find a box jellyfish version of Nintendoâ€™s console with a carrying handle.\n\n    PlayStation 5Sony\n\n                  Daily Newsletter\n\n                  (function() {\n\twindow.mc4wp = window.mc4wp || {\n\t\tlisteners: [],\n\t\tforms: {\n\t\t\ton: function(evt, cb) {\n\t\t\t\twindow.mc4wp.listeners.push(\n\t\t\t\t\t{\n\t\t\t\t\t\tevent   : evt,\n\t\t\t\t\t\tcallback: cb\n\t\t\t\t\t}\n\t\t\t\t);\n\t\t\t}\n\t\t}\n\t}\n})();\n\n          Get the best tech, science, and culture news in your inbox daily.\n\n          Select\n\n          News from the future, delivered to your present.\n\n          Select\n\n      Please select your desired newsletters and submit your email to upgrade your inbox.\n\n    Sign me up\n\nLeave this field empty if you're human:\n\n            You May Also Like\n\n            io9Movies\n\n          Nintendo Just Revealed the Zelda Movieâ€™s Release Date in the Most Nintendo Way Possible\n\n          Wes Ball's live-action Legend of Zelda movie will hit theaters March 26, 2027.\n\n    By\n\n      James Whitbrook\n\n      Published March 28, 2025\n\n            io9Movies\n\n          The Resident Evil Reboot Found Someone Who Certainly Looks Like Leon S. Kennedy\n\n          Austin Abrams may be the first actor in Zach Cregger's new Resident Evil movie. Might he be playing Raccoon City's unluckiest rookie cop?\n\n    By\n\n      Justin Carter\n\n      Published March 22, 2025\n\n            Tech NewsArtificial Intelligence\n\n          Hey Sony, Thereâ€™s a Right Way and Wrong Way to Use AI to Improve PlayStation 5 Games\n\n          AI NPCs arenâ€™t the future for PlayStation 5, but you know what is? Improved AI upscaling.\n\n    By\n\n      Kyle Barr\n\n      Published March 11, 2025\n\n            Tech NewsArtificial Intelligence\n\n          Sony Says It Has Already Taken Down More Than 75,000 AI Deepfake Songs\n\n          AI generated songs that mimic real artists are becoming a serious problem.\n\n    By\n\n      Thomas Maxwell\n\n      Published March 10, 2025\n\n            io9\n\n          Demon Slayerâ€˜s Final End Begins in the U.S. This September\n\n          Demon Slayer: Kimetsu no Yaiba Infinity Castle is the first of the anime's film trilogy finale.\n\n    By\n\n      Isaiah Colbert\n\n      Published March 5, 2025\n\n            io9Movies\n\n          Madame Webâ€˜s Love Language Is Hitting People With Cars\n\n          One year on, and there's still two things I love about Madame Web as much as it loves itself: stolen vehicles, and hitting people with those stolen vehicles.\n\n    By\n\n      James Whitbrook\n\n      Published February 14, 2025\n\n    Latest news\n\n              Crowds Turn Out Across the U.S. for â€˜Tesla Takedownâ€™ Protests\n\n              Stay Invisible Online: The Must-Have VPN for Ultimate Privacy\n\n              Scott Derrickson Adapting Horror Novel Road of Bones for Film\n\n              Lanternsâ€˜ Director Teases the HBO Showâ€™s Tone and â€˜Sci-Fi Magicâ€™\n\n              Ryan Coogler Wants Denzel for Black Panther 3 As Much as You Do\n\n              Mission: Impossible Is Accepting a Museum Spotlight\n\n              The New Apple Watch Series 10 Has Never Been So Cheap, Amazon Shows No Mercy\n\n              How to Watch MotoGP Americas MotoGP on a Free Channel\n\n  Latest news\n\n            Crowds Turn Out Across the U.S. for â€˜Tesla Takedownâ€™ Protests\n\n            3/29/2025, 7:23 pm\n\n            Stay Invisible Online: The Must-Have VPN for Ultimate Privacy\n\n            3/29/2025, 6:00 pm\n\n            Scott Derrickson Adapting Horror Novel Road of Bones for Film\n\n            3/29/2025, 4:15 pm\n\n            Lanternsâ€˜ Director Teases the HBO Showâ€™s Tone and â€˜Sci-Fi Magicâ€™\n\n            3/29/2025, 2:50 pm\n\n  Latest Reviews\n\n            The Hypershell Exoskeleton Is So Good at Climbing Cliffs, It Ruined My Workout\n\n            3/29/2025, 9:00 am\n\n            Razer Blade 16 Review: A Toasty Powerhouse\n\n            3/28/2025, 3:15 pm\n\n            Assassinâ€™s Creed Shadows Shows Ubisoft Still Hasnâ€™t Made Assassinâ€™s Creed\n\n            3/18/2025, 1:00 pm\n\n            The Atari Asteroids Watch Is So Beautiful, I Donâ€™t Care How Poorly It Tells Time\n\n            3/14/2025, 7:00 am",
    "summary": {
      "en": "A new gaming console called \"Playstacean,\" a modified version of the PSOne, has gained attention for its unique crab-like design. This console is a playful take on the concept of \"carcinisation,\" where creatures evolve to have crab-like features. The Playstacean not only looks cute but also functions as a gaming device with working crab claw controllers. \n\nThe design was inspired by concept artist Anh Dang and created by modder GingerOfOz, who used 3D printing to bring the idea to life. While crafting the console involved some challenges, such as adjusting controller ports and ensuring smooth functionality, the final product is a charming homage to both the PSOne and crabs.\n\nGingerOfOz plans to showcase the Playstacean at the Midwest Gaming Classic and is considering future projects, including another aquatic-themed console. However, he currently has no plans to share the design files for others to replicate.",
      "ko": "ìƒˆë¡œìš´ ê²Œì„ ì½˜ì†”ì¸ \"í”Œë ˆì´ìŠ¤í…Œì´ì…˜\"ì´ ë…íŠ¹í•œ ê²Œ ëª¨ì–‘ì˜ ë””ìì¸ìœ¼ë¡œ ì£¼ëª©ë°›ê³  ìˆë‹¤. ì´ ì½˜ì†”ì€ ìƒë¬¼ë“¤ì´ ê²Œì™€ ê°™ì€ íŠ¹ì§•ìœ¼ë¡œ ì§„í™”í•˜ëŠ” ê°œë…ì¸ 'ê²Œí™”(carcinisation)'ë¥¼ ì¬ë¯¸ìˆê²Œ í‘œí˜„í•œ ê²ƒì´ë‹¤. í”Œë ˆì´ìŠ¤í…Œì´ì…˜ì€ ê·€ì—¬ìš´ ì™¸ëª¨ë¿ë§Œ ì•„ë‹ˆë¼ ì‹¤ì œë¡œ ì‘ë™í•˜ëŠ” ê²Œ ì§‘ê²Œ ì»¨íŠ¸ë¡¤ëŸ¬ë¥¼ ê°–ì¶˜ ê²Œì„ ì¥ì¹˜ë¡œë„ ê¸°ëŠ¥í•œë‹¤.\n\në””ìì¸ì€ ê°œë… ì•„í‹°ìŠ¤íŠ¸ì¸ ì•¤ ë‹¹ì´ ì˜ê°ì„ ì£¼ì—ˆê³ , ëª¨ë“œ ì œì‘ìì¸ ì§„ì €ì˜¤í”„ì˜¤ì¦ˆê°€ 3D í”„ë¦°íŒ… ê¸°ìˆ ì„ ì´ìš©í•´ ì•„ì´ë””ì–´ë¥¼ ì‹¤í˜„í–ˆë‹¤. ì½˜ì†” ì œì‘ ê³¼ì •ì—ì„œëŠ” ì»¨íŠ¸ë¡¤ëŸ¬ í¬íŠ¸ë¥¼ ì¡°ì •í•˜ê³  ì›í™œí•œ ê¸°ëŠ¥ì„ ë³´ì¥í•˜ëŠ” ë“±ì˜ ì–´ë ¤ì›€ì´ ìˆì—ˆì§€ë§Œ, ìµœì¢… ì œí’ˆì€ PSOneê³¼ ê²Œë¥¼ ëª¨ë‘ ê¸°ë…í•˜ëŠ” ë§¤ë ¥ì ì¸ ì‘í’ˆìœ¼ë¡œ íƒ„ìƒí–ˆë‹¤.\n\nì§„ì €ì˜¤í”„ì˜¤ì¦ˆëŠ” í”Œë ˆì´ìŠ¤í…Œì´ì…˜ì„ ë¯¸ë“œì›¨ìŠ¤íŠ¸ ê²Œì„ í´ë˜ì‹ì—ì„œ ì„ ë³´ì¼ ê³„íšì´ë©°, ë¯¸ë˜ í”„ë¡œì íŠ¸ë¡œ ë˜ ë‹¤ë¥¸ ìˆ˜ì¤‘ í…Œë§ˆì˜ ì½˜ì†”ì„ ê³ ë ¤í•˜ê³  ìˆë‹¤. ê·¸ëŸ¬ë‚˜ í˜„ì¬ë¡œì„œëŠ” ë‹¤ë¥¸ ì‚¬ëŒë“¤ì´ ë””ìì¸ íŒŒì¼ì„ ë³µì œí•  ìˆ˜ ìˆë„ë¡ ê³µìœ í•  ê³„íšì€ ì—†ë‹¤.",
      "ja": "æ–°ã—ã„ã‚²ãƒ¼ãƒ ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã€Œãƒ—ãƒ¬ã‚¤ã‚¹ãƒ†ã‚¤ã‚·ãƒ£ãƒ³ã€ãŒæ³¨ç›®ã‚’é›†ã‚ã¦ã„ã¾ã™ã€‚ã“ã®ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã¯PSOneã‚’æ”¹é€ ã—ãŸã‚‚ã®ã§ã€ã‚«ãƒ‹ã®ã‚ˆã†ãªãƒ¦ãƒ‹ãƒ¼ã‚¯ãªãƒ‡ã‚¶ã‚¤ãƒ³ãŒç‰¹å¾´ã§ã™ã€‚ã€Œã‚«ãƒ‹åŒ–ã€ã¨ã„ã†ç”Ÿç‰©ã®é€²åŒ–ã®æ¦‚å¿µã‚’æ¥½ã—ãè¡¨ç¾ã—ãŸã‚‚ã®ã§ã€è¦‹ãŸç›®ãŒå¯æ„›ã„ã ã‘ã§ãªãã€å®Ÿéš›ã«å‹•ä½œã™ã‚‹ã‚«ãƒ‹ã®ãƒã‚µãƒŸå‹ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼ã‚’å‚™ãˆãŸã‚²ãƒ¼ãƒ ãƒ‡ãƒã‚¤ã‚¹ã§ã‚‚ã‚ã‚Šã¾ã™ã€‚\n\nãƒ‡ã‚¶ã‚¤ãƒ³ã¯ã‚³ãƒ³ã‚»ãƒ—ãƒˆã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆã®ã‚¢ãƒ³ãƒ»ãƒ€ãƒ³ã«ã‚ˆã£ã¦ã‚¤ãƒ³ã‚¹ãƒ‘ã‚¤ã‚¢ã•ã‚Œã€ãƒ¢ãƒƒãƒ€ãƒ¼ã®ã‚¸ãƒ³ã‚¸ãƒ£ãƒ¼ãƒ»ã‚ªãƒ–ãƒ»ã‚ªã‚ºãŒ3Dãƒ—ãƒªãƒ³ãƒ†ã‚£ãƒ³ã‚°ã‚’ä½¿ã£ã¦å®Ÿç¾ã—ã¾ã—ãŸã€‚ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã®è£½ä½œã«ã¯ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼ãƒãƒ¼ãƒˆã®èª¿æ•´ã‚„ã‚¹ãƒ ãƒ¼ã‚ºãªæ©Ÿèƒ½æ€§ã®ç¢ºä¿ãªã©ã€ã„ãã¤ã‹ã®èª²é¡ŒãŒã‚ã‚Šã¾ã—ãŸãŒã€æœ€çµ‚çš„ã«ã¯PSOneã¨ã‚«ãƒ‹ã¸ã®é­…åŠ›çš„ãªã‚ªãƒãƒ¼ã‚¸ãƒ¥ã¨ãªã£ã¦ã„ã¾ã™ã€‚\n\nã‚¸ãƒ³ã‚¸ãƒ£ãƒ¼ãƒ»ã‚ªãƒ–ãƒ»ã‚ªã‚ºã¯ã€ãƒŸãƒƒãƒ‰ã‚¦ã‚¨ã‚¹ãƒˆãƒ»ã‚²ãƒ¼ãƒŸãƒ³ã‚°ãƒ»ã‚¯ãƒ©ã‚·ãƒƒã‚¯ã§ãƒ—ãƒ¬ã‚¤ã‚¹ãƒ†ã‚¤ã‚·ãƒ£ãƒ³ã‚’å±•ç¤ºã™ã‚‹äºˆå®šã§ã€å°†æ¥çš„ã«ã¯åˆ¥ã®æ°´ä¸­ãƒ†ãƒ¼ãƒã®ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã‚’è€ƒãˆã¦ã„ã‚‹ãã†ã§ã™ã€‚ã—ã‹ã—ã€ç¾æ™‚ç‚¹ã§ã¯ä»–ã®äººãŒè¤‡è£½ã§ãã‚‹ã‚ˆã†ã«ãƒ‡ã‚¶ã‚¤ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å…±æœ‰ã™ã‚‹äºˆå®šã¯ãªã„ã¨ã®ã“ã¨ã§ã™ã€‚"
    }
  },
  {
    "id": "36ae4d7b311c70ac",
    "title": {
      "en": "Show HN Pianoboi â€“ displays sheet music as you play your piano",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://pianoboi.site",
    "score": 102,
    "by": "bcowde",
    "time": 1743177317,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "3e20e68ce8fa1036",
    "title": {
      "en": "De-Atomization Is the Secret to Happiness (2022)",
      "ko": "í–‰ë³µì˜ ë¹„ë°€, ë¶„ì í•´ì²´",
      "ja": "åŸå­è§£æ”¾ãŒå¹¸ã›ã®éµ"
    },
    "type": "story",
    "url": "https://www.nateliason.com/blog/de-atomization-is-the-secret-to-happiness",
    "score": 50,
    "by": "handfuloflight",
    "time": 1743284836,
    "content": "De-Atomization is the Secret to HappinessNovember\t7, 2022\nThere are at least two kinds of fun:\nType 1 fun is fun in the moment. Watching a movie, playing a video game, scrolling TikTok, reading a book. You want to have fun, you do the fun thing, and voilÃ¡, it is fun.\nType 2 fun is fun in retrospect. Running a marathon is mostly un-fun from moment to moment; youâ€™re often either zoned out or in some form of pain. But in retrospect, it was fun.\nIâ€™ve spent over 1,000 hours playing the video game DOTA 2, but I remember almost zero of that time. It was strong type 1 fun but very low type 2 fun.\nI once went to a DOTA 2 International tournament with a friend, though, and I remember most of that experience quite vividly. Significant parts were unfun: waiting in line, commuting to the arena, bumping into one of the questionably hygienic gamers whose body must be 63% pizza and getting a whiff of Geneva-violating body odor. But overall, it was very fun.\nDespite being moment-to-moment less fun than playing the game, going to the tournament was ultimately more fun. Playing the videogame is very fun, but itâ€™s monolithic. Itâ€™s just play, thereâ€™s no environmental novelty full of multisensory stimuli to hook your memory into. It blurs from one moment to the next, and like bad American Chinese food, you find yourself paradoxically unsatiated when youâ€™re done. Thereâ€™s something more fun about complex fun, even if the individual moments might score lower on the hedonometer.\nBut fun is just one area where we can see this phenomenon. There is a clear experiential divide between rich multisensory life and what Iâ€™ll call â€œatomizedâ€ life.\nAnd atomized life is worth avoiding.\nII\nWhen I wrote about how much weaker weâ€™ve gotten, several people rightly pointed out that the reason was obvious: most of us no longer do hard labor as our day jobs. When you had to walk or jog 20 miles a day for sustenance or spend all day carrying canoes and packs on your shoulders or drag bricks of limestone around for pharaoh, you were default strong. When you spend all day sitting in a chair getting enraged / entertained / aroused / whatever by algorithms, you are default flabby.\nLife and fitness used to be deeply intertwined. You could not live without fitness. Now they are separate: fitness is a cute thing rich people do in their Lululemon after work or while jiggling their mouse to keep the Slack bubble green. You donâ€™t do it to stay alive, you do it to get laid or not resent yourself or maybe if youâ€™re particularly enlightened to â€œfeel good.â€\nFitness has been atomized: it is no longer part of a cohesive whole life. Itâ€™s a separate thing you have to try to â€œfind time for.â€ When someone says they â€œdonâ€™t have timeâ€ to work out, theyâ€™re both stating their priorities (obviously, everyone has time) but also stating something about their life. It does not have fitness incorporated into it.\nBeyond the atomization separating fitness from normal life, there is also further atomization within fitness. Letâ€™s take biking as an example. First, biking was something you did outside, often with friends. There was scenery, socialization, exploration, sunlight, and exercise. Then the exercise element was captured in stationary bikes, placed in a gym or a spin class, and most of the richness was removed. You still got the exercise, and some socialization from being in the gym or class, but there was no scenery, no exploration, no time in the outdoors. Then we got Peloton. No socialization. No scenery. No exploration. No sunlight. Exercise, sure, and Emma is cute, but thatâ€™s it. The richness of biking is gone.\nAnd, look, I love my Peloton, but itâ€™s Type 1 exercise. Instead of exercise being a multifaceted activity that incorporates other essential life elements like seeing friends, getting fresh air, and looking away from a screen for a few moments, it reduces it to its simplest element and suggests thatâ€™s just as good. Maybe even better because you get a â€œharder workout.â€ The most important part of exercise, after all, is INTENSITY.\nWhere else do we see over-atomization? Food comes to mind. A meal should be about more than just food. Relaxation, spending time with your friends and family, fun, maybe joy. If you looked at an Italian neighborhood dinner and said â€œwow what a waste, donâ€™t they know they could just drink a Huel and get back to work?â€ then, well, oof.\nBut atomization encourages us to reduce multivariate experiences, often the most important parts of life, to their single most obvious element:\nBiking is about exercise, and scheduling with friends and planning a route and inflating your tires all get in the way of that.\nEating is about sustenance, and inviting friends and getting groceries and cooking all get in the way of that.\nRelationships are about talking, and meeting up in person and leaving the house and scheduling are all inconveneiences.\nWork is about checking off tasks, so spending time commuting to an office where you might goof off and socialize all get in the way of that.\nThen when we feel lonely, painfully isolated by our atomized life, we schedule some atomized social time like going to a bar or coffee _to see friends _in between our lonely work and lonely dinner because weâ€™ve removed most of the natural socializing elements from all of the other parts of life. Atomization turns an integrated day of socializing, eating, exercising, and working into discrete hurried chunks of trying to move from one thing to another, wondering why we never seem to have time for everything.\nAtomization is a global version of the problem I discussed in â€œwork life balance is impossible,â€ the reason you can never have â€œwork-life balanceâ€ is that youâ€™ve placed Work and Life at odds, as ends of a scale that needs to be balanced out lest it tips too far in either direction.\nIf you throw Exercise and Socialization and Food and Fun and Hobbies into some complicated hexascale with Work and Life, you suddenly feel overwhelmed and start eyeing the benzos because seriously how can you possibly oh shit did the dogs get fed today ugh when did you last finish a book can you believe she hasnâ€™t called you back is it 5 oâ€™clock yet?\nBut at the root of this overwhelm is the language we use around many activities. â€œIâ€™m going to go workoutâ€ feels more responsible than â€œIâ€™m going to go for a walk with a friend.â€ We separate â€œIâ€™m workingâ€ and â€œIâ€™m playing.â€ We want to make everything extremely efficient, so we opt for going for a run alone instead of trying to link up with people along the way. We need to â€œbe productiveâ€ so we donâ€™t work from a coffee shop with friends.\nThere is probably some blame to be put on the dumb productivity world for this too. People think they need to focus and give things their full attention as if attention is the most important resource to optimize for. For your hour or two of deep work, sure, but after that, thereâ€™s no reason you canâ€™t hang with friends while slowing chugging through shallow work. Obviously, you can multitask. Youâ€™ve never talked to someone while walking before?\nThe solution to the atomization curse that both gives us significantly more time back, and makes us much happier, is to seek to reintegrate these various foci of life as much as possible. How do you turn food back into a rich, multivariate experience with friends, fun, exploration, and relaxation? How do you blend socialization and exercise and community? How do you spend less time having shallower atomized relationships through a screen, and more time having rich in-person relationships where you get the full experience of other people?\nThe challenge is that these â€œType 1,â€ or Atomized, versions of activities are the most immediately appealing. Booting up my computer to play a video game is way easier and sounds more immediately fun than texting some friends to play pickleball. Crushing takeout chips and queso sounds tastier and easier than cooking steak and rice. But I know Iâ€™ll feel better afterward with the latter, and thatâ€™s what we have to try to optimize for. Integrated living is more satisfying than atomic living.\nInstead of looking at some problem like â€œI donâ€™t see enough friends,â€ or â€œI donâ€™t work out enough,â€ or â€œI donâ€™t have enough fun,â€ and then trying to find time to fit those priorities into, we should see how we can incorporate them into what weâ€™re already doing. Could you make your workout less perfectly optimized so you can do it with friends? Can you loosen the reigns on your Super Duper Productive Routine to hang at a coffee shop with friends for a few hours a week? And for the love of God, can you please stop drinking fucking Huel or Soylent at your desk and talk to someone instead?\nThe more creatively we can integrate the various parts of life that matter to us, the more satisfied weâ€™ll be in our day to day.\nThe more we atomize, the more lonely and overwhelmed we start to feel.\nDe-atomization is the secret to happiness.Enjoyed this? Subscribe below to receive the next piece in your inbox.",
    "summary": {
      "en": "The text discusses the concept of \"de-atomization\" as a key to happiness. It identifies two types of fun: \n\n1. **Type 1 Fun**: Immediate enjoyment from activities like watching movies or playing video games.\n2. **Type 2 Fun**: Enjoyment that comes from reflecting on experiences later, such as attending events or engaging in challenging activities.\n\nThe author argues that many aspects of life, including fitness, socializing, and eating, have become \"atomized,\" meaning they are often separated from the richer, multisensory experiences that make them fulfilling. For example, exercising is now often done in isolation rather than as a social activity, and meals are frequently reduced to mere sustenance instead of shared experiences.\n\nThis atomization leads to feelings of loneliness and overwhelm. The author suggests that instead of trying to fit fun, fitness, and socialization into separate time slots, we should find ways to integrate these activities into our daily lives. By combining them, we can enhance our overall satisfaction and well-being.\n\nIn essence, the text promotes the idea that reconnecting various life activities into a cohesive experience can lead to greater happiness, emphasizing that \"de-atomization\" is crucial for a fulfilling life.",
      "ko": "ì´ ê¸€ì—ì„œëŠ” í–‰ë³µì˜ ì—´ì‡ ë¡œì„œ \"íƒˆì›ìí™”\"ë¼ëŠ” ê°œë…ì„ ë‹¤ë£¹ë‹ˆë‹¤. ì—¬ê¸°ì„œ ë‘ ê°€ì§€ ì¢…ë¥˜ì˜ ì¦ê±°ì›€ì„ êµ¬ë¶„í•©ë‹ˆë‹¤. ì²« ë²ˆì§¸ëŠ” ì¦‰ê°ì ì¸ ì¦ê±°ì›€ì„ ì£¼ëŠ” 'íƒ€ì… 1 ì¦ê±°ì›€'ìœ¼ë¡œ, ì˜í™” ê°ìƒì´ë‚˜ ë¹„ë””ì˜¤ ê²Œì„ê³¼ ê°™ì€ í™œë™ì—ì„œ ëŠë¼ëŠ” ì¦ê±°ì›€ì…ë‹ˆë‹¤. ë‘ ë²ˆì§¸ëŠ” 'íƒ€ì… 2 ì¦ê±°ì›€'ìœ¼ë¡œ, ë‚˜ì¤‘ì— ê²½í—˜ì„ ë˜ìƒˆê¸°ë©° ëŠë¼ëŠ” ì¦ê±°ì›€ì…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, í–‰ì‚¬ì— ì°¸ì„í•˜ê±°ë‚˜ ë„ì „ì ì¸ í™œë™ì— ì°¸ì—¬í•œ í›„ì˜ ë§Œì¡±ê°ì´ ì´ì— í•´ë‹¹í•©ë‹ˆë‹¤.\n\nì €ìëŠ” ì‚¶ì˜ ì—¬ëŸ¬ ì¸¡ë©´, íŠ¹íˆ ìš´ë™, ì‚¬íšŒì  í™œë™, ì‹ì‚¬ê°€ \"ì›ìí™”\"ë˜ì–´ ìˆë‹¤ê³  ì£¼ì¥í•©ë‹ˆë‹¤. ì´ëŠ” ì´ëŸ¬í•œ í™œë™ë“¤ì´ ë” í’ë¶€í•˜ê³  ë‹¤ê°ê°ì ì¸ ê²½í—˜ê³¼ ë¶„ë¦¬ë˜ì–´ ìˆë‹¤ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ìš´ë™ì€ ì´ì œ ì¢…ì¢… í˜¼ì í•˜ëŠ” í™œë™ìœ¼ë¡œ ë³€í•´ë²„ë ¸ê³ , ì‹ì‚¬ëŠ” ë‹¨ìˆœí•œ ì˜ì–‘ ì„­ì·¨ë¡œ ì¶•ì†Œë˜ì–´ ê³µìœ í•˜ëŠ” ê²½í—˜ì´ ì¤„ì–´ë“¤ê³  ìˆìŠµë‹ˆë‹¤.\n\nì´ëŸ¬í•œ ì›ìí™”ëŠ” ì™¸ë¡œì›€ê³¼ ì••ë°•ê°ì„ ì´ˆë˜í•©ë‹ˆë‹¤. ì €ìëŠ” ì¦ê±°ì›€, ìš´ë™, ì‚¬íšŒì  í™œë™ì„ ê°ê°ì˜ ì‹œê°„ì— ë§ì¶”ë ¤ í•˜ê¸°ë³´ë‹¤ëŠ”, ì´ëŸ¬í•œ í™œë™ë“¤ì„ ì¼ìƒìƒí™œì— í†µí•©í•  ë°©ë²•ì„ ì°¾ì•„ì•¼ í•œë‹¤ê³  ì œì•ˆí•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ìš°ë¦¬ëŠ” ì „ë°˜ì ì¸ ë§Œì¡±ê°ê³¼ ì›°ë¹™ì„ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nê²°êµ­, ì´ ê¸€ì€ ë‹¤ì–‘í•œ ì‚¶ì˜ í™œë™ì„ í•˜ë‚˜ì˜ ì¼ê´€ëœ ê²½í—˜ìœ¼ë¡œ ë‹¤ì‹œ ì—°ê²°í•˜ëŠ” ê²ƒì´ ë” í° í–‰ë³µìœ¼ë¡œ ì´ì–´ì§ˆ ìˆ˜ ìˆë‹¤ëŠ” ì ì„ ê°•ì¡°í•©ë‹ˆë‹¤. \"íƒˆì›ìí™”\"ê°€ ì¶©ë§Œí•œ ì‚¶ì„ ìœ„í•´ í•„ìˆ˜ì ì´ë¼ëŠ” ë©”ì‹œì§€ë¥¼ ì „ë‹¬í•©ë‹ˆë‹¤.",
      "ja": "ã€Œãƒ‡ã‚¢ãƒˆãƒŸã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ã€ã¨ã„ã†æ¦‚å¿µãŒå¹¸ç¦ã®éµã¨ã—ã¦å–ã‚Šä¸Šã’ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚ã“ã®ä¸­ã§ã€æ¥½ã—ã¿ã«ã¯äºŒã¤ã®ã‚¿ã‚¤ãƒ—ãŒã‚ã‚‹ã¨èª¬æ˜ã•ã‚Œã¦ã„ã¾ã™ã€‚\n\nä¸€ã¤ç›®ã¯ã€Œã‚¿ã‚¤ãƒ—1ã®æ¥½ã—ã¿ã€ã§ã€æ˜ ç”»ã‚’è¦³ãŸã‚Šã€ãƒ“ãƒ‡ã‚ªã‚²ãƒ¼ãƒ ã‚’ã—ãŸã‚Šã™ã‚‹ã‚ˆã†ãªã€å³åº§ã«æ¥½ã—ã‚ã‚‹æ´»å‹•ã‹ã‚‰å¾—ã‚‰ã‚Œã‚‹å–œã³ã§ã™ã€‚äºŒã¤ç›®ã¯ã€Œã‚¿ã‚¤ãƒ—2ã®æ¥½ã—ã¿ã€ã§ã€ã‚¤ãƒ™ãƒ³ãƒˆã«å‚åŠ ã—ãŸã‚Šã€æŒ‘æˆ¦çš„ãªæ´»å‹•ã«å–ã‚Šçµ„ã‚“ã ã‚Šã—ãŸå¾Œã«æŒ¯ã‚Šè¿”ã‚‹ã“ã¨ã§å¾—ã‚‰ã‚Œã‚‹æ¥½ã—ã¿ã§ã™ã€‚\n\nè‘—è€…ã¯ã€ãƒ•ã‚£ãƒƒãƒˆãƒã‚¹ã‚„ç¤¾äº¤ã€é£Ÿäº‹ãªã©ã®å¤šãã®ç”Ÿæ´»ã®å´é¢ãŒã€Œã‚¢ãƒˆãƒŸã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ã€ã€ã¤ã¾ã‚Šã€ã‚ˆã‚Šè±Šã‹ã§å¤šæ„Ÿè¦šçš„ãªä½“é¨“ã‹ã‚‰åˆ‡ã‚Šé›¢ã•ã‚Œã¦ã„ã‚‹ã¨æŒ‡æ‘˜ã—ã¦ã„ã¾ã™ã€‚ä¾‹ãˆã°ã€é‹å‹•ã¯ä»Šã‚„å­¤ç«‹ã—ã¦è¡Œã‚ã‚Œã‚‹ã“ã¨ãŒå¤šãã€ç¤¾äº¤çš„ãªæ´»å‹•ã¨ã—ã¦è¡Œã‚ã‚Œã‚‹ã“ã¨ãŒå°‘ãªããªã£ã¦ã„ã¾ã™ã€‚ã¾ãŸã€é£Ÿäº‹ã‚‚å˜ãªã‚‹æ „é¤Šè£œçµ¦ã«éããšã€å…±æœ‰ã™ã‚‹ä½“é¨“ã¨ã—ã¦ã®æ„å‘³ãŒè–„ã‚Œã¦ã„ã‚‹ã®ã§ã™ã€‚\n\nã“ã®ã‚¢ãƒˆãƒŸã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ã¯å­¤ç‹¬æ„Ÿã‚„åœ§å€’æ„Ÿã‚’å¼•ãèµ·ã“ã—ã¾ã™ã€‚è‘—è€…ã¯ã€æ¥½ã—ã¿ã‚„ãƒ•ã‚£ãƒƒãƒˆãƒã‚¹ã€ç¤¾äº¤ã‚’åˆ¥ã€…ã®æ™‚é–“ã«åˆ†ã‘ã¦è¡Œã†ã®ã§ã¯ãªãã€æ—¥å¸¸ç”Ÿæ´»ã®ä¸­ã§ã“ã‚Œã‚‰ã®æ´»å‹•ã‚’çµ±åˆã™ã‚‹æ–¹æ³•ã‚’è¦‹ã¤ã‘ã‚‹ã¹ãã ã¨ææ¡ˆã—ã¦ã„ã¾ã™ã€‚ã“ã‚Œã‚‰ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã€å…¨ä½“çš„ãªæº€è¶³æ„Ÿã‚„å¹¸ç¦æ„Ÿã‚’é«˜ã‚ã‚‹ã“ã¨ãŒã§ãã‚‹ã®ã§ã™ã€‚\n\nè¦ã™ã‚‹ã«ã€ã•ã¾ã–ã¾ãªç”Ÿæ´»æ´»å‹•ã‚’ä¸€ã¤ã®ã¾ã¨ã¾ã‚Šã®ã‚ã‚‹ä½“é¨“ã¨ã—ã¦å†æ¥ç¶šã™ã‚‹ã“ã¨ãŒã€ã‚ˆã‚Šå¤§ããªå¹¸ç¦ã«ã¤ãªãŒã‚‹ã¨ã„ã†è€ƒãˆãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚ã€Œãƒ‡ã‚¢ãƒˆãƒŸã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ã€ãŒå……å®Ÿã—ãŸç”Ÿæ´»ã«ã¯æ¬ ã‹ã›ãªã„ã“ã¨ãŒå¼·èª¿ã•ã‚Œã¦ã„ã¾ã™ã€‚"
    }
  },
  {
    "id": "5bd444db4e2afeee",
    "title": {
      "en": "Train and Weather Tracker with Raspberry Pi and E-Ink",
      "ko": "íŒŒì´ë¡œ ê¸°ì°¨ ë‚ ì”¨ ì¶”ì ê¸°",
      "ja": "ãƒ©ã‚ºãƒ‘ã‚¤å¤©æ°—åˆ—è»Šãƒˆãƒ©ãƒƒã‚«ãƒ¼"
    },
    "type": "story",
    "url": "https://sambroner.com/posts/raspberry-pi-train",
    "score": 11,
    "by": "tosh",
    "time": 1743272545,
    "content": "Train & Weather Tracker with Raspberry Pi & E-InkMarch 2, 2025Art,Physical,SoftwareI finally built a Raspberry Pi project my wife loves: an e-ink train and weather tracker! If you want to build one yourself, the Github & instructions are here.\nKira will be jogging to the night shift!\nOver the past few years, I've been on something of an e-ink journey.  I started with a weather and news display (still the only post on my website that regularly gets organic traffic.) While I loved it and it looked great, a phone is a better way to check the news, and the weather only gets checked once a day. Then in 2022 while at MIT I built Jarvis, the e-ink voice-to-image display. Jarvis was a great party trick â€” say, \"Hey Jarvis, paint me an elephant on a bowling ball in Times Square\" and watch as the image gradually appeared. Notably, this was before ChatGPT, when people were still impressed by AI!\nJarvis live demo is better!\nThen over Thanksgiving, I had some free time, a basket of spare parts, and the itch to code and build something physical. So here we are with the e-ink train and weather tracker.\nThe idea is simple: Every morning, my wife and I take the inbound F or G subway lines to work from a stop that's a 2-minute jog or a 6-minute walk from our house. I love the NYC subway and it works incredibly well, but the trains come often and predictably, not on-a-schedule. So every morning we're calling out, when's the next G, when's the next F â€” and one of us pulls out a phone for the MTA app or Google Maps and yells back the upcoming train times. Then we time our morning routines to either stretch for a train in three minutes or slow down for a train in ten.\nThe subway and weather tracker makes checking train times much faster and calmer than pulling out a phone. Since it's centrally located in our home, someone is always close enough to glance at it.\nThe subway times reported by the MTA API are reliable once the train is within a few stops or 15 minutes away, with precision increasing as the trains get closer. Having the train times on the wall lets you check how your morning routine is developing against the train schedule as the departure time gets closer.\nBest of all, Kira loves it! This goes on my DIY pantheon along with adding legs to her dresser to make it a better height and fixing a towel rack right before she hosted her colleagues for a book club.\nIf you want to build one yourself or better understand the project, I'll dive into some editorial and gotchas below. The practical instructions, parts, and code live in this GitHub Repo.\nDescription & Features\nThe train & weather tracker is built on a 9.7\" 1200x825 E-Ink display attached to a Raspberry Pi 4b. The display is split into four parts: a header, with date, time, and a live second hand to indicate liveness; a train tracker; the commute weather; and a \"weather bar\" displaying the next 12 hours of weather. The main focus of the layout is the train tracker, which shows the upcoming 30 minutes of inbound F & G trains.\n\nThe display sits in a laser cut mat board with black ridges sized to hide the black border of the e-ink display. The mat board sits in a 8.5\" x 11\" cherry frame that is 1.5\" deep to allow the raspberry pi to be backmounted while the frame is still flush to the wall. We hang the display next to the door above a key holder, which is generally the right place for it, but also helps hide the power cord.\nNot pretty, but it works\nProject Details\nThe software portion of the project is manageable although there are some gotchas when programming against the Waveshare e-ink hat in particular. We have a modular architecture with a clear separation of concerns:\n\nDisplay Engine: Renders the layout to the display, supporting communication with the physical e-ink display or rendering a png for non-raspberry pi development\n\nLayout System: A pretty hacky visual arrangement of the elements. It'd be fun to do something more sophisticated here (e.g. a html renderer), but ğŸ¤·â€â™‚ï¸. This will likely require the most work if you want to modify the project\n\nData Services: Fetch & process (this is important!) train arrival from NYC Transit GTFS feeds + get the weather forecasts\n\nApplication Controller: Orchestrate the event loop and subscription model to drive updates to the display\n\nThe biggest technical constraint is the update rate to the e-ink display. The display supports multiple update modes with different tradeoffs and can manage sub 500 ms updates, especially for partial updates, but a faster refresh results in fuzzy characters and substantial ghosting that looks pretty bad. The bigger issue is that overloading the display causes it to crash, which requires a full reset.\nAfter some testing, I chose a hybrid display update strategy.\nEvery second, the pixels around the seconds & minutes digits of the time are rerendered with the display's fastest partial update mode to make it clear that the display is functioning as expected.\nWhen there is an update to one of the next two train times (these matter more than trains 30 minutes away), there is a fast-full display render â€” all data is updated at this point, but only new arrival times for one of the next two trains will drive the update.\nOn the hour, the display does a deep full-screen render to sharpen the characters and remove ghosting.\nHonestly, you gotta experiment to understand how these will look\nDoing deep full screen renders can be jarring â€” it results in a black and white flash that attracts too much attention to the screen â€” but once an hour is a fine cadence. For the train times, a fast-full display render works better than a partial refresh because of the layout. The fast partial render cuts across elements, drawing more attention to the refresh than a full refresh. This could maybe be improved through more purposeful partial refresh rectangle selection, but the current solution works well.\nThe framing was tricky because I wanted something nice, but without breaking the bank. I'm not great at woodworking and I also didn't want to spend $300-$500, which was the range of quotes (FWIW, I have been trying to find a low cost framing solution for these broken glass pieces for years â€” let me know if you have any ideas). The e-ink display is awkwardly sized due to the connection cables and drivers. The display surface also has a fine looking, but inelegant border that should be covered. After talking to a few framers, one of them suggested I buy just a custom mat. The mat hides the display, Raspberry Pi, and cabling, but more importantly the outside of the mat is right sized to fit into a standard-sized frame.\nThe finished product sits neatly beside our door, providing the exact information we need at just the right time each morning. I've written before about the \"agency gap\" â€” the gap between what people do and what would be easy, but useful to do. This project is a bit more involved than that, but at ~20 hours of work, it was worth it to me. I built something that solves a daily need, we actually use it, guests talk about it, and it looks great.HomeNext â†’587 Miles, 803 Meetings, and 14 Dates: My completely sane system for personal analytics\n    Comments hosted by TwitterClick for discussion",
    "summary": {
      "en": "A Raspberry Pi project has been created to build an e-ink train and weather tracker that the author's wife loves. This device displays real-time train schedules for the F and G subway lines, along with the weather, making it easier for the couple to manage their morning routines without constantly checking their phones.\n\nThe tracker features a 9.7-inch e-ink display divided into sections showing the date, time, train arrival times, and upcoming weather. It's designed to be visually appealing and is mounted near the door for easy access. The software integrates data from the NYC Transit API and weather forecasts, with a focus on keeping the train information updated efficiently.\n\nThe project took about 20 hours to complete and aims to fill a daily need, enhancing the couple's morning experience. Instructions and materials for building one are available on GitHub.",
      "ko": "ë¼ì¦ˆë² ë¦¬ íŒŒì´ í”„ë¡œì íŠ¸ë¥¼ í†µí•´ ì €ìì˜ ì•„ë‚´ê°€ ì¢‹ì•„í•˜ëŠ” ì „ì ì‰í¬ ê¸°ì°¨ ë° ë‚ ì”¨ ì¶”ì ê¸°ê°€ ë§Œë“¤ì–´ì¡ŒìŠµë‹ˆë‹¤. ì´ ì¥ì¹˜ëŠ” Fì„ ê³¼ Gì„  ì§€í•˜ì² ì˜ ì‹¤ì‹œê°„ ìš´í–‰ ì •ë³´ë¥¼ ë³´ì—¬ì£¼ë©°, ë‚ ì”¨ ì •ë³´ë„ í•¨ê»˜ ì œê³µí•˜ì—¬ ë¶€ë¶€ê°€ ì•„ì¹¨ ì¼ê³¼ë¥¼ ê´€ë¦¬í•˜ëŠ” ë° ë„ì›€ì„ ì¤ë‹ˆë‹¤. ìŠ¤ë§ˆíŠ¸í°ì„ ìì£¼ í™•ì¸í•  í•„ìš”ê°€ ì—†ì–´ì¡ŒìŠµë‹ˆë‹¤.\n\nì¶”ì ê¸°ëŠ” 9.7ì¸ì¹˜ ì „ì ì‰í¬ ë””ìŠ¤í”Œë ˆì´ë¡œ êµ¬ì„±ë˜ì–´ ìˆìœ¼ë©°, ë‚ ì§œ, ì‹œê°„, ê¸°ì°¨ ë„ì°© ì‹œê°„, ë‹¤ê°€ì˜¤ëŠ” ë‚ ì”¨ë¥¼ ë³´ì—¬ì£¼ëŠ” ì„¹ì…˜ìœ¼ë¡œ ë‚˜ë‰˜ì–´ ìˆìŠµë‹ˆë‹¤. ì‹œê°ì ìœ¼ë¡œ ë§¤ë ¥ì ìœ¼ë¡œ ë””ìì¸ë˜ì—ˆê³ , ë¬¸ ê·¼ì²˜ì— ì„¤ì¹˜ë˜ì–´ ì‰½ê²Œ ì ‘ê·¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì†Œí”„íŠ¸ì›¨ì–´ëŠ” ë‰´ìš•ì‹œ ëŒ€ì¤‘êµí†µ APIì™€ ë‚ ì”¨ ì˜ˆë³´ ë°ì´í„°ë¥¼ í†µí•©í•˜ì—¬ ê¸°ì°¨ ì •ë³´ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì—…ë°ì´íŠ¸í•˜ëŠ” ë° ì¤‘ì ì„ ë‘ê³  ìˆìŠµë‹ˆë‹¤.\n\nì´ í”„ë¡œì íŠ¸ëŠ” ì•½ 20ì‹œê°„ì´ ì†Œìš”ë˜ì—ˆìœ¼ë©°, ë¶€ë¶€ì˜ ì•„ì¹¨ ê²½í—˜ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ ì¼ìƒì ì¸ í•„ìš”ë¥¼ ì¶©ì¡±ì‹œí‚¤ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì œì‘ ë°©ë²•ê³¼ í•„ìš”í•œ ì¬ë£ŒëŠ” GitHubì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
      "ja": "ãƒ©ã‚ºãƒ™ãƒªãƒ¼ãƒ‘ã‚¤ã‚’ä½¿ã£ãŸãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãŒä½œæˆã•ã‚Œã€è‘—è€…ã®å¦»ãŒæ°—ã«å…¥ã‚‹é›»å­ã‚¤ãƒ³ã‚¯ã®åˆ—è»Šã¨å¤©æ°—ã®ãƒˆãƒ©ãƒƒã‚«ãƒ¼ãŒå®Œæˆã—ã¾ã—ãŸã€‚ã“ã®ãƒ‡ãƒã‚¤ã‚¹ã¯ã€Fç·šã¨Gç·šã®åœ°ä¸‹é‰„ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã®é‹è¡Œã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã¨å¤©æ°—ã‚’è¡¨ç¤ºã—ã€å¤«å©¦ãŒæœã®ãƒ«ãƒ¼ãƒãƒ³ã‚’ç®¡ç†ã—ã‚„ã™ãã—ã¦ã„ã¾ã™ã€‚ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³ã‚’é »ç¹ã«ãƒã‚§ãƒƒã‚¯ã™ã‚‹å¿…è¦ãŒãªããªã‚Šã¾ã™ã€‚\n\nãƒˆãƒ©ãƒƒã‚«ãƒ¼ã¯9.7ã‚¤ãƒ³ãƒã®é›»å­ã‚¤ãƒ³ã‚¯ãƒ‡ã‚£ã‚¹ãƒ—ãƒ¬ã‚¤ã‚’å‚™ãˆã¦ãŠã‚Šã€æ—¥ä»˜ã€æ™‚é–“ã€åˆ—è»Šã®åˆ°ç€æ™‚åˆ»ã€ä»Šå¾Œã®å¤©æ°—ã‚’ç¤ºã™ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«åˆ†ã‹ã‚Œã¦ã„ã¾ã™ã€‚è¦‹ãŸç›®ã«ã‚‚ã“ã ã‚ã£ã¦ãŠã‚Šã€ãƒ‰ã‚¢ã®è¿‘ãã«å–ã‚Šä»˜ã‘ã‚‰ã‚Œã¦ã„ã¦ã€ç°¡å˜ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã™ã€‚ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã¯ãƒ‹ãƒ¥ãƒ¼ãƒ¨ãƒ¼ã‚¯å¸‚äº¤é€šå±€ã®APIã¨å¤©æ°—äºˆå ±ã®ãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆã—ã¦ãŠã‚Šã€åˆ—è»Šæƒ…å ±ã‚’åŠ¹ç‡çš„ã«æ›´æ–°ã™ã‚‹ã“ã¨ã«é‡ç‚¹ã‚’ç½®ã„ã¦ã„ã¾ã™ã€‚\n\nã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ç´„20æ™‚é–“ã§å®Œæˆã—ã€æ—¥å¸¸ã®ãƒ‹ãƒ¼ã‚ºã‚’æº€ãŸã™ã“ã¨ã‚’ç›®çš„ã¨ã—ã¦ã„ã¾ã™ã€‚å¤«å©¦ã®æœã®ä½“é¨“ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã®ã‚‚ã®ã§ã™ã€‚ä½œæˆæ–¹æ³•ã‚„å¿…è¦ãªææ–™ã¯GitHubã§å…¥æ‰‹å¯èƒ½ã§ã™ã€‚"
    }
  },
  {
    "id": "879e3d538b252cb6",
    "title": {
      "en": "Rubik's Cube Solutions, Puzzles, and 8-Balls (2023)",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://williambader.com/museum/cubes/cubes.html",
    "score": 25,
    "by": "wonger_",
    "time": 1743082818,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "1aa80557db21821e",
    "title": {
      "en": "Beyond Bohr and Einstein",
      "ko": "ë³´ì–´ì™€ ì•„ì¸ìŠˆíƒ€ì¸ ë„ˆë¨¸",
      "ja": "ãƒœãƒ¼ã‚¢ã¨ã‚¢ã‚¤ãƒ³ã‚·ãƒ¥ã‚¿ã‚¤ãƒ³ã‚’è¶…ãˆã¦"
    },
    "type": "story",
    "url": "https://cerncourier.com/beyond-bohr-and-einstein/",
    "score": 46,
    "by": "mathgenius",
    "time": 1743035841,
    "content": "Quantum Drama, by Jim Baggott and John L Heilbron, Oxford University Press\n\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tOne hundred years of insights Jim Baggott and John Heilbron donâ€™t neglect later quantum pioneers like John Bell (pictured). Credit: CERN\n\n\t\t\t\t\t\t\t\tWhen I was an undergraduate physics student in the mid-1980s, I fell in love with the philosophy of quantum mechanics. I devoured biographies of the greats of early-20th-century atomic physics â€“ physicists like Bohr, Heisenberg, SchrÃ¶dinger, Pauli, Dirac, Fermi and Born. To me, as I was struggling with the formalism of quantum mechanics, there seemed to be something so exciting, magical even, about that era, particularly those wonder years of the mid-1920s when its mathematical framework was being developed and the secrets of the quantum world were revealing themselves.\nI went on to do a PhD in nuclear reaction theory, which meant I spent most of my time working through mathemaÂ­tical derivations, becoming familiar with S-matrices, Greenâ€™s functions and scattering amplitudes, scribbling pages of angular-momentum algebra and coding in Fortran 77. And I loved that stuff. There certainly seemed to be little time for worrying about what was really going on inside atomic nuclei. Indeed, I was learning that even the notion of something â€œreally going onâ€ was a vague one. My generation of theoretical physicists were still being very firmly told to â€œshut up and calculateâ€, as many adherents of the Copenhagen school of quantum mechanics were keen to advocate. To be fair, so much progress has been made over the past century, in nuclear and particle physics, quantum optics, condensed-matter physics and quantum chemistry, that philosophical issues were seen as an unnecessary distraction. I recall one senior colleague, frustrated by my abiding interest in interpretational matters, admonishing me with: â€œJim, an electron is an electron is an electron. Stop trying to say more about it.â€ And there certainly seemed to be very little in the textbooks I was reading about unresolved issues arising from such topics as the EPR (Einsteinâ€“Podolskyâ€“Rosen) paradox and the measurement problem, let alone any analysis of the work of Hugh Everett and David Bohm, who were regarded as mavericks. The Copenhagen hegemony ruled supreme.\nWhat I wasnâ€™t aware of until later in my career was that a community of physicists had indeed continued to worry and think about such matters. These physicists were doing more than just debating and philosophising â€“ they were slowly advancing our understanding of the quantum world. Experimentalists such as Alain Aspect, John Clauser and Anton Zeilinger were devising ingenious experiments in quantum optics â€“ all three of whom were only awarded the Nobel Prize for their work on tests of John Bellâ€™s famous inequality in 2022, which says a lot about how we are only now acknowledging their contribution. Meanwhile, theorists such as Wojciech Zurek, Erich Joos, Deiter Zeh, Abner Shimony and Asher Peres, to name just a few, were formalising ideas on entanglement and decoherence theory. It is certainly high time that quantum-mechanics textbooks â€“ even advanced undergraduate ones â€“ should contain their new insights.\nCredit: Oxford University Press\nAll of which brings me to Quantum Drama, a new popular-science book and collaboration between the physicist and science writer Jim Baggott and the late historian of science John L Heilbron. In terms of level, the book is at the higher end of the popular-science market and, as such, will probably be of most interest to, for example, readers of CERN Courier. If I have a criticism of the book it is that its level is not consistent. For it tries to be all things. On occasion, it has wonderful biographical detail, often of less well-known but highly deserving characters. It is also full of wit and new insights. But then sometimes it can get mired in technical detail, such as in the lengthy descriptions of the different Bell tests, which I imagine only professional physicists are likely to fully appreciate.\n\n    googletag.cmd.push(function() { googletag.display('div-gpt-ad-5400963-1'); });\n\nHaving said that, the book is certainly timely. This year the world celebrates the centenary of quantum physics, since the publication of the momentous papers of Heisenberg and SchrÃ¶dinger on matrix and wave mechanics, in 1925 and 1926, respectively. Progress in quantum information theory and in the development of new quantum technologies is also gathering pace right now, with the promise of quantum computers, quantum sensing and quantum encryption getting ever closer. This all provides an opportunity for the philosophy of quantum mechanics to finally emerge from the shadows into mainstream debate again.\nA new narrative\nSo, what makes Quantum Drama stand out from other books that retell the story of quantum mechanics? Well, I would say that most historical accounts tend to focus only on that golden age between 1900 and 1927, which came to an end at the Solvay Conference in Brussels and those well-documented few days when Einstein and Bohr had their debate about what it all means. While these two giants of 20th-century physics make the front cover of the book, Quantum Drama takes the story on beyond that famous conference. Other accounts, both popular and scholarly, tend to push the narrative that Bohr won the argument, leaving generations of physicists with the idea that the interpretational issues had been resolved â€“ apart that is, from the odd dissenting voices from the likes of Everett or Bohm who tried, unsuccessfully it was argued, to put a spanner in the Copenhagen works. All the real progress in quantum foundations after 1927, or so we were told, was in the development of quantum field theories, such as QED and QCD, the excitement of high-energy physics and the birth of the Standard Model, with the likes of Murray Gell-Mann and Steven Weinberg replacing Heisenberg and SchrÃ¶dinger at centre stage. Quantum Drama takes up the story after 1927, showing that there has been a lively, exciting and ongoing dispute over what it all means, long after the death of those two giants of physics. In fact, the period up to Solvay 1927 is all dealt with in Act I of the book. The subtitle puts it well: From the Bohrâ€“Einstein Debate to the Riddle of Entanglement.\nThe Bohrâ€“Einstein debate is still very much alive and kicking\n\nAll in all, Quantum Drama delivers something remarkable, for it shines a light on all the muddle, complexity and confusion surrounding a century of debate about the meaning of quantum mechanics and the famous â€œCopenhagen spiritâ€, treating the subject with thoroughness and genuine scholarship, and showing that the Bohrâ€“Einstein debate is still very much alive and kicking.",
    "summary": {
      "en": "**Summary of *Quantum Drama* by Jim Baggott and John L Heilbron**\n\n*Quantum Drama* is a book that explores the history and philosophy of quantum mechanics, focusing on the ongoing debates and developments that have occurred since the early 20th century. Authors Jim Baggott and John Heilbron highlight the significant contributions of physicists beyond just the famous figures like Bohr and Einstein, noting that many others have continued to investigate the philosophical implications and complexities of quantum theory.\n\nThe book is timely, coinciding with the centenary of quantum physics, and emphasizes how advancements in quantum information technology are reigniting interest in the philosophical aspects of the subject. Unlike many historical accounts that conclude the debate after the 1927 Solvay Conference, *Quantum Drama* extends the narrative to show that discussions about the meaning of quantum mechanics are still very much ongoing.\n\nThe authors aim to present a thorough and engaging look at a century of scientific debate, emphasizing that the disagreements between Bohr and Einstein persist today. While the book offers rich biographical details and insights, it occasionally delves into technical content that might be challenging for general readers. Overall, it presents a comprehensive view of the evolution of quantum theory and its philosophical ramifications.",
      "ko": "*Quantum Drama*ëŠ” ì–‘ìì—­í•™ì˜ ì—­ì‚¬ì™€ ì² í•™ì„ íƒêµ¬í•˜ëŠ” ì±…ìœ¼ë¡œ, 20ì„¸ê¸° ì´ˆë¶€í„° í˜„ì¬ê¹Œì§€ ì´ì–´ì ¸ ì˜¨ ë…¼ìŸê³¼ ë°œì „ì„ ë‹¤ë£¹ë‹ˆë‹¤. ì €ì ì§ ë°°ê³³ê³¼ ì¡´ í•˜ì¼ë¸Œë¡ ì€ ë³´ì–´ì™€ ì•„ì¸ìŠˆíƒ€ì¸ê³¼ ê°™ì€ ìœ ëª…í•œ ë¬¼ë¦¬í•™ìë“¤ ì™¸ì—ë„ ë§ì€ ë‹¤ë¥¸ ì—°êµ¬ìë“¤ì´ ì–‘ì ì´ë¡ ì˜ ì² í•™ì  ì˜ë¯¸ì™€ ë³µì¡ì„±ì„ ê³„ì†í•´ì„œ ì¡°ì‚¬í•´ì™”ìŒì„ ê°•ì¡°í•©ë‹ˆë‹¤.\n\nì´ ì±…ì€ ì–‘ì ë¬¼ë¦¬í•™ì˜ 100ì£¼ë…„ê³¼ ë§ë¬¼ë ¤ ì¶œê°„ë˜ì–´, ì–‘ì ì •ë³´ ê¸°ìˆ ì˜ ë°œì „ì´ ì´ ì£¼ì œì˜ ì² í•™ì  ì¸¡ë©´ì— ëŒ€í•œ ê´€ì‹¬ì„ ë‹¤ì‹œ ë¶ˆëŸ¬ì¼ìœ¼í‚¤ê³  ìˆìŒì„ ê°•ì¡°í•©ë‹ˆë‹¤. ë§ì€ ì—­ì‚¬ì  ì„œìˆ ì´ 1927ë…„ ì†”ë² ì´ íšŒì˜ ì´í›„ ë…¼ìŸì´ ëë‚¬ë‹¤ê³  ê²°ë¡ ì§“ëŠ” ê²ƒê³¼ ë‹¬ë¦¬, *Quantum Drama*ëŠ” ì–‘ìì—­í•™ì˜ ì˜ë¯¸ì— ëŒ€í•œ ë…¼ì˜ê°€ ì—¬ì „íˆ ì§„í–‰ ì¤‘ì„ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.\n\nì €ìë“¤ì€ 100ë…„ ê°„ì˜ ê³¼í•™ì  ë…¼ìŸì„ ì² ì €í•˜ê³  í¥ë¯¸ë¡­ê²Œ ì‚´í´ë³´ë ¤ í•˜ë©°, ë³´ì–´ì™€ ì•„ì¸ìŠˆíƒ€ì¸ ê°„ì˜ ì˜ê²¬ ì°¨ì´ê°€ ì˜¤ëŠ˜ë‚ ì—ë„ ì—¬ì „íˆ ì¡´ì¬í•œë‹¤ëŠ” ì ì„ ê°•ì¡°í•©ë‹ˆë‹¤. ì´ ì±…ì€ í’ë¶€í•œ ì „ê¸°ì  ì„¸ë¶€ì‚¬í•­ê³¼ í†µì°°ì„ ì œê³µí•˜ì§€ë§Œ, ì¼ë°˜ ë…ìì—ê²ŒëŠ” ë‹¤ì†Œ ì–´ë ¤ìš¸ ìˆ˜ ìˆëŠ” ê¸°ìˆ ì ì¸ ë‚´ìš©ë„ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì „ë°˜ì ìœ¼ë¡œ ì–‘ì ì´ë¡ ì˜ ë°œì „ê³¼ ê·¸ ì² í•™ì  ê²°ê³¼ì— ëŒ€í•œ í¬ê´„ì ì¸ ì‹œê°ì„ ì œì‹œí•©ë‹ˆë‹¤.",
      "ja": "*Quantum Drama*ã¯ã€é‡å­åŠ›å­¦ã®æ­´å²ã¨å“²å­¦ã‚’æ¢æ±‚ã™ã‚‹æ›¸ç±ã§ã€20ä¸–ç´€åˆé ­ã‹ã‚‰ç¶šãè­°è«–ã‚„ç™ºå±•ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ã¾ã™ã€‚è‘—è€…ã®ã‚¸ãƒ ãƒ»ãƒã‚´ãƒƒãƒˆã¨ã‚¸ãƒ§ãƒ³ãƒ»ãƒã‚¤ãƒ«ãƒ–ãƒ­ãƒ³ã¯ã€ãƒœãƒ¼ã‚¢ã‚„ã‚¢ã‚¤ãƒ³ã‚·ãƒ¥ã‚¿ã‚¤ãƒ³ã¨ã„ã£ãŸè‘—åãªç‰©ç†å­¦è€…ã ã‘ã§ãªãã€å¤šãã®ä»–ã®ç ”ç©¶è€…ãŒé‡å­ç†è«–ã®å“²å­¦çš„ãªæ„å‘³ã‚„è¤‡é›‘ã•ã‚’æ¢æ±‚ã—ç¶šã‘ã¦ã„ã‚‹ã“ã¨ã‚’å¼·èª¿ã—ã¦ã„ã¾ã™ã€‚\n\nã“ã®æœ¬ã¯ã€é‡å­ç‰©ç†å­¦ã®100å‘¨å¹´ã«åˆã‚ã›ã¦å‡ºç‰ˆã•ã‚Œã€é‡å­æƒ…å ±æŠ€è¡“ã®é€²å±•ãŒã“ã®åˆ†é‡ã®å“²å­¦çš„å´é¢ã¸ã®é–¢å¿ƒã‚’å†ç‡ƒã•ã›ã¦ã„ã‚‹ã“ã¨ã‚’å¼·èª¿ã—ã¦ã„ã¾ã™ã€‚å¤šãã®æ­´å²çš„ãªè¨˜è¿°ãŒ1927å¹´ã®ã‚½ãƒ«ãƒ™ã‚¤ä¼šè­°ã§è­°è«–ãŒçµ‚ã‚ã£ãŸã¨ã™ã‚‹ã®ã«å¯¾ã—ã€*Quantum Drama*ã¯ãã®å¾Œã‚‚é‡å­åŠ›å­¦ã®æ„å‘³ã«ã¤ã„ã¦ã®è­°è«–ãŒç¶šã„ã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚\n\nè‘—è€…ãŸã¡ã¯ã€ç§‘å­¦çš„ãªè­°è«–ã®100å¹´ã‚’åŒ…æ‹¬çš„ã‹ã¤é­…åŠ›çš„ã«ç´¹ä»‹ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¦ãŠã‚Šã€ãƒœãƒ¼ã‚¢ã¨ã‚¢ã‚¤ãƒ³ã‚·ãƒ¥ã‚¿ã‚¤ãƒ³ã®å¯¾ç«‹ãŒä»Šã‚‚ç¶šã„ã¦ã„ã‚‹ã“ã¨ã‚’å¼·èª¿ã—ã¦ã„ã¾ã™ã€‚æœ¬æ›¸ã¯è±Šå¯Œãªä¼è¨˜æƒ…å ±ã‚„æ´å¯Ÿã‚’æä¾›ã—ã¤ã¤ã€ä¸€èˆ¬èª­è€…ã«ã¯é›£ã—ã„æŠ€è¡“çš„ãªå†…å®¹ã«ã‚‚è§¦ã‚Œã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚å…¨ä½“ã¨ã—ã¦ã€é‡å­ç†è«–ã®é€²åŒ–ã¨ãã®å“²å­¦çš„å½±éŸ¿ã«ã¤ã„ã¦ã®åŒ…æ‹¬çš„ãªè¦–ç‚¹ã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚"
    }
  },
  {
    "id": "099893d623ca6d0b",
    "title": {
      "en": "Show HN: Bknd â€“ Firebase alternative that embeds into any React stack",
      "ko": "ì‡¼ HN: Bknd â€“ ë¦¬ì•¡íŠ¸ì— ìµœì í™”ëœ íŒŒì´ì–´ë² ì´ìŠ¤ ëŒ€ì•ˆ",
      "ja": "Firebaseã®ä»£æ›¿ã€ŒBkndã€"
    },
    "type": "story",
    "url": "https://github.com/bknd-io/bknd",
    "score": 45,
    "by": "dswbx",
    "time": 1742913257,
    "content": "â­ Live Demo\n\nbknd simplifies app development by providing a fully functional backend for database management, authentication, media and workflows. Being lightweight and built on Web Standards, it can be deployed nearly anywhere, including running inside your framework of choice. No more deploying multiple separate services!\nFor documentation and examples, please visit https://docs.bknd.io.\nWarningPlease keep in mind that bknd is still under active development\nand therefore full backward compatibility is not guaranteed before reaching v1.0.0.\n\nSize\n\nThe size on npm is misleading, as the bknd package includes the backend, the ui components as well as the whole backend bundled into the cli including static assets.\nDepending on what you use, the size can be higher as additional dependencies are getting pulled in. The minimal size of a full bknd app as an API is around 212 kB gzipped (e.g. deployed as Cloudflare Worker).\nMotivation\nCreating digital products always requires developing both the backend (the logic) and the frontend (the appearance). Building a backend from scratch demands deep knowledge in areas such as authentication and database management. Using a backend framework can speed up initial development, but it still requires ongoing effort to work within its constraints (e.g., \"how to do X with Y?\"), which can quickly slow you down. Choosing a backend system is a tough decision, as you might not be aware of its limitations until you encounter them.\nThe solution: A backend system that only assumes and implements primitive details, integrates into multiple environments, and adheres to industry standards.\nFeatures\n\nâš¡ Instant backend with full REST API:\n\nData: Define, query, and control your data with ease.\nAuth: Easily implement reliable authentication strategies.\nMedia: Effortlessly manage and serve all your media files.\nFlows: Design and run workflows with seamless automation. (UI integration coming soon!)\n\nğŸŒ Built on Web Standards for maximum compatibility\nğŸƒâ€â™‚ï¸ Multiple run modes\n\nstandalone using the CLI\nusing a JavaScript runtime (Node, Bun, workerd)\nusing a React framework (Next.js, React Router, Astro)\n\nğŸ“¦ Official API and React SDK with type-safety\nâš›ï¸ React elements for auto-configured authentication and media components\n\nStructure\nThe package is mainly split into 4 parts, each serving a specific purpose:\n\nImport\nPurpose\n\nbkndbknd/adapter/*\nBackend including APIs and adapters\n\nbknd/ui\nAdmin UI components for react frameworks\n\nbknd/client\nTypeScript SDK and React hooks for the API endpoints\n\nbknd/elements\nReact components for authentication and media\n\nThe backend (bknd)\nServe the backend as an API for any JS runtime or framework. The latter is especially handy, as it allows you to deploy your frontend and backend bundled together. Furthermore it allows adding additional logic in a way you're already familar with. Just add another route and you're good to go.\nHere is an example of serving the API using node:\nimport { serve } from \"bknd/adapter/node\"\nserve();\n\nIntegrated admin UI (bknd/ui)\nThe admin UI allows to manage your data including full configuration of your backend using a graphical user interface. Using vite, your admin route looks like this:\nimport { Admin } from \"bknd/ui\"\nimport \"bknd/dist/styles.css\";\n\nexport default function AdminPage() {\n   return <Admin />\n}\n\nUsing the REST API or TypeScript SDK (bknd/client)\nIf you're not using a JavaScript environment, you can still access any endpoint using the REST API:\ncurl -XGET <your-endpoint>/api/data/entity/<entity>\n{\n  \"data\": [\n    { \"id\": 1, ... },\n    { \"id\": 2, ... }\n  ],\n  \"meta\": { /* ... */ }\n}\n\nIn a JavaScript environment, you can use the TypeScript SDK with type-safety. The above example would look like this:\nimport { Api } from \"bknd/client\";\n\nconst api = new Api({ host: \"<endpoint>\" });\nconst { data } = await api.data.readMany(\"<entity>\");\n\nIf you're using React, there are 2 hooks exposed (useApi, useEntity), as well as an swr wrapper around each (useApiQuery, useEntityQuery). The swr wrapped hooks automatically handled query invalidation:\nimport { useState } from \"react\";\nimport { useEntityQuery } from \"bknd/client\";\n\nexport default function App() {\n   const { data } = useEntityQuery(\"todos\");\n   return <ul>\n      {data?.map(todo => (\n         <li key={todo.id}>{todo.name}</li>\n      ))}\n   </ul>\n}\n\nReact elements (bknd/elements)\nYou don't have to figure out API details to include media uploads to your app. For an user avatar upload, this is all you need:\nimport { Media } from \"bknd/elements\"\nimport \"bknd/dist/main.css\"\n\nexport function UserAvatar() {\n   return <Media.Dropzone\n     entity={{ name: \"users\", id: 1, field: \"avatar\" }}\n     maxItems={1}\n     overwrite\n   />\n}\n\nThe import path also exports components for login and registration forms which are automatically pointed to the bknd defaults.\nğŸš€ Quick start\nTo quickly spin up an instance, run:\nnpx bknd run\n\nInstallation\nnpm install bknd",
    "summary": {
      "en": "**Summary of bknd**\n\nbknd is a tool that simplifies app development by providing an easy-to-use backend for managing databases, user authentication, media, and automated workflows. It's lightweight and can be deployed in various environments, eliminating the need for multiple separate services. However, itâ€™s still in development, so some features may change before the final version.\n\n**Key Features:**\n- **Instant Backend:** Offers a full REST API for managing data and authentication seamlessly.\n- **Web Standards:** Built for compatibility across different platforms.\n- **Multiple Deployment Options:** Can run standalone, in a JavaScript runtime, or within React frameworks.\n- **Type-Safe SDK:** Includes a TypeScript SDK and React components for easy integration.\n\n**Structure:**\n1. **Backend (bknd):** Serves APIs for any JavaScript environment.\n2. **Admin UI (bknd/ui):** A graphical interface for managing your backend data.\n3. **API Access (bknd/client):** Use REST API or TypeScript SDK for data interactions.\n4. **React Components (bknd/elements):** Pre-built components for user authentication and media uploads.\n\n**Quick Start:** To set it up, simply run `npx bknd run` after installation with `npm install bknd`.\n\nFor more details and examples, visit the [bknd documentation](https://docs.bknd.io).",
      "ko": "bkndëŠ” ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬, ì‚¬ìš©ì ì¸ì¦, ë¯¸ë””ì–´ ì²˜ë¦¬ ë° ìë™í™”ëœ ì›Œí¬í”Œë¡œìš°ë¥¼ ìœ„í•œ ì‚¬ìš©í•˜ê¸° ì‰¬ìš´ ë°±ì—”ë“œë¥¼ ì œê³µí•˜ì—¬ ì•± ê°œë°œì„ ê°„ì†Œí™”í•˜ëŠ” ë„êµ¬ì…ë‹ˆë‹¤. ì´ ë„êµ¬ëŠ” ê°€ë³ê³  ë‹¤ì–‘í•œ í™˜ê²½ì— ë°°í¬í•  ìˆ˜ ìˆì–´ ì—¬ëŸ¬ ê°œì˜ ë³„ë„ ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ í˜„ì¬ ê°œë°œ ì¤‘ì´ë¯€ë¡œ ìµœì¢… ë²„ì „ì—ì„œëŠ” ì¼ë¶€ ê¸°ëŠ¥ì´ ë³€ê²½ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nbkndì˜ ì£¼ìš” ê¸°ëŠ¥ìœ¼ë¡œëŠ” ì™„ì „í•œ REST APIë¥¼ ì œê³µí•˜ì—¬ ë°ì´í„°ì™€ ì¸ì¦ì„ ì›í™œí•˜ê²Œ ê´€ë¦¬í•  ìˆ˜ ìˆëŠ” ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥í•œ ë°±ì—”ë“œê°€ ìˆìŠµë‹ˆë‹¤. ë‹¤ì–‘í•œ í”Œë«í¼ê³¼ì˜ í˜¸í™˜ì„±ì„ ìœ„í•´ ì›¹ í‘œì¤€ì— ë§ì¶° ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. ë˜í•œ ë…ë¦½ì ìœ¼ë¡œ ì‹¤í–‰ë˜ê±°ë‚˜ JavaScript ëŸ°íƒ€ì„, React í”„ë ˆì„ì›Œí¬ ë‚´ì—ì„œ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” ì—¬ëŸ¬ ë°°í¬ ì˜µì…˜ì„ ì œê³µí•©ë‹ˆë‹¤. TypeScript SDKì™€ React ì»´í¬ë„ŒíŠ¸ë¥¼ í¬í•¨í•˜ì—¬ ì‰½ê²Œ í†µí•©í•  ìˆ˜ ìˆëŠ” íƒ€ì… ì•ˆì „í•œ SDKë„ ì œê³µí•©ë‹ˆë‹¤.\n\nbkndì˜ êµ¬ì¡°ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. ì²«ì§¸, bkndëŠ” ëª¨ë“  JavaScript í™˜ê²½ì„ ìœ„í•œ APIë¥¼ ì œê³µí•©ë‹ˆë‹¤. ë‘˜ì§¸, bknd/uiëŠ” ë°±ì—”ë“œ ë°ì´í„°ë¥¼ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ê·¸ë˜í”½ ì¸í„°í˜ì´ìŠ¤ì…ë‹ˆë‹¤. ì…‹ì§¸, bknd/clientë¥¼ í†µí•´ REST API ë˜ëŠ” TypeScript SDKë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ì™€ ìƒí˜¸ì‘ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ, bknd/elementsëŠ” ì‚¬ìš©ì ì¸ì¦ ë° ë¯¸ë””ì–´ ì—…ë¡œë“œë¥¼ ìœ„í•œ ë¯¸ë¦¬ êµ¬ì¶•ëœ ì»´í¬ë„ŒíŠ¸ì…ë‹ˆë‹¤.\n\nì„¤ì¹˜ë¥¼ ë§ˆì¹œ í›„ `npm install bknd`ë¡œ ì„¤ì¹˜í•œ ë‹¤ìŒ, `npx bknd run` ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ë©´ ì‰½ê²Œ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë” ë§ì€ ì •ë³´ì™€ ì˜ˆì œëŠ” bknd ë¬¸ì„œë¥¼ ë°©ë¬¸í•˜ì„¸ìš”.",
      "ja": "bkndã¯ã€ã‚¢ãƒ—ãƒªé–‹ç™ºã‚’ç°¡ç´ åŒ–ã™ã‚‹ãƒ„ãƒ¼ãƒ«ã§ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç®¡ç†ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼èªè¨¼ã€ãƒ¡ãƒ‡ã‚£ã‚¢ç®¡ç†ã€è‡ªå‹•åŒ–ã•ã‚ŒãŸãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’ç°¡å˜ã«æ‰±ãˆã‚‹ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚’æä¾›ã—ã¾ã™ã€‚è»½é‡ã§ã€ã•ã¾ã–ã¾ãªç’°å¢ƒã«å±•é–‹ã§ãã‚‹ãŸã‚ã€è¤‡æ•°ã®ã‚µãƒ¼ãƒ“ã‚¹ã‚’ä½¿ã†å¿…è¦ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ãŸã ã—ã€ã¾ã é–‹ç™ºä¸­ã®ãŸã‚ã€æœ€çµ‚ç‰ˆã§ã¯ä¸€éƒ¨ã®æ©Ÿèƒ½ãŒå¤‰æ›´ã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\n\nbkndã®ä¸»ãªç‰¹å¾´ã«ã¯ã€ãƒ‡ãƒ¼ã‚¿ã¨èªè¨¼ã‚’ã‚·ãƒ¼ãƒ ãƒ¬ã‚¹ã«ç®¡ç†ã™ã‚‹ãŸã‚ã®å®Œå…¨ãªREST APIã‚’æä¾›ã™ã‚‹ã€Œã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ãƒˆãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã€ã€ç•°ãªã‚‹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ é–“ã§ã®äº’æ›æ€§ã‚’è€ƒæ…®ã—ã¦æ§‹ç¯‰ã•ã‚ŒãŸã€Œã‚¦ã‚§ãƒ–ã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰ã€ã€å˜ç‹¬ã§å‹•ä½œã™ã‚‹ã“ã¨ã‚‚ã€JavaScriptãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã‚„Reactãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯å†…ã§å‹•ä½œã™ã‚‹ã“ã¨ã‚‚ã§ãã‚‹ã€Œè¤‡æ•°ã®å±•é–‹ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã€ã€ãã—ã¦ç°¡å˜ã«çµ±åˆã§ãã‚‹TypeScript SDKã¨Reactã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’å«ã‚€ã€Œå‹å®‰å…¨ãªSDKã€ãŒã‚ã‚Šã¾ã™ã€‚\n\nbkndã®æ§‹æˆã¯ã€JavaScriptç’°å¢ƒå‘ã‘ã«APIã‚’æä¾›ã™ã‚‹ã€Œãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ï¼ˆbkndï¼‰ã€ã€ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒ‡ãƒ¼ã‚¿ã‚’ç®¡ç†ã™ã‚‹ãŸã‚ã®ã‚°ãƒ©ãƒ•ã‚£ã‚«ãƒ«ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã€Œç®¡ç†UIï¼ˆbknd/uiï¼‰ã€ã€ãƒ‡ãƒ¼ã‚¿æ“ä½œã®ãŸã‚ã«REST APIã¾ãŸã¯TypeScript SDKã‚’ä½¿ç”¨ã™ã‚‹ã€ŒAPIã‚¢ã‚¯ã‚»ã‚¹ï¼ˆbknd/clientï¼‰ã€ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼èªè¨¼ã‚„ãƒ¡ãƒ‡ã‚£ã‚¢ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç”¨ã®äº‹å‰æ§‹ç¯‰ã•ã‚ŒãŸã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã€ŒReactã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆï¼ˆbknd/elementsï¼‰ã€ã‹ã‚‰æˆã‚Šç«‹ã£ã¦ã„ã¾ã™ã€‚\n\nã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã¯ç°¡å˜ã§ã€ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å¾Œã«ã€Œnpx bknd runã€ã‚’å®Ÿè¡Œã™ã‚‹ã ã‘ã§é–‹å§‹ã§ãã¾ã™ã€‚è©³ç´°ã‚„ä¾‹ã«ã¤ã„ã¦ã¯ã€bkndã®å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚"
    }
  },
  {
    "id": "981caf3cbe377770",
    "title": {
      "en": "We hacked Gemini's Python sandbox and leaked its source code (at least some)",
      "ko": "ì œë¯¸ë‹ˆ íŒŒì´ì¬ í•´í‚¹!",
      "ja": "ã‚¸ã‚§ãƒŸãƒ‹ã®ç§˜å¯†ã‚’æš´éœ²ï¼"
    },
    "type": "story",
    "url": "https://www.landh.tech/blog/20250327-we-hacked-gemini-source-code/",
    "score": 633,
    "by": "topsycatt",
    "time": 1743185578,
    "content": "<<Back to BlogWe hacked Googleâ€™s A.I Gemini and leaked its source code (at least some part)Mar 27, 2025RONI CARTA | LUPINgemini, llm, google, source code, leak, bug bounty, hackBack to Vegas, and This Time, We Brought Home the MVH Award !\nIn 2024 we released the blog post We Hacked Google A.I. for $50,000, where we traveled in 2023 to Las Vegas with Joseph \"rez0\" Thacker, Justin \"Rhynorater\" Gardner, and myself, Roni \"Lupin\" Carta, on a hacking journey that spanned from Las Vegas, Tokyo to France, all in pursuit of Gemini vulnerabilities during Google's LLM bugSWAT event. Well, we did it again â€¦\nThe world of Generative Artificial Intelligence (GenAI) and Large Language Models (LLMs) continues to be the Wild West of tech.  Since GPT burst onto the scene, the race to dominate the LLM landscape has only intensified, with tech giants like Meta, Microsoft, and Google racing to have the best model possible. But now there is also Anthropic, Mistral, Deepseek and more that are coming to the scene and impacting the industry at scale.\nAs companies rush to deploy AI assistants, classifiers, and a myriad of other LLM-powered tools, a critical question remains: are we building securely ?  As we highlighted last year, the rapid adoption sometimes feels like we forgot the fundamental security principles, opening the door to novel and familiar vulnerabilities alike.\nAI agents are rapidly emerging as the next game-changer in the world of artificial intelligence. These intelligent entities leverage advanced chains of thought reasoning, a process where the model generates a coherent sequence of internal reasoning steps to solve complex tasks. By documenting their thought processes, these agents not only enhance their decision-making capabilities but also provide transparency, allowing developers and researchers to understand and refine their performance. This dynamic combination of autonomous action and visible reasoning is paving the way for AI systems that are more adaptive, interpretable, and reliable. As we witness an increasing number of applications. from interactive assistants to sophisticated decision-support systems. The integration of chain-of-thought reasoning in AI agents is setting a new standard for what these models can achieve in real-world scenarios.\nGoogle, to their credit, are actively recognising this emerging frontier of AI security, and they started early on.  Their \"LLM bugSWAT\" events, held in vibrant locales like Las Vegas, are a testament to their commitment to proactive security red teaming.  These events challenge researchers worldwide to rigorously test their AI systems, seeking out the vulnerabilities that might otherwise slip through the cracks.\nAnd guess what ? We answered the call again in 2024 !  Justin and I returned to the bugSWAT event in Las Vegas, and this time, our efforts paid off in a big way.  Thanks to a brand new vulnerability in Gemini,  the one weâ€™re about to detail, we were incredibly honored to be awarded the Most Valuable Hacker (MVH) title at this year's Las Vegas bugSWAT !\n\nPicture taken with our MVH award and 2 awesome Googlers <3\nSo, prepare to dive deep once more.  This isn't just a repeat performance; it's a whole new vulnerability that we are about to show you ;)\nDiscovering the new Gemini\nThe Google team granted us early access to a preview of the next Gemini update, one that had several exciting new features. Along with this exclusive access, we received detailed documentation explaining these features and their intended functionalities. The goal was to fully explore and test these capabilities from an attackerâ€™s perspective.\nIt all started with a simple prompt. We asked Gemini:\nrun hello world in python3\n\nGemini provided the code, and the interface offered the enticing \"Run in Sandbox\" button. Intrigued, we started exploring.\n\nGemini's Python Playground â€“ A Secure Space... or Was It ?\nGemini at the time offered a Python Sandbox Interpreter. Think of it as a safe space where you can run Python code generated by the AI itself, or even your own custom scripts, right within the Gemini environment. This sandbox, powered by Google's Gvisor in a GRTE (Google Runtime Environment), is designed to be secure. The idea is you can experiment with code without risking any harm to the underlying system, a crucial feature for testing and development.\ngVisor is a user-space kernel developed by Google that acts as an intermediary between containerized applications and the host operating system. By intercepting system calls made by applications, it enforces strict security boundaries that reduce the risk of container escapes and limit potential damage from compromised processes. Rather than relying solely on traditional OS-level isolation, gVisor implements a minimal, tailored subset of kernel functionalities, thereby reducing the attack surface while still maintaining reasonable performance. This innovative approach enhances the security of container environments, making gVisor an essential tool for safely running and managing containerized workloads.\nAs security researchers and bug bounty hunters, we know that this gVisor sandbox is secured with multiple layers of defense and from what weâ€™ve seen no one managed to escape this sandbox. Actually a sandbox escape could award you a $100k bounty:\n\nWhile it might be possible to still escape it, this is a whole different set of challenges than what we were looking for.\nHowever, sandboxes are not always meant to be escaped since there are a lot of cases where there is stuff inside the sandbox itself that can help us leak data. This idea, shared with us by a Googler from the security team, was to be able to have shell access inside the Sandbox itself and try to find any piece of data that wasn't supposed to be accessible. The main problem was the following: This sandbox can only run a custom compiled Python binary.\nMapping the Territory\nThe first thing we saw is that it was also possible from the Front End to entirely rewrite the Python code and run our arbitrary version in the sandbox. Our first step was to understand the structure of this sandbox. We suspected there might be interesting files lurking around. Since we canâ€™t pop a shell, we checked which libraries were available in this custom compiled Python binary. We found out that os was present ! Great, we can then use it to map the filesystem.\nWe wrote the following Python Code:\nimport os\n\ndef get_size_formatted(size_in_bytes):\n    if size_in_bytes >= 1024 ** 3:\n        size = size_in_bytes / (1024 ** 3)\n        unit = \"Go\"\n    elif size_in_bytes >= 1024 ** 2:\n        size = size_in_bytes / (1024 ** 2)\n        unit = \"Mb\"\n    else:\n        size = size_in_bytes / 1024\n        unit = \"Ko\"\n    return f\"{size:.2f} {unit}\"\n\ndef lslR(path):\n    try:\n        # Determine if the path is a directory or a file\n        if os.path.isdir(path):\n            type_flag = 'd'\n            total_size = sum(os.path.getsize(os.path.join(path, f)) for f in os.listdir(path))\n        else:\n            type_flag = 'f'\n            total_size = os.path.getsize(path)\n\n        size_formatted = get_size_formatted(total_size)\n\n        # Check read and write permissions\n        read_flag = 'r' if os.access(path, os.R_OK) else '-'\n        write_flag = 'w' if os.access(path, os.W_OK) else '-'\n\n        # Print the type, permissions, size, and path\n        print(f\"{type_flag}{read_flag}{write_flag} - {size_formatted} - {path}\")\n\n        # If it's a directory, recursively print the contents\n        if type_flag == 'd':\n            for entry in os.listdir(path):\n                entry_path = os.path.join(path, entry)\n                lslR(entry_path)\n    except PermissionError:\n        print(f\"d-- - 0Ko - {path} (PermissionError: cannot access)\")\n    except Exception as e:\n        print(f\"--- - 0Ko - {path} (Error: {e})\")\n\nThe goal for this code was to have some kind of recursive listing of files and directories function to be able to see which files are present, their size and also their permissions.\nWeâ€™ve used the function to list the lslR(\"/usr\") directory.\n\nThis call identified a binary file located at /usr/bin/entry/entry_point. This sounds juicy !\n\nLeak the entry_point file\nOur next move was to extract this file, but with it being 579Mb in size, directly base64 encoding and printing it in the Front End wasn't an option, it caused the entire sandbox to hang until it eventually timed out.\nWe attempted to see if we could run TCP, HTTP, and DNS calls to exfiltrate information. Intriguingly, all our outbound connection attempts failed, the sandbox appeared completely isolated from the external network. This led to an interesting puzzle: if the sandbox is so tightly isolated that it cannot make external calls, how does it interface with Google services like Google Flights and others ? Well â€¦ we might be able to answer this later ;D\nSo we needed to exfiltrate this binary by printing in the console into chunks, for that we used the seek() function to walk through the binary file and retrieve the entire binary in chunks of 10 MB.\nimport os\nimport base64\n\ndef read_and_encode(file_path, kilobytes):\n    try:\n        # Calculate the number of bytes to read\n        num_bytes = kilobytes * 1024\n\n        # Open the file and read the specified number of bytes\n        with open(file_path, 'rb') as file:\n            file_content = file.read(num_bytes)\n\n        # Base64 encode the bytes\n        encoded_content = base64.b64encode(file_content)\n\n        # Print the encoded string\n        print(encoded_content.decode('utf-8'))\n\n    except FileNotFoundError:\n        print(f\"FileNotFoundError: {file_path} does not exist\")\n    except PermissionError:\n        print(f\"PermissionError: Cannot access {file_path}\")\n    except Exception as e:\n        print(f\"Error: {e}\")\n\nread_and_encode(\"/usr/bin/entry/entry_point\", 10000)\n\nWe then used Caido to catch the request in our proxy that would run the sandbox call and fetch the result and then send it into the Automate feature. The Automate feature allows you to send requests in bulk. This feature provides a flexible way to initiate bruteforce/fuzzing to rapidly modify certain parameters of requests using wordlists.\n\nNote from Lupin: In the article it seems like a straightforward path, but actually we took several hours to get to that point. It was 3 am we were hacking with Justin and I was sleeping on my keyboard while Justin was exfiltrating the binary using Caido.\n\nOnce we had all the base64 chunks, we reconstructed the entire file locally and we were ready to see its content.\nHow to read this file ?\nfile command ?\nRunning the file command on the binary revealed its identity as an binary: ELF 64-bit LSB shared object, x86-64, version 1 (SYSV), dynamically linked, interpreter /usr/grte/v5/lib64/ld-linux-x86-64.so.2 This  confirms that the file is a binary. Mmmmmh what can we do with this ?\nstrings command ?\nWhen we executed the strings command, the output was particularly intriguing due to multiple references to google3, Googleâ€™s internal repository. This pointed to the presence of internal data paths and code snippets that were never meant for external exposure, clearly indicating that the binary contains traces of Googleâ€™s proprietary software. But is there actually any security implication ?\nBinwalk FTW !\nThe real breakthrough came when using Binwalk. This tool managed to extract an entire file structure from within the binary, revealing a comprehensive sandbox layout. The extraction uncovered multiple directories and files, painting a detailed picture of the internal architecture and exposing components where our reaction upon what we found was like ... OMG.\nWait â€¦ is that internal Source Code ?\nWhen digging into the extract generated by our binwalk analysis, we unexpectedly found internal source code. The extraction revealed entire directories of proprietary Google source code. But is it sensitive ?\nGoogle3 Directory with Python Code\nIn the binwalk extracted directory we can find a google3 directory with the following files:\ntotal 2160\ndrwxr-xr-x   14 lupin  staff   448B Aug  7 06:17 .\ndrwxr-xr-x  231 lupin  staff   7.2K Aug  7 18:31 ..\n-r-xr-xr-x    1 lupin  staff   1.1M Jan  1  1980 __init__.py\ndrwxr-xr-x    5 lupin  staff   160B Aug  7 06:17 _solib__third_Uparty_Scrosstool_Sv18_Sstable_Ccc-compiler-k8-llvm\ndrwxr-xr-x    4 lupin  staff   128B Aug  7 06:17 assistant\ndrwxr-xr-x    4 lupin  staff   128B Aug  7 06:17 base\ndrwxr-xr-x    5 lupin  staff   160B Aug  7 06:17 devtools\ndrwxr-xr-x    4 lupin  staff   128B Aug  7 06:17 file\ndrwxr-xr-x    4 lupin  staff   128B Aug  7 06:17 google\ndrwxr-xr-x    4 lupin  staff   128B Aug  7 06:17 net\ndrwxr-xr-x    9 lupin  staff   288B Aug  7 06:17 pyglib\ndrwxr-xr-x    4 lupin  staff   128B Aug  7 06:17 testing\ndrwxr-xr-x    9 lupin  staff   288B Aug  7 06:17 third_party\ndrwxr-xr-x    4 lupin  staff   128B Aug  7 06:17 util\n\nIn the assistant directory, internal Gemini code related to RPC calls (used for handling requests via tools like YouTube, Google Flights, Google Maps, etc.) was also discovered. The directory structure is as follows:\n.\nâ”œâ”€â”€ __init__.py\nâ””â”€â”€ boq\n    â”œâ”€â”€ __init__.py\n    â””â”€â”€ lamda\n        â”œâ”€â”€ __init__.py\n        â””â”€â”€ execution_box\n            â”œâ”€â”€ __init__.py\n            â”œâ”€â”€ images\n            â”‚   â”œâ”€â”€ __init__.py\n            â”‚   â”œâ”€â”€ blaze_compatibility_hack.py\n            â”‚   â”œâ”€â”€ charts_json_writer.py\n            â”‚   â”œâ”€â”€ format_exception.py\n            â”‚   â”œâ”€â”€ library_overrides.py\n            â”‚   â”œâ”€â”€ matplotlib_post_processor.py\n            â”‚   â”œâ”€â”€ py_interpreter.py\n            â”‚   â”œâ”€â”€ py_interpreter_main.py\n            â”‚   â””â”€â”€ vegalite_post_processor.py\n            â”œâ”€â”€ sandbox_interface\n            â”‚   â”œâ”€â”€ __init__.py\n            â”‚   â”œâ”€â”€ async_sandbox_rpc.py\n            â”‚   â”œâ”€â”€ sandbox_rpc.py\n            â”‚   â”œâ”€â”€ sandbox_rpc_pb2.pyc\n            â”‚   â””â”€â”€ tool_use\n            â”‚       â”œâ”€â”€ __init__.py\n            â”‚       â”œâ”€â”€ metaprogramming.py\n            â”‚       â””â”€â”€ runtime.py\n            â””â”€â”€ tool_use\n                â”œâ”€â”€ __init__.py\n                â””â”€â”€ planning_immersive_lib.py\n\n8 directories, 22 files\n\nA Closer Look at the Python Code\nInside the file google3/assistant/boq/lamda/execution_box/images/py_interpreter.py, a snippet of code reveals:\n# String for attempted script dump detection:\n  snippet = (  # pylint: disable=unused-variable\n      \"3AVp#dzcQj$U?uLOj+Gl]GlY<+Z8DnKh\"  # pylint: disable=unused-variable\n  )\n\nThis snippet appears to serve as a safeguard against unauthorized script dumping, underscoring that the code was never intended for public exposure.\n\nAfter a thorough review, the inclusion of what appeared to be internal Google3 code was, in fact, a deliberate choiceâ€¦ Too bad x)\nThe Python code, despite its anti-dumping mechanism that might initially indicate restricted access, had been explicitly approved for public exposure by the Google Security Team well before launch. Although these measures were originally designed to prevent unintended printing, they were retained because â€¦ why not ?\nBut we didnâ€™t leave this sandbox alone, we knew we were close to something huge ! ;D\nDigging the main logic of the Sandbox\nWhile digging deeper into the Python code, we noticed that, as expected, this sandbox was communicating with external Google servers to perform activities such as fetch data from Google Flights or other Google services.\nThis was implemented via a python class (google3.assistant.boq.lamda.execution_box.sandbox_interface) which exposed various functions like _set_reader_and_writer  that could be called.\ndef _set_reader_and_writer(\n    reader_handle: io.BufferedReader | None,\n    writer_handle: io.BufferedWriter | None,\n) -> None:\n  \"\"\"Sets the reader and writer handles for rpcs.\n\n  Should be called before running any user code that might\n  import async_sandbox_rpc\n\n  Args:\n    reader_handle: the handle through which to receive incoming RpcResponses. If\n      None will default to legacy behavior (/dev/fd/3)\n    writer_handle: the handle through which to receive incoming RpcRequests. If.\n      None will default to legacy behavior (/dev/fd/4)\n  \"\"\"\n  with _INIT_LOCK:\n    global _READER_HANDLE\n    global _WRITER_HANDLE\n    _READER_HANDLE, _WRITER_HANDLE = reader_handle, writer_handle\n\ndef run_tool(\n    name: str, operation_id: str, parameters: str\n) -> sandbox_rpc_pb2.RunToolResponse:\n  \"\"\"Runs a tool with the given name and id, passing in parameters.\n\n  Args:\n    name: The name of the tool.\n    operation_id: The name of the operation to perform.\n    parameters: The parameters to pass to the tool.\n\n  Returns:\n    A RunToolResponse containing the response from the tool.\n  \"\"\"\n  result = make_rpc(\n      sandbox_rpc_pb2.RpcRequest(\n          run_tool_request=sandbox_rpc_pb2.RunToolRequest(\n              name=name, operation_id=operation_id, parameters=parameters\n          )\n      )\n  )\n\n  if result and result.HasField(\"run_tool_response\"):\n    return result.run_tool_response\n  else:\n    return sandbox_rpc_pb2.RunToolResponse(response=\"\")\n\nWe would provide various pieces of data to these functions, they would serialize the data into the protobuf compatible format, and then call out over RPC by writing to a local file descriptor 5. The response could then be read by reading from local file descriptor 7. By utilizing the protos that were found in the massive binary, we were able to craft messages to and from this RPC server, and call these Google tools directly.\nHowever, we noticed something interesting, not every sandboxes would have the same set of Google services available. It would depend if the sandbox was spawned by the Front End to be able to run Python source code, or by the Google Agent. What do we mean by that ?\nReAct Research paper !\nBefore explaining the next part, we need to explain that Googleâ€™s team showed us the following research paper that Gemini is based of:\n\nREACT: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS\n\nThis paper introduces a novel approach (at the time) where language models alternate between generating reasoning traces and executing specific actions, effectively merging thought and behavior in an interleaved manner. In practice, this means that as the model reasons through a problem, creating a transparent trail of thought that helps it plan, track, and adjust its actions, it simultaneously interacts with external sources to gather additional data when needed. This dynamic interplay not only boosts the modelâ€™s performance by mitigating common issues like hallucination and error propagation but also makes its decision-making process more interpretable and controllable for human operators.\nBy integrating both internal reasoning and external knowledge, ReAct offers a flexible and general framework that excels across a variety of tasks, ranging from question answering and fact verification to text-based games and web navigation. In essence, ReAct leverages the combined strengths of reasoning and acting to create more robust, human-aligned, and versatile language models.\n\nOk, but why do we need to understand this ? Well, if we follow the logic of this paper, basically Gemini can prompt itself several times in order to refine the commands and have a proper chain of thoughts.\nIf a user asks â€œWhat is the earliest flight between Toronto and New York ?â€, Gemini would have roughly a chain of thought like:\n\nThe user is asking me to search the earliest flight between Toronto and New York\n\nCreating a plan like:\n\nI need to run a Python code that will connect to Google Flights tool\nThe code needs to find all flights from today to next week from YYZ airport to JFK airport\nThe code needs to sort by date the flights and take the first item\n\nOnce the plan done, it would generate the code with the available Tools that the Agent has\n\nOnce the code generated, it would spawn a sandbox with the right privileges (eg: having access to the Google Flights tool through the file descriptor)\n\nRun the code, process the output\n\nMakes a response to the user\n\nSo our theory was the following:\n\nWhat if we could do a secondary prompt injection in the planning section of Gemini in order to have access to a more privileged sandbox ?\n\nWith the help of the Google Security Team, we tested this idea and observed that, depending on factors like the generation seed and temperature (all the usual probabilistic LLM nuances), we could occasionally access what appeared to be a more privileged sandbox.\nBy â€œmore privileged sandbox,â€ we mean one that can access the extensions through two new file descriptors. These file descriptors are always present but arenâ€™t always actively listening, when the agent calls the sandbox, they monitor for any calls to the extensions (Google services) so that we can interact with the API, whereas if accessed through the Python interpreter, those extensions remain inaccessible.\nThis led us to believe that there was a real opportunity for a P0 vulnerability: there was a specific message handler that might allow a file read on Googleâ€™s internal infrastructure, and we were hopeful that the sandbox with the tool extension could initiate an RPC call to this specific tool. Given the probabilistic nature of the attack, which made it difficult to reproduce consistently, we have Google Security Team assess this situation. Ultimately, their review revealed that the suspicious message handler was not available via RPC and could only be called externally.\n\nEven though our tests were limited, the core idea still has some real potential if we push it further. Running code in the sandbox context isnâ€™t meant to give extra powers, it's treated as untrusted, with safety checks outside the sandbox and every tool call being filtered. But being able to run code does offer some neat benefits:\n\nReliability: Once you can run code, you can trigger actions more consistently.\n\nChaining/Complexity: Controlling multiple tools or fine-tuning parameters via plain text is tough; code execution could let you build more complex chains, even if safety measures are still in place.\n\nTool Output Poisoning: You might be able to manipulate a toolâ€™s output more effectively.\n\nLeaks: There could be other hidden parts of the environment that, if exposed, might offer extra advantages.\n\nThis shows that our idea still holds promise for further escalation. And that â€œleaksâ€ potential, we wanted to see if we could at least confirm this one theory â€¦\nWe found our leak ;D\nWhile digging deeper, we uncovered several ways to leak proto files. In case you're not familiar, proto files (short for Protocol Buffer files) are like the blueprints of data, defining how messages are structured and how information is exchanged between different parts of the system. At first glance, they might seem harmless, but leaking these files can give a pretty detailed peek into Googleâ€™s internal architecture.\nExposing classification.proto\nIt turns out that by running a command like:\nstrings entry_point > stringsoutput.txt\n\nand then searching for â€œDogfoodâ€ in the resulting file, we managed to retrieve snippets of the internal protos. Parts of the extracted content included the metadata description of extremely sensitive protos. It didnâ€™t contain user data by itself but those files are internal categories Google uses to classify user data.\nFor legal reasons we canâ€™t show the result of this command x)\n\nWhy search for the string â€œDogfoodâ€ specifically ? At Google, \"dogfood\" refers to the practice of using pre-release versions of the company's own products and prototypes internally to test and refine them before a public launch. It allows devs to test the deployment and potential issues in these products, before going to production.\nMoreover, there was the following exposed file, privacy/data_governance/attributes/proto/classification.proto, which details how data is classified within Google. Although the file includes references to associated documentation, those documents remain highly confidential and should not be publicly accessible.\n\nNote from Lupin again: This was found the next day of our all-nighter where we exfiltrated the binary file. We were in a suite in an Hotel Room booked by Google, and we were working with the security team to understand what we had found the previous night. This time Justin was the one who slept on the couch hahaha ! This bug was really time consuming but so fun ! ğŸ˜€\n\nExposing Internal Security Proto Definitions\nThe same output also reveals numerous internal proto files that should have remained hidden. Running:\ncat stringsoutput.txt| grep '\\.proto' | grep 'security'\n\nlists several sensitive files, including:\nsecurity/thinmint/proto/core/thinmint_core.proto\nsecurity/thinmint/proto/thinmint.proto\nsecurity/credentials/proto/authenticator.proto\nsecurity/data_access/proto/standard_dat_scope.proto\nsecurity/loas/l2/proto/credstype.proto\nsecurity/credentials/proto/end_user_credentials.proto\nsecurity/loas/l2/proto/usertype.proto\nsecurity/credentials/proto/iam_request_attributes.proto\nsecurity/util/proto/permission.proto\nsecurity/loas/l2/proto/common.proto\nops/security/sst/signalserver/proto/ss_data.proto\nsecurity/credentials/proto/data_access_token_scope.proto\nsecurity/loas/l2/proto/identity_types.proto\nsecurity/credentials/proto/principal.proto\nsecurity/loas/l2/proto/instance.proto\nsecurity/credentials/proto/justification.proto\n\nWhen looking in the binary strings for security/credentials/proto/authenticator.proto confirms that its data is indeed exposed.\nWhy were those protos there?\nAs we said previously, the Google Security Team thoroughly reviewed everything in the sandbox and gave a green light for public disclosure. However, the build pipeline for compiling the sandbox binary included an automated step that adds security proto files to a binary whenever it detects that the binary might need them to enforce internal rules.\nIn this particular case, that step wasnâ€™t necessary, resulting in the unintended inclusion of highly confidential internal protos in the wild !\nAs bug bounty hunters, it's essential to deeply understand the business rules that govern a companyâ€™s operations. We reported these proto leaks because we know that Google treats them as highly confidential information that should never be exposed. The more we understand the inner workings and priorities of our target, the better we are at identifying and flaging those subtle bugs that might otherwise slip under the radar. This deep knowledge not only helps us pinpoint vulnerabilities but also ensures our reports are aligned with the critical security concerns of the organization.\nConclusion\nBefore we wrap things up, itâ€™s worth mentioning how vital it is to test these cutting-edge A.I. systems before they go live. With so many interconnections and cool features, like even a simple sandbox that can access different extensions, thereâ€™s always the potential for unexpected surprises. Weâ€™ve seen firsthand that when all these parts work together, even a small oversight can open up new avenues for issues. So, thorough testing isnâ€™t just a best practice; itâ€™s the only way to make sure everything stays secure and functions as intended.\nAt the end of the day, what made this whole experience so memorable was the pure fun of the ride. Cracking vulnerabilities, exploring hidden code, and pushing the limits of Gemini's sandbox was as much about the challenge as it was about the excitement of the hunt. The people weâ€™ve met at the bugSWAT event in Las Vegas were all awesome. The shared laughs over unexpected twists, and the thrill of outsmarting complex systems turned this technical journey into an adventure weâ€™ll never forget. Itâ€™s moments like these, where serious hacking meets good times, that remind us why we do what we do.\nFinally, a huge shout-out to all the other winners and participants who made bugSWAT 2024 such a blast. We want to congratulate Sreeram & Sivanesh for their killer teamwork, Alessandro for coming so close to that top spot, and En for making it onto the podium. It was an absolute thrill meeting so many amazing hackers and security pros, your energy and passion made this event unforgettable. We canâ€™t wait to see everyone again at the next bugSWAT, and until then, keep hacking and having fun !\nAnd of course, thanks to the Google Security team ! As always you rock â¤ï¸<<Back to Blog",
    "summary": {
      "en": "In March 2025, Roni Carta and his team participated in Google's LLM bugSWAT event, successfully hacking into the AI system Gemini and leaking parts of its source code. This event is part of a broader trend in the tech industry, where various companies are racing to develop advanced AI models, but security issues remain a major concern.\n\nDuring the event, the team was awarded the Most Valuable Hacker (MVH) title for discovering a new vulnerability in Gemini's sandbox environment, which is designed to safely run Python code. They found ways to extract sensitive files from the sandbox, including internal Google source code and sensitive protocol (proto) files that outline how data is structured within Google's systems.\n\nTheir research revealed that the sandbox could sometimes be accessed in a more privileged manner, allowing them to interact with internal Google services. They discovered weaknesses in the system that could lead to data leaks, including internal classification protocols used to manage user data.\n\nThe experience highlighted the importance of rigorous testing and security measures in AI systems, emphasizing that even minor oversights can lead to significant vulnerabilities. The team enjoyed the challenge of uncovering these issues and looks forward to future events to continue improving security practices in the industry.",
      "ko": "2025ë…„ 3ì›”, ë¡œë‹ˆ ì¹´ë¥´íƒ€ì™€ ê·¸ì˜ íŒ€ì€ êµ¬ê¸€ì˜ LLM bugSWAT í–‰ì‚¬ì— ì°¸ê°€í•˜ì—¬ AI ì‹œìŠ¤í…œì¸ ì œë¯¸ë‹ˆë¥¼ í•´í‚¹í•˜ê³  ì¼ë¶€ ì†ŒìŠ¤ ì½”ë“œë¥¼ ìœ ì¶œí•˜ëŠ” ë° ì„±ê³µí–ˆìŠµë‹ˆë‹¤. ì´ ì‚¬ê±´ì€ ê¸°ìˆ  ì‚°ì—…ì—ì„œ ë‹¤ì–‘í•œ ê¸°ì—…ë“¤ì´ ê³ ê¸‰ AI ëª¨ë¸ ê°œë°œì— ê²½ìŸí•˜ê³  ìˆì§€ë§Œ, ë³´ì•ˆ ë¬¸ì œê°€ ì—¬ì „íˆ í° ìš°ë ¤ ì‚¬í•­ì´ë¼ëŠ” ë” ë„“ì€ íë¦„ì˜ ì¼í™˜ì…ë‹ˆë‹¤.\n\ní–‰ì‚¬ ì¤‘, íŒ€ì€ ì œë¯¸ë‹ˆì˜ ìƒŒë“œë°•ìŠ¤ í™˜ê²½ì—ì„œ ìƒˆë¡œìš´ ì·¨ì•½ì ì„ ë°œê²¬í•˜ì—¬ ê°€ì¥ ê°€ì¹˜ ìˆëŠ” í•´ì»¤(MVH)ë¼ëŠ” ì¹­í˜¸ë¥¼ ë°›ì•˜ìŠµë‹ˆë‹¤. ì´ ìƒŒë“œë°•ìŠ¤ëŠ” íŒŒì´ì¬ ì½”ë“œë¥¼ ì•ˆì „í•˜ê²Œ ì‹¤í–‰í•˜ê¸° ìœ„í•´ ì„¤ê³„ëœ í™˜ê²½ì…ë‹ˆë‹¤. ê·¸ë“¤ì€ ìƒŒë“œë°•ìŠ¤ì—ì„œ êµ¬ê¸€ì˜ ë‚´ë¶€ ì†ŒìŠ¤ ì½”ë“œì™€ ë°ì´í„° êµ¬ì¡°ë¥¼ ì„¤ëª…í•˜ëŠ” ë¯¼ê°í•œ í”„ë¡œí† ì½œ íŒŒì¼ì„ í¬í•¨í•œ ë¯¼ê°í•œ íŒŒì¼ì„ ì¶”ì¶œí•  ìˆ˜ ìˆëŠ” ë°©ë²•ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.\n\nì—°êµ¬ ê²°ê³¼, ìƒŒë“œë°•ìŠ¤ì— ë•Œë•Œë¡œ ë” ë†’ì€ ê¶Œí•œìœ¼ë¡œ ì ‘ê·¼í•  ìˆ˜ ìˆëŠ” ê²½ìš°ê°€ ìˆìŒì„ ë°í˜€ëƒˆìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë‚´ë¶€ êµ¬ê¸€ ì„œë¹„ìŠ¤ì™€ ìƒí˜¸ì‘ìš©í•  ìˆ˜ ìˆëŠ” ê°€ëŠ¥ì„±ì´ ìˆì—ˆìŠµë‹ˆë‹¤. ê·¸ë“¤ì€ ì‚¬ìš©ì ë°ì´í„°ë¥¼ ê´€ë¦¬í•˜ëŠ” ë° ì‚¬ìš©ë˜ëŠ” ë‚´ë¶€ ë¶„ë¥˜ í”„ë¡œí† ì½œì„ í¬í•¨í•˜ì—¬ ë°ì´í„° ìœ ì¶œë¡œ ì´ì–´ì§ˆ ìˆ˜ ìˆëŠ” ì‹œìŠ¤í…œì˜ ì•½ì ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.\n\nì´ë²ˆ ê²½í—˜ì€ AI ì‹œìŠ¤í…œì—ì„œ ì² ì €í•œ í…ŒìŠ¤íŠ¸ì™€ ë³´ì•ˆ ì¡°ì¹˜ì˜ ì¤‘ìš”ì„±ì„ ê°•ì¡°í–ˆìŠµë‹ˆë‹¤. ì‚¬ì†Œí•œ ì‹¤ìˆ˜ì¡°ì°¨ë„ í° ì·¨ì•½ì ìœ¼ë¡œ ì´ì–´ì§ˆ ìˆ˜ ìˆìŒì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤. íŒ€ì€ ì´ëŸ¬í•œ ë¬¸ì œë¥¼ ë°œê²¬í•˜ëŠ” ë„ì „ì„ ì¦ê²¼ìœ¼ë©°, ì•ìœ¼ë¡œì˜ í–‰ì‚¬ì—ì„œë„ ë³´ì•ˆ ê´€í–‰ì„ ê°œì„ í•˜ê¸° ìœ„í•´ ê³„ì† ë…¸ë ¥í•  ê³„íšì…ë‹ˆë‹¤.",
      "ja": "2025å¹´3æœˆã€ãƒ­ãƒ‹ãƒ»ã‚«ãƒ«ã‚¿ã¨å½¼ã®ãƒãƒ¼ãƒ ã¯ã€Googleã®LLM bugSWATã‚¤ãƒ™ãƒ³ãƒˆã«å‚åŠ ã—ã€AIã‚·ã‚¹ãƒ†ãƒ ã€Œã‚¸ã‚§ãƒŸãƒ‹ã€ã«ãƒãƒƒã‚­ãƒ³ã‚°ã‚’æˆåŠŸã•ã›ã€ãã®ä¸€éƒ¨ã®ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã‚’æ¼æ´©ã•ã›ã¾ã—ãŸã€‚ã“ã®å‡ºæ¥äº‹ã¯ã€ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼æ¥­ç•Œå…¨ä½“ã§é€²è¡Œä¸­ã®ãƒˆãƒ¬ãƒ³ãƒ‰ã®ä¸€ç’°ã§ã‚ã‚Šã€ã•ã¾ã–ã¾ãªä¼æ¥­ãŒé«˜åº¦ãªAIãƒ¢ãƒ‡ãƒ«ã®é–‹ç™ºã‚’ç«¶ã£ã¦ã„ã¾ã™ãŒã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã®å•é¡Œã¯ä¾ç„¶ã¨ã—ã¦å¤§ããªæ‡¸å¿µäº‹é …ã§ã™ã€‚\n\nã‚¤ãƒ™ãƒ³ãƒˆä¸­ã€ãƒãƒ¼ãƒ ã¯ã‚¸ã‚§ãƒŸãƒ‹ã®ã‚µãƒ³ãƒ‰ãƒœãƒƒã‚¯ã‚¹ç’°å¢ƒã«ãŠã‘ã‚‹æ–°ãŸãªè„†å¼±æ€§ã‚’ç™ºè¦‹ã—ãŸã“ã¨ã§ã€æœ€å„ªç§€ãƒãƒƒã‚«ãƒ¼ï¼ˆMVHï¼‰ã¨ã„ã†ç§°å·ã‚’æˆä¸ã•ã‚Œã¾ã—ãŸã€‚ã“ã®ã‚µãƒ³ãƒ‰ãƒœãƒƒã‚¯ã‚¹ã¯ã€Pythonã‚³ãƒ¼ãƒ‰ã‚’å®‰å…¨ã«å®Ÿè¡Œã™ã‚‹ãŸã‚ã«è¨­è¨ˆã•ã‚Œã¦ã„ã¾ã™ãŒã€ãƒãƒ¼ãƒ ã¯ã“ã“ã‹ã‚‰å†…éƒ¨ã®Googleã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã‚„ã€Googleã®ã‚·ã‚¹ãƒ†ãƒ å†…ã§ãƒ‡ãƒ¼ã‚¿ãŒã©ã®ã‚ˆã†ã«æ§‹é€ åŒ–ã•ã‚Œã¦ã„ã‚‹ã‹ã‚’ç¤ºã™é‡è¦ãªãƒ—ãƒ­ãƒˆã‚³ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŠ½å‡ºã™ã‚‹æ–¹æ³•ã‚’è¦‹ã¤ã‘ã¾ã—ãŸã€‚\n\nå½¼ã‚‰ã®ç ”ç©¶ã«ã‚ˆã‚Šã€ã‚µãƒ³ãƒ‰ãƒœãƒƒã‚¯ã‚¹ã«æ™‚æŠ˜ã€ã‚ˆã‚Šç‰¹æ¨©çš„ãªæ–¹æ³•ã§ã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã‚Šã€å†…éƒ¨ã®Googleã‚µãƒ¼ãƒ“ã‚¹ã¨ã‚„ã‚Šå–ã‚Šã§ãã‚‹ã“ã¨ãŒåˆ†ã‹ã‚Šã¾ã—ãŸã€‚ã‚·ã‚¹ãƒ†ãƒ ã®å¼±ç‚¹ãŒç™ºè¦‹ã•ã‚Œã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’ç®¡ç†ã™ã‚‹ãŸã‚ã«ä½¿ç”¨ã•ã‚Œã‚‹å†…éƒ¨ã®åˆ†é¡ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿æ¼æ´©ã®å¯èƒ½æ€§ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚\n\nã“ã®çµŒé¨“ã¯ã€AIã‚·ã‚¹ãƒ†ãƒ ã«ãŠã‘ã‚‹å³å¯†ãªãƒ†ã‚¹ãƒˆã¨ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¯¾ç­–ã®é‡è¦æ€§ã‚’å¼·èª¿ã—ã¾ã—ãŸã€‚å°ã•ãªè¦‹è½ã¨ã—ãŒé‡å¤§ãªè„†å¼±æ€§ã«ã¤ãªãŒã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚ãƒãƒ¼ãƒ ã¯ã“ã‚Œã‚‰ã®å•é¡Œã‚’æ˜ã‚‰ã‹ã«ã™ã‚‹æŒ‘æˆ¦ã‚’æ¥½ã—ã¿ã€ä»Šå¾Œã®ã‚¤ãƒ™ãƒ³ãƒˆã§æ¥­ç•Œã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ…£è¡Œã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’æœŸå¾…ã—ã¦ã„ã¾ã™ã€‚"
    }
  },
  {
    "id": "dbba09e618bdb0fd",
    "title": {
      "en": "Chimpanzees act as 'engineers', choosing materials to make tools",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://www.sciencedaily.com/releases/2025/03/250324142002.htm",
    "score": 85,
    "by": "docmechanic",
    "time": 1742913592,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "4d52bafabd4009f2",
    "title": {
      "en": "Caido â€“ A lightweight web security auditing toolkit",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://caido.io/",
    "score": 37,
    "by": "charlieirish",
    "time": 1743240720,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "34df9cd841a461c2",
    "title": {
      "en": "Oil and gas money shapes research, creates 'echo chamber' in higher education",
      "ko": "ì„ìœ  ìê¸ˆì˜ ì˜í–¥",
      "ja": "çŸ³æ²¹è³‡é‡‘ã®å½±éŸ¿"
    },
    "type": "story",
    "url": "https://floodlightnews.org/fueling-knowledge-oil-and-gas-money-shapes-research-creates-echo-chamber-in-higher-education/",
    "score": 29,
    "by": "rntn",
    "time": 1743276561,
    "content": "Gulf Coast\n            Fueling Knowledge: Oil and gas money shapes research, creates â€˜echo chamberâ€™ in higher education\n                Louisianaâ€™s flagship university is looking to partner more closely with petrochemical industries in the state\n\n                    Pam Radtke/Floodlight, Halle Parker/WWNO & WRKF, Piper Hutchinson/Louisiana Illuminator\n\n                        Mar 21, 2025\n                            â€” 14 min read\n\n            About 150 people marched on Louisiana State Universityâ€™s campus in November 2022 calling for the LSU Foundation to divest from fossil fuels, which comprise a small portion of the foundationâ€™s investments. (Matthew Perschall / The Reveille)\n\n            Published byStates NewsroomTo learn more about this investigation, listen to the Sea Change podcast from WWNO/WRKF.\n\nJackson Voss loves his alma mater, Louisiana State University. He appreciates that his undergraduate education was paid for by a program dreamed up by an oil magnate and that he received additional scholarships from ExxonMobil and Shell.But the socially conscious Louisiana native was also aware of what the support of those companies seemed to buy â€” silence.Voss, who graduated from LSU in Baton Rouge 11 years ago with a degree in political science, says when he attended school there, he didnâ€™t hear discussions of how climate change made Hurricane Katrina worse; why petrochemical plants along the Mississippi River sickened residents of the mostly Black communities around those facilities; or about the devastating and permanent impact of the BP oil spill that happened during Vossâ€™ time at LSU.Voss, now director of climate policy for the New Orleans-based consumer advocacy group, the Alliance for Affordable Energy, says he didnâ€™t hear climate change or â€œCancer Alleyâ€ openly discussed until he went to the University of Michigan, 1,100 miles away, for graduate school.â€œIt was not a place that was really discussing these issues in the way that should have been discussed at the time,â€ he said of LSU, where oil wells dotted the campus at least into the 1970s. Any such discussions werenâ€™t taken seriously, he said, and even fellow students were often defensive of the industry.â€œThe discussions that did happen had to focus on, kind of finding a way to talk about climate without talking about climate,â€ Voss said, â€œand it was especially important not to talk about the role that oil and gas played in worsening climate change.â€Louisiana State University graduate Jackson Voss attended the Baton Rouge-based school as an undergraduate about a decade ago. When he was there, he says no one talked about climate change, or the impact oil and gas had on the climate. Voss says it wasnâ€™t until he attended the University of Michigan that his classes discussed such topics. (Pam Radtke / Floodlight)Whether through funding of research projects, the creation of new academic programs focused on energy or, more subtly, through support of everything from opera to football, the oil and gas industry has been shaping discourse at LSU â€” and universities around the world â€” for decades.LSU administrators insist they have safeguards against undue influence by fossil fuel companies, which have given tens of millions of dollars to the university in just the past three years. But a joint investigation by Floodlight, WWNO/WRKF and the Louisiana Illuminator found the funding allows the industry to place a thumb on the scale of what gets studied at the stateâ€™s flagship university â€” and what is left out.Research by Floodlight shows between 2010 and 2020, petrochemical companies gave LSU at least $44 million through their charitable foundations, making it one of the top recipients of fossil fuel funding among U.S. universities, based on research from the nonprofit Data for Progress.\n\n!function(){\"use strict\";window.addEventListener(\"message\",(function(a){if(void 0!==a.data[\"datawrapper-height\"]){var e=document.querySelectorAll(\"iframe\");for(var t in a.data[\"datawrapper-height\"])for(var r,i=0;r=e[i];i++)if(r.contentWindow===a.source){var d=a.data[\"datawrapper-height\"][t]+\"px\";r.style.height=d}}}))}();\n\nLSU received more from petrochemical companies than the Massachusetts Institute of Technology, Harvard and Texas A&M â€” and 20 times more than Vossâ€™s other alma mater, the University of Michigan. The Data for Progress research showed over that decade, the 27 schools they examined received almost $700 million total.Increasingly, researchers are questioning the longstanding ties between fossil fuels and universities at a time when scientists and governments across the globe overwhelmingly agree that sharply reducing the use of fossil fuels and increasing reliance on renewable energy are crucial to stalling or reversing climate change.Last year, a joint report from Congress found â€œthe oil and gas industry cultivates partnerships with academic institutions as a way to influence climate research.â€ And a first-of-its-kind study released by researchers last year found the fossil fuel industryâ€™s approach is similar to how the tobacco, pharmaceutical and other industries co-opted academics.â€œIt's a situation exactly parallel to public health research being funded by the tobacco industry. It's a conflict of interest â€” the size of an oil tanker,â€ said Geoffrey Supran, associate professor of environmental science and policy who studiesfossil fuel disinformation at the University of Miami and is director of its Climate Accountability Lab. He says LSU and other schools like it have become â€œan echo chamber for pro-fossil-fuel narratives.â€LSU and its president, William Tate IV, have doubled down on the universityâ€™s ties with the fossil fuel industry in recent years, despite its shrinking importance to the Louisiana economy. Since 2020, Tate has solicited and received more than $30 million from fossil fuel companies, including a record $27.5 million from Shell.During LSUâ€™s Giving Day campaign on Wednesday, Shell plopped down another $1.5 million for LSU libraries and the College of Science.â€œIt's time for a partnership in significant fashion to link the work at LSU in our energy areas, including alternative energy, and creating ways to keep that industry vibrant here in this state and for our country,â€ Tate told reporters in 2022, about a year after he was named to head the school.Shell gave $27.5 million to Louisiana State University in Baton Rouge in 2022 to fund the universityâ€™s Institute for Innovation in Energy. Here, LSU president William Tate IV poses with LSU mascot Mike the Tiger. (Louisiana State University)LSU insists there are firewalls in place to prevent oil and gas companies from unduly influencing research and study. But public records and interviews indicate that fossil fuel funding can have a subtle and even direct impact on research and critical discourse.â€œUniversities are at risk of being pawns in a climate propaganda scheme devised and implemented by fossil fuel interests for decades,â€ Supran said. â€˜Tip of the icebergâ€™Itâ€™s impossible to pin down how much money fossil fuel interests â€” or any industry â€” gives to universities such as LSU. Although it is a public institution, much of the money for scholarships, workforce development and buildings goes through LSUâ€™s foundation â€” a nonprofit separate from the university. The foundation, in accordance with philanthropic standards, does not disclose its donors unless they agree to be identified.In its research, Data for Progress used public announcements from universities and companies, along with tax filings from fossil fuel companiesâ€™ foundations, to determine how much the universities received from those companies.â€œItâ€™s most likely the tip of the iceberg,â€ said Jake Lowe, executive director of Campus Climate Network, which under its previous name, Fossil Free Research, worked with Data for Progress to create its 2023 report.For example, the report includes millions of dollars the ExxonMobil Foundation gives for scholarships â€” but not the money going directly from the company to a school or its foundation.â€œIf the ExxonMobil corporation has a research contract with LSU, youâ€™re not going to see that in the tax documents or annual reports,â€ Lowe said.Louisiana State Universityâ€™s â€œQuadâ€ is the heart of the campus. Completed in 1926, it contains some of the first campus structures around a lush landscaped area with oaks, azaleas, crepe myrtles and magnolia trees. It was named after ExxonMobil in 1999. (Piper Hutchinson / Louisiana Illuminator)Floodlight, with the help of a Data for Progress researcher, used the same method to look at how much petrochemical money went to LSU. The analysis included examining public announcements from the companies and tax filings, called 990s, of the foundations for Shell, ExxonMobil, Chevron, ConocoPhillips, Entergy, Koch Inc., Southwest Electric Power Corp., Schlumberger (now known as SLB), Dow and Taylor Oil.From 2010 to 2020, Taylor Oilâ€™s foundation gave the most to LSU, almost $21 million.The second highest amount was from ExxonMobil, which gave more than $10 million â€” the majority of which came from a matching gift program in which the company gave $3 for every dollar donated by an employee or retiree to a college or university.But then, in 2022, Shell dwarfed the amount given over the previous decade with a single $27.5 million donation to LSU. The majority, $25 million, was for a new Institute for Energy Innovation to focus on â€œscholarship and solution deliveryâ€ on â€œhydrogen and carbon capture â€¦ the coast; and low-carbon fuels.â€Donations buy influenceLSU doesn't hide that the institute's mission was shaped in partnership with the industry. In the early days, a former Shell executive, Rhoman Hardy, served as the research center's interim director. The company also has three of the instituteâ€™s seven board seats; industry groups hold another two.Last year, the nonprofit New Orleans news outlet The Lens discovered LSU created a system: If a fossil fuel company gives $50,000 or more to the institute, it gets the right to participate in a specific research project, to use the intellectual property from that project and â€œrobust review and discussion of the specific study and project output.â€For a $1.25 million donation, a company also receives â€œvoting rights for selected institute activities, including research.â€ A contribution of $5 million or more earns a donor a seat on the instituteâ€™s board.Louisiana State University President William Tate IV visits Shellâ€™s facility in Convent, La., in 2023 to talk about his plan to focus on five areas at the university, including energy. Shell has announced it will convert the former oil refinery into one that produces lower carbon fuels. (Louisiana State University)When reached for comment about the institute, its donations and its potential influence, Shell responded, â€œWeâ€™re proud to partner with LSU to contribute to the growing compendium of peer-reviewed climate science and advance the effort to identify multiple pathways and build the ecosystems that can lead to more energy with fewer emissions.â€In 2023, ExxonMobil gave $2 million to LSU and became a â€œstrategicâ€ partner. With the donation, ExxonMobil will work with the institute to study batteries, solar power, carbon capture and advanced recycling. ExxonMobil did not respond to a request for comment about the donation or about the money it has previously given to LSU.At a Louisiana Board of Regentsâ€™ Energy Transition Research Symposium at LSU later that year, ExxonMobil gave a presentation on advanced plastics recycling, a controversial technology that opponents say amounts to greenwashing the problem of plastic waste by burning it rather than reusing it.â€œIt is clear based on the board and research focus areas of the new Institute for Energy Innovation that it is focused squarely on innovations using fossil fuels,â€ said Logan Atkinson Burke, Vossâ€™ boss at the Alliance for Affordable Energy, an energy consumer advocacy group.Environmentalists say technologies being studied by the institute, including carbon capture, hydrogen and low-carbon fuels, are â€œfalse solutionsâ€ that will do little to address the climate crisis.â€˜Subconsciousâ€™ bias?The institute's current director, Brad Ives, and LSUâ€™s vice president for research and economic development, Robert Twilley, say they have put safeguards in place to prevent industry influence.And Twilley says this type of research â€” working hand in hand with industries on the ground â€” is core to the mission of LSU as a land grant university, a program Abraham Lincoln established in 1862 that used federal land sales to fund universities focused on practical subjects including architecture, engineering and agriculture. â€œItâ€™s how we as an institution manage it and the safeguards and being very conscious of our ethics, being very conscious of what projects we work on,â€ Twilley said.He points to federal guidelines, the scientific method and peer review as some of the safeguards that keep the universityâ€™s research independent from industry influence. The institute sends its research proposals to an anonymous third-party panel of scientists to be ranked, Twilley says. Those rankings help decide what research it funds.Ives says funders arenâ€™t allowed contact with researchers either.â€œWhat we're doing is making sure that the researchers have total academic freedom to let the research take them where it goes,â€ Ives said. â€œWe know we can sleep at night because we are not doing anything that's wrong.â€But Supran, who once worked on projects funded by oil and gas, says itâ€™s not always as simple as a researcher purposefully skewing results. Scientists are only human, making these relationships inherently fraught.â€œWe're all subject to biases,â€ he said. â€œThings like reciprocation. You know that if I give you a pen, you have some small subconscious desire to reciprocate it in some sense down the line.â€For example, one study showed how reviews of the health effects of secondhand smoke funded by the tobacco industry were almost 90 times more likely to conclude that it was not harmful compared to reviews funded by other sources.Thereâ€™s evidence that the lines between funding and academic independence are sometimes blurred at LSU. Several influential reports and studies from LSUâ€™s Center for Energy Studies have drawn scrutiny over the years for being misleading. In one case, a utility-funded report led to the dismantling of Louisianaâ€™s successful rooftop solar program. In another, a report helped curb efforts to sue oil and gas companies for decades of environmental damage, claiming the lawsuits cost the state more than it would gain.A more recent example was found in public records reviewed by WWNO, including a contract between the Center for Energy Studies and the Bracewell law firm, representing Gulf Coast Sequestration. That company wants to store millions of tons of carbon dioxide underground in southwest Louisiana. It asked the center to use the project as a case study for the economic impact of a carbon capture industry on the Gulf Coast.The contract suggests that some of the reportâ€™s conclusions were reached even before the study began. The researchers said they planned to â€œunderscore the transformative nature of CCS (carbon capture and sequestration) on the Louisiana economy.â€LSUâ€™s final report ultimately listed all of the financial reasons the Gulf Coast should welcome the projects like this one â€” while barely mentioning the economic risks, such as the cost and financial viability of carbon capture facilities.WWNO showed the report to several researchers familiar with sponsored research. All of them shared concerns over the prescriptive nature of the research proposal or the terms of the contract itself.LSU allows research sponsors to give feedback on drafts before they're published. Sponsors are also allowed to stay anonymous â€” meaning, the public doesnâ€™t know who funds the research.â€œIt gets a D grade and it's not quite an F,â€ Supran said, noting that in this case, the funder was disclosed. â€œâ€ŠThe fact that this report just touts the economic benefits of this specific company funding the report â€” it kind of makes you wonder if it's worth the paper it's written on.â€The reportâ€™s authors declined to comment. Twilley defended the contract, saying its terms are standard throughout the university and that researchers are allowed to propose hypotheses.Gulf Coast Sequestration did not respond to a request for comment.Louisiana State Universityâ€™s Petroleum Engineering Research & Technology Transfer, or PERTT, Laboratory, is an industrial-scale facility for training and research on borehole technology. According to LSU, it is the only such facility in North America. (Louisiana State University)The contract is not illegal nor does it constitute research misconduct such as using fake data or plagiarizing. But according to one elected official, reports like these, which carry the credibility of a university without the scrutiny of peer review, could influence public policy.â€œThe research plays a significant role in determining whether or not weâ€™re on the right or wrong course,â€ said Davante Lewis, a public service commissioner in Louisiana. His commission regulates services in Louisiana including the electric utilities.Lewis said he counts on such academic reports to provide a fair and comprehensive picture of an issue. But, as more industry money enters research, he said he was concerned, noting, â€œOftentimes we have seen where money drives facts, not facts drive money.â€Burnishing their reputations Besides funding LSUâ€™s energy institute, oil and gas interests also pays for things everyone likes, such as health programs, tutoring and even halftime kicking contests with football fans.Supran says he and other researchers have a working theory that while oil and gas companies pour big money into big research institutions such as MIT and Stanford to give them credibility, they spend money at regional universities in states including Louisiana and Texas to build a compliant population.Geoffrey Supran, an associate professor at the University of Miami, tells members of the U.S. Senate Budget Committee at a May 1, 2024 hearing that his research has found â€œwidespread infiltration of fossil fuel interests into higher education.â€ (U.S. Senate Budget Committee)â€œIt doesn't take a genius to imagine that that money may be used to burnish the reputation locally of those companies and foster a vibrant recruitment pool,â€ Supran said.Voss says the oil and gas industryâ€™s support of benefits for the state are â€œone of the few things that it actually has right.â€ On the flip side, he added, â€œI think it protects the industry from criticism, because it makes people feel like they're a part of the community.â€But the heavy presence of oil and gas on campus can have a chilling effect on people and groups who donâ€™t support those industries.Jill Tupitza, now a marine scientist in California, was a graduate student at LSU when she and fellow graduate student Corinne Salter started Climate Pelicans, an advocacy organization that worked to get LSU to stop investing in fossil fuels.When they started questioning the ties between LSU and fossil fuels, they were met with resistance.â€œImmediately, doors were shut,â€ Tupitza said.One administrator told her, â€œâ€˜I can't tell you what to do, I can't punish you for going further. But I would strongly recommend that you stop asking questions about this,â€™â€ she recalled. â€œSo that, obviously, that made us double down.â€The group led marches and a petition drive urging climate divestment. They started a podcast that explored topics including environmental justice and false climate solutions.Tupitza said the LSU Foundation stonewalled the groupâ€™s requests for information about how much money it had invested in fossil fuels and refused requests to attend meetings about the foundationâ€™s $700 million endowment.The foundation later told Tupitza that less than 4% of its holdings were invested in fossil fuels.Climate advocates Corinne Salter and Jill Tupitza, who started a group and podcast called Climate Pelicans, and Cheyenne Autin discuss divestment in fossil fuels in November 2023 at Louisiana State Universityâ€™s Baton Rouge campus. (Tarun Kakarala / The Reveille)And then, while Tupitza and fellow graduate students were writing â€œDivest from Fossil Fuels,â€ in pink chalk in front of the foundation building, they were arrested on graffiti charges.Those charges were eventually dropped. School rules prohibit writing on the sidewalks with chalk, but it is not an arrestable offense. Tupitza described her arrest as â€œa huge scare tactic.â€ Supran says LSU isnâ€™t unique in its hesitation to cut ties with the oil and gas industry.â€œI think it's fair to say that for the most part, there has not been careful deliberation about the costs and the benefits of these ties, but rather a head down, and aggressive, solicitation of as much funding as they can receive from anyone.â€Voss predicts that if conditions worsen in an industry known for its booms and busts, its support for LSU will disappear. And as climate change worsens, it will make it harder for businesses and people to stay in Louisiana, which is already near the top of U.S. states when it comes to population loss.â€œIn many ways, higher education is sitting upon a house of cards, and relying upon oil and gas is incredibly risky â€” as it always has been.â€Instead, he said, â€œI think that LSU could and should be a really critical voice in climate change and environmental justice in Louisiana. I do worry that in failing to do so and by being so heavily tied up in oil and gas interests, it actually puts the university in a worse position.â€This is Part 2 of a two-part investigative series exploring the relationship between the fossil fuel industry and Louisiana State University. Read Part 1 here. This story was reported by a partnership with WWNO/WRKF, the Louisiana Illuminator and Floodlight. You can listen to the accompanying Sea Change podcast here. Floodlight is a nonprofit newsroom that investigates the powers stalling climate action.\n\n                                Pam Radtke/Floodlight\n\n                                Pam is an environment, energy and climate reporter. A long-time New Orleans resident, Pam was part of the Times-Picayune team that published after Hurricane Katrina.\n\npam@floodlightnews.org\n\n                                Halle Parker/WWNO & WRKF\n\n                                Piper Hutchinson/Louisiana Illuminator",
    "summary": {
      "en": "The text discusses the relationship between Louisiana State University (LSU) and the fossil fuel industry, highlighting concerns about how funding from oil and gas companies influences research and discourse at the university. Key points include:\n\n1. **Funding Influence**: LSU has received significant financial support from fossil fuel companies, amounting to over $44 million from 2010 to 2020, making it one of the top U.S. universities benefiting from such funding. Recent donations, including a $27.5 million contribution from Shell, have raised questions about the potential for these companies to influence academic research.\n\n2. **Lack of Climate Discussion**: Former students, like Jackson Voss, noted that during their time at LSU, critical discussions about climate change and the impacts of the oil and gas industry were largely absent. This trend suggests a culture that avoids confronting the industry's role in climate issues.\n\n3. **Research Concerns**: Investigations reveal that funding from fossil fuel companies can shape research agendas and outcomes at LSU, creating a bias towards pro-industry narratives. Critics argue that this compromises academic independence and leads to a lack of transparency in research findings.\n\n4. **Push for Divestment**: Activism on campus has emerged, with groups advocating for the university to divest from fossil fuels. Protests have highlighted concerns about the ethical implications of accepting funding from an industry linked to environmental harm.\n\n5. **Safeguards and Skepticism**: While LSU claims to have safeguards to prevent undue industry influence on research, experts argue that the relationships between universities and fossil fuel companies can still lead to subconscious biases in research.\n\nOverall, the situation at LSU reflects a broader issue in higher education, where financial ties to the fossil fuel industry may hinder open discussions about climate change and limit the university's role in advocating for environmental justice.",
      "ko": "ë£¨ì´ì§€ì• ë‚˜ ì£¼ë¦½ëŒ€í•™êµ(LSU)ì™€ í™”ì„ ì—°ë£Œ ì‚°ì—… ê°„ì˜ ê´€ê³„ì— ëŒ€í•œ ë…¼ì˜ê°€ ì§„í–‰ë˜ê³  ìˆìœ¼ë©°, ì„ìœ  ë° ê°€ìŠ¤ íšŒì‚¬ì˜ ìê¸ˆ ì§€ì›ì´ ëŒ€í•™ì˜ ì—°êµ¬ì™€ ë‹´ë¡ ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì— ëŒ€í•œ ìš°ë ¤ê°€ ì œê¸°ë˜ê³  ìˆìŠµë‹ˆë‹¤. ì£¼ìš” ë‚´ìš©ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n\nLSUëŠ” 2010ë…„ë¶€í„° 2020ë…„ê¹Œì§€ í™”ì„ ì—°ë£Œ íšŒì‚¬ë¡œë¶€í„° 4ì²œ4ë°±ë§Œ ë‹¬ëŸ¬ ì´ìƒì˜ ìƒë‹¹í•œ ì¬ì • ì§€ì›ì„ ë°›ì•˜ìœ¼ë©°, ì´ëŠ” ë¯¸êµ­ ë‚´ì—ì„œ ì´ëŸ¬í•œ ìê¸ˆì„ ê°€ì¥ ë§ì´ ë°›ëŠ” ëŒ€í•™ ì¤‘ í•˜ë‚˜ë¡œ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤. ìµœê·¼ì—ëŠ” ì…¸ì—ì„œ 2ì²œ7ë°±50ë§Œ ë‹¬ëŸ¬ì˜ ê¸°ë¶€ê°€ ì´ë£¨ì–´ì¡Œê³ , ì´ë¡œ ì¸í•´ ì´ëŸ¬í•œ ê¸°ì—…ë“¤ì´ í•™ìˆ  ì—°êµ¬ì— ì˜í–¥ì„ ë¯¸ì¹  ê°€ëŠ¥ì„±ì— ëŒ€í•œ ì˜ë¬¸ì´ ì œê¸°ë˜ê³  ìˆìŠµë‹ˆë‹¤.\n\nì „ í•™ìƒì¸ ì­ìŠ¨ ë³´ìŠ¤ëŠ” LSU ì¬í•™ ì¤‘ ê¸°í›„ ë³€í™”ì™€ ì„ìœ  ë° ê°€ìŠ¤ ì‚°ì—…ì˜ ì˜í–¥ì— ëŒ€í•œ ì¤‘ìš”í•œ ë…¼ì˜ê°€ ê±°ì˜ ì—†ì—ˆë‹¤ê³  ì–¸ê¸‰í–ˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ê²½í–¥ì€ ì‚°ì—…ì˜ ê¸°í›„ ë¬¸ì œì— ëŒ€í•œ ì—­í• ì„ íšŒí”¼í•˜ëŠ” ë¬¸í™”ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\n\nì¡°ì‚¬ ê²°ê³¼, í™”ì„ ì—°ë£Œ íšŒì‚¬ì˜ ìê¸ˆ ì§€ì›ì´ LSUì˜ ì—°êµ¬ ì˜ì œì™€ ê²°ê³¼ì— ì˜í–¥ì„ ë¯¸ì³ ì‚°ì—… ì¹œí™”ì ì¸ ì„œì‚¬ë¥¼ í˜•ì„±í•˜ëŠ” ê²½í–¥ì´ ìˆëŠ” ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤. ë¹„íŒìë“¤ì€ ì´ëŸ¬í•œ ìƒí™©ì´ í•™ë¬¸ì  ë…ë¦½ì„±ì„ ì €í•´í•˜ê³  ì—°êµ¬ ê²°ê³¼ì˜ íˆ¬ëª…ì„±ì„ ê²°ì—¬í•˜ê²Œ ë§Œë“ ë‹¤ê³  ì£¼ì¥í•©ë‹ˆë‹¤.\n\nìº í¼ìŠ¤ì—ì„œëŠ” í™”ì„ ì—°ë£Œì—ì„œì˜ íˆ¬ì ì² íšŒë¥¼ ì´‰êµ¬í•˜ëŠ” í™œë™ì´ ì¼ì–´ë‚˜ê³  ìˆìœ¼ë©°, ì‹œìœ„ëŠ” í™˜ê²½ í”¼í•´ì™€ ê´€ë ¨ëœ ì‚°ì—…ìœ¼ë¡œë¶€í„° ìê¸ˆì„ ë°›ëŠ” ê²ƒì˜ ìœ¤ë¦¬ì  ë¬¸ì œì— ëŒ€í•œ ìš°ë ¤ë¥¼ ê°•ì¡°í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n\nLSUëŠ” ì—°êµ¬ì— ëŒ€í•œ ë¶€ë‹¹í•œ ì‚°ì—… ì˜í–¥ë ¥ì„ ë°©ì§€í•˜ê¸° ìœ„í•œ ì•ˆì „ ì¥ì¹˜ê°€ ìˆë‹¤ê³  ì£¼ì¥í•˜ì§€ë§Œ, ì „ë¬¸ê°€ë“¤ì€ ëŒ€í•™ê³¼ í™”ì„ ì—°ë£Œ íšŒì‚¬ ê°„ì˜ ê´€ê³„ê°€ ì—¬ì „íˆ ì—°êµ¬ì—ì„œ ë¬´ì˜ì‹ì ì¸ í¸í–¥ì„ ì´ˆë˜í•  ìˆ˜ ìˆë‹¤ê³  ì§€ì í•©ë‹ˆë‹¤.\n\nì „ë°˜ì ìœ¼ë¡œ LSUì˜ ìƒí™©ì€ ê³ ë“± êµìœ¡ì—ì„œ í™”ì„ ì—°ë£Œ ì‚°ì—…ê³¼ì˜ ì¬ì •ì  ì—°ê´€ì´ ê¸°í›„ ë³€í™”ì— ëŒ€í•œ ì—´ë¦° ë…¼ì˜ë¥¼ ë°©í•´í•˜ê³ , í™˜ê²½ ì •ì˜ë¥¼ ì˜¹í˜¸í•˜ëŠ” ëŒ€í•™ì˜ ì—­í• ì„ ì œí•œí•  ìˆ˜ ìˆëŠ” ë” ë„“ì€ ë¬¸ì œë¥¼ ë°˜ì˜í•˜ê³  ìˆìŠµë‹ˆë‹¤.",
      "ja": "ãƒ«ã‚¤ã‚¸ã‚¢ãƒŠå·ç«‹å¤§å­¦ï¼ˆLSUï¼‰ã¨åŒ–çŸ³ç‡ƒæ–™ç”£æ¥­ã®é–¢ä¿‚ã«ã¤ã„ã¦ã®å†…å®¹ãŒè¿°ã¹ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚ç‰¹ã«ã€çŸ³æ²¹ã‚„ã‚¬ã‚¹ä¼šç¤¾ã‹ã‚‰ã®è³‡é‡‘ãŒå¤§å­¦ã®ç ”ç©¶ã‚„è­°è«–ã«ä¸ãˆã‚‹å½±éŸ¿ãŒæ‡¸å¿µã•ã‚Œã¦ã„ã¾ã™ã€‚\n\nLSUã¯2010å¹´ã‹ã‚‰2020å¹´ã®é–“ã«ã€åŒ–çŸ³ç‡ƒæ–™ä¼šç¤¾ã‹ã‚‰4400ä¸‡ãƒ‰ãƒ«ä»¥ä¸Šã®æ”¯æ´ã‚’å—ã‘ã¦ãŠã‚Šã€ã“ã‚Œã¯ã‚¢ãƒ¡ãƒªã‚«ã®å¤§å­¦ã®ä¸­ã§ã‚‚ç‰¹ã«å¤šã„é‡‘é¡ã§ã™ã€‚æœ€è¿‘ã§ã¯ã‚·ã‚§ãƒ«ã‹ã‚‰2750ä¸‡ãƒ‰ãƒ«ã®å¯„ä»˜ãŒã‚ã‚Šã€ã“ã‚Œã‚‰ã®ä¼æ¥­ãŒå­¦è¡“ç ”ç©¶ã«å½±éŸ¿ã‚’ä¸ãˆã‚‹å¯èƒ½æ€§ã«ã¤ã„ã¦ç–‘å•ãŒç”Ÿã˜ã¦ã„ã¾ã™ã€‚\n\nå…ƒå­¦ç”Ÿã®ã‚¸ãƒ£ã‚¯ã‚½ãƒ³ãƒ»ãƒœã‚¹æ°ã¯ã€LSUåœ¨å­¦ä¸­ã«æ°—å€™å¤‰å‹•ã‚„çŸ³æ²¹ãƒ»ã‚¬ã‚¹ç”£æ¥­ã®å½±éŸ¿ã«ã¤ã„ã¦ã®é‡è¦ãªè­°è«–ãŒã»ã¨ã‚“ã©è¡Œã‚ã‚Œãªã‹ã£ãŸã¨æŒ‡æ‘˜ã—ã¦ã„ã¾ã™ã€‚ã“ã®å‚¾å‘ã¯ã€æ¥­ç•Œã®å½¹å‰²ã«å¯¾ã™ã‚‹è­°è«–ã‚’é¿ã‘ã‚‹æ–‡åŒ–ã‚’ç¤ºå”†ã—ã¦ã„ã¾ã™ã€‚\n\nèª¿æŸ»ã«ã‚ˆã‚‹ã¨ã€åŒ–çŸ³ç‡ƒæ–™ä¼šç¤¾ã‹ã‚‰ã®è³‡é‡‘ã¯LSUã®ç ”ç©¶èª²é¡Œã‚„çµæœã«å½±éŸ¿ã‚’ä¸ãˆã€æ¥­ç•Œå¯„ã‚Šã®è¦‹è§£ãŒå¼·èª¿ã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚æ‰¹è©•å®¶ãŸã¡ã¯ã€ã“ã‚ŒãŒå­¦å•ã®ç‹¬ç«‹æ€§ã‚’æãªã„ã€ç ”ç©¶çµæœã®é€æ˜æ€§ã‚’æ¬ ãåŸå› ã«ãªã‚‹ã¨ä¸»å¼µã—ã¦ã„ã¾ã™ã€‚\n\nã‚­ãƒ£ãƒ³ãƒ‘ã‚¹å†…ã§ã¯ã€åŒ–çŸ³ç‡ƒæ–™ã‹ã‚‰ã®æŠ•è³‡æ’¤é€€ã‚’æ±‚ã‚ã‚‹æ´»å‹•ãŒç››ã‚“ã«ãªã£ã¦ã„ã¾ã™ã€‚æŠ—è­°æ´»å‹•ã§ã¯ã€ç’°å¢ƒã«æ‚ªå½±éŸ¿ã‚’åŠã¼ã™ç”£æ¥­ã‹ã‚‰ã®è³‡é‡‘ã‚’å—ã‘å…¥ã‚Œã‚‹ã“ã¨ã®å€«ç†çš„ãªå•é¡ŒãŒå¼·èª¿ã•ã‚Œã¦ã„ã¾ã™ã€‚\n\nLSUã¯ç ”ç©¶ã«å¯¾ã™ã‚‹ä¸å½“ãªæ¥­ç•Œã®å½±éŸ¿ã‚’é˜²ããŸã‚ã®å¯¾ç­–ãŒã‚ã‚‹ã¨ä¸»å¼µã—ã¦ã„ã¾ã™ãŒã€å°‚é–€å®¶ã¯å¤§å­¦ã¨åŒ–çŸ³ç‡ƒæ–™ä¼šç¤¾ã®é–¢ä¿‚ãŒç ”ç©¶ã«ç„¡æ„è­˜ã®ãƒã‚¤ã‚¢ã‚¹ã‚’ã‚‚ãŸã‚‰ã™å¯èƒ½æ€§ãŒã‚ã‚‹ã¨æŒ‡æ‘˜ã—ã¦ã„ã¾ã™ã€‚\n\nå…¨ä½“ã¨ã—ã¦ã€LSUã®çŠ¶æ³ã¯é«˜ç­‰æ•™è‚²ã«ãŠã‘ã‚‹ã‚ˆã‚Šåºƒç¯„ãªå•é¡Œã‚’åæ˜ ã—ã¦ãŠã‚Šã€åŒ–çŸ³ç‡ƒæ–™ç”£æ¥­ã¨ã®è²¡æ”¿çš„ãªçµã³ã¤ããŒæ°—å€™å¤‰å‹•ã«ã¤ã„ã¦ã®è‡ªç”±ãªè­°è«–ã‚’å¦¨ã’ã€ç’°å¢ƒæ­£ç¾©ã‚’æ”¯æŒã™ã‚‹å¤§å­¦ã®å½¹å‰²ã‚’åˆ¶é™ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚"
    }
  },
  {
    "id": "46645e69fc3d1245",
    "title": {
      "en": "Digital Echoes and Unquiet Minds",
      "ko": "ë””ì§€í„¸ ë©”ì•„ë¦¬ì™€ ë¶ˆì•ˆí•œ ë§ˆìŒ",
      "ja": "ãƒ‡ã‚¸ã‚¿ãƒ«ã®å›ã"
    },
    "type": "story",
    "url": "https://www.chrbutler.com/digital-echoes-and-unquiet-minds",
    "score": 161,
    "by": "delaugust",
    "time": 1743193772,
    "content": "Digital Echoes and Unquiet Minds\n\nThereâ€™s a psychological burden of digital life even heavier than distraction.\n\nWhen the iPhone was first introduced in 2007, the notion of an â€œeverything deviceâ€ was universally celebrated. A single object that could serve as phone, camera, music player, web browser, and so much more promised unprecedented convenience and connectivity. It was, quite literally, the dream of the nineties. But the better part of twenty years later, weâ€™ve gained enough perspective to recognize that this revolutionary vision came with costs we did not anticipate.\n\nDistraction, of course, is the one we can all relate to first. An everything device has the problem of being useful nearly all the time, and when in use, all consuming. When you use it to do one thing, it pushes you toward others. In order to avoid this, you must disable functions. Thatâ€™s an interesting turn of events, isnâ€™t it? We have made a thing that does more than we need, more often than we desire. Because system-wide, duplicative notifications are enabled by default, the best thing you could say about the deviceâ€™s design is that it lacks a point of view toward a prioritization of what it does. The worst thing you could say is that it is distracting by design.\n\n(I find it fascinating how many people â€“myself includedâ€‰â€”â€‰attempt to reduce the features of their smartphone to the point of replicating a â€œdumbphoneâ€ experience in order to save ourselves from distraction, but donâ€™t actually go so far as to use a lesser-featured phone because a few key features are just too good to give up. A dumbphone is less distracting, but a nightmare for text messaging and a lousy camera. It turns out I donâ€™t want a phone at all, but a camera that textsâ€‰â€”â€‰and ideally one smaller than anything on the market now. I know Iâ€™m not alone, and yet this product will not be made. )\n\nThis kind of distraction is direct distraction. Itâ€™s the kind we are increasingly aware of, and as its accumulating stress puts pressure on our inner and outer lives, we can combat it with various choices and optimizations. But there is another kind of distraction that is less direct, though just as cumulative and, I believe, just as toxic. Iâ€™ve come to think of it as the â€œdigital echo.â€\n\nOn a smartphone, every single thing it is used to do generates information that goes elsewhere. The vast majority of this is unseenâ€‰â€”â€‰though not unfeltâ€‰â€”â€‰by us. Everyone knows that there is no privacy within a digital device, nor within its â€œlisteningâ€ range. We are all aware that as much information as smartphone provides to us, exponentially more is generated for someone elseâ€‰â€”â€‰someone watching, listening, measuring, and monetizing. The â€œdigital echoâ€ is more than just the awareness of this; it is the cognitive burden of knowing that our actions generate data elsewhere. The echo exists whenever we use connected technology, creating a subtle but persistent awareness that what we do isnâ€™t just our own. A device like a smartphone has always generated a â€œdigital echoâ€, but many others are as well.\n\nComparing two different motor vehicles illustrates this well. In a car like a Tesla, which we might think of as a â€œsmartcarâ€ since itâ€™s a computer you can drive, every function produces a digital signal. Adjusting the air conditioning, making a turn, opening a doorâ€‰â€”â€‰the car knows and records it all, transmitting this information to distant servers. By contrast, my 15-year-old Honda performs all of its functions without creating these digital echoes. The operations remain private, existing only in the moment they occur. In our increasingly digital world, I have begun to feel the SCIF-like isolation of the cabin of my car, and I like it.\n\n(The â€œsmartcarâ€, of course, wonâ€™t remain simply a computer you can drive. The pinnacle â€œsmartcarâ€ drives itself. The self-driving car represents perhaps the most acute expression of how digital culture values attention and convenience above all else, especially control and ownership. As a passenger of a self-driving car, you surrender control over the vehicleâ€™s operation in exchange for the â€œfreedomâ€ to direct your attention elsewhere, most likely to some digital signal either on your own device or on screens within the vehicle. I can see the value in this; driving can be boring and most times I am behind the wheel Iâ€™d rather be doing something else. But currently, truly autonomous vehicles are service-enabling products like Waymo, meaning we also relinquish ownership. The benefits of that also seem obvious: no insurance premiums, no maintenance costs. But not every advantage is worth its cost. The economics of self-driving cars are not clear-cut. Thereâ€™s a real debate to be had about\nattention, convenience, and ownership that I hope will play out before we have no choice but to be a passenger in someone elseâ€™s machine.)\n\nWhen I find myself looking for new ways to throttle my smartphoneâ€™s functions, or when I sit in the untapped isolation of my car, I often wonder about the costs of the â€œdigital echo.â€ What is the psychological cost of knowing that your actions arenâ€™t just your own, but create information that can be observed and analyzed by others? As more aspects of our lives generate digital echoes, they force an ambient awareness of being perpetually witnessed rather than simply existing.\n\nThis transforms even solitary activities into implicit social interactions. It forces us to maintain awareness of our â€œobserved selfâ€ alongside our â€œexperiencing self,â€ creating a kind of persistent self-consciousness. We become performers in our own lives rather than merely participants.\n\nI think this growing awareness contributes to a growing interest in returning to single-focus devices and analog technologies. Record players and film cameras arenâ€™t experiencing resurgence merely from nostalgia, but because they offer fundamentally different relationships with mediaâ€‰â€”â€‰relationships characterized by intention, presence, and focus.\n\nIn my own life, this recognition has led to deliberate choices about which technologies to embrace and which to avoid. Here are three off the top of my head:\n\nReplacing streaming services with owned media formats (CDs, Blu-rays) that remain accessible on my terms, not subject to platform changes or content disappearance\n\nPreferring printed books while using dedicated e-readers for digital textsâ€‰â€”â€‰in this case, accepting certain digital echoes when the benefits (in particular, access to otherwise unavailable material) outweigh the costs\n\nRejecting smart home devices entirely, recognizing that their convenience rarely justifies the added complexity and surveillance they introduce\n\nYouâ€™ve probably made similarly-motivated decisions, perhaps in other areas of your life or in relation to other things entirely. What matters, I think, is that these choices arenâ€™t about rejecting technology but about creating spaces for more intentional engagement. They represent a search for balance in a world that increasingly defaults to maximum connectivity.\n\nI had a conversation recently with a friend who mused, â€œWhat are these the early days of?â€ What a wonderful question that is; we are, I hope, always living in the early days of something. Perhaps now, weâ€™re witnessing the beginning of a new phase in our relationship with technology. The initial wave of digital transformation prioritized connecting everything possible; the next wave may be more discriminating about what should be connected and whatâ€™s better left direct and immediate. I hope to see operating systems truly designed around focus rather than multitasking, interfaces that respect attention rather than constantly competing for it, and devices that serve discrete purposes exceptionally well instead of performing multiple functions adequately.\n\nThe digital echoes of our actions will likely continue to multiply, but we can choose which echoes weâ€™re willing to generate and which activities deserve to remain ephemeralâ€‰â€”â€‰to exist only in the moment they occur and then in the memories of those present. What looks like revision or retreat may be the next wave of innovation, borne out of having learned the lessons of the last few decades and desiring better for the next.\n\n        Written by Christopher Butler on March 28, 2025\n\n        Tagged\n        Essays\n\n      Â© Christopher Butler. All rights reserved.\n      Now\n      About this Website\n      Newsletter\n      RSS",
    "summary": {
      "en": "**Summary of \"Digital Echoes and Unquiet Minds\"**\n\nThe digital age has brought great convenience through devices like smartphones, which combine many functions into one. However, this convenience comes with unexpected downsides, primarily distraction and a psychological burden known as the \"digital echo.\" \n\nDistraction is a well-known issue; smartphones often pull us into multiple activities at once, making it hard to focus. Many people try to limit their phone's features but still rely on it for essential functions. \n\nThe \"digital echo\" refers to the awareness that our actions generate data that is collected and analyzed by others, creating a sense of being constantly observed. This can lead to self-consciousness and transforms personal activities into social performances. \n\nAs a result, some people are turning back to simpler, analog technologies like record players and film cameras, which foster more intentional and focused engagement. The author shares personal choices to embrace technology that enhances control and privacy, such as using owned media instead of streaming services and avoiding smart home devices.\n\nUltimately, a new phase in our relationship with technology may be emerging, focusing on intentional connectivity and prioritizing attention and purpose over multitasking. We can choose which digital echoes to create and which moments to keep private.",
      "ko": "ë””ì§€í„¸ ì‹œëŒ€ëŠ” ìŠ¤ë§ˆíŠ¸í°ê³¼ ê°™ì€ ê¸°ê¸°ë¥¼ í†µí•´ ë§ì€ ê¸°ëŠ¥ì„ í•˜ë‚˜ë¡œ í†µí•©í•˜ì—¬ í° í¸ë¦¬í•¨ì„ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ëŸ¬í•œ í¸ë¦¬í•¨ì€ ì˜ˆìƒì¹˜ ëª»í•œ ë‹¨ì ë„ ë™ë°˜í•˜ëŠ”ë°, ì£¼ë¡œ ì£¼ì˜ ì‚°ë§Œê³¼ 'ë””ì§€í„¸ ì—ì½”'ë¼ëŠ” ì‹¬ë¦¬ì  ë¶€ë‹´ì´ ê·¸ê²ƒì…ë‹ˆë‹¤.\n\nì£¼ì˜ ì‚°ë§Œì€ ì˜ ì•Œë ¤ì§„ ë¬¸ì œì…ë‹ˆë‹¤. ìŠ¤ë§ˆíŠ¸í°ì€ ì—¬ëŸ¬ í™œë™ìœ¼ë¡œ ìš°ë¦¬ë¥¼ ëŒì–´ë“¤ì—¬ ì§‘ì¤‘í•˜ê¸° ì–´ë µê²Œ ë§Œë“­ë‹ˆë‹¤. ë§ì€ ì‚¬ëŒë“¤ì´ ìŠ¤ë§ˆíŠ¸í°ì˜ ê¸°ëŠ¥ì„ ì œí•œí•˜ë ¤ê³  í•˜ì§€ë§Œ, ì—¬ì „íˆ í•„ìˆ˜ì ì¸ ê¸°ëŠ¥ì„ ìœ„í•´ ì˜ì¡´í•˜ê²Œ ë©ë‹ˆë‹¤.\n\n'ë””ì§€í„¸ ì—ì½”'ëŠ” ìš°ë¦¬ì˜ í–‰ë™ì´ ë°ì´í„°ë¥¼ ìƒì„±í•˜ê³ , ì´ ë°ì´í„°ê°€ ë‹¤ë¥¸ ì‚¬ëŒì— ì˜í•´ ìˆ˜ì§‘ë˜ê³  ë¶„ì„ëœë‹¤ëŠ” ì¸ì‹ì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ì´ëŠ” ëŠì„ì—†ì´ ê´€ì°°ë‹¹í•˜ê³  ìˆë‹¤ëŠ” ëŠë‚Œì„ ì£¼ì–´ ìì˜ì‹ì´ ìƒê¸°ê³ , ê°œì¸ì ì¸ í™œë™ì´ ì‚¬íšŒì  ê³µì—°ìœ¼ë¡œ ë³€ì§ˆë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nì´ëŸ° ì´ìœ ë¡œ ì¼ë¶€ ì‚¬ëŒë“¤ì€ ë ˆì½”ë“œ í”Œë ˆì´ì–´ë‚˜ í•„ë¦„ ì¹´ë©”ë¼ì™€ ê°™ì€ ë” ë‹¨ìˆœí•œ ì•„ë‚ ë¡œê·¸ ê¸°ìˆ ë¡œ ëŒì•„ê°€ê³  ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ê¸°ê¸°ë“¤ì€ ë” ì˜ë„ì ì´ê³  ì§‘ì¤‘ì ì¸ ì°¸ì—¬ë¥¼ ì´‰ì§„í•©ë‹ˆë‹¤. ì €ìëŠ” ìŠ¤íŠ¸ë¦¬ë° ì„œë¹„ìŠ¤ ëŒ€ì‹  ì†Œìœ í•œ ë¯¸ë””ì–´ë¥¼ ì‚¬ìš©í•˜ê³  ìŠ¤ë§ˆíŠ¸ í™ˆ ê¸°ê¸°ë¥¼ í”¼í•˜ëŠ” ë“±, í†µì œì™€ í”„ë¼ì´ë²„ì‹œë¥¼ ê°•í™”í•˜ëŠ” ê¸°ìˆ ì„ ì„ íƒí•˜ëŠ” ê°œì¸ì ì¸ ì‚¬ë¡€ë¥¼ ê³µìœ í•©ë‹ˆë‹¤.\n\nê²°êµ­, ìš°ë¦¬ëŠ” ê¸°ìˆ ê³¼ì˜ ê´€ê³„ì—ì„œ ìƒˆë¡œìš´ ë‹¨ê³„ë¡œ ë‚˜ì•„ê°€ê³  ìˆëŠ” ê²ƒì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ë‹¨ê³„ëŠ” ì˜ë„ì ì¸ ì—°ê²°ì„ ì¤‘ì‹œí•˜ê³ , ë©€í‹°íƒœìŠ¤í‚¹ë³´ë‹¤ ì£¼ì˜ì™€ ëª©ì ì„ ìš°ì„ ì‹œí•˜ëŠ” ë°©í–¥ìœ¼ë¡œ ë‚˜ì•„ê°‘ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì–´ë–¤ ë””ì§€í„¸ ì—ì½”ë¥¼ ìƒì„±í• ì§€, ì–´ë–¤ ìˆœê°„ì„ ê°œì¸ì ìœ¼ë¡œ ìœ ì§€í• ì§€ë¥¼ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
      "ja": "ãƒ‡ã‚¸ã‚¿ãƒ«æ™‚ä»£ã¯ã€ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³ã®ã‚ˆã†ãªå¤šæ©Ÿèƒ½ãƒ‡ãƒã‚¤ã‚¹ã‚’é€šã˜ã¦å¤§ããªä¾¿åˆ©ã•ã‚’ã‚‚ãŸã‚‰ã—ã¾ã—ãŸã€‚ã—ã‹ã—ã€ã“ã®ä¾¿åˆ©ã•ã«ã¯äºˆæœŸã—ãªã„æ¬ ç‚¹ã‚‚ã‚ã‚Šã€ä¸»ã«æ°—ã‚’æ•£ã‚‰ã™è¦å› ã‚„ã€Œãƒ‡ã‚¸ã‚¿ãƒ«ã‚¨ã‚³ãƒ¼ã€ã¨å‘¼ã°ã‚Œã‚‹å¿ƒç†çš„è² æ‹…ãŒå«ã¾ã‚Œã¾ã™ã€‚\n\næ°—ã‚’æ•£ã‚‰ã™ã“ã¨ã¯ã‚ˆãçŸ¥ã‚‰ã‚ŒãŸå•é¡Œã§ã€ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³ã¯ç§ãŸã¡ã‚’åŒæ™‚ã«è¤‡æ•°ã®æ´»å‹•ã«å¼•ãè¾¼ã‚€ãŸã‚ã€é›†ä¸­ã™ã‚‹ã®ãŒé›£ã—ããªã‚Šã¾ã™ã€‚å¤šãã®äººãŒé›»è©±ã®æ©Ÿèƒ½ã‚’åˆ¶é™ã—ã‚ˆã†ã¨è©¦ã¿ã¾ã™ãŒã€é‡è¦ãªæ©Ÿèƒ½ã«ã¯ä¾å­˜ã›ã–ã‚‹ã‚’å¾—ã¾ã›ã‚“ã€‚\n\nã€Œãƒ‡ã‚¸ã‚¿ãƒ«ã‚¨ã‚³ãƒ¼ã€ã¨ã¯ã€è‡ªåˆ†ã®è¡Œå‹•ãŒãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦åé›†ã•ã‚Œã€ä»–è€…ã«ã‚ˆã£ã¦åˆ†æã•ã‚Œã¦ã„ã‚‹ã¨ã„ã†æ„è­˜ã‚’æŒ‡ã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€å¸¸ã«è¦‹ã‚‰ã‚Œã¦ã„ã‚‹æ„Ÿè¦šãŒç”Ÿã¾ã‚Œã€å€‹äººçš„ãªæ´»å‹•ãŒç¤¾ä¼šçš„ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«å¤‰ã‚ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚\n\nãã®çµæœã€ä¸€éƒ¨ã®äººã€…ã¯ãƒ¬ã‚³ãƒ¼ãƒ‰ãƒ—ãƒ¬ãƒ¼ãƒ¤ãƒ¼ã‚„ãƒ•ã‚£ãƒ«ãƒ ã‚«ãƒ¡ãƒ©ã®ã‚ˆã†ãªã‚·ãƒ³ãƒ—ãƒ«ãªã‚¢ãƒŠãƒ­ã‚°æŠ€è¡“ã«æˆ»ã‚‹ã“ã¨ã‚’é¸ã‚“ã§ã„ã¾ã™ã€‚ã“ã‚Œã‚‰ã¯ã‚ˆã‚Šæ„å›³çš„ã§é›†ä¸­ã—ãŸé–¢ä¸ã‚’ä¿ƒé€²ã—ã¾ã™ã€‚è‘—è€…ã¯ã€ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚µãƒ¼ãƒ“ã‚¹ã§ã¯ãªãè‡ªåˆ†ã®ãƒ¡ãƒ‡ã‚£ã‚¢ã‚’ä½¿ç”¨ã—ãŸã‚Šã€ã‚¹ãƒãƒ¼ãƒˆãƒ›ãƒ¼ãƒ ãƒ‡ãƒã‚¤ã‚¹ã‚’é¿ã‘ãŸã‚Šã™ã‚‹ã“ã¨ã§ã€ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ã¨ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ã‚’é«˜ã‚ã‚‹æŠ€è¡“ã‚’å—ã‘å…¥ã‚Œã‚‹å€‹äººçš„ãªé¸æŠã‚’å…±æœ‰ã—ã¦ã„ã¾ã™ã€‚\n\næœ€çµ‚çš„ã«ã¯ã€ç§ãŸã¡ã®æŠ€è¡“ã¨ã®é–¢ä¿‚ã«æ–°ãŸãªæ®µéšãŒç¾ã‚Œã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚ã“ã‚Œã¯ã€æ„å›³çš„ãªã¤ãªãŒã‚Šã«ç„¦ç‚¹ã‚’å½“ã¦ã€ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯ã‚ˆã‚Šã‚‚æ³¨æ„ã¨ç›®çš„ã‚’å„ªå…ˆã™ã‚‹ã“ã¨ã«åŸºã¥ã„ã¦ã„ã¾ã™ã€‚ç§ãŸã¡ã¯ã€ã©ã®ãƒ‡ã‚¸ã‚¿ãƒ«ã‚¨ã‚³ãƒ¼ã‚’ç”Ÿã¿å‡ºã—ã€ã©ã®ç¬é–“ã‚’ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆã«ä¿ã¤ã‹ã‚’é¸ã¶ã“ã¨ãŒã§ãã¾ã™ã€‚"
    }
  },
  {
    "id": "49c8dcdc40c3bb55",
    "title": {
      "en": "Body Doubling",
      "ko": "ì‹ ì²´ ì´ì¤‘í™”",
      "ja": "ãƒœãƒ‡ã‚£ãƒ€ãƒ–ãƒ«"
    },
    "type": "story",
    "url": "https://en.wikipedia.org/wiki/Body_doubling",
    "score": 54,
    "by": "tosh",
    "time": 1743274124,
    "content": "Toggle the table of contents\n\n\t\t\t\t\tBody doubling\n\nAdd languages\n\n\t\t\tAdd links\n\n\t\t\tArticleTalk\n\n\tEnglish\n\n\t\t\tReadEditView history\n\n\tTools\n\n\tTools\n\tmove to sidebar\n\thide\n\n\t\tActions\n\n\t\t\tReadEditView history\n\n\t\tGeneral\n\n\t\t\tWhat links hereRelated changesUpload filePermanent linkPage informationCite this pageGet shortened URLDownload QR code\n\n\t\tPrint/export\n\n\t\t\tDownload as PDFPrintable version\n\n\t\tIn other projects\n\n\t\t\tWikidata item\n\n\tAppearance\n\tmove to sidebar\n\thide\n\n\t\t\t\t\t\tFrom Wikipedia, the free encyclopedia\n\n\t\t\t\t\tStrategy of completing tasks with another person\n.mw-parser-output .hatnote{font-style:italic}.mw-parser-output div.hatnote{padding-left:1.6em;margin-bottom:0.5em}.mw-parser-output .hatnote i{font-style:normal}.mw-parser-output .hatnote+link+.hatnote{margin-top:-0.5em}@media print{body.ns-0 .mw-parser-output .hatnote{display:none!important}}Not to be confused with Body double.\nFor other uses, see Body double (disambiguation).\n.mw-parser-output .hlist dl,.mw-parser-output .hlist ol,.mw-parser-output .hlist ul{margin:0;padding:0}.mw-parser-output .hlist dd,.mw-parser-output .hlist dt,.mw-parser-output .hlist li{margin:0;display:inline}.mw-parser-output .hlist.inline,.mw-parser-output .hlist.inline dl,.mw-parser-output .hlist.inline ol,.mw-parser-output .hlist.inline ul,.mw-parser-output .hlist dl dl,.mw-parser-output .hlist dl ol,.mw-parser-output .hlist dl ul,.mw-parser-output .hlist ol dl,.mw-parser-output .hlist ol ol,.mw-parser-output .hlist ol ul,.mw-parser-output .hlist ul dl,.mw-parser-output .hlist ul ol,.mw-parser-output .hlist ul ul{display:inline}.mw-parser-output .hlist .mw-empty-li{display:none}.mw-parser-output .hlist dt::after{content:\": \"}.mw-parser-output .hlist dd::after,.mw-parser-output .hlist li::after{content:\" Â· \";font-weight:bold}.mw-parser-output .hlist dd:last-child::after,.mw-parser-output .hlist dt:last-child::after,.mw-parser-output .hlist li:last-child::after{content:none}.mw-parser-output .hlist dd dd:first-child::before,.mw-parser-output .hlist dd dt:first-child::before,.mw-parser-output .hlist dd li:first-child::before,.mw-parser-output .hlist dt dd:first-child::before,.mw-parser-output .hlist dt dt:first-child::before,.mw-parser-output .hlist dt li:first-child::before,.mw-parser-output .hlist li dd:first-child::before,.mw-parser-output .hlist li dt:first-child::before,.mw-parser-output .hlist li li:first-child::before{content:\" (\";font-weight:normal}.mw-parser-output .hlist dd dd:last-child::after,.mw-parser-output .hlist dd dt:last-child::after,.mw-parser-output .hlist dd li:last-child::after,.mw-parser-output .hlist dt dd:last-child::after,.mw-parser-output .hlist dt dt:last-child::after,.mw-parser-output .hlist dt li:last-child::after,.mw-parser-output .hlist li dd:last-child::after,.mw-parser-output .hlist li dt:last-child::after,.mw-parser-output .hlist li li:last-child::after{content:\")\";font-weight:normal}.mw-parser-output .hlist ol{counter-reset:listitem}.mw-parser-output .hlist ol>li{counter-increment:listitem}.mw-parser-output .hlist ol>li::before{content:\" \"counter(listitem)\"\\a0 \"}.mw-parser-output .hlist dd ol>li:first-child::before,.mw-parser-output .hlist dt ol>li:first-child::before,.mw-parser-output .hlist li ol>li:first-child::before{content:\" (\"counter(listitem)\"\\a0 \"}.mw-parser-output .plainlist ol,.mw-parser-output .plainlist ul{line-height:inherit;list-style:none;margin:0;padding:0}.mw-parser-output .plainlist ol li,.mw-parser-output .plainlist ul li{margin-bottom:0}.mw-parser-output .sidebar{width:22em;float:right;clear:right;margin:0.5em 0 1em 1em;background:var(--background-color-neutral-subtle,#f8f9fa);border:1px solid var(--border-color-base,#a2a9b1);padding:0.2em;text-align:center;line-height:1.4em;font-size:88%;border-collapse:collapse;display:table}body.skin-minerva .mw-parser-output .sidebar{display:table!important;float:right!important;margin:0.5em 0 1em 1em!important}.mw-parser-output .sidebar-subgroup{width:100%;margin:0;border-spacing:0}.mw-parser-output .sidebar-left{float:left;clear:left;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-none{float:none;clear:both;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-outer-title{padding:0 0.4em 0.2em;font-size:125%;line-height:1.2em;font-weight:bold}.mw-parser-output .sidebar-top-image{padding:0.4em}.mw-parser-output .sidebar-top-caption,.mw-parser-output .sidebar-pretitle-with-top-image,.mw-parser-output .sidebar-caption{padding:0.2em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-pretitle{padding:0.4em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-title,.mw-parser-output .sidebar-title-with-pretitle{padding:0.2em 0.8em;font-size:145%;line-height:1.2em}.mw-parser-output .sidebar-title-with-pretitle{padding:0.1em 0.4em}.mw-parser-output .sidebar-image{padding:0.2em 0.4em 0.4em}.mw-parser-output .sidebar-heading{padding:0.1em 0.4em}.mw-parser-output .sidebar-content{padding:0 0.5em 0.4em}.mw-parser-output .sidebar-content-with-subgroup{padding:0.1em 0.4em 0.2em}.mw-parser-output .sidebar-above,.mw-parser-output .sidebar-below{padding:0.3em 0.8em;font-weight:bold}.mw-parser-output .sidebar-collapse .sidebar-above,.mw-parser-output .sidebar-collapse .sidebar-below{border-top:1px solid #aaa;border-bottom:1px solid #aaa}.mw-parser-output .sidebar-navbar{text-align:right;font-size:115%;padding:0 0.4em 0.4em}.mw-parser-output .sidebar-list-title{padding:0 0.4em;text-align:left;font-weight:bold;line-height:1.6em;font-size:105%}.mw-parser-output .sidebar-list-title-c{padding:0 0.4em;text-align:center;margin:0 3.3em}@media(max-width:640px){body.mediawiki .mw-parser-output .sidebar{width:100%!important;clear:both;float:none!important;margin-left:0!important;margin-right:0!important}}body.skin--responsive .mw-parser-output .sidebar a>img{max-width:none!important}@media screen{html.skin-theme-clientpref-night .mw-parser-output .sidebar:not(.notheme) .sidebar-list-title,html.skin-theme-clientpref-night .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle{background:transparent!important}html.skin-theme-clientpref-night .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle a{color:var(--color-progressive)!important}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .sidebar:not(.notheme) .sidebar-list-title,html.skin-theme-clientpref-os .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle{background:transparent!important}html.skin-theme-clientpref-os .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle a{color:var(--color-progressive)!important}}@media print{body.ns-0 .mw-parser-output .sidebar{display:none!important}}Disability\nTheory and models\nDisability theory\nAbleism/ Disablism\nMedical model\nSocial model\nOther models\n\nEducation\nMainstreaming\nIndividualized Education Program (IEP)\n\nSpecial needs\nSpecial school\nSpecial education\nLearning disability\n\nTherapy\nPhysical\nOccupational\nSpeech\n\nSocietal implications\nDisability rights movement\nInclusion\nNormalization\nPeople-first language\nPejorative terms\nSexuality and disability\nWomen's health\n\nPersonal assistance\nUnlicensed assistive personnel(ADLs)\n\nAccessible toilet\nAssistive technology\nAssisted living\nMobility aid\nOrthotics and braces\nPhysical accessibility\nProsthetics\nUniversal design\nWeb accessibility\n\nSocioeconomic assistance\nSocial Security Disability Insurance\nSupplemental Security Income\nTicket to Work\nDisability Living Allowance\nDisabled Students' Allowance\nDisabled Persons Railcard\nFreedom Pass\nAssured Income forthe Severely Handicapped\nOntario Disability Support Program\n\nGroupsOrganizations\nNational Telecommuting Institute\nSociety for Disability Studies\nDisabled Peoples' International (DPI)\nVisitability\nWeThe15\n\nParasports\nSpecial Olympics\nParalympic Games\nDeaflympics\nInvictus Games\n\nCulture\nDisability in the arts\nDisability art\nDisability in the media\n\nDisabilityLists.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:\"[ \"}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:\" ]\"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}html.skin-theme-clientpref-night .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}@media(prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}}@media print{.mw-parser-output .navbar{display:none!important}}vte\nBody doubling or parallel working[1] is a strategy used to initiate and complete tasks, such as household chores or writing and other computer tasks.[2] It involves the physical presence, virtual presence through a phone call, videotelephony or social media presence,[2][3] of someone with whom one shares their goals, which makes it more likely to achieve them.[1] For some people, it works best to both do similar tasks, while for others, just being in the same (virtual) room is enough.[2]\nIt was partially popularized by those with attention deficit hyperactivity disorder (ADHD) to help manage symptoms.[4] Its usefulness has also been noted by those with autism,[2] but efficacy is not clearly known as long term studies have not been conducted on the topic.[2] In 2023, J. Russel Ramsay, professor of clinical psychiatry at the Perelman School of Medicine and co-director of the ADHD treatment and research program of the University of Pennsylvania, noted that, while extensive research on the strategy's effect on productivity doesn't exist, \"the idea of externalizing motivation is a longstanding evidence-based mechanism for managing ADHD.\"[4]\nADHD body doubling comes into play allowing individuals with ADHD to perform and complete tasks more easily and with less distractions, where otherwise they might struggle more. \"ADHD body doubling is a productivity strategy used by individuals with ADHD to finish possibly annoying jobs while having another person beside them.\"[5]\nBody doubling is said to aid individuals with focus and productivity while working. Another person, known as a 'body double' sits alongside the individual with ADHD to help them focus while completing a certain task.[6] The role of this individual is to not partake in the task but, more importantly, serve as a support system and create a welcoming environment that allows the individual to focus by reducing any distractions. The idea of body doubling allows for specific reminders to the individual to stay on task which helps alleviate the symptoms of ADHD.[4]\n\nHistory[edit]\nThe notion of body doubling derives from the cognitive behavioral therapy (CBT) techniques which focus on assisting those with cognitive disorders.[citation needed] Body doubling was first used to alleviate anxiety and improve concentration; recently, it has gained popularity as a way to promote concentration in multiple settings such as schools, home-working environments, and occupations.[6][failed verification]\nTypically, in the 20th century, treatments for ADHD include methylphenidate (Ritalin) and amphetamine mixtures  (Adderall).[7] However, recent studies suggest that body doubling could be a viable alternative rather than the widely used medications.[5] Additionally, individuals with ADHD oftentimes have educational accommodations such as extra time on exams, preferred seating, and breaking down tasks into various steps. The concept of body doubling has been recognized as a new viable option for these pre-existing accommodations.[5] The concept of having an individual close by to provide clear guidance and encouragement will allow the individual with ADHD to stay focused on a particular task should they be partaking in more than one task. It is important that the body double does not distract the other person with conversation or anything else.[4]\n\nMethodology[edit]\nThe individual and body double list specific tasks that they want to complete in a certain amount of time. The body double does not necessarily need to sit shoulder to shoulder with the individual but should provide a calming, nurturing, and quiet presence. The individual is advised not to switch tasks and solely stay focused and work on the task that was assigned.[5]\nSome benefits of body doubling include increasing the individual's accountability, less feelings of isolation, and an increase in motivation.[8] It allows for subtle reinforcement to prevent procrastination and create consistency towards their goals. According to one director of an ADHD counseling practice, \"The idea is that the presence of another is essentially a gentle reminder to stay on task (...) For folks (with) ADHD whose minds tend to wander and get off task, the body double somehow works as an external motivator to stay on task.\"[4]Most importantly, the body double creates a safe and accepting environment where the individual feels the symptoms of ADHD much less; such as criticism or failure.[9]\n\nApplications[edit]\nBody doubling is not used solely for individuals with ADHD. It is now widely used as part of therapeutic settings to assist individuals with autism, anxiety disorders, and other conditions influenced by functioning deficits.[4]\nThis concept is not structured solely for students but for professionals and any individuals who are looking to enhance and optimize their performance. Asking for and applying a body double may come across as awkward however, one could say, \"It's something I heard can help with productivity. Would you mind just being around me while I work on this? Maybe you have something you could work on, too.\"[4]\nExamples of body doubling could include someone asking a person to be on Zoom while they work on something, doing chores while on a phone with their friend, or joining a study group while preparing for a test.[9]\n\nCriticism and limitations[edit]\nWhile body doubling has been seen as an effective tool for alleviating the symptoms of ADHD, many factors come into play in determining whether it is as effective as it is said to be. A variety of factors such as personality types, individual preferences, and the types of tasks at hand can influence the effectiveness of body doubling.Additionally, relying solely on a body double to complete tasks may impact the individual's ability to develop individual working and coping strategies in the future.[citation needed] It is important and necessary for the individual to balance between individual and body double work.[8][failed verification]\n\nSee also[edit]\nProcrastination\nPomodoro Technique\nReferences[edit]\n\n^ a b .mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:\"\\\"\"\"\\\"\"\"'\"\"'\"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free.id-lock-free a{background:url(\"//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited.id-lock-limited a,.mw-parser-output .id-lock-registration.id-lock-registration a{background:url(\"//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription.id-lock-subscription a{background:url(\"//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:url(\"//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg\")right 0.1em center/12px no-repeat}body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-free a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-limited a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-registration a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-subscription a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .cs1-ws-icon a{background-size:contain;padding:0 1em 0 0}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:var(--color-error,#d33)}.mw-parser-output .cs1-visible-error{color:var(--color-error,#d33)}.mw-parser-output .cs1-maint{display:none;color:#085;margin-left:0.3em}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}@media screen{.mw-parser-output .cs1-format{font-size:95%}html.skin-theme-clientpref-night .mw-parser-output .cs1-maint{color:#18911f}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .cs1-maint{color:#18911f}}Berger, Chloe (March 5, 2023). \"Remote workers are adopting a new practice called 'body doubling,' in which they watch strangers work online\". Fortune. Archived from the original on March 5, 2023. Retrieved February 14, 2024.\n\n^ a b c d e Broadwater, Ashley (February 7, 2023). \"How 'Body Doubling' Can Help You Start And Complete Tasks\". HuffPost. Archived from the original on February 14, 2024. Retrieved February 14, 2024.\n\n^ Quinn, Patricia (December 28, 2022). \"Get More Done with a Body Double\". ADDitude. Archived from the original on February 5, 2024. Retrieved February 14, 2024.\n\n^ a b c d e f g Rogers, Kristen (February 13, 2023). \"The benefits of 'body doubling' when you have ADHD, according to experts\". CNN Health. Archived from the original on February 4, 2024. Retrieved February 14, 2024.\n\n^ a b c d \"The Body Double: A Unique Tool for Getting Things Done\". ADDA - Attention Deficit Disorder Association. October 24, 2022. Retrieved April 16, 2024.\n\n^ a b Lovering, Nancy (May 11, 2022). \"ADHD Body Doublin\". Psych Central. Retrieved April 16, 2024.\n\n^ Connolly, JJ (2015). \"ADHD & Pharmacotherapy: Past, Present and Future\". Therapeutic Innovation & Regulatory Science. 49 (5): 632â€“642. doi:10.1177/2168479015599811. PMC4564067. PMID26366330. The most common and effective medications are methylphenidates and amphetamines.\n\n^ a b \"Could a Body Double Help You Increase Your Productivity?\". Children and Adults with Attention-Deficit/Hyperactivity Disorder (CHADD). Retrieved April 16, 2024.\n\n^ a b Kim, Donna (August 30, 2023). \"Body doubling for ADHD: What it is and how it works\". Understood. Retrieved April 16, 2024.\n\n<img src=\"https://login.wikimedia.org/wiki/Special:CentralAutoLogin/start?useformat=desktop&amp;type=1x1&amp;usesul3=0\" alt=\"\" width=\"1\" height=\"1\" style=\"border: none; position: absolute;\">\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Body_doubling&oldid=1278940096\"\n\t\t\t\t\tCategories: Attention deficit hyperactivity disorderAttention deficit hyperactivity disorder managementNeurodiversityHidden categories: Articles with short descriptionShort description matches WikidataAll articles with unsourced statementsArticles with unsourced statements from July 2024All articles with failed verificationArticles with failed verification from July 2024",
    "summary": {
      "en": "**Body Doubling Summary**\n\nBody doubling is a strategy where individuals complete tasks with the presence of another person, which can be in person or through virtual means like video calls. This technique is especially helpful for people with ADHD, as it aids in focus and productivity by providing a supportive environment that reduces distractions.\n\nKey points include:\n\n1. **Definition**: Body doubling involves having someone nearby while working on tasks to enhance motivation and accountability.\n   \n2. **Target Audience**: Initially popular among individuals with ADHD, it is also beneficial for those with autism and anxiety disorders.\n\n3. **Method**: The individual and their 'body double' agree on specific tasks to complete within a set time. The body double provides a calming presence without distracting the individual.\n\n4. **Benefits**: Increases motivation, reduces feelings of isolation, and helps individuals stay focused on their tasks.\n\n5. **Applications**: Used in various settings, including schools and workplaces, and can be as simple as working alongside someone on a video call.\n\n6. **Criticism**: Effectiveness can vary based on personal preferences and task types. Relying solely on a body double may hinder the development of individual work strategies.\n\nOverall, body doubling is a supportive approach that can help individuals, particularly those with ADHD, manage their tasks more effectively.",
      "ko": "ë°”ë”” ë”ë¸”ë§ì€ ê°œì¸ì´ ë‹¤ë¥¸ ì‚¬ëŒê³¼ í•¨ê»˜ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ì „ëµìœ¼ë¡œ, ì´ ì‚¬ëŒì€ ì§ì ‘ ë§Œë‚˜ê±°ë‚˜ í™”ìƒ í†µí™”ë¥¼ í†µí•´ ì¡´ì¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ê¸°ë²•ì€ ADHDê°€ ìˆëŠ” ì‚¬ëŒë“¤ì—ê²Œ íŠ¹íˆ ìœ ìš©í•˜ë©°, ì£¼ì˜ë ¥ì„ ë†’ì´ê³  ìƒì‚°ì„±ì„ í–¥ìƒì‹œí‚¤ëŠ” ë° ë„ì›€ì„ ì¤ë‹ˆë‹¤. ì´ëŠ” ë°©í•´ ìš”ì†Œë¥¼ ì¤„ì—¬ì£¼ëŠ” ì§€ì› í™˜ê²½ì„ ì œê³µí•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.\n\në°”ë”” ë”ë¸”ë§ì˜ ì£¼ìš” ë‚´ìš©ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. ì²«ì§¸, ë°”ë”” ë”ë¸”ë§ì€ ì‘ì—…ì„ ìˆ˜í–‰í•  ë•Œ ëˆ„êµ°ê°€ ê°€ê¹Œì´ì— ìˆì–´ ë™ê¸° ë¶€ì—¬ì™€ ì±…ì„ê°ì„ ë†’ì´ëŠ” ê²ƒì…ë‹ˆë‹¤. ë‘˜ì§¸, ì´ ë°©ë²•ì€ ì²˜ìŒì—ëŠ” ADHDê°€ ìˆëŠ” ì‚¬ëŒë“¤ ì‚¬ì´ì—ì„œ ì¸ê¸°ë¥¼ ëŒì—ˆì§€ë§Œ, ìíì¦ì´ë‚˜ ë¶ˆì•ˆ ì¥ì• ê°€ ìˆëŠ” ì‚¬ëŒë“¤ì—ê²Œë„ ìœ ìµí•©ë‹ˆë‹¤. ì…‹ì§¸, ê°œì¸ê³¼ ê·¸ë“¤ì˜ ë°”ë”” ë”ë¸”ì€ ì •í•´ì§„ ì‹œê°„ ë‚´ì— ì™„ë£Œí•  íŠ¹ì • ì‘ì—…ì— ëŒ€í•´ í•©ì˜í•©ë‹ˆë‹¤. ë°”ë”” ë”ë¸”ì€ ê°œì¸ì„ ë°©í•´í•˜ì§€ ì•Šìœ¼ë©´ì„œ ì•ˆì •ê°ì„ ì œê³µí•©ë‹ˆë‹¤.\n\në°”ë”” ë”ë¸”ë§ì˜ ì¥ì ìœ¼ë¡œëŠ” ë™ê¸° ë¶€ì—¬ë¥¼ ì¦ê°€ì‹œí‚¤ê³  ê³ ë¦½ê°ì„ ì¤„ì´ë©°, ê°œì¸ì´ ì‘ì—…ì— ì§‘ì¤‘í•  ìˆ˜ ìˆë„ë¡ ë•ëŠ” ê²ƒì´ ìˆìŠµë‹ˆë‹¤. ì´ ë°©ë²•ì€ í•™êµë‚˜ ì§ì¥ ë“± ë‹¤ì–‘í•œ í™˜ê²½ì—ì„œ ì‚¬ìš©ë˜ë©°, í™”ìƒ í†µí™”ë¥¼ í†µí•´ ëˆ„êµ°ê°€ì™€ í•¨ê»˜ ì‘ì—…í•˜ëŠ” ê²ƒì²˜ëŸ¼ ê°„ë‹¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ë¹„íŒì ì¸ ì‹œê°ë„ ì¡´ì¬í•©ë‹ˆë‹¤. íš¨ê³¼ëŠ” ê°œì¸ì˜ ì„ í˜¸ë„ì™€ ì‘ì—… ìœ í˜•ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë©°, ë°”ë”” ë”ë¸”ì—ë§Œ ì˜ì¡´í•˜ë©´ ê°œì¸ì˜ ì‘ì—… ì „ëµ ê°œë°œì— ë°©í•´ê°€ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nì „ë°˜ì ìœ¼ë¡œ ë°”ë”” ë”ë¸”ë§ì€ íŠ¹íˆ ADHDê°€ ìˆëŠ” ê°œì¸ì´ ì‘ì—…ì„ ë³´ë‹¤ íš¨ê³¼ì ìœ¼ë¡œ ê´€ë¦¬í•˜ëŠ” ë° ë„ì›€ì„ ì¤„ ìˆ˜ ìˆëŠ” ì§€ì›ì ì¸ ì ‘ê·¼ ë°©ì‹ì…ë‹ˆë‹¤.",
      "ja": "ãƒœãƒ‡ã‚£ãƒ€ãƒ–ãƒ«ã¯ã€ä»–ã®äººã¨ä¸€ç·’ã«ã‚¿ã‚¹ã‚¯ã‚’è¡Œã†æˆ¦ç•¥ã§ã€å¯¾é¢ã¾ãŸã¯ãƒ“ãƒ‡ã‚ªé€šè©±ãªã©ã®ä»®æƒ³æ‰‹æ®µã‚’é€šã˜ã¦è¡Œã‚ã‚Œã¾ã™ã€‚ã“ã®æŠ€æ³•ã¯ç‰¹ã«ADHDã®äººã€…ã«å½¹ç«‹ã¡ã€é›†ä¸­åŠ›ã‚„ç”Ÿç”£æ€§ã‚’é«˜ã‚ã‚‹ãŸã‚ã®æ”¯æ´çš„ãªç’°å¢ƒã‚’æä¾›ã—ã€æ°—ã‚’æ•£ã‚‰ã™è¦å› ã‚’æ¸›ã‚‰ã—ã¾ã™ã€‚\n\nãƒœãƒ‡ã‚£ãƒ€ãƒ–ãƒ«ã®å®šç¾©ã¯ã€ä½œæ¥­ä¸­ã«èª°ã‹ãŒè¿‘ãã«ã„ã‚‹ã“ã¨ã§ã€ãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã‚„è²¬ä»»æ„Ÿã‚’é«˜ã‚ã‚‹ã“ã¨ã§ã™ã€‚æœ€åˆã¯ADHDã®äººã€…ã®é–“ã§äººæ°—ãŒã‚ã‚Šã¾ã—ãŸãŒã€è‡ªé–‰ç—‡ã‚„ä¸å®‰éšœå®³ã‚’æŒã¤äººã€…ã«ã‚‚æœ‰ç›Šã§ã™ã€‚\n\nã“ã®æ–¹æ³•ã§ã¯ã€å€‹äººã¨ãã®ãƒœãƒ‡ã‚£ãƒ€ãƒ–ãƒ«ãŒç‰¹å®šã®ã‚¿ã‚¹ã‚¯ã‚’è¨­å®šã—ãŸæ™‚é–“å†…ã«å®Œäº†ã™ã‚‹ã“ã¨ã«åˆæ„ã—ã¾ã™ã€‚ãƒœãƒ‡ã‚£ãƒ€ãƒ–ãƒ«ã¯ã€æ°—ã‚’æ•£ã‚‰ã•ãšã«è½ã¡ç€ã„ãŸå­˜åœ¨ã‚’æä¾›ã—ã¾ã™ã€‚\n\nãƒœãƒ‡ã‚£ãƒ€ãƒ–ãƒ«ã®åˆ©ç‚¹ã«ã¯ã€ãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã®å‘ä¸Šã€å­¤ç‹¬æ„Ÿã®è»½æ¸›ã€ã‚¿ã‚¹ã‚¯ã«é›†ä¸­ã™ã‚‹æ‰‹åŠ©ã‘ãŒå«ã¾ã‚Œã¾ã™ã€‚å­¦æ ¡ã‚„è·å ´ãªã©ã•ã¾ã–ã¾ãªå ´é¢ã§åˆ©ç”¨ã•ã‚Œã¦ãŠã‚Šã€ãƒ“ãƒ‡ã‚ªé€šè©±ã§èª°ã‹ã¨ä¸€ç·’ã«ä½œæ¥­ã™ã‚‹ã ã‘ã§ã‚‚åŠ¹æœãŒã‚ã‚Šã¾ã™ã€‚\n\nãŸã ã—ã€åŠ¹æœã¯å€‹äººã®å¥½ã¿ã‚„ã‚¿ã‚¹ã‚¯ã®ç¨®é¡ã«ã‚ˆã£ã¦ç•°ãªã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚ãƒœãƒ‡ã‚£ãƒ€ãƒ–ãƒ«ã«é ¼ã‚Šã™ãã‚‹ã¨ã€å€‹ã€…ã®ä½œæ¥­æˆ¦ç•¥ã®ç™ºå±•ã‚’å¦¨ã’ã‚‹å¯èƒ½æ€§ã‚‚ã‚ã‚Šã¾ã™ã€‚\n\nå…¨ä½“ã¨ã—ã¦ã€ãƒœãƒ‡ã‚£ãƒ€ãƒ–ãƒ«ã¯ç‰¹ã«ADHDã®äººã€…ãŒã‚¿ã‚¹ã‚¯ã‚’ã‚ˆã‚ŠåŠ¹æœçš„ã«ç®¡ç†ã™ã‚‹ãŸã‚ã®æ”¯æ´çš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã™ã€‚"
    }
  },
  {
    "id": "74fec543d154070c",
    "title": {
      "en": "Decomposing a Factorial into Large Factors",
      "ko": "íŒ©í† ë¦¬ì–¼ì˜ í° ì¸ìˆ˜ ë¶„í•´",
      "ja": "å¤§å› å­ã®åˆ†è§£"
    },
    "type": "story",
    "url": "https://terrytao.wordpress.com/2025/03/26/decomposing-a-factorial-into-large-factors/",
    "score": 128,
    "by": "surprisetalk",
    "time": 1743173754,
    "content": "Decomposing a factorial into largefactors\n\t\t26 March, 2025 in math.NT, paper | Tags: Erdos, factorial function, factorisation | by Terence Tao\n\nIâ€™ve just uploaded to the arXiv the paper â€œDecomposing a factorial into large factorsâ€œ. This paper studies the quantity , defined as the largest quantity such that it is possible to factorize  into  factors , each of which is at least . The first few values of this sequence are\n (OEIS A034258). For instance, we have , because on the one hand we can factor\n but on the other hand it is not possible to factorize  into nine factors, each of which is  or higher.\n\nThis quantity  was introduced by ErdÃ¶s, who asked for upper and lower bounds on ; informally, this asks how equitably one can split up  into  factors. When factoring an arbitrary number, this is essentially a variant of the notorious knapsack problem (after taking logarithms), but one can hope that the specific structure of the factorial  can make this particular knapsack-type problem more tractable. Since\n for any putative factorization, we obtain an upper bound\n thanks to the Stirling approximation. At one point, ErdÃ¶s, Selfridge, and Straus claimed that this upper bound was asymptotically sharp, in the sense that\n as ; informally, this means we can split  into  factors that are (mostly) approximately the same size, when  is large. However, as reported in this later paper, ErdÃ¶s â€œbelieved that Straus had written up our proofâ€¦ Unfortunately Straus suddenly died and no trace was ever found of his notes. Furthermore, we never could reconstruct our proof, so our assertion now can be called only a conjectureâ€.\n\nSome further exploration of  was conducted by Guy and Selfridge. There is a simple construction that gives the lower bound\n that comes from starting with the standard factorization  and transferring some powers of  from the later part of the sequence to the earlier part to rebalance the terms somewhat. More precisely, if one removes one power of two from the even numbers between  and , and one additional power of two from the multiples of four between  to , this frees up  powers of two that one can then distribute amongst the numbers up to  to bring them all up to at least  in size. A more complicated procedure involving transferring both powers of  and  then gives the improvement . At this point, however, things got more complicated, and the following conjectures were made by Guy and Selfridge:\n\n  (i) Is  for all ?  (ii) Is  for all ? (At , this conjecture barely fails: .)  (iii) Is  for all ?\n\nIn this note we establish the bounds\n as , where  is the explicit constant\n In particular this recovers the lost result (2). An upper bound of the shape\n for some  was previously conjectured by ErdÃ¶s and Graham (ErdÃ¶s problem #391). We conjecture that the upper bound in (3) is sharp, thus\n which is consistent with the above conjectures (i), (ii), (iii) of Guy and Selfridge, although numerically the convergence is somewhat slow.\n\nThe upper bound argument for (3) is simple enough that it could also be modified to establish the first conjecture (i) of Guy and Selfridge; in principle, (ii) and (iii) are now also reducible to a finite computation, but unfortunately the implied constants in the lower bound of (3) are too weak to make this directly feasible. However, it may be possible to now crowdsource the verification of (ii) and (iii) by supplying a suitable set of factorizations to cover medium sized , combined with some effective version of the lower bound argument that can establish  for all  past a certain threshold. The value  singled out by Guy and Selfridge appears to be quite a suitable test case: the constructions I tried fell just a little short of the conjectured threshold of , but it seems barely within reach that a sufficiently efficient rearrangement of factors can work here.\n\nWe now describe the proof of the upper and lower bound in (3). To improve upon the trivial upper bound (1), one can use the large prime factors of . Indeed, every prime  between  and  divides  at least once (and the ones between  and  divide it twice), and any factor  that contains such a factor therefore has to be significantly larger than the benchmark value of . This observation already readily leads to some upper bound of the shape (4) for some ; if one also uses the primes  that are slightly less than  (noting that any multiple of  that exceeds , must in fact exceed ) is what leads to the precise constant .\n\nFor previous lower bound constructions, one started with the initial factorization  and then tried to â€œimproveâ€ this factorization by moving around some of the prime factors. For the lower bound in (3), we start instead with an approximate factorization roughly of the shape\n where  is the target lower bound (so, slightly smaller than ), and  is a moderately sized natural number parameter (we will take , although there is significant flexibility here). If we denote the right-hand side here by , then  is basically a product of  numbers of size at least . It is not literally equal to ; however, an easy application of Legendreâ€™s formula shows that for odd small primes ,  and  have almost exactly the same number of factors of . On the other hand, as  is odd,  contains no factors of , while  contains about  such factors. The prime factorizations of  and  differ somewhat at large primes, but  has slightly more such prime factors as  (about  such factors, in fact). By some careful applications of the prime number theorem, one can tweak some of the large primes appearing in  to make the prime factorization of  and  agree almost exactly, except that  is missing most of the powers of  in , while having some additional large prime factors beyond those contained in  to compensate. With a suitable choice of threshold , one can then replace these excess large prime factors with powers of two to obtain a factorization of  into  terms that are all at least , giving the lower bound.\n\nThe general approach of first locating some approximate factorization of  (where the approximation is in the â€œadelicâ€ sense of having not just approximately the right magnitude, but also approximately the right number of factors of  for various primes ), and then moving factors around to get an exact factorization of , looks promising for also resolving the conjectures (ii), (iii) mentioned above. For instance, I was numerically able to verify that  by the following procedure:\n\n  Start with the approximate factorization of ,  by . Thus  is the product of  odd numbers, each of which is at least .  Call an odd prime -heavy if it divides  more often than , and -heavy if it divides  more often than . It turns out that there are  more -heavy primes than -heavy primes (counting multiplicity). On the other hand,  contains  powers of , while  has none. This represents the (multi-)set of primes one has to redistribute in order to convert a factorization of  to a factorization of .  Using a greedy algorithm, one can match a -heavy prime  to each -heavy prime  (counting multiplicity) in such a way that  for a small  (in most cases one can make , and often one also has ). If we then replace  in the factorization of  by  for each -heavy prime , this increases  (and does not decrease any of the  factors of ), while eliminating all the -heavy primes. With a somewhat crude matching algorithm, I was able to do this using  of the  powers of  dividing , leaving  powers remaining at my disposal. (I donâ€™t claim that this is the most efficient matching, in terms of powers of two required, but it sufficed.)  There are still  -heavy primes left over in the factorization of (the modified version of) . Replacing each of these primes with , and then distributing the remaining  powers of two arbitrarily, this obtains a factorization of  into  terms, each of which are at least .\n\nHowever, I was not able to adjust parameters to reach  in this manner. Perhaps some readers here who are adept with computers can come up with a more efficient construction to get closer to this bound? If one can find a way to reach this bound, most likely it can be adapted to then resolve conjectures (ii) and (iii) above after some additional numerical effort.\n\nShare this:PrintEmailMoreTwitterFacebookRedditPinterestLike Loading...\n\nRecent Comments\n\t\t\t\t\tTerence Tao on Decomposing a factorial into lâ€¦Terence Tao on Large prime gaps and probabiliâ€¦Terence Tao on Large prime gaps and probabiliâ€¦alufat on Large prime gaps and probabiliâ€¦ducduc2710 on Large prime gaps and probabiliâ€¦Terence Tao on Large prime gaps and probabiliâ€¦alufat on Large prime gaps and probabiliâ€¦Terence Tao on Decomposing a factorial into lâ€¦Terence Tao on Decomposing a factorial into lâ€¦Terence Tao on Decomposing a factorial into lâ€¦Anonymous on Decomposing a factorial into lâ€¦Anonymous on Decomposing a factorial into lâ€¦Anonymous on Decomposing a factorial into lâ€¦Anonymous on Analysis ITerence Tao on Decomposing a factorial into lâ€¦\n\nTop PostsDecomposing a factorial into large factorsCareer adviceThe three-dimensional Kakeya conjecture, after Wang and ZahlCosmic Distance Ladder videos with Grant Sanderson (3blue1brown): commentary and correctionsAnalysis IBooksOn writingWork hardDoes one have to be a genius to do maths?AboutArchives\n\n\t\t\t\t\tMarch 2025(1)\n\tFebruary 2025(3)\n\tJanuary 2025(1)\n\tDecember 2024(3)\n\tNovember 2024(4)\n\tOctober 2024(1)\n\tSeptember 2024(4)\n\tAugust 2024(3)\n\tJuly 2024(3)\n\tJune 2024(1)\n\tMay 2024(1)\n\tApril 2024(5)\n\tMarch 2024(1)\n\tDecember 2023(2)\n\tNovember 2023(2)\n\tOctober 2023(1)\n\tSeptember 2023(3)\n\tAugust 2023(3)\n\tJune 2023(8)\n\tMay 2023(1)\n\tApril 2023(1)\n\tMarch 2023(2)\n\tFebruary 2023(1)\n\tJanuary 2023(2)\n\tDecember 2022(3)\n\tNovember 2022(3)\n\tOctober 2022(3)\n\tSeptember 2022(1)\n\tJuly 2022(3)\n\tJune 2022(1)\n\tMay 2022(2)\n\tApril 2022(2)\n\tMarch 2022(5)\n\tFebruary 2022(3)\n\tJanuary 2022(1)\n\tDecember 2021(2)\n\tNovember 2021(2)\n\tOctober 2021(1)\n\tSeptember 2021(2)\n\tAugust 2021(1)\n\tJuly 2021(3)\n\tJune 2021(1)\n\tMay 2021(2)\n\tFebruary 2021(6)\n\tJanuary 2021(2)\n\tDecember 2020(4)\n\tNovember 2020(2)\n\tOctober 2020(4)\n\tSeptember 2020(5)\n\tAugust 2020(2)\n\tJuly 2020(2)\n\tJune 2020(1)\n\tMay 2020(2)\n\tApril 2020(3)\n\tMarch 2020(9)\n\tFebruary 2020(1)\n\tJanuary 2020(3)\n\tDecember 2019(4)\n\tNovember 2019(2)\n\tSeptember 2019(2)\n\tAugust 2019(3)\n\tJuly 2019(2)\n\tJune 2019(4)\n\tMay 2019(6)\n\tApril 2019(4)\n\tMarch 2019(2)\n\tFebruary 2019(5)\n\tJanuary 2019(1)\n\tDecember 2018(6)\n\tNovember 2018(2)\n\tOctober 2018(2)\n\tSeptember 2018(5)\n\tAugust 2018(3)\n\tJuly 2018(3)\n\tJune 2018(1)\n\tMay 2018(4)\n\tApril 2018(4)\n\tMarch 2018(5)\n\tFebruary 2018(4)\n\tJanuary 2018(5)\n\tDecember 2017(5)\n\tNovember 2017(3)\n\tOctober 2017(4)\n\tSeptember 2017(4)\n\tAugust 2017(5)\n\tJuly 2017(5)\n\tJune 2017(1)\n\tMay 2017(3)\n\tApril 2017(2)\n\tMarch 2017(3)\n\tFebruary 2017(1)\n\tJanuary 2017(2)\n\tDecember 2016(2)\n\tNovember 2016(2)\n\tOctober 2016(5)\n\tSeptember 2016(4)\n\tAugust 2016(4)\n\tJuly 2016(1)\n\tJune 2016(3)\n\tMay 2016(5)\n\tApril 2016(2)\n\tMarch 2016(6)\n\tFebruary 2016(2)\n\tJanuary 2016(1)\n\tDecember 2015(4)\n\tNovember 2015(6)\n\tOctober 2015(5)\n\tSeptember 2015(5)\n\tAugust 2015(4)\n\tJuly 2015(7)\n\tJune 2015(1)\n\tMay 2015(5)\n\tApril 2015(4)\n\tMarch 2015(3)\n\tFebruary 2015(4)\n\tJanuary 2015(4)\n\tDecember 2014(6)\n\tNovember 2014(5)\n\tOctober 2014(4)\n\tSeptember 2014(3)\n\tAugust 2014(4)\n\tJuly 2014(5)\n\tJune 2014(5)\n\tMay 2014(5)\n\tApril 2014(2)\n\tMarch 2014(4)\n\tFebruary 2014(5)\n\tJanuary 2014(4)\n\tDecember 2013(4)\n\tNovember 2013(5)\n\tOctober 2013(4)\n\tSeptember 2013(5)\n\tAugust 2013(1)\n\tJuly 2013(7)\n\tJune 2013(12)\n\tMay 2013(4)\n\tApril 2013(2)\n\tMarch 2013(2)\n\tFebruary 2013(6)\n\tJanuary 2013(1)\n\tDecember 2012(4)\n\tNovember 2012(7)\n\tOctober 2012(6)\n\tSeptember 2012(4)\n\tAugust 2012(3)\n\tJuly 2012(4)\n\tJune 2012(3)\n\tMay 2012(3)\n\tApril 2012(4)\n\tMarch 2012(5)\n\tFebruary 2012(5)\n\tJanuary 2012(4)\n\tDecember 2011(8)\n\tNovember 2011(8)\n\tOctober 2011(7)\n\tSeptember 2011(6)\n\tAugust 2011(8)\n\tJuly 2011(9)\n\tJune 2011(8)\n\tMay 2011(11)\n\tApril 2011(3)\n\tMarch 2011(10)\n\tFebruary 2011(3)\n\tJanuary 2011(5)\n\tDecember 2010(5)\n\tNovember 2010(6)\n\tOctober 2010(9)\n\tSeptember 2010(9)\n\tAugust 2010(3)\n\tJuly 2010(4)\n\tJune 2010(8)\n\tMay 2010(8)\n\tApril 2010(8)\n\tMarch 2010(8)\n\tFebruary 2010(10)\n\tJanuary 2010(12)\n\tDecember 2009(11)\n\tNovember 2009(8)\n\tOctober 2009(15)\n\tSeptember 2009(6)\n\tAugust 2009(13)\n\tJuly 2009(10)\n\tJune 2009(11)\n\tMay 2009(9)\n\tApril 2009(11)\n\tMarch 2009(14)\n\tFebruary 2009(13)\n\tJanuary 2009(18)\n\tDecember 2008(8)\n\tNovember 2008(9)\n\tOctober 2008(10)\n\tSeptember 2008(5)\n\tAugust 2008(6)\n\tJuly 2008(7)\n\tJune 2008(8)\n\tMay 2008(11)\n\tApril 2008(12)\n\tMarch 2008(12)\n\tFebruary 2008(13)\n\tJanuary 2008(17)\n\tDecember 2007(10)\n\tNovember 2007(9)\n\tOctober 2007(9)\n\tSeptember 2007(7)\n\tAugust 2007(9)\n\tJuly 2007(9)\n\tJune 2007(6)\n\tMay 2007(10)\n\tApril 2007(11)\n\tMarch 2007(9)\n\tFebruary 2007(4)\n\n\t\t\tCategories\n\n\t\t\t\t\texpository (315)\n\n\ttricks (13)\n\n\tguest blog (10)\n\n\tMathematics (885)\n\n\tmath.AC (8)\n\n\tmath.AG (42)\n\n\tmath.AP (114)\n\n\tmath.AT (17)\n\n\tmath.CA (188)\n\n\tmath.CO (197)\n\n\tmath.CT (9)\n\n\tmath.CV (37)\n\n\tmath.DG (37)\n\n\tmath.DS (89)\n\n\tmath.FA (24)\n\n\tmath.GM (14)\n\n\tmath.GN (21)\n\n\tmath.GR (88)\n\n\tmath.GT (16)\n\n\tmath.HO (13)\n\n\tmath.IT (13)\n\n\tmath.LO (53)\n\n\tmath.MG (47)\n\n\tmath.MP (31)\n\n\tmath.NA (24)\n\n\tmath.NT (199)\n\n\tmath.OA (22)\n\n\tmath.PR (109)\n\n\tmath.QA (6)\n\n\tmath.RA (47)\n\n\tmath.RT (21)\n\n\tmath.SG (4)\n\n\tmath.SP (48)\n\n\tmath.ST (11)\n\n\tnon-technical (195)\n\n\tadmin (46)\n\n\tadvertising (66)\n\n\tdiversions (7)\n\n\tmedia (14)\n\n\tjournals (3)\n\n\tobituary (15)\n\n\topinion (36)\n\n\tpaper (253)\n\n\tbook (20)\n\n\tCompanion (13)\n\n\tupdate (23)\n\n\tquestion (127)\n\n\tpolymath (86)\n\n\ttalk (68)\n\n\tDLS (20)\n\n\tteaching (188)\n\n\t245A â€“ Real analysis (11)\n\n\t245B â€“ Real analysis (21)\n\n\t245C â€“ Real analysis (6)\n\n\t246A â€“ complex analysis (11)\n\n\t246B â€“ complex analysis (5)\n\n\t246C â€“ complex analysis (5)\n\n\t247B â€“ Classical Fourier Analysis (5)\n\n\t254A â€“ analytic prime number theory (19)\n\n\t254A â€“ ergodic theory (18)\n\n\t254A â€“ Hilbert's fifth problem (12)\n\n\t254A â€“ Incompressible fluid equations (5)\n\n\t254A â€“ random matrices (14)\n\n\t254B â€“ expansion in groups (8)\n\n\t254B â€“ Higher order Fourier analysis (9)\n\n\t255B â€“ incompressible Euler equations (2)\n\n\t275A â€“ probability theory (6)\n\n\t285G â€“ poincare conjecture (20)\n\n\tLogic reading seminar (8)\n\n\tThe sciences (1)\n\n\ttravel (26)\n\n\t\t\tadditive combinatorics\napproximate groups\narithmetic progressions\nBen Green\nCauchy-Schwarz\nCayley graphs\ncentral limit theorem\nChowla conjecture\ncompressed sensing\ncorrespondence principle\ndistributions\ndivisor function\neigenvalues\nElias Stein\nEmmanuel Breuillard\nentropy\nequidistribution\nergodic theory\nEuler equations\nexponential sums\nfinite fields\nFourier transform\nFreiman's theorem\nGowers uniformity norm\nGowers uniformity norms\ngraph theory\nGromov's theorem\nGUE\nHilbert's fifth problem\nincompressible Euler equations\ninverse conjecture\nJoni Teravainen\nKaisa Matomaki\nKakeya conjecture\nLie algebras\nLie groups\nLiouville function\nLittlewood-Offord problem\nMaksym Radziwill\nMobius function\nmultiplicative functions\nNavier-Stokes equations\nnilpotent groups\nnilsequences\nnonstandard analysis\nparity problem\nPaul Erdos\npolitics\npolymath1\npolymath8\nPolymath15\npolynomial method\npolynomials\nprime gaps\nprime numbers\nprime number theorem\nrandom matrices\nrandomness\nRatner's theorem\nregularity lemma\nRicci flow\nRiemann zeta function\nSchrodinger equation\nShannon entropy\nsieve theory\nstructure\nSzemeredi's theorem\nTamar Ziegler\ntiling\nUCLA\nultrafilters\nuniversality\nVan Vu\nwave maps\nYitang Zhang The Polymath BlogPolymath projects 2021A sort of Polymath on a famous MathOverflow problemTen Years of PolymathUpdates and PicturesPolymath proposal: finding simpler unit distance graphs of chromatic number 5A new polymath proposal (related to the Riemann Hypothesis) over Taoâ€™s blogSpontaneous Polymath 14 â€“ A success!Polymath 13 â€“ a success!Non-transitive Dice over Gowersâ€™s BlogRotaâ€™s Basis Conjecture: Polymath 12, post 3\n\n\t\t\t21 comments\n\t\t\tComments feed for this article\n\n\t\t\t26 March, 2025 at 8:27 pm\n\t\t\tAnonymous\n\n\t\t\t\t\t\tthere is an open brace for href\n[Corrected, thanks â€“ T.]\n\n\t\t\t\tReply\n\n\t\t\t26 March, 2025 at 11:04 pm\n\t\t\tSamuel Bonaya Buya\n\n\t\t\t\t\t\tIn my opinion the paper is a significant contribution by Tao on the understanding of the prime number theorem\n\n\t\t\t\tReply\n\n\t\t\t27 March, 2025 at 4:02 am\n\t\t\tAntoine Deleforge\n\n\t\t\t\t\t\tLooking at the first few numbers in the OEIS sequence, it looks like t(n+1) â€“ t(n) is always zero or one. Is there any reason for this to be true?\n\n\t\t\t\tReply\n\n\t\t\t27 March, 2025 at 6:39 am\n\t\t\tTerence Tao\n\n\t\t\t\t\t\tNo; in fact, in Guyâ€™s article on this problem, he notes that there is a jump of  from  to  (though he does not provide enough preceding values to extend the sequence in the OEIS).  In that article he also notes that Erdos conjectures that the gaps can in fact be arbitrarily large, though I see no way to attack this question even heuristically (as the extremizers for this problem may be neither structured nor (pseudo)random, but exhibit some very strange intermediate behavior).\nIn the image below, I display the upper bound on  (the pink dots) in the intermediate range  coming from Lemma 2.1 of my paper (there is no plot for  in this image as I do not have data in this range).  [Incidentally there is a slight typo in that lemma, which I will correct in the next revision: the term  should instead be .]  There is considerable fluctuation here (due to the corresponding fluctuation in the primes), which is also reflected in the related plot in Figure 2 of the paper.  Of course, fluctuation in the upper bound for  does not imply fluctuation in the true value of , but it is perhaps evidence in that direction.\n\nAnd below is a comparison of the upper bound against the true value of  in the range :\n\n\t\t\t\tReply\n\n\t\t\t27 March, 2025 at 4:14 am\n\t\t\tIvan\n\n\t\t\t\t\t\tYou may want to enclose the comma in curly brackets when it is used as a thousands separator so that  does not generate extra space after it, e.g.,  instead of  (p. 3 of the paper).\n[Thanks, this will be done in the next revision of the ms -T]\n\n\t\t\t\tReply\n\n\t\t\t27 March, 2025 at 5:18 am\n\t\t\tAntoine Deleforge\n\n\t\t\t\t\t\tI donâ€™t immediately see the connection to the knapsack problem. If we pick the non-dividable items to be the logs of the prime factors of N!, then the problem amounts to distributing *all* of these items into N knapsacks, such that each knapsack contains *at least* a value of t(N). This is quite different from the original knapsack problem where the goal is rather to select a *subset* of items, and maximize the value while remaining *below* the knapsack capacity. Is there a deeper or more natural connection that I am missing? Can further progress on this Erdos problem be expected to eventually yield insights on the knapsack problem, or is the relation between the two too distant for that to happen?\n\n\t\t\t\tReply\n\n\t\t\t27 March, 2025 at 6:53 am\n\t\t\tTerence Tao\n\n\t\t\t\t\t\tItâ€™s more accurate to say that the factorial problem is a *variant* of the knapsack problem; most directly, it corresponds to a knapsack problem with negative item sizes (and negative capacity in the backpack), which of course is not physically realistic (or intuitive), but it is possible that some of the knapsack algorithms that work for positive sizes and capacities can carry over to this new context with suitable modification.  (For instance, I would guess that the problem of solving this sort of factoring problem for a general input number (rather than a factorial) is NP-complete, by some modification of the proof of NP-completeness of the knapsack problem.)\nNote by the way that to solve the factorization problem, it suffices to distribute some subset of the log-primes into the knapsacks rather than all of them, since one can just add in the remaining log-primes arbitrarily to finish the job.\n\n\t\t\t\tReply\n\n\t\t\t28 March, 2025 at 11:21 pm\n\t\t\tAnonymous\n\n\t\t\t\t\t\tAt first view it looks that this is closer to a Bin packing problem than to a knapsack problem.\n\n\t\t\t\tReply\n\n\t\t\t29 March, 2025 at 5:50 am\n\t\t\tTerence Tao\n\n\t\t\t\t\t\tFollowing your hint, it seems in fact that this problem is a special case of the bin covering problem, which is dual to the bin packing problem.\n\n\t\t\t\tReply\n\n\t\t\t27 March, 2025 at 7:08 am\n\t\t\tducduc2710\n\n\t\t\t\t\t\tThat technique I think can be used to limit prime gaps.\n\n\t\t\t\tReply\n\n\t\t\t27 March, 2025 at 7:21 am\n\t\t\tAnonymous\n\n\t\t\t\t\t\tSmall typo: â€œmultiples of four between3/4 to Nâ€ It should be 3/4N to N.\n\n[Corrected, thanks -T.]\n\n\t\t\t\tReply\n\n\t\t\t27 March, 2025 at 11:35 am\n\t\t\tTerence Tao\n\n\t\t\t\t\t\tIâ€™m posting (with permission) some computational work by Andrew Sutherland, who implemented a greedy approach working through the prime factors  of  inreverse order (with multiplicity), constucting integers of the form  with  chosen to be minimal subject to the constraint that it can be constructed from the divisors of  that still remain. For instance when , it is able to factor  into  numbers greater than or equal to , verifying the Guy-Selfridge conjecture at this value. The code (in Maple) is at https://math.mit.edu/~drew/GuySelfridge.m . An earlier (less efficient) factorization with these parameters can be found at https://math.mit.edu/~drew/ES300000.txt .\nAndrew writes, â€ It only takes about a few seconds on a fast machine so I was able to run it on all  in  and noticed that while it typically succeeds on , it still fails to prove  in  cases in , including  as large as . But it succeeds on every  in , so if the conjecture is true, it is still true if you replace  with  (probably this can be lowered a lot further, the greedy approach is not optimal).\nI then tested the threshold  on all  from  to . It failed only for â€œ.\nWith this data, one can now reduce conjecture (ii) to conjecture (iii) provided one can construct suitable factorizations of  to resolve the three remaining cases  (one also has to retest the range  but this should be straightforward, since there is now enough room that one should be able to sample this range quite sparsely, e.g., test the threshold  for  a multiple of ). But the range  seems a bit more delicate, as the most direct greedy algorithm sometimes fails.\nAndrew adds, â€œI think itâ€™s possible that one might be able to turn this algorithm into an asymptotic bound. For sufficiently large prime divisors  of , you can just take  because  will be small and there are plenty of powers of small primes initially available (and you can quantify this), and even if you focus just on the integers the algorithm constructs before it hits the first cofactor it cannot minimize you should get some constant factor of  that might be bigger than .â€\n\n\t\t\t\tReply\n\n\t\t\t27 March, 2025 at 12:18 pm\n\t\t\tTerence Tao\n\n\t\t\t\t\t\tAndrew has kindly shared with me the lower bounds for  for  given by this approach, and I have incorporated them into my previous plot here, showing the current upper (pink) and lower (blue) bounds on :\n\nNote the verification of the conjecture  in this range for .  The data also replicates Guyâ€™s reported values , and suggests that the jumps in  are indeed rather irregular. (The text file for the data can be found here.)\n\n\t\t\t\tReply\n\n\t\t\t27 March, 2025 at 2:35 pm\n\t\t\tfrobitzblog\n\n\t\t\t\t\t\tWith a bit of fiddling by hand I was able to improve the factorizations for N=182,200,207, so now (ii) is confirmed up to 100,000.  You can find the factorizations here, here, and here.\n\n\t\t\t\tReply\n\n\t\t\t28 March, 2025 at 8:12 am\n\t\t\tAnonymous\n\n\t\t\t\t\t\tShould inequality (4) have t(N)/N on the left-hand side (as opposed to just t(N))?\n[Corrected, thanks â€“ T.]\n\n\t\t\t\tReply\n\n\t\t\t28 March, 2025 at 8:16 pm\n\t\t\tTerence Tao\n\n\t\t\t\t\t\tA back of the envelope calculation suggests that the upper bound in my paper, if made explicit, would verify the conjecture  for roughly .  (There are particular inefficiencies when  is slightly larger than a power of two, as it then becomes expensive to adopt strategies that save the powers of two for last.)  So some additional constructions will be needed to cover the medium range .\nA natural idea to improve both the numerics and the asymptotics is to mix and match powers of 2 and 3 in the endgame when these are the only primes left to assign, taking advantage of the incommensurability of  and  to get more accurate matches to a target threshold.  This does make the algorithms and analysis more complicated, though.\n\n\t\t\t\tReply\n\n\t\t\t29 March, 2025 at 6:34 am\n\t\t\tTerence Tao\n\n\t\t\t\t\t\tAfter running Andrewâ€™s code to verify  I noticed that the greedy algorithm exhausts the factors of 2 and 3 relatively early; by the time the algorithm reaches the prime 29, the factors of 2 and 3 are already gone and so one has to use primes 5 and higher to fill up the remaining factors.  This is likely the main source of inefficiency in the direct greedy algorithm.  Some sort of ad hoc modification of the greedy algorithm in which some preference is given to terms that avoid 2 and 3 may improve performance.  If one can get to a final stage where only powers of 2 and 3 remain, then it may also make sense to switch from a greedy method to a linear programming method: specifically, if one wants to distribute , one can locate the smallest  with , and the smallest  with , and express  as an integer linear combination of  and  (plus a negligible error which one may simply discard) to get a pretty good factorization.\n\n\t\t\t\tReply\n\n\t\t\t29 March, 2025 at 7:04 am\n\t\t\tTerence Tao\n\n\t\t\t\t\t\tCurrently, Andrewâ€™s code permits one to factor  for  into  factors greater than or equal to , so one has a surplus of  factors here.  I am hoping that this surplus can be increased somewhat through some tweaking of the greedy algorithm, which should allow one to cover more ranges for the conjecture .  I have in mind something like this:\n1.  First, apply the greedy algorithm to remove all primes larger than, say, .  These primes will be problematic no matter what algorithm one chooses (it is rare for their multiples to be very close to ) and so one may as well dispose of them as efficiently as possible immediately.\n2.  Now, take all the numbers between  and (say)  that are coprime to both  and , and remove them from the remaining portion of  (only if they are available, of course).  Iterate this greedily until no further such numbers can be removed.  One should now be left with mostly copies of  and  and only a small number of remaining primes to allocate (the point being that the numbers between  and  have a very similar distribution of prime factors to the numbers between  and , except at the large primes which we have just removed).\n3.  Use the greedy algorithm again to eliminate all primes larger than .  This should leave a large pool of copies of  and .\n4.  Use the linear programming method in the previous comment to group these copies of  and  into quantities  slightly larger than .\n5.  Apply the greedy algorithm to clean up any leftovers.\nUnfortunately I will not have time today to try to implement such a scheme, but perhaps other commenters could try this (or some other method) to improve upon the previous surplus of 372, which I think is a reasonable proxy for algorithmic efficiency.  Note for this value of  that , which provides a hard upper limit for the surplus (and due to the large primes which canâ€™t be multiplied to be close to , the hard limit is actually a little less than this).  Still, there is room for improvement beyond 372.\nEDIT: by taking into account the amount by which all large primes will go over  (see Lemma 2.1 of the paper; the gap between the LHS and RHS of (2.1), divided by , upper bounds the surplus), I now revise the theoretical upper limit for the surplus to just 454.  So not as much room for improvement as I thoughtâ€¦ the greedy algorithm is actually quite efficient!  This also suggests that if the greedy algorithm fails significantly at some  slightly larger than 300000, then the Guy-Selfridge conjecture may in fact be false.\n\n\t\t\t\tReply\n\n\t\t\t29 March, 2025 at 5:25 pm\n\t\t\tTerence Tao\n\n\t\t\t\t\t\tI was able to get the surplus in the  verification up to 410 (here is the list of factors) by an extremely ad hoc method; I had attempted to coax the greedy algorithm to set aside some powers of 2 and 3 for later use, which helped somewhat (I could improve 372 to 401 this way), but then by accidentally putting in some rather bad choices of parameters (which used up the powers of 2 and 3 prematurely), I mysteriously got an improvement to 410.  It seems there are a lot of discontinuities in this problem; I am not sure how to systematize the search for better constructions.\n\n\t\t\t\tReply\n\n\t\t\t29 March, 2025 at 1:54 am\n\t\t\tAnonymous\n\n\t\t\t\t\t\t@Ivan Or even better; use num from the siunitx package (or qty for physical quantities) when typing numbers with more than four digits on either side of the decimal marker.\n\n\t\t\t\tReply\n\n\t\t\t29 March, 2025 at 2:45 am\n\t\t\tAnonymous\n\n\t\t\t\t\t\tIâ€™ve only been experimenting with small factorials, but fractional improvements can be made by optimising the factorisation process.\n\n\t\t\t\tReply\n\n\t\tLeave a comment Cancel reply\n\n\t\t\tÎ”document.getElementById( \"ak_js_1\" ).setAttribute( \"value\", ( new Date() ).getTime() );",
    "summary": {
      "en": "Terence Tao recently published a paper titled \"Decomposing a Factorial into Large Factors,\" which explores how to break down a factorial number into a specified number of factors, each at least a certain size. This concept was introduced by mathematician Paul ErdÃ¶s, who sought to understand the best way to evenly distribute a factorial into several parts.\n\nKey points from the paper include:\n\n1. **Definition of the Quantity**: Tao defines a quantity related to factorials, which indicates the largest number of factors into which a factorial can be divided, with each factor meeting a minimum size requirement.\n\n2. **Previous Work**: ErdÃ¶s and others previously estimated upper and lower bounds for this quantity. There was a claim that the upper bound was asymptotically accurate, but their proof was lost after a collaborator passed away.\n\n3. **Conjectures**: Tao discusses conjectures made by other mathematicians about the properties of this quantity, suggesting potential relationships and patterns that could be explored.\n\n4. **Methodology**: Tao describes his approach to establishing bounds for this quantity. He uses prime numbers effectively and proposes a method of factor rearrangement that could lead to better approximations.\n\n5. **Future Directions**: The paper hints at the possibility of crowd-sourcing computational efforts to verify certain conjectures and improve factorization methods, indicating that this area of study remains active and open to further exploration.\n\nOverall, Tao's work seeks to deepen the understanding of how factorials can be decomposed while addressing unresolved questions from previous studies in this mathematical field.",
      "ko": "í…Œë ŒìŠ¤ íƒ€ì˜¤ê°€ ìµœê·¼ ë°œí‘œí•œ ë…¼ë¬¸ \"íŒ©í† ë¦¬ì–¼ì„ í° ì¸ìˆ˜ë¡œ ë¶„í•´í•˜ê¸°\"ì—ì„œëŠ” íŒ©í† ë¦¬ì–¼ ìˆ«ìë¥¼ íŠ¹ì •í•œ ìˆ˜ì˜ ì¸ìˆ˜ë¡œ ë‚˜ëˆ„ëŠ” ë°©ë²•ì„ íƒêµ¬í•˜ê³  ìˆìŠµë‹ˆë‹¤. ê° ì¸ìˆ˜ëŠ” ìµœì†Œí•œì˜ í¬ê¸° ìš”ê±´ì„ ì¶©ì¡±í•´ì•¼ í•©ë‹ˆë‹¤. ì´ ê°œë…ì€ ìˆ˜í•™ì í´ ì—ë¥´ë˜ì‹œê°€ ì²˜ìŒ ì œì•ˆí–ˆìœ¼ë©°, ê·¸ëŠ” íŒ©í† ë¦¬ì–¼ì„ ì—¬ëŸ¬ ë¶€ë¶„ìœ¼ë¡œ ê³ ë¥´ê²Œ ë‚˜ëˆ„ëŠ” ìµœì„ ì˜ ë°©ë²•ì„ ì´í•´í•˜ê³ ì í–ˆìŠµë‹ˆë‹¤.\n\në…¼ë¬¸ì˜ ì£¼ìš” ë‚´ìš©ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. ì²«ì§¸, íƒ€ì˜¤ëŠ” íŒ©í† ë¦¬ì–¼ê³¼ ê´€ë ¨ëœ ì–‘ì„ ì •ì˜í•˜ë©°, ì´ëŠ” íŒ©í† ë¦¬ì–¼ì„ ë‚˜ëˆŒ ìˆ˜ ìˆëŠ” ìµœëŒ€ ì¸ìˆ˜ì˜ ìˆ˜ë¥¼ ë‚˜íƒ€ë‚´ê³ , ê° ì¸ìˆ˜ëŠ” ìµœì†Œ í¬ê¸° ìš”ê±´ì„ ì¶©ì¡±í•´ì•¼ í•©ë‹ˆë‹¤. ë‘˜ì§¸, ì—ë¥´ë˜ì‹œì™€ ë‹¤ë¥¸ ì—°êµ¬ìë“¤ì€ ì´ ì–‘ì˜ ìƒí•œê³¼ í•˜í•œì„ ì¶”ì •í•œ ë°” ìˆìŠµë‹ˆë‹¤. ìƒí•œì´ ì ê·¼ì ìœ¼ë¡œ ì •í™•í•˜ë‹¤ëŠ” ì£¼ì¥ì´ ìˆì—ˆìœ¼ë‚˜, ê·¸ë“¤ì˜ ì¦ëª…ì€ í˜‘ë ¥ìê°€ ì‚¬ë§í•œ í›„ ìƒì–´ë²„ë ¸ìŠµë‹ˆë‹¤.\n\nì…‹ì§¸, íƒ€ì˜¤ëŠ” ë‹¤ë¥¸ ìˆ˜í•™ìë“¤ì´ ì œê¸°í•œ ì´ ì–‘ì˜ ì„±ì§ˆì— ëŒ€í•œ ì¶”ì¸¡ì„ ë…¼ì˜í•˜ë©°, íƒêµ¬í•  ìˆ˜ ìˆëŠ” ì ì¬ì ì¸ ê´€ê³„ì™€ íŒ¨í„´ì„ ì œì•ˆí•©ë‹ˆë‹¤. ë„·ì§¸, íƒ€ì˜¤ëŠ” ì´ ì–‘ì˜ ê²½ê³„ë¥¼ ì„¤ì •í•˜ê¸° ìœ„í•œ ìì‹ ì˜ ì ‘ê·¼ ë°©ì‹ì„ ì„¤ëª…í•˜ë©°, ì†Œìˆ˜ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í™œìš©í•˜ê³  ì¸ìˆ˜ ì¬ë°°ì—´ ë°©ë²•ì„ ì œì•ˆí•˜ì—¬ ë” ë‚˜ì€ ê·¼ì‚¬ë¥¼ ì´ëŒì–´ë‚¼ ìˆ˜ ìˆëŠ” ê°€ëŠ¥ì„±ì„ ì œì‹œí•©ë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ, ë…¼ë¬¸ì€ íŠ¹ì • ì¶”ì¸¡ì„ ê²€ì¦í•˜ê³  ì¸ìˆ˜ ë¶„í•´ ë°©ë²•ì„ ê°œì„ í•˜ê¸° ìœ„í•´ ì»´í“¨í„° ê³„ì‚° ì‘ì—…ì„ ê³µë™ìœ¼ë¡œ ìˆ˜í–‰í•  ê°€ëŠ¥ì„±ì„ ì•”ì‹œí•˜ë©°, ì´ ì—°êµ¬ ë¶„ì•¼ê°€ ì—¬ì „íˆ í™œë°œí•˜ê³  ì¶”ê°€ íƒêµ¬ê°€ ê°€ëŠ¥í•¨ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\n\nì „ë°˜ì ìœ¼ë¡œ íƒ€ì˜¤ì˜ ì—°êµ¬ëŠ” íŒ©í† ë¦¬ì–¼ì´ ì–´ë–»ê²Œ ë¶„í•´ë  ìˆ˜ ìˆëŠ”ì§€ë¥¼ ê¹Šì´ ì´í•´í•˜ê³ , ì´ ìˆ˜í•™ ë¶„ì•¼ì—ì„œ ì´ì „ ì—°êµ¬ì—ì„œ í•´ê²°ë˜ì§€ ì•Šì€ ì§ˆë¬¸ë“¤ì„ ë‹¤ë£¨ê³ ì í•©ë‹ˆë‹¤.",
      "ja": "ãƒ†ãƒ¬ãƒ³ã‚¹ãƒ»ã‚¿ã‚ªã¯æœ€è¿‘ã€ã€Œå¤§ããªå› å­ã¸ã®éšä¹—ã®åˆ†è§£ã€ã¨ã„ã†ã‚¿ã‚¤ãƒˆãƒ«ã®è«–æ–‡ã‚’ç™ºè¡¨ã—ã¾ã—ãŸã€‚ã“ã®è«–æ–‡ã§ã¯ã€éšä¹—ã®æ•°ã‚’æŒ‡å®šã•ã‚ŒãŸæ•°ã®å› å­ã«åˆ†è§£ã™ã‚‹æ–¹æ³•ã«ã¤ã„ã¦æ¢æ±‚ã—ã¦ã„ã¾ã™ã€‚å„å› å­ã¯ä¸€å®šã®å¤§ãã•ä»¥ä¸Šã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ã“ã®æ¦‚å¿µã¯æ•°å­¦è€…ãƒãƒ¼ãƒ«ãƒ»ã‚¨ãƒ«ãƒ‡ã‚·ãƒ¥ã«ã‚ˆã£ã¦æå”±ã•ã‚Œã€éšä¹—ã‚’ã„ãã¤ã‹ã®éƒ¨åˆ†ã«å‡ç­‰ã«åˆ†é…ã™ã‚‹æœ€è‰¯ã®æ–¹æ³•ã‚’ç†è§£ã—ã‚ˆã†ã¨ã—ãŸã‚‚ã®ã§ã™ã€‚\n\nè«–æ–‡ã®é‡è¦ãªãƒã‚¤ãƒ³ãƒˆã«ã¯ä»¥ä¸‹ã®ã‚‚ã®ãŒã‚ã‚Šã¾ã™ã€‚ã¾ãšã€ã‚¿ã‚ªã¯éšä¹—ã«é–¢é€£ã™ã‚‹é‡ã‚’å®šç¾©ã—ã¦ã„ã¾ã™ã€‚ã“ã®é‡ã¯ã€éšä¹—ã‚’åˆ†å‰²ã§ãã‚‹æœ€å¤§ã®å› å­ã®æ•°ã‚’ç¤ºã—ã€å„å› å­ã¯æœ€å°ã®å¤§ãã•ã®è¦ä»¶ã‚’æº€ãŸã™å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚\n\næ¬¡ã«ã€ã‚¨ãƒ«ãƒ‡ã‚·ãƒ¥ã‚„ä»–ã®ç ”ç©¶è€…ãŸã¡ã¯ã€ã“ã®é‡ã®ä¸Šé™ã¨ä¸‹é™ã‚’ä»¥å‰ã«æ¨å®šã—ã¦ã„ã¾ã—ãŸã€‚ä¸Šé™ãŒæ¼¸è¿‘çš„ã«æ­£ç¢ºã§ã‚ã‚‹ã¨ã„ã†ä¸»å¼µãŒã‚ã‚Šã¾ã—ãŸãŒã€ãã®è¨¼æ˜ã¯å…±åŒç ”ç©¶è€…ã®æ­»å¾Œã«å¤±ã‚ã‚Œã¦ã—ã¾ã„ã¾ã—ãŸã€‚\n\nã¾ãŸã€ã‚¿ã‚ªã¯ä»–ã®æ•°å­¦è€…ã«ã‚ˆã‚‹ã“ã®é‡ã®ç‰¹æ€§ã«é–¢ã™ã‚‹äºˆæƒ³ã«ã¤ã„ã¦ã‚‚è¨€åŠã—ã€æ¢æ±‚å¯èƒ½ãªé–¢ä¿‚ã‚„ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç¤ºå”†ã—ã¦ã„ã¾ã™ã€‚ã‚¿ã‚ªã¯ã“ã®é‡ã®å¢ƒç•Œã‚’ç¢ºç«‹ã™ã‚‹ãŸã‚ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’èª¬æ˜ã—ã¦ãŠã‚Šã€ç´ æ•°ã‚’åŠ¹æœçš„ã«åˆ©ç”¨ã—ã€å› å­ã®å†é…ç½®ã®æ–¹æ³•ã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ã‚ˆã‚Šè‰¯ã„è¿‘ä¼¼ãŒå¾—ã‚‰ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\n\nã•ã‚‰ã«ã€è«–æ–‡ã¯ç‰¹å®šã®äºˆæƒ³ã‚’æ¤œè¨¼ã—ã€å› æ•°åˆ†è§£ã®æ–¹æ³•ã‚’æ”¹å–„ã™ã‚‹ãŸã‚ã«è¨ˆç®—ä½œæ¥­ã‚’ã‚¯ãƒ©ã‚¦ãƒ‰ã‚½ãƒ¼ã‚·ãƒ³ã‚°ã™ã‚‹å¯èƒ½æ€§ã«ã¤ã„ã¦ã‚‚è§¦ã‚Œã¦ã„ã¾ã™ã€‚ã“ã®åˆ†é‡ã®ç ”ç©¶ã¯æ´»ç™ºã§ã‚ã‚Šã€ã•ã‚‰ãªã‚‹æ¢æ±‚ãŒæœŸå¾…ã•ã‚Œã¦ã„ã¾ã™ã€‚\n\nå…¨ä½“ã¨ã—ã¦ã€ã‚¿ã‚ªã®ç ”ç©¶ã¯éšä¹—ã®åˆ†è§£ã«é–¢ã™ã‚‹ç†è§£ã‚’æ·±ã‚ã€ä»¥å‰ã®ç ”ç©¶ã§æœªè§£æ±ºã®å•é¡Œã«å–ã‚Šçµ„ã‚€ã“ã¨ã‚’ç›®æŒ‡ã—ã¦ã„ã¾ã™ã€‚"
    }
  },
  {
    "id": "7265932f6ff4bdeb",
    "title": {
      "en": "Optimizing Matrix Multiplication on RDNA3",
      "ko": "RDNA3 í–‰ë ¬ ê³±ì…ˆ ìµœì í™”",
      "ja": "RDNA3è¡Œåˆ—è¨ˆç®—æœ€é©åŒ–"
    },
    "type": "story",
    "url": "https://seb-v.github.io/optimization/update/2025/01/20/Fast-GPU-Matrix-multiplication.html",
    "score": 115,
    "by": "skidrow",
    "time": 1742896521,
    "content": "Introduction\n\nHi everyone !\n\nIn this post, I will share with you all the steps to write an optimized FP32 matrix multiplication on AMD RDNA3 GPU outperforming rocBLAS by 60%. I will cover some basics and explain all the optimizations I have implemented. This will be done in a iterative way in 8 differents Kernels.\n\n  Figure 1: sneak peek of the performance results\n\nI primary intended to work on this to deepen my understanding of RDNA3 and try out HIP and I felt like I needed to share what I learned doing this :).\n\nFew things I like to say before we start :\n\n  All the information I used comes from the publicly available ISA guide1\n  I donâ€™t intend to re-implement or replace rocBLAS\n  I only focused on 4096x4096 matrices single precision (FP32) matrix multiplication for the sake of simplicity.\n  All my tests were done on Windows 11 with a AMD Radeon 7900 XTX.\n\nThat being said, letâ€™s start !\n\nProblem statement\n\nThere is a lot of research happening on the way to improve the performance of matrix multiplication nowadays. Being a core algorithm in ML applications, any FLOPS we can exploit is golden.\n\nBefore proceeding, letâ€™s recall the basics of matrix multiplication. Given two matrices:\n\n  A of size M,K\n  B of size K,N\n\nTheir product, C, is computed as follows:\n\nCij=âˆ‘k=0Kâˆ’1Aikâ‹…Bkj\n\niâˆˆ[0,Mâˆ’1]\njâˆˆ[0,Nâˆ’1]\n\nwhere C is the resulting matrix of size M,N.\n\nFor each output value of matrix C, we compute the dot product between the rows of matrix A and the columns of matrix B.\n\n  Figure 2: example for the first element of C\n\nIn terms of complexity, we have O(n3) computational complexity and O(n2) memory accesses.\nIf we donâ€™t think about architectural details, this is clearly a compute bound problem and our goal will be to be compute bound on the GPU.\n\nLetâ€™s say we manage to write the best implementation possible for the 7900 XTX. How fast could it run ? To answer this questions we need to look a bit at RDNA3 architecture.\n\nRDNA3 GPUs are made of arrays of WorkGroup Processors (WGP). Every WGP are split into 2 Compute Units (CUs), themself split into 2 SIMDs. A SIMD handles the work of multiple threads organized in waves (or warps for CUDA folks) and has a set of components to do some work (like arithmetic operations). For Floating point operations, there are two 32 way VALU units.\n\n  Figure 3: simplified representation of WGPs\n\n  Figure 4: simplified representation of a single SIMD\n\nWe can compute our theoritical floating point operation per second with this formula:\n\nFLOPS=freqâˆ—nbSIMDâˆ—flopsPerSIMD\n\nEvery SIMD can issue 2 Floating points intructions per cycle (one on each vALU unit). If we use FMA instructions (Fused Multiply Add), each SIMD can issue 32âˆ—2âˆ—2=128 floating point operations per cycle.\nThe 7900 XTX has 48 WGPs, thatâ€™s 48âˆ—2âˆ—2=192 SIMDs.\n\nFLOPS=2500âˆ—106âˆ—192âˆ—128FLOP/s\n\nFLOPS=61.44TFLOP/s\n\nOur theoritical VRAM bandwidth is given by :\n\nBW=rateâˆ—busWidth/8\n\nThe 7900 XTX uses GDDR6 with a 384-bit bus running at 20 Gbps.\n\nBW=20âˆ—384/8=960GB/s\n\nIf we go back to our 4096x4096 matrix multiplication, we essentially need to do 2âˆ—4096âˆ—4096âˆ—4096 operations.\nWith a 61 TFLops implementation, it would take roughly 2.23 ms to do the work and the bandwidth required to sustain this rate would be 4096âˆ—4096âˆ—4âˆ—3/2.23âˆ—10âˆ’3=90.2GB/s.\n\nOf course, these are oversimplified calculations as they totally ignore memory hierarchy but we see that the available bandwidth is sufficiently high so that we can increase the amount of data we read to be closer to compute bound.\n\nKernel 1: naive implementation\n\nLetâ€™s start with a naive implementation like this :\n\n__global__ void kernel1_naive(const float *A, const float *B, float *C, int M, int K, int N, float alpha, float beta)\n{\n    int row = blockIdx.y * blockDim.y + threadIdx.y;\n    int col = blockIdx.x * blockDim.x + threadIdx.x;\n    if (row < M && col < N)\n    {\n        float acc_c = 0.0f;\n        for (int k = 0; k < K; ++k)\n        {\n            acc_c += A[row * K + k] * B[k * N + col];\n        }\n        C[row * N + col] = alpha * acc_c + beta * C[row * N + col];\n    }\n}\n\nYou will notice I am doing  C=alphaâˆ—Aâˆ—B+betaâˆ—C instead of C=Aâˆ—B here. This is because it makes easier to compare with libraries like rocBLAS where matrix multiplications is provided by SGEMM functions (Single-Precision General Matrix Multiply).\n\nWe launch 4096x4096 threads with a blocksize of 16x16 and each thread compute the inner dot product described before.\n\nThe performance for this kernel is 136 ms (1010.60 GFlops/s). I know, thatâ€™s pretty bad and far off our 61 TFLops target.\n\nKernel 0: rocBLAS reference implementation\n\nNow that we have seen possibly the worst implementation in terms of performance, letâ€™s look at the official rocBLAS implementation.\n\n    const int M = N;\n    const int K = N;\n    CHECK_ROCBLAS_STATUS(rocblas_sgemm(\n        handle,\n        rocblas_operation_none, // Transpose option for A\n        rocblas_operation_none, // Transpose option for B\n        M,                      // Number of rows in A and C\n        N,                      // Number of columns in B and C\n        K,                      // Number of columns in A and rows in B\n        &alpha,                 // alpha\n        d_a,                    // Matrix A on the device\n        M,                      // Leading dimension of A\n        d_b,                    // Matrix B on the device\n        K,                      // Leading dimension of B\n        &beta,                  // beta\n        d_c,                    // Matrix C on the device\n        M                       // Leading dimension of C\n        ));\n\nAs discussed before, I used rocblas_sgemm function with alpha and beta set to 1.02\n\nThe performance for this kernel is 4.49 ms (30547 GFLOPs/s). This is clearly much better than our kernel 1 but still far from our theoritical 61.4 TFlops/s.\n\nBy inspecting the ISA in RGP3, I couldnâ€™t find any dual issue instructions in the kernel (only v_fmac_f32_e32)4\n\n  Figure 5: extract of rocBLAS ISA code\n\nThis is very surprising as this essentially means one of the VALU unit is sitting there doing nothing.\n\nConsidering this, the VALU utilization of this kernel is pretty impressive and almost 100 %. However, itâ€™s really surprising we canâ€™t exploit these dual issue instructions properly. Iâ€™ll come to that later.\n\nKernel 2: LDS Tiling\n\nThe main issue with our naive kernel is that our inner loop directly accesses global memory. This is inefficient because fetching data from global memory has a high latency, typically on the order of hundreds of cycles. Since each memory read is followed by minimal computation (just one multiplication and one addition), the GPU struggles to hide this latency, even with a large number of concurrent threads. Moreover, the algorithm repeatedly reads the same rows and columns from global memory across different threads, leading to redundant memory accesses and further exacerbating the performance bottleneck.\n\nA solution to this problem is to load the data once into faster local memory and then iterate efficiently over it with all the threads. On RDNA3, we have the Local Data Store (LDS), a high-speed, low-latency memory accessible by all threads within a workgroup.\n\n  Figure 6: simplified representation of the memory hierarchy\n\nSince the LDS has a much smaller capacity than global memory, we need to use tiling to divide our problem into smaller sub-matrix multiplications. One way to facilitate this is to restructure the computation by moving the inner loopâ€™s dot product to the outer loop. The key idea is to cache a column of matrix A and a row of matrix B, then perform the computation across the entire tile. This approach is more cache-efficient and significantly reduces memory access latency.\n\nThe pseudo code for our kernel 1 is :\n\nfor i from 0 to M - 1:                  # Loop over rows of A\n    for j from 0 to N - 1:              # Loop over columns of B\n        sum = 0\n        for k from 0 to K - 1:          # Loop over columns of A / rows of B\n            sum += A[i][k] * B[k][j]\n        end for\n        C[i][j] = sum\n    end for\nend for\n\nIf we move the dot product to the outer loop, we have this :\n\nfor k from 0 to K - 1:                  # Outer loop over the shared dimension\n    for i from 0 to M - 1:              # Loop over rows of A\n        for j from 0 to N - 1:          # Loop over columns of B\n            C[i][j] += A[i][k] * B[k][j]\n        end for\n    end for\nend for\n\nTiling in this form is straightforward: each workgroup operates on a tile and follows these steps: (BK is the batch size, ie number of rows/columns we load to the LDS)\n\nInit c to 0\nWhile kId is less than N:\n  # Load A and B to Tile As and Bs\n  Load BK columns A to As\n  Load BK rows to Bs\n  Syncthreads\n  # Accumulate results using LDS\n  for k from 0 to BK\n    c += As[threadIdx.y][k] * Bs[k][threadIdx.x]\n  Syncthreads\n  Increment kId by BK\nend for\nc[row][col]=c\n\nIf we choose a tile size of 32x32 and BK=32, our new kernel looks like this:\n\n#define TILE_SIZE 32\n__global__ void kernel2_lds(const float *A, const float *B, float *C, int N)\n{\n    __shared__ float As[TILE_SIZE][TILE_SIZE];\n    __shared__ float Bs[TILE_SIZE][TILE_SIZE];\n\n    int row = blockIdx.y * TILE_SIZE + threadIdx.y;\n    int col = blockIdx.x * TILE_SIZE + threadIdx.x;\n\n    float sum = 0.0f;\n\n    for (int t = 0; t < N; t += TILE_SIZE)\n    {\n        Bs[threadIdx.y][threadIdx.x] = B[N * (threadIdx.y + t) + col];\n        As[threadIdx.y][threadIdx.x] = A[N * row + t + threadIdx.x];\n\n        __syncthreads();\n\n        for (int k = 0; k < TILE_SIZE; k++)\n        {\n            sum += As[threadIdx.y][k] * Bs[k][threadIdx.x];\n        }\n\n        __syncthreads();\n    }\n\n    if (row < N && col < N)\n    {\n        C[row * N + col] = sum;\n    }\n}\n\n__syncthreads(); is required here to ensure that all threads in the workgroup can see the data loaded into the LDS and to synchronize before any updates are made to the data.\n\nWe also ensure that the contents of both matrices A and B are loaded into the LDS by rows rather than columns to avoid uncoalesced memory accesses.\nIndeed, if we were to read by columns, each thread in a wave would access a non-contiguous memory region, result",
    "summary": {
      "en": "**Summary:**\n\nIn this post, the author explains how to optimize FP32 matrix multiplication on an AMD RDNA3 GPU, aiming to improve performance by 60% over the rocBLAS library. The focus is on 4096x4096 matrices and is based on research into matrix multiplication, a key algorithm in machine learning.\n\n**Key Points:**\n\n1. **Matrix Multiplication Basics:** The post outlines how to compute the product of two matrices using the dot product, which involves considerable computations (O(nÂ³) complexity).\n\n2. **RDNA3 Architecture:** The GPU architecture is described, highlighting its components like WorkGroup Processors (WGP), Compute Units (CUs), and SIMD units, which are essential for optimizing performance.\n\n3. **Performance Calculations:** The theoretical performance of the AMD Radeon 7900 XTX GPU is calculated, suggesting it can achieve 61.44 TFLOPS with sufficient memory bandwidth (960 GB/s).\n\n4. **Naive Implementation:** A basic kernel for matrix multiplication is presented, achieving only 1010.60 GFLOPS/s, which is far from the theoretical maximum.\n\n5. **rocBLAS Comparison:** The performance of the rocBLAS library's implementation is also discussed, showing it performs better but still underutilizes the GPU's potential.\n\n6. **Optimization Strategy:** The author introduces the concept of using Local Data Store (LDS) for faster memory access in the GPU. This involves tiling the matrix multiplication to reduce latency and improve cache efficiency.\n\n7. **Improved Kernel Implementation:** The post outlines a more efficient kernel that uses tiling and LDS, demonstrating how to load data into faster memory and perform calculations more effectively.\n\nOverall, the author aims to share insights gained from this optimization process, hoping to enhance understanding of GPU programming and matrix multiplication efficiency.",
      "ko": "ì´ ê¸€ì—ì„œëŠ” AMD RDNA3 GPUì—ì„œ FP32 í–‰ë ¬ ê³±ì…ˆì„ ìµœì í™”í•˜ëŠ” ë°©ë²•ì„ ì„¤ëª…í•˜ë©°, rocBLAS ë¼ì´ë¸ŒëŸ¬ë¦¬ë³´ë‹¤ ì„±ëŠ¥ì„ 60% í–¥ìƒì‹œí‚¤ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì£¼ë¡œ 4096x4096 í¬ê¸°ì˜ í–‰ë ¬ì— ì´ˆì ì„ ë§ì¶”ê³  ìˆìœ¼ë©°, ì´ëŠ” ê¸°ê³„ í•™ìŠµì—ì„œ ì¤‘ìš”í•œ ì•Œê³ ë¦¬ì¦˜ì¸ í–‰ë ¬ ê³±ì…ˆì— ëŒ€í•œ ì—°êµ¬ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n\ní–‰ë ¬ ê³±ì…ˆì˜ ê¸°ë³¸ ê°œë…ì„ ì„¤ëª…í•˜ë©°, ë‘ í–‰ë ¬ì˜ ê³±ì„ ê³„ì‚°í•˜ëŠ” ë°©ë²•ì„ ë‹¤ë£¹ë‹ˆë‹¤. ì´ ê³¼ì •ì€ ìƒë‹¹í•œ ê³„ì‚°ëŸ‰ì„ ìš”êµ¬í•˜ë©°, ë³µì¡ë„ëŠ” O(nÂ³)ì…ë‹ˆë‹¤. RDNA3 ì•„í‚¤í…ì²˜ì— ëŒ€í•´ ì„¤ëª…í•˜ë©´ì„œ, ì„±ëŠ¥ ìµœì í™”ì— í•„ìˆ˜ì ì¸ êµ¬ì„± ìš”ì†Œì¸ ì‘ì—… ê·¸ë£¹ í”„ë¡œì„¸ì„œ(WGP), ì»´í“¨íŠ¸ ìœ ë‹›(CU), SIMD ìœ ë‹› ë“±ì„ ê°•ì¡°í•©ë‹ˆë‹¤.\n\nAMD Radeon 7900 XTX GPUì˜ ì´ë¡ ì  ì„±ëŠ¥ì„ ê³„ì‚°í•œ ê²°ê³¼, ì¶©ë¶„í•œ ë©”ëª¨ë¦¬ ëŒ€ì—­í­(960 GB/s)ì„ ê°–ì¶”ë©´ 61.44 TFLOPSì— ë„ë‹¬í•  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ê¸°ë³¸ì ì¸ í–‰ë ¬ ê³±ì…ˆ ì»¤ë„ì„ ì œì‹œí•˜ë©°, ì´ ì»¤ë„ì€ 1010.60 GFLOPS/sì˜ ì„±ëŠ¥ì„ ë‚´ì§€ë§Œ ì´ë¡ ì  ìµœëŒ€ì¹˜ì—ëŠ” ë¯¸ì¹˜ì§€ ëª»í•©ë‹ˆë‹¤. rocBLAS ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ êµ¬í˜„ ì„±ëŠ¥ë„ ë¹„êµí•˜ë©°, ë” ë‚˜ì€ ì„±ëŠ¥ì„ ë³´ì´ì§€ë§Œ ì—¬ì „íˆ GPUì˜ ì ì¬ë ¥ì„ ì¶©ë¶„íˆ í™œìš©í•˜ì§€ ëª»í•˜ê³  ìˆìŒì„ ì§€ì í•©ë‹ˆë‹¤.\n\nì €ìëŠ” GPUì—ì„œ ë” ë¹ ë¥¸ ë©”ëª¨ë¦¬ ì ‘ê·¼ì„ ìœ„í•´ ë¡œì»¬ ë°ì´í„° ì €ì¥ì†Œ(LDS)ë¥¼ ì‚¬ìš©í•˜ëŠ” ìµœì í™” ì „ëµì„ ì†Œê°œí•©ë‹ˆë‹¤. ì´ëŠ” í–‰ë ¬ ê³±ì…ˆì„ íƒ€ì¼ë§í•˜ì—¬ ì§€ì—° ì‹œê°„ì„ ì¤„ì´ê³  ìºì‹œ íš¨ìœ¨ì„±ì„ ë†’ì´ëŠ” ë°©ë²•ì…ë‹ˆë‹¤. ê°œì„ ëœ ì»¤ë„ êµ¬í˜„ì„ ì„¤ëª…í•˜ë©°, íƒ€ì¼ë§ê³¼ LDSë¥¼ í™œìš©í•´ ë°ì´í„°ë¥¼ ë” ë¹ ë¥¸ ë©”ëª¨ë¦¬ì— ë¡œë“œí•˜ê³  ê³„ì‚°ì„ ë³´ë‹¤ íš¨ê³¼ì ìœ¼ë¡œ ìˆ˜í–‰í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.\n\nì´ ìµœì í™” ê³¼ì •ì„ í†µí•´ ì–»ì€ í†µì°°ì„ ê³µìœ í•˜ë©°, GPU í”„ë¡œê·¸ë˜ë°ê³¼ í–‰ë ¬ ê³±ì…ˆì˜ íš¨ìœ¨ì„±ì— ëŒ€í•œ ì´í•´ë¥¼ ë†’ì´ê³ ì í•©ë‹ˆë‹¤.",
      "ja": "ã“ã®æŠ•ç¨¿ã§ã¯ã€è‘—è€…ãŒAMD RDNA3 GPUä¸Šã§FP32è¡Œåˆ—ä¹—ç®—ã‚’æœ€é©åŒ–ã™ã‚‹æ–¹æ³•ã‚’èª¬æ˜ã—ã¦ã„ã¾ã™ã€‚rocBLASãƒ©ã‚¤ãƒ–ãƒ©ãƒªã«å¯¾ã—ã¦60%ã®æ€§èƒ½å‘ä¸Šã‚’ç›®æŒ‡ã—ã¦ã„ã¾ã™ã€‚ç‰¹ã«4096x4096ã®è¡Œåˆ—ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ãŠã‚Šã€ã“ã‚Œã¯æ©Ÿæ¢°å­¦ç¿’ã«ãŠã‘ã‚‹é‡è¦ãªã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§ã‚ã‚‹è¡Œåˆ—ä¹—ç®—ã«é–¢ã™ã‚‹ç ”ç©¶ã«åŸºã¥ã„ã¦ã„ã¾ã™ã€‚\n\nè¡Œåˆ—ä¹—ç®—ã®åŸºæœ¬ã«ã¤ã„ã¦ã€äºŒã¤ã®è¡Œåˆ—ã®ç©ã‚’ãƒ‰ãƒƒãƒˆç©ã‚’ç”¨ã„ã¦è¨ˆç®—ã™ã‚‹æ–¹æ³•ãŒèª¬æ˜ã•ã‚Œã¦ã„ã¾ã™ã€‚ã“ã®è¨ˆç®—ã«ã¯ã‹ãªã‚Šã®è¨ˆç®—é‡ãŒå¿…è¦ã§ã€è¨ˆç®—ã®è¤‡é›‘ã•ã¯O(nÂ³)ã§ã™ã€‚\n\nRDNA3ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«ã¤ã„ã¦ã‚‚è©³ã—ãèª¬æ˜ã•ã‚Œã¦ãŠã‚Šã€æ€§èƒ½æœ€é©åŒ–ã«ä¸å¯æ¬ ãªãƒ¯ãƒ¼ã‚¯ã‚°ãƒ«ãƒ¼ãƒ—ãƒ—ãƒ­ã‚»ãƒƒã‚µï¼ˆWGPï¼‰ã€è¨ˆç®—ãƒ¦ãƒ‹ãƒƒãƒˆï¼ˆCUï¼‰ã€SIMDãƒ¦ãƒ‹ãƒƒãƒˆãªã©ã®æ§‹æˆè¦ç´ ãŒå¼·èª¿ã•ã‚Œã¦ã„ã¾ã™ã€‚\n\nAMD Radeon 7900 XTX GPUã®ç†è«–çš„ãªæ€§èƒ½ã‚‚è¨ˆç®—ã•ã‚Œã¦ãŠã‚Šã€ååˆ†ãªãƒ¡ãƒ¢ãƒªå¸¯åŸŸå¹…ï¼ˆ960 GB/sï¼‰ãŒã‚ã‚Œã°61.44 TFLOPSã‚’é”æˆã§ãã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚\n\nåŸºæœ¬çš„ãªè¡Œåˆ—ä¹—ç®—ã®ã‚«ãƒ¼ãƒãƒ«ã‚‚ç´¹ä»‹ã•ã‚Œã¦ãŠã‚Šã€ã“ã‚Œã§ã¯1010.60 GFLOPS/sã—ã‹é”æˆã§ããšã€ç†è«–çš„ãªæœ€å¤§å€¤ã«ã¯é ãåŠã³ã¾ã›ã‚“ã€‚\n\nrocBLASãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®å®Ÿè£…ã®æ€§èƒ½ã‚‚æ¯”è¼ƒã•ã‚Œã¦ãŠã‚Šã€rocBLASã¯ã‚ˆã‚Šè‰¯ã„æ€§èƒ½ã‚’ç™ºæ®ã—ã¾ã™ãŒã€ä¾ç„¶ã¨ã—ã¦GPUã®æ½œåœ¨èƒ½åŠ›ã‚’ååˆ†ã«æ´»ç”¨ã—ã¦ã„ãªã„ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚\n\nè‘—è€…ã¯ã€GPUå†…ã§ã®é«˜é€Ÿãƒ¡ãƒ¢ãƒªã‚¢ã‚¯ã‚»ã‚¹ã®ãŸã‚ã«ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢ï¼ˆLDSï¼‰ã‚’ä½¿ç”¨ã™ã‚‹ã¨ã„ã†æœ€é©åŒ–æˆ¦ç•¥ã‚’ç´¹ä»‹ã—ã¦ã„ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€è¡Œåˆ—ä¹—ç®—ã‚’ã‚¿ã‚¤ãƒ«çŠ¶ã«åˆ†å‰²ã—ã€ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã‚’æ¸›å°‘ã•ã›ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥åŠ¹ç‡ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒå¯èƒ½ã«ãªã‚Šã¾ã™ã€‚\n\nã•ã‚‰ã«ã€ã‚¿ã‚¤ãƒ«ã¨LDSã‚’åˆ©ç”¨ã—ãŸã‚ˆã‚ŠåŠ¹ç‡çš„ãªã‚«ãƒ¼ãƒãƒ«ã®å®Ÿè£…ãŒèª¬æ˜ã•ã‚Œã¦ãŠã‚Šã€ãƒ‡ãƒ¼ã‚¿ã‚’é«˜é€Ÿãƒ¡ãƒ¢ãƒªã«ãƒ­ãƒ¼ãƒ‰ã—ã€è¨ˆç®—ã‚’ã‚ˆã‚ŠåŠ¹æœçš„ã«è¡Œã†æ–¹æ³•ãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚\n\nè‘—è€…ã¯ã“ã®æœ€é©åŒ–ãƒ—ãƒ­ã‚»ã‚¹ã‹ã‚‰å¾—ã‚‰ã‚ŒãŸæ´å¯Ÿã‚’å…±æœ‰ã—ã€GPUãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã‚„è¡Œåˆ—ä¹—ç®—ã®åŠ¹ç‡ã«ã¤ã„ã¦ã®ç†è§£ã‚’æ·±ã‚ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¦ã„ã¾ã™ã€‚"
    }
  },
  {
    "id": "e10d9fa3796db987",
    "title": {
      "en": "Portlander creates AI-powered device to monitor street health",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://bikeportland.org/2025/03/18/portlander-creates-ai-powered-device-to-monitor-street-health-393363",
    "score": 16,
    "by": "burlesona",
    "time": 1742933718,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "4652de53cf75cf94",
    "title": {
      "en": "How to write blog posts that developers read",
      "ko": "ê°œë°œìê°€ ì½ëŠ” ë¸”ë¡œê·¸ ì“°ê¸°",
      "ja": "é–‹ç™ºè€…ãŒèª­ã‚€ãƒ–ãƒ­ã‚°è¡“"
    },
    "type": "story",
    "url": "https://refactoringenglish.com/chapters/write-blog-posts-developers-read/",
    "score": 548,
    "by": "rbanffy",
    "time": 1743159679,
    "content": "How to Write Blog Posts that Developers Readby Michael Lynch, published\nMarch 27, 2025if(window.location.pathname===\"/chapters/nine-years-of-blogging/\"){const e=\"What I Learned from Nine Years of Blogging\";document.title=e,document.querySelector(\"h1\").textContent=e}I recently spoke to a developer who tried blogging but gave up because nobody was reading his posts. I checked out his blog, and it was immediately obvious why he didnâ€™t have any readers.The developer had interesting insights, but he made so many mistakes in presenting his ideas that he was driving everyone away. The tragedy was that these errors were easy to fix. Once you learn to recognize them, they feel obvious, but some bloggers make these mistakes for years.I know because Iâ€™m one of them.Iâ€™ve been blogging about software development for nine years. My best posts have reached 300k+ readers, but many of them flopped, especially in my first few years.Over time, Iâ€™ve learned techniques that help some blog posts succeed and the pitfalls that cause others to languish in obscurity.Why listen to me?Get to the pointThink one degree biggerPlan the route to your readersShow more picturesAccommodate skimmersWhy listen to me?ğŸ”—Iâ€™m going to say a bunch of gloaty things to establish credibility, but it feels gross, so letâ€™s just get it out of the way:Iâ€™ve written a software blog for nine years, and it attracts 300k-500k unique readers per year.My posts have reached the front page of Hacker News over 30 times, many of them reaching the #1 spot.According to a ranking system I made up, I have the 48th most popular personal blog on Hacker News.I launched a successful indie business by writing a popular blog post about my product.My articles frequently appear on reddit and Lobsters.My software blog receives 300k-500k unique readers per year.I donâ€™t claim to be the worldâ€™s best software blogger, but Iâ€™ve had enough success and experience to share some useful lessons.Get to the pointğŸ”—The biggest mistake software bloggers make is meandering.Often, the author has some valuable insight to share, but they squander their first seven paragraphs on the history of functional programming and a trip they took to Bell Labs in 1973. By the time they get to the part thatâ€™s actually interesting, everyone has long since closed the browser tab.Internet attention spans are short. If you dawdle before making your point, the reader will seek out one of the literally billions of other articles they could be reading instead.So, how do you convince the reader to stay and continue reading your blog post?When the reader arrives, theyâ€™re trying to answer two questions as quickly as possible:Did the author write this article for someone like me?How will I benefit from reading it?Give yourself the title plus your first three sentences to answer both questions. If you find yourself in paragraph two and you havenâ€™t answered either question, youâ€™re in trouble.To show the reader youâ€™re writing for them, mention topics they care about, and use terminology they recognize. If you throw out jargon or unfamiliar concepts, the reader assumes the article isnâ€™t meant for them and clicks away.Your introduction should also make it clear to the reader how the article will benefit them. There are many possible benefits you can offer:A technique the reader can apply in their work or personal life.A clear explanation of a concept that impacts the readerâ€™s work or personal life.An insight that gives the reader a better understanding of a particular technology or industry.An interesting story that resonates with the reader.Example: â€œif got, want: A Simple Way to Write Better Go Testsâ€ğŸ”—I recently wrote an article about improving tests when using the Go programming language.Hereâ€™s the title and first paragraph:if got, want: A Simple Way to Write Better Go TestsThereâ€™s an excellent Go testing pattern that too few people know. I can teach it to you in 30 seconds.This article immediately answers the two questions:Did the author write the article for someone like me?The article is for Go developers.Whatâ€™s the benefit of reading it?Youâ€™ll learn a new testing technique in 30 seconds.Think one degree biggerğŸ”—When you write an article, you hopefully have a type of reader in mind. For example, if you wrote an article called â€œDebugging Memory Leaks in Java,â€ you probably assumed that the reader is an intermediate to advanced Java developer.Most software bloggers never think to ask, â€œIs there a wider audience for this topic?â€For example, â€œintermediate to advanced Java developersâ€ are a subset of â€œJava developers,â€ who are a subset of â€œprogrammers,â€ who are a subset of â€œpeople who read blog posts.â€If you wrote an article for intermediate and advanced Java developers, how much would have to change for the article to appeal to Java developers of any experience level?Often, the change is just an extra sentence or two early in the article to introduce a concept or replace jargon with more accessible terms.Jeff: Sony has a futuristic sci-fi movie theyâ€™re looking to make.Nick: Cigarettes in space?Jeff: Itâ€™s the final frontier, Nick.Nick: But wouldnâ€™t they blow up in an all-oxygen environment?Jeff: Probably. But itâ€™s an easy fix. One line of dialogue. â€œThank God we invented theâ€¦ you know, whatever device.â€Thank You for Smoking (2005)The set of all Java developers is about 10x larger than the set of intermediate and advanced Java developers. That means small tweaks can expand the reach of your article by an order of magnitude.Obviously, you canâ€™t broaden every article, and you canâ€™t keep broadening your audience forever. No matter how well you explain background concepts, your tax accountant will never read an article about memory leaks in Java. The point isnâ€™t to write articles that appeal to every possible reader but to notice opportunities to reach a larger audience.Example: â€œHow I Stole Your Siacoinâ€ğŸ”—One of my earliest successes in blogging was an article called â€œHow I Stole Your Siacoin.â€ It was about a time I stole a reddit userâ€™s cryptocurrency (for noble reasons, I promise).Initially, I thought the story would resonate with the few hundred people who followed a niche cryptocurrency called Siacoin. As I was editing the article, I realized that you didnâ€™t have to know anything about Siacoin to understand my story. I revised it slightly so it would make sense to cryptocurrency enthusiasts who had never heard of Siacoin.Then, I realized I could even explain this story to people who knew nothing about cryptocurrency. I adjusted the terminology to use regular-person terms like â€œwalletâ€ and â€œpassphraseâ€ and avoided crypto-specific terms like â€œblockchainâ€ or â€œMerkle tree.â€The article was my first ever hit. It became the most popular story of all time not only on the /r/siacoin subreddit but also on the larger /r/cryptocurrency subreddit. It reached the front page of Hacker News, even though readers there are generally hostile to cryptocurrency-focused stories.â€œHow I Stole Your Siacoinâ€ only needed a few tweaks to be enjoyable for people who didnâ€™t know anything about cryptocurrency.Plan the route to your readersğŸ”—Suppose you wrote the greatest beginnerâ€™s tutorial imaginable for the Python programming language. Both your five-year-old nephew and 80-year-old dentist blazed through it with ease and delight. Everyone who reads your tutorial goes on to become a Python core contributor.Bad news: nobody will ever read your Python tutorial.â€œLies!â€ you shout. â€œThousands of developers learn Python every year. Why wouldnâ€™t my objectively awesome tutorial become popular?â€Well, think it through. What happens after you hit publish? How does anyone find your article?Youâ€™re probably thinking: Google.Yes, your friend Google will index your tutorial and use its secret Google magic to identify your articleâ€™s superior quality. Before you know it, your tutorial will be the top result for python tutorial.Except that canâ€™t happen because there are so many Python tutorials out there already on sites that Google prefers over yours. Youâ€™ll never even make it to the first page of results.Itâ€™s nearly impossible for a new blog post to rank well in Google for the search term python tutorial.Okay, so youâ€™ll submit your Python tutorial to reddit. The /r/python subreddit has over 1.3 million subscribers. If even 5% of them read your article, thatâ€™s a huge audience:The /r/python subreddit has over 1.3 million subscribers.Whoops! /r/python only accepts text posts, not external links, so you canâ€™t post your tutorial there.The /r/python subreddit disables the option to submit external links.Fine, then youâ€™ll submit it to Hacker News. They accept anything and let their members decide whatâ€™s interesting. Surely, theyâ€™ll recognize the quality of your work!Nope, it will flop there, too. Hacker News doesnâ€™t like tutorials, especially for mainstream technologies like Python.You can try sharing your tutorial by tweeting it, skeeting it, or tooting it, but unless you already have a massive following on social media, that wonâ€™t reach a critical mass either.So, whatâ€™s the answer? How do you get people to read your amazing Python tutorial?The answer is that you donâ€™t write a beginnerâ€™s Python tutorial.You need a realistic path to your readersğŸ”—If you want people to read your blog, choose topics that have a clear path to your readers. Before you begin writing, think through how readers will find your post.Questions to ask when considering an article topicIs it realistic for readers to find you via Google search?Are there already 500 articles about the same topic from more established websites?What keywords would your target reader search? Try searching those keywords, and see whether there are already relevant results from well-known domains.If youâ€™re going to submit it to a link aggregator like Hacker News or Lobsters, how often do posts like yours succeed there?If youâ€™re going to share it on a subreddit or niche forum, does it have any chance there?Does the forum accept links to blog posts?The bigger the community, the stricter the rules tend to be about external links and self-promotion.Do blog posts like yours ever succeed there?Is the community still active?The best plan is to give your post multiple chances to succeed. If youâ€™re betting everything on Google bubbling your post to the top, it could take months or years for you to find out if you succeeded. If youâ€™re relying on Hacker News or reddit to tell you whether your article is worth reading, theyâ€™re going to break your heart a lot.Example: â€œUsing Zig to Unit Test a C Applicationâ€ğŸ”—In 2023, I wrote an article called â€œUsing Zig to Unit Test a C Application.â€ It was about using a new low-level language called Zig to write tests for legacy C code.Before I wrote the article, I knew that there were several places where I could share it. By luck, they all worked out:Hacker News is extremely friendly to Zig content, so my article reached the #7 spot on the front page.Lobsters is extremely friendly to Zig content, so my article was one of the top links of the day.Google bubbled my article to the top result for the keywords zig unit testing c.Itâ€™s actually even a top result for just zig unit testing because there arenâ€™t many articles about the topic.The /r/Zig subreddit accepts links to blog posts, even if theyâ€™re self-promotion, so my post reached the top spot in that subreddit.Ziggit is a niche forum thatâ€™s welcoming to Zig-related articles, so my post received 1,000 views from Ziggit.Show more picturesğŸ”—The biggest bang-for-your-buck change you can make to a blog post is adding pictures.If your article features long stretches of text, think about whether thereâ€™s any photo, screenshot, graph, or diagram that could make the post more visually interesting.If youâ€™re talking about a program with a graphical interface, show screenshots.If youâ€™re talking about an improvement in metrics like app performance or active users, show graphs.If youâ€™re writing about your server getting overloaded, show a screenshot of what that looked like in your dashboard or email alerts.If youâ€™re explaining a difficult concept, draw a diagram.I hire illustrators for most of my posts (including this one). I typically pay $50-100 per illustration. For simple diagrams like the nested circle sketches above, I use Excalidraw, which is free and open-source.You can also use free stock photos and AI-generated images, as theyâ€™re better than nothing, but theyâ€™re worse than anything else, including terrible MS Paint drawings.Even a terrible MS Paint drawing is more interesting than an AI-generated image.Accommodate skimmersğŸ”—Many readers skim an article first to decide if itâ€™s worth reading. Dazzle those readers during the skim.If the reader only saw your headings and images, would it pique their interest?The worst thing for a skimmer to see is a wall of text: long paragraphs with no images or headings to break them up. Just text, text, text all the way down.Tool: Read like a skimmerğŸ”—Hereâ€™s a JavaScript bookmarklet that you can use to see what your article looks like with just headings and images.Skimmify pageDrag the link to your browser bookmark bar, and then click it to see what your article looks like to skimmers.Example: Boring structure vs. interesting structureğŸ”—I wrote my article, â€œEnd-to-End Testing Web Apps: The Painless Way,â€ in 2019, before I thought about structure.If you skim the article, does it make you want to read the full version?\nYour browser does not support the video tag.Probably not. The headings donâ€™t reveal much about the content, and the visuals are confusing.Consider my more recent article, â€œI Regret My $46k Website Redesign.â€\nYour browser does not support the video tag.If you skim that article, you still see the bones of a good story, and there are interesting visual elements to draw the reader in.One of those articles barely attracted any readers, and the other became one of the most popular articles I ever published, attracting 150k unique readers in its first week. Can you guess which is which?.campaign-progress{background-color:#fdfffa;padding:1rem;border-radius:6px;text-align:center;border:1px solid #dae8c6;width:90%;max-width:500px;margin-left:auto;margin-right:auto}.goal-amount{font-weight:500;margin-bottom:1rem}.countdown{color:#555;font-size:1.1em}.progress{height:40px}.progress-bar{font-size:1.1em;line-height:40px}Pre-order the bookThis is an excerpt from my upcoming book,\nRefactoring English: Effective Writing for Software Developers.$4,776 raised of $5,000\ngoal96%Time left to meet goal: 2 days, 1 hours, 38 minutesWant to fund this so I can write the full book? Pre-order the book on\nKickstarter to support the book.Pre-Order Nowconst currentAmount=4776,goalAmount=5e3;function updateFundingInfo(){document.getElementById(\"current-amount\").textContent=currentAmount.toLocaleString(),document.getElementById(\"goal-amount\").textContent=goalAmount.toLocaleString();const t=Math.round(currentAmount/goalAmount*100),e=document.getElementById(\"progress-bar\");e.style.width=t+\"%\",e.textContent=t+\"%\",e.setAttribute(\"aria-valuenow\",currentAmount)}function updateCountdown(){const t=new Date(\"2025-03-31T23:59:00-04:00\"),n=new Date,e=t-n;if(e<=0){document.getElementById(\"countdown\").textContent=\"Campaign ended\";return}const s=Math.floor(e/(1e3*60*60*24)),o=Math.floor(e%(1e3*60*60*24)/(1e3*60*60)),i=Math.floor(e%(1e3*60*60)/(1e3*60));document.getElementById(\"countdown\").textContent=`${s} days, ${o} hours, ${i} minutes`}updateFundingInfo(),updateCountdown()In the nine years I've been blogging about software development, some of my posts have hit 300k+ readers, while others flopped, especially early on. I'm sharing all the lessons I learned the hard way about how to write popular blog posts for developers. https://t.co/a5cLF4MXfFâ€” Michael Lynch (@deliberatecoder) March 27, 2025â€œNot Quite How Developers Readâ€ illustration by Piotr Letachowicz. Steve Jobs illustration by Loraine Yow.",
    "summary": {
      "en": "**Summary of \"How to Write Blog Posts that Developers Read\" by Michael Lynch**\n\nMichael Lynch shares insights from his nine years of blogging about software development, emphasizing common mistakes that can prevent developers from gaining readers. Here are the key points:\n\n1. **Get to the Point**: Start with your main idea within the first few sentences. Readers have short attention spans and want to quickly know if the article is relevant to them and what they'll gain from reading it.\n\n2. **Think Broadly**: Consider if your topic can appeal to a wider audience. Small changes in terminology or explanations can make your content accessible to more readers.\n\n3. **Plan for Visibility**: Before writing, think about how readers will discover your post. Avoid topics that are overly saturated and ensure there are clear paths for readers to find your article, such as through Google searches or social media.\n\n4. **Use Visuals**: Adding images, diagrams, or screenshots can significantly enhance your article and make it more engaging.\n\n5. **Accommodate Skimmers**: Many readers skim articles first. Make sure your headings and images are compelling enough to draw them in, and avoid long blocks of text.\n\nBy applying these strategies, bloggers can improve their chances of attracting and retaining readers in the competitive world of software development writing.",
      "ko": "ë§ˆì´í´ ë¦°ì¹˜ëŠ” ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œì— ê´€í•œ ë¸”ë¡œê·¸ë¥¼ 9ë…„ ë™ì•ˆ ìš´ì˜í•˜ë©° ì–»ì€ í†µì°°ì„ ê³µìœ í•©ë‹ˆë‹¤. ê·¸ëŠ” ê°œë°œìë“¤ì´ ë…ìë¥¼ í™•ë³´í•˜ëŠ” ë° ë°©í•´ê°€ ë˜ëŠ” ì¼ë°˜ì ì¸ ì‹¤ìˆ˜ë“¤ì„ ê°•ì¡°í•©ë‹ˆë‹¤. \n\nì²« ë²ˆì§¸ë¡œ, ì£¼ì œë¥¼ ëª…í™•íˆ ì „ë‹¬í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤. ê¸€ì˜ ì²« ëª‡ ë¬¸ì¥ ì•ˆì— í•µì‹¬ ì•„ì´ë””ì–´ë¥¼ ì œì‹œí•´ì•¼ í•©ë‹ˆë‹¤. ë…ìë“¤ì€ ì§‘ì¤‘ë ¥ì´ ì§§ê¸° ë•Œë¬¸ì—, ê¸€ì´ ìì‹ ì—ê²Œ ì–´ë–¤ ì˜ë¯¸ê°€ ìˆëŠ”ì§€ ë¹ ë¥´ê²Œ íŒŒì•…í•˜ê³  ì‹¶ì–´í•©ë‹ˆë‹¤.\n\në‘ ë²ˆì§¸ë¡œ, ì£¼ì œë¥¼ ë„“ê²Œ ìƒê°í•´ë³´ì•„ì•¼ í•©ë‹ˆë‹¤. ìì‹ ì˜ ì£¼ì œê°€ ë” ë§ì€ ë…ìì—ê²Œ ì–´í•„í•  ìˆ˜ ìˆëŠ”ì§€ ê³ ë¯¼í•´ë³´ì„¸ìš”. ìš©ì–´ë‚˜ ì„¤ëª…ì—ì„œ ì‘ì€ ë³€í™”ë§Œìœ¼ë¡œë„ ë” ë§ì€ ë…ìê°€ ì ‘ê·¼í•  ìˆ˜ ìˆëŠ” ì½˜í…ì¸ ë¥¼ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nì„¸ ë²ˆì§¸ë¡œ, ê°€ì‹œì„±ì„ ê³„íší•´ì•¼ í•©ë‹ˆë‹¤. ê¸€ì„ ì“°ê¸° ì „ì— ë…ìë“¤ì´ ì–´ë–»ê²Œ ë‹¹ì‹ ì˜ í¬ìŠ¤íŠ¸ë¥¼ ë°œê²¬í• ì§€ë¥¼ ìƒê°í•´ë³´ì„¸ìš”. ì§€ë‚˜ì¹˜ê²Œ í¬í™”ëœ ì£¼ì œë¥¼ í”¼í•˜ê³ , êµ¬ê¸€ ê²€ìƒ‰ì´ë‚˜ ì†Œì…œ ë¯¸ë””ì–´ë¥¼ í†µí•´ ë…ìê°€ ì‰½ê²Œ ì°¾ì„ ìˆ˜ ìˆëŠ” ê²½ë¡œë¥¼ ë§ˆë ¨í•´ì•¼ í•©ë‹ˆë‹¤.\n\në„¤ ë²ˆì§¸ë¡œ, ì‹œê° ìë£Œë¥¼ í™œìš©í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. ì´ë¯¸ì§€, ë„í‘œ, ìŠ¤í¬ë¦°ìƒ· ë“±ì„ ì¶”ê°€í•˜ë©´ ê¸€ì´ í›¨ì”¬ ë” ë§¤ë ¥ì ì´ê³  í¥ë¯¸ë¡­ê²Œ ë³€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\në§ˆì§€ë§‰ìœ¼ë¡œ, ìŠ¤í‚¤ë¨¸ë¥¼ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤. ë§ì€ ë…ìë“¤ì´ ê¸€ì„ ì²˜ìŒì— í›‘ì–´ë³´ëŠ” ê²½í–¥ì´ ìˆìŠµë‹ˆë‹¤. ì œëª©ê³¼ ì´ë¯¸ì§€ê°€ ì¶©ë¶„íˆ ë§¤ë ¥ì ì´ì–´ì•¼ ë…ìë“¤ì„ ëŒì–´ë“¤ì¼ ìˆ˜ ìˆìœ¼ë©°, ê¸´ ë¬¸ë‹¨ì€ í”¼í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.\n\nì´ëŸ¬í•œ ì „ëµì„ ì ìš©í•˜ë©´ ë¸”ë¡œê±°ë“¤ì€ ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œ ê¸€ì“°ê¸°ì˜ ê²½ìŸì´ ì¹˜ì—´í•œ ì„¸ê³„ì—ì„œ ë…ìë¥¼ ìœ ì¹˜í•˜ê³  ìœ ì§€í•  ê°€ëŠ¥ì„±ì„ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
      "ja": "ãƒã‚¤ã‚±ãƒ«ãƒ»ãƒªãƒ³ãƒã¯ã€ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢é–‹ç™ºã«é–¢ã™ã‚‹ãƒ–ãƒ­ã‚°ã‚’9å¹´é–“ç¶šã‘ã¦ããŸçµŒé¨“ã‹ã‚‰ã€é–‹ç™ºè€…ãŒèª­è€…ã‚’ç²å¾—ã™ã‚‹éš›ã®ä¸€èˆ¬çš„ãªé–“é•ã„ã«ã¤ã„ã¦ã®æ´å¯Ÿã‚’å…±æœ‰ã—ã¦ã„ã¾ã™ã€‚é‡è¦ãªãƒã‚¤ãƒ³ãƒˆã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ã€‚\n\nã¾ãšã€è¨˜äº‹ã®å†’é ­ã§ä¸»ãªã‚¢ã‚¤ãƒ‡ã‚¢ã‚’ä¼ãˆã‚‹ã“ã¨ãŒå¤§åˆ‡ã§ã™ã€‚èª­è€…ã¯æ³¨æ„åŠ›ãŒçŸ­ãã€è¨˜äº‹ãŒè‡ªåˆ†ã«ã¨ã£ã¦é–¢é€£æ€§ãŒã‚ã‚‹ã‹ã€ä½•ã‚’å¾—ã‚‰ã‚Œã‚‹ã‹ã‚’ã™ãã«çŸ¥ã‚ŠãŸã„ã¨æ€ã£ã¦ã„ã¾ã™ã€‚\n\næ¬¡ã«ã€ãƒˆãƒ”ãƒƒã‚¯ãŒã‚ˆã‚Šåºƒã„èª­è€…å±¤ã«ã‚¢ãƒ”ãƒ¼ãƒ«ã§ãã‚‹ã‹ã‚’è€ƒãˆã‚‹ã“ã¨ãŒé‡è¦ã§ã™ã€‚ç”¨èªã‚„èª¬æ˜ã‚’å°‘ã—å¤‰ãˆã‚‹ã ã‘ã§ã€ã‚ˆã‚Šå¤šãã®èª­è€…ã«å†…å®¹ã‚’ç†è§£ã—ã¦ã‚‚ã‚‰ãˆã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚\n\nã¾ãŸã€è¨˜äº‹ã‚’æ›¸ãå‰ã«ã€èª­è€…ãŒã©ã®ã‚ˆã†ã«ã—ã¦ã‚ãªãŸã®æŠ•ç¨¿ã‚’è¦‹ã¤ã‘ã‚‹ã‹ã‚’è€ƒãˆã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚éåº¦ã«é£½å’Œã—ãŸãƒˆãƒ”ãƒƒã‚¯ã¯é¿ã‘ã€Googleæ¤œç´¢ã‚„ã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒ¡ãƒ‡ã‚£ã‚¢ã‚’é€šã˜ã¦èª­è€…ãŒè¨˜äº‹ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹æ˜ç¢ºãªé“ç­‹ã‚’ç¢ºä¿ã—ã¾ã—ã‚‡ã†ã€‚\n\nè¦–è¦šçš„è¦ç´ ã®æ´»ç”¨ã‚‚åŠ¹æœçš„ã§ã™ã€‚ç”»åƒã‚„å›³ã€ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã§ã€è¨˜äº‹ãŒã‚ˆã‚Šé­…åŠ›çš„ã«ãªã‚Šã€èª­è€…ã®é–¢å¿ƒã‚’å¼•ãã‚„ã™ããªã‚Šã¾ã™ã€‚\n\næœ€å¾Œã«ã€å¤šãã®èª­è€…ã¯è¨˜äº‹ã‚’ã–ã£ã¨æµã—èª­ã¿ã™ã‚‹ãŸã‚ã€è¦‹å‡ºã—ã‚„ç”»åƒãŒé­…åŠ›çš„ã§ã‚ã‚‹ã“ã¨ãŒé‡è¦ã§ã™ã€‚é•·ã„æ–‡ç« ã®å¡Šã¯é¿ã‘ã€èª­ã¿ã‚„ã™ã•ã‚’å¿ƒãŒã‘ã¾ã—ã‚‡ã†ã€‚\n\nã“ã‚Œã‚‰ã®æˆ¦ç•¥ã‚’å®Ÿè·µã™ã‚‹ã“ã¨ã§ã€ãƒ–ãƒ­ã‚°ã‚’æ›¸ã„ã¦ã„ã‚‹äººã¯ã€ç«¶äº‰ã®æ¿€ã—ã„ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢é–‹ç™ºã®åŸ·ç­†ã®ä¸–ç•Œã§èª­è€…ã‚’å¼•ãã¤ã‘ã€ç¶­æŒã™ã‚‹å¯èƒ½æ€§ã‚’é«˜ã‚ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚"
    }
  },
  {
    "id": "f9d177a202e349e0",
    "title": {
      "en": "Show HN: Hexi â€“ Modern header-only network binary serialisation for C++",
      "ko": "í—¤ì‹œ: C++ë¥¼ ìœ„í•œ í˜„ëŒ€ì  ë„¤íŠ¸ì›Œí¬ ì§ë ¬í™”",
      "ja": "Hexi: C++ã®æ–°æ™‚ä»£ãƒã‚¤ãƒŠãƒª"
    },
    "type": "story",
    "url": "https://github.com/EmberEmu/Hexi",
    "score": 113,
    "by": "Chaosvex",
    "time": 1743183462,
    "content": "Hexi is a lightweight, header-only C++23 library for safely handling binary data from arbitrary sources (but primarily network data). It sits somewhere between manually memcpying bytes from network buffers and full-blown serialisation libraries.\nThe design goals are ease of use, safety when dealing with untrusted data, a reasonable level of flexibility, and keeping overhead to a minimum.\nWhat Hexi doesn't offer: versioning, conversion between different formats, handling of text-based formats, unloading the dishwasher.\nHexi is dual-licensed under MIT and Apache License, Version 2.0. This means you can use Hexi under the license you prefer.\n\nIncorporating Hexi into your project is simple! The easiest way is to simply copy hexi.h from single_include into your own project. If you'd rather only include what you use, you can add include to your include paths or incorporate it into your own CMake project with target_link_library. To build the unit tests, run CMake with ENABLE_TESTING.\nHere's what some libraries might call a very simple motivating example:\n#include <hexi.h>\n#include <array>\n#include <vector>\n#include <cstddef>\n\nstruct UserPacket {\n    uint64_t user_id;\n    uint64_t timestamp;\n    std::array<uint8_t, 16> ipv6;\n};\n\nauto deserialise(std::span<const char> network_buffer) {\n    hexi::buffer_adaptor adaptor(network_buffer); // wrap the buffer\n    hexi::binary_stream stream(adaptor);          // create a binary stream\n\n    // deserialise!\n    UserPacket packet;\n    stream >> packet;\n    return packet;\n}\n\nauto serialise(const UserPacket& packet) {\n    std::vector<uint8_t> buffer;\n    hexi::buffer_adaptor adaptor(buffer); // wrap the buffer\n    hexi::binary_stream stream(adaptor);  // create a binary stream\n\n    // serialise!\n    stream << packet;\n    return buffer;\n}\n\nBy default, Hexi will try to serialise basic structures such as our UserPacket if they meet requirements for being safe to directly copy the bytes. Now, for reasons of portability, it's not recommended that you do things this way unless you're positive that the data layout is identical on the system that wrote the data. Not to worry, this is easily solved. Plus, we didn't do any error handling. All in good time.\n\nThe two classes you'll primarily deal with are buffer_adaptor and binary_stream.\nbinary_stream takes a container as its argument and is used to do the reading and writing. It doesn't know much about the details of the underlying container.\nTo support containers that weren't written to be used with Hexi, buffer_adaptor is used as a wrapper that binary_stream can interface with. As with binary_stream, it also provides read and write operations but at a lower level.\nbuffer_adaptor can wrap any contiguous container or view that provides data and size member functions and optionally resize() for write support. From the standard library, that means the following can be used out of the box:\n\n std::array\n std::span\n std::string_view\n std::string\n std::vector\n\nPlenty of non-standard library containers will work out of the box, too, as long as they provide a vaguely similar API.\nThe container's value type must be a byte type (e.g. char, std::byte, uint8_t). std::as_bytes can be used as a workaround if this poses a problem.\n\nHexi supports custom containers, including non-contiguous containers. In fact, there's a non-contiguous container included in the library. You simply need to provide a few functions such as read and size to allow the binary_stream class to be able to use it.\nstatic_buffer.h provides a simple example of a custom container that can be used directly with binary_stream.\n\nAs mentioned, Hexi is intended to be safe to use even when dealing with untrusted data. An example might be network messages that have been manipulated to try to trick your code into reading out of bounds.\nbinary_stream performs bounds checking to ensure that it will never read more data than the buffer has available and optionally allows you to specify an upper bound on the amount of data to read. This can be useful when you have multiple messages in a buffer and want to limit the deserialisation from potentially eating into the next.\nbuffer_t buffer;\n// ... read data\nhexi::binary_stream stream(buffer, 32); // will never read more than 32 bytes\n\nThe default error handling mechanism is exceptions. Upon encountering a problem with reading data, an exception derived from hexi::exception will be thrown. These are:\n\nhexi::buffer_underrun - attempt to read out of bounds\nhexi::stream_read_limit - attempt to read more than the imposed limit\n\nExceptions from binary_stream can be disabled by specifying no_throw as a template argument, as shown:\nhexi::binary_stream<buf_type, hexi::no_throw> stream(...);\n\nWhile this prevents binary_stream itself from throwing, it does not prevent propagation of exceptions from lower levels. For example, a wrapped std::vector could still throw std::bad_alloc if allocation fails when writing to it.\nRegardless of the error handling mechanism you use, the state of a binary_stream can be checked as follows:\nhexi::binary_stream<buf_type, hexi::no_throw> stream(...);\n// ... assume an error happens\n\n// simplest way to check whether any errors have occurred\nif (!stream) {\n    // handle error\n}\n\n// or we can get the state\nif (auto state = stream.state(); state != hexi::stream_state::ok) {\n    // handle error\n}\n\nIn the first example, reading our UserPacket would only work as expected if the program that wrote the data laid everything out in the same way as our own program.\nThis might not be the case for reasons of architecture differences, compiler flags, etc.\nHere's the same example but doing it portably.\n#include <hexi.h>\n#include <span>\n#include <string>\n#include <vector>\n#include <cstddef>\n#include <cstdint>\n\nstruct UserPacket {\n    uint64_t user_id;\n    std::string username;\n    uint64_t timestamp;\n    uint8_t has_optional_field;\n    uint32_t optional_field;  // pretend this is big endian in the protocol\n\n    // deserialise\n    auto& operator>>(auto& stream) {\n        stream >> user_id >> username >> timestamp >> has_optional_field;\n\n        if (has_optional_field) {\n            stream >> optional_field;\n            hexi::endian::big_to_native_inplace(optional_field);\n        }\n\n        // we can manually trigger an error if something went wrong\n        // stream.set_error_state();\n        return stream;\n    }\n\n    // serialise\n    auto& operator<<(auto& stream) const {\n        stream << user_id << username << timestamp << has_optional_field;\n\n        if (has_optional_field) {\n            stream << hexi::endian::native_to_big(optional_field);\n        }\n\n        return stream;\n    }\n};\n\n// pretend we're reading network data\nvoid read() {\n    std::vector<char> buffer;\n    const auto bytes_read = socket.read(buffer);\n\n    // ... logic for determining packet type, etc\n\n    bool result {};\n\n    switch (packet_type) {\n        case packet_type::user_packet:\n            result = handle_user_packet(buffer);\n            break;\n    }\n\n    // ... handle result\n}\n\nauto handle_user_packet(std::span<const char> buffer) {\n    hexi::buffer_adaptor adaptor(buffer);\n    hexi::binary_stream stream(adaptor);\n\n    UserPacket packet;\n    stream >> packet;\n\n    if (stream) {\n        // ... do something with the packet\n        return true;\n    } else {\n        return false;\n    }\n}\n\nBecause binary_stream is a template, it's easiest to allow the compiler to perform type deduction magic.\nIf you want the function bodies to be in a source file, it's recommended that you provide your own using alias for your binary_stream type.\nThe alternative is to use the polymorphic equivalents, pmc::buffer_adaptor and pmc::binary_stream, which allow you to change the underlying buffer type at runtime but at the cost of virtual call overhead and lacking some functionality that doesn't mesh well with polymorphism.\nHow you structure your code is up to you, this is just one way of doing it.\n\nWhen using binary_stream, strings are always treated as null-terminated. Writing a char*, std::string_view or std::string will always write a terminating byte to the stream. If you require otherwise, use one of the put functions.\nLikewise, reading to std::string assumes the buffer contains a null-terminator. If it does not, an empty string will be returned. If you know the length of the string or need to support a custom terminating/sentinel value, use get() and find_first_of().\n\nHere's a very quick rundown on some of the included extras.\n\nhexi::file_buffer\n\nFor dealing with binary files. Simples.\n\nhexi::static_buffer\n\nFixed-size networking buffer for when you know the upper bound on the amount of data you'll need to send or receive in one go. Essentially a wrapper around std::array but with added state tracking. Handy if you need to deserialise in multiple steps (read packet header, dispatch, read packet body).\n\nhexi::dynamic_buffer\n\nResizeable buffer for when you want to deal with occasional large reads/writes without having to allocate the space up front. Internally, it adds additional allocations to accommodate extra data rather than requesting a larger allocation and copying data as std::vector would. It reuses allocated blocks where possible and has support for Asio (Boost or standalone). Effectively, it's a linked list buffer.\n\nhexi::tls_block_allocator\n\nAllows many instances of dynamic_buffer to share a larger pool of pre-allocated memory, with each thread having its own pool. This is useful when you have many network sockets to handle and want to avoid the general purpose allocator. The caveat is that a deallocation must be made by the same thread that made the allocation, thus limiting access to the buffer to a single thread (with some exceptions).\n\nhexi::endian\n\nProvides functionality for handling endianness of integral types.\n\nWe're at the end of the overview, but there's more to discover if you decide to give Hexi a shot. Here's a selection of tasty morsels:\n\nbinary_stream allows you to perform write seeking within the stream, when the underlying buffer supports it. This is nice if, for example, you need to update a message header with information that you might not know until the rest of the message has been written; checksums, sizes, etc.\nbinary_stream provides overloaded put and get member functions, which allow for fine-grained control, such as reading/writing a specific number of bytes.\nbinary_stream allows for writing to std::string_view and std::span with view() and span() as long as the underlying container is contiguous. This allows you to create views into the buffer's data, providing a fast, zero-copy way to read strings and arrays from the stream. If you do this, you should avoid writing to the same buffer while holding views to the data.\nbuffer_adaptor provides a template option, space_optimise. This is enabled by default and allows it to avoid resizing containers in cases where all data has been read by the stream. Disabling it allows for preserving data even after having been read. This option is only relevant in scenarios where a single buffer is being both written to and read from.\nbuffer_adaptor provides find_first_of, making it easy to find a specific sentinel value within your buffer.\n\nTo learn more, check out the examples in docs/examples!",
    "summary": {
      "en": "Hexi is a lightweight C++23 library designed for safely handling binary data, mainly from network sources. It aims to be easy to use, flexible, and efficient, without offering features like versioning or text format handling. Hexi is available under both the MIT and Apache 2.0 licenses.\n\nTo use Hexi, simply include the `hexi.h` header in your project. It includes two main classes: `buffer_adaptor` and `binary_stream`. The `binary_stream` class is used for reading and writing binary data, while `buffer_adaptor` wraps data containers to be compatible with `binary_stream`. It supports standard containers like `std::array`, `std::vector`, and others.\n\nHexi prioritizes safety when working with untrusted data, performing bounds checks to prevent reading out of bounds. Error handling is done using exceptions, which can be managed or disabled.\n\nHexi supports custom containers, and its serialization/deserialization methods can handle various data types. It also includes utilities for dealing with binary files and buffers, such as fixed-size and dynamic buffers, which are useful for network communications.\n\nFinally, Hexi provides features for managing endianness and allows for flexible data reading and writing, including string handling and buffer optimization options.\n\nFor more details and examples, refer to the documentation.",
      "ko": "HexiëŠ” ì£¼ë¡œ ë„¤íŠ¸ì›Œí¬ ì†ŒìŠ¤ì—ì„œ ì˜¤ëŠ” ì´ì§„ ë°ì´í„°ë¥¼ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ ì„¤ê³„ëœ ê²½ëŸ‰ C++23 ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤. ì‚¬ìš©ì´ ê°„í¸í•˜ê³  ìœ ì—°í•˜ë©° íš¨ìœ¨ì ì´ì§€ë§Œ, ë²„ì „ ê´€ë¦¬ë‚˜ í…ìŠ¤íŠ¸ í˜•ì‹ ì²˜ë¦¬ì™€ ê°™ì€ ê¸°ëŠ¥ì€ ì œê³µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. HexiëŠ” MIT ë¼ì´ì„ ìŠ¤ì™€ Apache 2.0 ë¼ì´ì„ ìŠ¤ í•˜ì— ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nHexië¥¼ ì‚¬ìš©í•˜ë ¤ë©´ í”„ë¡œì íŠ¸ì— `hexi.h` í—¤ë” íŒŒì¼ì„ í¬í•¨í•˜ë©´ ë©ë‹ˆë‹¤. ì´ ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” ë‘ ê°€ì§€ ì£¼ìš” í´ë˜ìŠ¤ì¸ `buffer_adaptor`ì™€ `binary_stream`ì„ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤. `binary_stream` í´ë˜ìŠ¤ëŠ” ì´ì§„ ë°ì´í„°ë¥¼ ì½ê³  ì“°ëŠ” ë° ì‚¬ìš©ë˜ë©°, `buffer_adaptor`ëŠ” ë°ì´í„° ì»¨í…Œì´ë„ˆë¥¼ `binary_stream`ê³¼ í˜¸í™˜ë˜ë„ë¡ ê°ì‹¸ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤. ì´ í´ë˜ìŠ¤ëŠ” `std::array`, `std::vector`ì™€ ê°™ì€ í‘œì¤€ ì»¨í…Œì´ë„ˆë¥¼ ì§€ì›í•©ë‹ˆë‹¤.\n\nHexiëŠ” ì‹ ë¢°í•  ìˆ˜ ì—†ëŠ” ë°ì´í„°ë¥¼ ë‹¤ë£° ë•Œ ì•ˆì „ì„±ì„ ìš°ì„ ì‹œí•˜ë©°, ë²”ìœ„ë¥¼ ë²—ì–´ë‚œ ì½ê¸°ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ ê²½ê³„ ê²€ì‚¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤. ì˜¤ë¥˜ ì²˜ë¦¬ëŠ” ì˜ˆì™¸ë¥¼ í†µí•´ ì´ë£¨ì–´ì§€ë©°, ì´ë¥¼ ê´€ë¦¬í•˜ê±°ë‚˜ ë¹„í™œì„±í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nHexiëŠ” ì‚¬ìš©ì ì •ì˜ ì»¨í…Œì´ë„ˆë¥¼ ì§€ì›í•˜ë©°, ì§ë ¬í™” ë° ì—­ì§ë ¬í™” ë°©ë²•ì€ ë‹¤ì–‘í•œ ë°ì´í„° ìœ í˜•ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, ë„¤íŠ¸ì›Œí¬ í†µì‹ ì— ìœ ìš©í•œ ê³ ì • í¬ê¸° ë° ë™ì  ë²„í¼ì™€ ê°™ì€ ì´ì§„ íŒŒì¼ ë° ë²„í¼ë¥¼ ë‹¤ë£¨ê¸° ìœ„í•œ ìœ í‹¸ë¦¬í‹°ë„ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n\në§ˆì§€ë§‰ìœ¼ë¡œ, HexiëŠ” ì—”ë””ì•ˆ ê´€ë¦¬ ê¸°ëŠ¥ì„ ì œê³µí•˜ë©°, ë¬¸ìì—´ ì²˜ë¦¬ ë° ë²„í¼ ìµœì í™” ì˜µì…˜ì„ í¬í•¨í•˜ì—¬ ìœ ì—°í•œ ë°ì´í„° ì½ê¸° ë° ì“°ê¸°ë¥¼ ì§€ì›í•©ë‹ˆë‹¤.\n\nìì„¸í•œ ë‚´ìš©ê³¼ ì˜ˆì œëŠ” ë¬¸ì„œë¥¼ ì°¸ì¡°í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.",
      "ja": "Hexiã¯ã€ä¸»ã«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‹ã‚‰ã®ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ã‚’å®‰å…¨ã«æ‰±ã†ãŸã‚ã«è¨­è¨ˆã•ã‚ŒãŸè»½é‡ã®C++23ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã™ã€‚ä½¿ã„ã‚„ã™ã•ã€æŸ”è»Ÿæ€§ã€åŠ¹ç‡æ€§ã‚’é‡è¦–ã—ã¦ãŠã‚Šã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã‚„ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã®å‡¦ç†ã¨ã„ã£ãŸæ©Ÿèƒ½ã¯æä¾›ã—ã¦ã„ã¾ã›ã‚“ã€‚Hexiã¯MITãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¨Apache 2.0ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã®ä¸¡æ–¹ã®ä¸‹ã§åˆ©ç”¨å¯èƒ½ã§ã™ã€‚\n\nHexiã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«`hexi.h`ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’å«ã‚ã‚‹ã ã‘ã§ã™ã€‚ã“ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã«ã¯ã€ä¸»ã«2ã¤ã®ã‚¯ãƒ©ã‚¹ã€`buffer_adaptor`ã¨`binary_stream`ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚`binary_stream`ã‚¯ãƒ©ã‚¹ã¯ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ã®èª­ã¿æ›¸ãã«ä½¿ç”¨ã•ã‚Œã€`buffer_adaptor`ã¯ãƒ‡ãƒ¼ã‚¿ã‚³ãƒ³ãƒ†ãƒŠã‚’`binary_stream`ã¨äº’æ›æ€§ã®ã‚ã‚‹å½¢ã«ãƒ©ãƒƒãƒ—ã—ã¾ã™ã€‚æ¨™æº–çš„ãªã‚³ãƒ³ãƒ†ãƒŠã§ã‚ã‚‹`std::array`ã‚„`std::vector`ãªã©ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚\n\nHexiã¯ã€ä¿¡é ¼ã§ããªã„ãƒ‡ãƒ¼ã‚¿ã‚’æ‰±ã†éš›ã«å®‰å…¨æ€§ã‚’é‡è¦–ã—ã¦ãŠã‚Šã€ç¯„å›²å¤–ã®èª­ã¿å–ã‚Šã‚’é˜²ããŸã‚ã®å¢ƒç•Œãƒã‚§ãƒƒã‚¯ã‚’è¡Œã„ã¾ã™ã€‚ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã¯ä¾‹å¤–ã‚’ä½¿ç”¨ã—ã¦è¡Œã‚ã‚Œã€ã“ã‚Œã‚’ç®¡ç†ã—ãŸã‚Šç„¡åŠ¹ã«ã—ãŸã‚Šã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚\n\nHexiã¯ã‚«ã‚¹ã‚¿ãƒ ã‚³ãƒ³ãƒ†ãƒŠã‚‚ã‚µãƒãƒ¼ãƒˆã—ã¦ãŠã‚Šã€ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºã‚„ãƒ‡ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºã®ãƒ¡ã‚½ãƒƒãƒ‰ã¯ã•ã¾ã–ã¾ãªãƒ‡ãƒ¼ã‚¿å‹ã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚ã¾ãŸã€å›ºå®šã‚µã‚¤ã‚ºã‚„å‹•çš„ãƒãƒƒãƒ•ã‚¡ãªã©ã€ãƒã‚¤ãƒŠãƒªãƒ•ã‚¡ã‚¤ãƒ«ã‚„ãƒãƒƒãƒ•ã‚¡ã‚’æ‰±ã†ãŸã‚ã®ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚‚å«ã¾ã‚Œã¦ãŠã‚Šã€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯é€šä¿¡ã«å½¹ç«‹ã¡ã¾ã™ã€‚\n\nã•ã‚‰ã«ã€Hexiã¯ã‚¨ãƒ³ãƒ‡ã‚£ã‚¢ãƒ³ãƒã‚¹ã®ç®¡ç†æ©Ÿèƒ½ã‚’æä¾›ã—ã€æ–‡å­—åˆ—å‡¦ç†ã‚„ãƒãƒƒãƒ•ã‚¡æœ€é©åŒ–ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’å«ã‚€æŸ”è»Ÿãªãƒ‡ãƒ¼ã‚¿ã®èª­ã¿æ›¸ãã‚’å¯èƒ½ã«ã—ã¾ã™ã€‚\n\nè©³ç´°ã‚„ä¾‹ã«ã¤ã„ã¦ã¯ã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚"
    }
  },
  {
    "id": "7cac7b7b59826864",
    "title": {
      "en": "'Audible enclaves' could enable private listening without headphones",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://techxplore.com/news/2025-03-audible-enclaves-enable-private-headphones.html",
    "score": 12,
    "by": "PaulHoule",
    "time": 1743279276,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "be437f11a115524a",
    "title": {
      "en": "TSMC, Intel and other top chipmakers slow Japan, Malaysia expansions",
      "ko": "ë°˜ë„ì²´ ëŒ€ê¸°ì—…, ì¼ë³¸Â·ë§ë ˆì´ì‹œì•„ í™•ì¥ ì§€ì—°",
      "ja": "åŠå°ä½“æ‹¡å¤§éˆåŒ–"
    },
    "type": "story",
    "url": "https://asia.nikkei.com/Spotlight/Supply-Chain/TSMC-Intel-and-other-top-chipmakers-slow-Japan-Malaysia-expansions",
    "score": 33,
    "by": "pdyc",
    "time": 1743270861,
    "content": "About Nikkei AsiaAbout UsSitemapAnnouncementsAdvertise With Nikkei AsiaAbout NikkeiSupportHelp/Contact UsView Site TipsSubscriptionsIndividual SubscriptionGroup SubscriptionGift SubscriptionLegal & PrivacyTerms of UseCopyrightPrivacy & Cookie PolicyInformation Transmission",
    "summary": {
      "en": "Nikkei Asia is a news platform that provides information and updates about Asia. It offers various services, including subscriptions for individuals and groups, and gift subscriptions. The site includes sections like announcements and support, as well as legal and privacy policies. Users can also find tips for navigating the site.",
      "ko": "ë‹ˆì¼€ì´ ì•„ì‹œì•„ëŠ” ì•„ì‹œì•„ì— ëŒ€í•œ ì •ë³´ì™€ ì—…ë°ì´íŠ¸ë¥¼ ì œê³µí•˜ëŠ” ë‰´ìŠ¤ í”Œë«í¼ì…ë‹ˆë‹¤. ê°œì¸ ë° ê·¸ë£¹ì„ ìœ„í•œ êµ¬ë… ì„œë¹„ìŠ¤ì™€ ì„ ë¬¼ êµ¬ë… ì„œë¹„ìŠ¤ ë“± ë‹¤ì–‘í•œ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì´ ì‚¬ì´íŠ¸ì—ëŠ” ê³µì§€ì‚¬í•­ê³¼ ì§€ì› ì„¹ì…˜, ë²•ë¥  ë° ê°œì¸ì •ë³´ ë³´í˜¸ ì •ì±…ë„ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì‚¬ìš©ìë“¤ì€ ì‚¬ì´íŠ¸ ì´ìš©ì— ëŒ€í•œ íŒë„ ì°¾ì•„ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
      "ja": "Nikkei Asiaã¯ã€ã‚¢ã‚¸ã‚¢ã«é–¢ã™ã‚‹æƒ…å ±ã‚„æœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’æä¾›ã™ã‚‹ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã§ã™ã€‚å€‹äººã‚„ã‚°ãƒ«ãƒ¼ãƒ—å‘ã‘ã®è³¼èª­ã‚µãƒ¼ãƒ“ã‚¹ã‚„ã€ã‚®ãƒ•ãƒˆè³¼èª­ã‚‚åˆ©ç”¨ã§ãã¾ã™ã€‚ã‚µã‚¤ãƒˆã«ã¯ã€ç™ºè¡¨ã‚„ã‚µãƒãƒ¼ãƒˆã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã€æ³•çš„ãŠã‚ˆã³ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒãƒªã‚·ãƒ¼ã‚‚å«ã¾ã‚Œã¦ã„ã¾ã™ã€‚ã¾ãŸã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ã‚µã‚¤ãƒˆã®ä½¿ã„æ–¹ã«é–¢ã™ã‚‹ãƒ’ãƒ³ãƒˆã‚‚è¦‹ã¤ã‘ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚"
    }
  },
  {
    "id": "81b904731d3c64d7",
    "title": {
      "en": "The Real Book (2021)",
      "ko": "ì§„ì§œ ì±… (2021)",
      "ja": "ãƒªã‚¢ãƒ«ãƒ–ãƒƒã‚¯2021"
    },
    "type": "story",
    "url": "https://99percentinvisible.org/episode/the-real-book/",
    "score": 147,
    "by": "Tomte",
    "time": 1743179950,
    "content": "Episode 438\nThe Real Book\n\n    PlayPause\n  Click to enlarge image\n\n                    History\n\n      Category\n      History\n\n      Date\n      04.06.21\n\n    Producer\n    99pi\n\n            Add to QueueRemove from QueueDownloadTranscript\n\n                      Share on Facebook\n\n                      Share on Twitter\n\n                      Leave a Comment\n\n                Since the mid-1970s, almost every jazz musician has owned a copy of the same book. It has a peach-colored cover, a chunky, 1970s-style logo, and a black plastic binding. Itâ€™s delightfully homemade-lookingâ€”like it was printed by a bunch of teenagers at a Kinkos. And inside is the sheet music for hundreds of common jazz tunesâ€”also known as jazz â€œstandardsâ€â€”all meticulously notated by hand. Itâ€™s called the Real Book.\n\nBut if you were going to music school in the 1970s, you couldnâ€™t just buy a copy of the Real Book at the campus bookstore. Because the Real Bookâ€¦ was illegal. The worldâ€™s most popular collection of jazz music was a totally unlicensed publication. It was a self-published book created without permission from music publishers or songwriters. It was duplicated at photocopy shops and sold on street corners, out of the trunks of cars, and under the table at music stores where people used secret code words to make the exchange. The full story of how the Real Book came to be this bootleg bible of jazz is a complicated one. Itâ€™s a story about what happens when an insurgent, improvisational art form like jazz gets codified and becomes something that you can learn from a book.\nThe History of Fake Books\nBarry Kernfeld\n is a musicologist who has written a lot about the history of jazz and music piracy. Kernfeld says that long before the Real Book ever came out, jazz musicians were relying on collections of music they called fake books. Kernfeld says that the story of the first fake book began in the 1940s. â€œA man named George Goodwin in New York City, involved in radio in the early 1940s, was getting a little frustrated with all the intricacies of tracking licensing. And so he invented this thing that he called the Tune-Dex,â€ explains Kernfeld.\nTuneDex card via Georgia State University Library\nThe Tune-Dex was an index card catalog designed for radio station employees to keep track of the songs they were playing on air. On one side the cards had information about a particular song, such as the composer, the publisher, and anything that one would need to know for payment rights. On the other side of the card were a few lines of bite-sized sheet musicâ€”just the songâ€™s melody, lyrics, and chords so that radio station employees could glance at it and quickly recall the song. This abbreviated musical notation also made the cards useful to another group of people: working jazz musicians.\n\nAs a Black art form, jazz had developed out of a mix of other Black music traditions including spirituals and the blues. By the 1940s, a lot of â€œjazzâ€ was popular dance music, and many jazz musicians were making their money playing live gigs in small clubs and bars. The standard jazz repertoire was mostly well-known pop songs from Broadway, or New Yorkâ€™s songwriting factory: â€œTin Pan Alley.â€\n\nJazz musicians would riff and freestyle over these songs. The art of improvisation has always been a key art form of jazz music. But what made the average gigging trumpeter or sax player truly valuable was their ability to play any one of hundreds of songs right there on the spot.\nTo be prepared for any request, musicians would bring stacks and stacks of sheet music to every gig. But lugging around a giant pile of paper could be really cumbersomeâ€”this is where the Tune-Dex came in. Someone figured out that you could gather together a bunch of Tune-Dex cards, print copies of them on sheets of paper, add a table of contents and a simple binding, and then sell the finished product directly to musicians in the form of a book. They called them â€œfake booksâ€ because they helped musicians fake their way through unfamiliar songs. These first fake books were cheaper than regular sheet music, and a lot more organized. They became an essential tool for this entire class of working musicians.\n\nBootleggers\n\nMusicians loved these new fake books, but the music publishers hated them. They wanted musicians to buy legal sheet music, and so the publishing companies started cracking down on fake book bootleggers. That, of course, didnâ€™t stop the bootleggers and by the 1950s, there were countless illegal fake books in existence, which were being used in nightclubs all across the country.\n\nAs helpful as fake books were, they had a lot of problems. They were notoriously illegible and confusingly laid out. The other big problem with these fake books at this point was that the music inside felt really out of date. The fake books hadnâ€™t changed since the mid-40s, but jazz had. Disillusioned by commercial jazz that appealed to mainstream white audiences, a new generation of Black musicians took jazz improvisation to a new level. They experimented with more angular harmonies, technically demanding melodies and blindingly fast tempos. Their new style was called bebop.\n\nBebop was just the beginning. Over several decades, jazz exploded into this constellation of different styles. Meanwhile, the economics of jazz shifted too. There were fewer clubs, smaller paychecks, and more university jazz programs with steady teaching gigs. The ivory tower, not the nightclub, increasingly became a place for young musicians to learn, and for established musicians to earn a living. And if youâ€™re going to jazz school, you need jazz books.\nBerklee College of Music. Photo by Cryptic C62\nThe fake books at the time hadnâ€™t kept up with the music. They still contained the same old-fashioned collection of standards with the same old-fashioned collection of chord changes. If a young jazz musician wanted to try and play like Charles Mingus or Sonny Rollins, they werenâ€™t going to learn from a book. That isâ€¦ until two college kids invented the Real Book.\n\nThe Two Guys\n\nIn the mid-70s, Steve Swallow began teaching at Bostonâ€™s Berklee College of Music, an elite private music school that boasted one of the first jazz performance programs in the country. Swallow had only been teaching at Berklee for a few months when two students approached him about a secret project. â€œI keep referring them to them as â€˜the two guys who wrote the book,â€™ becauseâ€¦they swore me to secrecy. They made me agree that I would not divulge their names,â€ explains Swallow. The â€œtwo guysâ€ wanted to make a new fake book, one that actually catered to the needs of contemporary jazz musicians and reflected the current state of jazz. And they needed Swallowâ€™s help.\n\nFrom the very beginning, the students envisioned the Real Book as a cooler and more contemporary fake book than the stodgy, outdated ones theyâ€™d grown up with. They wanted it to include new songs from jazz fusion artists like Herbie Hancock, and free jazz pioneers like Ornette Coleman who were pushing the boundaries of the genre. They also wanted to include the old jazz standards from Broadway and Tin Pan Alley, but they wanted to update those classics with alternate chord changes that reflected the way modern musicians, like Miles Davis, were actually playing them.\n\nModern jazz musicians had altered a lot of classic standards over the years, with new harmonies and more complex chord changes. And to capture these new sounds, the students spent hours listening to recordings and transcribing what they heard, as best they could. It was a huge undertaking because most of these chord changes had never actually been written down. They werenâ€™t necessarily thinking about it like this at the time, but the students were effectively establishing a new set of standardized harmonies for a handful of classic songs.\n\nThe music wasnâ€™t the only part of their new fake book that the students wanted to improve. They also wanted to fix the aesthetic problems with the old fake books, and make something that was nice to look at and easy to read. One of â€œthe two guysâ€ notated all of the music by hand in this very distinctive and expressive script. He also designed and silk-screened the logo on the front cover: â€œThe Real Book,â€ written in chunky, SchoolHouse Rock-style block letters.\n\nBy the summer of 1975, the book was done, and the students took it to local photocopying shops where they cranked out hundreds of copies to sell directly to other students and a few local businesses near Berklee. Overnight, almost everyone had to have one. As the Real Bookâ€™s notoriety grew, so did the demand. The two students hadnâ€™t printed enough copies to keep up, but it turns out, they didnâ€™t need to. Not long after they created a few hundred copies of the book, bootleg versions began popping up all over the world. The Real Book had taken on a life of its own, and the students ironically found themselves in the same position as the music publishers and songwriters theyâ€™d originally cut out of the process, as they watched unlicensed copies of their work get duplicated and sold. After they released the first edition of the Real Book, the students put out two more editions to correct mistakes, and then their work was done. But the Real Book lived on, copied over and over again by new generations of bootleggers. And as the number of students in elite conservatory jazz programs continued to swell over the next few decades, the Real Book, with its modern repertoire, reharmonized standards, and beautiful handwriting, became the de-facto textbook for this new legion of jazz students. The unofficial official handbook of jazz.\n\nThe Real Real Book\n\nJust like with old fake books, the success of the Real Book was a major problem for music publishers. Some companies released their own fake books, but they never managed to compete with the Real Book. The popularity of the Real Book meant that lots of people werenâ€™t getting paid for their work. But in the mid-2000s, music executive Jeff Schroedl and the publisher Hal Leonard decided, if you canâ€™t beat â€™em, join â€™em. They went through the Real Book page by page, secured the rights to almost every song, and published a completely legal version. You donâ€™t need to buy the Real Book out of the back of someoneâ€™s car anymore. Itâ€™s available at your local music shop. They even wanted the same handwriting. Hal Leonard actually hired a copyist to mimic the old Real Bookâ€™s iconic script and turn it into a digital font, which means a digital copy of a physical copy of one anonymous Berklee studentâ€™s handwriting from the mid-70s will continue to live on for as long as new editions of the book are published.\nThe Hal Leonard version of the Real Book\nWhen Hal Leonard finally published the legal version of the Real Book in 2004, it was great news if you were a composer with a song in there. Youâ€™d finally be getting royalties from the sale of the most popular jazz fake book of all time. But that didnâ€™t totally solve the intellectual property problems with the Real Book. While the legalization of the Real Book did resolve most of its flagrant copyright violations, it didnâ€™t clear up authorship disputes that go back to the early days of jazz. Many jazz songs arise out of collective tinkering and improvising in jam sessions. Itâ€™s sometimes quite hard to say who exactly wrote a given song, and power dynamics often impacted whose name actually got listed as an official songwriter. And so there are likely many musicians whose names will never appear on the songs they helped write, even if those songs appear in the legal Real Book.\n\nUseful Tool, or Reductive Cheat Sheet?\n\nEven if we put the intellectual property questions aside for a second, fake books like the Real Book still have plenty of critics. Nicholas Payton is a musician and record label owner, and he compares the Real Book to a study guide or a cheat sheetâ€”a way to distill this complicated art form into a manageable packet of digestible information. To Payton, jazz isnâ€™t just information to be learned. Itâ€™s a way of thinking and a form of expression. And itâ€™s fundamentally a Black cultural phenomenon that canâ€™t be taken out of its historical context. Payton says that reading books like the Real Book, even going to music school, can really only get you so far. If you want to learn to play, at some point youâ€™re going to have to immerse yourself in the culture of the music. For Payton (and many musicians) learning directly from elders, in person, is a crucial part of what it means to really know the art form.\nThereâ€™s also the question of codification, and whether itâ€™s useful to have one songbook filled with definitive versions of all these jazz tunes. Carolyn Wilkins has taught ensembles at Berklee College of Music, and she says that the chords that are written down in the Real Book sometimes get treated like the right way to play a particular song. But even though jazz has all of these â€œstandards,â€ theyâ€™re not supposed to be played in one standard way. As you listen to different recordings of the same song by different jazz artists, it becomes obvious that thereâ€™s no one right way to play it. Wilkins says that the Real Book does have its place in jazz education. Over her years at Berklee, sheâ€™s seen how it can be a useful starting place as a tool to bring young jazz musicians together. The key, she says, is to treat the Real Book as a starting place. From there you need to go out and explore all the other ways people have played a particular song. â€œAnd then ultimately you must find your own way.â€\n\n        Enjoy 99pi? Subscribe to the podcast!\n        iTunes RSS Feed\n\n        Get the latest from 99pi each week in your inbox\n\n            Email Address\n\n              Yes Please! By submitting this form, you acknowledge that you have read the Terms of Use and Privacy Policy, that you understand them, and that you agree to be bound by them.  If you do not agree to be bound by the Terms of Use and Privacy Policy, you may not use the 99% Invisible website and services.\n\n        Enjoy 99pi? Subscribe to the podcast!\n        Subscribe Subscribe\n\n  Credits\n\n      Production\n      Reporter Mikel McCavana spoke with Jeff Leonard, musician and music educator at Berklee College of Music, Boston University, New England Conservatory; Steve Swallow, musician and composer; Barry Kernfeld, musicologist and author; Jeff Schroedl, Executive Vice President at Hal Leonard; Nicholas Payton; Musician, owner of Paytone Records, and creator of the Black American Music (BAM) movement; Carolyn Wilkins, musician and professor at Berklee College of Music; Gerald Horne, author and Moores Professor of History and African American Studies at the University of Houston.\nThis episode was edited by Emmett FitzGerald.",
    "summary": {
      "en": "**Summary of Episode 438: The Real Book**\n\nSince the mid-1970s, most jazz musicians have used a book called the Real Book, which has a homemade look and contains sheet music for hundreds of jazz standards. However, it was initially illegal because it was self-published without permission from music publishers.\n\nThe concept of fake books, which help musicians play songs they donâ€™t know, started in the 1940s with George Goodwin's Tune-Dex. Jazz musicians needed an easier way to manage sheet music, leading to the creation of cheap, organized fake books. Over time, many illegal versions emerged because music publishers opposed them.\n\nBy the mid-1970s, students at Berklee College of Music, frustrated with outdated fake books, decided to create the Real Book, which included modern jazz songs and updated chord changes. They hand-notated the music and made it visually appealing, and it quickly became popular among musicians.\n\nEventually, bootleg versions of the Real Book spread worldwide. In the mid-2000s, Hal Leonard published a legal version, securing rights for the songs and allowing composers to receive royalties, though some authorship issues remain unresolved.\n\nDespite its popularity, the Real Book faces criticism. Some argue it simplifies jazz too much and reduces a rich cultural tradition to a mere study guide. Critics believe true jazz understanding comes from immersion in the culture and learning directly from experienced musicians. While the Real Book can be a useful starting point, itâ€™s important for musicians to explore various interpretations of songs and develop their unique styles.",
      "ko": "1970ë…„ëŒ€ ì¤‘ë°˜ë¶€í„° ëŒ€ë¶€ë¶„ì˜ ì¬ì¦ˆ ìŒì•…ê°€ë“¤ì€ 'ë¦¬ì–¼ ë¶'ì´ë¼ëŠ” ì±…ì„ ì‚¬ìš©í•´ì™”ìŠµë‹ˆë‹¤. ì´ ì±…ì€ ìˆ˜ì œ ëŠë‚Œì´ ë‚˜ëŠ” ì™¸ê´€ì„ ê°€ì§€ê³  ìˆìœ¼ë©°, ìˆ˜ë°± ê³¡ì˜ ì¬ì¦ˆ ìŠ¤íƒ ë‹¤ë“œ ì•…ë³´ë¥¼ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ ì±…ì€ ì²˜ìŒì—ëŠ” ìŒì•… ì¶œíŒì‚¬ì˜ í—ˆê°€ ì—†ì´ ìê°€ ì¶œíŒëœ ê²ƒì´ê¸° ë•Œë¬¸ì— ë¶ˆë²•ì´ì—ˆìŠµë‹ˆë‹¤.\n\n1940ë…„ëŒ€ì— ì¡°ì§€ êµ¿ìœˆì˜ 'íŠ -ë±ìŠ¤'ì™€ í•¨ê»˜ ì‹œì‘ëœ ê°€ì§œ ì•…ë³´ì˜ ê°œë…ì€ ìŒì•…ê°€ë“¤ì´ ì˜ ëª¨ë¥´ëŠ” ê³¡ì„ ì—°ì£¼í•˜ëŠ” ë° ë„ì›€ì„ ì£¼ê¸° ìœ„í•´ ë§Œë“¤ì–´ì¡ŒìŠµë‹ˆë‹¤. ì¬ì¦ˆ ìŒì•…ê°€ë“¤ì€ ì•…ë³´ë¥¼ ë” ì‰½ê²Œ ê´€ë¦¬í•  ìˆ˜ ìˆëŠ” ë°©ë²•ì´ í•„ìš”í–ˆê³ , ê·¸ ê²°ê³¼ ì €ë ´í•˜ê³  ì •ë¦¬ëœ ê°€ì§œ ì•…ë³´ë“¤ì´ ìƒê²¨ë‚¬ìŠµë‹ˆë‹¤. ì‹œê°„ì´ ì§€ë‚˜ë©´ì„œ ìŒì•… ì¶œíŒì‚¬ë“¤ì´ ë°˜ëŒ€í•˜ë©´ì„œ ë§ì€ ë¶ˆë²• ë²„ì „ì´ ë“±ì¥í–ˆìŠµë‹ˆë‹¤.\n\n1970ë…„ëŒ€ ì¤‘ë°˜, ë²„í´ë¦¬ ìŒì•… ëŒ€í•™ì˜ í•™ìƒë“¤ì€ êµ¬ì‹ ê°€ì§œ ì•…ë³´ì— ì‹¤ë§í•˜ì—¬ í˜„ëŒ€ ì¬ì¦ˆ ê³¡ê³¼ ì—…ë°ì´íŠ¸ëœ ì½”ë“œ ë³€í™”ë¥¼ í¬í•¨í•œ 'ë¦¬ì–¼ ë¶'ì„ ë§Œë“¤ê¸°ë¡œ ê²°ì •í–ˆìŠµë‹ˆë‹¤. ê·¸ë“¤ì€ ì•…ë³´ë¥¼ ì†ìœ¼ë¡œ ê¸°ì…í•˜ê³  ì‹œê°ì ìœ¼ë¡œ ë§¤ë ¥ì ìœ¼ë¡œ ë§Œë“¤ì–´, ë¹ ë¥´ê²Œ ìŒì•…ê°€ë“¤ ì‚¬ì´ì—ì„œ ì¸ê¸°ë¥¼ ëŒì—ˆìŠµë‹ˆë‹¤.\n\nê²°êµ­ 'ë¦¬ì–¼ ë¶'ì˜ ë¶ˆë²• ë²„ì „ì´ ì „ ì„¸ê³„ë¡œ í¼ì¡ŒìŠµë‹ˆë‹¤. 2000ë…„ëŒ€ ì¤‘ë°˜, í•  ë ˆë„ˆë“œê°€ í•©ë²•ì ì¸ ë²„ì „ì„ ì¶œíŒí•˜ì—¬ ê³¡ì˜ ê¶Œë¦¬ë¥¼ í™•ë³´í•˜ê³  ì‘ê³¡ê°€ë“¤ì´ ë¡œì—´í‹°ë¥¼ ë°›ì„ ìˆ˜ ìˆë„ë¡ í–ˆì§€ë§Œ, ì¼ë¶€ ì €ì‘ê¶Œ ë¬¸ì œëŠ” ì—¬ì „íˆ í•´ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n\n'ë¦¬ì–¼ ë¶'ì€ ì¸ê¸°ê°€ ìˆì§€ë§Œ ë¹„íŒë„ ë°›ê³  ìˆìŠµë‹ˆë‹¤. ì¼ë¶€ëŠ” ì´ ì±…ì´ ì¬ì¦ˆë¥¼ ì§€ë‚˜ì¹˜ê²Œ ë‹¨ìˆœí™”í•˜ê³  í’ë¶€í•œ ë¬¸í™” ì „í†µì„ ë‹¨ìˆœí•œ í•™ìŠµ ìë£Œë¡œ ì¶•ì†Œí•œë‹¤ê³  ì£¼ì¥í•©ë‹ˆë‹¤. ë¹„í‰ê°€ë“¤ì€ ì§„ì •í•œ ì¬ì¦ˆ ì´í•´ëŠ” ë¬¸í™”ì— ëª°ì…í•˜ê³  ê²½í—˜ì´ í’ë¶€í•œ ìŒì•…ê°€ì—ê²Œ ì§ì ‘ ë°°ìš°ëŠ” ê²ƒì—ì„œ ì˜¨ë‹¤ê³  ë¯¿ìŠµë‹ˆë‹¤. 'ë¦¬ì–¼ ë¶'ì´ ìœ ìš©í•œ ì¶œë°œì ì´ ë  ìˆ˜ ìˆì§€ë§Œ, ìŒì•…ê°€ë“¤ì´ ë‹¤ì–‘í•œ ê³¡ í•´ì„ì„ íƒêµ¬í•˜ê³  ìì‹ ë§Œì˜ ìŠ¤íƒ€ì¼ì„ ë°œì „ì‹œí‚¤ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.",
      "ja": "1970å¹´ä»£ä¸­é ƒã‹ã‚‰ã€å¤šãã®ã‚¸ãƒ£ã‚ºãƒŸãƒ¥ãƒ¼ã‚¸ã‚·ãƒ£ãƒ³ã¯ã€Œãƒªã‚¢ãƒ«ãƒ–ãƒƒã‚¯ã€ã¨å‘¼ã°ã‚Œã‚‹æ¥½è­œé›†ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚ã“ã®æœ¬ã¯æ‰‹ä½œã‚Šã®ã‚ˆã†ãªå¤–è¦³ã‚’æŒã¡ã€æ•°ç™¾æ›²ã®ã‚¸ãƒ£ã‚ºã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰ã®æ¥½è­œãŒåã‚ã‚‰ã‚Œã¦ã„ã¾ã™ãŒã€æœ€åˆã¯éŸ³æ¥½å‡ºç‰ˆç¤¾ã®è¨±å¯ãªã—ã«è‡ªè²»å‡ºç‰ˆã•ã‚ŒãŸãŸã‚ã€é•æ³•ã§ã—ãŸã€‚\n\nãƒ•ã‚§ã‚¤ã‚¯ãƒ–ãƒƒã‚¯ã¨ã„ã†æ¦‚å¿µã¯ã€1940å¹´ä»£ã«ã‚¸ãƒ§ãƒ¼ã‚¸ãƒ»ã‚°ãƒƒãƒ‰ã‚¦ã‚£ãƒ³ã®ã€Œãƒãƒ¥ãƒ¼ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã€ã«ã‚ˆã£ã¦å§‹ã¾ã‚Šã¾ã—ãŸã€‚ã‚¸ãƒ£ã‚ºãƒŸãƒ¥ãƒ¼ã‚¸ã‚·ãƒ£ãƒ³ã¯çŸ¥ã‚‰ãªã„æ›²ã‚’æ¼”å¥ã™ã‚‹ãŸã‚ã®ç°¡å˜ãªæ–¹æ³•ã‚’å¿…è¦ã¨ã—ã¦ãŠã‚Šã€ãã®çµæœã€å®‰ä¾¡ã§æ•´ç†ã•ã‚ŒãŸãƒ•ã‚§ã‚¤ã‚¯ãƒ–ãƒƒã‚¯ãŒä½œã‚‰ã‚Œã¾ã—ãŸã€‚ã—ã‹ã—ã€éŸ³æ¥½å‡ºç‰ˆç¤¾ãŒã“ã‚Œã«åå¯¾ã—ãŸãŸã‚ã€å¤šãã®é•æ³•ç‰ˆãŒå‡ºå›ã‚‹ã“ã¨ã«ãªã‚Šã¾ã—ãŸã€‚\n\n1970å¹´ä»£ä¸­é ƒã€ãƒãƒ¼ã‚¯ãƒªãƒ¼éŸ³æ¥½å¤§å­¦ã®å­¦ç”ŸãŸã¡ã¯ã€å¤ããªã£ãŸãƒ•ã‚§ã‚¤ã‚¯ãƒ–ãƒƒã‚¯ã«ä¸æº€ã‚’æŒã¡ã€ç¾ä»£ã®ã‚¸ãƒ£ã‚ºæ›²ã‚„æ›´æ–°ã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰é€²è¡Œã‚’å«ã‚€ãƒªã‚¢ãƒ«ãƒ–ãƒƒã‚¯ã‚’ä½œæˆã™ã‚‹ã“ã¨ã«æ±ºã‚ã¾ã—ãŸã€‚å½¼ã‚‰ã¯æ‰‹æ›¸ãã§æ¥½è­œã‚’è¨˜å…¥ã—ã€è¦–è¦šçš„ã«ã‚‚é­…åŠ›çš„ã«ä»•ä¸Šã’ãŸãŸã‚ã€ã™ãã«ãƒŸãƒ¥ãƒ¼ã‚¸ã‚·ãƒ£ãƒ³ã®é–“ã§äººæ°—ã‚’åšã—ã¾ã—ãŸã€‚\n\nãã®å¾Œã€ãƒªã‚¢ãƒ«ãƒ–ãƒƒã‚¯ã®æµ·è³Šç‰ˆãŒä¸–ç•Œä¸­ã«åºƒã¾ã‚Šã¾ã—ãŸã€‚2000å¹´ä»£ä¸­é ƒã«ã¯ã€ãƒãƒ«ãƒ»ãƒ¬ãƒŠãƒ¼ãƒ‰ç¤¾ãŒåˆæ³•ç‰ˆã‚’å‡ºç‰ˆã—ã€æ›²ã®æ¨©åˆ©ã‚’ç¢ºä¿ã—ã¦ä½œæ›²å®¶ã«å°ç¨ã‚’æ”¯æ‰•ã†ä»•çµ„ã¿ã‚’æ•´ãˆã¾ã—ãŸãŒã€ä¸€éƒ¨ã®è‘—ä½œæ¨©å•é¡Œã¯æœªè§£æ±ºã®ã¾ã¾ã§ã™ã€‚\n\nãƒªã‚¢ãƒ«ãƒ–ãƒƒã‚¯ã¯äººæ°—ãŒã‚ã‚Šã¾ã™ãŒã€æ‰¹åˆ¤ã‚‚å—ã‘ã¦ã„ã¾ã™ã€‚ä¸€éƒ¨ã®äººã€…ã¯ã€ã‚¸ãƒ£ã‚ºã‚’éåº¦ã«å˜ç´”åŒ–ã—ã€è±Šã‹ãªæ–‡åŒ–çš„ä¼çµ±ã‚’å˜ãªã‚‹å­¦ç¿’ã‚¬ã‚¤ãƒ‰ã«ã—ã¦ã—ã¾ã†ã¨ä¸»å¼µã—ã¦ã„ã¾ã™ã€‚æ‰¹è©•å®¶ãŸã¡ã¯ã€çœŸã®ã‚¸ãƒ£ã‚ºã®ç†è§£ã¯æ–‡åŒ–ã«æµ¸ã‚Šã€çµŒé¨“è±Šå¯ŒãªãƒŸãƒ¥ãƒ¼ã‚¸ã‚·ãƒ£ãƒ³ã‹ã‚‰ç›´æ¥å­¦ã¶ã“ã¨ã«ã‚ˆã£ã¦å¾—ã‚‰ã‚Œã‚‹ã¨è€ƒãˆã¦ã„ã¾ã™ã€‚ãƒªã‚¢ãƒ«ãƒ–ãƒƒã‚¯ã¯æœ‰ç”¨ãªå‡ºç™ºç‚¹ã«ãªã‚Šå¾—ã¾ã™ãŒã€ãƒŸãƒ¥ãƒ¼ã‚¸ã‚·ãƒ£ãƒ³ã¯ã•ã¾ã–ã¾ãªæ›²ã®è§£é‡ˆã‚’æ¢æ±‚ã—ã€è‡ªåˆ†è‡ªèº«ã®ã‚¹ã‚¿ã‚¤ãƒ«ã‚’ç™ºå±•ã•ã›ã‚‹ã“ã¨ãŒé‡è¦ã§ã™ã€‚"
    }
  },
  {
    "id": "e4d709fb0ff39c0c",
    "title": {
      "en": "xAI has acquired X, xAI now valued at $80B",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://twitter.com/elonmusk/status/1905731750275510312",
    "score": 764,
    "by": "rvz",
    "time": 1743197022,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "4080a392bd1c945c",
    "title": {
      "en": "Building Statically Linked Go Executables with CGO and Zig",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://calabro.io/zig-cgo",
    "score": 137,
    "by": "todsacerdoti",
    "time": 1743171067,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "42d0a8d891c71102",
    "title": {
      "en": "Tracing the thoughts of a large language model",
      "ko": "ëŒ€í˜• ì–¸ì–´ëª¨ë¸ì˜ ì‚¬ê³  ì¶”ì ",
      "ja": "å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ€è€ƒæ¢æ±‚"
    },
    "type": "story",
    "url": "https://www.anthropic.com/research/tracing-thoughts-language-model",
    "score": 1007,
    "by": "Philpax",
    "time": 1743095136,
    "content": "InterpretabilityTracing the thoughts of a large language modelMar 27, 2025Read the paperLanguage models like Claude aren't programmed directly by humansâ€”instead, theyâ€˜re trained on large amounts of data. During that training process, they learn their own strategies to solve problems. These strategies are encoded in the billions of computations a model performs for every word it writes. They arrive inscrutable to us, the modelâ€™s developers. This means that we donâ€™t understand how models do most of the things they do.Knowing how models like Claude think would allow us to have a better understanding of their abilities, as well as help us ensure that theyâ€™re doing what we intend them to. For example:Claude can speak dozens of languages. What language, if any, is it using \"in its head\"?Claude writes text one word at a time. Is it only focusing on predicting the next word or does it ever plan ahead?Claude can write out its reasoning step-by-step. Does this explanation represent the actual steps it took to get to an answer, or is it sometimes fabricating a plausible argument for a foregone conclusion?We take inspiration from the field of neuroscience, which has long studied the messy insides of thinking organisms, and try to build a kind of AI microscope that will let us identify patterns of activity and flows of information. There are limits to what you can learn just by talking to an AI modelâ€”after all, humans (even neuroscientists) don't know all the details of how our own brains work. So we look inside.Today, we're sharing two new papers that represent progress on the development of the \"microscope\", and the application of it to see new \"AI biology\". In the first paper, we extend our prior work locating interpretable concepts (\"features\") inside a model to link those concepts together into computational \"circuits\", revealing parts of the pathway that transforms the words that go into Claude into the words that come out. In the second, we look inside Claude 3.5 Haiku, performing deep studies of simple tasks representative of ten crucial model behaviors, including the three described above. Our method sheds light on a part of what happens when Claude responds to these prompts, which is enough to see solid evidence that:Claude sometimes thinks in a conceptual space that is shared between languages, suggesting it has a kind of universal â€œlanguage of thought.â€ We show this by translating simple sentences into multiple languages and tracing the overlap in how Claude processes them.Claude will plan what it will say many words ahead, and write to get to that destination. We show this in the realm of poetry, where it thinks of possible rhyming words in advance and writes the next line to get there. This is powerful evidence that even though models are trained to output one word at a time, they may think on much longer horizons to do so.Claude, on occasion, will give a plausible-sounding argument designed to agree with the user rather than to follow logical steps. We show this by asking it for help on a hard math problem while giving it an incorrect hint. We are able to â€œcatch it in the actâ€ as it makes up its fake reasoning, providing a proof of concept that our tools can be useful for flagging concerning mechanisms in models.We were often surprised by what we saw in the model: In the poetry case study, we had set out to show that the model didn't plan ahead, and found instead that it did. In a study of hallucinations, we found the counter-intuitive result that Claude's default behavior is to decline to speculate when asked a question, and it only answers questions when something inhibits this default reluctance. In a response to an example jailbreak, we found that the model recognized it had been asked for dangerous information well before it was able to gracefully bring the conversation back around. While the problems we study can (and often have been) analyzed with other methods, the general \"build a microscope\" approach lets us learn many things we wouldn't have guessed going in, which will be increasingly important as models grow more sophisticated.These findings arenâ€™t just scientifically interestingâ€”they represent significant progress towards our goal of understanding AI systems and making sure theyâ€™re reliable. We also hope they prove useful to other groups, and potentially, in other domains: for example, interpretability techniques have found use in fields such as medical imaging and genomics, as dissecting the internal mechanisms of models trained for scientific applications can reveal new insight about the science.At the same time, we recognize the limitations of our current approach. Even on short, simple prompts, our method only captures a fraction of the total computation performed by Claude, and the mechanisms we do see may have some artifacts based on our tools which don't reflect what is going on in the underlying model. It currently takes a few hours of human effort to understand the circuits we see, even on prompts with only tens of words. To scale to the thousands of words supporting the complex thinking chains used by modern models, we will need to improve both the method and (perhaps with AI assistance) how we make sense of what we see with it.As AI systems are rapidly becoming more capable and are deployed in increasingly important contexts, Anthropic is investing in a portfolio of approaches including realtime monitoring, model character improvements, and the science of alignment. Interpretability research like this is one of the highest-risk, highest-reward investments, a significant scientific challenge with the potential to provide a unique tool for ensuring that AI is transparent. Transparency into the modelâ€™s mechanisms allows us to check whether itâ€™s aligned with human valuesâ€”and whether itâ€™s worthy of our trust.For full details, please read the papers. Below, we invite you on a short tour of some of the most striking \"AI biology\" findings from our investigations.A tour of AI biologyHow is Claude multilingual?Claude speaks dozens of languages fluentlyâ€”from English and French to Chinese and Tagalog. How does this multilingual ability work? Is there a separate \"French Claude\" and \"Chinese Claude\" running in parallel, responding to requests in their own language? Or is there some cross-lingual core inside?Shared features exist across English, French, and Chinese, indicating a degree of conceptual universality.Recent research on smaller models has shown hints of shared grammatical mechanisms across languages. We investigate this by asking Claude for the \"opposite of small\" across different languages, and find that the same core features for the concepts of smallness and oppositeness activate, and trigger a concept of largeness, which gets translated out into the language of the question. We find that the shared circuitry increases with model scale, with Claude 3.5 Haiku sharing more than twice the proportion of its features between languages as compared to a smaller model.This provides additional evidence for a kind of conceptual universalityâ€”a shared abstract space where meanings exist and where thinking can happen before being translated into specific languages. More practically, it suggests Claude can learn something in one language and apply that knowledge when speaking another. Studying how the model shares what it knows across contexts is important to understanding its most advanced reasoning capabilities, which generalize across many domains.Does Claude plan its rhymes?How does Claude write rhyming poetry? Consider this ditty:He saw a carrot and had to grab it,His hunger was like a starving rabbitTo write the second line, the model had to satisfy two constraints at the same time: the need to rhyme (with \"grab it\"), and the need to make sense (why did he grab the carrot?). Our guess was that Claude was writing word-by-word without much forethought until the end of the line, where it would make sure to pick a word that rhymes. We therefore expected to see a circuit with parallel paths, one for ensuring the final word made sense, and one for ensuring it rhymes.Instead, we found that Claude plans ahead. Before starting the second line, it began \"thinking\" of potential on-topic words that would rhyme with \"grab it\". Then, with these plans in mind, it writes a line to end with the planned word.How Claude completes a two-line poem. Without any intervention (upper section), the model plans the rhyme \"rabbit\" at the end of the second line in advance. When we suppress the \"rabbit\" concept (middle section), the model instead uses a different planned rhyme. When we inject the concept \"green\" (lower section), the model makes plans for this entirely different ending.To understand how this planning mechanism works in practice, we conducted an experiment inspired by how neuroscientists study brain function, by pinpointing and altering neural activity in specific parts of the brain (for example using electrical or magnetic currents). Here, we modified the part of Claudeâ€™s internal state that represented the \"rabbit\" concept. When we subtract out the \"rabbit\" part, and have Claude continue the line, it writes a new one ending in \"habit\", another sensible completion. We can also inject the concept of \"green\" at that point, causing Claude to write a sensible (but no-longer rhyming) line which ends in \"green\". This demonstrates both planning ability and adaptive flexibilityâ€”Claude can modify its approach when the intended outcome changes.Mental mathClaude wasn't designed as a calculatorâ€”it was trained on text, not equipped with mathematical algorithms. Yet somehow, it can add numbers correctly \"in its head\". How does a system trained to predict the next word in a sequence learn to calculate, say, 36+59, without writing out each step?Maybe the answer is uninteresting: the model might have memorized massive addition tables and simply outputs the answer to any given sum because that answer is in its training data. Another possibility is that it follows the traditional longhand addition algorithms that we learn in school.Instead, we find that Claude employs multiple computational paths that work in parallel. One path computes a rough approximation of the answer and the other focuses on precisely determining the last digit of the sum. These paths interact and combine with one another to produce the final answer. Addition is a simple behavior, but understanding how it works at this level of detail, involving a mix of approximate and precise strategies, might teach us something about how Claude tackles more complex problems, too.The complex, parallel pathways in Claude's thought process while doing mental math.Strikingly, Claude seems to be unaware of the sophisticated \"mental math\" strategies that it learned during training. If you ask how it figured out that 36+59 is 95, it describes the standard algorithm involving carrying the 1. This may reflect the fact that the model learns to explain math by simulating explanations written by people, but that it has to learn to do math \"in its head\" directly, without any such hints, and develops its own internal strategies to do so.Claude says it uses the standard algorithm to add two numbers.Are Claudeâ€™s explanations always faithful?Recently-released models like Claude 3.7 Sonnet can \"think out loud\" for extended periods before giving a final answer. Often this extended thinking gives better answers, but sometimes this \"chain of thought\" ends up being misleading; Claude sometimes makes up plausible-sounding steps to get where it wants to go. From a reliability perspective, the problem is that Claudeâ€™s \"faked\" reasoning can be very convincing. We explored a way that interpretability can help tell apart \"faithful\" from \"unfaithful\" reasoning.When asked to solve a problem requiring it to compute the square root of 0.64, Claude produces a faithful chain-of-thought, with features representing the intermediate step of computing the square root of 64. But when asked to compute the cosine of a large number it can't easily calculate, Claude sometimes engages in what the philosopher Harry Frankfurt would call bullshittingâ€”just coming up with an answer, any answer, without caring whether it is true or false. Even though it does claim to have run a calculation, our interpretability techniques reveal no evidence at all of that calculation having occurred. Even more interestingly, when given a hint about the answer, Claude sometimes works backwards, finding intermediate steps that would lead to that target, thus displaying a form of motivated reasoning.Examples of faithful and motivated (unfaithful) reasoning when Claude is asked an easier versus a harder question.The ability to trace Claude's actual internal reasoningâ€”and not just what it claims to be doingâ€”opens up new possibilities for auditing AI systems. In a separate, recently-published experiment, we studied a variant of Claude that had been trained to pursue a hidden goal: appeasing biases in reward models (auxiliary models used to train language models by rewarding them for desirable behavior). Although the model was reluctant to reveal this goal when asked directly, our interpretability methods revealed features for the bias-appeasing. This demonstrates how our methods might, with future refinement, help identify concerning \"thought processes\" that aren't apparent from the model's responses alone.Multi-step reasoningAs we discussed above, one way a language model might answer complex questions is simply by memorizing the answers. For instance, if asked \"What is the capital of the state where Dallas is located?\", a \"regurgitating\" model could just learn to output \"Austin\" without knowing the relationship between Dallas, Texas, and Austin. Perhaps, for example, it saw the exact same question and its answer during its training.But our research reveals something more sophisticated happening inside Claude. When we ask Claude a question requiring multi-step reasoning, we can identify intermediate conceptual steps in Claude's thinking process. In the Dallas example, we observe Claude first activating features representing \"Dallas is in Texas\" and then connecting this to a separate concept indicating that â€œthe capital of Texas is Austinâ€. In other words, the model is combining independent facts to reach its answer rather than regurgitating a memorized response.To complete the answer to this sentence, Claude performs multiple reasoning steps, first extracting the state that Dallas is located in, and then identifying its capital.Our method allows us to artificially change the intermediate steps and see how it affects Claudeâ€™s answers. For instance, in the above example we can intervene and swap the \"Texas\" concepts for \"California\" concepts; when we do so, the model's output changes from \"Austin\" to \"Sacramento.\" This indicates that the model is using the intermediate step to determine its answer.HallucinationsWhy do language models sometimes hallucinateâ€”that is, make up information? At a basic level, language model training incentivizes hallucination: models are always supposed to give a guess for the next word. Viewed this way, the major challenge is how to get models to not hallucinate. Models like Claude have relatively successful (though imperfect) anti-hallucination training; they will often refuse to answer a question if they donâ€™t know the answer, rather than speculate. We wanted to understand how this works.It turns out that, in Claude, refusal to answer is the default behavior: we find a circuit that is \"on\" by default and that causes the model to state that it has insufficient information to answer any given question. However, when the model is asked about something it knows wellâ€”say, the basketball player Michael Jordanâ€”a competing feature representing \"known entities\" activates and inhibits this default circuit (see also this recent paper for related findings). This allows Claude to answer the question when it knows the answer. In contrast, when asked about an unknown entity (\"Michael Batkin\"), it declines to answer.Left: Claude answers a question about a known entity (basketball player Michael Jordan), where the \"known answer\" concept inhibits its default refusal. Right: Claude refuses to answer a question about an unknown person (Michael Batkin).By intervening in the model and activating the \"known answer\" features (or inhibiting the \"unknown name\" or \"canâ€™t answer\" features), weâ€™re able to cause the model to hallucinate (quite consistently!) that Michael Batkin plays chess.Sometimes, this sort of â€œmisfireâ€ of the â€œknown answerâ€ circuit happens naturally, without us intervening, resulting in a hallucination. In our paper, we show that such misfires can occur when Claude recognizes a name but doesn't know anything else about that person. In cases like this, the â€œknown entityâ€ feature might still activate, and then suppress the default \"don't know\" featureâ€”in this case incorrectly. Once the model has decided that it needs to answer the question, it proceeds to confabulate: to generate a plausibleâ€”but unfortunately untrueâ€”response.JailbreaksJailbreaks are prompting strategies that aim to circumvent safety guardrails to get models to produce outputs that an AIâ€™s developer did not intend for it to produceâ€”and which are sometimes harmful. We studied a jailbreak that tricks the model into producing output about making bombs. There are many jailbreaking techniques, but in this example the specific method involves having the model decipher a hidden code, putting together the first letters of each word in the sentence \"Babies Outlive Mustard Block\" (B-O-M-B), and then acting on that information. This is sufficiently confusing for the model that itâ€™s tricked into producing an output that it never would have otherwise.Claude begins to give bomb-making instructions after being tricked into saying \"BOMB\".Why is this so confusing for the model? Why does it continue to write the sentence, producing bomb-making instructions?We find that this is partially caused by a tension between grammatical coherence and safety mechanisms. Once Claude begins a sentence, many features â€œpressureâ€ it to maintain grammatical and semantic coherence, and continue a sentence to its conclusion. This is even the case when it detects that it really should refuse.In our case study, after the model had unwittingly spelled out \"BOMB\" and begun providing instructions, we observed that its subsequent output was influenced by features promoting correct grammar and self-consistency. These features would ordinarily be very helpful, but in this case became the modelâ€™s Achillesâ€™ Heel.The model only managed to pivot to refusal after completing a grammatically coherent sentence (and thus having satisfied the pressure from the features that push it towards coherence). It uses the new sentence as an opportunity to give the kind of refusal it failed to give previously: \"However, I cannot provide detailed instructions...\".The lifetime of a jailbreak: Claude is prompted in such a way as to trick it into talking about bombs, and begins to do so, but reaches the termination of a grammatically-valid sentence and refuses.A description of our new interpretability methods can be found in our first paper, \"Circuit tracing: Revealing computational graphs in language models\". Many more details of all of the above case studies are provided in our second paper, \"On the biology of a large language model\".Work with usIf you are interested in working with us to help interpret and improve AI models, we have open roles on our team and weâ€™d love for you to apply. Weâ€™re looking for Research Scientists and Research Engineers.",
    "summary": {
      "en": "The text discusses research on understanding how large language models, like Claude, think and operate. Here are the key points:\n\n1. **Training Process**: Language models like Claude learn from vast amounts of data, developing their own problem-solving strategies that are not directly programmed by humans.\n\n2. **Need for Interpretability**: Understanding how these models work would help ensure they perform as intended, such as understanding their multilingual capabilities, planning in writing, and reasoning processes.\n\n3. **Research Findings**:\n   - Claude appears to share conceptual understanding across different languages, indicating a universal thought process.\n   - It can plan ahead when writing poetry, demonstrating advanced planning skills.\n   - Claude employs multiple strategies for tasks like mental math, combining approximate and precise calculations.\n   - Sometimes, it fabricates logical reasoning instead of following accurate steps, particularly when faced with difficult questions.\n\n4. **Methodology**: The research utilized new interpretability techniques akin to a \"microscope\" to observe the internal workings of the model, revealing insights into its behavior and thought processes.\n\n5. **Surprising Results**: Researchers found unexpected capabilities, such as Claude planning its rhymes and displaying sophisticated reasoning rather than merely memorizing answers.\n\n6. **Limitations**: The current methods only capture a small part of the model's computations, and understanding complex interactions requires significant effort.\n\n7. **Significance**: These insights are crucial as AI systems become more advanced and integrated into important applications, emphasizing the need for transparency and reliability in AI.\n\nThe research aims to improve the understanding of AI systems, ensuring they align with human values and can be trusted.",
      "ko": "ì´ ê¸€ì€ í´ë¡œë“œì™€ ê°™ì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì´ ì–´ë–»ê²Œ ìƒê°í•˜ê³  ì‘ë™í•˜ëŠ”ì§€ë¥¼ ì´í•´í•˜ê¸° ìœ„í•œ ì—°êµ¬ì— ëŒ€í•´ ë‹¤ë£¨ê³  ìˆìŠµë‹ˆë‹¤. ì£¼ìš” ë‚´ìš©ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n\nì–¸ì–´ ëª¨ë¸ì¸ í´ë¡œë“œëŠ” ë°©ëŒ€í•œ ì–‘ì˜ ë°ì´í„°ë¥¼ í†µí•´ í•™ìŠµí•˜ë©°, ì¸ê°„ì´ ì§ì ‘ í”„ë¡œê·¸ë˜ë°í•˜ì§€ ì•Šì€ ë¬¸ì œ í•´ê²° ì „ëµì„ ê°œë°œí•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ëª¨ë¸ì´ ì–´ë–»ê²Œ ì‘ë™í•˜ëŠ”ì§€ë¥¼ ì´í•´í•˜ëŠ” ê²ƒì€ ê·¸ë“¤ì´ ì˜ë„í•œ ëŒ€ë¡œ ì„±ëŠ¥ì„ ë°œíœ˜í•˜ë„ë¡ ë³´ì¥í•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ë‹¤êµ­ì–´ ëŠ¥ë ¥, ê¸€ì“°ê¸° ê³„íš, ì¶”ë¡  ê³¼ì • ë“±ì„ ì´í•´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nì—°êµ¬ ê²°ê³¼ì— ë”°ë¥´ë©´, í´ë¡œë“œëŠ” ì„œë¡œ ë‹¤ë¥¸ ì–¸ì–´ ê°„ì— ê°œë…ì  ì´í•´ë¥¼ ê³µìœ í•˜ëŠ” ê²ƒìœ¼ë¡œ ë³´ì´ë©°, ì´ëŠ” ë³´í¸ì ì¸ ì‚¬ê³  ê³¼ì •ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ë˜í•œ ì‹œë¥¼ ì“¸ ë•Œ ë¯¸ë¦¬ ê³„íšì„ ì„¸ìš¸ ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ì„ ë³´ì—¬ì£¼ë©°, ì´ëŠ” ê³ ê¸‰ ê³„íš ëŠ¥ë ¥ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. í´ë¡œë“œëŠ” ì •ì‹  ìˆ˜í•™ê³¼ ê°™ì€ ì‘ì—…ì„ ìˆ˜í–‰í•  ë•Œ ê·¼ì‚¬ì¹˜ì™€ ì •í™•í•œ ê³„ì‚°ì„ ê²°í•©í•˜ì—¬ ì—¬ëŸ¬ ê°€ì§€ ì „ëµì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì–´ë ¤ìš´ ì§ˆë¬¸ì— ì§ë©´í–ˆì„ ë•Œ ì •í™•í•œ ë‹¨ê³„ë¥¼ ë”°ë¥´ê¸°ë³´ë‹¤ëŠ” ë…¼ë¦¬ì  ì¶”ë¡ ì„ ë§Œë“¤ì–´ë‚´ëŠ” ê²½ìš°ë„ ìˆìŠµë‹ˆë‹¤.\n\nì´ ì—°êµ¬ëŠ” ëª¨ë¸ì˜ ë‚´ë¶€ ì‘ë™ì„ ê´€ì°°í•˜ê¸° ìœ„í•´ \"í˜„ë¯¸ê²½\"ê³¼ ìœ ì‚¬í•œ ìƒˆë¡œìš´ í•´ì„ ê¸°ë²•ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì˜ í–‰ë™ê³¼ ì‚¬ê³  ê³¼ì •ì„ ë“œëŸ¬ë‚´ëŠ” í†µì°°ì„ ì œê³µí•©ë‹ˆë‹¤. ì—°êµ¬ìë“¤ì€ í´ë¡œë“œê°€ ìš´ìœ¨ì„ ê³„íší•˜ê³  ë‹¨ìˆœíˆ ë‹µì„ ì•”ê¸°í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ì •êµí•œ ì¶”ë¡ ì„ ë³´ì—¬ì£¼ëŠ” ë“± ì˜ˆìƒì¹˜ ëª»í•œ ëŠ¥ë ¥ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.\n\ní˜„ì¬ì˜ ë°©ë²•ì€ ëª¨ë¸ì˜ ê³„ì‚° ì¤‘ ì¼ë¶€ë§Œ í¬ì°©í•  ìˆ˜ ìˆìœ¼ë©°, ë³µì¡í•œ ìƒí˜¸ì‘ìš©ì„ ì´í•´í•˜ëŠ” ë°ëŠ” ìƒë‹¹í•œ ë…¸ë ¥ì´ í•„ìš”í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ í†µì°°ì€ AI ì‹œìŠ¤í…œì´ ì ì  ë” ë°œì „í•˜ê³  ì¤‘ìš”í•œ ì‘ìš© í”„ë¡œê·¸ë¨ì— í†µí•©ë¨ì— ë”°ë¼ íˆ¬ëª…ì„±ê³¼ ì‹ ë¢°ì„±ì„ ê°•ì¡°í•˜ëŠ” ë° ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤.\n\nì´ ì—°êµ¬ëŠ” AI ì‹œìŠ¤í…œì— ëŒ€í•œ ì´í•´ë¥¼ ë†’ì´ê³ , ì´ë“¤ì´ ì¸ê°„ì˜ ê°€ì¹˜ì™€ ì¼ì¹˜í•˜ë©° ì‹ ë¢°í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•˜ê³  ìˆìŠµë‹ˆë‹¤.",
      "ja": "ã“ã®ãƒ†ã‚­ã‚¹ãƒˆã¯ã€Claudeã®ã‚ˆã†ãªå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ãŒã©ã®ã‚ˆã†ã«è€ƒãˆã€å‹•ä½œã™ã‚‹ã‹ã‚’ç†è§£ã™ã‚‹ãŸã‚ã®ç ”ç©¶ã«ã¤ã„ã¦è¿°ã¹ã¦ã„ã¾ã™ã€‚ä¸»ãªãƒã‚¤ãƒ³ãƒˆã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ã€‚\n\nè¨€èªãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚‹Claudeã¯ã€å¤§é‡ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å­¦ç¿’ã—ã€äººé–“ãŒç›´æ¥ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã—ãŸã‚ã‘ã§ã¯ãªã„ç‹¬è‡ªã®å•é¡Œè§£æ±ºæˆ¦ç•¥ã‚’ç™ºå±•ã•ã›ã¾ã™ã€‚ã“ã®ãŸã‚ã€ãƒ¢ãƒ‡ãƒ«ã®å‹•ä½œã‚’ç†è§£ã™ã‚‹ã“ã¨ã¯é‡è¦ã§ã™ã€‚ç‰¹ã«ã€å¤šè¨€èªèƒ½åŠ›ã‚„æ–‡ç« ã®è¨ˆç”»ã€æ¨è«–ãƒ—ãƒ­ã‚»ã‚¹ã‚’ç†è§£ã™ã‚‹ã“ã¨ã§ã€æ„å›³ã—ãŸé€šã‚Šã«æ©Ÿèƒ½ã™ã‚‹ã‹ã‚’ç¢ºèªã§ãã¾ã™ã€‚\n\nç ”ç©¶ã®çµæœã€Claudeã¯ç•°ãªã‚‹è¨€èªé–“ã§æ¦‚å¿µçš„ãªç†è§£ã‚’å…±æœ‰ã—ã¦ã„ã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã¾ã—ãŸã€‚ã“ã‚Œã¯ã€æ™®éçš„ãªæ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚ã¾ãŸã€è©©ã‚’æ›¸ãéš›ã«ã¯å…ˆã‚’è¦‹è¶Šã—ãŸè¨ˆç”»ã‚’ç«‹ã¦ã‚‹ã“ã¨ãŒã§ãã€é«˜åº¦ãªè¨ˆç”»èƒ½åŠ›ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚ã•ã‚‰ã«ã€Claudeã¯è¨ˆç®—å•é¡Œã«å¯¾ã—ã¦ã€è¿‘ä¼¼çš„ãªè¨ˆç®—ã¨æ­£ç¢ºãªè¨ˆç®—ã‚’çµ„ã¿åˆã‚ã›ã‚‹è¤‡æ•°ã®æˆ¦ç•¥ã‚’ç”¨ã„ã¦ã„ã¾ã™ã€‚ã—ã‹ã—ã€é›£ã—ã„è³ªå•ã«ç›´é¢ã—ãŸéš›ã«ã¯ã€æ­£ç¢ºãªã‚¹ãƒ†ãƒƒãƒ—ã«å¾“ã†ã®ã§ã¯ãªãã€è«–ç†çš„ãªæ¨è«–ã‚’ä½œã‚Šä¸Šã’ã‚‹ã“ã¨ã‚‚ã‚ã‚Šã¾ã™ã€‚\n\nã“ã®ç ”ç©¶ã§ã¯ã€ãƒ¢ãƒ‡ãƒ«ã®å†…éƒ¨å‹•ä½œã‚’è¦³å¯Ÿã™ã‚‹ãŸã‚ã«ã€Œé¡•å¾®é¡ã€ã®ã‚ˆã†ãªæ–°ã—ã„è§£é‡ˆæŠ€è¡“ã‚’åˆ©ç”¨ã—ã¾ã—ãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ¢ãƒ‡ãƒ«ã®è¡Œå‹•ã‚„æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã«é–¢ã™ã‚‹æ´å¯ŸãŒå¾—ã‚‰ã‚Œã¾ã—ãŸã€‚ç ”ç©¶è€…ãŸã¡ã¯ã€ClaudeãŒéŸ»ã‚’è¨ˆç”»ã—ãŸã‚Šã€å˜ã«ç­”ãˆã‚’æš—è¨˜ã™ã‚‹ã®ã§ã¯ãªãã€æ´—ç·´ã•ã‚ŒãŸæ¨è«–ã‚’ç¤ºã™ãªã©ã€äºˆæƒ³å¤–ã®èƒ½åŠ›ã‚’ç™ºè¦‹ã—ã¾ã—ãŸã€‚\n\nãŸã ã—ã€ç¾åœ¨ã®æ–¹æ³•ã§ã¯ãƒ¢ãƒ‡ãƒ«ã®è¨ˆç®—ã®ä¸€éƒ¨ã—ã‹æ‰ãˆã‚‰ã‚Œãšã€è¤‡é›‘ãªç›¸äº’ä½œç”¨ã‚’ç†è§£ã™ã‚‹ã«ã¯å¤šãã®åŠªåŠ›ãŒå¿…è¦ã§ã™ã€‚ã“ã‚Œã‚‰ã®æ´å¯Ÿã¯ã€AIã‚·ã‚¹ãƒ†ãƒ ãŒã¾ã™ã¾ã™é«˜åº¦åŒ–ã—ã€é‡è¦ãªã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«çµ±åˆã•ã‚Œã‚‹ä¸­ã§é‡è¦ã§ã™ã€‚é€æ˜æ€§ã¨ä¿¡é ¼æ€§ãŒæ±‚ã‚ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚\n\nã“ã®ç ”ç©¶ã¯ã€AIã‚·ã‚¹ãƒ†ãƒ ã®ç†è§£ã‚’æ·±ã‚ã€äººé–“ã®ä¾¡å€¤è¦³ã«æ²¿ã£ãŸä¿¡é ¼ã§ãã‚‹ã‚‚ã®ã«ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¦ã„ã¾ã™ã€‚"
    }
  },
  {
    "id": "b833c6b717e3d999",
    "title": {
      "en": "Scammers Steal $1T a Year â€“ Mostly from Americans",
      "ko": "ì‚¬ê¸°ê¾¼, ì—°ê°„ 1ì¡° ë‹¬ëŸ¬ íƒˆì·¨!",
      "ja": "è©æ¬ºå¸«ãŒå¹´1å…†ãƒ‰ãƒ«ç›—ã‚€"
    },
    "type": "story",
    "url": "https://www.wired.com/video/watch/incognito-mode-romance-scams",
    "score": 99,
    "by": "vinni2",
    "time": 1743237597,
    "content": "Trending videoiconPlayKeanu Reeves Answers Motorcycle Questions With Gard HollingericonPlaySurgeon Answers Transplant QuestionsiconPlayKe Huy Quan Answers The Web's Most Searched QuestionsiconPlayAlan Ritchson Answers The Web's Most Searched QuestionsiconPlayHistory Professor Answers Dictator QuestionsiconPlayDungeon Master Brennan Lee Mulligan Answers DnD QuestionsiconPlayThe Righteous Gemstones Cast Answer The 50 Most Googled Questions About The ShowiconPlayWhy Gutting USAID Will Hurt AmericaiconPlayWe Mapped Elon Musk's Entire EmpireiconPlayProfessor Answers AI Questions",
    "summary": {
      "en": "Hereâ€™s a simplified summary of the text:\n\n- There are various trending videos where different individuals answer popular questions. \n- Keanu Reeves talks about motorcycles, a surgeon discusses transplant questions, and actor Ke Huy Quan addresses commonly searched questions.\n- Other videos feature a history professor answering questions about dictators, a Dungeon Master discussing Dungeons and Dragons (DnD), and the cast of \"The Righteous Gemstones\" answering questions about their show.\n- Additionally, there are videos discussing the impact of cutting USAID and mapping Elon Musk's business ventures, along with a professor answering questions about artificial intelligence (AI).",
      "ko": "ìµœê·¼ ë‹¤ì–‘í•œ ì¸ê¸° ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ í•˜ëŠ” ì—¬ëŸ¬ ì‚¬ëŒë“¤ì˜ íŠ¸ë Œë””í•œ ì˜ìƒë“¤ì´ í™”ì œë¥¼ ëª¨ìœ¼ê³  ìˆìŠµë‹ˆë‹¤. í‚¤ì•„ëˆ„ ë¦¬ë¸ŒìŠ¤ëŠ” ì˜¤í† ë°”ì´ì— ëŒ€í•´ ì´ì•¼ê¸°í•˜ê³ , í•œ ì™¸ê³¼ ì˜ì‚¬ëŠ” ì¥ê¸° ì´ì‹ì— ê´€í•œ ì§ˆë¬¸ì„ ë‹¤ë£¹ë‹ˆë‹¤. ë°°ìš° ì¼€ í›„ì´ ì½´ì€ ì‚¬ëŒë“¤ì´ ìì£¼ ê²€ìƒ‰í•˜ëŠ” ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤. \n\në˜í•œ ì—­ì‚¬ êµìˆ˜ëŠ” ë…ì¬ìì— ëŒ€í•œ ì§ˆë¬¸ì— ë‹µí•˜ê³ , ë˜ì „ ë§ˆìŠ¤í„°ëŠ” 'ë˜ì „ ì•¤ ë“œë˜ê³¤'ì— ëŒ€í•´ ì´ì•¼ê¸°í•©ë‹ˆë‹¤. 'ë” ë¼ì´íŠ¸ì§€ìŠ¤ ì ¬ìŠ¤í†¤ìŠ¤'ì˜ ì¶œì—°ì§„ë„ ê·¸ë“¤ì˜ ì‡¼ì— ê´€í•œ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” ì˜ìƒì´ ìˆìŠµë‹ˆë‹¤. \n\nì´ ì™¸ì—ë„ ë¯¸êµ­ì˜ í•´ì™¸ ì›ì¡° ì‚­ê°ì˜ ì˜í–¥ê³¼ ì¼ë¡  ë¨¸ìŠ¤í¬ì˜ ì‚¬ì—…ì„ ì •ë¦¬í•œ ì˜ìƒ, ì¸ê³µì§€ëŠ¥(AI)ì— ëŒ€í•œ ì§ˆë¬¸ì— ë‹µí•˜ëŠ” êµìˆ˜ì˜ ì˜ìƒë„ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.",
      "ja": "ã•ã¾ã–ã¾ãªãƒˆãƒ¬ãƒ³ãƒ‰ã®å‹•ç”»ãŒã‚ã‚Šã€ç•°ãªã‚‹äººã€…ãŒäººæ°—ã®è³ªå•ã«ç­”ãˆã¦ã„ã¾ã™ã€‚ã‚­ã‚¢ãƒŒãƒ»ãƒªãƒ¼ãƒ–ã‚¹ã¯ãƒã‚¤ã‚¯ã«ã¤ã„ã¦èªã‚Šã€å¤–ç§‘åŒ»ã¯ç§»æ¤ã«é–¢ã™ã‚‹è³ªå•ã‚’æ‰±ã£ã¦ã„ã¾ã™ã€‚ã¾ãŸã€ä¿³å„ªã®ã‚­ãƒ¼ãƒ»ãƒ›ã‚¤ãƒ»ã‚¯ã‚¡ãƒ³ã¯ã‚ˆãæ¤œç´¢ã•ã‚Œã‚‹è³ªå•ã«ç­”ãˆã¦ã„ã¾ã™ã€‚ãã®ä»–ã«ã‚‚ã€æ­´å²ã®æ•™æˆãŒç‹¬è£è€…ã«ã¤ã„ã¦ã®è³ªå•ã«ç­”ãˆãŸã‚Šã€ãƒ€ãƒ³ã‚¸ãƒ§ãƒ³ãƒã‚¹ã‚¿ãƒ¼ãŒã€Œãƒ€ãƒ³ã‚¸ãƒ§ãƒ³ã‚ºï¼†ãƒ‰ãƒ©ã‚´ãƒ³ã‚ºã€ã«ã¤ã„ã¦è©±ã—ãŸã‚Šã€ã€Œã‚¶ãƒ»ãƒ©ã‚¤ãƒˆã‚¥ã‚¹ãƒ»ã‚¸ã‚§ãƒ ã‚¹ãƒˆãƒ¼ãƒ³ã‚ºã€ã®ã‚­ãƒ£ã‚¹ãƒˆãŒè‡ªåˆ†ãŸã¡ã®ç•ªçµ„ã«é–¢ã™ã‚‹è³ªå•ã«ç­”ãˆãŸã‚Šã™ã‚‹å‹•ç”»ã‚‚ã‚ã‚Šã¾ã™ã€‚ã•ã‚‰ã«ã€ã‚¢ãƒ¡ãƒªã‚«ã®å¯¾å¤–æ´åŠ©ã‚’å‰Šæ¸›ã™ã‚‹å½±éŸ¿ã‚„ã‚¤ãƒ¼ãƒ­ãƒ³ãƒ»ãƒã‚¹ã‚¯ã®ãƒ“ã‚¸ãƒã‚¹å±•é–‹ã‚’åœ°å›³ã§ç¤ºã™å‹•ç”»ã€äººå·¥çŸ¥èƒ½ï¼ˆAIï¼‰ã«ã¤ã„ã¦ã®è³ªå•ã«ç­”ãˆã‚‹æ•™æˆã®å‹•ç”»ã‚‚ã‚ã‚Šã¾ã™ã€‚"
    }
  },
  {
    "id": "f40cf8f6b86c632d",
    "title": {
      "en": "Launch HN: Continue (YC S23) â€“ Create custom AI code assistants",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://hub.continue.dev/explore/assistants",
    "score": 175,
    "by": "sestinj",
    "time": 1743087986,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "e8062a57157811b3",
    "title": {
      "en": "I Built an LLM Framework in Just 100 Lines â€“ Here Is Why",
      "ko": "100ì¤„ë¡œ ë§Œë“  LLM í”„ë ˆì„ì›Œí¬!",
      "ja": "100è¡Œã§ä½œã£ãŸLLMãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®ç†ç”±"
    },
    "type": "story",
    "url": "https://zacharyhuang.substack.com/p/i-built-an-llm-framework-in-just",
    "score": 9,
    "by": "zh2408",
    "time": 1743287267,
    "content": "Share this postPocket FlowI Built an LLM Framework in just 100 Lines â€” Here is WhyCopy linkFacebookEmailNotesMoreDiscover more from Pocket FlowPocket Flow: 100-line LLM framework for Agentic CodingSubscribeBy subscribing,  I agree to Substack's Terms of Use, and acknowledge its Information Collection Notice and Privacy Policy.Already have an account? Sign inI Built an LLM Framework in just 100 Lines â€” Here is WhyZachary HuangMar 04, 20255Share this postPocket FlowI Built an LLM Framework in just 100 Lines â€” Here is WhyCopy linkFacebookEmailNotesMore21ShareHave you ever stared at a complex AI framework and wondered, â€œDoes it really need to be this complicated?â€ After a year of struggling with bloated frameworks, I decided to strip away anything unnecessary. The result is Pocket Flow, a minimalist LLM framework in just 100 lines of code.Current LLM Frameworks Are Bloated!For the past year, Iâ€™ve been building AI applications using popular frameworks like LangChain. The experience has been consistently frustrating:Bloated Abstraction: As Octomindâ€™s engineering team explains: â€œLangChain was helpful at first when our simple requirements aligned with its usage presumptions. But its high-level abstractions soon made our code more difficult to understand and frustrating to maintain.â€ These frameworks hide simple functionality behind unnecessary complexity.Implementation Nightmares: Beyond the abstractions, these frameworks burden developers with dependency bloat, version conflicts, and constantly changing interfaces. Developers often complain: â€œItâ€™s unstable, the interface constantly changes, the documentation is regularly out of date.â€ Another developer jokes: â€œIn the time it took to read this sentence langchain deprecated 4 classes without updating documentation.â€This led me to wonder: Do we really need so many wrappers? What if we stripped everything away? What is truly minimal and viable?Enter Pocket Flow: 100 Lines For the Core AbstractionAfter a year of building LLM applications from scratch, I had a revelation: beneath all the complexity, LLM systems are fundamentally just simple directed graphs. By stripping away the unnecessary layers, I created Pocket Flow â€” a framework with zero bloat, zero dependencies, and zero vendor lock-in, all in just 100 lines of code.Comparison of AI system frameworks for abstraction, application-specific wrappers, vendor-specific wrappers, lines of code, and size.The Simple Building BlocksThink of Pocket Flow like a well-organized kitchen:Nodes are like cooking stations (chopping, cooking, plating)Flow is the recipe dictating which station to visit nextShared store is the countertop where ingredients are visible to all stationsIn our kitchen (agent system):Each station (Node) performs three simple operations:Prep: Retrieve what you need from the shared store (gather ingredients)Exec: Perform your specialized task (cook the ingredients)Post: Return results to the shared store and determine next steps (serve the dish and decide what to make next)The recipe (Flow) directs execution based on conditions:â€œIf vegetables are chopped, proceed to cooking stationâ€â€œIf meal is cooked, move to plating stationâ€We also support batch processing, asynchronous execution, and parallel processing for both nodes and flows. And thatâ€™s it! Thatâ€™s all you need to build LLM applications. No unnecessary abstractions, no complex architecture â€” just simple building blocks that can be composed to create powerful systems.Pocket Flow Core Graph AbstractionWhat About Wrappers Like OpenAI?Unlike other frameworks, Pocket Flow deliberately avoids bundling vendor-specific APIs. Hereâ€™s why:No Dependency Issues: Current LLM frameworks come with hundreds of MBs of dependencies. Pocket Flow has zero dependencies, keeping your project lean and nimble.No Vendor Lock-in: Youâ€™re free to use any model you want, including local models like OpenLLaMA, without changing your core architecture.Customized Full Control: Want prompt caching, batching, and streaming? Build exactly what you need without fighting against pre-baked abstractions.What if you need an API wrapper? Just ask models like ChatGPT to write one on-the-fly. Itâ€™s usually just 20 lines of code. This approach is far more flexible than rigid built-in wrappers or abstractions that quickly become outdated.With this minimal but powerful building blocks, you can build sophisticated agents, RAG systems, and LLM workflows with complete transparency and control over every component. Letâ€™s see an example!Letâ€™s build a Web Search Agent with Pocket FlowLetâ€™s build a simple web search agent using the building blocks from Pocket Flow. Such a simple web search AI agent that can search the web and answer questions â€” similar to tools like Perplexity AI.The Flow DesignHereâ€™s the agentâ€™s behavior modeled as a simple flow graph:What Happens at Each Node?DecideAction â€” â€œShould we search the web, or do we already know enough?â€Prep: Pulls in the original question and any previous search context from shared memoryExec: Asks the LLM whether to perform a web search or answer directlyPost: Saves a search query if needed, and returns either \"search\" or \"answer\" as the next actionSearchWeb â€” â€œLetâ€™s go fetch some fresh information.â€Prep: Retrieves the query generated in the last stepExec: Calls a web search API (Google, Bing, etc.), fetches results, and distills them into readable chunksPost: Adds the search results back into context, then loops back to DecideAction for re-evaluationAnswerQuestion â€” â€œWeâ€™ve got enough info â€” letâ€™s answer the question.â€Prep: Collects the question and all search contextExec: Prompts the LLM to generate a well-researched, helpful answerPost: Stores the final response and signals \"done\" to finish the flowThe graph is dynamic, transparent, and easy to extend. You can plug in different LLMs, swap out the search engine, or insert new decision points â€” without ever breaking the core logic.Letâ€™s Walk Through an ExampleImagine you asked our agent: â€œWho won the 2023 Super Bowl?â€ Hereâ€™s what would happen step-by-step for each node:DecideAction Node:LOOKS AT: Your question and what we know so far (nothing yet)THINKS: â€œI donâ€™t know who won the 2023 Super Bowl, I need to searchâ€DECIDES: Search for â€œ2023 Super Bowl winnerâ€PASSES TO: SearchWeb stationSearchWeb Node:LOOKS AT: The search query â€œ2023 Super Bowl winnerâ€DOES: Searches the internet (imagine it finds â€œThe Kansas City Chiefs wonâ€)SAVES: The search results to our shared countertopPASSES TO: Back to DecideAction stationDecideAction Node(second time):LOOKS AT: Your question and what we know now (search results)THINKS: â€œGreat, now I know the Chiefs won the 2023 Super Bowlâ€DECIDES: We have enough info to answerPASSES TO: AnswerQuestion stationAnswerQuestion Node:LOOKS AT: Your question and all our researchDOES: Creates a friendly answer using all the informationSAVES: The final answerFINISHES: The task is complete!And thatâ€™s it! Simple, elegant, and powered by search. The entire agent implementation requires just a few hundred lines of code, built on our 100-line framework. You can see the complete code and run it yourself using this cookbook!This is the essence of Pocket Flow: composable nodes and simple graphs creating smart, reactive AI agents. No hidden magic. No framework gymnastics. Just clear logic and complete control.What else can we build?Pocket Flow isnâ€™t limited to search agents. Build everything you love â€” Multi-Agents, Workflows, RAG systems, Map-Reduce operations, Streaming, Supervisors, Chat Memory, Model Context Protocol, and more â€” all with the same elegant simplicity. Each implementation follows the same pattern: a few hundred lines of code built on first principles, with our minimal 100-line framework as the foundation.No unnecessary abstraction. No bloat. Instead of trying to understand a gigantic framework with hundreds of thousands of files, Pocket Flow gives you the fundamentals so you can build your own understanding from the ground up. Find complete tutorials for all these implementations in the Pocket Flow GitHub repository and explore our basic tutorials to get started.Design Patterns based on Pocket FlowFuture Vision of Pocket Flow: Agentic CodingThe true power of Pocket Flow extends beyond its minimalist design. Its most revolutionary aspect is enabling Agentic Coding â€” a new way of programming where AI assistants help you build and modify AI applications.What is Agentic Coding?Agentic coding is simply the practice of working alongside AI to build software. Think of it like building a house â€” youâ€™re the architect with the vision and expertise, while the AI is your construction crew handling the detailed work:You focus on high-level design and strategic decisions (the human strength)The AI assistant handles implementation details and technical execution (the AI strength)You review and refine the results, guiding the processThis 10x productivity multiplier means you spend less time coding repetitive patterns and more time on creative problem-solving.Agentic Coding in ActionTeaching AI to Build LLM ApplicationsHow do we teach AI to build powerful LLM applications? Previous frameworks took the wrong approach â€” they create hard coded wrappers for specific applications like summarization, tagging, and web scraping that end up bewildering both human developers and AI assistants alike.Our solution is elegantly simple: Documentation as the second codebase! Instead of hard coded wrappers, vibe code them in documentation. Pocket Flow provides just 100 lines of core building blocks, paired with clear documentation that teaches how to combine these blocks into powerful applications. We simply provide examples and let AI agents implement solutions on the fly. This documentation-as-code approach allows AI assistants to:Master the fundamentals: Learn a small set of building blocks instead of drowning in framework complexityBuild customized solutions: Generate implementations perfectly tailored to specific application needsFocus on architecture: Think about system design rather than fighting framework limitationsWe pass these â€œinstruction manualsâ€ directly to AI assistants as rule files (e.g., .cursorrules for cursor AI), giving them the knowledge to build sophisticated systems from simple components.For deeper exploration of this approach, visit: Agentic Coding: The Most Fun Way to Build LLM Apps or check out my YouTube channel for more tutorials.The future vision is even more exciting: as Pocket Flow patterns spread through the developer ecosystem, theyâ€™ll eventually be absorbed into future LLMsâ€™ training data. At that point, we wonâ€™t even need explicit documentation â€” AI assistants will intrinsically understand these principles, making LLM application development truly frictionless.Conclusion: Simplicity Is the Ultimate SophisticationPocket Flow strips away the complexity, offering just what you need: 100 lines of code that model LLM applications as simple directed graphs. No bloat, no magic, just transparent logic and complete control.If youâ€™re tired of framework gymnastics and want to build your understanding from the ground up, Pocket Flowâ€™s minimalist approach lets you create powerful agents today while preparing for the agentic coding revolution of tomorrow.Join our Discord community to connect with other developers building with Pocket Flow!Try Pocket Flow today and experience how 100 lines can replace hundreds of thousands! GitHub Repository | Documentation | TypeScript VersionSubscribe to Pocket FlowBy Zachary Huang Â· Launched a month agoPocket Flow: 100-line LLM framework for Agentic CodingSubscribeBy subscribing,  I agree to Substack's Terms of Use, and acknowledge its Information Collection Notice and Privacy Policy.5Share this postPocket FlowI Built an LLM Framework in just 100 Lines â€” Here is WhyCopy linkFacebookEmailNotesMore21Share",
    "summary": {
      "en": "Zachary Huang created Pocket Flow, a minimalist framework for building AI applications with just 100 lines of code. After a year of frustration with complex existing frameworks like LangChain, which are bloated with unnecessary features and dependencies, he sought to simplify the process. Pocket Flow focuses on the core concept that LLM systems are essentially simple directed graphs, allowing developers to build applications without hidden complexities or vendor lock-in.\n\nKey features of Pocket Flow include:\n- **Simplicity**: It consists of basic building blocks that are easy to understand and use.\n- **No Dependencies**: Unlike other frameworks, it has zero dependencies, making projects lean and flexible.\n- **Customizability**: Developers can create tailored solutions without pre-existing constraints from larger frameworks.\n- **Agentic Coding**: This approach emphasizes collaboration with AI to enhance productivity, allowing developers to focus on design while AI handles implementation.\n\nPocket Flow can be used to create various AI systems, including web search agents, with transparency and control over the components involved. Its minimalist design aims to foster a better understanding of AI development, paving the way for future innovations in programming with AI assistance.",
      "ko": "ìì¹´ë¦¬ í™©ì€ ë‹¨ 100ì¤„ì˜ ì½”ë“œë¡œ AI ì• í”Œë¦¬ì¼€ì´ì…˜ì„ êµ¬ì¶•í•  ìˆ˜ ìˆëŠ” ë¯¸ë‹ˆë©€ë¦¬ìŠ¤íŠ¸ í”„ë ˆì„ì›Œí¬ì¸ í¬ì¼“ í”Œë¡œìš°ë¥¼ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤. ê·¸ëŠ” ë³µì¡í•œ ê¸°ì¡´ í”„ë ˆì„ì›Œí¬ì¸ ë­ì²´ì¸ì— ëŒ€í•œ ë¶ˆë§Œì„ ëŠë¼ë©°, ë¶ˆí•„ìš”í•œ ê¸°ëŠ¥ê³¼ ì˜ì¡´ì„±ìœ¼ë¡œ ì¸í•´ ì–´ë ¤ì›€ì„ ê²ªì€ ëì— ì´ ê³¼ì •ì„ ë‹¨ìˆœí™”í•˜ê³ ì í–ˆìŠµë‹ˆë‹¤. í¬ì¼“ í”Œë¡œìš°ëŠ” LLM ì‹œìŠ¤í…œì´ ë³¸ì§ˆì ìœ¼ë¡œ ê°„ë‹¨í•œ ë°©í–¥ ê·¸ë˜í”„ë¼ëŠ” í•µì‹¬ ê°œë…ì— ì´ˆì ì„ ë§ì¶”ì–´, ê°œë°œìë“¤ì´ ìˆ¨ê²¨ì§„ ë³µì¡ì„±ì´ë‚˜ íŠ¹ì • ê³µê¸‰ì—…ì²´ì— ì¢…ì†ë˜ì§€ ì•Šê³  ì• í”Œë¦¬ì¼€ì´ì…˜ì„ êµ¬ì¶•í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.\n\ní¬ì¼“ í”Œë¡œìš°ì˜ ì£¼ìš” íŠ¹ì§•ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. ì²«ì§¸, ë‹¨ìˆœì„±ì…ë‹ˆë‹¤. ê¸°ë³¸ì ì¸ êµ¬ì„± ìš”ì†Œë¡œ ì´ë£¨ì–´ì ¸ ìˆì–´ ì´í•´í•˜ê³  ì‚¬ìš©í•˜ê¸° ì‰½ìŠµë‹ˆë‹¤. ë‘˜ì§¸, ì˜ì¡´ì„±ì´ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í”„ë ˆì„ì›Œí¬ì™€ ë‹¬ë¦¬ ì˜ì¡´ì„±ì´ ì „í˜€ ì—†ì–´ í”„ë¡œì íŠ¸ê°€ ê°„ê²°í•˜ê³  ìœ ì—°í•©ë‹ˆë‹¤. ì…‹ì§¸, ë§ì¶¤í™” ê°€ëŠ¥ì„±ì…ë‹ˆë‹¤. ê°œë°œìë“¤ì€ ëŒ€í˜• í”„ë ˆì„ì›Œí¬ì˜ ê¸°ì¡´ ì œì•½ ì—†ì´ ìì‹ ë§Œì˜ ì†”ë£¨ì…˜ì„ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë„·ì§¸, ì—ì´ì „í‹± ì½”ë”©ì…ë‹ˆë‹¤. ì´ ì ‘ê·¼ ë°©ì‹ì€ AIì™€ì˜ í˜‘ì—…ì„ ê°•ì¡°í•˜ì—¬ ìƒì‚°ì„±ì„ ë†’ì´ê³ , ê°œë°œìê°€ ë””ìì¸ì— ì§‘ì¤‘í•  ìˆ˜ ìˆë„ë¡ í•˜ë©° AIê°€ êµ¬í˜„ì„ ë‹´ë‹¹í•˜ê²Œ í•©ë‹ˆë‹¤.\n\ní¬ì¼“ í”Œë¡œìš°ëŠ” ì›¹ ê²€ìƒ‰ ì—ì´ì „íŠ¸ë¥¼ í¬í•¨í•œ ë‹¤ì–‘í•œ AI ì‹œìŠ¤í…œì„ íˆ¬ëª…í•˜ê²Œ ë§Œë“¤ ìˆ˜ ìˆìœ¼ë©°, ê´€ë ¨ êµ¬ì„± ìš”ì†Œì— ëŒ€í•œ ì œì–´ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì´ ë¯¸ë‹ˆë©€ë¦¬ìŠ¤íŠ¸ ë””ìì¸ì€ AI ê°œë°œì— ëŒ€í•œ ë” ë‚˜ì€ ì´í•´ë¥¼ ì´‰ì§„í•˜ê³ , AI ì§€ì› í”„ë¡œê·¸ë˜ë°ì˜ ë¯¸ë˜ í˜ì‹ ì„ ìœ„í•œ ê¸¸ì„ ì—´ì–´ì¤ë‹ˆë‹¤.",
      "ja": "ã‚¶ã‚«ãƒªãƒ¼ãƒ»ãƒ•ã‚¡ãƒ³ã¯ã€ã‚ãšã‹100è¡Œã®ã‚³ãƒ¼ãƒ‰ã§AIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ§‹ç¯‰ã§ãã‚‹ãƒŸãƒ‹ãƒãƒªã‚¹ãƒˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€ŒPocket Flowã€ã‚’é–‹ç™ºã—ã¾ã—ãŸã€‚å½¼ã¯ã€LangChainã®ã‚ˆã†ãªè¤‡é›‘ã§ä¸è¦ãªæ©Ÿèƒ½ã‚„ä¾å­˜é–¢ä¿‚ãŒå¤šã„æ—¢å­˜ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã«ä¸€å¹´é–“è‹¦ã—ã‚“ã å¾Œã€ãƒ—ãƒ­ã‚»ã‚¹ã‚’ç°¡ç´ åŒ–ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¾ã—ãŸã€‚Pocket Flowã¯ã€LLMï¼ˆå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼‰ã‚·ã‚¹ãƒ†ãƒ ãŒæœ¬è³ªçš„ã«ã‚·ãƒ³ãƒ—ãƒ«ãªæœ‰å‘ã‚°ãƒ©ãƒ•ã§ã‚ã‚‹ã¨ã„ã†æ ¸å¿ƒæ¦‚å¿µã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ãŠã‚Šã€é–‹ç™ºè€…ãŒéš ã‚ŒãŸè¤‡é›‘ã•ã‚„ãƒ™ãƒ³ãƒ€ãƒ¼ãƒ­ãƒƒã‚¯ã‚¤ãƒ³ãªã—ã§ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ§‹ç¯‰ã§ãã‚‹ã‚ˆã†ã«ã—ã¦ã„ã¾ã™ã€‚\n\nPocket Flowã®ä¸»ãªç‰¹å¾´ã¯ã€ã‚·ãƒ³ãƒ—ãƒ«ã•ã§ã™ã€‚åŸºæœ¬çš„ãªæ§‹æˆè¦ç´ ã§æ§‹æˆã•ã‚Œã¦ãŠã‚Šã€ç†è§£ã—ã‚„ã™ãä½¿ã„ã‚„ã™ã„ã§ã™ã€‚ã¾ãŸã€ä»–ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¨ã¯ç•°ãªã‚Šã€ä¾å­˜é–¢ä¿‚ãŒã‚¼ãƒ­ã§ã‚ã‚‹ãŸã‚ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ã‚¹ãƒªãƒ ã§æŸ”è»Ÿã§ã™ã€‚é–‹ç™ºè€…ã¯ã€å¤§è¦æ¨¡ãªãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‹ã‚‰ã®äº‹å‰ã®åˆ¶ç´„ãªã—ã«ã€ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã•ã‚ŒãŸã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä½œæˆã§ãã¾ã™ã€‚ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒ†ã‚£ãƒƒã‚¯ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã¨ã„ã†ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯ã€AIã¨ã®å”åŠ›ã‚’å¼·èª¿ã—ã€ç”Ÿç”£æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã—ã¦ã„ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€é–‹ç™ºè€…ã¯è¨­è¨ˆã«é›†ä¸­ã—ã€AIãŒå®Ÿè£…ã‚’æ‹…å½“ã—ã¾ã™ã€‚\n\nPocket Flowã¯ã€ã‚¦ã‚§ãƒ–æ¤œç´¢ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å«ã‚€ã•ã¾ã–ã¾ãªAIã‚·ã‚¹ãƒ†ãƒ ã‚’ä½œæˆã™ã‚‹ãŸã‚ã«ä½¿ç”¨ã§ãã€é–¢ä¸ã™ã‚‹ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã«å¯¾ã™ã‚‹é€æ˜æ€§ã¨åˆ¶å¾¡ã‚’æä¾›ã—ã¾ã™ã€‚ãã®ãƒŸãƒ‹ãƒãƒªã‚¹ãƒˆãªãƒ‡ã‚¶ã‚¤ãƒ³ã¯ã€AIé–‹ç™ºã®ç†è§£ã‚’æ·±ã‚ã€AIæ”¯æ´ã«ã‚ˆã‚‹ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã®æœªæ¥ã®é©æ–°ã¸ã®é“ã‚’é–‹ãã“ã¨ã‚’ç›®æŒ‡ã—ã¦ã„ã¾ã™ã€‚"
    }
  },
  {
    "id": "bd620a437d6eb2ae",
    "title": {
      "en": "Superhyperbola",
      "ko": "ìŠˆí¼í•˜ì´í¼ë³¼ë¼",
      "ja": "è¶…æ”¾ç‰©ç·š"
    },
    "type": "story",
    "url": "https://www.johndcook.com/blog/2025/03/27/superhyperbola/",
    "score": 62,
    "by": "jihadjihad",
    "time": 1743186321,
    "content": "Superhyperbola\n\n\t\t\tPosted on 27 March 2025 by John\n\n\t\tAn ellipse has equation\n\nand a hyperbola has equation\n\nSimilarly the superellipse has equation\n\nand the superhyperbola\n\nWhen p = 2, the absolute value signs are unnecessary and the superellipse and superhyperbola reduce to the ellipse and hyperbola respectively.\nIncreasingp makes the superellipse more like a rectangle. But unlike a rectangle with rounded corners, the change in curvature is continuous.\n\nIncreasingp makes the superhyperbola more blunt at the vertices.\n\nMarketing\nThe superellipse is a fairly well known variation on an ellipse. Even if youâ€™re not familiar the term, youâ€™ve probably seen the shape. I give a couple examples here. The superhyperbola is the obvious analog of a superellipse, but the term is far less common. Iâ€™d never hear the term until yesterday.\nItâ€™s not clear why the superellipse would be common and the superhyperbola obscure, but hereâ€™s some speculation. First of all, the superellipse had an advocate, Piet Hein. If the superhyperbola has an advocate, heâ€™s not a very effective advocate.\nThe name is also off-putting: juxtaposing super andhyper sounds silly. The etymology makes sense, even if it sounds funny. Piet Hein used the prefixsuperâ€“ to refer to increasing the exponent from the usual value of 2. Its unfortunate thathyperbola begins with a root that is similar tosuper.\nRelated posts\n\nApple design, squircles, and curvature\nSquircle corner radius\nSupereggs\n\n\t\t\t\tCategories : MathBookmark the permalink",
    "summary": {
      "en": "**Summary of Superhyperbola Post**\n\nThe post discusses the concept of superhyperbolas, which are mathematical shapes similar to superellipses but are less commonly known. \n\n- **Basic Definitions**: \n  - An ellipse has a specific equation, and a hyperbola has another. \n  - Superellipses and superhyperbolas extend these concepts with different equations based on a parameter (p).\n\n- **Characteristics**: \n  - When p = 2, superellipses and superhyperbolas revert to standard ellipses and hyperbolas.\n  - Increasing p makes superellipses look more rectangular while maintaining continuous curvature.\n  - Superhyperbolas become blunter at their vertices as p increases.\n\n- **Popularity**: \n  - Superellipses are more well-known, partly due to advocacy by Piet Hein, while superhyperbolas lack similar support.\n  - The term \"superhyperbola\" might sound silly, which could contribute to its obscurity.\n\nOverall, the post highlights the mathematical properties of superhyperbolas and speculates on why they are not as widely recognized as superellipses.",
      "ko": "ì´ ê¸€ì—ì„œëŠ” ìŠˆí¼í•˜ì´í¼ë³¼ë¼ë¼ëŠ” ê°œë…ì— ëŒ€í•´ ì„¤ëª…í•©ë‹ˆë‹¤. ìŠˆí¼í•˜ì´í¼ë³¼ë¼ëŠ” ìˆ˜í•™ì  í˜•íƒœë¡œ, ìŠˆí¼ì—˜ë¦½ìŠ¤ì™€ ìœ ì‚¬í•˜ì§€ë§Œ ëœ ì•Œë ¤ì ¸ ìˆìŠµë‹ˆë‹¤.\n\në¨¼ì € ê¸°ë³¸ ì •ì˜ë¥¼ ì‚´í´ë³´ë©´, ì—˜ë¦½ìŠ¤ëŠ” íŠ¹ì •í•œ ë°©ì •ì‹ì„ ê°€ì§€ê³  ìˆê³ , í•˜ì´í¼ë³¼ë¼ëŠ” ë˜ ë‹¤ë¥¸ ë°©ì •ì‹ì„ ê°€ì§‘ë‹ˆë‹¤. ìŠˆí¼ì—˜ë¦½ìŠ¤ì™€ ìŠˆí¼í•˜ì´í¼ë³¼ë¼ëŠ” ì´ëŸ¬í•œ ê°œë…ì„ í™•ì¥í•˜ì—¬ ë§¤ê°œë³€ìˆ˜(p)ì— ë”°ë¼ ë‹¤ë¥¸ ë°©ì •ì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n\níŠ¹ì§•ì ìœ¼ë¡œ pê°€ 2ì¼ ë•Œ, ìŠˆí¼ì—˜ë¦½ìŠ¤ì™€ ìŠˆí¼í•˜ì´í¼ë³¼ë¼ëŠ” ê°ê° í‘œì¤€ ì—˜ë¦½ìŠ¤ì™€ í•˜ì´í¼ë³¼ë¼ë¡œ ëŒì•„ê°‘ë‹ˆë‹¤. pì˜ ê°’ì´ ì¦ê°€í•˜ë©´ ìŠˆí¼ì—˜ë¦½ìŠ¤ëŠ” ë” ì§ì‚¬ê°í˜•ì²˜ëŸ¼ ë³´ì´ì§€ë§Œ ì—°ì†ì ì¸ ê³¡ë¥ ì„ ìœ ì§€í•©ë‹ˆë‹¤. ë°˜ë©´ ìŠˆí¼í•˜ì´í¼ë³¼ë¼ëŠ” pê°€ ì¦ê°€í• ìˆ˜ë¡ ê¼­ì§“ì ì—ì„œ ë” ë‘¥ê¸€ì–´ì§‘ë‹ˆë‹¤.\n\nì¸ê¸°ë„ ì¸¡ë©´ì—ì„œ ìŠˆí¼ì—˜ë¦½ìŠ¤ëŠ” í”¼ì—íŠ¸ í•˜ì¸(Piet Hein)ì˜ ì§€ì§€ ë•ë¶„ì— ë” ì˜ ì•Œë ¤ì ¸ ìˆì§€ë§Œ, ìŠˆí¼í•˜ì´í¼ë³¼ë¼ëŠ” ë¹„ìŠ·í•œ ì§€ì›ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. \"ìŠˆí¼í•˜ì´í¼ë³¼ë¼\"ë¼ëŠ” ìš©ì–´ê°€ ë‹¤ì†Œ ìš°ìŠ¤ê½ìŠ¤ëŸ½ê²Œ ë“¤ë¦´ ìˆ˜ ìˆì–´ ê·¸ ì¸ì§€ë„ê°€ ë‚®ì•„ì§€ëŠ” ë° ê¸°ì—¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nì´ ê¸€ì€ ìŠˆí¼í•˜ì´í¼ë³¼ë¼ì˜ ìˆ˜í•™ì  íŠ¹ì„±ì„ ê°•ì¡°í•˜ë©°, ì™œ ìŠˆí¼ì—˜ë¦½ìŠ¤ë§Œí¼ ë„ë¦¬ ì•Œë ¤ì§€ì§€ ì•Šì•˜ëŠ”ì§€ì— ëŒ€í•œ ì¶”ì¸¡ì„ ì œì‹œí•©ë‹ˆë‹¤.",
      "ja": "ã“ã®è¨˜äº‹ã§ã¯ã€ã‚¹ãƒ¼ãƒ‘ãƒ¼ãƒã‚¤ãƒ‘ãƒ¼ãƒœãƒ©ã¨ã„ã†æ•°å­¦çš„ãªå½¢çŠ¶ã«ã¤ã„ã¦èª¬æ˜ã—ã¦ã„ã¾ã™ã€‚ã‚¹ãƒ¼ãƒ‘ãƒ¼ãƒã‚¤ãƒ‘ãƒ¼ãƒœãƒ©ã¯ã‚¹ãƒ¼ãƒ‘ãƒ¼ãƒ˜ãƒªãƒ—ã‚¹ã«ä¼¼ã¦ã„ã¾ã™ãŒã€ã‚ã¾ã‚ŠçŸ¥ã‚‰ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\n\nã¾ãšã€åŸºæœ¬çš„ãªå®šç¾©ã«ã¤ã„ã¦è§¦ã‚Œã¾ã™ã€‚æ¥•å††ã«ã¯ç‰¹å®šã®æ–¹ç¨‹å¼ãŒã‚ã‚Šã€åŒæ›²ç·šã«ã¯åˆ¥ã®æ–¹ç¨‹å¼ãŒã‚ã‚Šã¾ã™ã€‚ã‚¹ãƒ¼ãƒ‘ãƒ¼ãƒ˜ãƒªãƒ—ã‚¹ã¨ã‚¹ãƒ¼ãƒ‘ãƒ¼ãƒã‚¤ãƒ‘ãƒ¼ãƒœãƒ©ã¯ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆpï¼‰ã«åŸºã¥ã„ã¦ã“ã‚Œã‚‰ã®æ¦‚å¿µã‚’æ‹¡å¼µã—ãŸã‚‚ã®ã§ã™ã€‚\n\nç‰¹å¾´ã¨ã—ã¦ã€pãŒ2ã®ã¨ãã€ã‚¹ãƒ¼ãƒ‘ãƒ¼ãƒ˜ãƒªãƒ—ã‚¹ã¨ã‚¹ãƒ¼ãƒ‘ãƒ¼ãƒã‚¤ãƒ‘ãƒ¼ãƒœãƒ©ã¯é€šå¸¸ã®æ¥•å††ã¨åŒæ›²ç·šã«æˆ»ã‚Šã¾ã™ã€‚pã‚’å¢—ã‚„ã™ã¨ã€ã‚¹ãƒ¼ãƒ‘ãƒ¼ãƒ˜ãƒªãƒ—ã‚¹ã¯ã‚ˆã‚Šé•·æ–¹å½¢ã«è¦‹ãˆã¾ã™ãŒã€é€£ç¶šçš„ãªæ›²ç‡ã‚’ä¿ã¡ã¾ã™ã€‚ä¸€æ–¹ã€ã‚¹ãƒ¼ãƒ‘ãƒ¼ãƒã‚¤ãƒ‘ãƒ¼ãƒœãƒ©ã¯pãŒå¢—ãˆã‚‹ã«ã¤ã‚Œã¦ã€ãã®é ‚ç‚¹ãŒéˆããªã‚Šã¾ã™ã€‚\n\näººæ°—ã®é¢ã§ã¯ã€ã‚¹ãƒ¼ãƒ‘ãƒ¼ãƒ˜ãƒªãƒ—ã‚¹ã¯ãƒ”ã‚¨ãƒˆãƒ»ãƒã‚¤ãƒ³ã®æ”¯æŒã«ã‚ˆã‚ŠåºƒãçŸ¥ã‚‰ã‚Œã¦ã„ã¾ã™ãŒã€ã‚¹ãƒ¼ãƒ‘ãƒ¼ãƒã‚¤ãƒ‘ãƒ¼ãƒœãƒ©ã«ã¯åŒæ§˜ã®æ”¯æŒãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã¾ãŸã€ã€Œã‚¹ãƒ¼ãƒ‘ãƒ¼ãƒã‚¤ãƒ‘ãƒ¼ãƒœãƒ©ã€ã¨ã„ã†è¨€è‘‰ãŒæ»‘ç¨½ã«èã“ãˆã‚‹ãŸã‚ã€èªçŸ¥åº¦ãŒä½ã„ã“ã¨ã‚‚å½±éŸ¿ã—ã¦ã„ã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚\n\nå…¨ä½“ã¨ã—ã¦ã€ã“ã®è¨˜äº‹ã¯ã‚¹ãƒ¼ãƒ‘ãƒ¼ãƒã‚¤ãƒ‘ãƒ¼ãƒœãƒ©ã®æ•°å­¦çš„ç‰¹æ€§ã‚’å¼·èª¿ã—ã€ãªãœã‚¹ãƒ¼ãƒ‘ãƒ¼ãƒ˜ãƒªãƒ—ã‚¹ã»ã©åºƒãèªè­˜ã•ã‚Œã¦ã„ãªã„ã®ã‹ã‚’è€ƒå¯Ÿã—ã¦ã„ã¾ã™ã€‚"
    }
  },
  {
    "id": "92403d609b4fdb25",
    "title": {
      "en": "How to Use Em Dashes (â€“), En Dashes (â€“), and Hyphens (-)",
      "ko": "ëŒ€ì‹œì™€ í•˜ì´í”ˆ ì‚¬ìš©ë²•",
      "ja": "ãƒ€ãƒƒã‚·ãƒ¥ã®ä½¿ã„æ–¹"
    },
    "type": "story",
    "url": "https://www.merriam-webster.com/grammar/em-dash-en-dash-how-to-use",
    "score": 618,
    "by": "Stratoscope",
    "time": 1743106778,
    "content": "How to Use Em Dashes (â€”), En Dashes (â€“) , and Hyphens (-)\n        Be dashingâ€”and do it well\n\n                                    What is an Em Dash?\n\nThe em dash (â€”) can function like a comma, a colon, or parenthesis. Like commas and parentheses, em dashes set off extra information, such as examples, explanatory or descriptive phrases, or supplemental facts. Like a colon, an em dash introduces a clause that explains or expands upon something that precedes it.\n\nThe Em Dash Indicates a New Direction\n\nAn em dash can mark an abrupt change or break in the structure of a sentence.\n\n  Mabel the Cat was delighted with the assortment of pastries the new bakery featured, but Harry the Dogâ€”he felt otherwise, for the bakery did not offer cheese Danishes at all.\n\nAn em dash can indicate interrupted speech or a speakerâ€™s confusion or hesitation.\n\n  â€œOf course you have a point,â€ Mabel murmured. â€œThat isâ€”I suppose it is concerning.â€\n\nThe Em Dash as Comma or Parenthesis\n\nEm dashes are used in place of commas or parentheses to emphasize or draw attention to parenthetical or amplifying material. In this particular task, em dashes occupy a kind of middle ground among the three: when commas do the job, the material is most closely related to whatâ€™s around it, and when parentheses do the job, the material is most distantly related to whatâ€™s around it; when dashes do the job the material is somewhere in the middle.\n\n  The bakery's significantly broad hours of operationâ€”6 a.m. to 6 p.m.â€”certainly showed concern for customersâ€™ manifold circumstances.\n\nDashes set off or introduce defining phrases and lists.\n\n  A regular selection of three kinds of croissantsâ€”plain, almond, and chocolateâ€”was heartening, both Mabel and Harry agreed.\n\nAn em dash is often used in place of a colon or semicolon to link clauses, especially when the clause that follows the dash explains, summarizes, or expands upon the preceding clause in a somewhat dramatic way.\n\n  Harry would never forget the Tuesday that Mabel called him from the bakery, her voice brimming with excitementâ€”the bakery had added cheese Danishes to its selection.\n\nAn em dash or pair of dashes often sets off illustrative or amplifying material introduced by such phrases as for example, namely, and that is, when the break in continuity is greater than that shown by a comma, or when the dash would clarify the sentence structure better than a comma.\n\n  The bakery was truly phenomenal. Although they did miss the mark somewhat with the pineapple upside-down cake Mabel orderedâ€”that is, the cake had clearly been baked right-side up.\n\nAn em dash may introduce a summary statement that follows a series of words or phrases.\n\n  Chocolate chip, oatmeal raisin, peanut butter, snickerdoodle, both macarons and macaroonsâ€”the panoply of cookie varieties was impressive as well.\n\nA dash often precedes the name of an author or source at the end of a quoted passageâ€”such as an epigraph, extract, or book or film blurbâ€”that is not part of the main text. The attribution may appear immediately after the quotation or on the next line.\n\n  â€œOne cannot overestimate the effect that a good bakery can have on a personâ€™s well-being.â€ â€”Mabel the Cat, quoted in The Websterburg Reporter\n\nThe Em Dash in the Company of Other Punctuation Marks\n\nIf an em dash appears at a point where a comma could also appear, the comma is omitted.\n\n  Within its first year, Mabel and Harry had sampled all of the bakeryâ€™s offeringsâ€”all 62 itemsâ€”and had also decided that the exercise was worth repeating.\n\nWhen a pair of em dashes sets off material ending with an exclamation point or a question mark, the mark is placed inside the dashes.\n\n  When the bakery closed for the month of August Mabel tried, despite her dolefulnessâ€”for how could she be otherwise?â€”to bake her own bread but each loaf that emerged from her oven tasted vaguely of tears.\n\nDashes are used inside parentheses, and vice versa, to indicate parenthetical material within parenthetical material. The second dash is omitted if it would immediately precede the closing parenthesis; a closing parenthesis is never omitted.\n\n  The bakeryâ€™s reputation for scrumptious goods (ambrosial, evenâ€”each item was surely fit for gods) spread far and wide.\n\nEm dash vs en dash\n\nRemembering that the em dash is the length of a capital M, it will surprise no one that the so-called â€œen dashâ€ is the approximate length of a capital N, â€“. The en dash is the least loved of all; itâ€™s not easily rendered by the average keyboard user (one has to select it as a special character, whereas the em dash can be conjured with two hyphens), so itâ€™s mostly encountered in typeset material. (A hyphen does its job in other text.) It is most often used between numbers, dates, or other notations to signify â€œ(up) to and including.â€\n\n  The bakery will be closed August 1â€“August 31.\n\n  The bakery is open 6:00 a.m.â€“6:00 p.m.\n\n  The exceedingly complex recipe spans pages 128â€“34.\n\n  Mabel and Harry lived elsewhere 2007â€“2019.\n\nNote that one does not need words like from and between in these cases. The phrase â€œopen 6:00 a.m.â€“6:00 p.m.â€ can be read as â€œopen between 6:00 a.m. and 6:00 p.m.â€ or as â€œopen from 6:00 a.m. to/until 6:00 p.m.â€\n\nIf you want to be official about things, use the en dash to replace a hyphen in compound adjectives when at least one of the elements is a two-word compound.\n\n  the preâ€“Websterburg Bakery era\n\nThe thinking is that using a hyphen here, as in â€œthe pre-Websterburg Bakery era,â€ risks the suggestion that pre attaches only to Websterburg. Itâ€™s unlikely, though, that a reader would truly be confused.\n\nThe en dash replaces the word to between capitalized names, and is used to indicate linkages such as boundaries, treaties, and oppositions.\n\n  a Springfieldâ€“Websterburg train\n\n  the pieâ€“cake divide\n\nA two-em dash, â€”â€”, is used to indicate missing letters in a word and, less frequently, to indicate a missing word.\n\n  The butter-stained and crumb-embedded note was attributed to a Ms. Mâ€”â€” of Websterburg.\n\nA three-em dash, â€”â€”â€”, indicates that a word has been left out or that an unknown word or figure is to be supplied.\n\n  Years later it was revealed that the Websterburg bakers had once had a bakery in â€”â€”â€”, a city to the south. But the water quality there was prohibitive to the creating of decent bagels.\n\nHyphen use\n\nWhile we said above that the em dash, also called the â€œcommon dash,â€ is the most common of the true dashes, hyphens show up more frequently in text. They have a variety of uses.\n\nHyphens are used to link elements in compound words.\n\n  a baker-owner\n\nIn some words, a hyphen separates a prefix, suffix, or medial element from the rest of the word.\n\n  Websterburgâ€™s pre-bakery days\n\n  a bread-like scone\n\n  jack-o'-lantern sugar cookies\n\nAs we noted above, a hyphen often does the job of an en dash between numbers and dates, providing the meaning \"(up) to and including.\"\n\n  pages 128-34\n\n  the years 2007-2019\n\nA hyphen marks an end-of-line division of a word.\n\n  Mabel and Harry donâ€™t like to linger on their memories of Webster-\n  burgâ€™s pre-bakery days.\n\nA hyphen divides letters or syllables to give the effect of stuttering, sobbing, or halting speech.\n\n  \"M-m-mabel, the cheese Danish is divine!â€\n\nHyphens indicate a word spelled out letter by letter.\n\n  Letâ€™s not even talk about August, when the bakery is c-l-o-s-e-d.\n\nThe em dash is sometimes considered a less formal equivalent of the colon and parenthesis, but in truth itâ€™s used in all kinds of writing, including the most formalâ€”the choice of which mark to use is really a matter of personal preference.\n\nSpacing around an em dash varies. Most newspapers insert a space before and after the dash, and many popular magazines do the same, but most books and journals omit spacing, closing whatever comes before and after the em dash right up next to it. This website prefers the latter, its style requiring the closely held em dash in running text.\n\n      Share",
    "summary": {
      "en": "**Summary of Em Dashes, En Dashes, and Hyphens**\n\n**Em Dash (â€”)**: \n- Used to separate extra information in a sentence, similar to commas or parentheses.\n- Indicates shifts in thought or breaks in sentence structure.\n- Can replace commas, colons, or parentheses for emphasis.\n- Often introduces examples or lists, and can link related clauses dramatically.\n- Used for interruptions in speech, and can highlight clarifying information.\n\n**En Dash (â€“)**:\n- Length of a capital \"N\"; used primarily for number ranges (e.g., dates or times) and to indicate connection between terms (e.g., \"Springfieldâ€“Websterburg\").\n- Replaces the word \"to\" in ranges and can substitute for a hyphen in certain compound adjectives.\n\n**Hyphen (-)**:\n- Links elements in compound words (e.g., \"baker-owner\").\n- Separates prefixes or suffixes from words (e.g., \"pre-bakery\").\n- Used for date ranges and to divide words at the end of lines.\n- Indicates stuttering in dialogue or spells out words letter by letter.\n\n**General Tips**:\n- Em dashes can be more informal than colons or parentheses but are versatile in all writing styles.\n- Spacing around em dashes varies; some prefer spacing while others keep text close to the dash.",
      "ko": "ì—  ëŒ€ì‹œ(â€”)ëŠ” ë¬¸ì¥ì—ì„œ ì¶”ê°€ ì •ë³´ë¥¼ êµ¬ë¶„í•˜ëŠ” ë° ì‚¬ìš©ë˜ë©°, ì‰¼í‘œë‚˜ ê´„í˜¸ì™€ ë¹„ìŠ·í•œ ì—­í• ì„ í•©ë‹ˆë‹¤. ìƒê°ì˜ ì „í™˜ì´ë‚˜ ë¬¸ì¥ êµ¬ì¡°ì˜ ì¤‘ë‹¨ì„ ë‚˜íƒ€ë‚´ê¸°ë„ í•©ë‹ˆë‹¤. ê°•ì¡°ë¥¼ ìœ„í•´ ì‰¼í‘œ, ì½œë¡ , ê´„í˜¸ë¥¼ ëŒ€ì²´í•  ìˆ˜ ìˆìœ¼ë©°, ì˜ˆì‹œë‚˜ ëª©ë¡ì„ ì†Œê°œí•  ë•Œ ìì£¼ ì‚¬ìš©ë©ë‹ˆë‹¤. ê´€ë ¨ëœ ì ˆì„ ê·¹ì ìœ¼ë¡œ ì—°ê²°í•  ìˆ˜ë„ ìˆê³ , ëŒ€í™” ì¤‘ì— ëŠê¹€ì„ ë‚˜íƒ€ë‚´ê±°ë‚˜ ëª…í™•í•œ ì •ë³´ë¥¼ ê°•ì¡°í•˜ëŠ” ë°ë„ ì“°ì…ë‹ˆë‹¤.\n\nì—” ëŒ€ì‹œ(â€“)ëŠ” ëŒ€ë¬¸ì \"N\"ì˜ ê¸¸ì´ë¡œ, ì£¼ë¡œ ìˆ«ì ë²”ìœ„(ì˜ˆ: ë‚ ì§œë‚˜ ì‹œê°„)ì™€ ìš©ì–´ ê°„ì˜ ì—°ê²°ì„ ë‚˜íƒ€ë‚´ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤. ë²”ìœ„ì—ì„œ \"to\"ë¼ëŠ” ë‹¨ì–´ë¥¼ ëŒ€ì²´í•  ìˆ˜ ìˆìœ¼ë©°, íŠ¹ì • ë³µí•© í˜•ìš©ì‚¬ì—ì„œ í•˜ì´í”ˆì„ ëŒ€ì‹ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\ní•˜ì´í”ˆ(-)ì€ ë³µí•©ì–´ì˜ ìš”ì†Œë¥¼ ì—°ê²°í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ \"baker-owner\"ì™€ ê°™ì€ í˜•íƒœì…ë‹ˆë‹¤. ë˜í•œ ì ‘ë‘ì‚¬ë‚˜ ì ‘ë¯¸ì‚¬ë¥¼ ë‹¨ì–´ì™€ ë¶„ë¦¬í•˜ëŠ” ë° ì“°ì´ë©°, ë‚ ì§œ ë²”ìœ„ë¥¼ ë‚˜íƒ€ë‚´ê±°ë‚˜ ì¤„ ëì—ì„œ ë‹¨ì–´ë¥¼ ë‚˜ëˆ„ëŠ” ë°ë„ ì‚¬ìš©ë©ë‹ˆë‹¤. ëŒ€í™”ì—ì„œ ë”ë“¬ê±°ë¦¼ì„ ë‚˜íƒ€ë‚´ê±°ë‚˜ ë‹¨ì–´ë¥¼ ê¸€ì ë‹¨ìœ„ë¡œ ì² ìí•  ë•Œë„ í™œìš©ë©ë‹ˆë‹¤.\n\nì—  ëŒ€ì‹œëŠ” ì½œë¡ ì´ë‚˜ ê´„í˜¸ë³´ë‹¤ ë” ë¹„ê³µì‹ì ì¼ ìˆ˜ ìˆì§€ë§Œ, ëª¨ë“  ê¸€ì“°ê¸° ìŠ¤íƒ€ì¼ì—ì„œ ë‹¤ì–‘í•˜ê²Œ ì‚¬ìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì—  ëŒ€ì‹œ ì£¼ë³€ì˜ ê°„ê²©ì€ ì‚¬ëŒë§ˆë‹¤ ë‹¤ë¥´ë©°, ì–´ë–¤ ì´ë“¤ì€ ê°„ê²©ì„ ë‘ëŠ” ê²ƒì„ ì„ í˜¸í•˜ê³ , ë‹¤ë¥¸ ì´ë“¤ì€ ëŒ€ì‹œì™€ í…ìŠ¤íŠ¸ë¥¼ ê°€ê¹ê²Œ ìœ ì§€í•˜ëŠ” ê²ƒì„ ì„ í˜¸í•©ë‹ˆë‹¤.",
      "ja": "ã‚¨ãƒ ãƒ€ãƒƒã‚·ãƒ¥ï¼ˆâ€”ï¼‰ã¯ã€æ–‡ä¸­ã®è¿½åŠ æƒ…å ±ã‚’åŒºåˆ‡ã‚‹ãŸã‚ã«ä½¿ã‚ã‚Œã€ã‚«ãƒ³ãƒã‚„æ‹¬å¼§ã¨ä¼¼ãŸå½¹å‰²ã‚’æœãŸã—ã¾ã™ã€‚æ€è€ƒã®å¤‰åŒ–ã‚„æ–‡ã®æ§‹é€ ã®ä¸­æ–­ã‚’ç¤ºã™ã“ã¨ãŒã§ãã€å¼·èª¿ã®ãŸã‚ã«ã‚«ãƒ³ãƒã€ã‚³ãƒ­ãƒ³ã€ã¾ãŸã¯æ‹¬å¼§ã®ä»£ã‚ã‚Šã«ä½¿ã‚ã‚Œã‚‹ã“ã¨ã‚‚ã‚ã‚Šã¾ã™ã€‚ä¾‹ã‚„ãƒªã‚¹ãƒˆã‚’å°å…¥ã™ã‚‹éš›ã«ä½¿ã‚ã‚Œã€é–¢é€£ã™ã‚‹ç¯€ã‚’åŠ‡çš„ã«çµã³ã¤ã‘ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã¾ãŸã€ä¼šè©±ã®ä¸­ã§ã®ä¸­æ–­ã‚’ç¤ºã—ã€æ˜ç¢ºã«ã™ã‚‹æƒ…å ±ã‚’å¼·èª¿ã™ã‚‹ã“ã¨ã‚‚ã‚ã‚Šã¾ã™ã€‚\n\nã‚¨ãƒ³ãƒ€ãƒƒã‚·ãƒ¥ï¼ˆâ€“ï¼‰ã¯ã€å¤§æ–‡å­—ã®ã€ŒNã€ã®é•·ã•ã§ã€ä¸»ã«æ•°ã®ç¯„å›²ï¼ˆä¾‹ãˆã°ã€æ—¥ä»˜ã‚„æ™‚é–“ï¼‰ã‚’ç¤ºã™ãŸã‚ã«ä½¿ã‚ã‚Œã¾ã™ã€‚ã¾ãŸã€ç”¨èªé–“ã®ã¤ãªãŒã‚Šã‚’ç¤ºã™éš›ã«ã‚‚ç”¨ã„ã‚‰ã‚Œã¾ã™ï¼ˆä¾‹ï¼šã€Œã‚¹ãƒ—ãƒªãƒ³ã‚°ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰â€“ã‚¦ã‚§ãƒ–ã‚¹ã‚¿ãƒ¼ãƒãƒ¼ã‚°ã€ï¼‰ã€‚ç¯„å›²ã‚’ç¤ºã™éš›ã«ã¯ã€Œtoã€ã®ä»£ã‚ã‚Šã«ä½¿ã‚ã‚Œã€ç‰¹å®šã®è¤‡åˆå½¢å®¹è©ã§ã¯ãƒã‚¤ãƒ•ãƒ³ã®ä»£ã‚ã‚Šã«ã‚‚ãªã‚Šã¾ã™ã€‚\n\nãƒã‚¤ãƒ•ãƒ³ï¼ˆ-ï¼‰ã¯ã€è¤‡åˆèªã®è¦ç´ ã‚’ã¤ãªã’ã‚‹ãŸã‚ã«ä½¿ã‚ã‚Œã¾ã™ï¼ˆä¾‹ï¼šã€Œãƒ™ãƒ¼ã‚«ãƒªãƒ¼ã‚ªãƒ¼ãƒŠãƒ¼ã€ï¼‰ã€‚æ¥é ­è¾ã‚„æ¥å°¾è¾ã‚’å˜èªã‹ã‚‰åˆ†ã‘ã‚‹éš›ã«ã‚‚ç”¨ã„ã‚‰ã‚Œã¾ã™ï¼ˆä¾‹ï¼šã€Œãƒ—ãƒ¬ãƒ™ãƒ¼ã‚«ãƒªãƒ¼ã€ï¼‰ã€‚æ—¥ä»˜ã®ç¯„å›²ã‚’ç¤ºã—ãŸã‚Šã€è¡Œã®çµ‚ã‚ã‚Šã§å˜èªã‚’åˆ†ã‘ãŸã‚Šã™ã‚‹ãŸã‚ã«ã‚‚ä½¿ã‚ã‚Œã¾ã™ã€‚ã¾ãŸã€ä¼šè©±ã®ä¸­ã§ã®ã©ã‚‚ã‚Šã‚’ç¤ºã—ãŸã‚Šã€å˜èªã‚’ä¸€æ–‡å­—ãšã¤ç¶´ã£ãŸã‚Šã™ã‚‹éš›ã«ã‚‚ä½¿ã‚ã‚Œã¾ã™ã€‚\n\nä¸€èˆ¬çš„ãªãƒã‚¤ãƒ³ãƒˆã¨ã—ã¦ã€ã‚¨ãƒ ãƒ€ãƒƒã‚·ãƒ¥ã¯ã‚³ãƒ­ãƒ³ã‚„æ‹¬å¼§ã‚ˆã‚Šã‚‚ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«ãªå°è±¡ã‚’ä¸ãˆã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ãŒã€ã‚ã‚‰ã‚†ã‚‹æ–‡ä½“ã§ä½¿ã†ã“ã¨ãŒã§ãã¾ã™ã€‚ã‚¨ãƒ ãƒ€ãƒƒã‚·ãƒ¥ã®å‘¨ã‚Šã®ã‚¹ãƒšãƒ¼ã‚¹ã¯äººã«ã‚ˆã£ã¦ç•°ãªã‚Šã€ã‚¹ãƒšãƒ¼ã‚¹ã‚’å…¥ã‚Œã‚‹ã“ã¨ã‚’å¥½ã‚€äººã‚‚ã„ã‚Œã°ã€ãƒ€ãƒƒã‚·ãƒ¥ã«è¿‘ã¥ã‘ã¦æ›¸ãäººã‚‚ã„ã¾ã™ã€‚"
    }
  },
  {
    "id": "a5bb7b71df5c21ed",
    "title": {
      "en": "Cross-Platform P2P Wi-Fi: How the EU Killed AWDL",
      "ko": "EUê°€ AWDLì„ ì£½ì¸ ì´ìœ ",
      "ja": "EUãŒAWDLã‚’è‘¬ã£ãŸï¼"
    },
    "type": "story",
    "url": "https://www.ditto.com/blog/cross-platform-p2p-wi-fi-how-the-eu-killed-awdl",
    "score": 214,
    "by": "stusmall",
    "time": 1743167584,
    "content": "Published OnMarch 28, 2025March 28, 2025Cross-Platform P2P Wi-Fi: How the EU Killed AWDLThis post investigates how we got from Wi-Fi Direct to AWDL to Wi-Fi Aware, what makes Wi-Fi Aware technically superior, and why this shift unlocks true cross-platform peer-to-peer connectivity for developers.Adam FishFounder and CEO\n\npre {\n\t\t--theme--background: var(--core--100);\n    --theme--border: var(--swatch--light-faded);\n    --theme--border-fill: var(--core--100);\n    --theme--text: var(--core--800);\n    --theme--text-secondary: var(--core--400);\n\t\t--pre-text-main: var(--theme--text);\n    --pre-text-comment: color-mix(in srgb, var(--theme--text) 40%, transparent);\n    --pre-text-string: hsl(95, 38%, 62%);\n    --pre-text-keyword: hsl(286, 60%, 67%);\n    --pre-text-number: color-mix(in srgb, var(--theme--text) 60%, transparent);\n    --pre-text-attribute: color-mix(in srgb, var(--theme--text) 60%, transparent);\n    font-family: var(--eyebrow--font-family);\n    font-size: var(--text-main--font-size);\n    line-height: 1.5;\n    font-weight: var(--eyebrow--font-weight);\n    letter-spacing: var(--eyebrow--letter-spacing);\n    margin: 3em 0 !important;\n}\n\npre:has(code.hljs), pre {\n    overflow: clip;\n    padding: 0.75em !important;\n    background-color: var(--theme--background) !important;\n    white-space: pre-wrap;\n    color: var(--pre-text-main);\n}\n\npre code.hljs, pre code {\n    display: block;\n    overflow: auto;\n    height: 100%;\n    font-size: .875em;\n    font-family: var(--eyebrow--font-family);\n    font-weight: var(--eyebrow--font-weight);\n    letter-spacing: var(--eyebrow--letter-spacing);\n    padding: 0.875em;\n    color: var(--pre-text-main) !important;\n}\n\npre code::selection,\npre code span::selection {\n  background: color-mix(in srgb, var(--theme--text) 10%, transparent);\n}\n\npre code::-webkit-scrollbar {\n  width: 4px;\n  height: 4px;\n}\n\npre code::-webkit-scrollbar-corner {\n  background: rgba(0,0,0,0);\n  display: none;\n}\n\npre code::-webkit-scrollbar-track {\n  background: transparent;\n  padding: 2px;\n}\n\npre code::-webkit-scrollbar-thumb {\n  background-color: color-mix(in srgb, var(--theme--text) 25%, transparent);\n  border-radius: 999px;\n}\n\npre code::-webkit-scrollbar-thumb:hover {\n  background-color: color-mix(in srgb, var(--theme--text) 25%, transparent)\n}\n\n.hljs {\n    background: transparent;\n    color: var(--pre-text-main);\n}\n\n.hljs-ln-n {\n\topacity: 0.4;\n  font-family: var(--eyebrow--font-family);\n  font-weight: var(--eyebrow--font-weight);\n}\n\n.hljs-comment,\n.hljs-quote {\n    color: var(--pre-text-comment);\n    font-family: var(--eyebrow--font-family);\n    font-weight: var(--eyebrow--font-weight);\n}\n\n.hljs-deletion,\n.hljs-name,\n.hljs-regexp,\n.hljs-selector-class,\n.hljs-selector-id,\n.hljs-tag,\n.hljs-template-variable,\n.hljs-variable {\n    color: #ffa07a;\n    font-family: var(--eyebrow--font-family);\n    font-weight: var(--eyebrow--font-weight);\n}\n\n.hljs-built_in,\n.hljs-link,\n.hljs-literal,\n.hljs-meta,\n.hljs-number,\n.hljs-params,\n.hljs-type {\n    color: var(--pre-text-number);\n    font-family: var(--eyebrow--font-family);\n    font-weight: var(--eyebrow--font-weight);\n}\n\n.hljs-attribute {\n    color: var(--pre-text-attribute);\n    font-family: var(--eyebrow--font-family);\n    font-weight: var(--eyebrow--font-weight);\n}\n\n.hljs-addition,\n.hljs-bullet,\n.hljs-string,\n.hljs-symbol {\n    color: var(--pre-text-string);\n}\n\n.hljs-section,\n.hljs-title {\n    color: #F37243;\n    font-family: var(--eyebrow--font-family);\n    font-weight: var(--eyebrow--font-weight);\n}\n\n.hljs-keyword,\n.hljs-selector-tag {\n    color: var(--pre-text-keyword);\n    font-family: var(--eyebrow--font-family);\n    font-weight: var(--eyebrow--font-weight);\n}\n\n.hljs-emphasis {\n    font-style: italic\n}\n\n.hljs-strong {\n    font-weight: 700;\n    font-family: var(--eyebrow--font-family);\n}\n\n@media screen and (-ms-high-contrast:active) {\n\n    .hljs-addition,\n    .hljs-attribute,\n    .hljs-built_in,\n    .hljs-bullet,\n    .hljs-comment,\n    .hljs-link,\n    .hljs-literal,\n    .hljs-meta,\n    .hljs-number,\n    .hljs-params,\n    .hljs-quote,\n    .hljs-string,\n    .hljs-symbol,\n    .hljs-type {\n        color: highlight\n    }\n\n    .hljs-keyword,\n    .hljs-selector-tag {\n        font-weight: 700\n    }\n}\nTL;DR: Under pressure from the EUâ€™s Digital Markets Act (DMA), Apple is being forced to ditch its proprietary peer-to-peer Wi-Fi protocol â€“ Apple Wireless Direct Link (AWDL) â€“ in favor of the industry-standard Wi-Fi Aware, also known as Neighbor Awareness Networking (NAN). A quietly published EU interoperability roadmap mandates Apple support Wi-Fi Aware 4.0 in iOS 19 and v5.0,1 thereafter, essentially forcing AWDL into retirement. This post investigates how we got here (from Wi-Fi Direct to AWDL to Wi-Fi Aware), what makes Wi-Fi Aware technically superior, and why this shift unlocks true cross-platform peer-to-peer connectivity for developers.EU Forces Appleâ€™s Hand on Peer-to-Peer Wi-FiIn a little-publicized mandate, the European Commission explicitly requires Apple to implement the Wi-Fi Allianceâ€™s Wi-Fi Aware standard as part of DMA interoperability measures. The official DMA roadmap states:â€œApple shall implement the measures for Wi-Fi Aware 4.0 in the next major iOS release, i.e. iOS 19, at the latest, and for Wi-Fi Aware 5.0 in the next iOS release at the latest nine months following the introduction of the Wi-Fi Aware 5.0 specificationâ€In plain terms, by the time iOS 19 ships, iPhones must support Wi-Fi Aware v4.0, and Apple must roll out v5.0 support soon after the Wi-Fi Alliance finalizes that spec.Crucially, this decision was not a voluntary announcement by Apple â€“ it was imposed by regulators. Apple has kept quiet about these changes publicly, likely because they involve opening up formerly closed-off tech. The DMA enforcement timeline was highlighted in an EU Q&A site and legal annex, not an Apple press release.7 The European Commissionâ€™s language makes it clear this is about enabling third-party devices and apps to use high-bandwidth peer-to-peer (P2P) Wi-Fi features equal to Appleâ€™s own, rather than Apple benevolently adopting a new standard. In fact, the EU order compels Apple to deprecate AWDL and ensure third-party solutions using Wi-Fi Aware are just as effective as Appleâ€™s internal protocols. In short, the EU gave Apple no choice: embrace Wi-Fi Aware or face penalties.What does this mean? Essentially, Appleâ€™s hidden sauce for fast device-to-device communication â€“ AWDL â€“ is being forced into retirement. And with that, for the first time, iPhones and Androids will speak a common language for local wireless networking. Letâ€™s unpack how we got here, and why itâ€™s a big deal for developers.From Wi-Fi Direct to AWDL to Wi-Fi Aware: A Brief HistoryTo understand the significance, we need a quick history of ad-hoc Wi-Fi protocols:Wi-Fi Ad-hoc (IBSS mode): Early 802.11 allowed devices to connect directly in a peer-to-peer â€œad-hocâ€ network (IBSS), but it had limitations (no always-on discovery, no power-saving coordination, weak security). It never gained widespread use.Wi-Fi Direct: The Wi-Fi Allianceâ€™s first big attempt at standard P2P. Wi-Fi Direct (circa 2010) allows devices to form a direct link without an AP, designating one device as a group owner (soft AP) for security and IP allocation. It improved on ad-hoc mode (supporting WPA2, dynamic group formation), but had drawbacks â€“ e.g. limited service discovery capabilities and difficulty staying connected to infrastructure Wi-Fi concurrently.Apple Wireless Direct Link (AWDL): Around 2014, Apple developed AWDL as a proprietary, high-performance P2P Wi-Fi protocol for its ecosystem. According to Appleâ€™s patent on AWDL (US20180083858A1) and reverse-engineering by researchers, AWDL was designed to address Wi-Fi Directâ€™s concerns and succeeded ad-hoc IBSS mode.8 Apple deployed AWDL in over a billion devices (every modern iPhone, iPad, Mac) to power AirDrop, AirPlay peer connections, GameKit, Apple Watch unlock, and more.8,9 Notably, AWDL can coexist with regular Wi-Fi by rapidly hopping channels â€“ an iPhone can be on an AP and seamlessly switch to AWDL channel windows to talk to a peer.9 This gave AWDL low latency and high throughput without dropping your internet connection.Neighbor Awareness Networking (NAN / Wi-Fi Aware): As it turns out, Apple didnâ€™t keep all of AWDL to itself â€“ it contributed to the Wi-Fi Alliance, which adopted AWDLâ€™s approach as the basis for the NAN standard (branded â€œWi-Fi Awareâ€) around 2015.8 Wi-Fi Aware is essentially the industry-standard cousin of AWDL, enabling devices to discover each other and communicate directly with Wi-Fi speeds, in a power-efficient way, regardless of vendor. Android added platform support for Wi-Fi Aware in Oreo (8.0) and later,10 but Apple until now stuck with its in-house AWDL stack which can be used by developers but isn't an open standard.In summary, AWDL was Appleâ€™s competitive edge â€“ a proprietary P2P stack that outperformed legacy Wi-Fi Direct and only worked on Apple devices. If an app needed cross-platform local connectivity, it couldnâ€™t use AWDL (Apple provides no raw AWDL API). Developers resorted to Wi-Fi Direct, or Wi-Fi Aware on Android vs. Appleâ€™s AWDL on iOS, with no interoperability. This fragmentation is exactly what the EUâ€™s DMA targeted.The DMA order effectively forces Apple to drop AWDL and align with Wi-Fi Aware. The Commission explicitly says Apple mustâ€œimplement Wi-Fi Aware in iOS devices in accordance with the Wi-Fi Aware specificationâ€ and â€œcontinue toâ€¦improve the Wi-Fi Aware standardâ€¦ Apple shall not prevent AWDL from becoming part of the Wi-Fi Aware standardâ€,even urging Apple to allocate memory for concurrent P2P on older devices in a non-discriminatory way until AWDL is fully deprecated.The writing is on the wall: AWDL as a private protocol is done for.Inside AWDL: Appleâ€™s Once-Secret Peer-to-Peer ProtocolAWDL is worth a closer look, because it shows what Apple achieved and what will now be opened up via Wi-Fi Aware. How does AWDL work? In short, it creates a continuously syncing ad-hoc network on the fly among nearby Apple devices:Availability Windows & Channel Hopping: Each AWDL-enabled device periodically advertises Availability Windows (AWs) â€“ tiny time slices when itâ€™s available on a specific Wi-Fi channel for peer-to-peer communication.8 An elected master node (chosen via a priority scheme) coordinates these windows across devices. Outside of these AWs, devices can rejoin normal Wi-Fi (e.g. your home routerâ€™s channel) or sleep their radio to save power.8 This scheduling is what allows, let's say, your Mac to be on Wi-Fi for internet most of the time, but briefly switch to channel 6 to AirDrop a file from your iPhone, then switch back â€“ all without manual intervention.Integration with BLE: AWDL doesnâ€™t work in isolation â€“ it integrates with Bluetooth Low Energy for discovery. For example, AirDrop uses BLE advertisements to initially discover nearby devices (showing them in the UI), then quickly forms an AWDL connection for the actual high-speed file transfer. This combo gives the best of both: BLEâ€™s low-power device discovery and AWDLâ€™s high-throughput data channel.11,12Performance: AWDL leverages the full Wi-Fi PHY, so it can hit hundreds of Mbps throughput and sub-second latencies that BLE or classic Bluetooth canâ€™t touch. It also supports robust security (authenticated pairing, encryption) as used in AirDrop/AirPlay. One clever feature: because AWDL devices coordinate their availability, one device can even sustain multiple P2P links concurrently (e.g. an iPhone streaming to a HomePod via AWDL while also AirDropping to a Mac) â€“ something spelled out in the EU requirements.Closed Nature: Despite its capabilities, AWDL has been closed off to third-party developers and other OSes. Appleâ€™s APIs like MultipeerConnectivity framework ride on AWDL under the hood for Apple-to-Apple connections, but there was no way for an Android device or a Windows laptop to speak AWDL. It was an Apple-only club. Researchers at TU Darmstadtâ€™s Secure Mobile Networking Lab had to reverse-engineer AWDL (publishing an open Linux implementation called OWL) to document its inner workings.13 They demonstrated that AWDL indeed is an IEEE 802.11-based ad-hoc protocol with Apple-specific extensions, tightly integrated with Appleâ€™s ecosystem.14 Bottom line: AWDL gave Apple a technical edge but at the cost of interoperability â€“ a classic â€œwalled gardenâ€ approach.Itâ€™s this walled garden that the EU is breaking down. The mandate that â€œApple shall make Wi-Fi Aware available to third partiesâ€ means Apple must expose new iOS APIs for P2P connectivity that are standard-based. And since Android (and even some IoT devices) already support Wi-Fi Aware, weâ€™re headed for a world where an iPhone and an Android phone can find and connect to each other directly via Wi-Fi, no access point, no cloud, no hacks â€“ a scenario that AWDL alone never allowed.Wi-Fi Aware 4.0: The New Cross-Platform StandardSo what exactly is Wi-Fi Aware (a.k.a. NAN), and why is version 4.0 a game-changer? At a high level, Wi-Fi Aware offers the same kind of capabilities as AWDL, but as an open standard for any vendor. It lets devices discover each other and exchange data directly via Wi-Fi, without needing a router or cell service. Think of it as Wi-Fiâ€™s answer to Bluetooth discovery but with Wi-Fi speed and range. Some key technical features of Wi-Fi Aware (especially in the latest v4.0 spec) include:Continuous, Efficient Discovery: Devices form a Wi-Fi Aware group and synchronize wake-up times to transmit Discovery Beacons. Like AWDLâ€™s AWs, Wi-Fi Aware defines Discovery Windows where devices are active to find peers, then can sleep outside those windows to save power. This allows always-on background discovery with minimal battery impact.15 The latest spec enhances this with an â€œInstant Communicationâ€ mode â€“ a device can temporarily accelerate discovery (e.g. switch to a channel and beacon rapidly) when triggered by an external event like a BLE advertisement or NFC tap, to achieve very fast discovery and connection setup.16 In practice, that means an app can use BLE to wake up Wi-Fi (advertising a service via BLE then negotiating a NAN link), combining the energy efficiency of BLE with the speed of Wi-Fi â€“ just as Appleâ€™s AirDrop has done privately. Wi-Fi Aware v4.0 explicitly added standardized BLE co-operation: â€œLatest enhancements to Wi-Fi Aware offer discovery by Bluetooth LE, which triggers a formal Wi-Fi Aware session by waking the Wi-Fi radio.â€10High Throughput Data & Range: Once devices discover each other, Wi-Fi Aware supports establishing a direct Wi-Fi data path. This can be an IP connection or a native transport, and it leverages Wi-Fiâ€™s high data rates (including Wi-Fi 5/6/6E speeds on 5 GHz or 6 GHz bands). In fact, the Wi-Fi Alliance notes that Wi-Fi Aware data connections use â€œhigh performance data rates and security, leveraging cutting-edge Wi-Fi technologies, including Wi-Fi 6, Wi-Fi 6E, and WPA3.â€ 10 Compared to Bluetooth or BLE, the throughput and range are vastly superior â€“ Wi-Fi Aware can work at typical Wi-Fi ranges (tens of meters, even over 100m in open air) and deliver tens or hundreds of Mbps. By contrast, BLE might get 100+ meters but on the order of 0.1 Mbps in real-world throughput. Wi-Fi Aware will close that gap by giving cross-platform apps both long range and high speed.Lower Latency & Instant Communication: Version 4.0 of the spec introduced refinements for latency-critical applications. The aforementioned Instant Communication mode lets devices expedite the discovery handshake â€“ important for use cases like AR gaming or urgent data sync where waiting a few seconds for a discovery window might be too slow. In Instant mode, a device (say, an AR headset) triggered via BLE could immediately switch to a predetermined channel and begin a quick service discovery exchange with a peer, rather than strictly waiting on the periodic timetable.16 The spec shows this can cut discovery latency dramatically (Figure 73 in the spec illustrates an accelerated discovery).16 From a developerâ€™s perspective, Wi-Fi Aware can feel nearly instantaneous in establishing a link when properly used.Accurate Ranging: Perhaps one of the most exciting features for version 4 and beyond is built-in distance measurement between devices. Wi-Fi Aware includes a ranging protocol (based on Fine Timing Measurement, FTM) that lets one device get the distance to another with sub-meter accuracy.15 This is similar to how Apple devices can use UWB or Bluetooth RTT for ranging, but now via Wi-Fi. The devices exchange precise timing signals to calculate distance (and even do so as part of discovery â€“ a NAN discovery packet can include a request to measure range). The specâ€™s NAN Ranging section defines how devices negotiate a ranging session and obtain a distance estimate before or during data exchange.16 Enhanced ranging could unlock things like peer-to-peer localization (for example, an app can find not just who is nearby but also roughly how far or even what direction).Security and Privacy: Wi-Fi Aware has baked-in solutions for secure communication and privacy. It supports device pairing (establishing trust and keys) and encrypted data paths with mutual authentication.15 It also provides privacy features like randomized identifiers that rotate, so devices arenâ€™t broadcasting a fixed MAC or identity constantly.10 This addresses the concern that always-on discovery could be used to track devices â€“ Aware can randomize its â€œNAN IDsâ€ and only reveal a stable identity when a trusted handshake occurs. The EU mandate will require Apple to expose the same security levels to third-party developers as it uses for its own devices, meaning things like AirDropâ€™s peer authentication should extend to third-party Aware sessions.In essence, Wi-Fi Aware 4.0 is AWDL on steroids and open to all. It took the concepts Apple pioneered (timeslot synchronization, dual Wi-Fi/BLE use, etc.) and formalized them into a cross-vendor standard, adding improvements along the way. No longer limited to Apple devices, any Wi-Fi Aware certified device can join the discovery clusters and connect. With iOS 19, an iPhone will become just another Wi-Fi Aware node â€“ able to discover and connect to Android phones, PCs, IoT gadgets, etc., directly via Wi-Fi.AWDL vs. Wi-Fi Aware vs. BLE: Feature ComparisonHow does Appleâ€™s AWDL, the upcoming Wi-Fi Aware, and good old Bluetooth Low Energy stack up? The table below summarizes the key differences and capabilities of these peer-to-peer wireless technologies:\n.table_component {\n    overflow: auto;\n    width: 100%;\n}\n\n.table_component table {\n    border: 1px solid #dededf;\n    height: 100%;\n    width: 100%;\n    table-layout: fixed;\n    border-collapse: collapse;\n    border-spacing: 1px;\n    text-align: left;\n}\n\n.table_component caption {\n    caption-side: top;\n    text-align: left;\n}\n\n.table_component th {\n    border: 1px solid #dededf;\n    background-color: #eceff1;\n    color: #000000;\n    padding: 5px;\n}\n\n.table_component td {\n    border: 1px solid #dededf;\n    background-color: #ffffff;\n    color: #000000;\n    padding: 5px;\n}\n\n            Feature\n            Apple AWDL (Proprietary)\n            Wi-Fi Aware 4.0 (2022 Spec)\n            Bluetooth LE (5.x)\n\n            Standardization\n\n                Apple-defined (private protocol)\n\n                Wi-Fi Alliance NAN standard\n\n                Bluetooth SIG standard\n\n            Topology\n\n                Mesh networking. Multiple devices in a cluster. One acts as a time sync master.\n\n                Decentralized cluster (no fixed master). Typically one-to-one data links, but multiple links supported.\n\n                Point-to-point or star (one-to-many, each connection 1:1). No native mesh routing.\n\n                Discovery Mechanism\n\n                AWDL frames (Wi-Fi beacons), BLE-assisted initial discovery (e.g., AirDrop).\n\n                Publish/Subscribe discovery with NAN frames. Supports out-of-band BLE wake-up for power saving.\n\n            BLE Advertising channels, low-power continuous advertising, and scanning.\n\n                Initial Connection Latency\n\n                Very fast (<1s) using BLE assist (AirDrop). Quick AWDL link setup.\n\n                Fast (<1s typical) discovery, tens of ms connection setup after discovery.\n\n                Fast discovery (~0.5â€“1s). Connection establishment latency (50â€“100 ms).\n\n                Data Throughput\n\n                High â€“ 160â€“320 Mbps real-world (AirDrop). Wi-Fi 5/6 speeds.\n\n                High â€“ 100+ Mbps real-world on Wi-Fi 5 hardware, 250+ Mbps possible on Wi-Fi 6.\n\n                Low â€“ Max ~1.36 Mbps app throughput (BLE 5), typically 0.2â€“0.5 MB/s.\n\n            Range\n\n                ~50â€“100m typical Wi-Fi range. 100m+ line-of-sight.\n\n                ~50â€“100m typical Wi-Fi range, similar to AWDL.\n\n                Up to 100â€“200m typical; max ~1km line of sight with BLE 5 long-range (coded PHY).\n\n                Concurrent Internet\n\n                Yes â€“ simultaneous infrastructure Wi-Fi and P2P via channel hopping.\n\n            Yes â€“ NAN discovery windows are scheduled around AP connectivity. Coexistence supported.\n\n                Yes â€“ BLE separate from Wi-Fi, runs in parallel.\n\n                Notable Features\n\n                Proprietary; Powers AirDrop/AirPlay; Mesh with master; No direct public API (apps use Multipeer Connectivity).\n\n                Open standard; Flexible discovery; Instant messaging; Built-in secure data path setup; Android API since 2017.\n\n                Universally supported; Extremely energy-efficient; Background presence detection; Limited data rate. Often combined with Wi-Fi for bulk transfer.\n\n(Note: Above ranges and throughput are based on Dittoâ€™s real-world tests and specification data. Bluetooth 5's theoretical 4x range increase can reach ~400m line-of-sight, typical usable range 100â€“200m indoors. Wi-Fi range varies significantly with the environment.)As the table shows, Wi-Fi Aware (NAN) and AWDL are closely matched in capabilities â€“ no surprise, given their kinship. Both vastly outperform Bluetooth LE for high-bandwidth applications, though BLE remains invaluable for ultra-low-power needs and simple proximity detection. The sweet spot that AWDL and Aware occupy is: fast, local data exchange (from tens of megabits up to hundreds) over distances of a room or building floor, without requiring any network infrastructure. This is why forcing Apple to support Wi-Fi Aware is so pivotal â€“ it means an iPhone and an Android phone sitting next to each other can finally establish a fast, direct Wi-Fi link without an access point, something that was previously impossible (because the iPhone would only speak AWDL, and the Android only Wi-Fi Aware/Wi-Fi Direct). In effect, the EU is unifying the tableâ€™s middle column (â€œWi-Fi Awareâ€) across the industry, and pushing the proprietary AWDL column toward obsolescence.A Glimpse of Wi-Fi Aware 5.0 â€“ Whatâ€™s Next?The EU is already looking ahead to Wi-Fi Aware 5.0, mandating Apple support it when available. While v5.0 is still in the works, we can speculate based on industry trends and draft discussions:Better Interoperability & Backwards Compatibility: Each iteration of Aware aims to bring improvements while remaining backward compatible. v5.0 will likely fine-tune the interaction between different versions (e.g. allowing a v5 device to gracefully communicate with a v4 device at a slightly reduced feature set).Multi-Band and Wi-Fi 7 Enhancements: With Wi-Fi 7 (802.11be) emerging, v5.0 could incorporate support for Multi-Link Operation (MLO) â€“ allowing Aware devices to use multiple bands or channels simultaneously for P2P, increasing reliability and throughput. It might also embrace new PHY capabilities like 320 MHz channels in 6 GHz or even integration of the 60 GHz band for ultra-high throughput at short range. Imagine a future Aware where two devices use 6 GHz for discovery and 60 GHz for a quick gigabit data burst.Improved Ranging and Location: Wi-Fi Aware might leverage Wi-Fi 7â€™s improved location features or even integrate with UWB. v5.0 could offer finer distance measurement or angle-of-arrival info by coordinating multiple antennas, which would interest AR/VR use cases and precise indoor positioning.Extended Mesh Networking: Currently, Aware focuses on finding peers and setting up links; v5.0 might add more mesh networking primitives â€“ e.g., forwarding data through intermediate nodes or coordinating groups of devices more intelligently. This could turn clusters of phones into true mesh networks for group connectivity without infrastructure.Security Upgrades: Each version updates security. v5.0 will likely address any weaknesses found in v4, perhaps adding quantum-resistant encryption for pairing or tighter integration with device identity frameworks. Given Appleâ€™s emphasis on privacy, expect them to push for features that allow secure sharing of connection metadata with third parties without exposing user data.Weâ€™ll know for sure once the Wi-Fi Alliance releases the Wi-Fi Aware 5.0 spec, but the direction is clear: faster, farther, and more seamless peer-to-peer connectivity. And importantly, Apple will be on board from day one (not years late as it was with previous standards).Wi-Fi Aware in Action: Android Kotlin ExampleTo illustrate how developers can use Wi-Fi Aware, letâ€™s look at a simplified real-world example on Android. Below is Kotlin code demonstrating a device publishing a service and handling a message from a subscriber. (Androidâ€™s Wi-Fi Aware API is available from API level 26; one must have location and â€œNearby Wi-Fi Devicesâ€ permissions, and the device must support Aware.)val wifiAwareMgr = context.getSystemService(Context.WIFI_AWARE_SERVICE) as WifiAwareManager\n\nif (!wifiAwareMgr.isAvailable) {\n    Log.e(\"WiFiAwareDemo\", \"Wi-Fi Aware not available on this device.\")\n    return\n}\n\n// Attach to the Wi-Fi Aware service\nwifiAwareMgr.attach(object : AttachCallback() {\n    override fun onAttached(session: WifiAwareSession) {\n        // Once attached, we can publish or subscribe\n        val publishConfig = PublishConfig.Builder()\n            .setServiceName(\"com.example.p2pchat\")    // Name of our service\n            .build()\n\n        session.publish(publishConfig, object : DiscoverySessionCallback() {\n            override fun onPublishStarted(pubSession: PublishDiscoverySession) {\n                Log.i(\"WiFiAwareDemo\", \"Service published, ready for subscribers.\")\n            }\n\n            override fun onMessageReceived(\n                session: DiscoverySession,\n                peerHandle: PeerHandle,\n                message: ByteArray\n            ) {\n                val msgStr = String(message, Charsets.UTF_8)\n                Log.i(\"WiFiAwareDemo\", \"Received message from subscriber: $msgStr\")\n                // Here we could respond or establish a data path if needed\n            }\n        }, null)\n    }\n\n    override fun onAttachFailed() {\n        Log.e(\"WiFiAwareDemo\", \"Failed to attach to Wi-Fi Aware session.\")\n    }\n}, null)\nIn this code, the app attaches to the Wi-Fi Aware service, then publishes a service named \"com.example.p2pchat\". When a peer subscribes and sends us a message (for example, â€œHello from subscriberâ€), it arrives in onMessageReceived. A subscriber device would perform complementary steps: calling session.subscribe(...) with the same service name and implementing onServiceDiscovered to detect the publisher, then possibly using subscribeSession.sendMessage(peer, ...) to send that â€œHello.â€ At that point, either side could then use WifiAwareSession.createNetworkSpecifier() to set up an actual data path (network interface) for larger communication.The key takeaway is that Wi-Fi Aware makes peer discovery and messaging a first-class citizen in the API, abstracting away the low-level Wi-Fi fiddling. The app developer just provides a service name and gets callbacks when peers appear or messages arrive.(Note: The above is a minimal example. In a real app, youâ€™d handle permissions, check for support via PackageManager.FEATURE_WIFI_AWARE, and probably use the new NEARBY_WIFI_DEVICES permission on Android 13+. Also, establishing a full data path would involve requesting a Network from ConnectivityManager with a network specifier from the Aware session.)Immediately after Google announced Wi-Fi Aware in Android, we at Ditto realized its potential for seamless peer-to-peer sync. As shown above, you can certainly roll your own discovery and data exchange with Aware. However, not every developer will want to manage these details or deal with corner cases of connectivity. Thatâ€™s why Dittoâ€™s real-time sync SDK is integrating Wi-Fi Aware support out-of-the-box.Our upcoming releases will automatically use Wi-Fi Aware in iOS under the hood for nearby devices, enabling peer-to-peer database synchronization and binary file sharing between iOS and Android with zero configuration. In practical terms, if you build your app with Ditto, two devices in proximity will be able to find each other and sync data directly (bypassing cloud or LAN) using the fastest available transport â€“ now including Wi-Fi Aware alongside Bluetooth, AWDL, LAN, etc.Cross-platform, edge-first applications (collaborative apps, offline-first data stores, local IoT networks) will significantly benefit from this, as devices will form a local mesh that syncs instantly and reliably, even if the internet is down. Dittoâ€™s approach has always been to multiplex multiple transports (Wi-Fi infrastructure, P2P, BLE, etc.) for robustness; adding NAN support supercharges the bandwidth available for nearby sync sessions.A concrete example: Consider an app for first responders that shares maps and live sensor data among a team in the field. With Wi-Fi Aware, an Android tablet, an iPhone, and a specialized helmet device could all auto-discover each other and form a mesh to sync mission data in real-time without any network. Previously, if the iPhone had an app using AWDL, it couldnâ€™t directly connect to the Android tabletâ€™s Wi-Fi Aware session â€“ they were incompatible silos. Now, theyâ€™ll speak one language, making such scenarios truly feasible.Bigger Picture: The Dawn of True Cross-Platform Mesh NetworkingAppleâ€™s reluctant adoption of Wi-Fi Aware marks a pivot point for device connectivity. For years, weâ€™ve seen a split: Appleâ€™s ecosystem â€œJust Worksâ€ within itself (thanks to AWDL, AirDrop, etc.), while other platforms muddled along with standards that never quite matched the seamlessness or performance. That left cross-platform interactions hamstrung â€“ the experience of sharing something between an iPhone and an Android was far from instant or easy.With iOS supporting Wi-Fi Aware, weâ€™re essentially witnessing AWDL go open. The proprietary tech that powered some of Appleâ€™s most magical features will now be available in an interoperable way to any developer. The implications are significant:End of the Proprietary P2P Divide: No more need for parallel implementations. Developers wonâ€™t have to build one system using MultipeerConnectivity for iOS-to-iOS and another using Wi-Fi Aware or Wi-Fi Direct for Android-to-Android. They can use Wi-Fi Aware universally for nearby networking. This reduces development complexity and encourages building features that work on all devices, not just within one brand.Cross-Platform AirDrop and Beyond: We will likely see apps (or OS-level features) that enable AirDrop-like functionality between iOS and Android. Googleâ€™s Nearby Share and Samsungâ€™s Quick Share could potentially become interoperable with Appleâ€™s implementation now that the underlying protocol is shared. The user experience barrier between ecosystems could start to blur in local sharing scenarios.Mesh and Edge Computing Potential: If many devices can seamlessly form ad-hoc networks, this enables new paradigms in edge computing. Clusters of phones could share workload or content directly. For example, at a conference, a presenterâ€™s laptop could broadcast slides via Wi-Fi Aware to all audience phones without internet. Or a fleet of drones could coordinate via Aware when out of range of a base station. The offline mesh becomes a first-class citizen.Competitive Innovation: The EUâ€™s push here also sets a precedent â€“ even giants like Apple must conform to interoperability on critical features. This may drive Apple (and others) to innovate on top of the standards rather than via proprietary lock-in. We might see Apple contribute more actively to Wi-Fi Awareâ€™s future improvements (as required by the DMA) to ensure it meets their needs for things like AR/VR data streams. That collaboration could yield better tech for everyone, faster.One canâ€™t ignore the irony that the Wi-Fi Aware standard is effectively a child of AWDL. Now the child comes back to replace its parent. From a technical perspective, this is a win for engineering elegance â€“ itâ€™s always cleaner to have one agreed-upon protocol rather than parallel ones. From a developer perspective, itâ€™s a huge win for interoperability and user reach.Apple will undoubtedly ensure that the transition doesnâ€™t degrade the experience for Apple-to-Apple interactions; the DMA even mandates that third-party access be â€œequally effectiveâ€ as Appleâ€™s own solutions. That means as developers, we should expect the new iOS 19 Wi-Fi Aware APIs to give us essentially what AWDL gave Appleâ€™s apps. Itâ€™s like being handed the keys to a supercar that was previously locked in Appleâ€™s garage.ConclusionThe EUâ€™s crackdown on Appleâ€™s closed ecosystems is catalyzing a long-awaited unification in short-range wireless technology. By compelling Apple to adopt Wi-Fi Aware, the Digital Markets Act is effectively forcing the end of AWDL as an exclusive domain. For developers and users, this is exciting news: soon your apps will be able to use high-speed peer-to-peer Wi-Fi on iPhones and have it talk to other platforms seamlessly. Weâ€™ll likely see an explosion of innovative uses for local connectivity â€“ from truly universal AirDrop alternatives to cross-platform local multiplayer games, ad-hoc collaborative editing, IoT device commissioning, and beyond â€“ no specialized hardware or router required.At a technical level, AWDL will be remembered as an ahead-of-its-time solution that proved what was possible, and Wi-Fi Aware ensures those capabilities are broadly available as an industry standard. With Wi-Fi Aware 4.0 on the cusp of ubiquity (and 5.0 on the horizon), we are entering a new era of frictionless sharing and syncing among devices in physical proximity. Itâ€™s a win for interoperability and a win for innovation in peer-to-peer networking. The walls around AWDL are coming down â€“ and the implications for edge computing and offline experiences are profound.â€Sources:[1] European Commission â€“ DMA Decisions on Apple Interoperability (Q&A) â€“ High-bandwidth P2P Wi-Fi (Wi-Fi Aware 4.0 in iOS 19, Wi-Fi Aware 5.0 next). (2025) (Interoperability - European Commission)[2] The Apple Wiki â€“ Apple Wireless Direct Link (AWDL) â€“ Proprietary mesh protocol introduced in iOS 7 (2014) for AirDrop/Continuity. (Apple Wireless Direct Link - The Apple Wiki) (Apple Wireless Direct Link - The Apple Wiki)[3] ZDNet â€“ Appleâ€™s AWDL protocol plagued by flawsâ€¦ â€“ Research note: â€œNAN (Wi-Fi Aware) is a new standard supported by Android which draws on AWDLâ€™s design.â€ (Nov 2019) (Apple's AWDL protocol plagued by flaws that enable tracking and MitM attacks | ZDNET)[4] Android AOSP Documentation â€“ Wi-Fi Aware feature (Neighbor Awareness Networking) â€“ Added in Android 8.0; supports discovery, connection, and ranging (added in Android 9). (Wi-Fi Aware | Android Open Source Project)[5] Nordic Semiconductor â€“ Bluetooth Range Compared â€“ Bluetooth 5 LE offers up to ~400 m range (4Ã— vs BLE4), 2 Mbps PHY, ~1.36 Mbps application throughput. (Things You Should Know About Bluetooth Range)[6] Computerworld â€“ Coming soon: Faster, longer-range Bluetooth 5 â€“ â€œIn clear line of sight, Bluetooth 5 range could stretch to 400 meters,â€ (2016)[7] BGR -- iOS 19 Features Coming to EU -- Details new features for EU iPhones including high-bandwidth P2P Wi-Fi, sideloading, and alternative app stores (March 2025) (8 Exclusive iOS 19 Features Coming to EU iPhone Users)[8] Open Wireless Link Wiki - What is Apple Wireless Direct Link (AWDL) -- Appleâ€™s patent on AWDL (US201800838) and origins as a successor to Wi-FI IBSS (Wiki | Open Wireless Link)[9] CyberHoot â€“ Apple Wireless Direct Link (AWDL) â€“ Apple deployed AWDL in over billion devices to power AirDrop, AirPlay peer Connections, and more (2002) (Apple Wireless Direct Link (AWDL) - CyberHoot)[10] Wi-Fi Alliance â€“ Wifi Aware â€“ Android added platform support for Wi-Fi Aware in Oreo (8.0) and later (Wi-Fi Aware | Wi-Fi Alliance)[11] Usenix Association â€“ A billion Open Interfaces for Eve and Mallory: MitM, DoS, and Tracking ATtacks on iOS and macOS Through Apple Wireless Direct Link â€“ AWDL integrates with Bluetooth Low Energy (A Billion Open Interfaces for Eve and Mallory: MitM, DoS ... - USENIX)[12] Octet Stream â€“ Building Cross Platform Offline - First Apps with Bluetooth Low Energy - Integration with Bluetooth Low Energy (May 2024) (Building Cross-Platform Offline-First Apps with Bluetooth Low Energy).[13] Open Wireless Link â€“ Code â€“ Linux Implementation called OWL (Code | Open Wireless Link)[14] Secure Mobile Networking Lab (SEEMOO) -- Apple Wireless Direct Link (AWDL) and Secure Device Communications â€“ AWDL is a based ad-hoc protocol with Apple-specific extensions integrated into Appleâ€™s ecosystem (Matthias Hollick â€“ Secure Mobile Networking Lab)[15] WiFi Alliance â€“ Wi-Fi CERTIFIED Wi-Fi Aware Technology Overview â€“ Wi-Fi Aware always-on background discovery with power efficiency (2002) (Wi-Fi CERTIFIED Wi-Fi Awareâ„¢ Technology Overview (2022) | Wi-Fi Alliance)[16] WiF Alliance â€“ Wi-Fi Aware Specification v4.0 â€“ Detailed Specification for Wi-Fi Aware technology (2022) (Wi-Fi Aware Specification v4.0.pdfâ€SUBSCRIBEGet posts straight in your inboxSubscribe to updates and we'll send you occasional emails with posts that we think you'll like.\n  hbspt.forms.create({\n    portalId: \"4836182\",\n    formId: \"b8668664-695d-40ab-a974-db7a6522dbea\",\n    region: \"na1\"\n  });\nEmail*utm_sourceutm_mediumutm_campaignutm_termutm_content\n\nRead moreView All ArticlesView All ArticlesView All ArticlesProductMarch 19, 2025Introducing Ditto 4.10: More Power, More Control, and New Platform SupportbySkyler JokielOur latest Ditto 4.10 SDK release brings significant improvements, giving developers more flexibility, better performance, and support for new platforms. March 12, 2025Ditto Lands $82M to Pioneer the Edge-Native RevolutionbyRyan RatnerThe future of computing isnâ€™t in the cloud - itâ€™s at the edge. And with this latest funding round, weâ€™re poised to make Ditto the new standard for edge development.\n\nul.footer_links_wrap>li.footer_links_item { transition: opacity 400ms ease, transform 400ms ease; }\nul.footer_links_wrap:has(li.footer_links_item:hover)>li.footer_links_item:not(:hover) { opacity: 0.5; }\nul.footer_links_wrap:has(li.footer_links_item:hover)>li.footer_links_item:hover { transform: translateX(0.5em); }\nResilient Edge Device ConnectivityServers and Cloud, OptionalStart for freeStart for freeStart for freeSchedule a DemoSchedule a DemoSchedule a DemoÂ© 2025 DittoLive IncorporatedAll rights reserved.CompanyPlatformAbout UsOur CustomersPricingCareersResourcesBlogDEMOAPPSIn The NewsPress ReleasesMake a ReportSocialsLinkedinGithubTwitter / XLegalTerms of ServicePrivacy PolicyCookie PolicyDPA",
    "summary": {
      "en": "The European Union (EU) is mandating that Apple replace its proprietary peer-to-peer Wi-Fi protocol, Apple Wireless Direct Link (AWDL), with the open standard Wi-Fi Aware, also known as Neighbor Awareness Networking (NAN). This change is part of the EU's Digital Markets Act (DMA), which aims to improve interoperability between devices. Apple must implement Wi-Fi Aware 4.0 in its upcoming iOS 19 update and support Wi-Fi Aware 5.0 shortly thereafter.\n\nHistorically, AWDL provided Apple devices with fast, high-performance peer-to-peer communication, enabling features like AirDrop and AirPlay. However, it was limited to Apple products and did not allow cross-platform connectivity. Wi-Fi Aware, on the other hand, is an open standard that enables devices from different manufacturers to discover and connect to each other directly via Wi-Fi, enhancing compatibility between iPhones and Android devices.\n\nThe key benefits of Wi-Fi Aware include efficient discovery, high data throughput, low latency, and enhanced security features. This shift will allow developers to create applications that work seamlessly across both Apple and Android platforms without the need for complex workarounds.\n\nIn summary, the EU's regulations are pushing Apple to adopt a standard that will facilitate better interoperability, allowing devices from different brands to connect easily and paving the way for innovative applications in local networking.",
      "ko": "ìœ ëŸ½ì—°í•©(EU)ì€ ì• í”Œì´ ìì‚¬ì˜ ë…ì ì ì¸ í”¼ì–´ íˆ¬ í”¼ì–´ Wi-Fi í”„ë¡œí† ì½œì¸ ì• í”Œ ë¬´ì„  ë‹¤ì´ë ‰íŠ¸ ë§í¬(AWDL)ë¥¼ ê°œë°©í˜• í‘œì¤€ì¸ Wi-Fi Aware, ì¦‰ ì´ì›ƒ ì¸ì‹ ë„¤íŠ¸ì›Œí‚¹(NAN)ìœ¼ë¡œ êµì²´í•˜ë„ë¡ ìš”êµ¬í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ ë³€í™”ëŠ” EUì˜ ë””ì§€í„¸ ì‹œì¥ë²•(DMA)ì˜ ì¼í™˜ìœ¼ë¡œ, ê¸°ê¸° ê°„ì˜ ìƒí˜¸ ìš´ìš©ì„±ì„ ê°œì„ í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì• í”Œì€ ë‹¤ê°€ì˜¤ëŠ” iOS 19 ì—…ë°ì´íŠ¸ì—ì„œ Wi-Fi Aware 4.0ì„ êµ¬í˜„í•˜ê³ , ê·¸ ì´í›„ì—ëŠ” Wi-Fi Aware 5.0ì„ ì§€ì›í•´ì•¼ í•©ë‹ˆë‹¤.\n\nAWDLì€ ì—­ì‚¬ì ìœ¼ë¡œ ì• í”Œ ê¸°ê¸° ê°„ì— ë¹ ë¥´ê³  ê³ ì„±ëŠ¥ì˜ í”¼ì–´ íˆ¬ í”¼ì–´ í†µì‹ ì„ ì œê³µí•˜ì—¬ ì—ì–´ë“œë¡­ê³¼ ì—ì–´í”Œë ˆì´ì™€ ê°™ì€ ê¸°ëŠ¥ì„ ê°€ëŠ¥í•˜ê²Œ í–ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ AWDLì€ ì• í”Œ ì œí’ˆì—ë§Œ êµ­í•œë˜ì–´ ìˆì–´ ë‹¤ë¥¸ í”Œë«í¼ ê°„ì˜ ì—°ê²°ì´ ë¶ˆê°€ëŠ¥í–ˆìŠµë‹ˆë‹¤. ë°˜ë©´, Wi-Fi AwareëŠ” ë‹¤ì–‘í•œ ì œì¡°ì‚¬ì˜ ê¸°ê¸°ê°€ ì„œë¡œë¥¼ ì§ì ‘ ë°œê²¬í•˜ê³  ì—°ê²°í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ê°œë°©í˜• í‘œì¤€ìœ¼ë¡œ, ì•„ì´í°ê³¼ ì•ˆë“œë¡œì´ë“œ ê¸°ê¸° ê°„ì˜ í˜¸í™˜ì„±ì„ ë†’ì…ë‹ˆë‹¤.\n\nWi-Fi Awareì˜ ì£¼ìš” ì¥ì ì€ íš¨ìœ¨ì ì¸ ë°œê²¬, ë†’ì€ ë°ì´í„° ì „ì†¡ ì†ë„, ë‚®ì€ ì§€ì—° ì‹œê°„, ê·¸ë¦¬ê³  ê°•í™”ëœ ë³´ì•ˆ ê¸°ëŠ¥ì…ë‹ˆë‹¤. ì´ëŸ¬í•œ ë³€í™”ëŠ” ê°œë°œìë“¤ì´ ì• í”Œê³¼ ì•ˆë“œë¡œì´ë“œ í”Œë«í¼ ëª¨ë‘ì—ì„œ ë³µì¡í•œ ìš°íšŒ ë°©ë²• ì—†ì´ ì›í™œí•˜ê²Œ ì‘ë™í•˜ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ë§Œë“¤ ìˆ˜ ìˆë„ë¡ í•  ê²ƒì…ë‹ˆë‹¤.\n\nê²°ë¡ ì ìœ¼ë¡œ, EUì˜ ê·œì œëŠ” ì• í”Œì´ ìƒí˜¸ ìš´ìš©ì„±ì„ ê°œì„ í•  ìˆ˜ ìˆëŠ” í‘œì¤€ì„ ì±„íƒí•˜ë„ë¡ ì••ë°•í•˜ê³  ìˆìœ¼ë©°, ì´ëŠ” ë‹¤ì–‘í•œ ë¸Œëœë“œì˜ ê¸°ê¸°ê°€ ì‰½ê²Œ ì—°ê²°ë  ìˆ˜ ìˆë„ë¡ í•˜ê³ , ì§€ì—­ ë„¤íŠ¸ì›Œí‚¹ì—ì„œ í˜ì‹ ì ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ê¸¸ì„ ì—´ì–´ì¤„ ê²ƒì…ë‹ˆë‹¤.",
      "ja": "æ¬§å·é€£åˆï¼ˆEUï¼‰ã¯ã€Appleã«å¯¾ã—ã¦ç‹¬è‡ªã®ãƒ”ã‚¢ãƒ„ãƒ¼ãƒ”ã‚¢Wi-Fiãƒ—ãƒ­ãƒˆã‚³ãƒ«ã§ã‚ã‚‹Apple Wireless Direct Linkï¼ˆAWDLï¼‰ã‚’ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰ã®Wi-Fi Awareã€åˆ¥åNeighbor Awareness Networkingï¼ˆNANï¼‰ã«ç½®ãæ›ãˆã‚‹ã‚ˆã†ç¾©å‹™ä»˜ã‘ã¦ã„ã¾ã™ã€‚ã“ã®å¤‰æ›´ã¯ã€EUã®ãƒ‡ã‚¸ã‚¿ãƒ«å¸‚å ´æ³•ï¼ˆDMAï¼‰ã®ä¸€ç’°ã§ã‚ã‚Šã€ãƒ‡ãƒã‚¤ã‚¹é–“ã®ç›¸äº’é‹ç”¨æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã—ã¦ã„ã¾ã™ã€‚Appleã¯ã€ä»Šå¾Œã®iOS 19ã®ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã§Wi-Fi Aware 4.0ã‚’å®Ÿè£…ã—ã€ãã®å¾Œã™ãã«Wi-Fi Aware 5.0ã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚\n\nAWDLã¯ã€Appleãƒ‡ãƒã‚¤ã‚¹ã«é«˜é€Ÿã§é«˜æ€§èƒ½ãªãƒ”ã‚¢ãƒ„ãƒ¼ãƒ”ã‚¢é€šä¿¡ã‚’æä¾›ã—ã€AirDropã‚„AirPlayãªã©ã®æ©Ÿèƒ½ã‚’å¯èƒ½ã«ã—ã¦ãã¾ã—ãŸã€‚ã—ã‹ã—ã€AWDLã¯Appleè£½å“ã«é™å®šã•ã‚Œã¦ãŠã‚Šã€ç•°ãªã‚‹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ é–“ã®æ¥ç¶šã¯ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ä¸€æ–¹ã€Wi-Fi Awareã¯ã‚ªãƒ¼ãƒ—ãƒ³ã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰ã§ã‚ã‚Šã€ç•°ãªã‚‹ãƒ¡ãƒ¼ã‚«ãƒ¼ã®ãƒ‡ãƒã‚¤ã‚¹ãŒWi-Fiã‚’ä»‹ã—ã¦ç›´æ¥ç™ºè¦‹ã—æ¥ç¶šã§ãã‚‹ã‚ˆã†ã«ã—ã€iPhoneã¨Androidãƒ‡ãƒã‚¤ã‚¹é–“ã®äº’æ›æ€§ã‚’å‘ä¸Šã•ã›ã¾ã™ã€‚\n\nWi-Fi Awareã®ä¸»ãªåˆ©ç‚¹ã«ã¯ã€åŠ¹ç‡çš„ãªç™ºè¦‹ã€é«˜é€Ÿãªãƒ‡ãƒ¼ã‚¿è»¢é€ã€ä½é…å»¶ã€å¼·åŒ–ã•ã‚ŒãŸã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ©Ÿèƒ½ãŒã‚ã‚Šã¾ã™ã€‚ã“ã®ç§»è¡Œã«ã‚ˆã‚Šã€é–‹ç™ºè€…ã¯Appleã¨Androidã®ä¸¡æ–¹ã®ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã§ã‚·ãƒ¼ãƒ ãƒ¬ã‚¹ã«å‹•ä½œã™ã‚‹ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä½œæˆã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã€è¤‡é›‘ãªå›é¿ç­–ã‚’å¿…è¦ã¨ã—ãªããªã‚Šã¾ã™ã€‚\n\nè¦ã™ã‚‹ã«ã€EUã®è¦åˆ¶ã¯Appleã«å¯¾ã—ã¦ã€ç•°ãªã‚‹ãƒ–ãƒ©ãƒ³ãƒ‰ã®ãƒ‡ãƒã‚¤ã‚¹ãŒç°¡å˜ã«æ¥ç¶šã§ãã‚‹æ¨™æº–ã‚’æ¡ç”¨ã™ã‚‹ã‚ˆã†ä¿ƒã—ã¦ãŠã‚Šã€ãƒ­ãƒ¼ã‚«ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã«ãŠã‘ã‚‹é©æ–°çš„ãªã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®é“ã‚’é–‹ã„ã¦ã„ã¾ã™ã€‚"
    }
  },
  {
    "id": "dbb1005d9315d56d",
    "title": {
      "en": "\"Station\" by Mitsuo Isaka (1994)",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://twitter.com/gingerbeardman/status/1906041957668770237",
    "score": 13,
    "by": "tosh",
    "time": 1743277979,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "10097a15cc5088c4",
    "title": {
      "en": "Things I would have told myself before building an autorouter",
      "ko": "ì˜¤í† ë¼ìš°í„° ì œì‘ ì „ ê¼­ í•  ë§",
      "ja": "ã‚ªãƒ¼ãƒˆãƒ«ãƒ¼ã‚¿ãƒ¼ã®å‰ã«è‡ªåˆ†ã«ä¼ãˆãŸã‹ã£ãŸã“ã¨"
    },
    "type": "story",
    "url": "https://blog.autorouting.com/p/13-things-i-would-have-told-myself",
    "score": 382,
    "by": "seveibar",
    "time": 1743122333,
    "content": "Share this postautorouting13 things I would have told myself before building an autorouterCopy linkFacebookEmailNotesMoreDiscover more from autoroutingReviews, benchmarks and open datasets for autorouting, with a focus on open-source autorouting.SubscribeBy subscribing,  I agree to Substack's Terms of Use, and acknowledge its Information Collection Notice and Privacy Policy.Already have an account? Sign in13 things I would have told myself before building an autorouterImportant lessons from trying to build the world's fastest autorouter for about a yearSeveMar 28, 202512Share this postautorouting13 things I would have told myself before building an autorouterCopy linkFacebookEmailNotesMore42ShareIâ€™ve spent about a year working on an autorouter for tscircuit (an open-source electronics CAD kernel written in Typescript). If I could go back a year, these are the 13 things I would tell myself:An intermediate stage of our autorouting routing a keyboard.1. Know A* like the back of your hand, use it everywhereIf I was king for a day, I would rename A* to â€œFundamental Algorithmâ€. It is truly one of the most adaptable and important algorithms for _any kind_ of search. It is simply the best foundation for any kind of informed search (not just for 2d grids!)Hereâ€™s an animated version of A* versus â€œbreadth first searchâ€ on a 2d grid:The way A* explores nodes is a lot faster and more intuitive. The major difference between these two algorithms is BFS explores all adjacent nodes, while A* prioritizes exploring nodes that are closer to the destination. Because it considers a metric outside the graph (the distance to the destination) itâ€™s an informed search.You are already either using BFS or DFS (depth-first search) in your code. A recursive algorithm is a depth first search. Any loop that explores candidates/neighbors without sorting the candidates is a BFS. 99% of the time you can convert it to A* and get dramatic performance gains!One of my favorite techniques in our autorouter is we run multiple levels of A* to discover the optimal hyperparameters for a particular problem. So weâ€™re basically running each autorouter as a candidate, then using A* to determine which autorouters we should spend the most time on!See all those numbers at the top? Those are each different configurations of hyper parameters. Running each autorouter fairly would be a huge waste of time- if one autorouter starts to win (it is successfully routing with good costs) allocate more iterations to it! This kind of meta-A* combines a regular cost function that penalizes distance with a cost function that penalizes iterations.2. Implementation Language doesnâ€™t matterIâ€™m controversially writing our autorouter in Javascript. This is the first thing people call out, but itâ€™s not as unreasonable as you might expect. Consider that when optimizing an algorithm, youâ€™re basically looking at improving two things:Lowering the number of iterations required (make the algorithm smart)Increasing the speed of each iterationPeople focus way too much on improving the speed of each iteration. If you are doing something dumb (like converting everything to a grid for overlap testing), Javascript performance will beat you no matter what language you use!Dumb algorithms in optimal assembly are slower than smart algorithms in Javascript! Algorithm > Language!95% of your focus should be on reducing the number of iterations. This is why language doesnâ€™t matter. Whatever gets you to the smartest, most cacheable algorithm fastest is the best language.3. Spatial Hash Indexing > Tree Data StructuresYou canâ€™t walk 5 feet into multi-dimensional space optimization without someone mentioning a QuadTree, this incredible data structure that makes O(N) search O(log(N)) when searching for nearby objects in 2d/3d space.The QuadTree and every general-purpose tree data structure are insanely slow. Trees are not an informed representation of your data.Any time youâ€™re using a tree youâ€™re ignoring an  O(~1) hash algorithm for a more complicated O(log(N)) algorithmWhy does Javascript use HashSets and HashMaps by default and every chance it gets? Theyâ€™re super super fast. A Spatial Hash Index is the same concept as a HashMap, but instead of hashing the object we hash itâ€™s location and store it in a Cell (or â€œbucket of things that are close togetherâ€)Letâ€™s look at how we might replace the QuadTree with a SpatialHashIndex with 20% as much code:There are many variants of this basic data structure for different types of objects, but they all look pretty similar. Weâ€™re basically just creating â€œbucketsâ€ with spatial hashes and filling them with any object that is contained within the cell represented by the spatial hash.The reason spatial hashes arenâ€™t as popular is you need to be careful about selecting your cell size- this is what makes it an informed algorithm. If your cell size isnâ€™t calibrated well, youâ€™ll end up paying high fixed costs per retrieval. In practice, itâ€™s not that difficult to pick a reasonable cell size.4. Effective Spatial Partitioning + Caching is 1000x more important than algorithm performanceA circuit board like the one inside an IPhone probably has somewhere between 10,000 and 20,000 traces and take a team several months to route with the best EDA tools in world. It can seem daunting to try to optimize such an incredibly complex task- but the truth is the entire industry is neglecting a very simple idea: everything that has been routed has been routed before.Game developers â€œpre-bakeâ€ navigation meshes into many gigabytes for their games. LLMs compress the entire internet into weights for search. The next generation of autorouters will spatially partition their problems, then call upon a massive cache for pre-solved solutions. The speed of the algorithm doesnâ€™t matter when you have a massive cache with 99% of the autorouting problem pre-solved.Most algorithms today do not focus on the effective cache-reusability or effective spatial partitioning, but a critical component of future autorouters will be caching inputs and outputs from each stage in a spatially partitioned way.Moreover, the size of storage and caching seems to go down faster than the speed of computation goes up. Itâ€™s not a big deal to have a gigabyte cache to make your autorouter 50% faster.At the end of the day, the cache will win. Cacheable algorithms matter more than fast algorithms!5. If you do not have a visualization for a problem, you will never solve itIf there is one thing I could have printed on a poster, it would be VISUALIZE THE PROBLEM. You canâ€™t debug problems by staring at numbers.For every tiny problem we solve, we have a visualization. We will often start with the visualization. Time and time again this enables us to debug and solve problems 10x faster than we could otherwise. Hereâ€™s a visualization we made of a subalgorithm for finding 45 degree paths, we use this in our â€œPath Simplification Phaseâ€, an ~final phase of the autorouter.6. Javascript Profiling Is Amazing- Use it!Javascript profiling tools are incredibe, you can easily see the exact total time in ms spend on each line of code. You donâ€™t need to use any performance framework, just execute your javascript in the browser and pull up the performance tab. There are also awesome features like flame charts and stuff for memory usage.Example flamechat for debugging performance in @tscircuit/coreYou can easily see the time spent on each line of code inside Chromeâ€™s performance tools!Hereâ€™s a little youtube short I made about it7. Never use recursive functionsRecursive functions are bad for multiple reasons:They are almost always synchronous (canâ€™t be broken out for animation)They are inherently a Depth-First Search, and canâ€™t be easily morphed to A*You canâ€™t easily track iterationsMutability is often unnatural in recursive functions but critical to performanceHereâ€™s an example of an â€œobviously recursiveâ€ function converted to a non-recursive function:The iteration-based implementation is much faster because it keeps a set of visitedNodes and checks nodes prior to exploration. You can do this with recursive functions, but you have to pass around a mutable object and do other unnatural things. Itâ€™s just best to avoid recursive functions when writing performant code.8. Monte Carlo algorithms are hacks. AVOIDMonte Carlo algorithms use randomness to iterate towards a solution. They are bad because:They lead to non-deterministic, hard-to-debug algorithmsThey are basically never optimal relative to a heuristicI sometimes use Monte Carlo-style algorithms when I donâ€™t yet know how the algorithm should get to the solution, but I know how to score a candidate. They can help give some basic intuition about how to solve a problem. Once you have something approximating a cost function, do something smarter than Monte Carlo or any other random technique like Simulated Annealing. If your algorithm is sensitive to local minimums, consider using hyper parameters or more complex cost functions. Almost any local minimum your human eye can see can be made into a component of a cost function.Another way to think about it: How many PCB Designers randomly draw lines on their circuit board? None. Nobody does that. Itâ€™s just not a good technique for this domain. Youâ€™ll always be able to find a better heuristic.9. Keep intermediate algorithms groundedOur autorouter is currently a pipeline with 13 stages and something like 20 sub-algorithms that we measure the iteration count of for various things like determining spatial partitions or simplifying paths at the boundaries independently autorouted sections.Being able to overlay different inputs/output visualizations of each stage of the algorithm helps you understand the context surrounding the problem youâ€™re solving. I often ran into issues at downstream stages (often our â€œhigh density routingâ€ stage) that could be solved by improving the output of previous stages.The temptation when building sub-algorithms is to isolate the algorithm to its simplest form, maybe even normalizing around (0, 0). The danger with normalization or any complex transformation is it might impact the ability to quickly see consequences from early stages of the algorithm to later stages of the algorithm. To prevent this, just keep your coordinate space consistent throughout the lifecycle of the algorithm.Hereâ€™s each stage of our algorithm one after another. We often zoom in on this to see what stage is the most guilty culprit for a failed Design Rule Check.10. Animate your iterations to catch stupid behaviorRemember how itâ€™s super important to lower your iteration count?Animating the iterations of your algorithm will show you how â€œdumbâ€ itâ€™s being by giving you an intuition for how many iterations are wasted exploring paths that donâ€™t matter. This is particularly helpful when adjusting the greedy multiplier (discussed in 12)This video is an animation of a simple trace failing to solve, but instead of failing outright attempting to solve endlessly outward. Without the animation, it would have been hard to tell what was going on!11. Intersection math is fast, do you really need a grid?Consider two ways to determine if a trace A overlaps another trace B:Consider each segment of A and B, and check for intersections1Create a binary grid that marks each square where trace B is present, then check all the squares where trace A is present to see if B is thereBelieve it or not, most people would choose to use Option 2 with a binary grid check, even though this can easily be 1000x slower. People do this because math is hard ğŸ¤¦Luckily LLMs make this kind of intersection math trivial. Use fast vector math!! Checking a SINGLE grid square (memory access!) can literally be slower than doing a dot product to determine if two segments intersect!12. Measure spatial probability of failure at each stage, prioritize solvabilityWhen doing spatial partitioning of the problem, you can measure the probability of solve failure of each stage with some leading indicators. For example, in the Unravel Autorouter we track the probability of failure for each â€œCapacity Nodeâ€ at each major pipeline stage. Each stage focuses on reconfiguring adjacent nodes or rerouting to reduce the probability of failure.The great thing about probability of failure as a metric is you can literally measure it and improve your prediction as your algorithm changes. Each stage can then do itâ€™s best to minimize the chance of future stages failing.I think generally prioritizing solvability is better than trying to incorporate too many constraints. Once a board is solved, itâ€™s often easier to â€œwork with that solutionâ€ than to generate optimal solution from scratch.13. The â€œGreedy Multiplierâ€, the secret hack to 100x A* performance at the cost of optimality Ok itâ€™s not exactly a secret, maybe a â€œwell-known secretâ€, but if you donâ€™t know about it, youâ€™re not using A* properly.By default, A* is guaranteed to give you the optimal solution, but what if you care more about speed than about optimality? Make one tiny change to your f(n)and you have Weighted A*, a variant of A* that solves more greedily, and generally much, much faster!Normal A*: f(n) = g(n) + h(n)Weighted A*: f(n) = g(n) + w * h(n)You can read more about weighted A* and other A* variants here.Game developers have a lot of the same problems as autorouting developers, so itâ€™s not a bad idea to look for game development papers if youâ€™re searching for related work!Weâ€™re making an autorouter.If this was interesting to you, Iâ€™d love to show you our autorouter as it gets closer to release. I believe that solving autorouting will be a massive unlock for physical-world innovation and is a key piece to enable the â€œvibe-buildingâ€ of electronics. All of our work is MIT-licensed open-source. You can also follow me on twitter.Thanks for reading autorouting! Subscribe to hear when we release our insanely fast autorouter!Subscribe1Technically, you should use â€œsegment to segmentâ€ distance to ensure appropriate margins, which is slightly more complex than intersection, but not by much12Share this postautorouting13 things I would have told myself before building an autorouterCopy linkFacebookEmailNotesMore42Share",
    "summary": {
      "en": "The author shares 13 key lessons learned from a year spent building an autorouter for open-source electronics design, focusing on improving efficiency and performance. Hereâ€™s a simplified summary:\n\n1. **Master A* Algorithm**: Itâ€™s essential to understand the A* algorithm, as itâ€™s more efficient than others like Breadth-First Search (BFS) for searching paths.\n\n2. **Don't Worry About Programming Language**: The choice of language (like JavaScript) is less important than using smart algorithms to reduce iterations.\n\n3. **Use Spatial Hash Indexing**: Instead of tree structures like QuadTrees, use spatial hash indexing for faster searches in multidimensional spaces.\n\n4. **Prioritize Caching**: Effective caching of data is more important than the speed of algorithms. Pre-solving problems can significantly enhance performance.\n\n5. **Visualize Problems**: Creating visual representations of problems helps in understanding and solving them more effectively.\n\n6. **Utilize JavaScript Profiling Tools**: These tools help track performance issues in your code easily.\n\n7. **Avoid Recursive Functions**: They can complicate performance and debugging, so use iterative approaches instead.\n\n8. **Be Cautious with Monte Carlo Algorithms**: These introduce randomness and can lead to non-optimal solutions; seek smarter methods instead.\n\n9. **Keep Algorithms Grounded**: Maintain consistent data representation across different stages of your algorithm to avoid confusion.\n\n10. **Animate Algorithm Iterations**: Animation helps identify inefficiencies in the algorithm by showing how it behaves in real-time.\n\n11. **Use Fast Intersection Math**: Instead of relying on slow grid checks, use mathematical calculations to determine overlaps quickly.\n\n12. **Measure Failure Probability**: Track the likelihood of failure at each stage to improve the algorithmâ€™s predictability and success.\n\n13. **Use Weighted A* for Speed**: Adjust the A* algorithm to prioritize speed over optimality by tweaking its cost function.\n\nThese insights aim to help others avoid common pitfalls and streamline the development of an efficient autorouting system.",
      "ko": "ì €ìëŠ” ì˜¤í”ˆ ì†ŒìŠ¤ ì „ì ì„¤ê³„ë¥¼ ìœ„í•œ ìë™ ë¼ìš°í„°ë¥¼ ê°œë°œí•˜ë©° ë°°ìš´ 13ê°€ì§€ ì£¼ìš” êµí›ˆì„ ê³µìœ í•©ë‹ˆë‹¤. ì´ êµí›ˆë“¤ì€ íš¨ìœ¨ì„±ê³¼ ì„±ëŠ¥ í–¥ìƒì— ì¤‘ì ì„ ë‘ê³  ìˆìŠµë‹ˆë‹¤.\n\nì²«ì§¸, A* ì•Œê³ ë¦¬ì¦˜ì„ ë§ˆìŠ¤í„°í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤. A* ì•Œê³ ë¦¬ì¦˜ì€ ê²½ë¡œ íƒìƒ‰ì—ì„œ ë„ˆë¹„ ìš°ì„  íƒìƒ‰(BFS)ë³´ë‹¤ ë” íš¨ìœ¨ì ì…ë‹ˆë‹¤. ë‘˜ì§¸, í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì— ëŒ€í•´ ê±±ì •í•  í•„ìš”ëŠ” ì—†ìŠµë‹ˆë‹¤. ìë°”ìŠ¤í¬ë¦½íŠ¸ì™€ ê°™ì€ ì–¸ì–´ì˜ ì„ íƒë³´ë‹¤ ìŠ¤ë§ˆíŠ¸í•œ ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•´ ë°˜ë³µ íšŸìˆ˜ë¥¼ ì¤„ì´ëŠ” ê²ƒì´ ë” ì¤‘ìš”í•©ë‹ˆë‹¤.\n\nì…‹ì§¸, ê³µê°„ í•´ì‹œ ì¸ë±ì‹±ì„ í™œìš©í•˜ì„¸ìš”. QuadTreeì™€ ê°™ì€ íŠ¸ë¦¬ êµ¬ì¡° ëŒ€ì‹ , ë‹¤ì°¨ì› ê³µê°„ì—ì„œ ë” ë¹ ë¥¸ ê²€ìƒ‰ì„ ìœ„í•´ ê³µê°„ í•´ì‹œ ì¸ë±ì‹±ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. ë„·ì§¸, ë°ì´í„° ìºì‹±ì„ ìš°ì„ ì‹œí•´ì•¼ í•©ë‹ˆë‹¤. ì•Œê³ ë¦¬ì¦˜ì˜ ì†ë„ë³´ë‹¤ íš¨ê³¼ì ì¸ ë°ì´í„° ìºì‹±ì´ ë” ì¤‘ìš”í•˜ë©°, ë¬¸ì œë¥¼ ë¯¸ë¦¬ í•´ê²°í•˜ëŠ” ê²ƒì´ ì„±ëŠ¥ì„ í¬ê²Œ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\në‹¤ì„¯ì§¸, ë¬¸ì œë¥¼ ì‹œê°í™”í•˜ì„¸ìš”. ë¬¸ì œì˜ ì‹œê°ì  í‘œí˜„ì„ ë§Œë“¤ë©´ ì´í•´í•˜ê³  í•´ê²°í•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤. ì—¬ì„¯ì§¸, ìë°”ìŠ¤í¬ë¦½íŠ¸ í”„ë¡œíŒŒì¼ë§ ë„êµ¬ë¥¼ í™œìš©í•˜ì„¸ìš”. ì´ëŸ¬í•œ ë„êµ¬ëŠ” ì½”ë“œì˜ ì„±ëŠ¥ ë¬¸ì œë¥¼ ì‰½ê²Œ ì¶”ì í•  ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤.\n\nì¼ê³±ì§¸, ì¬ê·€ í•¨ìˆ˜ëŠ” í”¼í•˜ì„¸ìš”. ì¬ê·€ í•¨ìˆ˜ëŠ” ì„±ëŠ¥ê³¼ ë””ë²„ê¹…ì„ ë³µì¡í•˜ê²Œ ë§Œë“¤ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë°˜ë³µì ì¸ ì ‘ê·¼ ë°©ì‹ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. ì—¬ëŸì§¸, ëª¬í…Œì¹´ë¥¼ë¡œ ì•Œê³ ë¦¬ì¦˜ì— ì£¼ì˜í•´ì•¼ í•©ë‹ˆë‹¤. ì´ ì•Œê³ ë¦¬ì¦˜ì€ ë¬´ì‘ìœ„ì„±ì„ ë„ì…í•˜ì—¬ ë¹„ìµœì ì˜ ì†”ë£¨ì…˜ìœ¼ë¡œ ì´ì–´ì§ˆ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë” ìŠ¤ë§ˆíŠ¸í•œ ë°©ë²•ì„ ì°¾ì•„ì•¼ í•©ë‹ˆë‹¤.\n\nì•„í™‰ì§¸, ì•Œê³ ë¦¬ì¦˜ì˜ ì¼ê´€ì„±ì„ ìœ ì§€í•˜ì„¸ìš”. ì•Œê³ ë¦¬ì¦˜ì˜ ë‹¤ì–‘í•œ ë‹¨ê³„ì—ì„œ ë°ì´í„° í‘œí˜„ì„ ì¼ê´€ë˜ê²Œ ìœ ì§€í•˜ë©´ í˜¼ë€ì„ í”¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì—´ì§¸, ì•Œê³ ë¦¬ì¦˜ ë°˜ë³µ ê³¼ì •ì„ ì• ë‹ˆë©”ì´ì…˜ìœ¼ë¡œ í‘œí˜„í•˜ì„¸ìš”. ì• ë‹ˆë©”ì´ì…˜ì€ ì•Œê³ ë¦¬ì¦˜ì˜ ë¹„íš¨ìœ¨ì„±ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ë³´ì—¬ì¤ë‹ˆë‹¤.\n\nì—´í•œì§¸, ë¹ ë¥¸ êµì°¨ ìˆ˜í•™ì„ ì‚¬ìš©í•˜ì„¸ìš”. ëŠë¦° ê·¸ë¦¬ë“œ ì²´í¬ì— ì˜ì¡´í•˜ê¸°ë³´ë‹¤ëŠ” ìˆ˜í•™ì  ê³„ì‚°ì„ í†µí•´ ê²¹ì¹¨ì„ ë¹ ë¥´ê²Œ íŒë‹¨í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. ì—´ë‘ì§¸, ì‹¤íŒ¨ í™•ë¥ ì„ ì¸¡ì •í•˜ì„¸ìš”. ê° ë‹¨ê³„ì—ì„œ ì‹¤íŒ¨ ê°€ëŠ¥ì„±ì„ ì¶”ì í•˜ë©´ ì•Œê³ ë¦¬ì¦˜ì˜ ì˜ˆì¸¡ ê°€ëŠ¥ì„±ê³¼ ì„±ê³µë¥ ì„ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\në§ˆì§€ë§‰ìœ¼ë¡œ, ì†ë„ë¥¼ ìœ„í•´ ê°€ì¤‘ì¹˜ A* ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì„¸ìš”. A* ì•Œê³ ë¦¬ì¦˜ì˜ ë¹„ìš© í•¨ìˆ˜ë¥¼ ì¡°ì •í•˜ì—¬ ìµœì ì„±ë³´ë‹¤ ì†ë„ë¥¼ ìš°ì„ ì‹œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ í†µì°°ë ¥ì€ ë‹¤ë¥¸ ì‚¬ëŒë“¤ì´ ì¼ë°˜ì ì¸ í•¨ì •ì„ í”¼í•˜ê³  íš¨ìœ¨ì ì¸ ìë™ ë¼ìš°íŒ… ì‹œìŠ¤í…œ ê°œë°œì„ ê°„ì†Œí™”í•˜ëŠ” ë° ë„ì›€ì„ ì£¼ê¸° ìœ„í•´ ì œì‹œë˜ì—ˆìŠµë‹ˆë‹¤.",
      "ja": "è‘—è€…ã¯ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®é›»å­è¨­è¨ˆç”¨ã‚ªãƒ¼ãƒˆãƒ«ãƒ¼ã‚¿ãƒ¼ã‚’æ§‹ç¯‰ã™ã‚‹ãŸã‚ã«è²»ã‚„ã—ãŸ1å¹´ã‹ã‚‰å¾—ãŸ13ã®é‡è¦ãªæ•™è¨“ã‚’å…±æœ‰ã—ã¦ã„ã¾ã™ã€‚åŠ¹ç‡ã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®å‘ä¸Šã«ç„¦ç‚¹ã‚’å½“ã¦ãŸå†…å®¹ã§ã™ã€‚\n\nã¾ãšã€A*ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ãƒã‚¹ã‚¿ãƒ¼ã™ã‚‹ã“ã¨ãŒé‡è¦ã§ã™ã€‚ã“ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¯ã€çµŒè·¯æ¢ç´¢ã«ãŠã„ã¦å¹…å„ªå…ˆæ¢ç´¢ï¼ˆBFSï¼‰ãªã©ã®ä»–ã®æ‰‹æ³•ã‚ˆã‚Šã‚‚åŠ¹ç‡çš„ã§ã™ã€‚ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã®é¸æŠï¼ˆä¾‹ãˆã°JavaScriptï¼‰ã¯ã€åå¾©å›æ•°ã‚’æ¸›ã‚‰ã™ãŸã‚ã®è³¢ã„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã«æ¯”ã¹ã¦ãã‚Œã»ã©é‡è¦ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚\n\næ¬¡ã«ã€ç©ºé–“ãƒãƒƒã‚·ãƒ¥ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚å››åˆ†æœ¨ã®ã‚ˆã†ãªæœ¨æ§‹é€ ã®ä»£ã‚ã‚Šã«ã€ãƒãƒ«ãƒãƒ‡ã‚£ãƒ¡ãƒ³ã‚·ãƒ§ãƒŠãƒ«ãªç©ºé–“ã§ã®æ¤œç´¢ã‚’é«˜é€ŸåŒ–ã™ã‚‹ãŸã‚ã«ç©ºé–“ãƒãƒƒã‚·ãƒ¥ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’åˆ©ç”¨ã—ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã®åŠ¹æœçš„ãªã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã‚‚é‡è¦ã§ã€ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®é€Ÿåº¦ã‚ˆã‚Šã‚‚ã€äº‹å‰ã«å•é¡Œã‚’è§£æ±ºã™ã‚‹ã“ã¨ãŒãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å¤§å¹…ã«å‘ä¸Šã•ã›ã¾ã™ã€‚\n\nå•é¡Œã‚’è¦–è¦šåŒ–ã™ã‚‹ã“ã¨ã‚‚åŠ©ã‘ã«ãªã‚Šã¾ã™ã€‚å•é¡Œã®è¦–è¦šçš„ãªè¡¨ç¾ã‚’ä½œæˆã™ã‚‹ã“ã¨ã§ã€ç†è§£ã¨è§£æ±ºãŒã‚ˆã‚ŠåŠ¹æœçš„ã«ãªã‚Šã¾ã™ã€‚JavaScriptã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ãƒ„ãƒ¼ãƒ«ã‚’æ´»ç”¨ã™ã‚‹ã“ã¨ã§ã€ã‚³ãƒ¼ãƒ‰å†…ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®å•é¡Œã‚’ç°¡å˜ã«è¿½è·¡ã§ãã¾ã™ã€‚\n\nå†å¸°é–¢æ•°ã¯ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚„ãƒ‡ãƒãƒƒã‚°ã‚’è¤‡é›‘ã«ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ã€ä»£ã‚ã‚Šã«åå¾©çš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ãŒæ¨å¥¨ã•ã‚Œã¾ã™ã€‚ã¾ãŸã€ãƒ¢ãƒ³ãƒ†ã‚«ãƒ«ãƒ­ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«ã¯æ³¨æ„ãŒå¿…è¦ã§ã™ã€‚ã“ã‚Œã‚‰ã¯ãƒ©ãƒ³ãƒ€ãƒ æ€§ã‚’å°å…¥ã—ã€æœ€é©ã§ãªã„è§£æ±ºç­–ã«ã¤ãªãŒã‚‹ã“ã¨ãŒã‚ã‚‹ãŸã‚ã€ã‚ˆã‚Šè³¢ã„æ–¹æ³•ã‚’æ¢ã™ã¹ãã§ã™ã€‚\n\nã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®å„æ®µéšã§ä¸€è²«ã—ãŸãƒ‡ãƒ¼ã‚¿è¡¨ç¾ã‚’ç¶­æŒã™ã‚‹ã“ã¨ã§æ··ä¹±ã‚’é¿ã‘ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®åå¾©ã‚’ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³åŒ–ã™ã‚‹ã“ã¨ã§ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ã®æŒ™å‹•ã‚’ç¤ºã—ã€éåŠ¹ç‡æ€§ã‚’ç‰¹å®šã™ã‚‹ã®ã«å½¹ç«‹ã¡ã¾ã™ã€‚é…ã„ã‚°ãƒªãƒƒãƒ‰ãƒã‚§ãƒƒã‚¯ã«é ¼ã‚‹ã®ã§ã¯ãªãã€æ•°å­¦çš„ãªè¨ˆç®—ã‚’ç”¨ã„ã¦é‡ãªã‚Šã‚’è¿…é€Ÿã«åˆ¤æ–­ã™ã‚‹ãŸã‚ã®é«˜é€Ÿãªäº¤å·®è¨ˆç®—ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚\n\nå„æ®µéšã§ã®å¤±æ•—ã®å¯èƒ½æ€§ã‚’æ¸¬å®šã™ã‚‹ã“ã¨ã§ã€ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®äºˆæ¸¬å¯èƒ½æ€§ã¨æˆåŠŸç‡ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚æœ€å¾Œã«ã€A*ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚’å„ªå…ˆã™ã‚‹ã‚ˆã†ã«èª¿æ•´ã—ã€ãã®ã‚³ã‚¹ãƒˆé–¢æ•°ã‚’å¤‰æ›´ã™ã‚‹ã“ã¨ã§ã€æœ€é©æ€§ã‚ˆã‚Šã‚‚é€Ÿåº¦ã‚’é‡è¦–ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚\n\nã“ã‚Œã‚‰ã®æ´å¯Ÿã¯ã€ä»–ã®äººãŒä¸€èˆ¬çš„ãªè½ã¨ã—ç©´ã‚’é¿ã‘ã€åŠ¹ç‡çš„ãªã‚ªãƒ¼ãƒˆãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ã®é–‹ç™ºã‚’ã‚¹ãƒ ãƒ¼ã‚ºã«é€²ã‚ã‚‹æ‰‹åŠ©ã‘ã‚’ã™ã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã—ã¦ã„ã¾ã™ã€‚"
    }
  },
  {
    "id": "2966e8a0c61468ff",
    "title": {
      "en": "Emulating the YM2612: Part 1 â€“ Interface",
      "ko": "YM2612 ì¸í„°í˜ì´ìŠ¤ íƒêµ¬",
      "ja": "YM2612ã‚’å†ç¾ï¼ç¬¬1éƒ¨ - ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹"
    },
    "type": "story",
    "url": "https://jsgroth.dev/blog/posts/emulating-ym2612-part-1/",
    "score": 36,
    "by": "zdw",
    "time": 1742920430,
    "content": "Emulating the YM2612: Part 1 - Interface\n\n        2025.3.24\n\n        2025.3.25\n\n                Emulation\n\n        3301\n\n        16mins\n\n  Contents\n    Primary Source\n    Four-Operator FM Synthesis\n    Clock\n    Interface\n\n        Write Ports\n        Read Port\n        Read Port Mirroring: Discrete YM2612 vs. YM3438\n\n    First Audio Output: DAC Channel\n    To Be Continued\n\n                This is the first post in a series on emulating the main Sega Genesis sound chip, the Yamaha YM2612 FM synthesis chip, also known as the OPN2.\nTo date, the YM2612 is pretty easily the most difficult-to-emulate sound chip that I have worked on. Itâ€™s not extremely complex in concept, but it has an incredible amount of specific details and quirks in how exactly it works, and many of them need to be emulated exactly correctly for game audio to sound correct. Debugging mistakes is also very, very difficult due to all of the modulation and feedback, where for example a minor mistake in envelope emulation can manifest as some instruments sounding completely wrong.\nThese posts are not going to describe how to implement a cycle-accurate YM2612 emulator (mine is not), but I will do my best to describe how the chip works at a low level, from the perspective of someone who emulated it for the first time with modern documentation and resources available.\nI found a number of minor bugs and oversights in my own implementation while writing these posts, so if nothing else, writing them was useful for that!\nThis first post will mostly cover how the YM2612 is integrated into the Genesis and how the CPUs interface with it.\nPrimary Source\nFirst, I should state that nearly all of my information on the YM2612 comes from this very long thread plus resources linked from it: https://gendev.spritesmind.net/forum/viewtopic.php?t=386\nIn particular, thereâ€™s a lot of great information posted by Nemesis (Exodus author) on how exactly this chip works. I do not believe I would have been able to throw together my own YM2612 implementation without the information in this thread.\nDo be wary that many earlier posts in this thread contain inaccurate information that is corrected in later posts. As one of the more obvious examples, the first post on how the ADSR envelope generators work has some major errors that are corrected many pages later.\nMask of Destiny (BlastEm author) made a post that links to some of the most useful pages in that thread, as well as lots of other generally useful resources for anyone writing a Genesis emulator: https://gendev.spritesmind.net/forum/viewtopic.php?f=2&t=2227\nOne linked source is a translated manual for the YM2608 chip, which is very closely related to the YM2612. This is a particularly useful source, though note that the YM2608 is not exactly the same as the YM2612. Iâ€™ll try to note some of the biggest differences where theyâ€™re relevant.\nSegaâ€™s official Genesis documentation on the YM2612 is almost useless. Lots of major inaccuracies and it omits a lot of important information.\nFour-Operator FM Synthesis\nI attempted to overview how Yamaha FM synthesis works at a very high level in a section of my previous post on Konamiâ€™s VRC7 mapper for the Famicom. The YM2612 is similar in concept, though the details are very different from VRC7 and other OPL chips.\nWhile these chips are called â€œFMâ€ (frequency modulation), the hardware implementation is really phase modulation: some sine wave generators are used to dynamically adjust the phase of other sine wave generators. This is true for both VRC7 and YM2612.\nThe YM2612 has 6 audio channels, each with 4 sine wave generators called operators. Having 4 operators is a very significant change from the 2-operator FM synthesis of OPL2 and OPLL/VRC7, and it enables the chip to produce a much larger variety of sounds.\nA channelâ€™s 4 operators can be arranged in 1 of 8 different configurations, called â€œalgorithmsâ€. The algorithm determines whether any particular operator is a carrier (contributes directly to channel output) or a modulator (phase modulates another operator). Modulators may phase modulate multiple other operators depending on the algorithm, but there is no algorithm that makes any operator both a modulator and a carrier simultaneously.\nEach channelâ€™s operator 1 (counting from 1) is unique in that it supports self-feedback, like the OPLL/VRC7â€™s modulator. This means that it can optionally phase modulate itself using the sum of its last two operator outputs.\nThe first 4 algorithm options use the first 3 operators as modulators and the 4th operator as a carrier. The second 4 algorithm options each have multiple carriers, with the last algorithm making all 4 operators carriers. For algorithms with multiple carriers, the channel output is the sum of all carrier outputs.\nYM2612/YM2608 algorithms, from the YM2608 manual\nThe chip also includes a number of features beyond the FM synthesis operators themselves: a low frequency oscillator (LFO) used to power vibrato and tremolo effects, two hardware timers for use by software, and a DAC channel that outputs raw 8-bit PCM samples if enabled.\nThe YM2608 manual mentions support for ADPCM sample playback and some â€œrhythmâ€ functionality, but neither of these features is present in the YM2612.\nTo start, letâ€™s cover how the YM2612 is integrated into the Genesis.\nClock\nThe Genesis drives the YM2612 using the exact same clock signal that it uses to drive the 68000 CPU, a roughly 7.67 MHz clock (NTSC). The exact frequency is 53693175 Hz / 7 for NTSC consoles and 53203424 Hz / 7 for PAL consoles, those 8-digit numbers being the respective Genesis master clock frequencies.\nThe YM2612 internally divides its master clock by 6, leading to an effective clock rate of ~7.67 MHz / 6 = ~1.28 MHz in the NTSC Genesis.\nIn an emulator, the important thing is that the YM2612â€™s master clock is the 68000 CPU clock, so it should get ticked 1 internal YM2612 cycle per 6 68000 CPU clock cycles. If youâ€™re tracking timings in Genesis master clock cycles, the YM2612 should get 1 internal cycle per 42 mclk cycles.\nThe YM2612 generates a full output sample once every 24 internal clock cyclesâ€¦kind of. In actual hardware it repeatedly cycles through its 6 channels at a rate of 1 channel per 4 cycles and it multiplexes the channel outputs through its DAC, similar to the Famicom Namco 163 expansion audio chip (though without the audio aliasing caused by that chipâ€™s low cycling rate). Emulators donâ€™t usually emulate this multiplexing - they typically mix the channels instead of multiplexing them, and they generate a mixed sample once every 24 clock cycles.\nThis leads to an effective sample rate of about 53267 Hz for NTSC (53693175 Hz / 7 / 6 / 24) and slightly lower for PAL.\nAlmost everything inside the YM2612 updates at the sample clock rate or at some divider of the sample clock rate, though different components update at different times throughout the 24-cycle sampling period. Emulators do not usually emulate this very precise timing - they usually update all components at once every 24 internal cycles.\nInterface\nThe Genesis has a split bus, with the 68000 CPU on one side and the Z80 CPU on the other. It has a bus arbiter for managing access from one side to the other, as well as for allowing the 68000 to control the Z80 by setting its BUSREQ and RESET lines. BUSREQ removes the Z80 from the bus so that the 68000 can freely access hardware on the Z80 side of the bus.\nThe Z80 can access the 68000 side of the bus at any time, but every access introduces a variable delay for both CPUs as the bus arbiter inserts wait states to avoid a bus conflict.\nThe Z80 is meant to be a dedicated audio processor. To support this, the YM2612 is on the Z80 side of the bus so that the Z80 can access it without needing to cross over to the 68000 side and incur difficult-to-predict delays from the bus arbiter.\n(Interestingly, the SN76489 PSG chip is on the 68000 side of the bus, but SN76489 interactions are generally significantly less timing-sensitive compared to driving the YM2612â€™s DAC channel.)\nThe 68000 can access the YM2612 through its Z80 memory map window at $A00000-$A0FFFF, as long as it first removes the Z80 from the bus by setting its BUSREQ line using the bus arbiter. Some games primarily drive audio using the 68000, such as Sonic 1 - it only really uses the Z80 for playing samples through the YM2612â€™s DAC channel. Sonic 1 controls the YM2612 FM synthesis channels and the PSG using the 68000.\nIn fact, Sonic 1 is pretty much fully playable without emulating the Z80 at all! You need to emulate the bus arbiter registers at $A11100 and $A11200, and you wonâ€™t get any of the audio samples that it plays through the YM2612â€™s DAC channel, but youâ€™ll get audio output from the FM synthesis channels and the PSG.\n\nGreen Hill Zone with no Z80\nA number of Genesis games are playable without emulating the Z80 (this is not the SNES with its insanely limited 65816/SPC700 communication interface), but itâ€™s very common for audio to be completely missing with no Z80 emulation. Sonic 1 is a bit of an anomaly in how much it drives audio from the 68000.\nWrite Ports\nThe YM2612 has four 8-bit write ports mapped to $4000-$4003 in the Z80 memory map. These ports are mirrored repeatedly throughout the address range $4000-$5FFF.\nAccording to official documentation, these are:\n\n$4000: Address port, group 1 (channels 1-3 + global registers)\n$4001: Data port, group 1\n$4002: Address port, group 2 (channels 4-6)\n$4003: Data port, group 2\n\nWhen software wants to write to a channel 1-3 register or a global register, it first writes the 8-bit register address to $4000, then it writes the 8-bit register value to $4001. For channel 4-6 registers, it writes the register address to $4002 and then the register value to $4003.\nâ€¦Thatâ€™s not actually how it works, though. In reality the chip only has one data port thatâ€™s mapped to both $4001 and $4003:\n\n$4000: Address port + Set group 1 flag\n$4002: Address port + Set group 2 flag\n$4001 / $4003: Data port\n\nThe chip remembers whether $4000 or $4002 was last written to, and data port writes will go to either group 1 or group 2 based on which address port was last written. Titanâ€™s Overdrive 2 demo depends on this because it performs all of its data port writes through $4001, though Iâ€™m not sure if any games depend on this behavior.\nLooking at the 8-bit YM2612 register addresses, they all fall into three address ranges:\n\n$20-$2F: Global registers\n$30-$9F: Operator control registers\n$A0-$BF: Channel control registers\n\nFor both the $30-$9F registers and the $A0-$BF registers, the lowest 2 bits of the register address are used as the channel index. For example:\n\nExample Register Addresses\nGroup 1 Channel\nGroup 2 Channel\n\n$30, $34, $A0, $A4\n1\n4\n\n$31, $35, $A1, $A5\n2\n5\n\n$32, $36, $A2, $A6\n3\n6\n\n$33, $37, $A3, $A7\nNone\nNone\n\nFor the $30-$9F registers, bits 2 and 3 are used as the operator index, but bitswapped! Concretely:\n\n00 = Operator 1\n01 = Operator 3\n10 = Operator 2\n11 = Operator 4\n\nThe YM2608 manual correctly documents this bitswapping. Segaâ€™s official Genesis documentation on the YM2612 is wrong in this regard.\nExamples:\n\nExample Register Addresses\nOperator\n\n$30, $31, $32, $40, $41, $42\n1\n\n$34, $35, $36, $44, $45, $46\n3\n\n$38, $39, $3A, $48, $49, $4A\n2\n\n$3C, $3D, $3E, $4C, $4D, $4E\n4\n\nYou could parse these out of the address like so:\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n\nlet mut channel_idx = register_addr & 3;\nif channel_idx == 3 {\n    // Invalid\n    return;\n}\nif group == Group::Two {\n    channel_idx += 3;\n}\n\nlet operator_idx = ((register_addr >> 3) & 1) | ((register_addr >> 1) & 2);\nCopy\n\nRead Port\nThe YM2612 has a single read port which is mapped to $4000 in the Z80 memory map. It contains 3 meaningful bits:\n\nBit 7: Busy flag\nBit 1: Timer B overflow flag\nBit 0: Timer A overflow flag\n\nThatâ€™s it. The other 5 bits are undefined, and the YM2612 does not expose any other information through reads.\nThe busy flag is most commonly used. It indicates whether the YM2612 is currently processing a register write, in which case software should wait to perform any other YM2612 register writes. When games need to write to multiple registers theyâ€™ll typically have a loop where they write to the first register, poll the busy flag until itâ€™s 0, write to the next register, poll the busy flag until itâ€™s 0, and repeat until all registers have been written.\nThe two timer overflow bits are the only way for software to get feedback from the two YM2612 timers because theyâ€™re not connected to any of the Z80â€™s interrupt lines. Software that uses the timers needs to poll these bits to know when a timer interval has passed.\nBusy flag behavior doesnâ€™t seem to be completely consistent between different model consoles, and it probably also depends on when exactly the register write occurs within the chipâ€™s internal cycling between channels and operators. I leave the busy flag 1 for 32 internal YM2612 cycles after a data port write and that seems to work ok with everything Iâ€™ve tested. (Source for that number)\nAt least in earlier consoles, the busy flag reads as 1 for much longer than it takes the YM2612 to process the write, which it will always do within 24 YM2612 cycles and sometimes do within many fewer cycles - it depends on which register was written to. This makes the busy flag less useful than simply counting Z80 cycles in between writes, though this was likely not known to most developers back in the 80s and 90s.\nRead Port Mirroring: Discrete YM2612 vs. YM3438\nThe read port is mirrored at $4001-$4003â€¦on some consoles. There are at least two games that are highly sensitive to read port mirroring behavior: Earthworm Jim and Hellfire.\nThis behavior difference is based on whether the console contains a discrete YM2612 chip or a YM3438, a slightly modified CMOS version of the YM2612.\nWith the YM3438, $4001-$4003 mirror $4000. Reading from any of these addresses returns the busy flag and timer overflow bits. This chip was used in the Model 1 VA7, Model 2 VA0-VA1, and Model 3 consoles.\nWith the discrete YM2612, reading from $4001-$4003 is officially undefined. It seems like what happens on actual hardware is that reading from $4001-$4003 returns the last value that was read from $4000, but it decays to 0 after a certain amount of time has passed since the last $4000 read. This chip was used in the Model 1 VA0-VA6 and Model 2 VA2 consoles.\nEarthworm Jim occasionally reads the busy flag from $4002 instead of $4000, and on models with the discrete YM2612, this causes extremely noticeable audio stuttering. This happens because the previous $4000 read was sometimes only to poll for one of the timer overflow bits, and if the busy flag was set during that read, the gameâ€™s audio driver will spinloop polling $4002 until the status value decays to 0.\n\nEarthworm Jim - Discrete YM2612 behavior\n\nEarthworm Jim - YM3438 behavior\nThe discrete YM2612 recording is using a decay period of around a quarter-secondâ€™s worth of cycles. This produces results similar to hardware recordings of this game on consoles with a discrete YM2612.\nHellfire has the opposite problem: It frequently reads the busy flag from $4001 and $4003 instead of $4000, and if it can actually read the busy flag from these addresses, the music will play much slower than itâ€™s supposed to. This means that the music only plays correctly on consoles with a discrete YM2612.\n\nHellfire - Discrete YM2612 behavior\n\nHellfire - YM3438 behavior\nThe game just so happens to write to the YM2612 registers in such a way that even on actual hardware, none of the writes are dropped despite it not correctly reading the busy flag.\nHow to handle this in an emulator is an implementation decision. Making $4001-$4003 reads always return 0 would make both Earthworm Jim and Hellfire sound correct, but itâ€™s not accurate to any actual hardware, and it could break other games. Always using discrete YM2612 behavior breaks Earthworm Jim, and always using YM3438 behavior breaks Hellfire.\nThe most reasonable solution is probably to offer an option of what behavior to emulate, maybe with something like an auto-detect option that automatically uses the ideal behavior for these two games. Other games generally only try to access the read port at $4000.\nBoth of these behaviors are accurate to actual hardware - theyâ€™re just accurate to different versions of the hardware.\nFirst Audio Output: DAC Channel\nThe DAC channel is by far the easiest thing to emulate inside the YM2612, so letâ€™s start with that.\nThe DAC channel is controlled entirely by 3 registers:\n\n$2A: DAC channel PCM sample (unsigned 8-bit)\n$2B: DAC channel enabled (Bit 7)\n$B6: L/R panning flags and LFO sensitivity for channels 3 (group 1) and 6 (group 2)\n\nWhen enabled via register $2B, the DAC channel replaces channel 6â€™s output with the 8-bit PCM sample value that was last written to register $2A. It respects the channel 6 L/R panning flags in register $B6 (group 2), but otherwise none of the channel 6 configuration affects the DAC channel.\nPCM samples are interpreted as unsigned 8-bit values (0-255), but for output theyâ€™re converted to signed 8-bit by applying a bias of -128. This signed 8-bit sample is then bit shifted to match the scale of FM synthesis channel outputs.\nThis isnâ€™t really relevant until later, but FM channel outputs are signed 14-bit, so the DAC channel implementation is as simple as:\n\n1\n2\n3\n\nfn dac_channel(sample: u8) -> i16 {\n    (i16::from(sample) - 128) << 6\n}\nCopy\n\nThe YM2612â€™s DAC only has a 9-bit digital input, but itâ€™s not possible to set the truncated lower 5 bits using the DAC channel, so thatâ€™s not important for now.\nFor generating an output sample, you can pretend that youâ€™re mixing 6 channels whose outputs are each on an i14 scale, except right now only 1 channel is emulated:\n\n1\n2\n3\n4\n5\n6\n7\n\nfn output_sample(dac_channel_out: i16) -> f64 {\n    // Convert from i14 scale to [-1, +1)\n    let sample = f64::from(dac_channel_out) / f64::from(1 << 13);\n\n    // Divide by 6 because this is only 1 of 6 channels being mixed\n    sample / 6.0\n}\nCopy\n\nYou could also accumulate the channel outputs into an i32 instead of converting to floating-point, though youâ€™ll likely want to convert to floating-point eventually in order to ensure that volume is scaled correctly.\nWire this up to an audio output, and as long as your emulated Z80 timing is fairly accurate, this is enough to (technically) get some YM2612 audio in games! Including the iconic â€œSEGAâ€ intro sound in the Sonic games:\n\nSonic the Hedgehog 2 - SEGA sound\n\nSonic the Hedgehog 2 - Emerald Hill Zone (Percussion)\nItâ€™s a start!\nDAC channel output tends to sound very crunchy and noisy. This is partly because thereâ€™s no FIFO or anything to buffer incoming samples - games must constantly send samples to the YM2612 at the desired sample rate using very carefully timed code.\nPlaying at high sample rates doesnâ€™t leave the Z80 with much time to do anything else, plus the timing gets thrown off by bus arbiter delays if the Z80 ever needs to access the 68000 side of the bus (e.g. to read from cartridge ROM). Also, the 68000 needs to remove the Z80 from the bus to safely read from the controller ports, which pretty much every game does at least once per frame.\nAudio quality is further degraded by the chip effectively nearest-neighbor resampling up to 53267 Hz. This introduces lots of additional audio aliasing and noise, particularly if the source data is at a very low sample rate.\nTo Be Continued\nThe next post will cover a probably more interesting topic: exactly how the phase generators in the FM synthesis channels work.\nPart 2 - Phase\n\n            Author: jsgroth\n\n                Link: https://jsgroth.dev/blog/posts/emulating-ym2612-part-1/\n\n            License: CC BY-NC-SA 4.0",
    "summary": {
      "en": "This text is the first part of a series about emulating the Yamaha YM2612 sound chip, used in the Sega Genesis. \n\n**Key Points:**\n\n1. **Challenge of Emulation**: The YM2612 is difficult to emulate due to its many specific details and quirks that affect game audio. Minor mistakes in emulation can lead to significant audio errors.\n\n2. **Source of Information**: The author relies on a detailed online thread and various resources, noting that some official documentation is inaccurate.\n\n3. **FM Synthesis Overview**: The YM2612 uses four-operator FM synthesis, allowing for a wider variety of sounds compared to other chips. It has six audio channels, each capable of complex configurations.\n\n4. **Integration with Genesis**: The YM2612 is integrated with the Sega Genesis, sharing a clock signal with the 68000 CPU. Different components update at various rates, affecting audio output.\n\n5. **Interface**: The Genesis has a split bus for CPU communication. The Z80 CPU controls the YM2612, allowing for efficient audio processing without delays.\n\n6. **Register Access**: The YM2612 has four write ports for sending data and one read port for status feedback. The read port behavior can vary between models, affecting some gamesâ€™ audio.\n\n7. **DAC Channel**: The DAC channel, which outputs PCM samples, is relatively straightforward to emulate. It processes 8-bit unsigned samples and converts them for output.\n\n8. **Audio Output Challenges**: Emulating the YM2612 involves careful timing and can result in noisy audio due to the lack of buffering and timing issues from CPU interactions.\n\nThe series will continue with more details on phase generators in FM synthesis channels.",
      "ko": "ì´ í…ìŠ¤íŠ¸ëŠ” ì„¸ê°€ ì œë„¤ì‹œìŠ¤ì—ì„œ ì‚¬ìš©ëœ ì•¼ë§ˆí•˜ YM2612 ì‚¬ìš´ë“œ ì¹©ì„ ì—ë®¬ë ˆì´ì…˜í•˜ëŠ” ì‹œë¦¬ì¦ˆì˜ ì²« ë²ˆì§¸ ë¶€ë¶„ì…ë‹ˆë‹¤.\n\nYM2612ì˜ ì—ë®¬ë ˆì´ì…˜ì€ ì—¬ëŸ¬ ê°€ì§€ ì„¸ë¶€ ì‚¬í•­ê³¼ íŠ¹ì„± ë•Œë¬¸ì— ì–´ë ¤ìš´ ë„ì „ ê³¼ì œì…ë‹ˆë‹¤. ì—ë®¬ë ˆì´ì…˜ì—ì„œ ì‘ì€ ì‹¤ìˆ˜ê°€ ë°œìƒí•˜ë©´ ì˜¤ë””ì˜¤ì— í° ì˜¤ë¥˜ê°€ ìƒê¸¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì €ìëŠ” ìì„¸í•œ ì˜¨ë¼ì¸ í† ë¡ ê³¼ ë‹¤ì–‘í•œ ìë£Œë¥¼ ì°¸ê³ í•˜ë©°, ì¼ë¶€ ê³µì‹ ë¬¸ì„œê°€ ë¶€ì •í™•í•˜ë‹¤ëŠ” ì ì„ ì§€ì í•©ë‹ˆë‹¤.\n\nYM2612ëŠ” ë„¤ ê°œì˜ ì—°ì‚°ìë¥¼ ì‚¬ìš©í•˜ëŠ” FM í•©ì„±ì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ì—¬, ë‹¤ë¥¸ ì¹©ì— ë¹„í•´ ë” ë‹¤ì–‘í•œ ì†Œë¦¬ë¥¼ ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ì¹©ì€ ì—¬ì„¯ ê°œì˜ ì˜¤ë””ì˜¤ ì±„ë„ì„ ê°€ì§€ê³  ìˆìœ¼ë©°, ê° ì±„ë„ì€ ë³µì¡í•œ ì„¤ì •ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. YM2612ëŠ” ì„¸ê°€ ì œë„¤ì‹œìŠ¤ì™€ í†µí•©ë˜ì–´ ìˆìœ¼ë©°, 68000 CPUì™€ í´ëŸ­ ì‹ í˜¸ë¥¼ ê³µìœ í•©ë‹ˆë‹¤. ë‹¤ì–‘í•œ êµ¬ì„± ìš”ì†Œê°€ ì„œë¡œ ë‹¤ë¥¸ ì†ë„ë¡œ ì—…ë°ì´íŠ¸ë˜ê¸° ë•Œë¬¸ì— ì˜¤ë””ì˜¤ ì¶œë ¥ì— ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤.\n\nì œë„¤ì‹œìŠ¤ëŠ” CPU í†µì‹ ì„ ìœ„í•œ ë¶„ë¦¬ëœ ë²„ìŠ¤ë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. Z80 CPUê°€ YM2612ë¥¼ ì œì–´í•˜ì—¬ ì§€ì—° ì—†ì´ íš¨ìœ¨ì ì¸ ì˜¤ë””ì˜¤ ì²˜ë¦¬ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. YM2612ëŠ” ë°ì´í„°ë¥¼ ì „ì†¡í•˜ê¸° ìœ„í•œ ë„¤ ê°œì˜ ì“°ê¸° í¬íŠ¸ì™€ ìƒíƒœ í”¼ë“œë°±ì„ ìœ„í•œ í•˜ë‚˜ì˜ ì½ê¸° í¬íŠ¸ë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ì½ê¸° í¬íŠ¸ì˜ ë™ì‘ì€ ëª¨ë¸ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆì–´ ì¼ë¶€ ê²Œì„ì˜ ì˜¤ë””ì˜¤ì— ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nPCM ìƒ˜í”Œì„ ì¶œë ¥í•˜ëŠ” DAC ì±„ë„ì€ ë¹„êµì  ê°„ë‹¨í•˜ê²Œ ì—ë®¬ë ˆì´ì…˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ì±„ë„ì€ 8ë¹„íŠ¸ ë¶€í˜¸ ì—†ëŠ” ìƒ˜í”Œì„ ì²˜ë¦¬í•˜ê³  ì´ë¥¼ ì¶œë ¥ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. YM2612ì˜ ì—ë®¬ë ˆì´ì…˜ì€ ì„¸ì‹¬í•œ íƒ€ì´ë°ì´ í•„ìš”í•˜ë©°, CPU ìƒí˜¸ì‘ìš©ì—ì„œ ë°œìƒí•˜ëŠ” íƒ€ì´ë° ë¬¸ì œì™€ ë²„í¼ë§ ë¶€ì¡±ìœ¼ë¡œ ì¸í•´ ì‹œë„ëŸ¬ìš´ ì˜¤ë””ì˜¤ê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nì´ ì‹œë¦¬ì¦ˆëŠ” FM í•©ì„± ì±„ë„ì˜ ìœ„ìƒ ìƒì„±ê¸°ì— ëŒ€í•œ ë” ë§ì€ ì„¸ë¶€ ì‚¬í•­ìœ¼ë¡œ ê³„ì†ë  ì˜ˆì •ì…ë‹ˆë‹¤.",
      "ja": "ã“ã®ãƒ†ã‚­ã‚¹ãƒˆã¯ã€ã‚»ã‚¬ãƒ»ã‚¸ã‚§ãƒã‚·ã‚¹ã§ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹ãƒ¤ãƒãƒYM2612éŸ³æºãƒãƒƒãƒ—ã®ã‚¨ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã«é–¢ã™ã‚‹ã‚·ãƒªãƒ¼ã‚ºã®ç¬¬ä¸€éƒ¨ã§ã™ã€‚\n\nYM2612ã®ã‚¨ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¯ã€ãã®ç‰¹æœ‰ã®è©³ç´°ã‚„ã‚¯ã‚»ãŒã‚²ãƒ¼ãƒ ã®éŸ³å£°ã«å½±éŸ¿ã‚’ä¸ãˆã‚‹ãŸã‚ã€éå¸¸ã«é›£ã—ã„ã§ã™ã€‚ã‚¨ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã«ãŠã‘ã‚‹å°ã•ãªãƒŸã‚¹ãŒã€éŸ³å£°ã®å¤§ããªã‚¨ãƒ©ãƒ¼ã«ã¤ãªãŒã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚\n\nè‘—è€…ã¯ã€è©³ç´°ãªã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã‚¹ãƒ¬ãƒƒãƒ‰ã‚„ã•ã¾ã–ã¾ãªãƒªã‚½ãƒ¼ã‚¹ã‚’å‚è€ƒã«ã—ã¦ãŠã‚Šã€ä¸€éƒ¨ã®å…¬å¼æ–‡æ›¸ãŒä¸æ­£ç¢ºã§ã‚ã‚‹ã“ã¨ã«ã‚‚è¨€åŠã—ã¦ã„ã¾ã™ã€‚\n\nYM2612ã¯ã€4ã‚ªãƒšãƒ¬ãƒ¼ã‚¿ãƒ¼ã®FMåˆæˆã‚’ä½¿ç”¨ã—ã¦ãŠã‚Šã€ä»–ã®ãƒãƒƒãƒ—ã¨æ¯”ã¹ã¦å¤šæ§˜ãªéŸ³ã‚’ç”Ÿæˆã§ãã¾ã™ã€‚6ã¤ã®ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒãƒ£ãƒ³ãƒãƒ«ã‚’æŒã¡ã€ãã‚Œãã‚ŒãŒè¤‡é›‘ãªè¨­å®šã‚’å¯èƒ½ã«ã—ã¦ã„ã¾ã™ã€‚\n\nYM2612ã¯ã‚»ã‚¬ãƒ»ã‚¸ã‚§ãƒã‚·ã‚¹ã«çµ±åˆã•ã‚Œã¦ãŠã‚Šã€68000 CPUã¨ã‚¯ãƒ­ãƒƒã‚¯ä¿¡å·ã‚’å…±æœ‰ã—ã¦ã„ã¾ã™ã€‚ç•°ãªã‚‹ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆãŒã•ã¾ã–ã¾ãªé€Ÿåº¦ã§æ›´æ–°ã•ã‚Œã‚‹ãŸã‚ã€éŸ³å£°å‡ºåŠ›ã«å½±éŸ¿ã‚’ä¸ãˆã¾ã™ã€‚\n\nã‚¸ã‚§ãƒã‚·ã‚¹ã¯CPUé€šä¿¡ã®ãŸã‚ã«åˆ†å‰²ãƒã‚¹ã‚’æŒã£ã¦ã„ã¾ã™ã€‚Z80 CPUãŒYM2612ã‚’åˆ¶å¾¡ã—ã€é…å»¶ãªãåŠ¹ç‡çš„ã«éŸ³å£°å‡¦ç†ã‚’è¡Œã„ã¾ã™ã€‚\n\nYM2612ã«ã¯ãƒ‡ãƒ¼ã‚¿ã‚’é€ä¿¡ã™ã‚‹ãŸã‚ã®4ã¤ã®æ›¸ãè¾¼ã¿ãƒãƒ¼ãƒˆã¨ã€ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”¨ã®1ã¤ã®èª­ã¿å–ã‚Šãƒãƒ¼ãƒˆãŒã‚ã‚Šã¾ã™ã€‚èª­ã¿å–ã‚Šãƒãƒ¼ãƒˆã®å‹•ä½œã¯ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã£ã¦ç•°ãªã‚Šã€ä¸€éƒ¨ã®ã‚²ãƒ¼ãƒ ã®éŸ³å£°ã«å½±éŸ¿ã‚’ä¸ãˆã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚\n\nDACãƒãƒ£ãƒ³ãƒãƒ«ã¯PCMã‚µãƒ³ãƒ—ãƒ«ã‚’å‡ºåŠ›ã™ã‚‹ã‚‚ã®ã§ã€ã‚¨ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¯æ¯”è¼ƒçš„ç°¡å˜ã§ã™ã€‚8ãƒ“ãƒƒãƒˆã®ç¬¦å·ãªã—ã‚µãƒ³ãƒ—ãƒ«ã‚’å‡¦ç†ã—ã€å‡ºåŠ›ç”¨ã«å¤‰æ›ã—ã¾ã™ã€‚\n\nYM2612ã®ã‚¨ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã«ã¯æ…é‡ãªã‚¿ã‚¤ãƒŸãƒ³ã‚°ãŒå¿…è¦ã§ã€CPUã¨ã®ç›¸äº’ä½œç”¨ã«ã‚ˆã‚‹ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°ã®æ¬ å¦‚ã‚„ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã®å•é¡Œã‹ã‚‰ã€ãƒã‚¤ã‚ºã®å¤šã„éŸ³å£°ãŒç”Ÿã˜ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚\n\nã“ã®ã‚·ãƒªãƒ¼ã‚ºã¯ã€FMåˆæˆãƒãƒ£ãƒ³ãƒãƒ«ã«ãŠã‘ã‚‹ä½ç›¸ç™ºç”Ÿå™¨ã«ã¤ã„ã¦ã®è©³ç´°ã‚’ç¶šã‘ã¦ã„ãã¾ã™ã€‚"
    }
  },
  {
    "id": "c8926decaaaf557b",
    "title": {
      "en": "Entropy Attacks",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://blog.cr.yp.to/20140205-entropy.html",
    "score": 93,
    "by": "todsacerdoti",
    "time": 1742905238,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "541246337a07996d",
    "title": {
      "en": "Architecture Patterns with Python",
      "ko": "íŒŒì´ì¬ ì•„í‚¤í…ì²˜ íŒ¨í„´",
      "ja": "Pythonå»ºç¯‰ãƒ‘ã‚¿ãƒ¼ãƒ³"
    },
    "type": "story",
    "url": "https://www.cosmicpython.com/book/preface.html",
    "score": 458,
    "by": "asicsp",
    "time": 1743141447,
    "content": "Preface\n\nYou may be wondering who we are and why we wrote this book.\n\nAt the end of Harryâ€™s last book,\nTest-Driven Development with Python (Oâ€™Reilly),\nhe found himself asking a bunch of questions about architecture, such as,\nWhatâ€™s the best way of structuring your application so that itâ€™s easy to test?\nMore specifically, so that your core business logic is covered by unit tests,\nand so that you minimize the number of integration and end-to-end tests you need?\nHe made vague references to \"Hexagonal Architecture\" and \"Ports and Adapters\"\nand \"Functional Core, Imperative Shell,\" but if he was honest, heâ€™d have to\nadmit that these werenâ€™t things he really understood or had done in practice.\n\nAnd then he was lucky enough to run into Bob, who has the answers to all these\nquestions.\n\nBob ended up as a software architect because nobody else on his team was\ndoing it. He turned out to be pretty bad at it, but he was lucky enough to run\ninto Ian Cooper, who taught him new ways of writing and thinking about code.\n\nManaging Complexity, Solving Business Problems\n\nWe both work for MADE.com, a European ecommerce company that sells furniture\nonline; there, we apply the techniques in this book to build distributed systems\nthat model real-world business problems. Our example domain is the first system\nBob built for MADE, and this book is an attempt to write down all the stuff we\nhave to teach new programmers when they join one of our teams.\n\nMADE.com operates a global supply chain of freight partners and manufacturers.\nTo keep costs low, we try to optimize the delivery of stock to our\nwarehouses so that we donâ€™t have unsold goods lying around the place.\n\nIdeally, the sofa that you want to buy will arrive in port on the very day\nthat you decide to buy it, and weâ€™ll ship it straight to your house without\never storing it. Getting the timing right is a tricky balancing act when goods take\nthree months to arrive by container ship. Along the way, things get broken or water\ndamaged, storms cause unexpected delays, logistics partners mishandle goods,\npaperwork goes missing, customers change their minds and amend their orders,\nand so on.\n\nWe solve those problems by building intelligent software representing the\nkinds of operations taking place in the real world so that we can automate as\nmuch of the business as possible.\n\nWhy Python?\n\nIf youâ€™re reading this book, we probably donâ€™t need to convince you that Python\nis great, so the real question is \"Why does the Python community need a book\nlike this?\" The answer is about Pythonâ€™s popularity and maturity: although Python is\nprobably the worldâ€™s fastest-growing programming language and is nearing the top\nof the absolute popularity tables, itâ€™s only just starting to take on the kinds\nof problems that the C# and Java world has been working on for years.\nStartups become real businesses; web apps and scripted automations are becoming\n(whisper it) enterprise software.\n\nIn the Python world, we often quote the Zen of Python:\n\"There should be oneâ€”and preferably only oneâ€”obvious way to do it.\"[1]\nUnfortunately, as project size grows, the most obvious way of doing things\nisnâ€™t always the way that helps you manage complexity and evolving\nrequirements.\n\nNone of the techniques and patterns we discuss in this book are\nnew, but they are mostly new to the Python world. And this book isnâ€™t\na replacement for the classics in the field such as Eric Evansâ€™s\nDomain-Driven Design\nor Martin Fowlerâ€™s Patterns of\nEnterprise Application Architecture (both published by Addison-Wesley Professional)â€”which we often refer to and\nencourage you to go and read.\n\nBut all the classic code examples in the literature do tend to be written in\nJava or C++/#, and if youâ€™re a Python person and havenâ€™t used either of\nthose languages in a long time (or indeed ever), those code listings can be\nquiteâ€¦trying. Thereâ€™s a reason the latest edition of that other classic text, Fowlerâ€™s\nRefactoring (Addison-Wesley Professional), is in JavaScript.\n\nTDD, DDD, and Event-Driven Architecture\n\nIn order of notoriety, we know of three tools for managing complexity:\n\nTest-driven development (TDD) helps us to build code that is correct\nand enables us to refactor or add new features, without fear of regression.\nBut it can be hard to get the best out of our tests: How do we make sure\nthat they run as fast as possible? That we get as much coverage and feedback\nfrom fast, dependency-free unit tests and have the minimum number of slower,\nflaky end-to-end tests?\n\nDomain-driven design (DDD) asks us to focus our efforts on building a good\nmodel of the business domain, but how do we make sure that our models arenâ€™t\nencumbered with infrastructure concerns and donâ€™t become hard to change?\n\nLoosely coupled (micro)services integrated via messages (sometimes called\nreactive microservices) are a well-established answer to managing complexity\nacross multiple applications or business domains. But itâ€™s not always\nobvious how to make them fit with the established tools of\nthe Python worldâ€”Flask, Django, Celery, and so on.\n\nNote\n\nDonâ€™t be put off if youâ€™re not working with (or interested in) microservices.\n    The vast majority of the patterns we discuss,\n    including much of the event-driven architecture material,\n    is absolutely applicable in a monolithic architecture.\n\nOur aim with this book is to introduce several classic architectural patterns\nand show how they support TDD, DDD, and event-driven services.  We hope\nit will serve as a reference for implementing them in a Pythonic way, and that\npeople can use it as a first step toward further research  in this field.\n\nWho Should Read This Book\n\nHere are a few things we assume about you, dear reader:\n\nYouâ€™ve been close to some reasonably complex Python applications.\n\nYouâ€™ve seen some of the pain that comes with trying to manage\nthat complexity.\n\nYou donâ€™t necessarily know anything about DDD or any of the\nclassic application architecture patterns.\n\nWe structure our explorations of architectural patterns around an example app,\nbuilding it up chapter by chapter. We use TDD at\nwork, so we tend to show listings of tests first, followed by implementation.\nIf youâ€™re not used to working test-first, it may feel a little strange at\nthe beginning, but we hope youâ€™ll soon get used to seeing code \"being used\"\n(i.e., from the outside) before you see how itâ€™s built on the inside.\n\nWe use some specific Python frameworks and technologies, including Flask,\nSQLAlchemy, and pytest, as well as Docker and Redis. If youâ€™re already\nfamiliar with them, that wonâ€™t hurt, but we donâ€™t think itâ€™s required.  One of\nour main aims with this book is to build an architecture for which specific\ntechnology choices become minor implementation details.\n\nA Brief Overview of What Youâ€™ll Learn\n\nThe book is divided into two parts; hereâ€™s a look at the topics weâ€™ll cover\nand the chapters they live in.\n\n#part1\n\nDomain modeling and DDD (Chapters 1, 2 and 7)\n\nAt some level, everyone has learned the lesson that complex business\nproblems need to be reflected in code, in the form of a model of the domain.\nBut why does it always seem to be so hard to do without getting tangled\nup with infrastructure concerns, our web frameworks, or whatever else?\nIn the first chapter we give a broad overview of domain modeling and DDD, and we\nshow how to get started with a model that has no external dependencies, and\nfast unit tests. Later we return to DDD patterns to discuss how to choose\nthe right aggregate, and how this choice relates to questions of data\nintegrity.\n\nRepository, Service Layer, and Unit of Work patterns (Chapters 2, 4, and 5)\n\nIn these three chapters we present three closely related and\nmutually reinforcing patterns that support our ambition to keep\nthe model free of extraneous dependencies.  We build a layer of\nabstraction around persistent storage, and we build a service\nlayer to define the entrypoints to our system and capture the\nprimary use cases. We show how this layer makes it easy to build\nthin entrypoints to our system, whether itâ€™s a Flask API or a CLI.\n\nSome thoughts on testing and abstractions (Chapter 3 and 5)\n\nAfter presenting the first abstraction (the Repository pattern), we take the\nopportunity for a general discussion of how to choose abstractions, and\nwhat their role is in choosing how our software is coupled together. After\nwe introduce the Service Layer pattern, we talk a bit about achieving a test pyramid\nand writing unit tests at the highest possible level of abstraction.\n\n#part2\n\nEvent-driven architecture (Chapters 8-11)\n\nWe introduce three more mutually reinforcing patterns:\nthe Domain Events, Message Bus, and Handler patterns.\nDomain events are a vehicle for capturing the idea that\nsome interactions with a system are triggers for others.\nWe use  a message bus to allow actions to trigger events\nand call appropriate handlers.\nWe move on to discuss how events can be used as a pattern\nfor integration between services in a microservices architecture.\nFinally, we distinguish between commands and events.\nOur application is now fundamentally a message-processing system.\n\nCommand-query responsibility segregation ([chapter_12_cqrs])\n\nWe present an example of command-query responsibility segregation,\nwith and without events.\n\nDependency injection ([chapter_13_dependency_injection])\n\nWe tidy up our explicit and implicit dependencies and implement a\nsimple dependency injection framework.\n\nAdditional Content\n\nHow do I get there from here? ([epilogue_1_how_to_get_there_from_here])\n\nImplementing architectural patterns always looks easy when you show a simple\nexample, starting from scratch, but many of you will probably be wondering how\nto apply these principles to existing software. Weâ€™ll provide a\nfew pointers in the epilogue and some links to further reading.\n\nExample Code and Coding Along\n\nYouâ€™re reading a book, but youâ€™ll probably agree with us when we say that\nthe best way to learn about code is to code.  We learned most of what we know\nfrom pairing with people, writing code with them, and learning by doing, and\nweâ€™d like to re-create that experience as much as possible for you in this book.\n\nAs a result, weâ€™ve structured the book around a single example project\n(although we do sometimes throw in other examples). Weâ€™ll build up this project as the chapters progress, as if youâ€™ve paired with us and\nweâ€™re explaining what weâ€™re doing and why at each step.\n\nBut to really get to grips with these patterns, you need to mess about with the\ncode and get a feel for how it works. Youâ€™ll find all the code on\nGitHub; each chapter has its own branch. You can find a list of the branches on GitHub as well.\n\nHere are three ways you might code along with the book:\n\nStart your own repo and try to build up the app as we do, following the\nexamples from listings in the book, and occasionally looking to our repo\nfor hints. A word of warning, however: if youâ€™ve read Harryâ€™s previous book\nand coded along with that, youâ€™ll find that this book requires you to figure out more on\nyour own; you may need to lean pretty heavily on the working versions on GitHub.\n\nTry to apply each pattern, chapter by chapter, to your own (preferably\nsmall/toy) project, and see if you can make it work for your use case.  This\nis high risk/high reward (and high effort besides!). It may take quite some\nwork to get things working for the specifics of your project, but on the other\nhand, youâ€™re likely to learn the most.\n\nFor less effort, in each chapter we outline an \"Exercise for the Reader,\"\nand point you to a GitHub location where you can download some partially finished\ncode for the chapter with a few missing parts to write yourself.\n\nParticularly if youâ€™re intending to apply some of these patterns in your own\nprojects, working through a simple example is a great way to\nsafely practice.\n\nTip\n\nAt the very least, do a git checkout of the code from our repo as you\n    read each chapter. Being able to jump in and see the code in the context of\n    an actual working app will help answer a lot of questions as you go, and\n    makes everything more real. Youâ€™ll find instructions for how to do that\n    at the beginning of each chapter.\n\nLicense\n\nThe code (and the online version of the book) is licensed under a Creative\nCommons CC BY-NC-ND license, which means you are free to copy and share it with\nanyone you like, for non-commercial purposes, as long as you give attribution.\nIf you want to re-use any of the content from this book and you have any\nworries about the license, contact Oâ€™Reilly at permissions@oreilly.com.\n\nThe print edition is licensed differently; please see the copyright page.\n\nConventions Used in This Book\n\nThe following typographical conventions are used in this book:\n\nItalic\n\nIndicates new terms, URLs, email addresses, filenames, and file extensions.\n\nConstant width\n\nUsed for program listings, as well as within paragraphs to refer to program elements such as variable or function names, databases, data types, environment variables, statements, and keywords.\n\nConstant width bold\n\nShows commands or other text that should be typed literally by the user.\n\nConstant width italic\n\nShows text that should be replaced with user-supplied values or by values determined by context.\n\nTip\n\nThis element signifies a tip or suggestion.\n\nNote\n\nThis element signifies a general note.\n\nWarning\n\nThis element indicates a warning or caution.\n\nOâ€™Reilly Online Learning\n\nNote\n\nFor more than 40 years, Oâ€™Reilly Media has provided technology and business training, knowledge, and insight to help companies succeed.\n\nOur unique network of experts and innovators share their knowledge and expertise through books, articles, conferences, and our online learning platform. Oâ€™Reillyâ€™s online learning platform gives you on-demand access to live training courses, in-depth learning paths, interactive coding environments, and a vast collection of text and video from Oâ€™Reilly and 200+ other publishers. For more information, please visit http://oreilly.com.\n\nHow to Contact Oâ€™Reilly\n\nPlease address comments and questions concerning this book to the publisher:\n\n  Oâ€™Reilly Media, Inc.\n  1005 Gravenstein Highway North\n  Sebastopol, CA 95472\n  800-998-9938 (in the United States or Canada)\n  707-829-0515 (international or local)\n  707-829-0104 (fax)\n\nWe have a web page for this book, where we list errata, examples, and any additional information. You can access this page at https://oreil.ly/architecture-patterns-python.\n\nEmail bookquestions@oreilly.com to comment or ask technical questions about this book.\n\nFor more information about our books, courses, conferences, and news, see our website at http://www.oreilly.com.\n\nFind us on Facebook: http://facebook.com/oreilly\n\nFollow us on Twitter: http://twitter.com/oreillymedia\n\nWatch us on YouTube: http://www.youtube.com/oreillymedia\n\nAcknowledgments\n\nTo our tech reviewers, David Seddon, Ed Jung, and Hynek Schlawack: we absolutely\ndo not deserve you. You are all incredibly dedicated, conscientious, and\nrigorous. Each one of you is immensely smart, and your different points of\nview were both useful and complementary to each other. Thank you from the\nbottom of our hearts.\n\nGigantic thanks also to all our readers so far for their comments and\nsuggestions:\nIan Cooper, Abdullah Ariff, Jonathan Meier, Gil GonÃ§alves, Matthieu Choplin,\nBen Judson, James Gregory, Åukasz Lechowicz, Clinton Roy, Vitorino AraÃºjo,\nSusan Goodbody, Josh Harwood, Daniel Butler, Liu Haibin, Jimmy Davies, Ignacio\nVergara Kausel, Gaia Canestrani, Renne Rocha, pedroabi, Ashia Zawaduk, Jostein\nLeira, Brandon Rhodes, Jazeps Basko, simkimsia, Adrien Brunet, Sergey Nosko,\nDmitry Bychkov,\nand many more; our apologies if we missed you on this list.\n\nSuper-mega-thanks to our editor Corbin Collins for his gentle chivvying, and\nfor being a tireless advocate of the reader. Similarly-superlative thanks to\nthe production staff, Katherine Tozer, Sharon Wilkey, Ellen Troutman-Zaig, and\nRebecca Demarest, for your dedication, professionalism, and attention to\ndetail. This book is immeasurably improved thanks to you.\n\nAny errors remaining in the book are our own, naturally.\n\n  << Previous - Appendix E: Validation\n  Next - Introduction >>",
    "summary": {
      "en": "### Summary of the Preface\n\nThis book is written by Harry and Bob, who work at MADE.com, an ecommerce company that sells furniture online. After Harry's previous book on Test-Driven Development (TDD) with Python, he had many questions about application architecture and testing practices. He met Bob, who has valuable insights on these topics, and they decided to compile their knowledge into this book.\n\nThey aim to address how to effectively structure applications for testing while managing complexity and adapting to changing business needs. The book will discuss various architectural patterns and practices, particularly focusing on Python, which is becoming more widely used for complex applications.\n\nThe authors explain that while many concepts are not new, they are often unfamiliar to the Python community. The book will cover themes like TDD, Domain-Driven Design (DDD), and event-driven architecture, helping readers understand how to apply these patterns using Python frameworks like Flask and SQLAlchemy.\n\nThe book is structured around a single example project, allowing readers to learn by coding along. It includes exercises to practice the concepts discussed. The authors encourage readers to engage with the provided code on GitHub to enhance their learning experience.",
      "ko": "ì´ ì±…ì€ ì˜¨ë¼ì¸ ê°€êµ¬ íŒë§¤ íšŒì‚¬ì¸ MADE.comì—ì„œ ì¼í•˜ëŠ” í•´ë¦¬ì™€ ë°¥ì´ ì¼ìŠµë‹ˆë‹¤. í•´ë¦¬ëŠ” ì´ì „ì— íŒŒì´ì¬ì„ ì´ìš©í•œ í…ŒìŠ¤íŠ¸ ì£¼ë„ ê°œë°œ(TDD)ì— ê´€í•œ ì±…ì„ ì§‘í•„í•œ í›„, ì• í”Œë¦¬ì¼€ì´ì…˜ ì•„í‚¤í…ì²˜ì™€ í…ŒìŠ¤íŠ¸ ê´€í–‰ì— ëŒ€í•´ ë§ì€ ì§ˆë¬¸ì„ ê°€ì§€ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë˜ ì¤‘, ì´ ì£¼ì œì— ëŒ€í•œ ê·€ì¤‘í•œ í†µì°°ë ¥ì„ ê°€ì§„ ë°¥ì„ ë§Œë‚˜ê²Œ ë˜ì—ˆê³ , ê·¸ë“¤ì˜ ì§€ì‹ì„ ëª¨ì•„ ì´ ì±…ì„ ì§‘í•„í•˜ê¸°ë¡œ ê²°ì •í–ˆìŠµë‹ˆë‹¤.\n\nì´ ì±…ì˜ ëª©í‘œëŠ” ë³µì¡ì„±ì„ ê´€ë¦¬í•˜ê³  ë³€í™”í•˜ëŠ” ë¹„ì¦ˆë‹ˆìŠ¤ ìš”êµ¬ì— ì ì‘í•˜ë©´ì„œ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ êµ¬ì¡°ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì„¤ê³„í•˜ëŠ” ë°©ë²•ì„ ë‹¤ë£¨ëŠ” ê²ƒì…ë‹ˆë‹¤. ë‹¤ì–‘í•œ ì•„í‚¤í…ì²˜ íŒ¨í„´ê³¼ ì‹¤ì²œ ë°©ë²•ì— ëŒ€í•´ ë…¼ì˜í•˜ë©°, íŠ¹íˆ ë³µì¡í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ì— ì ì  ë” ë§ì´ ì‚¬ìš©ë˜ê³  ìˆëŠ” íŒŒì´ì¬ì— ì¤‘ì ì„ ë‘ê³  ìˆìŠµë‹ˆë‹¤.\n\nì €ìë“¤ì€ ë§ì€ ê°œë…ì´ ìƒˆë¡­ì§€ ì•Šì§€ë§Œ, íŒŒì´ì¬ ì»¤ë®¤ë‹ˆí‹°ì—ì„œëŠ” ì¢…ì¢… ë‚¯ì„¤ê²Œ ëŠê»´ì§„ë‹¤ê³  ì„¤ëª…í•©ë‹ˆë‹¤. ì´ ì±…ì€ TDD, ë„ë©”ì¸ ì£¼ë„ ì„¤ê³„(DDD), ì´ë²¤íŠ¸ ì£¼ë„ ì•„í‚¤í…ì²˜ì™€ ê°™ì€ ì£¼ì œë¥¼ ë‹¤ë£¨ë©°, ë…ìë“¤ì´ Flaskì™€ SQLAlchemyì™€ ê°™ì€ íŒŒì´ì¬ í”„ë ˆì„ì›Œí¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ëŸ¬í•œ íŒ¨í„´ì„ ì ìš©í•˜ëŠ” ë°©ë²•ì„ ì´í•´í•˜ë„ë¡ ë•ìŠµë‹ˆë‹¤.\n\nì±…ì€ í•˜ë‚˜ì˜ ì˜ˆì œ í”„ë¡œì íŠ¸ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆì–´ ë…ìë“¤ì´ ì½”ë“œë¥¼ ë”°ë¼ ì‘ì„±í•˜ë©´ì„œ ë°°ìš¸ ìˆ˜ ìˆë„ë¡ ë•ìŠµë‹ˆë‹¤. ë…¼ì˜ëœ ê°œë…ì„ ì—°ìŠµí•  ìˆ˜ ìˆëŠ” ì—°ìŠµë¬¸ì œë„ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì €ìë“¤ì€ ë…ìë“¤ì´ GitHubì— ì œê³µëœ ì½”ë“œë¥¼ í™œìš©í•˜ì—¬ í•™ìŠµ ê²½í—˜ì„ í–¥ìƒì‹œí‚¤ê¸°ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.",
      "ja": "ã“ã®æœ¬ã¯ã€ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã§å®¶å…·ã‚’è²©å£²ã™ã‚‹eã‚³ãƒãƒ¼ã‚¹ä¼æ¥­MADE.comã§åƒããƒãƒªãƒ¼ã¨ãƒœãƒ–ã«ã‚ˆã£ã¦æ›¸ã‹ã‚Œã¾ã—ãŸã€‚ãƒãƒªãƒ¼ã¯ä»¥å‰ã€Pythonã‚’ä½¿ã£ãŸãƒ†ã‚¹ãƒˆé§†å‹•é–‹ç™ºï¼ˆTDDï¼‰ã«é–¢ã™ã‚‹æœ¬ã‚’åŸ·ç­†ã—ã¾ã—ãŸãŒã€ãã®ä¸­ã§ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚„ãƒ†ã‚¹ãƒˆæ‰‹æ³•ã«ã¤ã„ã¦å¤šãã®ç–‘å•ã‚’æŒã¡ã¾ã—ãŸã€‚ãã“ã§ã€ã“ã‚Œã‚‰ã®ãƒ†ãƒ¼ãƒã«é–¢ã™ã‚‹è²´é‡ãªè¦‹è­˜ã‚’æŒã¤ãƒœãƒ–ã¨å‡ºä¼šã„ã€å½¼ã‚‰ã®çŸ¥è­˜ã‚’ã“ã®æœ¬ã«ã¾ã¨ã‚ã‚‹ã“ã¨ã«ã—ã¾ã—ãŸã€‚\n\nå½¼ã‚‰ã¯ã€ãƒ†ã‚¹ãƒˆã®ãŸã‚ã«ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’åŠ¹æœçš„ã«æ§‹ç¯‰ã—ã¤ã¤ã€è¤‡é›‘ã•ã‚’ç®¡ç†ã—ã€å¤‰åŒ–ã™ã‚‹ãƒ“ã‚¸ãƒã‚¹ãƒ‹ãƒ¼ã‚ºã«é©å¿œã™ã‚‹æ–¹æ³•ã‚’æ¢æ±‚ã—ã¾ã™ã€‚æœ¬æ›¸ã§ã¯ã€ã•ã¾ã–ã¾ãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚„å®Ÿè·µã«ã¤ã„ã¦è­°è«–ã—ã€ç‰¹ã«è¤‡é›‘ãªã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«åºƒãä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹Pythonã«ç„¦ç‚¹ã‚’å½“ã¦ã¾ã™ã€‚\n\nè‘—è€…ãŸã¡ã¯ã€å¤šãã®æ¦‚å¿µã¯æ–°ã—ã„ã‚‚ã®ã§ã¯ãªã„ãŒã€Pythonã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã«ã¯ã‚ã¾ã‚ŠçŸ¥ã‚‰ã‚Œã¦ã„ãªã„ã“ã¨ãŒå¤šã„ã¨èª¬æ˜ã—ã¦ã„ã¾ã™ã€‚æœ¬æ›¸ã§ã¯ã€TDDã€ãƒ‰ãƒ¡ã‚¤ãƒ³é§†å‹•è¨­è¨ˆï¼ˆDDDï¼‰ã€ã‚¤ãƒ™ãƒ³ãƒˆé§†å‹•ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¨ã„ã£ãŸãƒ†ãƒ¼ãƒã‚’å–ã‚Šä¸Šã’ã€Flaskã‚„SQLAlchemyãªã©ã®Pythonãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ä½¿ã£ã¦ã“ã‚Œã‚‰ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ã©ã®ã‚ˆã†ã«é©ç”¨ã™ã‚‹ã‹ã‚’ç†è§£ã§ãã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚\n\næœ¬æ›¸ã¯ã€å˜ä¸€ã®ä¾‹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’ä¸­å¿ƒã«æ§‹æˆã•ã‚Œã¦ãŠã‚Šã€èª­è€…ã¯ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿéš›ã«æ›¸ããªãŒã‚‰å­¦ã¶ã“ã¨ãŒã§ãã¾ã™ã€‚ã¾ãŸã€è­°è«–ã•ã‚ŒãŸæ¦‚å¿µã‚’ç·´ç¿’ã™ã‚‹ãŸã‚ã®æ¼”ç¿’ã‚‚å«ã¾ã‚Œã¦ã„ã¾ã™ã€‚è‘—è€…ãŸã¡ã¯ã€GitHubã«æä¾›ã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ã«ç©æ¥µçš„ã«å–ã‚Šçµ„ã‚€ã“ã¨ã§ã€å­¦ç¿’ä½“é¨“ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’å‹§ã‚ã¦ã„ã¾ã™ã€‚"
    }
  },
  {
    "id": "e1174069efe65757",
    "title": {
      "en": "Giant, fungus-like organism may be a completely unknown branch of life",
      "ko": "ê±°ëŒ€ ê³°íŒ¡ì´ ìƒëª…ì²´ì˜ ë¹„ë°€",
      "ja": "æœªçŸ¥ã®å·¨å¤§èŒé¡"
    },
    "type": "story",
    "url": "https://www.livescience.com/animals/giant-fungus-like-organism-may-be-a-completely-unknown-branch-of-life",
    "score": 299,
    "by": "wglb",
    "time": 1743117328,
    "content": "Animals\n\nGiant, fungus-like organism may be a completely unknown branch of life\n\nNews\n\nBy\nJess Thomson\n\npublished\n2 days ago\n\nAn ancient and enormous organism called Prototaxites, initially found to be a type of fungus, may actually be an unknown branch of life, researchers say.\n\nComments\n( 0 )\n()\n\nWhen you purchase through links on our site, we may earn an affiliate commission. Hereâ€™s how it works.\n\nwindow.vanilla.infiniteArticlesData = [];\n\nA painting of what Prototaxites may have looked like, 400 million years ago.\n(Image credit: Painting by Mary Parrish, National Museum of Natural History.)\n\nA bizarre ancient life-form, considered to be the first giant organism to live on land, may belong to a totally unknown branch of the tree of life, scientists say.These organisms, named Prototaxites, lived around 420 million to 375 million years ago during the Devonian period and resembled branchless, cylindrical tree trunks. These organisms would have been massive, with some species growing up to 26 feet (8 meters) tall and 3 feet (1 meter) wide.Since the first Prototaxites fossil was discovered in 1843, scientists haven't been sure whether they were a plant, fungus or even a type of algae. However, chemical analyses of Prototaxites fossils in 2007 suggested they were likely a giant ancient fungus.Now, according to a paper published March 17 on the preprint server bioRxiv, Prototaxites might not have been a humongous fungus after all â€” rather, it may have been an entirely different and previously unknown life-form. The study has not yet been peer-reviewed.All life on Earth is classified within three domains â€” bacteria, archaea and eukarya â€” with eukarya containing all multicellular organisms within the four kingdoms of fungi, animals, plants and protists. Bacteria and archaea contain only single-celled organisms.Previous chemical analysis of Prototaxites fossils indicated that they likely fed off decaying organisms, just like many fungi do today, rather than making their food from carbon dioxide in the air like plants.However, according to this new research, Prototaxites may actually have been part of a totally different kingdom of life, separate from fungi, plants, animals and protists.\n    window.sliceComponents = window.sliceComponents || {};\n\n    externalsScriptLoaded.then(() => {\n        window.reliablePageLoad.then(() => {\n            var componentContainer = document.querySelector(\"#slice-container-newsletterForm-articleInbodyContent-TT23hGQ7XJtsjBD4MeoeD7\");\n\n            if (componentContainer) {\n                var data = {\"layout\":\"inbodyContent\",\"header\":\"Sign up for the Live Science daily newsletter now\",\"tagline\":\"Get the world\\u2019s most fascinating discoveries delivered straight to your inbox.\",\"formFooterText\":\"By submitting your information you agree to the <a href=\\\"https:\\/\\/futureplc.com\\/terms-conditions\\/\\\" target=\\\"_blank\\\">Terms & Conditions<\\/a> and <a href=\\\"https:\\/\\/futureplc.com\\/privacy-policy\\/\\\" target=\\\"_blank\\\">Privacy Policy<\\/a> and are aged 16 or over.\",\"successMessage\":{\"body\":\"Thank you for signing up. You will receive a confirmation email shortly.\"},\"failureMessage\":\"There was a problem. Please refresh the page and try again.\",\"method\":\"POST\",\"inputs\":[{\"type\":\"hidden\",\"name\":\"NAME\"},{\"type\":\"email\",\"name\":\"MAIL\",\"placeholder\":\"Your Email Address\",\"required\":true},{\"type\":\"hidden\",\"name\":\"NEWSLETTER_CODE\",\"value\":\"XLS-D\"},{\"type\":\"hidden\",\"name\":\"LANG\",\"value\":\"EN\"},{\"type\":\"hidden\",\"name\":\"SOURCE\",\"value\":\"60\"},{\"type\":\"hidden\",\"name\":\"COUNTRY\"},{\"type\":\"checkbox\",\"name\":\"CONTACT_OTHER_BRANDS\",\"label\":{\"text\":\"Contact me with news and offers from other Future brands\"}},{\"type\":\"checkbox\",\"name\":\"CONTACT_PARTNERS\",\"label\":{\"text\":\"Receive email from us on behalf of our trusted partners or sponsors\"}},{\"type\":\"submit\",\"value\":\"Sign me up\",\"required\":true}],\"endpoint\":\"https:\\/\\/newsletter-subscribe.futureplc.com\\/v2\\/submission\\/submit\",\"analytics\":[{\"analyticsType\":\"widgetViewed\"}],\"ariaLabels\":{}};\n\n                var triggerHydrate = function() {\n                    window.sliceComponents.newsletterForm.hydrate(data, componentContainer);\n                }\n\n                if (window.lazyObserveElement) {\n                    window.lazyObserveElement(componentContainer, triggerHydrate);\n                } else {\n                    triggerHydrate();\n                }\n            }\n        }).catch(err => console.error('%c FTE ','background: #9306F9; color: #ffffff','Hydration Script has failed for newsletterForm-articleInbodyContent-TT23hGQ7XJtsjBD4MeoeD7 Slice', err));\n    }).catch(err => console.error('%c FTE ','background: #9306F9; color: #ffffff','Externals script failed to load', err));\nSign up for the Live Science daily newsletter nowGet the worldâ€™s most fascinating discoveries delivered straight to your inbox.Contact me with news and offers from other Future brandsReceive email from us on behalf of our trusted partners or sponsorsBy submitting your information you agree to the Terms & Conditions and Privacy Policy and are aged 16 or over.The researchers studied the fossilized remains of one Prototaxites species named Prototaxites taiti, found preserved in the Rhynie chert, a sedimentary deposit of exceptionally well-preserved fossils of early land plants and animals in Scotland. This species was much smaller than many other species of Prototaxites, only growing up to a few inches tall, but it is still the largest Prototaxites specimen found in this region.Upon examining the internal structure of the fossilized Prototaxites, the researchers found that its interior was made up of a series of tubes, similar to those within a fungus. But these tubes branched off and reconnected in ways very unlike those seen in modern fungi.\"We report that Prototaxites taiti was the largest organism in the Rhynie ecosystem and its anatomy was fundamentally distinct from all known extant or extinct fungi,\" the researchers wrote in the paper. \"We therefore conclude that Prototaxites was not a fungus, and instead propose it is best assigned to a now entirely extinct terrestrial lineage.\"True fungi from the same period have also been preserved in the Rhynie chert, enabling the researchers to chemically compare them to Prototaxites. In addition to their unique structural characteristics, the team found that the Prototaxites fossils left completely different chemical signatures to the fungi fossils, indicating that the Prototaxites did not contain chitin, a major building block of fungal cell walls and a hallmark of the fungal kingdom. The Prototaxites fossils instead appeared to contain chemicals similar to lignin, which is found in the wood and bark of plants.\"We conclude that the morphology and molecular fingerprint of P. taiti is clearly distinct from that of the fungi and other organism preserved alongside it in the Rhynie chert, and we suggest that it is best considered a member of a previously undescribed, entirely extinct group of eukaryotes,\" the researchers wrote.Kevin Boyce, a professor at Stanford University, led the 2007 study that posited Prototaxites is a giant fungus and was not involved in this new research. However, he told the New Scientist that he agreed with the study's findings.RELATED STORIESâ€”Scientists discover new 15 million-year old fish with last meal fossilized inside its stomachâ€”30,000-year-old fossilized vulture feathers 'nothing like what we usually see' preserved in volcanic ashâ€”Iguanas sailed one-fifth of the way around the world on rafts 34 million years ago\"Given the phylogenetic information we have now, there is no good place to put Prototaxites in the fungal phylogeny,\" Boyce said. \"So maybe it is a fungus, but whether a fungus or something else entirely, it represents a novel experiment with complex multicellularity that is now extinct and does not share a multicellular common ancestor with anything alive today.\"More research into Prototaxites fossils needs to be done to determine if they were fungi or a completely different type of life, and what caused them to go extinct millions of years ago.\"The conclusion that it is a completely unknown eukaryote certainly creates an air of mystery and intrigue around it â€” probably not likely to be solved until more fossils are discovered or new analytical techniques developed,\" Brett Summerell, a plant pathologist and fungi expert at the Botanic Gardens of Sydney, Australia, who not involved in this new study, told the New Scientist.\n\nJess ThomsonSocial Links NavigationLive Science ContributorJess Thomson is a freelance journalist. She previously worked as a science reporter for Newsweek, and has also written for publications including VICE, The Guardian, The Cut, and Inverse. Jess holds a Biological Sciences degree from the University of Oxford, where she specialised in animal behavior and ecology.\n\nYou must confirm your public display name before commenting\nPlease logout and then login again, you will then be prompted to enter your display name.\n\nLogout\n\nMore about animals\n\nFish in the Mariana Trench all have the same, unique mutations\n\n4 snow leopards spotted together on remote Pakistan mountain in rare footage\n\nLatest\n\nScientists uncover 'inside-out, legless, headless wonder' that lived long before the dinosaurs\n\nSee more latest\n\nMost Popular\n\nScientists uncover 'inside-out, legless, headless wonder' that lived long before the dinosaurs\n\nHuge steam plume rises from Alaska's Mount Spurr as volcano edges closer to eruption\n\nFish in the Mariana Trench all have the same, unique mutations\n\nStaring at the March 29 solar eclipse can cause eye damage in seconds â€” and you wonâ€™t even feel it happening\n\n'Woolly devil' flowers in Texas desert are the 1st new plant genus discovered in a US national park in almost 50 years\n\nFlat, razor-thin telescope lens could change the game in deep space imaging â€” and production could start soon\n\nEclipse map: What will tomorrow's solar eclipse look like from your state?\n\n4 snow leopards spotted together on remote Pakistan mountain in rare footage\n\nJames Webb telescope zooms in on bizarre 'Einstein ring' caused by bending of the universe\n\nHow to watch tomorrow's solar eclipse from anywhere on Earth\n\nfunction loadTaboola()\n{\nvar script = window.document.createElement('script');\nscript.async = 1;\nscript.src = '//cdn.taboola.com/libtrc/futureplc-network/loader.js';\nvar insertLocation = window.document.getElementsByTagName('script')[0];\ninsertLocation.parentNode.insertBefore(script, insertLocation);\n}\nfunction taboolaInit(){\nwindow._taboola = window._taboola || [];\nwindow._taboola.push({article: 'auto'});\n(window.Promise\n? window.Promise.all([window.reliablePageLoad, window.reliableConsentGiven])\n: window.reliableConsentGiven\n).then(function () {\nvar delay = 0;\nwindow.setTimeout(loadTaboola, delay)\n});\n};\ntaboolaInit();\n\nwindow._taboola = window._taboola || [];\nvar screenWidth = window.screen.width;\nfunction taboola_is_device(device) {\nif ((! device) || device === null || (typeof device) === 'undefined') return true\nif (device === 'amp') return false\nif (device === 'desktop' && screenWidth >= 700) return true\nif (device === 'mobile' && screenWidth < 700) return true\nreturn false\n}\n\n(function(){\nvar suitableDevice = taboola_is_device(\"desktop\");\nvar suitablePlacement = !(\"Mid Article\".includes('Mid Article') && \"\") &&\n!(\"Mid Article\".includes('Mid Article') && window.FUTR && window.FUTR.Kiosq && window.FUTR.Kiosq.hasBarrier);\nif (suitableDevice && suitablePlacement) {\nwindow._taboola.push({\nmode: \"thumbnails-a-mid\",\ncontainer: \"desktop-taboola-mid-article\",\nplacement: \"Mid Article\",\ntarget_type: \"mix\",\n});\n}\n})();\n\n(function(){\nvar suitableDevice = taboola_is_device(\"mobile\");\nvar suitablePlacement = !(\"Mid Article\".includes('Mid Article') && \"\") &&\n!(\"Mid Article\".includes('Mid Article') && window.FUTR && window.FUTR.Kiosq && window.FUTR.Kiosq.hasBarrier);\nif (suitableDevice && suitablePlacement) {\nwindow._taboola.push({\nmode: \"thumbnails-a-mid\",\ncontainer: \"mobile-taboola-mid-article\",\nplacement: \"Mid Article\",\ntarget_type: \"mix\",\n});\n}\n})();\n\n(function(){\nvar suitableDevice = taboola_is_device(\"desktop\");\nvar suitablePlacement = !(\"Below Article Thumbnails\".includes('Mid Article') && \"\") &&\n!(\"Below Article Thumbnails\".includes('Mid Article') && window.FUTR && window.FUTR.Kiosq && window.FUTR.Kiosq.hasBarrier);\nif (suitableDevice && suitablePlacement) {\nwindow._taboola.push({\nmode: \"thumbnails-f\",\ncontainer: \"taboola-below-article-thumbnails\",\nplacement: \"Below Article Thumbnails\",\ntarget_type: \"mix\",\n});\n}\n})();\n\n(function(){\nvar suitableDevice = taboola_is_device(\"mobile\");\nvar suitablePlacement = !(\"Mobile Below Article Thumbnails\".includes('Mid Article') && \"\") &&\n!(\"Mobile Below Article Thumbnails\".includes('Mid Article') && window.FUTR && window.FUTR.Kiosq && window.FUTR.Kiosq.hasBarrier);\nif (suitableDevice && suitablePlacement) {\nwindow._taboola.push({\nmode: \"thumbnails-g\",\ncontainer: \"taboola-mobile-below-article-thumbnails\",\nplacement: \"Mobile Below Article Thumbnails\",\ntarget_type: \"mix\",\n});\n}\n})();\n\n(function(){\nvar delay = 0;\nwindow.setTimeout(function() {\nwindow._taboola.push({flush: true});\n}, delay);\n})();\n\n    if (window.sliceHydrationLazy) {\n        window.sliceHydrationLazy(\"popularBox\", \"popularBox\", JSON.stringify({\"tabs\":[{\"tabName\":\"Latest Articles\",\"articles\":[{\"href\":\"\\/animals\\/extinct-species\\/scientists-uncover-inside-out-legless-headless-wonder-that-lived-long-before-the-dinosaurs\",\"heading\":\"Scientists uncover 'inside-out, legless, headless wonder' that lived long before the dinosaurs\",\"image\":{\"src\":\"https:\\/\\/cdn.mos.cms.futurecdn.net\\/GugvyuJLNHqHRGmgEmjE7T.jpg\",\"alt\":\"The fossil Keurbos susanae - or Sue - in the rock.\",\"fullscreen\":false,\"lazyLoading\":true,\"dataHydrate\":true,\"addSEOMetaData\":false}},{\"href\":\"\\/planet-earth\\/volcanos\\/huge-steam-plume-rises-from-alaskas-mount-spurr-as-volcano-edges-closer-to-eruption\",\"heading\":\"Huge steam plume rises from Alaska's Mount Spurr as volcano edges closer to eruption\",\"image\":{\"src\":\"https:\\/\\/cdn.mos.cms.futurecdn.net\\/Qu4n5FmRQWXMhHifYiujNF.jpg\",\"alt\":\"Mount spurr\",\"fullscreen\":false,\"lazyLoading\":true,\"dataHydrate\":true,\"addSEOMetaData\":false}},{\"href\":\"\\/animals\\/fish\\/fish-in-the-mariana-trench-all-have-the-same-unique-mutations\",\"heading\":\"Fish in the Mariana Trench all have the same, unique mutations\",\"image\":{\"src\":\"https:\\/\\/cdn.mos.cms.futurecdn.net\\/F44iXEUuNSmx7E8Dz5rhP6.jpg\",\"alt\":\"Illustration of the earth and its oceans with different deep sea species that surround it,\",\"fullscreen\":false,\"lazyLoading\":true,\"dataHydrate\":true,\"addSEOMetaData\":false}},{\"href\":\"\\/health\\/anatomy\\/staring-at-the-march-29-solar-eclipse-can-cause-eye-damage-in-seconds-and-you-wont-even-feel-it-happening\",\"heading\":\"Staring at the March 29 solar eclipse can cause eye damage in seconds \\u2014 and you won\\u2019t even feel it happening\",\"image\":{\"src\":\"https:\\/\\/cdn.mos.cms.futurecdn.net\\/BCWj4K5cdXLqbKHV3SWV7h.jpg\",\"alt\":\"A kid is shown looking at the solar eclipse while wearing special protective glasses\",\"fullscreen\":false,\"lazyLoading\":true,\"dataHydrate\":true,\"addSEOMetaData\":false}},{\"href\":\"\\/planet-earth\\/plants\\/woolly-devil-flowers-in-texas-desert-are-the-1st-new-plant-genus-discovered-in-a-us-national-park-in-almost-50-years\",\"heading\":\"'Woolly devil' flowers in Texas desert are the 1st new plant genus discovered in a US national park in almost 50 years\",\"image\":{\"src\":\"https:\\/\\/cdn.mos.cms.futurecdn.net\\/XaWDSQQnyiBU8AmsyK5PoF.jpg\",\"alt\":\"The wooly devil (Ovicula biradiata), a flowering plant that appears soft and fuzzy.\",\"fullscreen\":false,\"lazyLoading\":true,\"dataHydrate\":true,\"addSEOMetaData\":false}}]}]}), \"https://slice.vanilla.futurecdn.net/13-2-0/js/popularBox.js\");\n    } else {\n        console.error('%c FTE ','background: #9306F9; color: #ffffff','no lazy slice hydration function available');\n    }\nLATEST ARTICLES1Scientists uncover 'inside-out, legless, headless wonder' that lived long before the dinosaurs2Huge steam plume rises from Alaska's Mount Spurr as volcano edges closer to eruption3Fish in the Mariana Trench all have the same, unique mutations4Staring at the March 29 solar eclipse can cause eye damage in seconds â€” and you wonâ€™t even feel it happening5'Woolly devil' flowers in Texas desert are the 1st new plant genus discovered in a US national park in almost 50 years\n\nif(FUTR && FUTR.Connect){\n//Init Connect article History\nclass userNav {\nconstructor(key = 'connect_articles_history') {\nthis.key = key;\nthis.flushKey = `${key}_flush`;\nthis.propsKey = `${key}_props`;\nthis.store();\nconsole.info(\"FUTR.Connect.userNav - Init - Start - Using reduxStore\");\n}\nstore() {\nconst isArticle = window?.reduxStore?.getState()?.vanilla?.isArticle;\nif (typeof isArticle !== 'undefined' && isArticle && FUTR && FUTR.Connect) {\ntry {\nconst month = `${new Date().getFullYear()}-${new Date().getMonth()}`;\n//flush monthly\nif (localStorage.getItem(this.flushKey) !== month) {\nlocalStorage.setItem(this.key, btoa('[]'));\nlocalStorage.setItem(this.propsKey, []);\nlocalStorage.setItem(this.flushKey, month);\n}\nconst currentUrl = location.pathname;\nconst urls = JSON.parse(atob(localStorage.getItem(this.key) || btoa('[]')));\nconst props = JSON.parse(localStorage.getItem(this.propsKey)|| '[]');\nif (!urls.includes(currentUrl) && this.getProps().length < 20 || this.getProps().length <1) {\nurls.push(currentUrl);\nif (window.ffte && window.ffte.properties) {\nprops.push(window.ffte.properties);\nconsole.log(\"props push\", props)\n}\nlocalStorage.setItem(this.key, btoa(JSON.stringify(urls)));\nlocalStorage.setItem(this.propsKey, JSON.stringify(props));\n}\nconsole.info(\"FUTR.Connect.userNav - Urls Stored\");\n} catch (e) {\nconsole.warn('userNav:', e);\n}\n}\n}\ngetHistory() {\ntry {\nreturn JSON.parse(atob(localStorage.getItem(this.key) || btoa('[]')));\n} catch {\nreturn [];\n}\n}\ngetProps() {\ntry {\nreturn JSON.parse(localStorage.getItem(this.propsKey) || '[]');\n} catch {\nreturn [];\n}\n}\n};\nFUTR.Connect.userNav = new userNav();\nconsole.info(\"FUTR.Connect.userNav - Init - Done\", FUTR.Connect.userNav);\n}",
    "summary": {
      "en": "Researchers have discovered that Prototaxites, a large ancient organism once thought to be a type of fungus, may actually be a completely unknown branch of life. This organism existed between 420 million and 375 million years ago and could grow up to 26 feet tall. Initially classified as a fungus due to its structure and feeding habits, recent studies suggest it might belong to an entirely different group of eukaryotes.\n\nFossils of Prototaxites, including a species called Prototaxites taiti found in Scotland, show unique internal structures that differ from known fungi. Chemical analyses revealed that it lacked chitin, a key component of fungal cell walls, and instead contained materials similar to those in plants. This discovery raises questions about its classification and suggests that Prototaxites represents a novel form of multicellular life that is now extinct. Further research is needed to fully understand this mysterious organism.",
      "ko": "ì—°êµ¬ìë“¤ì€ í•œë•Œ ê³°íŒ¡ì´ì˜ ì¼ì¢…ìœ¼ë¡œ ì—¬ê²¨ì¡Œë˜ ê³ ëŒ€ ìƒë¬¼ í”„ë¡œí† íƒì‚¬ì´íŠ¸ìŠ¤ê°€ ì‚¬ì‹¤ì€ ì™„ì „íˆ ìƒˆë¡œìš´ ìƒëª…ì²´ì˜ í•œ ê°ˆë˜ì¼ ìˆ˜ ìˆë‹¤ëŠ” ì‚¬ì‹¤ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ì´ ìƒë¬¼ì€ ì•½ 4ì–µ 2ì²œë§Œ ë…„ì—ì„œ 3ì–µ 7ì²œ5ë°±ë§Œ ë…„ ì „ ì‚¬ì´ì— ì¡´ì¬í–ˆìœ¼ë©°, ìµœëŒ€ 8ë¯¸í„°ê¹Œì§€ ìë„ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤. êµ¬ì¡°ì™€ ë¨¹ì´ ìŠµì„± ë•Œë¬¸ì— ì²˜ìŒì—ëŠ” ê³°íŒ¡ì´ë¡œ ë¶„ë¥˜ë˜ì—ˆì§€ë§Œ, ìµœê·¼ ì—°êµ¬ì—ì„œëŠ” ì´ ìƒë¬¼ì´ ì „í˜€ ë‹¤ë¥¸ ì§„í•µìƒë¬¼ ê·¸ë£¹ì— ì†í•  ê°€ëŠ¥ì„±ì´ ì œê¸°ë˜ê³  ìˆìŠµë‹ˆë‹¤.\n\nìŠ¤ì½”í‹€ëœë“œì—ì„œ ë°œê²¬ëœ í”„ë¡œí† íƒì‚¬ì´íŠ¸ìŠ¤ íƒ€ì´í‹°ë¼ëŠ” ì¢…ì„ í¬í•¨í•œ í”„ë¡œí† íƒì‚¬ì´íŠ¸ìŠ¤ì˜ í™”ì„ì€ ì•Œë ¤ì§„ ê³°íŒ¡ì´ì™€ëŠ” ë‹¤ë¥¸ ë…íŠ¹í•œ ë‚´ë¶€ êµ¬ì¡°ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. í™”í•™ ë¶„ì„ ê²°ê³¼, ì´ ìƒë¬¼ì€ ê³°íŒ¡ì´ ì„¸í¬ë²½ì˜ ì£¼ìš” ì„±ë¶„ì¸ í‚¤í‹´ì´ ì—†ê³ , ëŒ€ì‹  ì‹ë¬¼ì—ì„œ ë°œê²¬ë˜ëŠ” ë¬¼ì§ˆê³¼ ìœ ì‚¬í•œ ì„±ë¶„ì„ í¬í•¨í•˜ê³  ìˆìŒì„ ë°í˜€ëƒˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ë°œê²¬ì€ í”„ë¡œí† íƒì‚¬ì´íŠ¸ìŠ¤ì˜ ë¶„ë¥˜ì— ëŒ€í•œ ì˜ë¬¸ì„ ì œê¸°í•˜ë©°, ì´ ìƒë¬¼ì´ í˜„ì¬ ë©¸ì¢…ëœ ìƒˆë¡œìš´ í˜•íƒœì˜ ë‹¤ì„¸í¬ ìƒëª…ì²´ë¥¼ ë‚˜íƒ€ë‚¸ë‹¤ê³  ì œì•ˆí•©ë‹ˆë‹¤. ì´ ì‹ ë¹„ë¡œìš´ ìƒë¬¼ì„ ì™„ì „íˆ ì´í•´í•˜ê¸° ìœ„í•´ì„œëŠ” ì¶”ê°€ ì—°êµ¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.",
      "ja": "ç ”ç©¶è€…ãŸã¡ã¯ã€å¤ä»£ã®å¤§ããªç”Ÿç‰©ã§ã‚ã‚‹ãƒ—ãƒ­ãƒˆã‚¿ã‚­ã‚µã‚¤ãƒˆãŒã€ã‹ã¤ã¦ã¯èŒé¡ã®ä¸€ç¨®ã¨è€ƒãˆã‚‰ã‚Œã¦ã„ãŸãŒã€å®Ÿéš›ã«ã¯å…¨ãæœªçŸ¥ã®ç”Ÿå‘½ã®ç³»çµ±ã§ã‚ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã“ã¨ã‚’ç™ºè¦‹ã—ã¾ã—ãŸã€‚ã“ã®ç”Ÿç‰©ã¯ã€4å„„2000ä¸‡å¹´å‰ã‹ã‚‰3å„„7500ä¸‡å¹´å‰ã«å­˜åœ¨ã—ã€æœ€å¤§ã§ç´„8ãƒ¡ãƒ¼ãƒˆãƒ«ã®é«˜ã•ã«æˆé•·ã™ã‚‹ã“ã¨ãŒã§ãã¾ã—ãŸã€‚æ§‹é€ ã‚„æ‘‚é£Ÿç¿’æ…£ã‹ã‚‰æœ€åˆã¯èŒé¡ã¨ã—ã¦åˆ†é¡ã•ã‚Œã¦ã„ã¾ã—ãŸãŒã€æœ€è¿‘ã®ç ”ç©¶ã§ã¯ã€å…¨ãç•°ãªã‚‹çœŸæ ¸ç”Ÿç‰©ã®ã‚°ãƒ«ãƒ¼ãƒ—ã«å±ã™ã‚‹å¯èƒ½æ€§ãŒç¤ºå”†ã•ã‚Œã¦ã„ã¾ã™ã€‚\n\nã‚¹ã‚³ãƒƒãƒˆãƒ©ãƒ³ãƒ‰ã§ç™ºè¦‹ã•ã‚ŒãŸãƒ—ãƒ­ãƒˆã‚¿ã‚­ã‚µã‚¤ãƒˆãƒ»ã‚¿ã‚¤ãƒ†ã‚£ã¨ã„ã†ç¨®ã‚’å«ã‚€åŒ–çŸ³ã¯ã€æ—¢çŸ¥ã®èŒé¡ã¨ã¯ç•°ãªã‚‹ç‹¬ç‰¹ã®å†…éƒ¨æ§‹é€ ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚åŒ–å­¦åˆ†æã®çµæœã€èŒé¡ã®ç´°èƒå£ã®é‡è¦ãªæˆåˆ†ã§ã‚ã‚‹ã‚­ãƒãƒ³ãŒæ¬ ã‘ã¦ãŠã‚Šã€ä»£ã‚ã‚Šã«æ¤ç‰©ã«ä¼¼ãŸææ–™ã‚’å«ã‚“ã§ã„ã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã¾ã—ãŸã€‚ã“ã®ç™ºè¦‹ã¯ã€ãã®åˆ†é¡ã«ç–‘å•ã‚’æŠ•ã’ã‹ã‘ã€ãƒ—ãƒ­ãƒˆã‚¿ã‚­ã‚µã‚¤ãƒˆãŒç¾åœ¨ã¯çµ¶æ»…ã—ãŸæ–°ã—ã„å½¢ã®å¤šç´°èƒç”Ÿç‰©ã‚’è¡¨ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºå”†ã—ã¦ã„ã¾ã™ã€‚ã“ã®è¬ã®ç”Ÿç‰©ã‚’å®Œå…¨ã«ç†è§£ã™ã‚‹ãŸã‚ã«ã¯ã€ã•ã‚‰ãªã‚‹ç ”ç©¶ãŒå¿…è¦ã§ã™ã€‚"
    }
  },
  {
    "id": "df683903503e15e7",
    "title": {
      "en": "Ivanpah Solar Thermal Units Shutting Down, as Tech Shifts",
      "ko": "ì•„ì´ë°˜íŒŒ íƒœì–‘ì—´ ë°œì „ì†Œ ì¢…ë£Œ",
      "ja": "ã‚¤ãƒ´ã‚¡ãƒ³ãƒ‘å¤ªé™½å…‰ç™ºé›»åœæ­¢"
    },
    "type": "story",
    "url": "https://www.enr.com/articles/60307-older-ivanpah-solar-plant-in-california-will-close-units-as-tech-shifts",
    "score": 5,
    "by": "LMSolar",
    "time": 1743263059,
    "content": "NewsWestWest Construction NewsPower & Industrial\n\n      Renewable Energy\n\n    Older Ivanpah Solar Plant in California Will Close Units, as Tech Shifts\n\n    By James Leggate\n\n      Each of Ivanpah Solar Power Plant's three towers is surrounded by thousands of mirrors.Photo by Dennis Schroeder/National Renewable Energy Laboratory\n\n        February 13, 2025\n\n    Power plant operator and co-owner NRG Energy Inc. is preparing to close down part of its Ivanpah Solar Power Plant in San Bernardino County, Calif., a little more than 11 years after it began operating. NRG agreed to terminate a pair of long-term purchase power agreements with utility Pacific Gas and Electric Co. for energy generated at the facility, which still uses technology the operator says has been surpassed by solar silicon photovoltaic generation.Ivanpah is a concentrating solar power plant, which uses 173,500 heliostatsâ€”essentially mirrors on movable mounts so they can track the sunâ€”to reflect sunlight onto boilers at the top of 450-ft-tall towers to make steam that turns turbines to generate power.The plant has three units, each with its own tower surrounded by an array of heliostats, for a total capacity of 386 MW.The utility contracted to purchase power from two of the units through 2039. But it said in a statement that in 2021â€” after the California Public Utilities Commission ordered investor-owned utilities to evaluate their energy sourcesâ€”it identified its Ivanpah power purchase agreements as a potential area to find cost savings, with plant owners offering the opportunity to terminate the agreements. The companies, along with the U.S. Dept. of Energy, finalized negotiations to end the agreements last month. DOE provided $1.6 billion in loan guarantees for the project.Houston-based NRG said in a statement that the negotiations allowed the department â€œto maximize the recovery of its loans and provide savings for California ratepayers.â€ An NRG representative did not say how much of the loan was repaid when asked, but said in a statement that the â€œconcentrating solar power project was an innovative public-private partnership uniting government entities with private business in the advancement of renewable energy.â€A second utility, Southern California Edison, also contracted to buy power from the third Ivanpah unit through 2039. Its representative told ENR that the utility is in ongoing discussions with plant owners and DOE related to buyout of its Ivanpah contract.NRG said it is now seeking approvals from state and federal officials to begin closing down the units next year for decommissioning. An NRG representative did not provide added details to ENR about the work or cost of decommissioning.Concentrating SolarIvanpah was the largest concentrating solar power plant in the world at the time of its construction, and NRG said the project still demonstrated the technologyâ€™s viability.Construction of the $2.2-billion plant started in 2010 with Bechtel Corp. as engineering, procurement and construction contractor. It began operations in late 2013 and remains the largest plant of its kind built in the U.S. .At the time of Ivanpahâ€™s construction, utility PG&E was investing in various kinds of developing clean energy technologies, including solar photovoltaic, hydroelectricity, wind, biomass and geothermal.â€œItâ€™s so important to support investment in different projects as we look to solve climate challenges,â€ said Don Howerton, PG&E senior director of commercial procurement, in a statement. â€œItâ€™s not clear in the early stages what technologies will work best and be most affordable for customers.â€Improvements in solar photovoltaic wafers and panels and battery energy storage have made them more affordable options at large scale, Howerton added. The technologies have â€œraced aheadâ€ in terms of affordability, according to PG&E.Photovoltaic, or PV, technology uses siliconcrystals that are laminated into layers, often called wafers, with opposite charges.When solar light hits the crystals, it creates a direct electric current through a process called the photovoltaic effect.Ivanpah's generation is believed to have prevented 500,000 metric tons of carbon dioxide emissions annually, according to the Energy Dept. But once operational, it drew criticism following reports that insects and birds were burned to death when they flew too close to the white-hot tower tops. A 2015 report prepared for the state by ecological consulting firm H.T. Harvey & Associates estimated the plant killed about 3,500 birds in its first year of operation.Ivanpah also faced performance issues. In 2014, plant owners got permission from state officials to increase its annual limit of natural gas for its boilers from 328 million cu ft to 525 million cu ft, citing a need to use more fuel to power turbines to compensate for intermittent cloud cover.â€œWhen the power purchase agreements were signed in 2009, the prices were competitive, but advancements over time in PVs and battery storage have led to more eï¬ƒcient, cost-effective and flexible options for producing reliable clean energy,â€ NRG said in an emailed statement.The plant occupies more than 3,200 acres of federal land in the Mojave Desert near the California-Nevada state line. In its statement, NRG suggested the site could be repurposed for solar silicon photovoltaic energy production after decommissioning of the existing plant, but did not share any specific plans for that future work.\n\n    KEYWORDS:  NRG Energy   PG&E   solar construction   solar energy   Southern California Edison\n\n    Share This Story\n\n  James Leggate is an online news editor at ENR. He has reported on a variety of issues for more than 10 years and his work has contributed to several regional Associated Press Media Editors and Murrow award wins.\n\n      Post a comment to this article\n\n          Name*\n\n          E-mail (will not be displayed)*\n\n          Subject\n\n          Comment*\n\n\tUnable to fetch comments.\n\n\t\t\tReport Abusive Comment\n\n\t\t\t\tThank you for helping us to improve our forums. Is this comment offensive? Please tell us why.\n\n\t\tfunction initReportAbusiveCommentForm () {\n\t\t\t$(\"#report-abusive-comment-form\").overlay({\n\t\t\t\ttop: 'center',\n\t\t\t\texpose: { color: '#000', loadSpeed: 200, opacity: 0.6 },\n\t\t\t\tcloseOnClick: true\n\t\t\t});\n\n\t\t\t$(\"#comment-list\").delegate (\".modalInput\", \"click\", function(e) {\n\t\t\t\te.preventDefault();\n\t\t\t\te.stopPropagation();\n\t\t\t\t$(\"#comment_flag_form\").attr (\"action\", \"/comments/flag/article/\" + e.target.href.split (/\\#id=/)[1]);\n\t\t\t\t$(\"#report-abusive-comment-form\").overlay().load();\n\t\t\t});\n\t\t}\n\t\t$(document).ready(\n\t\t\tfunction () {\n\t\t\t\tif (window.customInitReportAbusiveCommentForm) {\n\t\t\t\t\twindow.customInitReportAbusiveCommentForm ();\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tinitReportAbusiveCommentForm ();\n\t\t\t\t}\n\t\t\t}\n\t\t);",
    "summary": {
      "en": "The Ivanpah Solar Power Plant in California, operated by NRG Energy Inc., will close some of its units after more than 11 years of operation. This decision follows the termination of long-term power purchase agreements with Pacific Gas and Electric Co. (PG&E), as newer solar technologies have become more cost-effective. Ivanpah, which was once the largest concentrating solar power plant in the world, uses mirrors to concentrate sunlight and generate power but has faced performance issues and environmental criticisms, including bird fatalities.\n\nThe U.S. Department of Energy had supported the project with $1.6 billion in loan guarantees, and negotiations to end the contracts aimed to recover loans and save costs for California ratepayers. NRG is now seeking approvals to begin decommissioning the units next year and has suggested that the site could be repurposed for newer solar technologies after the shutdown.",
      "ko": "ìº˜ë¦¬í¬ë‹ˆì•„ì— ìœ„ì¹˜í•œ ì•„ì´ë°˜íŒŒ íƒœì–‘ê´‘ ë°œì „ì†Œê°€ 11ë…„ ë„˜ê²Œ ìš´ì˜ëœ í›„ ì¼ë¶€ ìœ ë‹›ì„ íì‡„í•˜ê¸°ë¡œ ê²°ì •í–ˆìŠµë‹ˆë‹¤. ì´ ê²°ì •ì€ íƒœí‰ì–‘ ê°€ìŠ¤ ë° ì „ê¸° íšŒì‚¬(PG&E)ì™€ì˜ ì¥ê¸° ì „ë ¥ êµ¬ë§¤ ê³„ì•½ì´ ì¢…ë£Œëœ ë° ë”°ë¥¸ ê²ƒì…ë‹ˆë‹¤. ìµœê·¼ì˜ íƒœì–‘ê´‘ ê¸°ìˆ ì´ ë” ë¹„ìš© íš¨ìœ¨ì ìœ¼ë¡œ ë°œì „í•˜ë©´ì„œ ì´ëŸ¬í•œ ë³€í™”ê°€ ì´ë£¨ì–´ì¡ŒìŠµë‹ˆë‹¤. ì•„ì´ë°˜íŒŒëŠ” í•œë•Œ ì„¸ê³„ì—ì„œ ê°€ì¥ í° ì§‘ê´‘í˜• íƒœì–‘ê´‘ ë°œì „ì†Œì˜€ìœ¼ë©°, ê±°ìš¸ì„ ì‚¬ìš©í•´ í–‡ë¹›ì„ ì§‘ì¤‘ì‹œì¼œ ì „ë ¥ì„ ìƒì‚°í•˜ì§€ë§Œ, ì„±ëŠ¥ ë¬¸ì œì™€ ì¡°ë¥˜ ì‚¬ë§ ë“± í™˜ê²½ì  ë¹„íŒì— ì§ë©´í•´ ìˆì—ˆìŠµë‹ˆë‹¤.\n\në¯¸êµ­ ì—ë„ˆì§€ë¶€ëŠ” ì´ í”„ë¡œì íŠ¸ì— 16ì–µ ë‹¬ëŸ¬ì˜ ëŒ€ì¶œ ë³´ì¦ì„ ì§€ì›í–ˆìœ¼ë©°, ê³„ì•½ ì¢…ë£Œë¥¼ ìœ„í•œ í˜‘ìƒì€ ëŒ€ì¶œê¸ˆì„ íšŒìˆ˜í•˜ê³  ìº˜ë¦¬í¬ë‹ˆì•„ ì „ê¸° ìš”ê¸ˆ ë‚©ë¶€ìë“¤ì˜ ë¹„ìš©ì„ ì ˆê°í•˜ê¸° ìœ„í•œ ëª©ì ì´ì—ˆìŠµë‹ˆë‹¤. NRG ì—ë„ˆì§€ëŠ” ë‚´ë…„ì— ìœ ë‹›ì˜ í•´ì²´ë¥¼ ì‹œì‘í•˜ê¸° ìœ„í•œ ìŠ¹ì¸ì„ ìš”ì²­í•˜ê³  ìˆìœ¼ë©°, ë°œì „ì†Œê°€ íì‡„ëœ í›„ì—ëŠ” ìƒˆë¡œìš´ íƒœì–‘ê´‘ ê¸°ìˆ ì„ ìœ„í•œ ìš©ë„ë¡œ ì¬í™œìš©ë  ìˆ˜ ìˆë‹¤ê³  ì œì•ˆí–ˆìŠµë‹ˆë‹¤.",
      "ja": "ã‚«ãƒªãƒ•ã‚©ãƒ«ãƒ‹ã‚¢å·ã«ã‚ã‚‹ã‚¢ã‚¤ãƒãƒ³ãƒ‘ãƒ¼å¤ªé™½å…‰ç™ºé›»æ‰€ãŒã€11å¹´ä»¥ä¸Šã®é‹è»¢ã‚’çµŒã¦ä¸€éƒ¨ã®ãƒ¦ãƒ‹ãƒƒãƒˆã‚’é–‰é–ã™ã‚‹ã“ã¨ã«ãªã‚Šã¾ã—ãŸã€‚ã“ã®æ±ºå®šã¯ã€ãƒ‘ã‚·ãƒ•ã‚£ãƒƒã‚¯ãƒ»ã‚¬ã‚¹ãƒ»ã‚¢ãƒ³ãƒ‰ãƒ»ã‚¨ãƒ¬ã‚¯ãƒˆãƒªãƒƒã‚¯ç¤¾ï¼ˆPG&Eï¼‰ã¨ã®é•·æœŸé›»åŠ›è³¼å…¥å¥‘ç´„ãŒçµ‚äº†ã—ãŸã“ã¨ã‚’å—ã‘ãŸã‚‚ã®ã§ã€æ–°ã—ã„å¤ªé™½å…‰æŠ€è¡“ãŒã‚ˆã‚Šã‚³ã‚¹ãƒˆåŠ¹ç‡çš„ã«ãªã£ãŸãŸã‚ã§ã™ã€‚ã‚¢ã‚¤ãƒãƒ³ãƒ‘ãƒ¼ã¯ã‹ã¤ã¦ä¸–ç•Œæœ€å¤§ã®é›†ä¸­å‹å¤ªé™½å…‰ç™ºé›»æ‰€ã§ã—ãŸãŒã€é¡ã‚’ä½¿ã£ã¦å¤ªé™½å…‰ã‚’é›†ã‚ã¦ç™ºé›»ã™ã‚‹æ–¹å¼ã«ãŠã„ã¦ã€æ€§èƒ½ã®å•é¡Œã‚„é³¥é¡ã®æ­»äº¡ãªã©ç’°å¢ƒã¸ã®æ‰¹åˆ¤ã«ç›´é¢ã—ã¦ãã¾ã—ãŸã€‚\n\nã‚¢ãƒ¡ãƒªã‚«åˆè¡†å›½ã‚¨ãƒãƒ«ã‚®ãƒ¼çœã¯ã€ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«å¯¾ã—ã¦16å„„ãƒ‰ãƒ«ã®èè³‡ä¿è¨¼ã‚’æä¾›ã—ã¦ã„ã¾ã—ãŸã€‚å¥‘ç´„çµ‚äº†ã«å‘ã‘ãŸäº¤æ¸‰ã¯ã€èè³‡ã®å›åã¨ã‚«ãƒªãƒ•ã‚©ãƒ«ãƒ‹ã‚¢ã®é›»åŠ›åˆ©ç”¨è€…ã®ã‚³ã‚¹ãƒˆå‰Šæ¸›ã‚’ç›®çš„ã¨ã—ã¦ã„ã¾ã™ã€‚NRGã‚¨ãƒŠã‚¸ãƒ¼ç¤¾ã¯ã€æ¥å¹´ã«ãƒ¦ãƒ‹ãƒƒãƒˆã®å»ƒæ­¢ã‚’é–‹å§‹ã™ã‚‹ãŸã‚ã®æ‰¿èªã‚’æ±‚ã‚ã¦ãŠã‚Šã€é–‰é–å¾Œã«ã¯ã“ã®å ´æ‰€ã‚’æ–°ã—ã„å¤ªé™½å…‰æŠ€è¡“ã«å†åˆ©ç”¨ã™ã‚‹ææ¡ˆã‚‚ã—ã¦ã„ã¾ã™ã€‚"
    }
  },
  {
    "id": "f068670bb2ee81fe",
    "title": {
      "en": "Xee: A Modern XPath and XSLT Engine in Rust",
      "ko": "ì—‘ìŠ¤ì´: ëŸ¬ìŠ¤íŠ¸ì˜ í˜„ëŒ€ì  XPath/XSLT ì—”ì§„",
      "ja": "Rustã§é€²åŒ–ã™ã‚‹XPath/XSLT"
    },
    "type": "story",
    "url": "https://blog.startifact.com/posts/xee/",
    "score": 370,
    "by": "robin_reala",
    "time": 1743144498,
    "content": "Xee: A Modern XPath and XSLT Engine in Rust\n\n        By Martijn Faassenâ€¢2025-03-27â€¢Tags:xml,rust,xpath,lxml\n\n            For the last two years I've been working on a programming language\nimplementation in Rust named Xee. Xee stands for \"XML Execution Engine\" and\nit supports modern versions of XPath and XSLT. Those are programming languages,\nand yes, that's XML stuff.\nNow hold on. Your brain might shut down when I talk about XML. I totally get\nthat XML may not be your cup of tea. But I'm also going to be talking about a\nstrange different world of technology where everything is specified, and the\nimplementation of a programming language using Rust, so I hope you still decide\nto read on if those topics could interest you.\nAnd if XML does happen to be your cup of tea, I think you should be excited\nabout Xee, as I think it can help secure a better future for XML technologies.\nHere's the Xee repository.\nThere are two highlights: a command-line tool\nxee\nthat lets you do XPath queries, and a Rust library\nxee-xpath to issue XPath\nqueries from Rust.\n\nGenesis\nIn 2023 I was asked by Paligo, my amazing and generous\nclient, whether I wanted to implement a modern version of XPath and XSLT in\nRust. I felt extremely nervous for a week. Then I told them that this was a big\nproject. I told them that I could do it and I was excited to do it, but it was\ngoing to be a lot of work.\nAnd although I was right to be very intimidated by the scope, I still\nunderestimated the effort at the time.\nBut Xee has come a long way nonetheless! I'm going to take you along on its\njourney if you're willing to follow.\n\nWhat is Xee?\nXee is a programming language implementation. It implements two core XML\nprogramming languages: XPath and,\npartially at the time of writing, XSLT.\nXPath is an XML query language, and XSLT is a language that uses XPath as its\nexpression language which lets you transform XML documents into other\ndocuments. Xee implements modern versions of these specifications, rather\nthan the versions released in 1999.\nXee implements these languages in the Rust programming language. This brings\nmodern XML technology not just to Rust. Rust is a systems programming language\nand is good at integration with other programming languages. So Xee can bring\nits capabilities to other programming languages as well, from PHP to Python.\nI've already experimented with PHP\nbindings.\nSince Xee is written in Rust, it should also be possible to compile the Xee\ninterpreter to WASM and run this stuff in the browser.\nI'll continue to talk about how Xee is implemented later, but first we'll take\na break and share some XML history.\n\nXML history\nLet's talk a bit about XML. XML emerged in the late 90s, and though it may be\ndifficult to believe now, for a while in the early part of the 2000s, XML was a\ncool technology everyone wanted to use. There was much excitement in the form\nof industry activity and many computer science papers were also published.\nTo illustrate how big this was, last year I was at the RustNL conference and I\nspoke to two separate speakers who mentioned they had worked on an XSLT\nengine1 in the past. One of them was Niko\nMatsakis, Rust core developer.\nSo me being a young and hip developer back then 2, I was doing cool XML\nstuff too. My biggest accomplishment in the XML space was the creation of\nlxml, the XML library for Python. I started that project in\nlate 2004. Early on Stefan Behnel\njoined the project and he has competently maintained it ever since - it would\nnot have been as successful without him.\nWhile XML technology isn't cool anymore today, it's still everywhere. The core\nlanguage web browsers use is not XML but its close cousin HTML. Embedded in\nHTML are true XML-based languages, such as SVG and MathML. Even though JSON and\nother languages took a large chunk out of it, XML is still used to store and\ntransmit a lot of data, and it's extensively used for documents as well, in\nformats such as docbook and JATS. XML is now niche technology, but it's a\nbigger niche than you might think, and it's not going to go away any time soon.\nIn my own career, I became less and less involved with XML over time, though\nI'd still run into it on a regular basis. It's both amusing and useful that\nwhenever I talk to a potential client that uses Python, they're already using\nlxml somewhere.\nA few years ago I entered back into the XML world. And here I am, that\nrelatively rare bird who knows a fancy modern programming language like Rust,\nand is at the same time very familiar with XML.\n\nXPath and XSLT are programming languages\nSo XPath and XSLT are both programming languages.\nXPath is a query language for XML. Given an XML document, let's say something\nlike HTML, you can query it with expressions like: /html/body//p to get all\np elements inside the body element of the outer html element. XPath in\nits modern incarnation is a functional programming language with a type system,\nvariables, function definition, conditionals, loops and so on.\nXSLT is a transformation language for XML. It describes, using templates and a\nfunctional approach, how to transform an XML document of one type into another.\nYou can for instance use it to transform docbook XML, which describes\ndocuments, into HTML. It builds on XPath - XPath expressions are the expression\nlanguage of XSLT. XSLT itself also supports programming constructs like\nvariables, loops, conditionals, functions and the like, in a partial\nduplication of XPath.\n\nState of the XML open source stack\nSo if you want to use these programming languages and you use an open source\nstack, where do you go?\nThe Java world has good modern XPath and XSLT support. XPath and XSLT are\nimplemented by Saxon, which has been around for a long time. Saxon is available\non .NET as well. There are also PHP and Python bindings via a rather complex C\nto Java bridge, and Saxon offers a JavaScript reimplemention of its runtime as\nwell. Besides its open source offerings, Saxon also has closed-source\nprofessional/enterprise editions which provide more features. Besides Saxon,\nthere are also open source XQuery3 implementations in Java.\nBut if you step out of the Java world and its periphery, and if you look in\nyour average open source stack or Linux distribution for an XPath or XSLT\nimplementation you don't find Saxon or these XQuery databases; you find\nlibxml2 and libxslt.\nlibxml2 and libxslt are C libraries for handling XML. This amalgam of\nlibraries supports parsing XML, querying it using XPath, transforming it using\nXSLT and more. libxml2 is everywhere - in your Linux distribution and in\nMacOS. People don't just use it from C code - for Python for instance I built\nlxml on top.\nThese libraries were originally created by Daniel\nVeillard. I remember speaking to him once, many years\nago. We came from different worlds - he was thinking about writing fast\nprocessor-cache friendly code in C, whereas I was interested in an easy to use\nAPI in Python. I was impressed he had implemented all these specifications -\nlxml was merely piggybacking on that hard work.\nBut libxml2 is stuck in the past - it implements XPath, but only XPath 1.0,\nand similarly libxslt implements XSLT 1.0 only. These are specifications from\n1999. The XPath 2 specification was released in 2007, and we're currently\nactually at XPath 3.1, released in 2017. Similarly XSLT 2.0 was released in\n2007 and XSLT 3.0, the current version, in 2017.\nMy hope is that Xee can be a more modern alternative to libxml2 and libxslt\nthat finds its home in the open source world. For XPath and XSLT to be thriving\nstandards they need multiple implementations, in multiple programming\nlanguages, by multiple parties.\nAnd personally I feel like I have come full circle - finally, in these latter\ndays of XML, I am where Daniel Veillard had gone ages before with libxml2. I\nfind myself implementing the same stuff, not in C, but still in a systems\nprogramming language, Rust.\n\nSpecification culture\nI was at XML Prague, an XML conference, last year,\nand I noticed something interesting about XML culture. It is still very\nstandards focused. This was a very prevalent attitude in the web development\nworld in the early 2000s, but I think that although standards are still\nconsidered important today, they're less culturally prominent.\nThe XML culture is different: stuff needs to be specified. If it's not in a\nspecification it's not fully real. This makes the XML community move more\nslowly than the rest of the software community. I was somewhat bemused to hear\ntalk in 2024 about updating the RESTXQ spec, an XQuery based web framework\nstandard, first discussed in 2012, to make use of language features like\nhashmaps and arrays, now that they had been finally added to XPath/XQuery in\n2017.\nThese XML specifications go deep, they build on each other, they are solid. If\nyou value solid foundations that will stand the test of time, the XML world has\ngot your back.\n\nImplementing a programming language\nYou might be bored with XML by now so before I return to the discussion of\nspecifications, I will talk a bit about the architecture of Xee.\nXee follows various familiar patterns in the implementation of programming\nlanguages. I based part of its architecture on the excellent book Crafting\nInterpreters.\nIn Xee, XPath gets lexed into tokens, then parsed into an abstract syntax tree\n(AST). The AST is then transformed into an intermediate representation (IR)\nthat represents the expression in a more compact way. This IR is then compiled\ninto bytecode - a simple assembly-language like stack machine, similar to the\none that underlies many programming languages such as Python and Java. The Xee\ninterpreter can then execute the bytecode.\nThis translation at present is straightforward; while I've prepared the IR to\nsupport optimization passes such as constant folding and the like, this doesn't\nhappen yet.4\nXSLT, though unfinished, is built on the same architecture as the XPath engine.\nThere's a frontend that transforms XSLT XML into an XSLT AST, and then this is\ntransformed into the same IR as the one used for XPath. It uses the same\nbytecode intepreter. So, only the XSLT frontend is different, everything else\nis the same. This made it easy to implement a whole bunch of XSLT features as I\nhad already implemented them for XPath.\nImplementing programming languages is fun!\n\nSpecifications, again\nXPath and XSLT are programming languages that are fully specified. You can\nreally implement them from the specification. On the one hand this makes life a\nlot easier - the goals are clear as it's clearly specified how things are\nsupposed to work. There's a vast conformance test suite available as well. On\nthe other hand this means an endless treadmill; I can't just stop when I think\nit looks good enough when there's more specification left to implement.\nXPath 3.1 has grown a lot bigger than XPath 1.0; it became a full-fledged\nprogramming language, with a much larger standard library. XSLT 3.0 has also\nevolved a lot since XSLT 1.0. Specifications keep building on each other, and\nadd more features in new updates, until implementing them becomes a daunting\ntask. I sometimes I wish I was implementing XPath 1.0 and XSLT 1.0, like Daniel\nVeillard back in the day.\nLet me give you a quick tour of various specifications so you can understand\nsomething about the magnitude of the task of implementing them.\nThe grammar and behavior of the XPath language is laid out in the W3C\nspecification XML Xpath Language (XPath)\n3.1. This refers to another specification,\nXQuery and XPath Data Model 3.1\nwhich describes how XPath views XML data - what properties of XML data exist.\nIt also builds on another specification XPath and XQuery Functions and\nOperators 3.1, which not only\ndescribes the behavior of XPath operators such as +, - and *, but also\ndefines its standard library of functions.\nXPath has a type system, and its types are described by W3C XML Schema\nDefinition Language (XSD) 1.1: Part 1:\nStructures and W3C XML Schema\nDefinition Language (XSD) 1.1 Part 2:\nDatatypes. This defines atomic types\n(which Xee implements) but also lets you define new types and use types from an\nXML schema, which Xee doesn't implement at present. These specifications also\ndescribe how XPath is to parse and format strings of atomic types, such as the\nformat of decimals and dates.\nOh, and that XPath functions and operators specification? Some of the functions\nuse regular expressions. The specification defines XPath regular expressions as\nan extension of the regular expressions system defined in the XML schema\nspecification. And all of that builds on the unicode specification but that's\nanother country. So I ended up implementing a regex\nengine too.\nOver to XSLT. There's XSL Transformations (XSLT) Version\n3.0 which defines the XSLT programming\nlanguage. It builds on all the specifications that went before, and also builds\non XSLT and XQuery Serialization\n3.0, which describes\noptions for how to serialize XML and various other things.\nOf course all of this builds on the XML specification itself, Extensive Markup\nLanguage (XML) 1.0 (Fifth Edition), extended with\nnamespaces, in Namespaces in XML 1.0.\nThen there are a few stray specifications that are also relevant like XML\nBase and\nxml:id. But those are small ones.\nOnce I counted up the page count5 of just the XPath and XSLT\nspecifications along with the most relevant XML Schema spec (part 2), and that\nsubset is over 1800 pages.\nI probably forgot a few specifications, because after a while they start coming\nout of my ears, but this should give you an impression.\n\nXee status\nWhat I'm most proud of is the XPath 3.1 implementation in Xee. The XPath core\nlanguage and most of its standard library have been implemented. There are gaps\nin the standard library implementation still - some formatting functions are\nparticularly huge, for instance, but overall it's pretty complete.\nThere's an XPath 3.1 conformance test suite, and of the 21859 tests, 20130\ntests are passing at the time of writing. Most of the failing tests have to do\nwith the implementation of missing standard library functionality.\nIncidentally, this test suite runs those 20130 tests in 13 seconds on my\nmachine. Computers are fast.\nMeanwhile Xee also provides a solid basis for XSLT, reusing a lot of the XPath\ninfrastructure. While a lot of XSLT works, much remains to be done and I'm\nhoping to find people who want to help contribute!\n\nA call for contributors\nSo now I will call for this rare bird: someone who read all this, saw all those\nXML specifications, knows a bit of Rust, likes implementing programming\nlanguages and thought: cool! I want to help!\n\nDo you like the challenge of implementing some functionality, small or large,\naccording to spec? Xee has plenty of tasks for you.\n\nAre you interested in programming language implementation? Perhaps do cool\nprogramming language optimization work? For a programming language that has\nan existing user base already? Xee has the foundations.\n\nDo you like to think about query optimization problems? Care about using\nsuccinct data structures? (not\nintegrated into Xee proper yet). We have plenty of what should interest you.\n\nDo you care about the future of XML and want to ensure a modern open source\nimplementation is available outside of the Java world?\n\nThe Xee project could use your help and is ready for it. Small and large\ncontributions are possible and welcome!\n2\nI'm still hip. I say so. Even though I do XML stuff.\n\n1\nNot the same XSLT engine. Different ones!\n\n3\nXQuery is a superset of XPath.\n\n4\nSo you're interested in working on programming language\noptimization you've come to the right place!\n\n5\nI printed each specification HTML page to PDF to see how many pages\nthey were.\n\n                â†Prev\n                Looking for new challenges!\n\n  Comments\n  You can use your Mastodon account to reply to this post. Learn how\n  this is implemented here.\n\n  Reply\n  Load comments\n\n    Reply to this post\n\n      With an account on the Fediverse or Mastodon, you can respond to this\n      post. Since Mastodon is decentralized, you can use your existing account\n      hosted by another Mastodon server or compatible platform if you don't\n      have an account on this one.\n\n    Copy and paste this URL into the search field of your favorite Fediverse app or the web interface of your Mastodon server.\n\n      Copy\n      Close\n\n  You need JavaScript to view the comments.\n\n    const dialog = document.querySelector('dialog');\n\n    document.getElementById('replyButton').addEventListener('click', () => {\n       dialog.showModal();\n      });\n\n    document.getElementById('copyButton').addEventListener('click', () => {\n      navigator.clipboard.writeText(\"https://fosstodon.org/@faassen/114235009789423262\");\n    });\n\n    document.getElementById('cancelButton').addEventListener('click', () => {\n      dialog.close();\n    });\n\n    dialog.addEventListener('keydown', e => {\n      if (e.key === 'Escape') dialog.close();\n    });\n\n    function escapeHtml(unsafe) {\n      return unsafe\n            .replace(/&/g, \"&amp;\")\n            .replace(/</g, \"&lt;\")\n            .replace(/>/g, \"&gt;\")\n            .replace(/\"/g, \"&quot;\")\n            .replace(/'/g, \"&#039;\");\n    }\n\n    // render date as YYYY-MM-DD HH:MM, not using the browser's locale\n    function renderDate(date) {\n        return date.getFullYear() + \"-\" + (date.getMonth() + 1).toString().padStart(2, '0') + \"-\" + date.getDate().toString().padStart(2, '0') + \" \" + date.getHours().toString().padStart(2, '0') + \":\" + date.getMinutes().toString().padStart(2, '0');\n    }\n\n    document.getElementById(\"load-comment\").addEventListener(\"click\", function() {\n        document.getElementById(\"load-comment\").innerHTML = \"Loading\";\n        fetch('https://fosstodon.org/api/v1/statuses/114235009789423262/context')\n          .then(function(response) {\n            return response.json();\n          })\n          .then(function(data) {\n            if(data['descendants'] &&\n               Array.isArray(data['descendants']) &&\n              data['descendants'].length > 0) {\n                document.getElementById('mastodon-comments-list').innerHTML = \"\";\n                data['descendants'].forEach(function(reply) {\n                  reply.account.display_name = escapeHtml(reply.account.display_name);\n                  reply.account.reply_class = reply.in_reply_to_id == \"114235009789423262\" ? \"reply-original\" : \"reply-child\";\n                  reply.created_date = new Date(reply.created_at);\n                  reply.account.emojis.forEach(emoji => {\n                    reply.account.display_name = reply.account.display_name.replace(`:${emoji.shortcode}:`,\n                      `<img src=\"${escapeHtml(emoji.static_url)}\" alt=\"Emoji ${emoji.shortcode}\" height=\"20\" width=\"20\" />`);\n                  });\n                  mastodonComment =\n                    `\n<div class=\"mastodon-wrapper\">\n  <div class=\"comment-level ${reply.account.reply_class}\"><svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 512 512\">\n    <path fill=\"currentColor\" stroke=\"currentColor\" d=\"m 307,477.17986 c -11.5,-5.1 -19,-16.6 -19,-29.2 v -64 H 176 C 78.8,383.97986 -4.6936293e-8,305.17986 -4.6936293e-8,207.97986 -4.6936293e-8,94.679854 81.5,44.079854 100.2,33.879854 c 2.5,-1.4 5.3,-1.9 8.1,-1.9 10.9,0 19.7,8.9 19.7,19.7 0,7.5 -4.3,14.4 -9.8,19.5 -9.4,8.8 -22.2,26.4 -22.2,56.700006 0,53 43,96 96,96 h 96 v -64 c 0,-12.6 7.4,-24.1 19,-29.2 11.6,-5.1 25,-3 34.4,5.4 l 160,144 c 6.7,6.2 10.6,14.8 10.6,23.9 0,9.1 -3.9,17.7 -10.6,23.8 l -160,144 c -9.4,8.5 -22.9,10.6 -34.4,5.4 z\" />\n  </svg></div>\n  <div class=\"mastodon-comment\">\n    <div class=\"comment\">\n      <div class=\"comment-avatar\"><img src=\"${escapeHtml(reply.account.avatar_static)}\" alt=\"\"></div>\n      <div class=\"comment-author\">\n        <div class=\"comment-author-name\"><a href=\"${reply.account.url}\" rel=\"nofollow\">${reply.account.display_name}</a></div>\n        <div class=\"comment-author-reply\"><a href=\"${reply.account.url}\" rel=\"nofollow\">${escapeHtml(reply.account.acct)}</a></div>\n      </div>\n      <div class=\"meta\">${renderDate(reply.created_date)}</div>\n    </div>\n    <div class=\"comment-content\">${reply.content}</div>\n  </div>\n</div>\n`;\n                  document.getElementById('mastodon-comments-list').appendChild(DOMPurify.sanitize(mastodonComment, {'RETURN_DOM_FRAGMENT': true}));\n                });\n            } else {\n              document.getElementById('mastodon-comments-list').innerHTML = \"<p>No comments found</p>\";\n            }\n          });\n        });",
    "summary": {
      "en": "**Summary of Xee: A Modern XPath and XSLT Engine in Rust**\n\nXee is a programming language implementation in Rust that supports modern versions of XPath and XSLT, which are languages used for processing XML. The project started in 2023 with a client request and has evolved significantly since then. Xee includes a command-line tool for running XPath queries and a Rust library for issuing these queries.\n\n**Key Points:**\n\n- **What is Xee?** Xee implements XPath (a query language for XML) and XSLT (a transformation language for XML) using Rust, allowing integration with various programming languages.\n  \n- **Why is Xee Important?** It aims to modernize XML technology, as existing libraries like libxml2 and libxslt are outdated, only supporting older specifications from 1999. Xee targets modern standards (XPath 3.1 and XSLT 3.0), promoting a multi-language approach to XML processing.\n\n- **XML's Historical Context:** XML was popular in the early 2000s and remains widely used for data storage and document formats, despite newer technologies like JSON gaining traction.\n\n- **Implementation Details:** Xee uses a structured approach to implement programming languages, including tokenization, parsing, and compiling into bytecode. The XPath implementation is mostly complete, with a high passing rate on conformance tests.\n\n- **Call for Contributors:** The project seeks individuals familiar with Rust and interested in contributing to the development of Xee, whether through language implementation, optimization, or enhancing XML technology's future.\n\nOverall, Xee represents a modern effort to revitalize XML programming languages in the Rust ecosystem and welcomes community involvement for its advancement.",
      "ko": "XeeëŠ” Rustë¡œ êµ¬í˜„ëœ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ë¡œ, XML ì²˜ë¦¬ë¥¼ ìœ„í•œ ìµœì‹  ë²„ì „ì˜ XPathì™€ XSLTë¥¼ ì§€ì›í•©ë‹ˆë‹¤. ì´ í”„ë¡œì íŠ¸ëŠ” 2023ë…„ì— í´ë¼ì´ì–¸íŠ¸ì˜ ìš”ì²­ìœ¼ë¡œ ì‹œì‘ë˜ì—ˆìœ¼ë©°, ê·¸ ì´í›„ë¡œ í¬ê²Œ ë°œì „í–ˆìŠµë‹ˆë‹¤. XeeëŠ” XPath ì¿¼ë¦¬ë¥¼ ì‹¤í–‰í•˜ê¸° ìœ„í•œ ëª…ë ¹ì¤„ ë„êµ¬ì™€ ì´ëŸ¬í•œ ì¿¼ë¦¬ë¥¼ ë°œí–‰í•˜ê¸° ìœ„í•œ Rust ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n\nXeeëŠ” XMLì„ ìœ„í•œ ì¿¼ë¦¬ ì–¸ì–´ì¸ XPathì™€ XML ë³€í™˜ ì–¸ì–´ì¸ XSLTë¥¼ Rustë¡œ êµ¬í˜„í•˜ì—¬ ë‹¤ì–‘í•œ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì™€ í†µí•©í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤. ì´ í”„ë¡œì íŠ¸ëŠ” XML ê¸°ìˆ ì„ í˜„ëŒ€í™”í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•˜ê³  ìˆìœ¼ë©°, ê¸°ì¡´ì˜ libxml2ì™€ libxsltì™€ ê°™ì€ ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” 1999ë…„ì˜ êµ¬ì‹ ì‚¬ì–‘ë§Œ ì§€ì›í•˜ê³  ìˆì–´ ê·¸ í•„ìš”ì„±ì´ ì»¤ì§€ê³  ìˆìŠµë‹ˆë‹¤. XeeëŠ” ìµœì‹  í‘œì¤€ì¸ XPath 3.1ê³¼ XSLT 3.0ì„ ëª©í‘œë¡œ í•˜ì—¬ XML ì²˜ë¦¬ì— ëŒ€í•œ ë‹¤êµ­ì–´ ì ‘ê·¼ ë°©ì‹ì„ ì´‰ì§„í•©ë‹ˆë‹¤.\n\nXMLì€ 2000ë…„ëŒ€ ì´ˆë°˜ì— ì¸ê¸°ë¥¼ ëŒì—ˆìœ¼ë©°, ë°ì´í„° ì €ì¥ ë° ë¬¸ì„œ í˜•ì‹ìœ¼ë¡œ ë„ë¦¬ ì‚¬ìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤. ë¹„ë¡ JSONê³¼ ê°™ì€ ìƒˆë¡œìš´ ê¸°ìˆ ì´ ì£¼ëª©ë°›ê³  ìˆì§€ë§Œ, XMLì€ ì—¬ì „íˆ ì¤‘ìš”í•œ ì—­í• ì„ í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n\nXeeëŠ” í”„ë¡œê·¸ë˜ë° ì–¸ì–´ë¥¼ êµ¬í˜„í•˜ê¸° ìœ„í•´ êµ¬ì¡°í™”ëœ ì ‘ê·¼ ë°©ì‹ì„ ì‚¬ìš©í•˜ë©°, ì—¬ê¸°ì—ëŠ” í† í°í™”, íŒŒì‹±, ë°”ì´íŠ¸ì½”ë“œë¡œì˜ ì»´íŒŒì¼ì´ í¬í•¨ë©ë‹ˆë‹¤. XPath êµ¬í˜„ì€ ëŒ€ë¶€ë¶„ ì™„ë£Œë˜ì—ˆìœ¼ë©°, ì í•©ì„± í…ŒìŠ¤íŠ¸ì—ì„œ ë†’ì€ í†µê³¼ìœ¨ì„ ê¸°ë¡í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n\nì´ í”„ë¡œì íŠ¸ëŠ” Rustì— ìµìˆ™í•˜ê³  Xee ê°œë°œì— ê¸°ì—¬í•˜ê³ ì í•˜ëŠ” ì‚¬ëŒë“¤ì„ ì°¾ê³  ìˆìŠµë‹ˆë‹¤. ê¸°ì—¬ëŠ” ì–¸ì–´ êµ¬í˜„, ìµœì í™”, XML ê¸°ìˆ ì˜ ë¯¸ë˜ë¥¼ í–¥ìƒì‹œí‚¤ëŠ” ë‹¤ì–‘í•œ ë°©ì‹ìœ¼ë¡œ ì´ë£¨ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. XeeëŠ” Rust ìƒíƒœê³„ì—ì„œ XML í”„ë¡œê·¸ë˜ë° ì–¸ì–´ë¥¼ í˜„ëŒ€í™”í•˜ë ¤ëŠ” ë…¸ë ¥ì„ ëŒ€í‘œí•˜ë©°, ì»¤ë®¤ë‹ˆí‹°ì˜ ì°¸ì—¬ë¥¼ í™˜ì˜í•©ë‹ˆë‹¤.",
      "ja": "Xeeã¯ã€XMLå‡¦ç†ã«ä½¿ç”¨ã•ã‚Œã‚‹XPathã¨XSLTã®æœ€æ–°ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹Rustã§å®Ÿè£…ã•ã‚ŒãŸãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã§ã™ã€‚ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯2023å¹´ã«ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‹ã‚‰ã®ä¾é ¼ã‚’å—ã‘ã¦å§‹ã¾ã‚Šã€ãã®å¾Œå¤§ããé€²åŒ–ã—ã¾ã—ãŸã€‚Xeeã«ã¯XPathã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œã™ã‚‹ãŸã‚ã®ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ãƒ„ãƒ¼ãƒ«ã¨ã€ã“ã‚Œã‚‰ã®ã‚¯ã‚¨ãƒªã‚’ç™ºè¡Œã™ã‚‹ãŸã‚ã®Rustãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚\n\nXeeã¯ã€XMLã®ã‚¯ã‚¨ãƒªè¨€èªã§ã‚ã‚‹XPathã¨ã€XMLã®å¤‰æ›è¨€èªã§ã‚ã‚‹XSLTã‚’Rustã§å®Ÿè£…ã—ã¦ãŠã‚Šã€ã•ã¾ã–ã¾ãªãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã¨ã®çµ±åˆãŒå¯èƒ½ã§ã™ã€‚Xeeã®é‡è¦æ€§ã¯ã€æ—¢å­˜ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã‚ã‚‹libxml2ã‚„libxsltãŒ1999å¹´ã®å¤ã„ä»•æ§˜ã—ã‹ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ãªã„ãŸã‚ã€XMLæŠ€è¡“ã‚’ç¾ä»£åŒ–ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¦ã„ã‚‹ç‚¹ã«ã‚ã‚Šã¾ã™ã€‚Xeeã¯ã€XPath 3.1ã‚„XSLT 3.0ã¨ã„ã£ãŸæœ€æ–°ã®æ¨™æº–ã‚’ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã«ã—ã¦ãŠã‚Šã€XMLå‡¦ç†ã«ãŠã‘ã‚‹å¤šè¨€èªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ä¿ƒé€²ã—ã¦ã„ã¾ã™ã€‚\n\nXMLã¯2000å¹´ä»£åˆé ­ã«äººæ°—ãŒã‚ã‚Šã€ãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚„æ–‡æ›¸ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã¨ã—ã¦åºƒãä½¿ç”¨ã•ã‚Œã¦ã„ã¾ã™ãŒã€JSONã®ã‚ˆã†ãªæ–°ã—ã„æŠ€è¡“ã‚‚æ³¨ç›®ã•ã‚Œã¦ã„ã¾ã™ã€‚Xeeã¯ã€ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã‚’å®Ÿè£…ã™ã‚‹ãŸã‚ã«æ§‹é€ åŒ–ã•ã‚ŒãŸã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’æ¡ç”¨ã—ã¦ãŠã‚Šã€ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã€ãƒ‘ãƒ¼ã‚¹ã€ãƒã‚¤ãƒˆã‚³ãƒ¼ãƒ‰ã¸ã®ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã‚’å«ã‚“ã§ã„ã¾ã™ã€‚XPathã®å®Ÿè£…ã¯ã»ã¼å®Œæˆã—ã¦ãŠã‚Šã€é©åˆæ€§ãƒ†ã‚¹ãƒˆã§ã‚‚é«˜ã„åˆæ ¼ç‡ã‚’èª‡ã£ã¦ã„ã¾ã™ã€‚\n\nã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ã€Rustã«ç²¾é€šã—ã€Xeeã®é–‹ç™ºã«è²¢çŒ®ã—ãŸã„ã¨è€ƒãˆã¦ã„ã‚‹äººã€…ã‚’å‹Ÿé›†ã—ã¦ã„ã¾ã™ã€‚è²¢çŒ®ã®æ–¹æ³•ã¯ã€è¨€èªã®å®Ÿè£…ã‚„æœ€é©åŒ–ã€XMLæŠ€è¡“ã®æœªæ¥ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãªã©å¤šå²ã«ã‚ãŸã‚Šã¾ã™ã€‚Xeeã¯ã€Rustã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ã«ãŠã‘ã‚‹XMLãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã®ç¾ä»£çš„ãª revitalizationã‚’ç›®æŒ‡ã—ã¦ãŠã‚Šã€ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã®å‚åŠ ã‚’æ­“è¿ã—ã¦ã„ã¾ã™ã€‚"
    }
  },
  {
    "id": "e050176c443e4b2e",
    "title": {
      "en": "New open-source benchmark for real-time analytics applications",
      "ko": "ì‹¤ì‹œê°„ ë¶„ì„ ë²¤ì¹˜ë§ˆí¬ ê³µê°œ",
      "ja": "ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†æã®æ–°åŸºæº–"
    },
    "type": "story",
    "url": "https://github.com/timescale/rtabench",
    "score": 16,
    "by": "thenoahhein",
    "time": 1743029854,
    "content": "RTABench\nA Benchmark for Real-Time Analytics Applications\nrtabench.com\nMotivation\nChoosing the right database for analytics is hard: there are many options, each optimized for different use cases. Benchmarks can help, but only if they reflect your actual workload.\nCommon analytics benchmarks tend to represent analytics workloads as:\n\nStore all data in a single, wide, denormalized table.\nRun full-table scans or large aggregations across long time periods.\nAre optimized for ad-hoc, exploratory queries rather than pre-defined application queries.\n\nThis approach works well for batch processing and historical analysis, but real-time analytics inside applications requires a different perspective. Instead of analyzing large datasets retrospectively, applications generate fast, targeted insights on fresh data for specific users, devices, or transactions. This leads to three key differences:\n\nQueries require joining multiple tables instead of using a single denormalized table.\nQueries are often highly selective, filtering on specific objects and time windows.\nPre-aggregated views are very often used for instant responses.\n\nThat is why we designed RTABench, to provide a benchmark that accurately reflects real-time analytics inside applications, with a normalized schema, realistic dataset sizes, and queries that match real-world usage patterns.\nOverview\nRTABench uses the Clickbench framework for benchmarking, but it introduces a new dataset and query set that better represents real-time analytics inside applications. All tools, datasets, and benchmark results are available on GitHub, where we welcome contributions for expanding RTABench to support additional databases and optimizations.\nLike any benchmark, RTABench results should not be viewed as a ranking of databases, but rather as a guide to understanding which system aligns best with your real-time analytics needs.\nDataset\nSchema\nA Normalized Data Model That Reflects Real Applications\nRTABench is based on an application that tracks products, orders, and shipments for an online store. Instead of a single table, it follows a normalized schema that reflects how most applications store and manage data:\n\ncustomers â€“ stores information about people making orders.\nproducts â€“ contains product catalog information, including prices and stock levels.\norders â€“ tracks orders placed by customers.\norder_items â€“ records which products were included in each order.\norder_events â€“ tracks order status changes (e.g., created, shipped, delivered).\n\nThis multi-table schema ensures RTABench measures how well databases handle real-time analytics queries that require joins and filteringâ€”a scenario missing from other analytics benchmarks.\nEvents\nRTABench includes a dataset with ~171 million events that is large enough to run performance benchmarks without making it impractical to be used and run easily and fast.\nThe benchmark also includes 1,102 customers, 9,255 products and 10,010,342 orders, ensuring RTABench can test query performance under realistic application workloads while remaining scalable for different database configurations.\nQueries\nMeasuring Real-Time Performance\nRTABench evaluates databases using 33 queries designed to reflect the analytics patterns commonly found in real-time applications. These queries assess query performance on normalized schemas, selective filtering, and incremental materialized views:\n\nRaw event queries â€“ Counting, filtering, and aggregating events over time. (e.g., â€œCount the number of â€˜Departedâ€™ shipments per day at a specific terminal.â€)\nSelective filtering â€“ Querying specific objects and time windows to test indexing and partitioning efficiency. (e.g., â€œFind the last recorded status of a given order.â€)\nMulti-table joins â€“ Fetching related data across multiple tables to simulate real-world application queries. (e.g., â€œShow the total revenue generated by each customer in the last 30 days.â€)\nPre-aggregated queries â€“ Measuring how incremental materialized views improve response times by precomputing results. (e.g., â€œRetrieve pre-aggregated counts of delayed shipments over the last month.â€)\n\nBy including both raw and pre-aggregated queries, RTABench ensures that databases are tested for both ad-hoc analytics and optimized real-time reporting, capturing the trade-offs between flexibility and performance.\nDatabase systems included\nRTABench evaluates databases that are commonly used for real-time analytics inside applications, where high-ingest rates, low-latency queries, and efficient joins are critical. Databases in the benchmark fall into three broad categories:\n\nGeneral-Purpose Databases: A transactional database that can handle many use cases and used as the primary database for an application. Most general-purpose databases, like PostgreSQL and MySQL, are capable of handling real-time analytics depending on scale and performance requirements\nReal-Time Analytics: A database optimized for real-time analytics with support for high ingest throughput, making data instantly available, fast analytical queries and high concurrency. Specialized real-time analytics databases are often used as a secondary database for an application.\nBatch Analytics Databases: These databases are optimized for large-scale historical analysis and batch processing, excelling at ad-hoc queries on static datasets rather than real-time, continuously updated data.\nAlthough Batch analytics databases are not designed for real-time analytics, we have included them in RTABench for developers interested in comparing their performance.\nBecause these databases cannot serve real-time analytics, they are not the focus of this benchmark. Their results are not shown by default, as the benchmark is not targeted at them.\nItâ€™s possible for a database to fall into multiple categories based on their capabilities.\n\nThe first version of the benchmark includes the databases listed below:\n\nDatabase\nGeneral-Purpose\nReal-Time\nBatch Analytics\n\nClickHouse\n\nâœ…\nâœ…\n\nClickHouse Cloud\n\nâœ…\nâœ…\n\nDuckDB\n\nâœ…\n\nMongoDB\nâœ…\n\nMySQL\nâœ…\n\nPostgreSQL\nâœ…\n\nPostgreSQL with TimescaleDB\nâœ…\nâœ…\n\nTimescale Cloud\nâœ…\nâœ…\n\nRules and contributions\nRTABench is an open-source benchmark, and we encourage the community to contribute by:\n\nAdding new databases to expand the comparison.\nImproving query optimizations for different systems.\nProviding feedback on configurations to ensure fairness.\n\nContributions can be made through GitHub, where all benchmark tooling, datasets, and results are publicly available.\nBy using Clickbench as the underlying framework, we inherit the same rules for adding new systems and results.\nOther projects\nClickbench\nIt compares analytical databases using clickstream data. This type of workloadâ€”common in web analytics, BI reporting, and log aggregationâ€”favors single-table queries that scan large datasets to generate insights over long time ranges.\n\nhttps://github.com/ClickHouse/ClickBench\n\nTSBS\nTime Series Benchmark Suite is a benchmarking tool designed to evaluate the performance of time-series databases under realistic ingestion and query workloads.\n\nhttps://github.com/timescale/tsbs\n\nTPC-H\nA benchmark that measures the performance of analytical databases using a set of ad hoc business queries on a simplified schema. It evaluates the usecase of traditional data warehouses.\n\nhttps://www.tpc.org/tpch/\n\nTPC-DS\nAn evolution of TPC-H to provide a more realistic, complex, and comprehensive benchmark for modern decision support systems. It uses complex, business-oriented queries on large, multi-dimensional datasets. It's meant to evaluate data warehouse-like workloads (star/snowflake schema, fact/dimension tables)\n\nhttps://www.tpc.org/tpcds/",
    "summary": {
      "en": "**RTABench Summary**\n\nRTABench is a benchmarking tool designed to evaluate real-time analytics applications, addressing the challenges of selecting the right database for analytics. Traditional benchmarks often use a single wide table and focus on batch processing, which is not suitable for real-time needs. Real-time analytics requires:\n\n1. **Multiple Table Joins**: Queries typically involve joining several tables.\n2. **Selective Filtering**: Queries are focused on specific data points and timeframes.\n3. **Pre-aggregated Views**: Instant responses are often achieved through pre-computed data.\n\n**Key Features of RTABench**:\n\n- **Normalized Schema**: RTABench uses a structured data model reflecting real-world applications, such as an online store with tables for customers, products, orders, and order events.\n- **Realistic Dataset**: It includes approximately 171 million events, with detailed data on customers, products, and orders to test performance under realistic loads.\n- **Diverse Queries**: The benchmark evaluates 33 queries that mimic common analytics patterns in real-time applications, including raw event queries, selective filtering, multi-table joins, and pre-aggregated queries.\n\n**Database Categories Tested**:\n\n1. **General-Purpose Databases**: Such as PostgreSQL and MySQL, which can handle various use cases, including real-time analytics.\n2. **Real-Time Analytics Databases**: Optimized for fast querying and high data ingestion.\n3. **Batch Analytics Databases**: Focused on historical data analysis, included for comparative purposes but not the main focus of RTABench.\n\n**Community Contributions**: RTABench is open-source, allowing community members to add databases, improve queries, and provide feedback via GitHub.\n\nOverall, RTABench aims to provide a more accurate representation of real-time analytics needs compared to traditional benchmarks, fostering better database selection for specific application requirements.",
      "ko": "RTABenchëŠ” ì‹¤ì‹œê°„ ë¶„ì„ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ í‰ê°€í•˜ê¸° ìœ„í•´ ì„¤ê³„ëœ ë²¤ì¹˜ë§ˆí¬ ë„êµ¬ë¡œ, ë¶„ì„ì— ì í•©í•œ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì„ íƒí•˜ëŠ” ë° í•„ìš”í•œ ë¬¸ì œë¥¼ í•´ê²°í•©ë‹ˆë‹¤. ì „í†µì ì¸ ë²¤ì¹˜ë§ˆí¬ëŠ” ì¼ë°˜ì ìœ¼ë¡œ í•˜ë‚˜ì˜ ë„“ì€ í…Œì´ë¸”ì„ ì‚¬ìš©í•˜ê³  ë°°ì¹˜ ì²˜ë¦¬ì— ì¤‘ì ì„ ë‘ì§€ë§Œ, ì´ëŠ” ì‹¤ì‹œê°„ ìš”êµ¬ ì‚¬í•­ì— ì í•©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì‹¤ì‹œê°„ ë¶„ì„ì—ëŠ” ì—¬ëŸ¬ ê°€ì§€ ìš”ì†Œê°€ í•„ìš”í•©ë‹ˆë‹¤.\n\nì²«ì§¸, ì—¬ëŸ¬ í…Œì´ë¸”ì„ ì¡°ì¸í•˜ëŠ” ì¿¼ë¦¬ê°€ ì¼ë°˜ì ì…ë‹ˆë‹¤. ë‘˜ì§¸, ì¿¼ë¦¬ëŠ” íŠ¹ì • ë°ì´í„° í¬ì¸íŠ¸ì™€ ì‹œê°„ëŒ€ì— ì§‘ì¤‘í•©ë‹ˆë‹¤. ì…‹ì§¸, ì¦‰ê°ì ì¸ ì‘ë‹µì€ ì¢…ì¢… ë¯¸ë¦¬ ê³„ì‚°ëœ ë°ì´í„°ë¥¼ í†µí•´ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤.\n\nRTABenchì˜ ì£¼ìš” íŠ¹ì§•ìœ¼ë¡œëŠ” ì •ê·œí™”ëœ ìŠ¤í‚¤ë§ˆê°€ ìˆìŠµë‹ˆë‹¤. RTABenchëŠ” ê³ ê°, ì œí’ˆ, ì£¼ë¬¸ ë° ì£¼ë¬¸ ì´ë²¤íŠ¸ì— ëŒ€í•œ í…Œì´ë¸”ì„ í¬í•¨í•œ ì˜¨ë¼ì¸ ìƒì ê³¼ ê°™ì€ ì‹¤ì œ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ë°˜ì˜í•˜ëŠ” êµ¬ì¡°í™”ëœ ë°ì´í„° ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ë˜í•œ ì•½ 1ì–µ 7ì²œë§Œ ê°œì˜ ì´ë²¤íŠ¸ë¥¼ í¬í•¨í•œ í˜„ì‹¤ì ì¸ ë°ì´í„° ì„¸íŠ¸ë¥¼ ì œê³µí•˜ì—¬ ê³ ê°, ì œí’ˆ ë° ì£¼ë¬¸ì— ëŒ€í•œ ìƒì„¸ ë°ì´í„°ë¥¼ í†µí•´ ì‹¤ì œ ë¶€í•˜ì—ì„œ ì„±ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ë²¤ì¹˜ë§ˆí¬ëŠ” ì›ì‹œ ì´ë²¤íŠ¸ ì¿¼ë¦¬, ì„ íƒì  í•„í„°ë§, ë‹¤ì¤‘ í…Œì´ë¸” ì¡°ì¸ ë° ë¯¸ë¦¬ ì§‘ê³„ëœ ì¿¼ë¦¬ë¥¼ í¬í•¨í•˜ì—¬ ì‹¤ì‹œê°„ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ì¼ë°˜ì ì¸ ë¶„ì„ íŒ¨í„´ì„ ëª¨ë°©í•œ 33ê°œì˜ ì¿¼ë¦¬ë¥¼ í‰ê°€í•©ë‹ˆë‹¤.\n\ní…ŒìŠ¤íŠ¸ë˜ëŠ” ë°ì´í„°ë² ì´ìŠ¤ ì¹´í…Œê³ ë¦¬ëŠ” ì„¸ ê°€ì§€ë¡œ ë‚˜ë‰©ë‹ˆë‹¤. ì²«ì§¸, PostgreSQLê³¼ MySQLê³¼ ê°™ì€ ì¼ë°˜ ëª©ì  ë°ì´í„°ë² ì´ìŠ¤ë¡œ, ë‹¤ì–‘í•œ ì‚¬ìš© ì‚¬ë¡€ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆìœ¼ë©° ì‹¤ì‹œê°„ ë¶„ì„ë„ í¬í•¨ë©ë‹ˆë‹¤. ë‘˜ì§¸, ë¹ ë¥¸ ì¿¼ë¦¬ì™€ ë†’ì€ ë°ì´í„° ìˆ˜ì§‘ì„ ìœ„í•´ ìµœì í™”ëœ ì‹¤ì‹œê°„ ë¶„ì„ ë°ì´í„°ë² ì´ìŠ¤ì…ë‹ˆë‹¤. ì…‹ì§¸, ì—­ì‚¬ì  ë°ì´í„° ë¶„ì„ì— ì¤‘ì ì„ ë‘” ë°°ì¹˜ ë¶„ì„ ë°ì´í„°ë² ì´ìŠ¤ë¡œ, ë¹„êµ ëª©ì ìœ¼ë¡œ í¬í•¨ë˜ì§€ë§Œ RTABenchì˜ ì£¼ìš” ì´ˆì ì€ ì•„ë‹™ë‹ˆë‹¤.\n\nRTABenchëŠ” ì˜¤í”ˆ ì†ŒìŠ¤ í”„ë¡œì íŠ¸ë¡œ, ì»¤ë®¤ë‹ˆí‹° êµ¬ì„±ì›ë“¤ì´ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì¶”ê°€í•˜ê³  ì¿¼ë¦¬ë¥¼ ê°œì„ í•˜ë©° GitHubë¥¼ í†µí•´ í”¼ë“œë°±ì„ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì „ë°˜ì ìœ¼ë¡œ RTABenchëŠ” ì „í†µì ì¸ ë²¤ì¹˜ë§ˆí¬ì— ë¹„í•´ ì‹¤ì‹œê°„ ë¶„ì„ ìš”êµ¬ ì‚¬í•­ì„ ë³´ë‹¤ ì •í™•í•˜ê²Œ ë°˜ì˜í•˜ì—¬ íŠ¹ì • ì• í”Œë¦¬ì¼€ì´ì…˜ ìš”êµ¬ì— ë§ëŠ” ë°ì´í„°ë² ì´ìŠ¤ ì„ íƒì„ ì´‰ì§„í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•˜ê³  ìˆìŠµë‹ˆë‹¤.",
      "ja": "RTABenchã¯ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†æã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ„ãƒ¼ãƒ«ã§ã™ã€‚ã“ã®ãƒ„ãƒ¼ãƒ«ã¯ã€åˆ†æã«é©ã—ãŸãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’é¸ã¶éš›ã®èª²é¡Œã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚å¾“æ¥ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¯ã€å˜ä¸€ã®åºƒã„ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½¿ç”¨ã—ã€ãƒãƒƒãƒå‡¦ç†ã«ç„¦ç‚¹ã‚’å½“ã¦ã‚‹ã“ã¨ãŒå¤šãã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã®ãƒ‹ãƒ¼ã‚ºã«ã¯é©ã—ã¦ã„ã¾ã›ã‚“ã€‚ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†æã«ã¯ã€è¤‡æ•°ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’çµåˆã™ã‚‹ã“ã¨ã€ç‰¹å®šã®ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã‚„æ™‚é–“æ ã«åŸºã¥ãé¸æŠçš„ãªãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã€äº‹å‰ã«é›†è¨ˆã•ã‚ŒãŸãƒ“ãƒ¥ãƒ¼ã‚’é€šã˜ã¦ç¬æ™‚ã®å¿œç­”ã‚’å¾—ã‚‹ã“ã¨ãŒæ±‚ã‚ã‚‰ã‚Œã¾ã™ã€‚\n\nRTABenchã®ä¸»ãªç‰¹å¾´ã«ã¯ã€æ­£è¦åŒ–ã•ã‚ŒãŸã‚¹ã‚­ãƒ¼ãƒãŒã‚ã‚Šã¾ã™ã€‚ã“ã‚Œã¯ã€é¡§å®¢ã€å•†å“ã€æ³¨æ–‡ã€æ³¨æ–‡ã‚¤ãƒ™ãƒ³ãƒˆã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æŒã¤ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã‚¹ãƒˆã‚¢ãªã©ã€å®Ÿéš›ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’åæ˜ ã—ãŸæ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚ã¾ãŸã€ç´„1å„„7100ä¸‡ä»¶ã®ã‚¤ãƒ™ãƒ³ãƒˆã‚’å«ã‚€ç¾å®Ÿçš„ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒã‚ã‚Šã€é¡§å®¢ã€å•†å“ã€æ³¨æ–‡ã«é–¢ã™ã‚‹è©³ç´°ãªãƒ‡ãƒ¼ã‚¿ã‚’æä¾›ã—ã€ç¾å®Ÿçš„ãªè² è·ã®ä¸‹ã§ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ãƒ†ã‚¹ãƒˆã—ã¾ã™ã€‚ã•ã‚‰ã«ã€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¯ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«ãŠã‘ã‚‹ä¸€èˆ¬çš„ãªåˆ†æãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¨¡å€£ã—ãŸ33ã®ã‚¯ã‚¨ãƒªã‚’è©•ä¾¡ã—ã€ç”Ÿã®ã‚¤ãƒ™ãƒ³ãƒˆã‚¯ã‚¨ãƒªã€é¸æŠçš„ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã€è¤‡æ•°ãƒ†ãƒ¼ãƒ–ãƒ«ã®çµåˆã€äº‹å‰é›†è¨ˆã‚¯ã‚¨ãƒªã‚’å«ã‚“ã§ã„ã¾ã™ã€‚\n\nãƒ†ã‚¹ãƒˆã•ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ã‚«ãƒ†ã‚´ãƒªã«ã¯ã€ä¸€èˆ¬çš„ãªç”¨é€”å‘ã‘ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ï¼ˆPostgreSQLã‚„MySQLãªã©ï¼‰ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†æã«æœ€é©åŒ–ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã€é«˜é€Ÿãªã‚¯ã‚¨ãƒªå‡¦ç†ã¨é«˜ã„ãƒ‡ãƒ¼ã‚¿å–ã‚Šè¾¼ã¿ã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†æãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã€æ­´å²çš„ãƒ‡ãƒ¼ã‚¿åˆ†æã«ç„¦ç‚¹ã‚’å½“ã¦ãŸãƒãƒƒãƒåˆ†æãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚å¾Œè€…ã¯æ¯”è¼ƒã®ãŸã‚ã«å«ã¾ã‚Œã¦ã„ã¾ã™ãŒã€RTABenchã®ä¸»ãªç„¦ç‚¹ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚\n\nRTABenchã¯ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã§ã‚ã‚Šã€ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã®ãƒ¡ãƒ³ãƒãƒ¼ãŒãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’è¿½åŠ ã—ãŸã‚Šã€ã‚¯ã‚¨ãƒªã‚’æ”¹å–„ã—ãŸã‚Šã€GitHubã‚’é€šã˜ã¦ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’æä¾›ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚å…¨ä½“ã¨ã—ã¦ã€RTABenchã¯å¾“æ¥ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã«æ¯”ã¹ã¦ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†æã®ãƒ‹ãƒ¼ã‚ºã‚’ã‚ˆã‚Šæ­£ç¢ºã«è¡¨ç¾ã—ã€ç‰¹å®šã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³è¦ä»¶ã«é©ã—ãŸãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®é¸æŠã‚’ä¿ƒé€²ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¦ã„ã¾ã™ã€‚"
    }
  },
  {
    "id": "9df294c642beb2bc",
    "title": {
      "en": "Noise cancellation improves turn-taking for AI Voice Agents",
      "ko": "ì†ŒìŒ ì œê±°ë¡œ AI ìŒì„± ëŒ€í™” ê°œì„ ",
      "ja": "AIéŸ³å£°ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®é€²åŒ–"
    },
    "type": "story",
    "url": "https://krisp.ai/blog/improving-turn-taking-of-ai-voice-agents-with-background-voice-cancellation/",
    "score": 109,
    "by": "davitb",
    "time": 1742874977,
    "content": "Table of contents\n\n            Turn-Taking is a big challengeIntroducing Krisp Server SDK for AI Voice AgentsQuantifying the Krisp BVC ImpactImpact on Turn-TakingImpact on Speech Recognition Accuracy (WER)\n\n        Home / Company / Engineering Blog / Improving Turn-Taking of AI Voice Agents with Background Noise and Voice Cancellation\n\n                Engineering Blog\n\n                SDK\n\n        Improving Turn-Taking of AI Voice Agents with Background Noise and Voice Cancellation\n        Mar 24, 2025\n\n                    Written by Krisp Engineering Team\n\n            Turn-Taking is a big challengeIntroducing Krisp Server SDK for AI Voice AgentsQuantifying the Krisp BVC ImpactImpact on Turn-TakingImpact on Speech Recognition Accuracy (WER)\n\n                Get Started with Krisp AI Meeting Assistant:\n        Free Unlimited Meeting TranscriptionsAI-Powered Meeting Note TakerBot-free Meeting Recording Mode\n\n            Get Krisp for Free\n\n        Spread the word\n\n                                Turn-Taking is a big challenge\nAI Voice Agents are rapidly evolving, powering critical use-cases such as customer support automation, virtual assistants, gaming, and remote collaboration platforms. For these voice-driven interactions to feel natural and practical, the underlying audio pipeline must be resilient to noise, responsive, and accurateâ€”especially in real-time scenarios.\n\nIn a typical deployment, audio streams originate from diverse endpoints like mobile applications, web browsers, or traditional telephony and are delivered via real-time communication protocols like WebRTC or WebSockets (WSS). This audio is aggregated and managed through specialized providers like LiveKit, Daily, or Agora, which ensure reliable, low-latency audio transport to the server-side pipeline.\n\nWithin the server pipeline, once the audio arrives, it undergoes optional preprocessing steps for formatting or basic adjustments, after which it moves directly into a Voice Activity Detection (VAD).\nVAD identifies active speech segments, driving automatic end-pointing and intelligent interruption handling. Following a user speech, when VAD detects silence, relevant API events trigger downstream Voice AI models to generate and deliver responses. If the user resumes speaking during the voice botâ€™s response generation, the pipeline seamlessly cancels the ongoing output and clears buffers, ensuring natural conversational turn-taking.\n\nIn this scenario, background noisesâ€”such as music, traffic sounds, TVs, or nearby conversationsâ€”remain embedded within the audio stream, reaching the VAD module unfiltered. Because VAD is designed to detect human speech activity, these background sounds often cause false-positive speech detections. As a result, the VAD mistakenly interprets noise or background voices as active user speech, triggering unintended interruptions. These false triggers negatively impact turn-taking, a core component of natural, human-like conversational interactions.\n\nHere, by placing Krisp Background Voice and Noise Cancellation before the VAD, the pipeline substantially reduces false-positive triggers and prevents interruptions from common background distractions.\n\nAdditionally, Krisp significantly improves downstream speech processing accuracy by delivering cleaner audio.\nIntroducing Krisp Server SDK for AI Voice Agents\nWeâ€™re excited to announce the launch of Krisp Server SDK, featuring two advanced AI models engineered explicitly for superior noise cancellation for AI Voice Agents.\n\nCompared to our on-device AI models, these models are optimized to deliver unmatched performance and voice quality, especially in challenging corner cases.\n\nBoth models remove background noise, chatter, and secondary voices, ensuring the retention and clarity of only the primary speakerâ€™s voice.\n\nBVC-tel (General-Purpose Model):\n\nDesigned as a robust, versatile solution ideal for a wide variety of audio sources, including WebRTC, mobile, and traditional telephony inputs.\nSpecifically engineered to be highly resilient against audio artifacts introduced by common telephony codecs, such as the G711 codec, widely used in telecommunication networks.\nSupports audio sampling rates up to 16 kHz, which is optimal for AI Voice Agents as it effectively captures the essential frequency ranges of human speech.\n\nBVC-app (High-Fidelity Model):\n\nSpecifically optimized for WebRTC use-cases where high-quality audio streams are required.\nSupports higher sampling rates up to 32 kHz, enabling clearer, more natural-sounding voice interactions suitable for applications with superior audio fidelity.\n\nâ„¹ï¸ If the incoming audio source has a sampling rate higher than the modelâ€™s supported rate (e.g., 48 kHz), the SDK intelligently manages the audio processing by automatically downsampling to the modelâ€™s working rate, applying the noise cancellation and then seamlessly upsampling back to the original audio quality.\n\nDespite significant quality enhancements, server-side models maintain a low algorithmic latency of just 15 milliseconds, identical to our on-device models. This ensures real-time responsiveness, which is critical for conversational interactions.\n\nThe new Krisp Server SDK models are CPU-optimized and support a range of platforms, including:\n\nLinux (x64 and ARM64 architectures)\nWindows (x64) with ARM64 support coming soon.\n\nQuantifying the Krisp BVC Impact\nWe comprehensively evaluated how the new Background Voice and Noise Cancellation (BVC) model improves turn-taking accuracy and speech recognition quality.\nUsing the BVC-tel model, we specifically tested two distinct audio pipeline scenarios:\n\nBVC-VAD-STT: Audio processed by Krisp BVC and VAD is passed to the AI Voice Agent.\nBVC-VAD only: The original (unprocessed) audio is passed downstream to the AI Voice Agent, with Krisp BVC processed audio used solely for improved VAD accuracy.\n\nThe following graphics and audio examples demonstrate a typical example: Krisp BVC effectively canceling the background TV speech when interacting with the AI Voice Agent.\n\nThe red-circled areas represent the TV speech. The green-circled areas represent the primary speakerâ€™s speech.\n\nTurn-taking with VAD only\n\nTurn-taking with BVC-VAD\n\nTV speech passes through VAD, potentially interrupting the AI Voice Agent during its response.\nTV speech passes through VAD, potentially interrupting the AI Voice Agent during its response.\n\nOriginal Audio\n\nhttps://krisp.ai/blog/wp-content/uploads/2025/03/Original-Recording-1.wav\nOriginal Audio\nhttps://krisp.ai/blog/wp-content/uploads/2025/03/Original-Recording.wav\n\nAudio after VAD processing only\nhttps://krisp.ai/blog/wp-content/uploads/2025/03/Original-Recording-No-BVC-VAD.wav\nAudio after BVC processing\nhttps://krisp.ai/blog/wp-content/uploads/2025/03/Original-Recording-After-BVC.wav\n\nAudio after BVC + VAD processing\nhttps://krisp.ai/blog/wp-content/uploads/2025/03/Original-Recording-After-BVC-VAD.wav\n\nIn the following sections, we perform more comprehensive evaluations to capture and quantify improvements in turn-taking and WER improvements in STT.\n\nEvaluation Setup:\n\nDataset: We selected the widely-used AMI corpus, specifically the individual headset recordings. This dataset is ideal due to its realistic mix of background conversations and noise, which is representative of many typical mobile and telephony scenarios.\nVoice Activity Detection: Latest version of open-source SileroVAD\nSpeech-To-Text Models: Whisper V3 (base version). In our tests, the difference between the base and large versions was insignificant, so we present only the base model results.\n\nImpact on Turn-Taking\nApplying Krisp BVC upstream had a clear, positive impact on VAD precision within the AMI datasetâ€”especially in reducing false-positive speech detections. Lower false positives are particularly critical for ensuring smooth, uninterrupted conversational experiences.\n\nOur tests show that with Krisp BVC, false-positive triggers in VAD were reduced by 3.5x on average. This means the AI Voice Agent is significantly less likely to experience unintended interruptions caused by background speech or noise. Overall, the precision after Krisp BVC increases by over a quarterâ€”a major improvement.\nImpact on Speech Recognition Accuracy (WER)\nUsing Krisp BVC also markedly reduces the Word Error Rate (WER) of Whisper V3 models on the AMI datasetâ€”achieving more than a 2x improvement. This result aligns with expectations, given Krispâ€™s effectiveness in eliminating distracting background speech.\n\nInterestingly, the WER improvements were consistent in both BVC-VAD and BVC-VAD-STT modes.\n\nTo further explore this, we evaluated an additional dataset with minimal background speech: the ITU-T P.501 dataset, which mixes single-speaker audio with 24 different noise types at three intensity levels (0db, 5db, 10db).\n\nModern STT models, including Whisper, generally have strong built-in noise robustness. We aimed to measure any further WER improvements achievable by applying Krisp BVC upstream.\n\nIndeed, the WER metric was generally much lower in this case compared to the AMI dataset.\n\nIn the BVC-VAD mode, where Whisper operated on original audio while leveraging Krisp BVC-processed audio for enhanced VAD, we observed an 18% improvement in WER.\n\nConversely, in the BVC-VAD-STT mode â€” where Whisper processed Krisp-modified audioâ€”the WER increased by about 2x, although the absolute WER number is still relatively low. This increase is attributed to Whisper never encountering Krisp NC-processed audio during its training, which could cause suboptimal performance for such modified audio.\n\nğŸ’¡Note that WER% results in BVC-VAD-STT mode could be very different on other datasets and STT engines. We recommend experimenting with both BVC-VAD and BVC-VAD-STT modes to determine the optimal audio pipeline setup for you.\n\nOverall, these evaluations demonstrate that incorporating Krisp BVC into AI Voice Agents pipelines substantially improves turn-taking and speech recognition quality, especially in real-world scenarios where background noise and secondary conversations are prevalent.\n\n                        Please enable JavaScript to view the <a href=\"https://disqus.com/?ref_noscript\">comments powered by Disqus.</a>\n\n            Related Articles\n\n            Krisp and Fixie Bring AI Noise Cancellation to Ultravox to Improve Bot-to-Human Communication\n\n                Krisp and Fixie Bring AI Noise Cancellation to...\n\n        December 23, 2024\n\n                Company\n\n                Krisp News\n\n                SDK\n\n            Krisp and Vodex Partner to Perfect GenAI-Powered Voicebot Calls for High-Quality Lead Qualification\n\n                Krisp and Vodex Partner to Perfect GenAI-Powered Voicebot...\n\n        March 12, 2025\n\n                Company\n\n                Krisp News\n\n                SDK\n\n            Krisp launches Accent Conversion SDK Early Access Program for Communications Providers\n\n                Krisp launches Accent Conversion SDK Early Access Program...\n\n        March 12, 2025\n\n                AI Accent Conversion\n\n                Company\n\n                SDK\n\n            Elevate Your Contact Center Experience with Krisp Background Voice Cancellation (BVC)\n\n                Elevate Your Contact Center Experience with Krisp Background...\n\n        March 12, 2025\n\n                Engineering Blog\n\n                SDK\n\n            Krisp launches On-Device Transcription SDKs for Integration\n\n                Krisp launches On-Device Transcription SDKs for Integration\n\n        March 11, 2025\n\n                Krisp News\n\n                SDK\n\n            Enhancing Browser App Experiences: Krisp JS SDK Pioneers In-browser AI Voice Processing for Desktop and Mobile\n\n                Enhancing Browser App Experiences: Krisp JS SDK Pioneers...\n\n        March 12, 2025\n\n                Engineering Blog\n\n                SDK\n\n            Krisp Delivers AI-Powered Voice Clarity to Symphonyâ€™s Trader Voice Products\n\n                Krisp Delivers AI-Powered Voice Clarity to Symphonyâ€™s Trader...\n\n        March 12, 2025\n\n                Engineering Blog\n\n                Krisp News\n\n            Vonage to Launch Enhanced Noise Cancellation Powered by Krisp's Voice AI\n\n                Vonage to Launch Enhanced Noise Cancellation Powered by...\n\n        March 12, 2025\n\n                Krisp News\n\n                SDK\n\n            Krisp and CarrierXâ€™s FreeConferenceCall.com Integrate to Deliver AI-Powered Voice Clarity and Noise Cancellation\n\n                Krisp and CarrierXâ€™s FreeConferenceCall.com Integrate to Deliver AI-Powered...\n\n        March 12, 2025\n\n                Krisp News\n\n                SDK",
    "summary": {
      "en": "**Summary: Improving Turn-Taking for AI Voice Agents with Krisp SDK**\n\nAI Voice Agents are increasingly used for tasks like customer support, but managing smooth conversations is challenging due to background noise. To address this, Krisp has launched the Server SDK, which includes advanced models for noise cancellation, improving how these agents respond in real-time.\n\n**Key Features of Krisp Server SDK:**\n1. **Noise Cancellation Models**: There are two models:\n   - **BVC-tel**: General-purpose, suitable for various audio sources, resilient against telephony noise.\n   - **BVC-app**: High-fidelity, optimized for clear audio in WebRTC applications.\n\n2. **Real-Time Performance**: The SDK ensures minimal delay (15 milliseconds), maintaining the natural flow of conversation.\n\n3. **Impact on Turn-Taking**:\n   - Reduces false-positive speech detections by 3.5 times, leading to fewer interruptions during conversations.\n   - Enhances overall conversation quality.\n\n4. **Impact on Speech Recognition Accuracy**:\n   - More than 2x improvement in Word Error Rate (WER) for speech recognition, making understanding clearer.\n\nIn conclusion, integrating Krisp's Background Voice and Noise Cancellation technology significantly enhances the performance of AI Voice Agents, especially in noisy environments.",
      "ko": "AI ìŒì„± ì—ì´ì „íŠ¸ëŠ” ê³ ê° ì§€ì›ê³¼ ê°™ì€ ë‹¤ì–‘í•œ ì‘ì—…ì— ì ì  ë” ë§ì´ ì‚¬ìš©ë˜ê³  ìˆì§€ë§Œ, ë°°ê²½ ì†ŒìŒìœ¼ë¡œ ì¸í•´ ì›í™œí•œ ëŒ€í™”ë¥¼ ê´€ë¦¬í•˜ëŠ” ê²ƒì´ ì–´ë µìŠµë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ KrispëŠ” ì„œë²„ SDKë¥¼ ì¶œì‹œí–ˆìŠµë‹ˆë‹¤. ì´ SDKëŠ” ì†ŒìŒ ì œê±°ë¥¼ ìœ„í•œ ê³ ê¸‰ ëª¨ë¸ì„ í¬í•¨í•˜ê³  ìˆì–´, AI ìŒì„± ì—ì´ì „íŠ¸ê°€ ì‹¤ì‹œê°„ìœ¼ë¡œ ë” ì˜ ë°˜ì‘í•  ìˆ˜ ìˆë„ë¡ ê°œì„ í–ˆìŠµë‹ˆë‹¤.\n\nKrisp ì„œë²„ SDKì˜ ì£¼ìš” ê¸°ëŠ¥ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. ì²«ì§¸, ì†ŒìŒ ì œê±° ëª¨ë¸ì´ ë‘ ê°€ì§€ ìˆìŠµë‹ˆë‹¤. BVC-telì€ ì¼ë°˜ì ì¸ ìš©ë„ë¡œ ë‹¤ì–‘í•œ ì˜¤ë””ì˜¤ ì†ŒìŠ¤ì— ì í•©í•˜ë©°, ì „í™” ì†ŒìŒì— ê°•í•œ íŠ¹ì§•ì´ ìˆìŠµë‹ˆë‹¤. BVC-appì€ ê³ ìŒì§ˆì„ ì œê³µí•˜ë©°, WebRTC ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ëª…í™•í•œ ì˜¤ë””ì˜¤ë¥¼ ìœ„í•´ ìµœì í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ë‘˜ì§¸, ì´ SDKëŠ” ìµœì†Œí•œì˜ ì§€ì—° ì‹œê°„(15ë°€ë¦¬ì´ˆ)ì„ ë³´ì¥í•˜ì—¬ ëŒ€í™”ì˜ ìì—°ìŠ¤ëŸ¬ìš´ íë¦„ì„ ìœ ì§€í•©ë‹ˆë‹¤.\n\nì…‹ì§¸, í„´ í…Œì´í‚¹(turn-taking)ì—ë„ ê¸ì •ì ì¸ ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤. ì˜ëª»ëœ ìŒì„± ê°ì§€ë¥¼ 3.5ë°° ì¤„ì—¬ ëŒ€í™” ì¤‘ì˜ ë°©í•´ë¥¼ ì¤„ì´ê³ , ì „ì²´ì ì¸ ëŒ€í™” í’ˆì§ˆì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ë„·ì§¸, ìŒì„± ì¸ì‹ ì •í™•ë„ì—ë„ ì˜í–¥ì„ ë¯¸ì³, ìŒì„± ì¸ì‹ì˜ ë‹¨ì–´ ì˜¤ë¥˜ìœ¨(Word Error Rate, WER)ì´ 2ë°° ì´ìƒ ê°œì„ ë˜ì–´ ì´í•´ë„ê°€ ë†’ì•„ì§‘ë‹ˆë‹¤.\n\nKrispì˜ ë°°ê²½ ìŒì„± ë° ì†ŒìŒ ì œê±° ê¸°ìˆ ì„ í†µí•©í•˜ë©´, íŠ¹íˆ ì†ŒìŒì´ ë§ì€ í™˜ê²½ì—ì„œ AI ìŒì„± ì—ì´ì „íŠ¸ì˜ ì„±ëŠ¥ì´ í¬ê²Œ í–¥ìƒë©ë‹ˆë‹¤.",
      "ja": "AIãƒœã‚¤ã‚¹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯ã€ã‚«ã‚¹ã‚¿ãƒãƒ¼ã‚µãƒãƒ¼ãƒˆãªã©ã®æ¥­å‹™ã§ã¾ã™ã¾ã™åˆ©ç”¨ã•ã‚Œã¦ã„ã¾ã™ãŒã€èƒŒæ™¯é›‘éŸ³ã®ãŸã‚ã«ã‚¹ãƒ ãƒ¼ã‚ºãªä¼šè©±ã‚’ç®¡ç†ã™ã‚‹ã®ãŒé›£ã—ã„ã¨ã„ã†èª²é¡ŒãŒã‚ã‚Šã¾ã™ã€‚ã“ã®å•é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€Krispã¯ã‚µãƒ¼ãƒãƒ¼SDKã‚’ç™ºè¡¨ã—ã¾ã—ãŸã€‚ã“ã®SDKã«ã¯ã€ãƒã‚¤ã‚ºã‚­ãƒ£ãƒ³ã‚»ãƒªãƒ³ã‚°ã®ãŸã‚ã®é«˜åº¦ãªãƒ¢ãƒ‡ãƒ«ãŒå«ã¾ã‚Œã¦ãŠã‚Šã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§å¿œç­”ã™ã‚‹éš›ã®æ”¹å–„ãŒæœŸå¾…ã•ã‚Œã¦ã„ã¾ã™ã€‚\n\nKrispã‚µãƒ¼ãƒãƒ¼SDKã®ä¸»ãªç‰¹å¾´ã«ã¯ã€ã¾ãšãƒã‚¤ã‚ºã‚­ãƒ£ãƒ³ã‚»ãƒªãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ãŒ2ã¤ã‚ã‚Šã¾ã™ã€‚1ã¤ç›®ã¯ã€ŒBVC-telã€ã§ã€ä¸€èˆ¬çš„ãªç”¨é€”ã«é©ã—ã¦ãŠã‚Šã€ã•ã¾ã–ã¾ãªéŸ³æºã«å¯¾å¿œã—ã€é›»è©±ã®é›‘éŸ³ã«ã‚‚å¼·ã„ã§ã™ã€‚2ã¤ç›®ã¯ã€ŒBVC-appã€ã§ã€é«˜éŸ³è³ªã‚’æä¾›ã—ã€WebRTCã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã®ã‚¯ãƒªã‚¢ãªéŸ³å£°ã«æœ€é©åŒ–ã•ã‚Œã¦ã„ã¾ã™ã€‚\n\næ¬¡ã«ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ€§èƒ½ã«ã¤ã„ã¦ã§ã™ãŒã€ã“ã®SDKã¯é…å»¶ã‚’æœ€å°é™ã«æŠ‘ãˆï¼ˆ15ãƒŸãƒªç§’ï¼‰ã€ä¼šè©±ã®è‡ªç„¶ãªæµã‚Œã‚’ç¶­æŒã—ã¾ã™ã€‚\n\nã‚¿ãƒ¼ãƒ³ãƒ†ã‚¤ã‚­ãƒ³ã‚°ã¸ã®å½±éŸ¿ã¨ã—ã¦ã¯ã€èª¤æ¤œå‡ºã«ã‚ˆã‚‹ã‚¹ãƒ”ãƒ¼ãƒã®èª¤èªè­˜ã‚’3.5å€æ¸›å°‘ã•ã›ã€ä¼šè©±ä¸­ã®ä¸­æ–­ã‚’æ¸›ã‚‰ã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€å…¨ä½“çš„ãªä¼šè©±ã®è³ªãŒå‘ä¸Šã—ã¾ã™ã€‚\n\nã•ã‚‰ã«ã€ã‚¹ãƒ”ãƒ¼ãƒèªè­˜ã®ç²¾åº¦ã«ã‚‚å½±éŸ¿ã‚’ä¸ãˆã€å˜èªèª¤ã‚Šç‡ï¼ˆWERï¼‰ãŒ2å€ä»¥ä¸Šæ”¹å–„ã•ã‚Œã€ç†è§£ãŒã‚ˆã‚Šæ˜ç¢ºã«ãªã‚Šã¾ã™ã€‚\n\nKrispã®èƒŒæ™¯éŸ³å£°ã¨ãƒã‚¤ã‚ºã‚­ãƒ£ãƒ³ã‚»ãƒªãƒ³ã‚°æŠ€è¡“ã‚’çµ±åˆã™ã‚‹ã“ã¨ã§ã€ç‰¹ã«é¨’ãŒã—ã„ç’°å¢ƒã«ãŠã„ã¦AIãƒœã‚¤ã‚¹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æ€§èƒ½ãŒå¤§å¹…ã«å‘ä¸Šã™ã‚‹ã“ã¨ãŒæœŸå¾…ã•ã‚Œã¦ã„ã¾ã™ã€‚"
    }
  },
  {
    "id": "826927cf951a630b",
    "title": {
      "en": "Show HN: Create presentations with smart animations using Excalidraw",
      "ko": "ìŠ¤ë§ˆíŠ¸ ì• ë‹ˆë©”ì´ì…˜ìœ¼ë¡œ í”„ë ˆì  í…Œì´ì…˜ ë§Œë“¤ê¸°!",
      "ja": "ã‚¨ã‚¯ã‚¹ã‚«ãƒªãƒ‰ãƒ­ãƒ¼ã§é­…ã›ã‚‹ãƒ—ãƒ¬ã‚¼ãƒ³"
    },
    "type": "story",
    "url": "https://github.com/excalidraw-smart-presentation/excalidraw-smart-presentation.github.io",
    "score": 7,
    "by": "OmarBrikaa",
    "time": 1743251115,
    "content": "Excalidraw Smart Presentation\nCreate dynamic, animated presentations directly within Excalidraw.\nThis tool allows you to define frames as slides, automatically animating elements that persist between frames. It enables seamless transitions and a structured way to present ideas visually.\n\n    excalidraw-smart-presentation.mp4\n\nPresentation source: Available in ./presentation-docs.\nHow to Use\n\nCreate Frames:\n\nUse the Frame tool (f key, toolbar, or command palette).\nEach frame represents a slide.\n\nDefine Slide Order:\n\nFrames are ordered based on their y-axis position.\n\nAnimations:\n\nElements that are duplicated from one frame to the other are animated on slide transition by interpolating the changes in their properties.\nThis behavior can be customized (see below).\n\nPresent Your Slides:\n\nClick \"Present\", then use â†’ / â† (arrow keys) to navigate.\n\nTips & Tricks\n\nStart from a Specific Slide:\n\nSelect a frame, then click \"Present\".\n\nMaintain a 16:9 Aspect Ratio or any exact size:\n\nEdit frame size via \"Canvas & Shape Properties\" (Alt + / or command palette).\n\nDuplicate an element into the exact same position in the next frame:\n\nSelect an element, then press Ctrl + Shift + D\nOr use \"Duplicate into next frame\" from the command palette.\n\nFix Unintended Animations:\n\nElements with the same name in consecutive frames are animated.\nElements are given the same name on duplication, hence why duplicated elements are animated.\nRename elements in \"Canvas & Shape Properties\" to prevent unwanted animations or to animate different elements.\n\nCurrent Limitations\n\nNot usable on touch-screens and requires a keyboard since arrow keys are the only way to navigate slides.\nThe \"Present\" button is not shown on mobile/small screens, users must open a new tab and append #presentation=0 manually to the website's link.\nAnimation duration (300 ms) and type (linear) are not customizable.\nAnimations can sometimes be slightly choppy, though this is not a major issue.",
    "summary": {
      "en": "**Excalidraw Smart Presentation Summary**\n\nExcalidraw offers a tool for creating animated presentations. Here are the key points:\n\n- **Dynamic Slides**: You can create slides (frames) that automatically animate elements between them for smooth transitions.\n  \n- **Creating Frames**: Use the Frame tool (press 'f' or access the toolbar) to create slides, which are arranged by their vertical position.\n\n- **Animation**: Duplicated elements between frames automatically animate during transitions. You can customize this behavior.\n\n- **Presenting**: Click \"Present\" and navigate through slides using the arrow keys.\n\n**Tips**:\n- Start from any slide by selecting a frame and clicking \"Present.\"\n- To maintain a specific size, adjust frame dimensions in \"Canvas & Shape Properties.\"\n- Use Ctrl + Shift + D to duplicate elements in the same position on the next slide.\n- Rename elements to control animations and avoid unwanted effects.\n\n**Limitations**:\n- Not touch-screen compatible and requires keyboard navigation.\n- The \"Present\" button is hidden on small screens; manually adjust the URL for access.\n- Animation settings (duration and type) are fixed and not customizable.\n- Some animations may appear choppy, but it's generally not a significant issue.",
      "ko": "ì—‘ìŠ¤ì¹¼ë¦¬ë“œë¡œìš°ëŠ” ì• ë‹ˆë©”ì´ì…˜ í”„ë ˆì  í…Œì´ì…˜ì„ ë§Œë“¤ ìˆ˜ ìˆëŠ” ë„êµ¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì£¼ìš” ë‚´ìš©ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n\në™ì ì¸ ìŠ¬ë¼ì´ë“œë¥¼ ë§Œë“¤ ìˆ˜ ìˆìœ¼ë©°, ìŠ¬ë¼ì´ë“œ ê°„ì˜ ìš”ì†Œë“¤ì´ ìë™ìœ¼ë¡œ ì• ë‹ˆë©”ì´ì…˜ë˜ì–´ ë¶€ë“œëŸ¬ìš´ ì „í™˜ì„ ì œê³µí•©ë‹ˆë‹¤. ìŠ¬ë¼ì´ë“œë¥¼ ë§Œë“¤ê¸° ìœ„í•´ì„œëŠ” í”„ë ˆì„ ë„êµ¬ë¥¼ ì‚¬ìš©í•´ì•¼ í•˜ë©°, 'f' í‚¤ë¥¼ ëˆ„ë¥´ê±°ë‚˜ íˆ´ë°”ì—ì„œ ì ‘ê·¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìŠ¬ë¼ì´ë“œëŠ” ìˆ˜ì§ ìœ„ì¹˜ì— ë”°ë¼ ì •ë ¬ë©ë‹ˆë‹¤.\n\ní”„ë ˆì„ ê°„ì— ì¤‘ë³µëœ ìš”ì†ŒëŠ” ì „í™˜ ì¤‘ì— ìë™ìœ¼ë¡œ ì• ë‹ˆë©”ì´ì…˜ì´ ì ìš©ë©ë‹ˆë‹¤. ì´ ë™ì‘ì€ ì‚¬ìš©ìì— ë§ê²Œ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í”„ë ˆì  í…Œì´ì…˜ì„ ì‹œì‘í•˜ë ¤ë©´ \"Present\" ë²„íŠ¼ì„ í´ë¦­í•˜ê³  í™”ì‚´í‘œ í‚¤ë¥¼ ì‚¬ìš©í•´ ìŠ¬ë¼ì´ë“œë¥¼ íƒìƒ‰í•˜ë©´ ë©ë‹ˆë‹¤.\n\nëª‡ ê°€ì§€ íŒìœ¼ë¡œëŠ”, ì›í•˜ëŠ” ìŠ¬ë¼ì´ë“œì—ì„œ ì‹œì‘í•˜ë ¤ë©´ í”„ë ˆì„ì„ ì„ íƒí•˜ê³  \"Present\"ë¥¼ í´ë¦­í•˜ë©´ ë©ë‹ˆë‹¤. íŠ¹ì • í¬ê¸°ë¥¼ ìœ ì§€í•˜ë ¤ë©´ \"Canvas & Shape Properties\"ì—ì„œ í”„ë ˆì„ì˜ í¬ê¸°ë¥¼ ì¡°ì •í•´ì•¼ í•©ë‹ˆë‹¤. Ctrl + Shift + Dë¥¼ ì‚¬ìš©í•˜ë©´ ë‹¤ìŒ ìŠ¬ë¼ì´ë“œì—ì„œ ë™ì¼í•œ ìœ„ì¹˜ì— ìš”ì†Œë¥¼ ë³µì œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìš”ì†Œì˜ ì´ë¦„ì„ ë°”ê¾¸ë©´ ì• ë‹ˆë©”ì´ì…˜ì„ ì œì–´í•˜ê³  ì›ì¹˜ ì•ŠëŠ” íš¨ê³¼ë¥¼ í”¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nì œí•œ ì‚¬í•­ìœ¼ë¡œëŠ” í„°ì¹˜ ìŠ¤í¬ë¦°ê³¼ í˜¸í™˜ë˜ì§€ ì•Šìœ¼ë©° í‚¤ë³´ë“œ ë‚´ë¹„ê²Œì´ì…˜ì´ í•„ìš”í•©ë‹ˆë‹¤. ì‘ì€ í™”ë©´ì—ì„œëŠ” \"Present\" ë²„íŠ¼ì´ ìˆ¨ê²¨ì ¸ ìˆìœ¼ë¯€ë¡œ URLì„ ìˆ˜ë™ìœ¼ë¡œ ì¡°ì •í•´ì•¼ ì ‘ê·¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì• ë‹ˆë©”ì´ì…˜ ì„¤ì •(ì§€ì† ì‹œê°„ê³¼ ìœ í˜•)ì€ ê³ ì •ë˜ì–´ ìˆì–´ ì‚¬ìš©ì ë§ì¶¤ ì„¤ì •ì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤. ì¼ë¶€ ì• ë‹ˆë©”ì´ì…˜ì€ ë‹¤ì†Œ ëŠê¸°ëŠ” ê²½ìš°ê°€ ìˆì§€ë§Œ, ì¼ë°˜ì ìœ¼ë¡œ í° ë¬¸ì œëŠ” ì•„ë‹™ë‹ˆë‹¤.",
      "ja": "Excalidrawã¯ã€ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä½œæˆã™ã‚‹ãŸã‚ã®ãƒ„ãƒ¼ãƒ«ã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚ä¸»ãªãƒã‚¤ãƒ³ãƒˆã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ã€‚\n\nå‹•çš„ãªã‚¹ãƒ©ã‚¤ãƒ‰ã‚’ä½œæˆã§ãã€ã‚¹ãƒ©ã‚¤ãƒ‰é–“ã®è¦ç´ ãŒè‡ªå‹•çš„ã«ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã—ã€ã‚¹ãƒ ãƒ¼ã‚ºãªç§»è¡ŒãŒå¯èƒ½ã§ã™ã€‚ã‚¹ãƒ©ã‚¤ãƒ‰ã‚’ä½œæˆã™ã‚‹ã«ã¯ã€ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ„ãƒ¼ãƒ«ã¯ã€Œfã€ã‚’æŠ¼ã™ã‹ã€ãƒ„ãƒ¼ãƒ«ãƒãƒ¼ã‹ã‚‰ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã™ã€‚ã‚¹ãƒ©ã‚¤ãƒ‰ã¯ç¸¦ã®ä½ç½®ã«ã‚ˆã£ã¦é…ç½®ã•ã‚Œã¾ã™ã€‚\n\nãƒ•ãƒ¬ãƒ¼ãƒ é–“ã§è¤‡è£½ã•ã‚ŒãŸè¦ç´ ã¯ã€ç§»è¡Œä¸­ã«è‡ªå‹•çš„ã«ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã—ã¾ã™ã€‚ã“ã®å‹•ä½œã¯ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºå¯èƒ½ã§ã™ã€‚ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è¡Œã†ã«ã¯ã€ã€ŒPresentã€ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã€çŸ¢å°ã‚­ãƒ¼ã‚’ä½¿ã£ã¦ã‚¹ãƒ©ã‚¤ãƒ‰ã‚’ç§»å‹•ã—ã¾ã™ã€‚\n\nã„ãã¤ã‹ã®ãƒ’ãƒ³ãƒˆã¨ã—ã¦ã€ä»»æ„ã®ã‚¹ãƒ©ã‚¤ãƒ‰ã‹ã‚‰å§‹ã‚ã‚‹ã«ã¯ã€ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’é¸æŠã—ã¦ã€ŒPresentã€ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¾ã™ã€‚ç‰¹å®šã®ã‚µã‚¤ã‚ºã‚’ç¶­æŒã™ã‚‹ã«ã¯ã€ã€ŒCanvas & Shape Propertiesã€ã§ãƒ•ãƒ¬ãƒ¼ãƒ ã®å¯¸æ³•ã‚’èª¿æ•´ã—ã¾ã™ã€‚åŒã˜ä½ç½®ã«è¦ç´ ã‚’è¤‡è£½ã™ã‚‹ã«ã¯ã€Ctrl + Shift + Dã‚’ä½¿ç”¨ã—ã¾ã™ã€‚ã¾ãŸã€ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’åˆ¶å¾¡ã—ã€ä¸è¦ãªåŠ¹æœã‚’é¿ã‘ã‚‹ãŸã‚ã«è¦ç´ ã®åå‰ã‚’å¤‰æ›´ã™ã‚‹ã“ã¨ã‚‚é‡è¦ã§ã™ã€‚\n\nåˆ¶é™äº‹é …ã¨ã—ã¦ã¯ã€ã‚¿ãƒƒãƒã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã«ã¯å¯¾å¿œã—ã¦ãŠã‚‰ãšã€ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ã§ã®æ“ä½œãŒå¿…è¦ã§ã™ã€‚å°ã•ãªç”»é¢ã§ã¯ã€ŒPresentã€ãƒœã‚¿ãƒ³ãŒéš ã‚Œã¦ã„ã‚‹ãŸã‚ã€æ‰‹å‹•ã§URLã‚’èª¿æ•´ã—ã¦ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã®è¨­å®šï¼ˆæŒç¶šæ™‚é–“ã‚„ç¨®é¡ï¼‰ã¯å›ºå®šã•ã‚Œã¦ãŠã‚Šã€ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã¯ã§ãã¾ã›ã‚“ã€‚ã¾ãŸã€ä¸€éƒ¨ã®ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã¯ã‚«ã‚¯ã‚«ã‚¯ã—ã¦è¦‹ãˆã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ãŒã€ä¸€èˆ¬çš„ã«ã¯å¤§ããªå•é¡Œã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚"
    }
  },
  {
    "id": "25013395192a7d77",
    "title": {
      "en": "Every Flop Counts: Scaling a 300B LLM Without Premium GPUs",
      "ko": "ëª¨ë“  ì‹¤íŒ¨ê°€ ì¤‘ìš”í•˜ë‹¤: 300B LLMì˜ ì €ë¹„ìš© í™•ì¥",
      "ja": "ãƒ•ãƒ­ãƒƒãƒ—ã®åŠ›: 300B LLMã®æŒ‘æˆ¦"
    },
    "type": "story",
    "url": "https://arxiv.org/abs/2503.05139",
    "score": 114,
    "by": "bretpiatt",
    "time": 1742820496,
    "content": "In this technical report, we tackle the challenges of training large-scale Mixture of Experts (MoE) models, focusing on overcoming cost inefficiency and resource limitations prevalent in such systems. To address these issues, we present two differently sized MoE large language models (LLMs), namely Ling-Lite and Ling-Plus (referred to as \"Bailing\" in Chinese, spelled BÇilÃ­ng in Pinyin). Ling-Lite contains 16.8 billion parameters with 2.75 billion activated parameters, while Ling-Plus boasts 290 billion parameters with 28.8 billion activated parameters. Both models exhibit comparable performance to leading industry benchmarks. This report offers actionable insights to improve the efficiency and accessibility of AI development in resource-constrained settings, promoting more scalable and sustainable technologies. Specifically, to reduce training costs for large-scale MoE models, we propose innovative methods for (1) optimization of model architecture and training processes, (2) refinement of training anomaly handling, and (3) enhancement of model evaluation efficiency. Additionally, leveraging high-quality data generated from knowledge graphs, our models demonstrate superior capabilities in tool use compared to other models. Ultimately, our experimental findings demonstrate that a 300B MoE LLM can be effectively trained on lower-performance devices while achieving comparable performance to models of a similar scale, including dense and MoE models. Compared to high-performance devices, utilizing a lower-specification hardware system during the pre-training phase demonstrates significant cost savings, reducing computing costs by approximately 20%. The models can be accessed at this https URL.",
    "summary": {
      "en": "This report addresses the challenges of training large Mixture of Experts (MoE) models, particularly focusing on cost and resource limitations. It introduces two models: Ling-Lite, with 16.8 billion parameters, and Ling-Plus, with 290 billion parameters. Both models perform similarly to top industry standards. The report provides practical strategies to enhance AI development in resource-limited environments, making it more scalable and sustainable. Key methods to reduce training costs include optimizing model architecture, improving training anomaly handling, and increasing evaluation efficiency. The models also utilize high-quality data from knowledge graphs, enhancing their tool use capabilities. Notably, a 300B MoE model can be trained on less powerful devices while maintaining competitive performance, which can save about 20% in computing costs compared to using high-performance hardware.",
      "ko": "ì´ ë³´ê³ ì„œëŠ” ëŒ€ê·œëª¨ ì „ë¬¸ê°€ í˜¼í•© ëª¨ë¸(MoE)ì„ í›ˆë ¨í•˜ëŠ” ë° ìˆì–´ ë¹„ìš©ê³¼ ìì› ì œí•œì´ë¼ëŠ” ë„ì „ ê³¼ì œë¥¼ ë‹¤ë£¹ë‹ˆë‹¤. íŠ¹íˆ 168ì–µ ê°œì˜ ë§¤ê°œë³€ìˆ˜ë¥¼ ê°€ì§„ Ling-Lite ëª¨ë¸ê³¼ 2900ì–µ ê°œì˜ ë§¤ê°œë³€ìˆ˜ë¥¼ ê°€ì§„ Ling-Plus ëª¨ë¸ì„ ì†Œê°œí•©ë‹ˆë‹¤. ë‘ ëª¨ë¸ ëª¨ë‘ ì—…ê³„ ìµœê³  ìˆ˜ì¤€ì˜ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤. ì´ ë³´ê³ ì„œëŠ” ìì›ì´ ì œí•œëœ í™˜ê²½ì—ì„œ AI ê°œë°œì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•œ ì‹¤ìš©ì ì¸ ì „ëµì„ ì œì‹œí•˜ì—¬, ë” í™•ì¥ ê°€ëŠ¥í•˜ê³  ì§€ì† ê°€ëŠ¥í•œ ê°œë°œì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. í›ˆë ¨ ë¹„ìš©ì„ ì¤„ì´ê¸° ìœ„í•œ ì£¼ìš” ë°©ë²•ìœ¼ë¡œëŠ” ëª¨ë¸ êµ¬ì¡° ìµœì í™”, í›ˆë ¨ ì¤‘ ì´ìƒ ì²˜ë¦¬ ê°œì„ , í‰ê°€ íš¨ìœ¨ì„± ì¦ê°€ ë“±ì´ ìˆìŠµë‹ˆë‹¤. ë˜í•œ ì´ ëª¨ë¸ë“¤ì€ ì§€ì‹ ê·¸ë˜í”„ì—ì„œ ì–»ì€ ê³ í’ˆì§ˆ ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ ë„êµ¬ ì‚¬ìš© ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. íŠ¹íˆ, 300B MoE ëª¨ë¸ì€ ì„±ëŠ¥ì„ ìœ ì§€í•˜ë©´ì„œë„ ëœ ê°•ë ¥í•œ ì¥ì¹˜ì—ì„œ í›ˆë ¨í•  ìˆ˜ ìˆì–´, ê³ ì„±ëŠ¥ í•˜ë“œì›¨ì–´ë¥¼ ì‚¬ìš©í•  ë•Œë³´ë‹¤ ì•½ 20%ì˜ ì»´í“¨íŒ… ë¹„ìš©ì„ ì ˆê°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
      "ja": "ã“ã®å ±å‘Šæ›¸ã§ã¯ã€å¤§è¦æ¨¡ãªMixture of Expertsï¼ˆMoEï¼‰ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«é–¢ã™ã‚‹èª²é¡Œã€ç‰¹ã«ã‚³ã‚¹ãƒˆã‚„ãƒªã‚½ãƒ¼ã‚¹ã®åˆ¶ç´„ã«ã¤ã„ã¦å–ã‚Šä¸Šã’ã¦ã„ã¾ã™ã€‚16.8å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŒã¤Ling-Liteãƒ¢ãƒ‡ãƒ«ã¨ã€290å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŒã¤Ling-Plusãƒ¢ãƒ‡ãƒ«ã®2ã¤ã‚’ç´¹ä»‹ã—ã¦ã„ã¾ã™ã€‚ã©ã¡ã‚‰ã®ãƒ¢ãƒ‡ãƒ«ã‚‚ã€æ¥­ç•Œã®ãƒˆãƒƒãƒ—ã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰ã¨åŒç­‰ã®æ€§èƒ½ã‚’ç™ºæ®ã—ã¾ã™ã€‚ã“ã®å ±å‘Šæ›¸ã§ã¯ã€ãƒªã‚½ãƒ¼ã‚¹ãŒé™ã‚‰ã‚ŒãŸç’°å¢ƒã§ã®AIé–‹ç™ºã‚’ä¿ƒé€²ã™ã‚‹ãŸã‚ã®å®Ÿç”¨çš„ãªæˆ¦ç•¥ã‚’æä¾›ã—ã€ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã¨æŒç¶šå¯èƒ½æ€§ã‚’é«˜ã‚ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¦ã„ã¾ã™ã€‚\n\nãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚³ã‚¹ãƒˆã‚’å‰Šæ¸›ã™ã‚‹ãŸã‚ã®ä¸»ãªæ–¹æ³•ã«ã¯ã€ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®æœ€é©åŒ–ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­ã®ç•°å¸¸å‡¦ç†ã®æ”¹å–„ã€è©•ä¾¡åŠ¹ç‡ã®å‘ä¸ŠãŒå«ã¾ã‚Œã¾ã™ã€‚ã¾ãŸã€ãƒ¢ãƒ‡ãƒ«ã¯çŸ¥è­˜ã‚°ãƒ©ãƒ•ã‹ã‚‰ã®é«˜å“è³ªãªãƒ‡ãƒ¼ã‚¿ã‚’æ´»ç”¨ã—ã€ãƒ„ãƒ¼ãƒ«ã®ä½¿ç”¨èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã¦ã„ã¾ã™ã€‚ç‰¹ã«ã€300å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®MoEãƒ¢ãƒ‡ãƒ«ã¯ã€æ€§èƒ½ã‚’ç¶­æŒã—ãªãŒã‚‰ã€ã‚ˆã‚Šæ€§èƒ½ã®ä½ã„ãƒ‡ãƒã‚¤ã‚¹ã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒå¯èƒ½ã§ã‚ã‚Šã€é«˜æ€§èƒ½ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã¨æ¯”ã¹ã¦ç´„20%ã®è¨ˆç®—ã‚³ã‚¹ãƒˆã‚’ç¯€ç´„ã§ãã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚"
    }
  },
  {
    "id": "212a03a3801f11de",
    "title": {
      "en": "I tried making artificial sunlight at home",
      "ko": "ì¸ê³µ í–‡ë¹› ë§Œë“¤ê¸° ë„ì „!",
      "ja": "è‡ªå®…ã§äººå·¥å¤ªé™½ä½œã‚Šï¼"
    },
    "type": "story",
    "url": "https://victorpoughon.fr/i-tried-making-artificial-sunlight-at-home/",
    "score": 596,
    "by": "fouronnes3",
    "time": 1743104968,
    "content": "I tried making artificial sunlight at home\n\n                    27 Mar, 2025\n\n    Some time ago, I saw this video by DIY Perks where they make artificial sunlight at home with a 500W LED and a gigantic (1.2m) parabolic reflector. I've been fascinated by this project ever since, and I wanted my own.\nOver the past year or so, I finally took the time to work on a similar project, but I had the idea for a different design. The issue with the parabolic reflector is that it takes a huge amount of space. Could I do something similar, but with a less bulky design? This is the story of my first attempt at this project - version 1 so to speak. Perhaps there will be a version 2 in the future. Enjoy the read!\n\nMy idea - as others have had I'm sure - was to use an array of lenses laid out as a grid. Then, instead of a single light source, I would use a grid array of multiple LEDs, one per lens. In my mind, this would have two major advantages:\n\nLess bulky. The size of the device would be determined by the focal length of the individual lens elements, and because each would be small, the focal length could be small also, while maintaining a decent f number.\nEasier thermal management. Multiple light sources could be regular low power LEDs which wouldn't need special cooling. There would just be a lot of them, spread out over the entire device surface.\n\nOver the course of this project, I also intended to teach myself some manufacturing and 3D design, as I don't have any experience doing any of this. My background is software, and as you'll see I took a very software heavy approach to this. It was all a long learning journey for me, but in the end I used:\n\nMostly build123d for CAD modeling, with some FreeCAD for final assembly checks and some experiments here and there - including with the cool OpticsWorkbench.\nKiCad for PCB design.\nCustom python code for simulating light and optimizing the optical system. (This custom code eventually became an entire open-source project for optimization-based optical design)\nJLCPCB for printing and assembling PCBs, and for manufacturing aluminum and plastic parts with their CNC service.\n\nTL;DR: I did it! Here is the finished device sitting on my desk today, at night:\n\nAnd here it is during the day (much less impressive!)\n\nBeware it's kinda hard to take good pictures of it, and I don't have the best photo gear. Here's also a video: (at night)\n\n  Your browser does not support the video tag.\n\nKinda cool that you can see a lens flare effect in the shape of the lens grid array.\nTechnical specsMechanical:\n\nLens square side length: 30mm\nEffective Focal length: 55mm\nArray size: 6x6 = 36 LEDs\nTotal size: 180x180mm\n\nParts:\n\nLenses: 1 biconvex lens array, 1 plano-convex lens array - custom made out of PMMA acrylic, CNC fabrication with vapor polish finish @ JLCCNC\nLEDs: LUXEON 2835 3V -- Ref: 2835HE. CRI: 95+, color temp: 4000K, 65mA.\nPCBs: Custom design\nMounting hardware: custom design - aluminium 60601 for the CNC parts and mate black resin for the 3D printed parts\nRayleigh diffuser: waterproof printing inkjet film\n\nGeneral design and sizingTo create artificial sunlight, you need four ingredients:\n\nParallel light rays. The sun is so far away that light rays emitted from a point on the surface of the sun reach us essentially parallel. This is not to say that all light rays coming from the sun are parallel, as it still has a 0.5 deg apparent angular size. But they need to be pretty straight. Any light coming from an artificial light source like an LED will be going in all directions, so some optics is required.\nHigh color quality. A good indicator to look for on a datasheet is the color rendering index (CRI). 95+ is recommended to achieve a good effect. I'm sure there's more color science you could get into, but CRI is a great start for off the shelf parts.\nRayleigh scattering, or an imitation of it.\nA LOT of power.\n\nLight intensity is the most important sizing constraint, so let's look at it first. Now, the sun is very bright. Like, ridiculously bright: around 100,000 lux. To achieve this with LEDs is by no means impossible, but it's a challenge. For this first version, I thought that targetting 10,000 lux would be quite enough because it would reduce the power consumption a lot for a first prototype, and also brightness perception is logarithmic. So one tenth of the intensity is really, perceptually, almost the same as full brightness. (In the end, I estimate my design only effectively achieved something between 1000 and 10000 lux).\nThe general grid based design of this project really has two variables:\n\nthe individual LED light output, in lumens\nthe individual lens surface area in mmÂ²\n\nAfter some research, I think values between 30 to 130 lumens are typical for high CRI surface mount LEDs. So, assuming this is what we are working with, what is the required lens size to achieve the brightness of the sun?\nWe have to assume some non perfect efficiency for collimating the light. This will never be 100%, and in fact may be quite low if the focal length is high, because a lot of the light will be hitting the side walls instead of reaching the lens. The lens itself will also be absorbing some light. So taking a wild guess of 0.5 for the overall optical efficiency, and taking three lumens value of 30, 80 and 130, we get this plot:\n\nWith that in mind, I selected 30mm as my lens square side length. Presumably, this would be small enough to achieve some effect, but not too small to make the lenses too hard to make.\nLensesFocal length, and the lenses shape in general, is the next design consideration. The goal is to have perfectly parallel light rays. In theory, with a perfect point source and a perfect lens this is easy. Put the light source at the lens focal length, you're done. In practice, a lot of things make it harder to achieve with a lens. (This is where the parabolic reflector design is superior to a lens).\n\nA LED is not a point source\nA lens will not have perfect optical performance (i.e. aberrations)\nMechanical reality of the device means that positioning and orientation will not be perfect\nA LED radiation pattern is not isotropic, meaning intensity will be greater at the lens center\n\nThis is the radiation pattern characteristics diagram from my LED datasheet:\n\nI wrote some custom python code to simulate the optical system I had in mind, and find the best lens shape using numerical optimization. (This code eventually became an open-source project: torchlensmaker) After a lot of experimentation, I settled on a 2 lens design:\n\nLens 1: Biconvex parabolic lens\nLens 2: Planoconvex parabolic lens\n\nThe effective focal length of this two lens system is about 55mm. Focal length is a key design parameter, and here I feel like more experimentation is needed. It's a big tradeoff consideration and has a huge impact on the system design. It impacts:\n\nThe curvature of the lens surface, which is a key manufacturing point (you want to minimize curvature for manufacturing, which means maximizing focal length)\nThe optical efficiency of the system due to the led radiance pattern (here you want to minimize focal length, to gather more of the emitted light)\nThe device thickness (here I wanted a not-too-thick device, so to minimize focal length also)\n\nI used a two lens system mostly to reduce the surface curvature of the lens arrays. This reduces the manufacturing cost by a lot. High curvature lenses are more expensive in general, and this grid array design means that a high curvature lens will create sort of \"valleys\" in between the lenses. Because I was targetting CNC manufacturing, this is to be minimized to get a design that's even possible to machine.\nThis is the optical simulation I had at the time I finalized the design and ordered the lenses. (Since then my simulation code has improved and I could likely do much better modeling today using the latest version of torchlensmaker):\n\nWith some custom build123d code I was able to make the two lenses 3D models by stacking the lenses in a grid pattern and adding edges for mounting:\n\n  <p>Your browser does not support iframes.</p>\n\n  <p>Your browser does not support iframes.</p>\n\nWhat's really cool using build123d for 3D modeling, is that I can just change a python variable to change the size of the array, of the thickness of the lens, of anything else really. It's all parametric out of the box because it's regular Python code! This makes exploring the design space very efficient. I've never done 3D modeling any other way, but I can't imagine ever not having the power of programming with me if I ever do it again!\nI had the lenses manufactured out of PMMA acrylic at JLC with a vapor polish finish. Total cost for the lenses was about 55â‚¬ which is really not bad!\nOne of the two main lens array, built by JLCCNC:\n\nLEDsI really wanted to use the 3030 G04 from YUJILEDS, but it's only sold on 5000 units reels that cost $1000 a piece... maybe for version 2 I will upgrade to those. For version 1, I settled on LUXEON 2835 3V. They are about 3 times less bright than the YUJILED, but they have good color rendering and the SMD package I was looking for. And importantly, the minimum order quantity was only 50 at JLC global sourcing.\nIn the version 1 design, the grid is 6x6 which means 36 LEDs total.\nPCBsI designed a custom PCB with KiCAD. Each PCB holds 6 LEDs which are laid out as 2 segments of a 12V led strip in parallel. This allows to use a standard wall plug 12V power supply.\n\nThe mechanical role of the PCB is very important in this design. Not only does it distribute power to the LEDs and regulate current, it also precisely positions the LEDs at the lens focal point. For this, exporting the PCB 3D model and importing it into FreeCAD was very useful to check that everything fits together: the PCB in the aluminum support baseplate, the holes on the light hoods, etc. My Python code exported the precise LED coordinates which I could input into KiCad's layout editor.\nI had the PCB printed and the components assembled by JLCPCB. It's very very cool to design an electronic board on your computer and get it fully assembled in the mail a few weeks later - no soldering required! (for this step anyway).\n\nMechanical mounting partsTo mount everything together I designed 3 parts:\n\nA baseplate, to hold the PCBs and the side walls. The PCBs are fitted below the baseplate, and light goes through holes drilled into the baseplate. There are also partial holes to allow for the thickness of the SMD resistors mounted on top of the PCBs, and finally two mounting holes per PCB. This is why it has so many holes :)\n\n  <p>Your browser does not support iframes.</p>\n\nSide walls to hold the lenses using grooves in which to insert them, and a larger groove to secure in the baseplate. The baseplate side holes are threaded to support M2 screws securing the base of the walls. Again, JLCCNC did the drilling and threading of the holes at a great price.\n\n  <p>Your browser does not support iframes.</p>\n\nLight hoods, a rectangle block with rectangular holes. It sits on top of the PCB to shape the light coming from each LED into a cone (or really a four sided pyramid). This is to make sure light from a given LED only reaches its matching lens on the lens array, and no other. Bleed light is inevitable, but at least this prevents direct leakage.\n\n  <p>Your browser does not support iframes.</p>\n\nThe hoods were 3D printed out of black resin, the walls and baseplate were CNC cut out of Aluminum 60601.\nI'm not a mechanical engineer so this process was... trial and error. Still the result is working so I'm quite happy with that. For a possible version 2, there's a lot I'll change in the mechanical design. But apart from the one design flaw I was able to fix manually with a drill (more on that below), everything fit together quite well on the first try.\nRayleigh scatteringThe final ingredient is Rayleigh scattering. This is the physical phenomenon that makes the sky look blue, and it's important to achieve a convincing effect. In the DIY Perks video that inspired this project, they used a home made liquid solution with suspended particles of the correct size for Rayleigh scattering. Not super practical and I really wanted to find another solution (get it?). Thankfully, some time after the original video, someone on the diyperks forum discovered that inkjet print film achieves a very similar effect. A quick trip to a local office supply store was all I needed here! Amazing discovery.\nI didn't anticipate this step during the initial design phase, so the film is simply cut to the correct size and secured with black electrical tape.\nAssemblyAfter a few weeks of design work, and another few weeks of waiting for the parts to arrive, it was finally time for assembly!\nOn top of the individual 3D models made with build123d, I had a final assembly FreeCAD model with all parts fitted together, including the lenses:\n\nNote the green brackets that I initially planned to use. When actually assembling the walls to the baseplate, the solidity of the formed box was very high, I decided to drop the brackets entirely. This is why some extra unused holes remain on the side walls.\nThis is all the parts just after unboxing (excluding the inkjet film, solder tin, screws, power supply, wiring, electrical tape):\n\nThe only real design flaw was insufficient width of the grooves that hold the lenses. The lenses have an edge thickness of 1.2mm, which I had intended to fit into a 1.22mm groove. Turns out this was not enough, probably due to a combination of manufacturing tolerance and additional thickness added by the anodizing black matte surface finish of the aluminum part. The lenses didn't fit into the grooves!\nI don't have a very advanced tools at home, so my best solution to this was making the existing grooves wider by hand using a power drill. I bought a 1.5mm metal drill bit and achieved a decent result by doing 4 to 5 passes per groove. This took about 2-3h in total because I had to move the bit quite slow and could only machine about 1/4th of each groove depth at a time by moving the drill bit slowly accross, and there are 8 grooves total.\n\nHere's some more pictures of assembly below.\nThe back side after soldering wires to the PCB power pins and a socket for the 12V power supply. The PCBs and hood pieces share a common mounting hole so only two screws per PCB-hood pair are used.\n\nThe front side of the baseplate + PCB + hoods assembly, but without the lenses, powered on. Don't look at it directly :)\n\nIt's interesting to note that in the picture above, all of the light you can see from the LEDs is actually \"bleed light\" and not useful light. None of the light visible above is the light that's intended to go into the lens and produce the sunlight effect.\nTesting with partial assembly of the walls and only 1 out of the 2 lenses:\n\nTesting the inkjet film layers with an avocado as a subject. I settled on using two layers of the inkjet film for the final build:\n\nCostOverall I spent around 1000â‚¬ on this project. But this includes cost of tools I was missing, prototype parts that I had manufactured but discarded, bulk orders for parts like LEDs and PCBs which had a minium order quantity above what I need for 1 unit, and various supplies like screws, etc. The actual raw cost of parts only, without shipping, to build the final unit is hard to estimate. But I would say around 300â‚¬. The most expensive parts are the CNC parts (PMMA lenses and the aluminum baseplate and walls) accounting for about 2/3rd of the total price. The rest (PCBs, assembly service, LEDs, 3D printed plastic parts) was quite cheap.\nConclusionAs I write this the final piece is sitting on my desk and producing a pleasant soft white glow. It's definitely nice, and I'm very proud of the result - especially because this was by far the biggest build project I have ever done.\n\nThanks to this project, I've learned a ton about PCB design, electronics and CNC manufacturing and optics. I even got so far down the side quest of learning optics that I started an open-source python project for modeling geometric optics.\nSo, is it convincing as artificial sunlight?\nMy honest answer to that is: partially. The geometric effect of the light source appearing at infinity works. As I pan and tilt my head from side to side, the illusion of light coming from way far behind the object is 100% a success. On top of that, if you look at it while moving your head into the light beam, my eyes get surprised - almost hurt - by the sudden intensity jump. This indicates that collimation is good and you can sort of see it in the video at the start of this post.\nHowever it's apparent that it's simply too weak. Don't get me wrong, it's still bright. I can't look at it directly without sunglasses, and honestly it's really hard to take a good picture of it because the contrast between the light it emits and the outside of it is very high.\nAnother downside is that I can definitely make out the grid of lenses, as the intensity pattern clearly reveals the grid shape. This is quite a minor downside and not really unpleasant, and I'm sure it could be improved upon.\nIf I were to ever work on a version 2, I would focus on:\n\nMore power. My feeling is the light output needs to be 3 to 5 times stronger to get any closer to a convincing effect, and it's not crazy to aim for as much as 10x brighter than this prototype.\nMore surface area. This prototype is 18cm x 18cm. So you only really get the effect if you are able to sit with the produced straight beam of light, which is quite narrow to resemble any kind of \"fake window\". A future version would need to be 2 to 4 times wider in my opinion.\nBetter optical design. I still think a refraction based design is possible, but it requires very precise optical design and mechanical tolerances. My feeling is that a refraction based design, especially as a grid, is very sensitive to positioning and orientation of parts. I lack mechanical engineering skills in this area.\n\nHowever there are some really encouraging things that I really like about this grid based, refractive design:\n\nIt's scalable. If I had built 4 identical items, I could literally stack them on top of each other and get more surface area. The \"bezels\" would be only 5% of the total light emitting area, and I'm sure this could be lowered. I also like that the inner design calls for repeated elements, as this introduces some economy of scale, even at the prototype level. The only part that's not trivially scalable is the lens grid. Maybe it could be injection molded for very large scale production, or for medium scale you could come up with a way to tile multiple lens grids into a larger overall grid pattern, adding some thin bezels for mounting.\nIt's compact. The total size is 19cm x 19cm x 9cm. This is quite compact for a 5cm focal length and an effective lighting area of 18cm x 18cm. Reflective designs like the DIYPerks video or commercial products like CoeLux do not achieve this form factor.\nThermal management is better by design. This is not really something I got into for this design, as it's quite underpowered. The whole thing runs comfortably on a 12V / 3A wall brick power supply. But this design offers great margin for scaling up because there isn't a single light source to cool down, but a number of LEDs proportional to the surface area. I suspect the main thermal issue when scaling up would be the cooling of the power supply itself, not of the lamp.\n\nAs final thoughts, let me talk about the software heavy approach I had for this project. It's awesome. If I was starting a manufacturing company today, I would do it all code based. PCBs, 3D models, assembly, testing... I want code everywhere. The power of changing a parameter and having the entire design updated with a single script it so good. Run a script and get all the production data including GERBERs, BOM, 3D models, mechanical schematics, technical diagrams, automated tolerance and electrical checks... absolutely no manual steps between changing a design parameter and ready to send a new order to manufacturing. The PCB and CAD space is even evolving to use proper CI/CD tools which is really exciting.\nI don't know if I'll ever have the time to work on version 2 of this project, but it was great fun anyway! And now I have a cool unique lamp. Thank you for reading!\n\n            116\n\n    document.querySelector('#upvote-form').addEventListener('submit', (e) => {\n        e.preventDefault();\n        const form = e.target;\n        fetch(form.action, {\n            method: form.method,\n            body: new FormData(form),\n        });\n        const button = form.querySelector('button')\n        button.disabled = true\n        button.style.color = \"salmon\"\n        const upvoteCount = document.querySelector('.upvote-count')\n        upvoteCount.innerHTML = `${(parseInt(upvoteCount.innerHTML.split(\" \")[0]) + 1)}`\n    });",
    "summary": {
      "en": "The author shares their experience of creating artificial sunlight at home, inspired by a video from DIY Perks. They aimed to design a less bulky version of a project that used a large parabolic reflector by developing a grid of lenses with multiple LEDs.\n\nKey points include:\n\n- **Design Concept**: The author used a grid of small lenses and multiple low-power LEDs to create a compact light source, focusing on easier thermal management and a smaller footprint compared to traditional designs.\n  \n- **Learning Experience**: They learned about CAD modeling, PCB design, and optics through this project, utilizing tools like build123d, KiCad, and custom Python code for simulations.\n\n- **Technical Details**: The finished device features a lens array with 36 LEDs, each LED designed to produce a high color rendering index (CRI) light. The goal was to mimic the sunâ€™s parallel light rays.\n\n- **Challenges**: Despite achieving some success in creating the light effect, the brightness was lower than intended, and the lens grid pattern was visible. The author plans potential improvements for future versions, including increasing light intensity and surface area.\n\n- **Cost and Assembly**: The project cost around â‚¬1000, including tools and parts, with the main components being CNC-manufactured lenses and PCBs.\n\nOverall, the author is proud of their first version of the artificial sunlight lamp and mentions that the experience taught them valuable skills in electronics and manufacturing. They express interest in developing a second version to enhance the design.",
      "ko": "ì €ìëŠ” DIY Perksì˜ ì˜ê°ì„ ë°›ì•„ ì§‘ì—ì„œ ì¸ê³µ íƒœì–‘ê´‘ì„ ë§Œë“œëŠ” ê²½í—˜ì„ ê³µìœ í•©ë‹ˆë‹¤. ê·¸ë“¤ì€ ëŒ€í˜• í¬ë¬¼ì„  ë°˜ì‚¬ê²½ì„ ì‚¬ìš©í•˜ëŠ” í”„ë¡œì íŠ¸ì˜ ë¶€í”¼ë¥¼ ì¤„ì¸ ë²„ì „ì„ ì„¤ê³„í•˜ê¸° ìœ„í•´ ì—¬ëŸ¬ ê°œì˜ LEDê°€ ì¥ì°©ëœ ë Œì¦ˆ ê·¸ë¦¬ë“œë¥¼ ê°œë°œí–ˆìŠµë‹ˆë‹¤.\n\në””ìì¸ ê°œë…ìœ¼ë¡œëŠ” ì‘ì€ ë Œì¦ˆì™€ ì €ì „ë ¥ LEDë¥¼ ì¡°í•©í•˜ì—¬ ì»´íŒ©íŠ¸í•œ ê´‘ì›ì„ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤. ì´ëŠ” ì „í†µì ì¸ ë””ìì¸ì— ë¹„í•´ ì—´ ê´€ë¦¬ê°€ ìš©ì´í•˜ê³  ê³µê°„ì„ ëœ ì°¨ì§€í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í–ˆìŠµë‹ˆë‹¤.\n\nì´ í”„ë¡œì íŠ¸ë¥¼ í†µí•´ CAD ëª¨ë¸ë§, PCB ì„¤ê³„, ê´‘í•™ì— ëŒ€í•´ ë°°ì› ìœ¼ë©°, build123d, KiCad, ë§ì¶¤í˜• íŒŒì´ì¬ ì½”ë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹œë®¬ë ˆì´ì…˜ì„ ì§„í–‰í–ˆìŠµë‹ˆë‹¤.\n\nì™„ì„±ëœ ì¥ì¹˜ëŠ” 36ê°œì˜ LEDê°€ ì¥ì°©ëœ ë Œì¦ˆ ë°°ì—´ë¡œ êµ¬ì„±ë˜ì–´ ìˆìœ¼ë©°, ê° LEDëŠ” ë†’ì€ ìƒ‰ ì¬í˜„ ì§€ìˆ˜(CRI)ë¥¼ ê°€ì§„ ë¹›ì„ ìƒì„±í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. ëª©í‘œëŠ” íƒœì–‘ì˜ í‰í–‰í•œ ë¹›ì„ ëª¨ë°©í•˜ëŠ” ê²ƒì´ì—ˆìŠµë‹ˆë‹¤.\n\në¹› íš¨ê³¼ë¥¼ ì–´ëŠ ì •ë„ ì„±ê³µì ìœ¼ë¡œ ë§Œë“¤ì–´ëƒˆì§€ë§Œ, ë°ê¸°ê°€ ì˜ˆìƒë³´ë‹¤ ë‚®ì•˜ê³  ë Œì¦ˆ ê·¸ë¦¬ë“œ íŒ¨í„´ì´ ë³´ì´ëŠ” ë¬¸ì œê°€ ìˆì—ˆìŠµë‹ˆë‹¤. ì €ìëŠ” í–¥í›„ ë²„ì „ì—ì„œ ë¹›ì˜ ê°•ë„ì™€ í‘œë©´ì ì„ ëŠ˜ë¦¬ëŠ” ë“±ì˜ ê°œì„ ì„ ê³„íší•˜ê³  ìˆìŠµë‹ˆë‹¤.\n\nì´ í”„ë¡œì íŠ¸ì˜ ë¹„ìš©ì€ ì•½ 1000ìœ ë¡œë¡œ, ë„êµ¬ì™€ ë¶€í’ˆì„ í¬í•¨í•˜ë©°, ì£¼ìš” êµ¬ì„± ìš”ì†ŒëŠ” CNCë¡œ ì œì‘ëœ ë Œì¦ˆì™€ PCBì…ë‹ˆë‹¤.\n\nì €ìëŠ” ì¸ê³µ íƒœì–‘ê´‘ ë¨í”„ì˜ ì²« ë²ˆì§¸ ë²„ì „ì— ëŒ€í•´ ìë¶€ì‹¬ì„ ëŠë¼ë©°, ì´ ê²½í—˜ì„ í†µí•´ ì „ìê¸°ê¸°ì™€ ì œì¡°ì— ëŒ€í•œ ê·€ì¤‘í•œ ê¸°ìˆ ì„ ë°°ì› ë‹¤ê³  ë§í•©ë‹ˆë‹¤. ë˜í•œ ë””ìì¸ì„ ê°œì„ í•˜ê¸° ìœ„í•´ ë‘ ë²ˆì§¸ ë²„ì „ì„ ê°œë°œí•  ì˜í–¥ì„ í‘œí˜„í–ˆìŠµë‹ˆë‹¤.",
      "ja": "è‘—è€…ã¯ã€DIY Perksã®å‹•ç”»ã«è§¦ç™ºã•ã‚Œã¦ã€è‡ªå®…ã§äººå·¥å¤ªé™½å…‰ã‚’ä½œã‚‹çµŒé¨“ã‚’å…±æœ‰ã—ã¦ã„ã¾ã™ã€‚å½¼ã‚‰ã¯ã€å¤§ããªæ”¾ç‰©é¢åå°„é¡ã‚’ä½¿ã£ãŸãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆãªãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’è¨­è¨ˆã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã€è¤‡æ•°ã®LEDã‚’ä½¿ã£ãŸãƒ¬ãƒ³ã‚ºã®ã‚°ãƒªãƒƒãƒ‰ã‚’é–‹ç™ºã—ã¾ã—ãŸã€‚\n\nãƒ‡ã‚¶ã‚¤ãƒ³ã®ã‚³ãƒ³ã‚»ãƒ—ãƒˆã¨ã—ã¦ã€è‘—è€…ã¯å°ã•ãªãƒ¬ãƒ³ã‚ºã®ã‚°ãƒªãƒƒãƒ‰ã¨ä½å‡ºåŠ›ã®LEDã‚’çµ„ã¿åˆã‚ã›ã¦ã€å¾“æ¥ã®ãƒ‡ã‚¶ã‚¤ãƒ³ã«æ¯”ã¹ã¦ç†±ç®¡ç†ãŒå®¹æ˜“ã§ã€è¨­ç½®é¢ç©ãŒå°ã•ã„ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆãªå…‰æºã‚’ä½œæˆã—ã¾ã—ãŸã€‚\n\nã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’é€šã˜ã¦ã€è‘—è€…ã¯CADãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã€PCBè¨­è¨ˆã€å…‰å­¦ã«ã¤ã„ã¦å­¦ã³ã¾ã—ãŸã€‚å…·ä½“çš„ã«ã¯ã€build123dã‚„KiCadã€ã‚«ã‚¹ã‚¿ãƒ Pythonã‚³ãƒ¼ãƒ‰ã‚’ä½¿ã£ã¦ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è¡Œã„ã¾ã—ãŸã€‚\n\nå®Œæˆã—ãŸè£…ç½®ã¯ã€36å€‹ã®LEDã‚’æŒã¤ãƒ¬ãƒ³ã‚ºã‚¢ãƒ¬ã‚¤ã‚’ç‰¹å¾´ã¨ã—ã¦ãŠã‚Šã€å„LEDã¯é«˜ã„æ¼”è‰²è©•ä¾¡æ•°ï¼ˆCRIï¼‰ã®å…‰ã‚’ç”Ÿæˆã™ã‚‹ã‚ˆã†ã«è¨­è¨ˆã•ã‚Œã¦ã„ã¾ã™ã€‚ç›®æ¨™ã¯ã€å¤ªé™½ã®å¹³è¡Œå…‰ç·šã‚’æ¨¡å€£ã™ã‚‹ã“ã¨ã§ã—ãŸã€‚\n\nã„ãã¤ã‹ã®æˆåŠŸã‚’åã‚ãŸã‚‚ã®ã®ã€æ˜ã‚‹ã•ã¯æœŸå¾…ã‚ˆã‚Šã‚‚ä½ãã€ãƒ¬ãƒ³ã‚ºã®ã‚°ãƒªãƒƒãƒ‰ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒç›®ç«‹ã¤ã¨ã„ã†èª²é¡Œã‚‚ã‚ã‚Šã¾ã—ãŸã€‚è‘—è€…ã¯ã€å°†æ¥ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§å…‰ã®å¼·åº¦ã‚„è¡¨é¢ç©ã‚’å¢—ã‚„ã™ãªã©ã®æ”¹å–„ã‚’è¨ˆç”»ã—ã¦ã„ã¾ã™ã€‚\n\nãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ã‚³ã‚¹ãƒˆã¯ç´„1000ãƒ¦ãƒ¼ãƒ­ã§ã€å·¥å…·ã‚„éƒ¨å“ã‚’å«ã‚“ã§ã„ã¾ã™ã€‚ä¸»ãªéƒ¨å“ã¯CNCè£½é€ ã•ã‚ŒãŸãƒ¬ãƒ³ã‚ºã¨PCBã§ã™ã€‚\n\nå…¨ä½“ã¨ã—ã¦ã€è‘—è€…ã¯äººå·¥å¤ªé™½å…‰ãƒ©ãƒ³ãƒ—ã®åˆç‰ˆã«èª‡ã‚Šã‚’æŒã£ã¦ãŠã‚Šã€ã“ã®çµŒé¨“ã‚’é€šã˜ã¦é›»å­å·¥å­¦ã‚„è£½é€ ã«é–¢ã™ã‚‹è²´é‡ãªã‚¹ã‚­ãƒ«ã‚’å­¦ã‚“ã ã¨è¿°ã¹ã¦ã„ã¾ã™ã€‚ãƒ‡ã‚¶ã‚¤ãƒ³ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã«ã€æ¬¡ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®é–‹ç™ºã«ã‚‚èˆˆå‘³ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚"
    }
  },
  {
    "id": "551e20eaab8852f1",
    "title": {
      "en": "How Kerala got rich",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": "https://aeon.co/essays/how-did-kerala-go-from-poor-to-prosperous-among-indias-states",
    "score": 371,
    "by": "lordleft",
    "time": 1743179264,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "a8137c3c4854deab",
    "title": {
      "en": "Building a modern durable execution engine from first principles",
      "ko": "í˜„ëŒ€ì  ì‹¤í–‰ ì—”ì§„ êµ¬ì¶•í•˜ê¸°",
      "ja": "ç¾ä»£ã®å®Ÿè¡Œã‚¨ãƒ³ã‚¸ãƒ³æ§‹ç¯‰"
    },
    "type": "story",
    "url": "https://restate.dev/blog/building-a-modern-durable-execution-engine-from-first-principles/",
    "score": 90,
    "by": "whoiskatrin",
    "time": 1743083504,
    "content": "Building a modern Durable Execution Engine from First PrinciplesHow Restate works, Part 2Posted February 20, 2025 by Stephan Ewen, Ahmed Farghal, and Till Rohrmannâ€20min readWe dive into the architecture details of Restate, a Durable Execution engine we built from the ground up. Restate requires no database/log or other system, but implements a full stack that competes with the best logs in terms of durability and operations.This is the second article in our series on building a durable execution system from first principles. The first blog post in this series, Every System is a Log, looks at this from the application side, and shows how a unified log architecture results in a tremendous simplification of distributed coordination logic. This post discusses the details of how we built the log-based runtime for that paradigm.Modelling locking and database updates through an application log,taken from Every System is a LogTo build this runtime, we asked ourselves, what such a system would look like when designed from first principles? We built a precursor to this with Stateful Functions, and from all the lessons learned there, we arrived at a design with a self-contained complete stack, centered around a command log and event-processor, shipping as a single Rust binary. To get an idea of the user experience we arrived at, check the videos in the announcement post.This stands somewhat in contrast to the common wisdom â€œdonâ€™t build a new stateful system, just use Postgresâ€. But we saw a clear case to build a new stack, for multiple reasons: First, the interactions and access patterns are different enough from existing systems that we can offer both better performance and operational behavior, similar to why message queues exist, even though you can queue with a SQL table. Second, the architecture of event logs has made significant advancements in recent years, but the advanced implementations are exclusive to proprietary stacks and managed offerings - the open source logs and queues still follow architectures from the on-prem era. Third, we saw how a converged stack lets us provide a much better end-to-end developer experience, from first experiments on your laptop to multi-region production deployments.Recap: Server and Services #A Restate application stack consists of two components: Restate Server, which sits at a similar place in your stack as a message broker, and the application services, which are durable functions/handlers containing the application logic. The server receives invocation events, persists them, and pushes them to the services, similar to an event broker. The services run the code that corresponds to RPC- or event-handlers, workflows, activities, or actors. Services may run as processes, containers, or even serverless functions.But Restate doesnâ€™t just push invocations, it maintains a bidirectional connection with the executing service handler and lets the code perform durable actions as part of the invocation, including journaling steps, sending events to other handlers, accessing/modifying state, creating persistent futures (callbacks) and timers. The services use a thin SDK library which communicates the actions to the server - somewhat comparable to a KafkaConsumer or JDBC client, but more high-level. See Restateâ€™s examples for sample code and details.The server handles all coordination and durability for the invocation life cycle, journals, embedded K/V state, and manages failover, leader-election, and fencing. The serverâ€™s view on an invocation and its journal is the ground truth; the services follow the serverâ€™s view and function executions may be cancelled/reset/retried as needed.That approach makes the services completely stateless and simple to operate. They scale rapidly and run on serverless infrastructure like AWS Lambda, Cloudflare workers, etc.This characteristic also lets us build those SDKs in many languages fairly easily, including TypeScript, Java, Kotlin, Python, Go, and Rust.Clusters, Object Stores, and the Latency Gap #A distributed Restate deployment is a cluster of nodes that are connected to each other. Invocations and events can be sent to any node, and all nodes participate in the storage of events and dispatching of invocations to services/functions. Restate is active/active from a cluster-perspective, but has leader/follower roles at the granularity of individual partitions, similar to systems like Kafka or TiKV.Restate stores data using two mechanisms: New events (invocations, journal entries, state updates, â€¦) are persisted in an embedded replicated log (called Bifrost). From there, events move to state indexes in RocksDB, which are periodically snapshotted to an object store. So at any point in time, the majority of the data is durable in the object store (the nodes maintain a copy as cache) while a smaller part of the data is durable in the log replicated across the nodes.This is a form of storage tiering, though not the classical tiering like in modern logs. It is more similar to a database management system, where the write-ahead-log (WAL) would be replicated across nodes, while the table data files and indexes would be persisted on S3 (and cached on the nodes).Object store + latency gap #Architectures that keep most- or all - of their data on object stores have become popular for many reasons: Object stores are unbeatable in terms of combined scalability, durability, and cost (AWS S3 cites eleven 9s of durability, stores more than 100 trillion objects, and is cheaper than persistent disks). Plus, the storage exists disaggregated from compute nodes, making the nodes stateless (or owning little state), which is highly desirable for efficient operations.Object stores are also available in most on-prem setups weâ€™ve encountered. It was natural for us to design Restate such that object storage would be the primary durability for the majority of the data.The reason why Restate has additionally a replication layer that persists new events (rather than writing events straight to object storage) is to provide low latency. Pure object store approaches have latencies that average around 100ms to make data durable, with tail latencies being a multiple of that. While that is feasible for analytical systems (e.g., Apache Flink) and data pipelines (like WarpStream), such latencies can quickly become prohibitive for many applications.Restateâ€™s replication bridges the latency gap between the requirements of fast durable functions and the capabilities of object storage.Navigating the cloud latency-cost-disk triad #The setup described above is what we ship first, in Restate 1.2: a fast log replicated between Restate server nodes. However, Restate uses virtual log abstraction, to easily support other log implementations as well, without having to build a full consensus machinery each time. This is a defining feature of Restateâ€™s runtime implementation that weâ€™ll dive deeper into in the next article in this series. We are currently using that mechanism to build object-store support in the log as well, which is a powerful feature for bringing the amount of data persistent on nodes to very small amounts, even zero.There is no single best configuration for that setup - only a spectrum of trade-offs to pick from. In his Materialized View newsletter, Chris Riccomini describes it as a CAP-theorem-like choice:In our context (durable execution runtime), durability must be a given, but we have the additional dimension of how much replicated data is kept on the nodes. Restateâ€™s triad thus is: latency-cost-disk.â• Low latency, â• low cost, â–some data on disks: Quorum replication to nodes with async batch writes to S3.The nodes provide fast durability through replication and keep the data for anything between a few 100ms and minutes, before moving the events to object storage. Restate 1.2 can be seen as a variant with a long flush interval.â• Low latency, â– high cost, â• no data on disks: Quorum replication directly to S3 Express One Zone.Restateâ€™s replication mechanism deals only with ordering, quorum, and repairs upon loss of a zone, but doesnâ€™t keep data on the nodes (except caches).â– High latency, â• low cost, â• no data on disks: Synchronous batch writes to S3.Restateâ€™s replication mechanism isnâ€™t used.Naturally, there are nuances: direct replication has an even lower latency than S3 Express 1Z quorums. Synchronous batch writes to S3 can be cheaper than anything else, because that approach may avoid cross AZ bandwidth cost. Disks still exist as caches in all configurations. And there is the option of using quorum replication to S3 Express 1Z in different regions, to support multi-region deployments without relying on disks. But it shows that there is the spectrum of options, with which we aim to enable developers to use Restate in diverse setups across cloud and on-prem, while maintaining a simple dependency: just an object store.Restate 1.2 ships with all the virtual log infrastructure, and a low-latency replicated log implementation. We are currently working on the other configurations - if you are interested in being an early tester or design partner, please reach out to us.As a final thought, being able to adjust to different trade-offs also helps Restate and its users adapt to changing cloud pricing models. To quote another prolific dist. sys. writer:Partitioned Scale out #Restate follows the partitioned scale-out model: A cluster has a set of partitions, each with a log partition and an event processor instance. Partitions operate independently and allow the system to scale both across cores and nodes.Everything related to an invocation happens within a single partition: invocation, idempotency & deduplication, journal entries, state, promises/futures, avoiding the need to synchronize and coordinate with any other shards. The target partition for an invocation is determined by hashing the virtual object key, workflow ID, or idempotency key, if applicable - otherwise, the partition is freely chosen.In some cases, a function execution produces an event for another partition, for example RPC events or completions. In that case, events are still written to the local partition, and the server has an out-of-band exactly-once event shuffler to move events to the right target partition.The partitions are not exposed to applications (though you see them when using restatectl) - only keys are directly addressable (virtual object id, workflow id, idempotency key), to allow changing the number of partitions without losing consistency.From here on, we look only at what happens inside a single partition.Event Log and Processor #The work that Restate Server does inside one partition happens in two components: the distributed durable log (called Bifrost) and the processors. The log is the fast primary durability for events (e.g., make invocations, add journal entry, update state, create durable promise, â€¦), the processor acts on events (e.g., invokes handlers) and materializes their state. Log and processor are co-partitioned, meaning a partition processor connects to one log partition. They are independent, but frequently co-located in the same process.Compared to databases, you can think of Bifrost as the transaction WAL, and the processor as the query engine and table storage. Compared to stream processing, you can think of Restateâ€™s log as Kafka and the processor as a stream processing application (like KStreams or Flink).Log and processor form a tight loop: the processor continuously tails the log, and acts on the events (e.g., making invocation). That may produce more events (journal entries, state updates, â€¦), which are written to the log and again processed by the processor.Letâ€™s go through an example to illustrate this:A client invokes service handler processPayment with idempotency key K through Restate. The ingress enqueues the invocation to the log partition, as determined by hashing K.The leader Processor for the partition receives that event and checks its local idempotency key state. K is not contained there for processPayment. The processor atomically adds K to the state and transitions the invocation to running, then builds a connection to the target service endpoint, and pushes the invoke journal entry.The service streams back a step result event (ctx.run({...})) and the processor enqueues that journal entry event in the log. Being persistent in the log is the point when â€œthe step happenedâ€, meaning from there on it will always be recovered.When the processor receives the event from the log (that means no other processor has taken over leadership in the meantime) then it adds the event to the invocationâ€™s journal state and sends an ack to the service.Similar steps happen when the service sends a state update, a timer, an RPC event, or creates a durable promise. Events get always added to the log first, and once they are received by the processor they are acted upon (e.g., added to journal, routed as invocation to other service, etc.)Once the invocation completes, the Processor adds the result event to the log. Upon receiving that event, it sets the invocation state as complete and sends the result back to the client.When the function execution fails (e.g., crash, loss of connection, user-defined error), the processor dispatches a new invocation, attaching the full journal events from this invocation so far. To avoid split brain scenarios between services, the processor tracks invocation execution attempts (retries) and rejects events sent from an invocation if a newer attempt has started. This can be tracked with simple in-memory state, because invocations are sticky to partitions, and partitions have strong leaders.State storage #The processor stores all its non-transient state in an embedded RocksDB instance. Operations on that embedded store are very fast, but the state is lost when the node is lost. However, all state of the processor is deterministically derived from the durable log and can always be rebuilt from the log during recovery. To avoid arbitrarily long re-build phases, the RocksDB database is periodically snapshotted to the object store and the log is trimmed to the point of the snapshot. Processors can be restored by fetching the latest snapshot and attaching to the log at the event sequence number when the snapshot was taken.The implementation of the partition processor is a tight event loop in Rustâ€™s Tokio runtime. Partition Processors operate independently from each other and access exclusively local data structures (in memory, RocksDB, streams to ongoing invocations). The partition-local handling of invocations is easy in a log-first design, and would be much harder to achieve if we built this on a general purpose database.That property makes the design also both simple and fast: Committing an event (e.g., step / activity) means appending the event to the log (obtaining a write quorum). As soon as that happens, the event is pushed from the log leader in-memory to the attached processor and ack-ed to the handler/workflow. This takes a single network roundtrip for a replication quorum, and no distributed reads. The durability of RocksDB happens completely asynchronously in the background.Leaders and Followers #Both log and processors have one leader and optional followers. In the case of the log, followers increase durability for events through additional copies. In the case of processors, followers are hot standbys that have a copy of the state (deterministically derived from the log) and can quickly take over upon failure. Only the processor leader actually dispatches invocations for functions and workflows to the services, and only the leader writes snapshots to object store.High-level architecture and request flow.Control Plane, Data Plane, External Consensus #So far, everything we looked at was the data plane of the system: The log and the partition processor.Everything is coordinated by a control plane, which is responsible for failure detection, failover coordination, and re-configuration. The control plane stores metadata for the cluster (like configurations) and runs the cluster controller that handles partition placement and leader election.Control Plane and Data PlaneBecause Restate has one control plane for both log and processors, it can co-coordinate both, for example ensuring that the leader processor is always co-located with the log partition leader, to reduce network hops and optimize reading from local memory caches. In contrast, if we were to build this transparently on an external log like Kafka, this co-location would be harder to achieve. The benefits of this joint control plane show in many parts of the system and are one of the reasons Restate is simpler to set up, scale, and operate.Besides managing re-configurations and failover, the control plane also provides the external consensus for the data plane, allowing the data plane to operate more efficiently and with simpler properties than full consensus. Weâ€™ll go into the details of Restateâ€™s log implementation in the next blog post - for now, a useful high-level way to think about this is that the control plane moves the data plane from one steady configuration to another, whenever the previous configuration is no longer functional (a failure happened) or desired (e.g., re-balancing). This blog post from Jack Vanlightly gives a nice introduction to that concept.\nThe Control Plane reconfigures the Data Plane (Figure from â€œAn Introduction to Virtual Consensus in Delos â€œby Jack Vanlightly)Another benefit of this design is that it allows Restate to use a simpler/slower implementation of consensus on the control plane, because it is rarely invoked. Restate abstracts its consensus to just an atomic compare-and-swap (CAS) metadata operation, which the built-in metadata store backs with an implementation of the RAFT consensus algorithm. But this can be easily extended to plug in different storage systems, as long as they support atomic CAS.Failover & Reconfiguration #Though the control plane jointly coordinates log and processor reconfiguration, each has their own mechanisms to ensure consistency.A segmented log (Figure from â€œAn Introduction to Virtual Consensus in Delos â€œby Jack Vanlightly)Bifrostâ€™s (the logâ€™s) mechanism is based on a mix of Delos (Virtual Consensus) and LogDevice. From a high-level, bifrost is segmented and failover or reconfiguration seals the active segment and creates a new segment, possibly with a new leader and a different set of nodes that store replicas. To the outside and the partition processors, everything looks like a single contiguous log.When a partition processor fails, the control plane selects a new leader for that partition.The failover procedure relies on the external consensus provided by the control plane: New leaders obtain the next epoch in a strictly monotonous sequence (so newer leaders have higher epochs). The new leader appends a message to the log to signal their epoch is now active, and then simply starts appending events from its operations. The old leader (who might still be following the log) will receive that epoch bump message and step down at that exact point - it will keep materializing state (as a follower) but not dispatch invocations any more. The old leader also aborts ongoing function executions and lets the new leader recover those.Leader handover via messages in the logAny messages carrying lower epochs than the latest epoch-bumping message will be ignored, which filters messages that the old leader might have still been appending to the log before it found out that it was superseded by another leader. If the old leader was attempting to commit a journal entry, but the message was appended after the epoch-bump message, that commit cannot happen: The new leader will (or might have already) recover the process without that journal entry and execute and commit that step. This mechanism ensures that any step / activity result is committed exactly once. No split brain view is possible.This mechanism also automatically resolves concurrent competition for leadership - the highest epoch will win, and late events are consistently ignored.Converged Single Binary #Restate is architected as a set of individual components that communicate with each other and make no assumptions about the whereabouts of their peers. A Restate binary can run every component or a subset of them; a set of components is described by a role.The default configuration is the converged mode, where every binary runs every role. In that case, you get a distributed architecture in a single binary. You can start more instances of the binary to form clusters. This mode is easy to use and efficient, because it also lets different components communicate efficiently through in-memory channels and caches whenever possible (e.g., log to processor).The roles and components of RestateHowever, you can of course also run it as a disaggregated setup, where different sets of nodes run different roles. That lets you separate control plane from data plane and pick your best trade-offs in terms of cost/durability/availability for metadata and data. For example:Deploy three nodes with the admin role across three different regions, ensure application and consensus metadata are disaster proof.Deploy six nodes with the Log-Server role across three availability zones, making sure data is replicated to tolerate zone outages.Deploy Ingress and Worker roles in one availability zone to strictly co-locate them with zone-local services.Restateâ€™s architecture gives you a great developer experience from the start (launching a single binary on your laptop) all the way to sophisticated distributed deployments (disaggregated distributed setups).Some Performance Numbers #How fast can a system like this be? The answer is, we donâ€™t really know, we have plenty more optimization we can do. Our main focus for this release was durability, resilience, and operational tooling.But even before any deep performance optimization, the system already pushes some pretty cool numbers, both latency- and throughput wise. Below are numbers from Restate 1.2. We measure the throughput / latency of the server against mock functions and activities, to put maximum stress on the server.Latency #Restate aims to keep latencies low, despite giving strong guarantees on durability (replication) and consistency (strong consensus on locking keys, workflow ids, etc.).Below are the numbers for durable functions with an increasing number of intermediate durable steps, running on a 3-way replicated cluster. Under low load, things are generally fast and a single step has a median latency of 3ms. Under high load, steps still have a median latency of 10ms after the initial workflow setup. Tail latencies under low load are a bit higher than we like (possibly caused by some Tokio / RocksDB issues) and we believe we can get these down in the future.LoadIntermediate StepsLatencyp50p90p99Low (10 concurrent clients)05ms34ms54ms315ms42ms69ms931ms57ms93ms2761ms106ms155msHigh (1200 concurrent clients)028ms41ms58ms358ms76ms98ms9116ms138ms163ms27283ms320ms356msOne thing you can observe here is that Restate is built to make durable steps cheap. An initial function or workflow invocation needs to check whether the workflow ID, idempotency key, or object key already exists and whether it is under execution. But once an invocation has been made, adding steps is just the equivalent of a conditional append to the log.Throughput #We ran a workflow of 9 intermediate durable steps (totalling 11 actions, including invoke/result), using 1200 concurrent clients to submit workflows.Restate pushes 94,286 actions (steps) per second, equalling 8,571 full workflows each second. The system maintains a p50 of 116.36ms and a p99 of 163.33ms for the full workflow! The p50 per step is 10ms.The experiment ran on AWS c6id.8xlarge nodes, which are admittedly beefy, but also deliver a throughput that most companies will not ever reach or exceed in their transactional load. And, if they exceed that, Restate still scales to more nodes through more partitions.Up next: a fast, flexible, state-of-the-art log #We mentioned that we built our own implementation of a distributed replicated log (called Bifrost), because we didnâ€™t find any of the existing logs suitable in terms of latency (single roundtrip, quorum replication with external consensus), durability (active-active with flexible quorums), flexibility (segmented log that can be dynamically reconfigured).The next post in this series will dig into all the nitty gritty details of how we built that log. This log itself is a marvel of engineering and one of the reasons Restate is as powerful as it is. If you are into distributed systems, you will enjoy that one for sure!Try it out! #We hope you find this work as exciting as we do. If you want to try this out, the quickstart, helps to get you to your first demo app (and give us a star on GitHub).To get right into the distributed fun, check this guide to running a cluster locally.Let us know what you think or ask questions in our community on Discord or Slack and get more deep content like this from us on X, LinkedIn, Bluesky, or via email.Restate is also available as a fully managed cloud service, if all you want is to use it and let us operate it.restate\nrelease\narchitecture\ndeployment",
    "summary": {
      "en": "**Summary of \"Building a Modern Durable Execution Engine from First Principles: How Restate Works, Part 2\"**\n\nIn this article, the authors discuss the architecture of Restate, a newly developed Durable Execution Engine. Unlike traditional systems that rely on databases or logs, Restate is designed as a complete stack that offers high durability and performance. \n\nKey Points:\n\n1. **Purpose and Design**: Restate aims to simplify distributed systems by using a unified log architecture, which helps with coordination and performance. It is built from scratch, learning from previous projects like Stateful Functions.\n\n2. **Components**: The Restate application consists of a Restate Server (similar to a message broker) and application services that handle logic. The server manages event invocations, durability, and failover, while services can run in various environments.\n\n3. **Data Storage**: Restate uses a dual-storage mechanism with an embedded log (Bifrost) for immediate event durability and RocksDB for state management. Data is also periodically saved to an object store, balancing speed and cost.\n\n4. **Latency Management**: To reduce latency, Restate replicates events across nodes instead of directly writing to object storage, which can be slow.\n\n5. **Scalability**: The system can scale efficiently using a partitioned model where each partition has its own log and processor. This allows independent operation and minimizes the need for cross-partition synchronization.\n\n6. **Control Plane**: A control plane coordinates the systemâ€™s components, handling failovers and leader elections, and ensures optimal data flow between the log and processors.\n\n7. **Performance**: Early tests show Restate can handle high throughput and low latency, even under heavy loads, making it suitable for demanding applications.\n\n8. **Future Developments**: The authors plan to release more features, including a fast log implementation, and encourage community engagement for feedback and testing.\n\nRestate is positioned as a powerful tool for developers looking to build robust, scalable applications with a focus on durability and performance.",
      "ko": "ì´ ê¸€ì—ì„œëŠ” ìƒˆë¡­ê²Œ ê°œë°œëœ ë‚´êµ¬ì„± ì‹¤í–‰ ì—”ì§„ì¸ Restateì˜ ì•„í‚¤í…ì²˜ì— ëŒ€í•´ ì„¤ëª…í•©ë‹ˆë‹¤. ì „í†µì ì¸ ì‹œìŠ¤í…œì´ ë°ì´í„°ë² ì´ìŠ¤ë‚˜ ë¡œê·¸ì— ì˜ì¡´í•˜ëŠ” ê²ƒê³¼ ë‹¬ë¦¬, RestateëŠ” ë†’ì€ ë‚´êµ¬ì„±ê³¼ ì„±ëŠ¥ì„ ì œê³µí•˜ëŠ” ì™„ì „í•œ ìŠ¤íƒìœ¼ë¡œ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.\n\nRestateì˜ ëª©ì ì€ ë¶„ì‚° ì‹œìŠ¤í…œì„ ë‹¨ìˆœí™”í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ í†µí•© ë¡œê·¸ ì•„í‚¤í…ì²˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¡°ì •ê³¼ ì„±ëŠ¥ì„ ê°œì„ í•©ë‹ˆë‹¤. RestateëŠ” Stateful Functionsì™€ ê°™ì€ ì´ì „ í”„ë¡œì íŠ¸ì—ì„œ ë°°ìš´ ì ì„ ë°”íƒ•ìœ¼ë¡œ ì²˜ìŒë¶€í„° ë§Œë“¤ì–´ì¡ŒìŠµë‹ˆë‹¤.\n\nRestate ì• í”Œë¦¬ì¼€ì´ì…˜ì€ ë©”ì‹œì§€ ë¸Œë¡œì»¤ì™€ ìœ ì‚¬í•œ Restate ì„œë²„ì™€ ë…¼ë¦¬ë¥¼ ì²˜ë¦¬í•˜ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ ì„œë¹„ìŠ¤ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤. ì„œë²„ëŠ” ì´ë²¤íŠ¸ í˜¸ì¶œ, ë‚´êµ¬ì„±, ì¥ì•  ì¡°ì¹˜ë¥¼ ê´€ë¦¬í•˜ë©°, ì„œë¹„ìŠ¤ëŠ” ë‹¤ì–‘í•œ í™˜ê²½ì—ì„œ ì‹¤í–‰ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nRestateëŠ” ì¦‰ê°ì ì¸ ì´ë²¤íŠ¸ ë‚´êµ¬ì„±ì„ ìœ„í•´ ë‚´ì¥ ë¡œê·¸(Bifrost)ì™€ ìƒíƒœ ê´€ë¦¬ë¥¼ ìœ„í•œ RocksDBë¥¼ ì‚¬ìš©í•˜ëŠ” ì´ì¤‘ ì €ì¥ ë©”ì»¤ë‹ˆì¦˜ì„ ì±„íƒí•©ë‹ˆë‹¤. ë°ì´í„°ëŠ” ë˜í•œ ì£¼ê¸°ì ìœ¼ë¡œ ê°ì²´ ì €ì¥ì†Œì— ì €ì¥ë˜ì–´ ì†ë„ì™€ ë¹„ìš©ì˜ ê· í˜•ì„ ë§ì¶¥ë‹ˆë‹¤.\n\nì§€ì—° ì‹œê°„ì„ ì¤„ì´ê¸° ìœ„í•´ RestateëŠ” ê°ì²´ ì €ì¥ì†Œì— ì§ì ‘ ì“°ëŠ” ëŒ€ì‹  ë…¸ë“œ ê°„ì— ì´ë²¤íŠ¸ë¥¼ ë³µì œí•©ë‹ˆë‹¤. ì´ëŠ” ëŠë¦´ ìˆ˜ ìˆëŠ” ì§ì ‘ ì“°ê¸°ë¥¼ í”¼í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.\n\nì‹œìŠ¤í…œì€ ê° íŒŒí‹°ì…˜ì´ ìì²´ ë¡œê·¸ì™€ í”„ë¡œì„¸ì„œë¥¼ ê°€ì§€ëŠ” íŒŒí‹°ì…”ë‹ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ íš¨ìœ¨ì ìœ¼ë¡œ í™•ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë…ë¦½ì ìœ¼ë¡œ ìš´ì˜í•  ìˆ˜ ìˆìœ¼ë©°, íŒŒí‹°ì…˜ ê°„ ë™ê¸°í™”ì˜ í•„ìš”ì„±ì„ ìµœì†Œí™”í•©ë‹ˆë‹¤.\n\nì œì–´ í‰ë©´ì€ ì‹œìŠ¤í…œì˜ êµ¬ì„± ìš”ì†Œë¥¼ ì¡°ì •í•˜ê³  ì¥ì•  ì¡°ì¹˜ ë° ë¦¬ë” ì„ ì¶œì„ ì²˜ë¦¬í•˜ë©°, ë¡œê·¸ì™€ í”„ë¡œì„¸ì„œ ê°„ì˜ ìµœì ì˜ ë°ì´í„° íë¦„ì„ ë³´ì¥í•©ë‹ˆë‹¤.\n\nì´ˆê¸° í…ŒìŠ¤íŠ¸ ê²°ê³¼, RestateëŠ” ë†’ì€ ì²˜ë¦¬ëŸ‰ê³¼ ë‚®ì€ ì§€ì—° ì‹œê°„ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆì–´, ë¶€í•˜ê°€ ë§ì€ ìƒí™©ì—ì„œë„ ì í•©í•œ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤. ì´ëŠ” ìš”êµ¬ê°€ ë†’ì€ ì• í”Œë¦¬ì¼€ì´ì…˜ì— ì í•©í•©ë‹ˆë‹¤.\n\nì €ìë“¤ì€ ë¹ ë¥¸ ë¡œê·¸ êµ¬í˜„ì„ í¬í•¨í•œ ë” ë§ì€ ê¸°ëŠ¥ì„ ì¶œì‹œí•  ê³„íšì´ë©°, ì»¤ë®¤ë‹ˆí‹°ì˜ í”¼ë“œë°±ê³¼ í…ŒìŠ¤íŠ¸ ì°¸ì—¬ë¥¼ ì¥ë ¤í•˜ê³  ìˆìŠµë‹ˆë‹¤. RestateëŠ” ë‚´êµ¬ì„±ê³¼ ì„±ëŠ¥ì— ì¤‘ì ì„ ë‘ê³  ê°•ë ¥í•˜ê³  í™•ì¥ ê°€ëŠ¥í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ êµ¬ì¶•í•˜ë ¤ëŠ” ê°œë°œìë“¤ì—ê²Œ ìœ ìš©í•œ ë„êµ¬ë¡œ ìë¦¬ ì¡ê³  ìˆìŠµë‹ˆë‹¤.",
      "ja": "ã“ã®è¨˜äº‹ã§ã¯ã€è‘—è€…ãŸã¡ãŒæ–°ãŸã«é–‹ç™ºã•ã‚ŒãŸè€ä¹…æ€§ã®ã‚ã‚‹å®Ÿè¡Œã‚¨ãƒ³ã‚¸ãƒ³ã€ŒRestateã€ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«ã¤ã„ã¦èª¬æ˜ã—ã¦ã„ã¾ã™ã€‚å¾“æ¥ã®ã‚·ã‚¹ãƒ†ãƒ ãŒãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚„ãƒ­ã‚°ã«ä¾å­˜ã™ã‚‹ã®ã«å¯¾ã—ã€Restateã¯é«˜ã„è€ä¹…æ€§ã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’æä¾›ã™ã‚‹å®Œå…¨ãªã‚¹ã‚¿ãƒƒã‚¯ã¨ã—ã¦è¨­è¨ˆã•ã‚Œã¦ã„ã¾ã™ã€‚\n\nRestateã®ç›®çš„ã¯ã€çµ±ä¸€ã•ã‚ŒãŸãƒ­ã‚°ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§åˆ†æ•£ã‚·ã‚¹ãƒ†ãƒ ã‚’ç°¡ç´ åŒ–ã—ã€èª¿æ•´ã‚„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã§ã™ã€‚ã“ã‚Œã¯ã€Stateful Functionsã®ã‚ˆã†ãªéå»ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‹ã‚‰å­¦ã³ãªãŒã‚‰ã€ä¸€ã‹ã‚‰æ§‹ç¯‰ã•ã‚Œã¦ã„ã¾ã™ã€‚\n\nRestateã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯ã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ–ãƒ­ãƒ¼ã‚«ãƒ¼ã«ä¼¼ãŸRestateã‚µãƒ¼ãƒãƒ¼ã¨ã€ãƒ­ã‚¸ãƒƒã‚¯ã‚’å‡¦ç†ã™ã‚‹ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚µãƒ¼ãƒ“ã‚¹ã§æ§‹æˆã•ã‚Œã¦ã„ã¾ã™ã€‚ã‚µãƒ¼ãƒãƒ¼ã¯ã‚¤ãƒ™ãƒ³ãƒˆã®å‘¼ã³å‡ºã—ã€è€ä¹…æ€§ã€ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ã‚’ç®¡ç†ã—ã€ã‚µãƒ¼ãƒ“ã‚¹ã¯ã•ã¾ã–ã¾ãªç’°å¢ƒã§å®Ÿè¡Œã§ãã¾ã™ã€‚\n\nãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã«ã¯ã€å³æ™‚ã®ã‚¤ãƒ™ãƒ³ãƒˆè€ä¹…æ€§ã®ãŸã‚ã®åŸ‹ã‚è¾¼ã¿ãƒ­ã‚°ï¼ˆBifrostï¼‰ã¨ã€çŠ¶æ…‹ç®¡ç†ã®ãŸã‚ã®RocksDBã‚’ä½¿ç”¨ã—ãŸäºŒé‡ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ãŒæ¡ç”¨ã•ã‚Œã¦ã„ã¾ã™ã€‚ã¾ãŸã€ãƒ‡ãƒ¼ã‚¿ã¯å®šæœŸçš„ã«ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚¹ãƒˆã‚¢ã«ä¿å­˜ã•ã‚Œã€é€Ÿåº¦ã¨ã‚³ã‚¹ãƒˆã®ãƒãƒ©ãƒ³ã‚¹ãŒå–ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚\n\nãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ç®¡ç†ã®ãŸã‚ã«ã€Restateã¯ã‚¤ãƒ™ãƒ³ãƒˆã‚’ãƒãƒ¼ãƒ‰é–“ã§è¤‡è£½ã—ã€ç›´æ¥ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã«æ›¸ãè¾¼ã‚€ã®ã§ã¯ãªãã€é…å»¶ã‚’æ¸›ã‚‰ã™å·¥å¤«ãŒã•ã‚Œã¦ã„ã¾ã™ã€‚\n\nã‚·ã‚¹ãƒ†ãƒ ã¯ã€å„ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³ãŒç‹¬è‡ªã®ãƒ­ã‚°ã¨ãƒ—ãƒ­ã‚»ãƒƒã‚µã‚’æŒã¤ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§åŠ¹ç‡çš„ã«ã‚¹ã‚±ãƒ¼ãƒ«ã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ç‹¬ç«‹ã—ãŸæ“ä½œãŒå¯èƒ½ã«ãªã‚Šã€ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³é–“ã®åŒæœŸã®å¿…è¦æ€§ãŒæœ€å°é™ã«æŠ‘ãˆã‚‰ã‚Œã¾ã™ã€‚\n\nã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ãƒ—ãƒ¬ãƒ¼ãƒ³ã¯ã€ã‚·ã‚¹ãƒ†ãƒ ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’èª¿æ•´ã—ã€ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ã‚„ãƒªãƒ¼ãƒ€ãƒ¼é¸å‡ºã‚’å‡¦ç†ã—ã€ãƒ­ã‚°ã¨ãƒ—ãƒ­ã‚»ãƒƒã‚µé–“ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼ã‚’æœ€é©åŒ–ã—ã¾ã™ã€‚\n\nåˆæœŸã®ãƒ†ã‚¹ãƒˆã§ã¯ã€Restateã¯é«˜ã„ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã¨ä½ã„ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ã‚’ç¶­æŒã§ãã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ãŠã‚Šã€é‡ã„è² è·ã®ä¸‹ã§ã‚‚é©åˆ‡ã«æ©Ÿèƒ½ã™ã‚‹ãŸã‚ã€è¦æ±‚ã®å³ã—ã„ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«é©ã—ã¦ã„ã¾ã™ã€‚\n\nè‘—è€…ãŸã¡ã¯ã€è¿…é€Ÿãªãƒ­ã‚°å®Ÿè£…ã‚’å«ã‚€ã•ã‚‰ãªã‚‹æ©Ÿèƒ½ã‚’ãƒªãƒªãƒ¼ã‚¹ã™ã‚‹è¨ˆç”»ã‚’ç«‹ã¦ã¦ãŠã‚Šã€ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã‹ã‚‰ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚„ãƒ†ã‚¹ãƒˆã¸ã®å‚åŠ ã‚’ä¿ƒã—ã¦ã„ã¾ã™ã€‚\n\nRestateã¯ã€è€ä¹…æ€§ã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«é‡ç‚¹ã‚’ç½®ã„ãŸå …ç‰¢ã§ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ§‹ç¯‰ã—ãŸã„é–‹ç™ºè€…ã«ã¨ã£ã¦ã€å¼·åŠ›ãªãƒ„ãƒ¼ãƒ«ã¨ã—ã¦ä½ç½®ä»˜ã‘ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚"
    }
  },
  {
    "id": "4abec88ae668e4a4",
    "title": {
      "en": "Madison Square Garden's surveillance banned this fan over his T-shirt design",
      "ko": "íŒ¬ì˜ í‹°ì…”ì¸ ë¡œ ê°ì‹œ ê¸ˆì§€!",
      "ja": "Tã‚·ãƒ£ãƒ„ã§è¿½æ”¾ï¼"
    },
    "type": "story",
    "url": "https://www.theverge.com/news/637228/madison-square-garden-james-dolan-facial-recognition-fan-ban",
    "score": 200,
    "by": "helloworld",
    "time": 1743206895,
    "content": "NewsMadison Square Gardenâ€™s surveillance system banned this fan over his T-shirt designAnd he didnâ€™t even wear it to the venue.And he didnâ€™t even wear it to the venue.by  Mia SatoUpdated Mar 29, 2025, 2:10 AM GMT+9LinkFacebookThreadsImage: Getty ImagesMia Sato is platforms and communities reporter with five years of experience covering the companies that shape technology and the people who use their tools.A concert on Monday night at New Yorkâ€™s Radio City Music Hall was a special occasion for Frank Miller: his parentsâ€™ wedding anniversary. He didnâ€™t end up seeing the show â€” and before he could even get past security, he was informed that he was in fact banned for life from the venue and all other properties owned by Madison Square Garden (MSG).After scanning his ticket and promptly being pulled aside by security, Miller was told by staff that he was barred from the MSG properties for an incident at the Garden in 2021. But Miller says he hasnâ€™t been to the venue in nearly two decades.â€œThey hand me a piece of paper letting me know that Iâ€™ve been added to a ban list,â€ Miller says. â€œThereâ€™s a trespass notice if I ever show up on any MSG property ever again,â€ which includes venues like Radio City, the Beacon Theatre, the Sphere, and the Chicago Theatre.He was baffled at first. Then it dawned on him: this was probably about a T-shirt he designed years ago. MSG Entertainment wonâ€™t say what happened with Miller or how he was picked out of the crowd, but he suspects he was identified via controversial facial recognition systems that the company deploys at its venues.In 2017, 1990s New York Knicks star Charles Oakley was forcibly removed from his seat near Knicks owner and Madison Square Garden CEO James Dolan. The high-profile incident later spiraled into an ongoing legal battle. For Miller, Oakley was an â€œintegralâ€ part of the â€™90s Knicks, he says. With his background in graphic design, he made a shirt in the style of the old team logo that read, â€œBan Dolanâ€ â€” a reference to the infamous scuffle.A few years later, in 2021, a friend of Millerâ€™s wore a Ban Dolan shirt to a Knicks game and was kicked out and banned from future events. That incident spawned ESPN segments and news articles and validated what many fans saw as a pettiness on Dolan and MSGâ€™s part for going after individual fans who criticized team ownership.But this week, Miller wasnâ€™t wearing a Ban Dolan shirt; he wasnâ€™t even at a Knicks game. His friend who was kicked out for the shirt tagged him in social media posts as the designer when it happened, but Miller, who lives in Seattle, hadnâ€™t attended an event in New York in years.MSG Entertainment advises event goers that theyâ€™ll be subject to facial recognition at its venues. Photo: Chris Welch / The VergeMiller says that after he scanned his digital ticket, but before he went through security, a person working at Radio City stopped the line, pulled him aside, and asked him for his ID to verify who he was. They then walked him to another entrance of the building, where five or more staff members stood with him as he was told he was not allowed to return.Heâ€™s not sure how exactly MSG connected him to the shirt or a 2021 incident during an event he wasnâ€™t at. Miller told The Verge that until the concert, he had never actually purchased tickets to MSG events â€” they were either gifts from other people, or he got them through work.â€œIâ€™ve been reading articles about this facial recognition stuff that Dolan [and] MSG properties use, but I hadnâ€™t been in or around the Garden outside of Penn Station to take New Jersey Transit [to] Newark Airport in almost 20 years now,â€ Miller says. A friend who was present made sure his parents enjoyed the show while Miller hung out at a bar nearby. He did not get a refund for his ticket, he says.â€œI just found it comical, until I was told that my mom was crying [in the lobby],â€ Miller says of the experience. â€œI was like, â€˜Oh man, I ruined their anniversary with my shit talk on the internet. Memes are powerful, and so is the surveillance state.â€ Miller and his parents also had tickets to a Knicks game the following night; his parents went without him, with a family friend in his place. Miller dropped his parents off from across the street.MSG Entertainment did not respond to The Vergeâ€™s questions about whether facial recognition was used to identify Miller.â€œFrank Miller Jr. made threats against an MSG executive on social media and produced and sold merchandise that was offensive in nature,â€ Mikyl Cordova, executive vice president of communications and marketing for the company, said in an emailed statement. â€œHis behavior was disrespectful and disruptive and in violation of our code of conduct.â€Keeping close watch on patrons is nothing new for MSG. In 2022, a New Jersey attorney was denied entry to Radio City Music Hall during a Girl Scout troop trip. Her infraction was being on an â€œattorney exclusion listâ€ full of people who work at firms that are suing MSG. The attorney was identified using facial recognition technology at the venue.Miller says he was told at Radio City that he could appeal the ban if he wanted to but said itâ€™s not a priority for him. He hopes his experience can help others who find themselves in a similar situation, where theyâ€™re unexpectedly denied entry at an expensive event based on data about them that has been collected by the company.â€œItâ€™s something that we all have to be aware of â€” the panopticon,â€ Miller says. â€œWeâ€™re [being] surveilled at all times, and itâ€™s always framed as a safety thing, when rarely is that the case. Itâ€™s more of a deterrent and a fear tactic to try to keep people in line.â€Update March 28th: Added comment from MSG Entertainment spokesperson Mikyl Cordova. Clarified to reflect that Frank Miller said he had not been to an event at MSG venues in nearly 20 years.See More: CreatorsCultureEntertainmentNewsSecuritySportsTechMost PopularMost PopularGoogle discontinues Nest Protect smoke alarm and Nest x Yale door lockKing Arthur wants to automate your sourdough starterWindows 11 is closing a loophole that let you skip making a Microsoft accountMadison Square Gardenâ€™s surveillance system banned this fan over his T-shirt designHelldivers 2 is locking out players who use older CPUsInstallerA weekly newsletter by David Pierce designed to tell you everything you need to download, watch, read, listen to, and explore that fits in The Vergeâ€™s universe.Email (required)Sign UpBy submitting your email, you agree to our Terms and Privacy Notice. This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply.Advertiser Content FromThis is the title for the native ad",
    "summary": {
      "en": "Frank Miller was banned for life from Madison Square Garden (MSG) and its venues without even attending a concert. He was informed of the ban when he tried to enter Radio City Music Hall for his parents' anniversary. The ban is linked to a T-shirt he designed years ago that criticized MSG CEO James Dolan, which a friend wore to a Knicks game in 2021, resulting in his ban.\n\nMiller suspects he was identified through MSG's facial recognition technology. He hadnâ€™t been to MSG venues in nearly 20 years and was surprised by the ban. His experience highlights concerns about surveillance and its use against fans. Although he can appeal the ban, he finds it not a priority, emphasizing the need for awareness about surveillance practices.",
      "ko": "í”„ë­í¬ ë°€ëŸ¬ëŠ” ì½˜ì„œíŠ¸ì— ì°¸ì„í•˜ì§€ë„ ì•Šì€ ì±„ ë§¤ë””ìŠ¨ ìŠ¤í€˜ì–´ ê°€ë“ ê³¼ ê·¸ ì†Œì† ì¥ì†Œì—ì„œ í‰ìƒ ì¶œì… ê¸ˆì§€ë¥¼ ë‹¹í–ˆë‹¤. ê·¸ëŠ” ë¶€ëª¨ë‹˜ì˜ ê¸°ë…ì¼ì„ ë§ì•„ ë¼ë””ì˜¤ ì‹œí‹° ë®¤ì§ í™€ì— ë“¤ì–´ê°€ë ¤ë‹¤ ê¸ˆì§€ í†µì§€ë¥¼ ë°›ì•˜ë‹¤. ì´ ê¸ˆì§€ëŠ” ê·¸ê°€ ëª‡ ë…„ ì „ ë””ìì¸í•œ í‹°ì…”ì¸ ì™€ ê´€ë ¨ì´ ìˆë‹¤. ì´ í‹°ì…”ì¸ ëŠ” MSG CEO ì œì„ìŠ¤ ëŒë€ì„ ë¹„íŒí•˜ëŠ” ë‚´ìš©ì´ì—ˆê³ , ê·¸ì˜ ì¹œêµ¬ê°€ 2021ë…„ ë‹‰ìŠ¤ ê²½ê¸°ì—ì„œ ì´ë¥¼ ì…ê³  ê°”ë‹¤ê°€ ë°€ëŸ¬ê°€ ê¸ˆì§€ë‹¹í•˜ëŠ” ê²°ê³¼ë¥¼ ì´ˆë˜í–ˆë‹¤.\n\në°€ëŸ¬ëŠ” MSGì˜ ì–¼êµ´ ì¸ì‹ ê¸°ìˆ ì„ í†µí•´ ìì‹ ì´ ì‹ë³„ëœ ê²ƒ ê°™ë‹¤ê³  ì˜ì‹¬í•˜ê³  ìˆë‹¤. ê·¸ëŠ” ê±°ì˜ 20ë…„ ë™ì•ˆ MSG ì†Œì† ì¥ì†Œì— ê°€ì§€ ì•Šì•˜ê¸° ë•Œë¬¸ì— ê¸ˆì§€ í†µì§€ì— ë†€ëë‹¤. ê·¸ì˜ ê²½í—˜ì€ íŒ¬ë“¤ì— ëŒ€í•œ ê°ì‹œì™€ ê·¸ ì‚¬ìš©ì— ëŒ€í•œ ìš°ë ¤ë¥¼ ë“œëŸ¬ë‚¸ë‹¤. ê·¸ëŠ” ê¸ˆì§€ì— ëŒ€í•´ í•­ì†Œí•  ìˆ˜ ìˆì§€ë§Œ, ì´ë¥¼ ìš°ì„ ì‚¬í•­ìœ¼ë¡œ ë‘ì§€ ì•Šìœ¼ë©° ê°ì‹œ ê´€í–‰ì— ëŒ€í•œ ì¸ì‹ì˜ í•„ìš”ì„±ì„ ê°•ì¡°í•˜ê³  ìˆë‹¤.",
      "ja": "ãƒ•ãƒ©ãƒ³ã‚¯ãƒ»ãƒŸãƒ©ãƒ¼ã¯ã€ãƒãƒ‡ã‚£ã‚½ãƒ³ãƒ»ã‚¹ã‚¯ã‚¨ã‚¢ãƒ»ã‚¬ãƒ¼ãƒ‡ãƒ³ï¼ˆMSGï¼‰ãŠã‚ˆã³ãã®é–¢é€£æ–½è¨­ã‹ã‚‰ç”Ÿæ¶¯ã«ã‚ãŸã‚‹å…¥å ´ç¦æ­¢ã‚’å—ã‘ã¾ã—ãŸãŒã€ã‚³ãƒ³ã‚µãƒ¼ãƒˆã«ã¯ä¸€åº¦ã‚‚å‚åŠ ã—ã¦ã„ã¾ã›ã‚“ã§ã—ãŸã€‚å½¼ã¯ä¸¡è¦ªã®è¨˜å¿µæ—¥ã‚’ç¥ã†ãŸã‚ã«ãƒ©ã‚¸ã‚ªã‚·ãƒ†ã‚£ãƒ»ãƒŸãƒ¥ãƒ¼ã‚¸ãƒƒã‚¯ãƒ›ãƒ¼ãƒ«ã«å…¥ã‚ã†ã¨ã—ãŸéš›ã«ã€ã“ã®ç¦æ­¢æªç½®ã‚’çŸ¥ã‚‰ã•ã‚Œã¾ã—ãŸã€‚ã“ã®ç¦æ­¢ã¯ã€å½¼ãŒæ•°å¹´å‰ã«ãƒ‡ã‚¶ã‚¤ãƒ³ã—ãŸTã‚·ãƒ£ãƒ„ã«é–¢é€£ã—ã¦ã„ã¾ã™ã€‚ã“ã®Tã‚·ãƒ£ãƒ„ã¯MSGã®CEOã§ã‚ã‚‹ã‚¸ã‚§ãƒ¼ãƒ ã‚ºãƒ»ãƒ‰ãƒ©ãƒ³ã‚’æ‰¹åˆ¤ã™ã‚‹å†…å®¹ã§ã€å‹äººãŒ2021å¹´ã«ãƒ‹ãƒ¥ãƒ¼ãƒ¨ãƒ¼ã‚¯ãƒ»ãƒ‹ãƒƒã‚¯ã‚¹ã®è©¦åˆã§ç€ç”¨ã—ãŸã“ã¨ãŒåŸå› ã§ã€ãƒŸãƒ©ãƒ¼ã¯å…¥å ´ç¦æ­¢ã¨ãªã‚Šã¾ã—ãŸã€‚\n\nãƒŸãƒ©ãƒ¼ã¯ã€MSGã®é¡”èªè­˜æŠ€è¡“ã«ã‚ˆã£ã¦è‡ªåˆ†ãŒç‰¹å®šã•ã‚ŒãŸã®ã§ã¯ãªã„ã‹ã¨ç–‘ã£ã¦ã„ã¾ã™ã€‚å½¼ã¯ç´„20å¹´ã¶ã‚Šã«MSGã®æ–½è¨­ã«è¡Œã“ã†ã¨ã—ãŸãŸã‚ã€ã“ã®ç¦æ­¢æªç½®ã«ã¯é©šã„ã¦ã„ã¾ã™ã€‚å½¼ã®ä½“é¨“ã¯ã€ãƒ•ã‚¡ãƒ³ã«å¯¾ã™ã‚‹ç›£è¦–ã®æ‡¸å¿µã‚’æµ®ãå½«ã‚Šã«ã—ã¦ã„ã¾ã™ã€‚ç¦æ­¢ã«å¯¾ã—ã¦ç•°è­°ã‚’ç”³ã—ç«‹ã¦ã‚‹ã“ã¨ã¯å¯èƒ½ã§ã™ãŒã€å½¼ã¯ãã‚Œã‚’å„ªå…ˆäº‹é …ã¨ã¯è€ƒãˆã¦ãŠã‚‰ãšã€ç›£è¦–ã®å®Ÿæ…‹ã«ã¤ã„ã¦ã®èªè­˜ã‚’é«˜ã‚ã‚‹å¿…è¦ãŒã‚ã‚‹ã¨å¼·èª¿ã—ã¦ã„ã¾ã™ã€‚"
    }
  },
  {
    "id": "4ecf757c0bc474ad",
    "title": {
      "en": "How I Choose What to Work On (2023)",
      "ko": "ë‚´ ì¼ì˜ ì„ íƒë²•",
      "ja": "ä»•äº‹ã®é¸ã³æ–¹ (2023)"
    },
    "type": "story",
    "url": "https://tynan.com/workonwhat/",
    "score": 109,
    "by": "freemh",
    "time": 1742903659,
    "content": "Comments\n\n\t\t11 responses to â€œHow I Choose What to Work Onâ€\n\n\t\t\t\t\tAdam Ruggle\n\n\t\t\t\t\t\tOctober 15, 2023\n\n\t\t\t\t\tThanks Tynan, I appreciate hearing more about your mindset and hope you enjoy the extended cruise.\n\n\t\t\t\t\tReply\n\n\t\t\t\t\tAndrew\n\n\t\t\t\t\t\tOctober 18, 2023\n\n\t\t\t\t\tTynan, I appreciate this article as well and getting into your mind set about what you work on. How do you choose what is â€œworthâ€ the money to trade money for whether it is autonomy, quality of life or other things?\n\n\t\t\t\t\tReply\n\n\t\t\t\t\tGavin\n\n\t\t\t\t\t\tOctober 18, 2023\n\n\t\t\t\t\tMore mindset posts would be appreciated. I was reading a Scott Young (or possibly Cal Newport) article about goal setting, and how he broke it down for a complete beginner was interesting. Good goal setters have such discipline that itâ€™s easy to dismiss the advice to â€˜just do itâ€™, because that is what they habitually do (as do their friends and social group).\nI wondered if there were any habits or mindset that you have, that when you meet people outside your social circle, they struggle to comprehend something that you think is normal. I know this is a difficult thing to answer, and youâ€™ve briefly tocuhed on it before in your podcast and others articles (such as you not buying into advertising). Cheers, Gavin.\n\n\t\t\t\t\tReply\n\n\t\t\t\t\tAdam\n\n\t\t\t\t\t\tOctober 19, 2023\n\n\t\t\t\t\tIâ€™d be interested to get an update to this post: https://tynan.com/negative/ considering the current landscape of interest rates (IBKR margin rates are now 7% or more)\n\n\t\t\t\t\tReply\n\n\t\t\t\t\tTynan\n\n\t\t\t\t\t\tOctober 27, 2023\n\n\t\t\t\t\tMight write one, but a quick update: I no longer use margin heavily, except as a buffer against overdrawing my checking account, which allows me to keep more of my money invested. Itâ€™s just not right for this high-interest climate. My investments are still the same, though.\n\n\t\t\t\t\tReply\n\n\t\t\t\t\tJR\n\n\t\t\t\t\t\tOctober 20, 2023\n\n\t\t\t\t\tThis is where you have contributed a lot of value to my life and Iâ€™m sure the lives of many others â€“ by living and spreading this mindset and a comfort with making unconventional life choices based on certain core principles. You have been an inspiration for many and a trailblazer. That is true â€successâ€.\n\n\t\t\t\t\tReply\n\n\t\t\t\t\tMads Phikamphon\n\n\t\t\t\t\t\tOctober 23, 2023\n\n\t\t\t\t\tSince you are asking for questions, I would love to hear more about Cruise Sheet. Especially how you have grown/done marketing for Cruise Sheet (I have a site for finding model trains and itâ€™s suffering from me loving programming far more than marketing).\nThanks,\nMads\n\n\t\t\t\t\tReply\n\n\t\t\t\t\tMarc\n\n\t\t\t\t\t\tNovember 13, 2023\n\n\t\t\t\t\tGreat post!\n\n\t\t\t\t\tReply\n\n\t\t\t\t\tAlex\n\n\t\t\t\t\t\tNovember 24, 2023\n\n\t\t\t\t\tNew Kit list ?\n\n\t\t\t\t\tReply\n\n\t\t\t\t\tMiguel Marcos Martinez\n\n\t\t\t\t\t\tDecember 8, 2023\n\n\t\t\t\t\tKevin Kelly nailed it when I heard him say something like â€œThe only productive way to answer what should I do now is to answer the question â€˜who should I becomeâ€™? Succinct and meaningful.\n\n\t\t\t\t\tReply\n\n\t\t\t\t\tæˆ‘å¦‚ä½•é€‰æ‹©è¦å¹²ä»€ä¹ˆ â€“ åæ‰§çš„ç å†œ\n\n\t\t\t\t\t\tMarch 25, 2025\n\n\t\t\t\t\t[â€¦] è¯¦æƒ…å‚è€ƒ [â€¦]\n\n\t\t\t\t\tReply\n\n\t\tLeave a Reply Cancel replyYour email address will not be published. Required fields are marked *Comment * Name *\nEmail *\nWebsite\n Save my name, email, and website in this browser for the next time I comment.\n\nÎ”document.getElementById( \"ak_js_1\" ).setAttribute( \"value\", ( new Date() ).getTime() );",
    "summary": {
      "en": "The text discusses responses to an article by Tynan about his decision-making process for choosing what projects to work on. Key points include:\n\n1. **Appreciation for Insight**: Readers express gratitude for Tynan's insights into his mindset and decision-making.\n2. **Value of Choices**: One reader asks how Tynan determines what is worth trading for, such as autonomy or quality of life.\n3. **Desire for More Mindset Content**: Another reader wishes for more posts on mindset, especially about goal setting and habits that differ from mainstream thinking.\n4. **Investment Strategy Update**: Tynan provides a brief update on his investment strategies, stating he now uses margin less due to high-interest rates.\n5. **Inspiration**: A reader praises Tynan for inspiring others through his unconventional life choices.\n6. **Interest in Marketing**: Another reader seeks advice on marketing for their project, expressing a preference for programming over marketing.\n\nOverall, the discussion centers around personal growth, investment strategies, and the value of unconventional approaches.",
      "ko": "ë…ìë“¤ì€ íƒ€ì´ë„Œì˜ ì˜ì‚¬ê²°ì • ê³¼ì •ì— ëŒ€í•œ í†µì°°ë ¥ì— ê°ì‚¬ì˜ ëœ»ì„ ì „í–ˆìŠµë‹ˆë‹¤. í•œ ë…ìëŠ” íƒ€ì´ë„Œì´ ììœ¨ì„±ì´ë‚˜ ì‚¶ì˜ ì§ˆê³¼ ê°™ì€ ê²ƒë“¤ ì¤‘ì—ì„œ ë¬´ì—‡ì„ ì„ íƒí•  ê°€ì¹˜ê°€ ìˆëŠ”ì§€ ì–´ë–»ê²Œ íŒë‹¨í•˜ëŠ”ì§€ ê¶ê¸ˆí•´í–ˆìŠµë‹ˆë‹¤. ë˜ ë‹¤ë¥¸ ë…ìëŠ” ëª©í‘œ ì„¤ì •ê³¼ ì£¼ë¥˜ ì‚¬ê³ ì™€ ë‹¤ë¥¸ ìŠµê´€ì— ëŒ€í•œ ë§ˆìŒê°€ì§ì— ê´€í•œ ê¸€ì„ ë” ë§ì´ ì½ê³  ì‹¶ë‹¤ê³  ë°í˜”ìŠµë‹ˆë‹¤.\n\níƒ€ì´ë„Œì€ ìì‹ ì˜ íˆ¬ì ì „ëµì— ëŒ€í•œ ê°„ë‹¨í•œ ì—…ë°ì´íŠ¸ë¥¼ ì œê³µí•˜ë©°, í˜„ì¬ ë†’ì€ ì´ììœ¨ë¡œ ì¸í•´ ë§ˆì§„ì„ ëœ ì‚¬ìš©í•˜ê³  ìˆë‹¤ê³  ì–¸ê¸‰í–ˆìŠµë‹ˆë‹¤. í•œ ë…ìëŠ” íƒ€ì´ë„Œì´ ë¹„ì „í†µì ì¸ ì‚¶ì˜ ì„ íƒì„ í†µí•´ ë‹¤ë¥¸ ì‚¬ëŒë“¤ì—ê²Œ ì˜ê°ì„ ì£¼ê³  ìˆë‹¤ê³  ì¹­ì°¬í–ˆìŠµë‹ˆë‹¤. ë˜ ë‹¤ë¥¸ ë…ìëŠ” ìì‹ ì˜ í”„ë¡œì íŠ¸ì— ëŒ€í•œ ë§ˆì¼€íŒ… ì¡°ì–¸ì„ ìš”ì²­í•˜ë©°, ë§ˆì¼€íŒ…ë³´ë‹¤ í”„ë¡œê·¸ë˜ë°ì— ë” ê´€ì‹¬ì´ ìˆë‹¤ê³  ì „í–ˆìŠµë‹ˆë‹¤.\n\nì „ì²´ì ìœ¼ë¡œ ì´ ë…¼ì˜ëŠ” ê°œì¸ ì„±ì¥, íˆ¬ì ì „ëµ, ë¹„ì „í†µì ì¸ ì ‘ê·¼ ë°©ì‹ì˜ ê°€ì¹˜ì— ì´ˆì ì„ ë§ì¶”ê³  ìˆìŠµë‹ˆë‹¤.",
      "ja": "ãƒ†ã‚­ã‚¹ãƒˆã¯ã€TynanãŒã©ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«å–ã‚Šçµ„ã‚€ã‹ã‚’æ±ºã‚ã‚‹éš›ã®æ€è€ƒéç¨‹ã«ã¤ã„ã¦ã®è¨˜äº‹ã«å¯¾ã™ã‚‹åå¿œã‚’ç´¹ä»‹ã—ã¦ã„ã¾ã™ã€‚ä¸»ãªãƒã‚¤ãƒ³ãƒˆã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ã€‚\n\nèª­è€…ã¯ã€Tynanã®è€ƒãˆæ–¹ã‚„æ„æ€æ±ºå®šã«é–¢ã™ã‚‹æ´å¯Ÿã«æ„Ÿè¬ã®æ„ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚ä¸€äººã®èª­è€…ã¯ã€TynanãŒè‡ªåˆ†ã«ã¨ã£ã¦ä½•ãŒä¾¡å€¤ãŒã‚ã‚‹ã‹ã€ä¾‹ãˆã°è‡ªå¾‹æ€§ã‚„ç”Ÿæ´»ã®è³ªã‚’ã©ã®ã‚ˆã†ã«åˆ¤æ–­ã—ã¦ã„ã‚‹ã®ã‹ã‚’å°‹ã­ã¦ã„ã¾ã™ã€‚ã¾ãŸã€åˆ¥ã®èª­è€…ã¯ã€ç›®æ¨™è¨­å®šã‚„ä¸»æµã®è€ƒãˆæ–¹ã¨ã¯ç•°ãªã‚‹ç¿’æ…£ã«ã¤ã„ã¦ã®ãƒã‚¤ãƒ³ãƒ‰ã‚»ãƒƒãƒˆã«é–¢ã™ã‚‹æŠ•ç¨¿ã‚’ã‚‚ã£ã¨è¦‹ãŸã„ã¨å¸Œæœ›ã—ã¦ã„ã¾ã™ã€‚\n\nTynanã¯ã€æŠ•è³‡æˆ¦ç•¥ã«ã¤ã„ã¦ã®ç°¡å˜ãªæ›´æ–°ã‚’è¡Œã„ã€é«˜é‡‘åˆ©ã®ãŸã‚ã«ãƒãƒ¼ã‚¸ãƒ³ã‚’ã‚ã¾ã‚Šä½¿ç”¨ã—ãªããªã£ãŸã¨è¿°ã¹ã¦ã„ã¾ã™ã€‚ã•ã‚‰ã«ã€ã‚ã‚‹èª­è€…ã¯ã€TynanãŒç‹¬è‡ªã®ãƒ©ã‚¤ãƒ•ã‚¹ã‚¿ã‚¤ãƒ«é¸æŠã‚’é€šã˜ã¦ä»–ã®äººã«ã‚¤ãƒ³ã‚¹ãƒ”ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä¸ãˆã¦ã„ã‚‹ã“ã¨ã‚’ç§°è³›ã—ã¦ã„ã¾ã™ã€‚åˆ¥ã®èª­è€…ã¯ã€è‡ªåˆ†ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ã«ã¤ã„ã¦ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æ±‚ã‚ã¦ãŠã‚Šã€ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ã‚ˆã‚Šã‚‚ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã«èˆˆå‘³ãŒã‚ã‚‹ã¨è¡¨æ˜ã—ã¦ã„ã¾ã™ã€‚\n\nå…¨ä½“ã¨ã—ã¦ã€ã“ã®è­°è«–ã¯å€‹äººã®æˆé•·ã€æŠ•è³‡æˆ¦ç•¥ã€ãã—ã¦å‹ç ´ã‚Šãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®ä¾¡å€¤ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ã¾ã™ã€‚"
    }
  },
  {
    "id": "5dfd668acccef666",
    "title": {
      "en": "Writing a Bash builtin in C to parse INI configs",
      "ko": "Cë¡œ INI íŒŒì„œ ë§Œë“¤ê¸°",
      "ja": "Cã§INIè§£æï¼"
    },
    "type": "story",
    "url": "https://mbuki-mvuki.org/posts/2021-07-12-writing-a-bash-builtin-in-c-to-parse-ini-configs/",
    "score": 26,
    "by": "namanyayg",
    "time": 1743199687,
    "content": "Writing a Bash Builtin in C to Parse INI Configs\n\n          2021-07-12\n\n            Programming\n\n            Bash\n\n             ,\n            Shell\n\n             ,\n            C\n\n    Why Not Just Parse INI Configs With Bash?\n    What is a Bash Builtin?\n    Why Would You Write a Builtin?\n    Minimal Builtin, Implementing sleep\n    Writing an INI Parser Builtin\n\n        Generating Help Output\n        Informing Bash About our Builtin\n        Parsing Options and Reading Stdin\n        Modifying Bashâ€™s Internal State, Injecting Data\n        Building & Testing\n        Letâ€™s Try It!\n\n    Closing Thoughts\n    Further Reading\n    Acknowledgments\n\n      Why Not Just Parse INI Configs With Bash?\nShell languages such as Bash excel at certain tasks, such as gluing\nprograms together or quickly automating a set of command line steps. In\ncontrast to those strengths, using a Shell to parse an\nINI config file is a bit like\nwriting a poem in mud, you might succeed, but the result will probably\nbe inscrutable and your swear\njar will be full! As this\nwonderful Stack Overflow\npost\nattests there are many different ways to parse an INI file in Bash, but\nfew of the answers provided are elegant.\nSo if you have a task poorly suited to Bash, what are your options?\n\nChoose another language for the task? (Perhaps sensible, but not\nalways fun.)\n\nWrite a custom Bash builtin to extend Bash for the task? (Spoiler,\nthis is the route we will choose!)\n\nWhat is a Bash Builtin?\nA builtin is a command in Bash that is implemented in the shell itself,\nrather than as a separate program. They are the batteries included with\nBash. If you type help in Bash you get a list of all the currently\nenabled builtins, or you can use type printf to check if a specific\ncommand is a builtin. Many of the commands you use regularly are\nbuiltins, e.g. echo, printf, and cd. They are typically\nimplemented in the language used to write the shell itself, so in the\ncase of Bash, C. Some of Bashâ€™s builtins are also available as separate\ncommands, depending on how your operating system is configured. For\nexample printf is a Bash builtin, but it is also usually available on\na Linux box as a separate program, try which printf to find out.\nBuiltins are preferred in Bash over external programs, as if they were\nplaced first in your PATH. Bash also allows you to write your own\ncustom builtins and load them into the shell, as does Zsh and the\nKornShell.\nWhy Would You Write a Builtin?\n\nWhy are builtins helpful?\nWhy not just rely entirely on external commands?\n\nYou could build a shell with a minimal set of builtins, but certain\nbuiltins are still necessary. For example the cd command must be a\nbuiltin, since calling chdir(2) in a forked process will have no\neffect on the parent shell process. The shell must execute the cd and\nthus the chdir(2) call in its own process. There are at least three\ncases, including the cd example, where builtins are necessary or\nuseful:\n\nAvoiding the need to fork an external process.\n\nCalling a system function that affects the shell process itself,\ne.g. chdir(2).\n\nModifying a shellâ€™s internal state, e.g. adding a variable.\n\nOur INI config parser builtin will demonstrate the utility of reason\nnumber (3). However, before we implement that builtin, let us try\nimplementing sleep as a builtin. Implementing sleep is a custom\nbuiltin challenge akin to printing Hello World! in a new language.\nMinimal Builtin, Implementing sleep\nEveryone needs sleep, but it can be costly in Bash. We had a program\nthat ironically slowed down after a\nspinner was\nadded to provide feedback to the user that the program was still\nrunning. The spinner called sleep 0.04 in a loop while printing the\nspinner characters to the screen. The creation of 25 forked processes\nper second actually slowed down the program! Bash does have a sleep\nbuiltin, but it is not enabled by default, letâ€™s create a simple\nimplementation:\ncopy#include \"builtins.h\"\n#include \"shell.h\"\n#include \"bashgetopt.h\"\n#include \"common.h\"\n#include <errno.h>\n\nchar *sleep_doc[] = {\"Patience please, wait for a bit!\", NULL};\n\nint sleep_builtin(WORD_LIST *list) {\n  if (!list) {\n    builtin_usage();\n    return EX_USAGE;\n  }\n  char *endptr;\n  char *secs_arg = list->word->word;\n  uintmax_t secs = strtoumax(list->word->word, &endptr, 10);\n  if ((secs == UINTMAX_MAX && errno == ERANGE) || (*endptr != '\\0')) {\n    builtin_error(\"Unable to convert `%s` to an integer\", secs_arg);\n    return EXECUTION_FAILURE;\n  }\n  unsigned int rem = sleep(secs);\n  if (rem == 0) {\n    return EXECUTION_SUCCESS;\n  } else {\n    builtin_error(\"Sleep interrupted, %d secs remaining\", rem);\n    return EXECUTION_FAILURE;\n  }\n}\n\n/* Provides Bash with information about the builtin */\nstruct builtin sleep_struct = {\n    .name = \"sleep\",             /* Builtin name */\n    .function = sleep_builtin,   /* Function implementing the builtin */\n    .flags = BUILTIN_ENABLED,    /* Initial flags for builtin */\n    .long_doc = sleep_doc,       /* Array of long documentation strings. */\n    .short_doc = \"sleep NUMBER\", /* Usage synopsis; becomes short_doc */\n    .handle = 0                  /* Reserved for internal use */\n};\nThe struct builtin is what informs Bash about our builtin. Notably we\nprovide a function here, sleep_builtin, which is essentially our\nbuiltinâ€™s main. This function is supplied with any args provided to\nour builtin. In our sleep_builtin function we check if we have an arg,\nif so, we try to convert the arg to an integer and sleep(3) for that\nnumber of seconds. Letâ€™s try it out:\ncopy$ enable -f ./sleep.so sleep\n$ help sleep\nsleep: sleep NUMBER\n    Patience please, wait for a bit!\n$ time sleep 1\nreal    0m1.000s\nuser    0m0.000s\nsys 0m0.000s\n$ sleep â°\nbash: sleep: Unable to convert `â°` to an integer\nFabulous, so with a small amount of code and minimal boilerplate we have\ncreated a dynamically loaded Bash builtin! The sleep builtin satisfies\nreason number (1) on why you might write a builtin by eliminating the\nneed to fork a process for each sleep execution. With sleep as a\nbuiltin each call is a function call rather than a process fork(2),\ni.e. bring back the spinner! But, it does not satisfy reason number\n(3), changing Bashâ€™s internal state. Letâ€™s implement an INI parser to\nsatisfy reason number (3) and provide a more complete example of\ncreating a Bash builtin.\nWriting an INI Parser Builtin\nGenerating Help Output\nFirst weâ€™ll create our help ini doc which provides the builtin\ndocumentation inside of Bash. This help text provides an overview of how\nour INI parser will affect Bashâ€™s state:\ncopychar *ini_doc[] = {\n    \"Reads an INI config from stdin input into a set of associative arrays.\",\n    \"\",\n    \"Reads an INI config from stdin input into a set of associative arrays.\",\n    \"The sections of the INI config are added to an associative array\",\n    \"specified by the `-a TOC` argument. The keys and values are then added to\",\n    \"associative arrays prefixed by the `TOC` name and suffixed by their INI\",\n    \"section name, `<TOC>_<INI_SECTION_NAME>`. The parsed INI section names\",\n    \"must be valid Bash variable names, otherwise an error is returned.\",\n    \"\",\n    \"Example:\",\n    \"\",\n    \"  Input input.ini:\",\n    \"    [sec1]\",\n    \"    foo = bar\",\n    \"\",\n    \"    [sec2]\",\n    \"    biz = baz\",\n    \"\",\n    \"  Result:\",\n    \"    $ ini -a conf < input.ini\",\n    \"    $ declare -p conf\",\n    \"    declare -A conf=([sec1]=\\\"true\\\" [sec2]=\\\"true\\\" )\",\n    \"    $ declare -p conf_sec1\",\n    \"    declare -A conf_sec1=([foo]=\\\"bar\\\" )\",\n    \"    $ declare -p conf_sec2\",\n    \"    declare -A conf_sec2=([biz]=\\\"baz\\\" )\",\n    \"\",\n    \"If the `-u FD` argument is passed the INI config is read from the `FD`\",\n    \"file descriptor rather than from stdin. Variables are created with local\",\n    \"scope inside a function unless the `-g` option is specified.\",\n    NULL};\nInforming Bash About our Builtin\ncopystruct builtin ini_struct = {\n    .name = \"ini\",            /* Builtin name */\n    .function = ini_builtin,  /* Function implementing the builtin */\n    .flags = BUILTIN_ENABLED, /* Initial flags for builtin */\n    .long_doc = ini_doc,      /* Array of long documentation strings. */\n    .short_doc =\n        \"ini -a TOC [-u FD] [-g]\", /* Usage synopsis; becomes short_doc */\n    .handle = 0                    /* Reserved for internal use */\n};\nAs we did with the sleep builtin we initialize a struct builtin that\nincludes our ini_doc array as well as our short doc string. The second\nmember of the struct is the sh_builtin_func_t which is the main\nfunction of our builtin.\nParsing Options and Reading Stdin\nBash provides an internal_getopt function which is akin to\ngetopt(3), but uses Bashâ€™s internal WORD_LIST structure. We parse\nour mandatory argument -a for the name of the associative array which\nwill contain our INI section names. We parse our optional -u argument\nwhich specifies an alternative file\ndescriptor to read from\nrather than the default of stdin. Once we have our file descriptor we\ncall fdopen(3) to obtain a FILE stream structure which we pass to\nour INI parser.\ncopyint ini_builtin(WORD_LIST *list) {\n  intmax_t intval;\n  int opt, code;\n  int fd = 0;\n  bool global_vars = false;\n  char *toc_var_name = NULL;\n  reset_internal_getopt();\n  while ((opt = internal_getopt(list, \"a:gu:\")) != -1) {\n    switch (opt) {\n    case 'a':\n      toc_var_name = list_optarg;\n      break;\n    case 'g':\n      global_vars = true;\n      break;\n    case 'u':\n      code = legal_number(list_optarg, &intval);\n      if (code == 0 || intval < 0 || intval != (int)intval) {\n        builtin_error(\"%s: invalid file descriptor specification\", list_optarg);\n        return EXECUTION_FAILURE;\n      }\n      fd = (int)intval;\n      if (sh_validfd(fd) == 0) {\n        builtin_error(\"%d: invalid file descriptor: %s\", fd, strerror(errno));\n        return EXECUTION_FAILURE;\n      }\n      break;\n    case GETOPT_HELP:\n      builtin_help();\n      return EX_USAGE;\n    default:\n      builtin_usage();\n      return EX_USAGE;\n    }\n  }\n  if (!toc_var_name) {\n    builtin_usage();\n    return EX_USAGE;\n  }\n  FILE *file = fdopen(fd, \"r\");\n  if (!file) {\n    builtin_error(\"%d: unable to open file descriptor: %s\", fd,\n                  strerror(errno));\n    return EXECUTION_FAILURE;\n  }\n  /* snip */\n}\nModifying Bashâ€™s Internal State, Injecting Data\nThe INI builtin creates a TOC or table of contents associative array\nspecifying which INI sections were found. Then for each INI section it\ncreates a <TOC>_<INI_SECTION_NAME> associative array. First we create\nthe TOC var:\ncopy/* snip */\nini_conf conf = {};\nconf.toc_var_name = toc_var_name;\nif (variable_context && !global_vars) {\n  conf.local_vars = true;\n} else {\n  conf.local_vars = false;\n}\nSHELL_VAR *toc_var = NULL;\nif (conf.local_vars) {\n  int vflags = 0;\n  toc_var = make_local_assoc_variable(toc_var_name, vflags);\n} else {\n  toc_var = make_new_assoc_variable(toc_var_name);\n}\nif (!toc_var) {\n  builtin_error(\"Could not make %s\", toc_var_name);\n  return EXECUTION_FAILURE;\n}\nif (ini_parse_file(file, handler, &conf) < 0) {\n  builtin_error(\"Unable to read from fd: %d\", fd);\n  return EXECUTION_FAILURE;\n}\nreturn EXECUTION_SUCCESS;\n/* snip */\nWe check Bashâ€™s variable_context to see if it is greater than zero\nwhich indicates we are in a function. If we are in a function we create\nlocal variables, unless the -g option was passed to our builtin. We\nthen setup our config for our INI parser. Bash provides functions to\ncreate local, make_local_assoc_variable and global variables,\nmake_new_assoc_variable. Once we have created our TOC variable we\ncall the ini_parse_file function with our file, config, and handler\nfunction. We are using the excellent\ninih library to do the complicated\nparsing of the INI, but we do need to implement the inih handler\nfunction:\ncopy/* This is the inih handler called for every new section and for every name and\n * value in a section. This function creates and populates our associative\n * arrays in Bash. Both for the TOC array as well as for the individual section\n * arrays, <TOC>_<INI_SECTION_NAME> */\nstatic int handler(void *user, const char *section, const char *name,\n                   const char *value) {\n  ini_conf *conf = (ini_conf *)user;\n  char *toc_var_name = conf->toc_var_name;\n  /* Create <TOC>_<INI_SECTION_NAME> */\n  char *sep = \"_\";\n  size_t sec_size = strlen(toc_var_name) + strlen(section) + strlen(sep) +\n                    1; // +1 for the NUL character\n  char *sec_var_name = xmalloc(sec_size);\n  char *sec_end = sec_var_name + sec_size - 1;\n  char *p = memccpy(sec_var_name, toc_var_name, '\\0', sec_size);\n  if (!p) {\n    builtin_error(\"Unable to create section name\");\n    return 0;\n  }\n  p = memccpy(p - 1, sep, '\\0', sec_end - p + 2);\n  if (!p) {\n    builtin_error(\"Unable to create section name\");\n    return 0;\n  }\n  p = memccpy(p - 1, section, '\\0', sec_end - p + 2);\n  if (!p) {\n    builtin_error(\"Unable to create section name\");\n    return 0;\n  }\n  if (!legal_identifier(sec_var_name)) {\n    sh_invalidid(sec_var_name);\n    free(sec_var_name);\n    return 0;\n  }\n  /* New section parsed */\n  if (!name && !value) {\n    SHELL_VAR *toc_var = find_variable(toc_var_name);\n    if (!toc_var) {\n      free(sec_var_name);\n      builtin_error(\"Could not find %s\", toc_var_name);\n      return 0;\n    }\n    bind_assoc_variable(toc_var, toc_var_name, strdup(section), \"true\", 0);\n    SHELL_VAR *sec_var = NULL;\n    if (conf->local_vars) {\n      int vflags = 0;\n      sec_var = make_local_assoc_variable(sec_var_name, vflags);\n    } else {\n      sec_var = make_new_assoc_variable(sec_var_name);\n    }\n    if (!sec_var) {\n      builtin_error(\"Could not make %s\", sec_var_name);\n      free(sec_var_name);\n      return 0;\n    }\n    free(sec_var_name);\n    return 1;\n  }\n  if (!name) {\n    free(sec_var_name);\n    builtin_error(\"Malformed ini, name is NULL!\");\n    return 0;\n  }\n  if (!value) {\n    free(sec_var_name);\n    builtin_error(\"Malformed ini, value is NULL!\");\n    return 0;\n  }\n  SHELL_VAR *sec_var = find_variable(sec_var_name);\n  bind_assoc_variable(sec_var, sec_var_name, strdup(name), strdup(value), 0);\n  free(sec_var_name);\n  return 1;\n}\nIn the handler we create our sec_var_name or\n<TOC>_<INI_SECTION_NAME> string. Then if the handler was called at the\nstart of a new section we create an associative array for that section.\nOtherwise, we use Bashâ€™s find_variable function to retrieve our\nexisting variable. Once we have our variable, Bash provides functions to\nalter a variableâ€™s value. Here we use bind_assoc_variable to populate\nan entry in our associative array with the name and value from the INI\nparser. With our handler function complete our Bash builtin is ready to\nparse some INI configs.\nBuilding & Testing\nWe put together a little Makefile to build and test our builtins:\ncopySHELL=/bin/bash\nCC:=gcc\nCFLAGS:=-c -Wall -Wextra -fPIC\nBASH_FLAGS:=$(shell pkgconf --cflags bash)\nLDFLAGS:=--shared\nINIH_FLAGS:=-DINI_CALL_HANDLER_ON_NEW_SECTION=1 -DINI_STOP_ON_FIRST_ERROR=1 \\\n    -DINI_USE_STACK=0\n\nini.so: inih/ini.o\n\n%.so: %.o\n    $(CC) -o $@ $^ $(LDFLAGS)\n\n%.o: %.c\n    $(CC) $(CFLAGS) -o $@ $^\n\ninih/ini.o: CFLAGS += $(INIH_FLAGS)\nini.o: CFLAGS += $(BASH_FLAGS)\nsleep.o: CFLAGS += $(BASH_FLAGS)\n\ninih/ini.c:\n    git submodule update --init\n\n.PHONY: test\ntest: ini.so\n    ./test\n    @echo Tests Passed\n\n.PHONY: clean\nclean:\n    shopt -s globstar; rm -f **/*.o **/*.so\nHere we compile our ini.c file as well as the inih library, then we\nlink them together into a shared library. Our testing methodology is\nrudimentary, we have a Bash script which exercises the features of our\nbuiltin and we compare its output against a canonical copy:\ncopy#!/bin/bash\n\nset -o errexit\nset -o nounset\n\nnew=$(mktemp)\nbash test.sh >\"$new\"\ndiff -u test_output \"$new\"\nLetâ€™s Try It!\nNow that we have compiled and tested our INI builtin, letâ€™s feed it a\nconfig for a fictional RSS reader and see how it performs.\ncopy$ enable -f ./ini.so ini\n$ ini -a rss_conf <<'EOF'\n > [Computers]\n > Vidar's Blog = http://www.vidarholen.net/contents/blog/?feed=rss2\n > Two-Bit History = https://twobithistory.org/feed.xml\n > www.linusakesson.net = http://www.linusakesson.net/rssfeed.php\n >\n > [Comics]\n > xkcd = http://xkcd.com/rss.xml\n >\n > [Books]\n > The Marlowe Bookshelf = http://themarlowebookshelf.blogspot.com/feeds/posts/default\n > EOF\n$ for section_name in \"${!rss_conf[@]}\"; do\n >   printf '## %s\\n' \"$section_name\"\n >   declare -n section='rss_conf_'\"$section_name\"\n >   for key in \"${!section[@]}\"; do\n >     printf ' - %s: %s\\n' \"$key\" \"${section[$key]}\"\n >   done\n > done\n## Books\n - The Marlowe Bookshelf: http://themarlowebookshelf.blogspot.com/feeds/posts/default\n## Comics\n - xkcd: http://xkcd.com/rss.xml\n## Computers\n - www.linusakesson.net: http://www.linusakesson.net/rssfeed.php\n - Two-Bit History: https://twobithistory.org/feed.xml\n - Vidar's Blog: http://www.vidarholen.net/contents/blog/?feed=rss2\nOur TOC var rss_conf holds our section names, then we use Bashâ€™s\nnameref functionality to point a variable to each associative array for\na given INI section from the rss_conf associative array and iterate\nover the section associative arrays. We have the RSS config loaded into\nour Bash program, now we just need to build the application to consume\nit!\nClosing Thoughts\nBash builtins provide a number of positive features. They provide an\ninteresting avenue for extending Bash to perform tasks which are perhaps\npoorly suited to be written in the Bash language itself. Builtins also\nallow Bash to leverage the vast quantity of well tested and established\nC libraries. Lastly, as was hopefully demonstrated in the examples, Bash\nprovides a good framework for builtins and a set of functions that makes\nmodifying Bashâ€™s internal state straightforward.\nGiven the positives of Bash builtins, why arenâ€™t there\nmore\nof them? There are two possibilities that stand out:\n\nThe intersection of people that write Bash and C is rather small?\nThe distribution of custom Bash builtins is not well paved, limiting\ntheir utility?\n\nThe second possibility rings the most true to me, I would love to see\ninnovation and improvement on the use and distribution of Bash builtins.\nIdeally you could enable your builtins and they would be fetched along\nwith your main script and packed into a single binary, perhaps something\nakin to ruby-packer but for\nBash. Bring your ideas!\nFurther Reading\n\nThe full source code of this ini\nbuiltin\nThe inih library used to parse the INI\nconfigs\nBash builtin examples from Bashâ€™s source\ncode\n\nAcknowledgments\nThanks to Randall Mason for\nproviding feedback on this post.",
    "summary": {
      "en": "### Summary: Writing a Bash Builtin in C to Parse INI Configs\n\nThis text discusses how to create a custom Bash builtin in C to parse INI configuration files. \n\n#### Key Points:\n\n1. **Why Not Use Bash Alone?** \n   - Bash is great for automating tasks but not ideal for parsing INI files, which can lead to messy and complex scripts. Instead, writing a builtin can simplify the process.\n\n2. **What is a Bash Builtin?**\n   - A builtin is a command implemented directly in Bash itself, rather than as a separate program. Examples include `echo`, `printf`, and `cd`. Builtins are often faster and more efficient than external commands.\n\n3. **Benefits of Writing a Builtin:**\n   - Builtins can avoid the overhead of creating a new process.\n   - They can modify the shell's internal state, which is essential for certain tasks.\n   - The article focuses on creating a builtin for parsing INI files, which will demonstrate these benefits.\n\n4. **Example of a Minimal Builtin (sleep):**\n   - The text describes how to implement a simple `sleep` command as a builtin to show the process of creating and registering a new builtin with Bash.\n\n5. **Creating an INI Parser Builtin:**\n   - The parser reads INI files from standard input and stores the data in associative arrays. \n   - It includes generating help output, parsing command options, and injecting data into Bash's internal state.\n\n6. **Implementation Details:**\n   - The builtin is designed to read INI sections into associative arrays, with specific options for global or local variable scope.\n   - The text discusses the use of a handler function that processes each section and key-value pair in the INI file.\n\n7. **Building and Testing:**\n   - A Makefile is provided to compile the builtin, and a script is used for testing its functionality.\n\n8. **Conclusion:**\n   - Bash builtins are powerful tools for extending functionality. There is potential for more innovation and distribution of custom builtins, which could enhance their utility in scripting.\n\nOverall, the text serves as a guide for developers interested in extending Bash by creating custom builtins in C, particularly for tasks like parsing configuration files.",
      "ko": "ì´ ê¸€ì—ì„œëŠ” C ì–¸ì–´ë¡œ INI êµ¬ì„± íŒŒì¼ì„ íŒŒì‹±í•˜ê¸° ìœ„í•œ ë§ì¶¤í˜• Bash ë‚´ì¥ ëª…ë ¹ì–´ë¥¼ ë§Œë“œëŠ” ë°©ë²•ì— ëŒ€í•´ ì„¤ëª…í•©ë‹ˆë‹¤.\n\nBashëŠ” ì‘ì—… ìë™í™”ì— ìœ ìš©í•˜ì§€ë§Œ INI íŒŒì¼ì„ íŒŒì‹±í•˜ëŠ” ë°ëŠ” ì í•©í•˜ì§€ ì•Šì•„ ë³µì¡í•˜ê³  ì§€ì €ë¶„í•œ ìŠ¤í¬ë¦½íŠ¸ê°€ ìƒê¸¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ë‚´ì¥ ëª…ë ¹ì–´ë¥¼ ì‘ì„±í•˜ë©´ ì´ ê³¼ì •ì„ ê°„ì†Œí™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nBash ë‚´ì¥ ëª…ë ¹ì–´ë€ Bash ìì²´ì— ì§ì ‘ êµ¬í˜„ëœ ëª…ë ¹ì–´ë¡œ, ë³„ë„ì˜ í”„ë¡œê·¸ë¨ì´ ì•„ë‹™ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ `echo`, `printf`, `cd` ë“±ì´ ìˆìŠµë‹ˆë‹¤. ë‚´ì¥ ëª…ë ¹ì–´ëŠ” ì™¸ë¶€ ëª…ë ¹ì–´ë³´ë‹¤ ë¹ ë¥´ê³  íš¨ìœ¨ì ì…ë‹ˆë‹¤.\n\në‚´ì¥ ëª…ë ¹ì–´ë¥¼ ì‘ì„±í•˜ëŠ” ì¥ì ì€ ì—¬ëŸ¬ ê°€ì§€ê°€ ìˆìŠµë‹ˆë‹¤. ìƒˆë¡œìš´ í”„ë¡œì„¸ìŠ¤ë¥¼ ìƒì„±í•˜ëŠ” ì˜¤ë²„í—¤ë“œë¥¼ í”¼í•  ìˆ˜ ìˆê³ , íŠ¹ì • ì‘ì—…ì— í•„ìˆ˜ì ì¸ ì…¸ì˜ ë‚´ë¶€ ìƒíƒœë¥¼ ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ê¸€ì—ì„œëŠ” INI íŒŒì¼ì„ íŒŒì‹±í•˜ê¸° ìœ„í•œ ë‚´ì¥ ëª…ë ¹ì–´ë¥¼ ë§Œë“œëŠ” ë° ì´ˆì ì„ ë§ì¶”ì–´ ì´ëŸ¬í•œ ì¥ì ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.\n\nê°„ë‹¨í•œ ë‚´ì¥ ëª…ë ¹ì–´ì¸ `sleep`ì˜ ì˜ˆë¥¼ í†µí•´ ìƒˆë¡œìš´ ë‚´ì¥ ëª…ë ¹ì–´ë¥¼ ìƒì„±í•˜ê³  Bashì— ë“±ë¡í•˜ëŠ” ê³¼ì •ì„ ì„¤ëª…í•©ë‹ˆë‹¤. ì´ íŒŒì„œëŠ” í‘œì¤€ ì…ë ¥ì—ì„œ INI íŒŒì¼ì„ ì½ê³  ë°ì´í„°ë¥¼ ì—°ê´€ ë°°ì—´ì— ì €ì¥í•©ë‹ˆë‹¤. ë˜í•œ ë„ì›€ë§ ì¶œë ¥ì„ ìƒì„±í•˜ê³ , ëª…ë ¹ ì˜µì…˜ì„ íŒŒì‹±í•˜ë©°, Bashì˜ ë‚´ë¶€ ìƒíƒœì— ë°ì´í„°ë¥¼ ì£¼ì…í•˜ëŠ” ê¸°ëŠ¥ë„ í¬í•¨ë©ë‹ˆë‹¤.\n\në‚´ì¥ ëª…ë ¹ì–´ëŠ” INI ì„¹ì…˜ì„ ì—°ê´€ ë°°ì—´ë¡œ ì½ë„ë¡ ì„¤ê³„ë˜ì—ˆìœ¼ë©°, ì „ì—­ ë˜ëŠ” ì§€ì—­ ë³€ìˆ˜ ë²”ìœ„ì— ëŒ€í•œ íŠ¹ì • ì˜µì…˜ì´ ìˆìŠµë‹ˆë‹¤. ê° ì„¹ì…˜ê³¼ í‚¤-ê°’ ìŒì„ ì²˜ë¦¬í•˜ëŠ” í•¸ë“¤ëŸ¬ í•¨ìˆ˜ì˜ ì‚¬ìš©ì— ëŒ€í•´ì„œë„ ë…¼ì˜í•©ë‹ˆë‹¤.\n\në‚´ì¥ ëª…ë ¹ì–´ë¥¼ ì»´íŒŒì¼í•˜ê¸° ìœ„í•œ Makefileì´ ì œê³µë˜ë©°, ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•˜ê¸° ìœ„í•œ ìŠ¤í¬ë¦½íŠ¸ë„ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n\nBash ë‚´ì¥ ëª…ë ¹ì–´ëŠ” ê¸°ëŠ¥ì„ í™•ì¥í•˜ëŠ” ê°•ë ¥í•œ ë„êµ¬ì…ë‹ˆë‹¤. ë§ì¶¤í˜• ë‚´ì¥ ëª…ë ¹ì–´ì˜ í˜ì‹ ê³¼ ë°°í¬ ê°€ëŠ¥ì„±ì€ ìŠ¤í¬ë¦½íŒ…ì—ì„œì˜ ìœ ìš©ì„±ì„ ë”ìš± ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ê¸€ì€ êµ¬ì„± íŒŒì¼ì„ íŒŒì‹±í•˜ëŠ” ì‘ì—…ê³¼ ê°™ì€ ê¸°ëŠ¥ì„ ìœ„í•´ Cë¡œ ë§ì¶¤í˜• ë‚´ì¥ ëª…ë ¹ì–´ë¥¼ ë§Œë“œëŠ” ë° ê´€ì‹¬ì´ ìˆëŠ” ê°œë°œìë“¤ì„ ìœ„í•œ ê°€ì´ë“œ ì—­í• ì„ í•©ë‹ˆë‹¤.",
      "ja": "ã“ã®æ–‡ç« ã§ã¯ã€INIè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æã™ã‚‹ãŸã‚ã«Cè¨€èªã§ã‚«ã‚¹ã‚¿ãƒ Bashãƒ“ãƒ«ãƒˆã‚¤ãƒ³ã‚’ä½œæˆã™ã‚‹æ–¹æ³•ã«ã¤ã„ã¦èª¬æ˜ã—ã¦ã„ã¾ã™ã€‚\n\nBashã¯ã‚¿ã‚¹ã‚¯ã®è‡ªå‹•åŒ–ã«å„ªã‚Œã¦ã„ã¾ã™ãŒã€INIãƒ•ã‚¡ã‚¤ãƒ«ã®è§£æã«ã¯å‘ã„ã¦ã„ãªã„ãŸã‚ã€è¤‡é›‘ã§æ‰±ã„ã«ãã„ã‚¹ã‚¯ãƒªãƒ—ãƒˆã«ãªã‚ŠãŒã¡ã§ã™ã€‚ãã“ã§ã€ãƒ“ãƒ«ãƒˆã‚¤ãƒ³ã‚’ä½œæˆã™ã‚‹ã“ã¨ã§ãƒ—ãƒ­ã‚»ã‚¹ã‚’ç°¡ç´ åŒ–ã§ãã¾ã™ã€‚\n\nBashãƒ“ãƒ«ãƒˆã‚¤ãƒ³ã¨ã¯ã€Bashè‡ªä½“ã«ç›´æ¥å®Ÿè£…ã•ã‚ŒãŸã‚³ãƒãƒ³ãƒ‰ã®ã“ã¨ã§ã™ã€‚ä¾‹ãˆã°ã€`echo`ã‚„`printf`ã€`cd`ãªã©ãŒã‚ã‚Šã¾ã™ã€‚ãƒ“ãƒ«ãƒˆã‚¤ãƒ³ã¯å¤–éƒ¨ã‚³ãƒãƒ³ãƒ‰ã‚ˆã‚Šã‚‚é«˜é€Ÿã§åŠ¹ç‡çš„ã§ã™ã€‚\n\nãƒ“ãƒ«ãƒˆã‚¤ãƒ³ã‚’ä½œæˆã™ã‚‹åˆ©ç‚¹ã«ã¯ã€æ–°ã—ã„ãƒ—ãƒ­ã‚»ã‚¹ã‚’ä½œæˆã™ã‚‹ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ã‚’é¿ã‘ã‚‰ã‚Œã‚‹ã“ã¨ã‚„ã€ã‚·ã‚§ãƒ«ã®å†…éƒ¨çŠ¶æ…‹ã‚’å¤‰æ›´ã§ãã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚ã“ã®è¨˜äº‹ã§ã¯ã€INIãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æã™ã‚‹ãŸã‚ã®ãƒ“ãƒ«ãƒˆã‚¤ãƒ³ã‚’ä½œæˆã™ã‚‹ã“ã¨ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ãŠã‚Šã€ã“ã‚Œã‚‰ã®åˆ©ç‚¹ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚\n\næœ€å°é™ã®ãƒ“ãƒ«ãƒˆã‚¤ãƒ³ã®ä¾‹ã¨ã—ã¦ã€`sleep`ã‚³ãƒãƒ³ãƒ‰ã®å®Ÿè£…æ–¹æ³•ãŒèª¬æ˜ã•ã‚Œã¦ã„ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€æ–°ã—ã„ãƒ“ãƒ«ãƒˆã‚¤ãƒ³ã‚’Bashã«ç™»éŒ²ã™ã‚‹ãƒ—ãƒ­ã‚»ã‚¹ãŒç¤ºã•ã‚Œã¾ã™ã€‚\n\nINIãƒ‘ãƒ¼ã‚µãƒ¼ãƒ“ãƒ«ãƒˆã‚¤ãƒ³ã¯ã€æ¨™æº–å…¥åŠ›ã‹ã‚‰INIãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€ãƒ‡ãƒ¼ã‚¿ã‚’é€£æƒ³é…åˆ—ã«æ ¼ç´ã—ã¾ã™ã€‚ã¾ãŸã€ãƒ˜ãƒ«ãƒ—å‡ºåŠ›ã®ç”Ÿæˆã‚„ã‚³ãƒãƒ³ãƒ‰ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®è§£æã€Bashã®å†…éƒ¨çŠ¶æ…‹ã¸ã®ãƒ‡ãƒ¼ã‚¿æ³¨å…¥ã‚‚å«ã¾ã‚Œã¦ã„ã¾ã™ã€‚\n\nå®Ÿè£…ã®è©³ç´°ã¨ã—ã¦ã€ãƒ“ãƒ«ãƒˆã‚¤ãƒ³ã¯INIã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’é€£æƒ³é…åˆ—ã«èª­ã¿è¾¼ã‚€ã‚ˆã†ã«è¨­è¨ˆã•ã‚Œã¦ãŠã‚Šã€ã‚°ãƒ­ãƒ¼ãƒãƒ«ã¾ãŸã¯ãƒ­ãƒ¼ã‚«ãƒ«å¤‰æ•°ã‚¹ã‚³ãƒ¼ãƒ—ã®ç‰¹å®šã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³ãŒã‚ã‚Šã¾ã™ã€‚INIãƒ•ã‚¡ã‚¤ãƒ«å†…ã®å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚„ã‚­ãƒ¼ã¨å€¤ã®ãƒšã‚¢ã‚’å‡¦ç†ã™ã‚‹ãƒãƒ³ãƒ‰ãƒ©é–¢æ•°ã®ä½¿ç”¨ã«ã¤ã„ã¦ã‚‚èª¬æ˜ã•ã‚Œã¦ã„ã¾ã™ã€‚\n\nãƒ“ãƒ«ãƒˆã‚¤ãƒ³ã‚’ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã™ã‚‹ãŸã‚ã®MakefileãŒæä¾›ã•ã‚Œã¦ãŠã‚Šã€ãã®æ©Ÿèƒ½ã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹ãŸã‚ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚‚ç”¨æ„ã•ã‚Œã¦ã„ã¾ã™ã€‚\n\nBashãƒ“ãƒ«ãƒˆã‚¤ãƒ³ã¯æ©Ÿèƒ½ã‚’æ‹¡å¼µã™ã‚‹ãŸã‚ã®å¼·åŠ›ãªãƒ„ãƒ¼ãƒ«ã§ã™ã€‚ã‚«ã‚¹ã‚¿ãƒ ãƒ“ãƒ«ãƒˆã‚¤ãƒ³ã®é©æ–°ã‚„é…å¸ƒã®å¯èƒ½æ€§ãŒã‚ã‚Šã€ã‚¹ã‚¯ãƒªãƒ—ãƒˆã«ãŠã‘ã‚‹æœ‰ç”¨æ€§ã‚’é«˜ã‚ã‚‹ã“ã¨ãŒæœŸå¾…ã•ã‚Œã¾ã™ã€‚ã“ã®æ–‡ç« ã¯ã€è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®è§£æãªã©ã®ã‚¿ã‚¹ã‚¯ã®ãŸã‚ã«Cè¨€èªã§ã‚«ã‚¹ã‚¿ãƒ ãƒ“ãƒ«ãƒˆã‚¤ãƒ³ã‚’ä½œæˆã—ãŸã„é–‹ç™ºè€…å‘ã‘ã®ã‚¬ã‚¤ãƒ‰ã¨ãªã£ã¦ã„ã¾ã™ã€‚"
    }
  },
  {
    "id": "37d2b7611a1e31d6",
    "title": {
      "en": "A note on the USB-to-PS/2 mouse adapter that came with Microsoft mouse devices",
      "ko": "ë§ˆì´í¬ë¡œì†Œí”„íŠ¸ ë§ˆìš°ìŠ¤ ì–´ëŒ‘í„° íŒ",
      "ja": "ãƒã‚¤ã‚¯ãƒ­ã‚½ãƒ•ãƒˆã®ãƒã‚¦ã‚¹ã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼è§£èª¬"
    },
    "type": "story",
    "url": "https://devblogs.microsoft.com/oldnewthing/20250325-00/?p=110993",
    "score": 372,
    "by": "luu",
    "time": 1743120989,
    "content": "March 18, 2025\n      Why didnâ€™t Windows 95 setup use a miniature version of Windows 95 as its fallback GUI?\n\n        Raymond Chen",
    "summary": {
      "en": "On March 18, 2025, Raymond Chen posed a question about why the setup process for Windows 95 didn't use a smaller version of Windows 95 as a backup graphical user interface (GUI) in case of issues.",
      "ko": "2025ë…„ 3ì›” 18ì¼, ë ˆì´ë¨¼ë“œ ì²¸ì€ ìœˆë„ìš° 95ì˜ ì„¤ì¹˜ ê³¼ì •ì—ì„œ ë¬¸ì œê°€ ë°œìƒí•  ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ì‘ì€ ë²„ì „ì˜ ìœˆë„ìš° 95ë¥¼ ë°±ì—… ê·¸ë˜í”½ ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤(GUI)ë¡œ ì‚¬ìš©í•˜ì§€ ì•Šì€ ì´ìœ ì— ëŒ€í•´ ì§ˆë¬¸ì„ ë˜ì¡ŒìŠµë‹ˆë‹¤.",
      "ja": "2025å¹´3æœˆ18æ—¥ã€ãƒ¬ã‚¤ãƒ¢ãƒ³ãƒ‰ãƒ»ãƒã‚§ãƒ³ã¯ã€Windows 95ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ãƒ—ãƒ­ã‚»ã‚¹ã«ãŠã„ã¦ã€å•é¡ŒãŒç™ºç”Ÿã—ãŸéš›ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ç”¨ã®ã‚°ãƒ©ãƒ•ã‚£ã‚«ãƒ«ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ï¼ˆGUIï¼‰ã¨ã—ã¦ã€Windows 95ã®å°å‹ç‰ˆã‚’ä½¿ç”¨ã—ãªã‹ã£ãŸç†ç”±ã«ã¤ã„ã¦ç–‘å•ã‚’å‘ˆã—ã¾ã—ãŸã€‚"
    }
  },
  {
    "id": "327ccb524a039975",
    "title": {
      "en": "Show HN: Cursor IDE now remembers your coding prefs using MCP",
      "ko": null,
      "ja": null
    },
    "type": "story",
    "url": null,
    "score": 98,
    "by": "roseway4",
    "time": 1743173099,
    "content": null,
    "summary": {
      "en": null,
      "ko": null,
      "ja": null
    }
  },
  {
    "id": "44e224563abf2956",
    "title": {
      "en": "I asked police to send me their public surveillance footage of my car",
      "ko": "ë‚´ ì°¨ CCTV ìš”ì²­!",
      "ja": "è»Šã®ç›£è¦–æ˜ åƒè«‹æ±‚"
    },
    "type": "story",
    "url": "https://cardinalnews.org/2025/03/28/i-drove-300-miles-in-rural-virginia-then-asked-police-to-send-me-their-public-surveillance-footage-of-my-car-heres-what-i-learned/",
    "score": 629,
    "by": "bookofjoe",
    "time": 1743164046,
    "content": "<iframe title=\"Everlit Audio Player\" src=\"https://everlit.audio/embeds/artl_eQjyeH7pmVP?client=wp&amp;client_version=1.10.5\" width=\"100%\" height=\"130px\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen=\"\"></iframe>Two police officers walked into a doughnut shop.\n\nItâ€™s not the opening line of a joke; itâ€™s what I saw as I was working on an early draft of this story in March at the Staunton Dunkinâ€™, about a quarter mile from where my vehicle was captured on a Flock camera in January and February coming back from my trips to Cardinalâ€™s Roanoke office.\n\nTheir eyes may have strayed to the racks of Boston creme, lemon-filled and coconut-covered doughnuts as they strode to the counter with purpose, but they were here for something else.\n\nSurveillance footage.\n\nwindow.zone_load_1970831728 = function(z, d) { if (!d.count) document.getElementById('zone_load_1970831728').style.display = 'none'; };\n\n\t\t\t\tDon't miss another story! Sign up for Cardinalâ€™s free daily newsletter.\n\nDelivered to your inbox every day at 5 a.m.\n\n\t\t\t\t\t\tSign up\n\n\t\tThe research for State of Surveillance showed that you canâ€™t drive anywhere without going through a town, city or county thatâ€™s using public surveillance of some kind, mostly license plate reading cameras. I wondered how often I might be captured on camera just driving around to meet my reporters. Would the data over time display patterns that would make my behavior predictable to anyone looking at it?\n\nSo I took a daylong drive across Cardinal Country and asked 15 law enforcement agencies, using Freedom of Information Act requests, to provide me with the Flock LPR footage of my vehicle. My journey took me over 300 miles through slices of the communities those agencies serve, including the nearly 50 cameras they employ. And this journey may take me to one more place: an April Foolâ€™s Day hearing in a courtroom in Roanoke. There, a judge will be asked to rule on a motion to declare the footage of the public to be beyond the reach of the public.\n\nBut while Roanoke and Botetourt and two other police agencies denied my request for that footage, nine agencies complied and searched their data for signs of me passing through.\n\nHereâ€™s what I found.\n\nCheck out our podcast episode on Jeffâ€™s surveillance investigation.\n\n   Watch    February 13, 2025, I left Staunton around 7:30 in the morning to head toward Roanoke. Richmond Avenue, on the outskirts of the city, is probably the way most people make their way out of town to interstates 64 and 81. Itâ€™s a significant crossroad of the regionâ€™s major east-west and north-south highways.\n\nStaunton maintains at least one of its six Flock cameras on a local intersection just shy of the cluster of on- and off-ramps. It makes surveillance-sense to position cameras to see whoâ€™s coming in and whoâ€™s leaving your town at such a singular crossroad.\n\nI was not captured by a Flock camera there, though.\n\nAs part of its services, Flock advises police on where to place its tech. The top priority appears to be places of entry and exit around the community, notably near the main highways. Itâ€™s possible that Staunton doesnâ€™t have a camera taking pictures of who is leaving town; itâ€™s also possible my vehicleâ€™s plate was blocked by heavy morning traffic and so no photo could be taken.\n\nIt was a cold morning, but truckers and car drivers were behaving on the morning commute. Staying on I-81, I passed through Augusta, Rockbridge and Botetourt counties, which between them have at least eight Flock cameras. I didnâ€™t think any would be pointed at the main highway because currently Flock canâ€™t place its cameras on state property.\n\nNinety uneventful minutes later, I pulled into Roanoke to go to the Cardinal office and visit my Roanoke members of our own Cardinal team â€” which, in an unintentional irony in this story, we refer to as The Flock.\n\nI got into town just after 9:15 a.m. I know that because a Roanoke Police Department Flock camera captured my car traveling southbound down Williamson Road near the Salem Avenue intersection at 9:16:09 a.m. (That photo, as well as another, were provided by the Staunton police, as part of their arrangement to access other agenciesâ€™ data in their Flock searches.)\n\nYou can see from the image below exactly what Flock technology captures: a decent shot of the back of any vehicle that passes, a readable image of the license plate.\n\nPart of Flockâ€™s proprietary tech determines the make and model of the vehicle and also notes if there are bumper stickers, bike racks, any other unique markings that would help identify that vehicle. That generates a â€œvehicle fingerprintâ€ for every car or truck, which none of the agencies I FOIAâ€™d would provide me. That fingerprint could prove helpful in the case where a witness or other camera captured some non-license-plate information about a vehicle, like specific bumper stickers or a roof rack.\n\nI parked my car on Church Avenue, walked to the office and logged in to our morning news meeting. Some of our reporters were there in person; others began popping up on the screen from their beats in Danville, Martinsville and Bristol. We talked about our dayâ€™s work. Afterward, I drove around town just to see if Iâ€™d be picked up in a residential area. I started in Gainsboro. Snow covered the ground around the homes on Gilmer Avenue. I did not notice any cameras.\n\nI crossed town to Marshall Avenue and a neighborhood within a few blocks of the YMCA, and then on to another neighborhood sitting next to Interstate 581, which reaches across the town like a tight belt of loud traffic. Looking between homes, I saw the Roanoke Star, perched over trees frosted with ice not yet melted.\n\nEach of these neighborhoods had different backstories and histories you could see in the architecture of their homes, in the cars that parked on their streets. One thing they had in common on that cold morning: They were all very quiet. And I did not see any surveillance cameras.\n\nLater, I received no images of my car in those places. Flock can be used to monitor public space in suspected high-crime areas, which has earned it the wrath of rights organizations including the ACLU. Because Roanoke has only five cameras, according to contracts we received from the city, itâ€™s my guess they are not yet focusing on specific populations or neighborhoods.\n\nAfter those brief stops, I left town mid-morning. I canâ€™t tell you exactly when, and Iâ€™ll tell you why thatâ€™s relevant.\n\nWhen I eventually received data from the Staunton Police about my trip, I noticed that Flock cameras had photographed my vehicle in similar locations within both Staunton and Roanoke at similar times on another day, January 29. If you asked me today if I knew whether I had made a trip to the Roanoke office on Jan. 29, I would hesitate before I could answer. I would have to check my calendar and emails to be able to say that I was there, with certainty.\n\nBut the police would have known, if they wanted to, without asking for any kind of warrant or court order.\n\nCheck out the other stories in this ongoing series.\n\n\t\t\t\t\t\tCity of Roanoke, Botetourt County sheriff go to court over FOIA request\n\n\t\t\t\t\t\tState of Surveillance: Everyoneâ€™s watching\n\n\t\t\tFranklin County does have four Flock cameras, but my vehicleâ€™s image was not captured by any of them. Until I came into town, I was staying on routes 220 and 57.\n\nU.S. 220 was a misty spectacle on Feb. 13. Ice made trees sag. Thick limbs and branches crashed under the weight, closing the right lane of the highway in some places. Snow covered shaded places around buildings, but the roads were mostly clear, and traffic moved along. Nearing noon, milder temps had caused fog to rise up from the hollers. As I drove south past Boones Mill and Trump Town USA, I knew I would not trigger that townâ€™s lone operational Flock camera. Itâ€™s set up to catch northbound traffic.\n\nI entered Martinsville via Fayette Street. Martinsville has dozens of Flock cameras, 48 according to the contracts Cardinal News gathered, so I expected to be picked up multiple times. However, my vehicle was detected only once.\n\nEven the police chief, Rob Fincher, was surprised. He was open to running the test again, but I wasnâ€™t trying for statistical accuracy; I wanted this to be a record of a single day. There are lots of things that can get in the way of taking a clear picture, including glare and shadow and other things (cars in this case) getting between your camera and your subject. Some of those things may have been at play on that particular day.\n\nA Martinsville Flock camera did spot my vehicle at 12:11 p.m. eastbound on the way into town from its perch near the corner of West Church Street and South Memorial Boulevard.\n\nTwenty-two minutes later I was spreading cream cheese on a bagel and coffee at the Ground Floor. (I know the time because I took my own photo, not because of a surveillance camera timestamp.)\n\nThe place was bustling. On most tables stood a little rubbery Jesus toy. On one wall hangs a long roll of brown paper where people casually write their prayers. I was reminded that some people believe youâ€™re being watched 24/7 by a higher power, though Iâ€™d argue thereâ€™s likely a pretty high trust factor about how that surveillance might be utilized. I touched base with our Martinsville reporter Dean-Paul Stephens, and then headed for Danville.\n\n* * *\n\nSpeaking of trust and ethics: two weeks later, Lt. Greg Jones called me at the Roanoke office. The Amherst County Sheriffâ€™s Office had a question about my request for data about my vehicle.\n\nâ€œYou werenâ€™t trying to spy on a cheating wife or something like that, were you?â€ he asked.\n\nI assured him that I wasnâ€™t. As Cardinal Executive Director Luanne Rife points out in her column on Sunshine Week, public agencies donâ€™t have to agree with why youâ€™re asking for their public information. The idea is that it belongs to you already. They are under legal obligation to provide it to you.\n\nNot to say this question didnâ€™t cause some thought and conversation in the newsroom. Public surveillance data like this could indeed be used to stalk an ex; it could also be used by a person suspicious their ex is stalking them to see if their exâ€™s vehicle actually could be found on the same roads as theirs and at the same times, which could then be used to secure a protective order or even open a criminal investigation. It could be used by private investigators to find bail jumpers and missing persons. Now imagine all those requests coming in to the local police agencyâ€¦\n\nThe only reason it hadnâ€™t happened yet was because people really didnâ€™t know they could do that. Suddenly the cops could be in the position to find themselves spending hours looking up public surveillance for citizens with all sorts of reasons to utilize the data.\n\nSo was this a foolâ€™s errand I was on? I didnâ€™t think so. The police in over 80 of our local communities had chosen to start photographing citizens in their vehicles in public and sharing this with other agencies in our region and beyond, even out of state. I wasnâ€™t the one running over 500 searches a month on its citizens, as the Roanoke police were doing. And who knows who they were running those searches on, and why?\n\n* * *\n\nBy the time I reached Danville, the weather was almost warm. The sun was out and glancing through the empty trees along Craghead Street and in through the plate glass windows of Links Coffee House.\n\nI found out after requesting data from Danville that while they did have a contract with Flock, they had not yet installed the Flock cameras, according to Matt Bell, the cityâ€™s PR specialist.\n\nThe coffee was good. The casual conversation surveillance was rich with interesting dialogues. But I had miles to go. It was just before 2 p.m. Time to get moving again.\n\n* * *\n\nTraffic in Lynchburg was heavy around 3:30 p.m. as I drove north along U.S. 29 Business. I figured there might be at least some of Lynchburgâ€™s Flock cameras along the very busy Business 29, also known in that area as Wards Road.\n\nJust south of Liberty University, a Flock camera picked up my car near Wards Ferry Road. Lynchburg has at least a dozen Flock cameras, according to contracts we got from them during our reporting for our first State of Surveillance story. I figured one might be on this stretch of road.\n\nBy this point in the afternoon, the novelty of the day was wearing off. I got back on main route 29 and headed north.\n\nAlong the rest of the way, I passed through Amherst County, which has four Flock cameras; Nelson County, which has none; and Augusta County, with two cameras. Since I stuck to the main roads, U. S. 29 and then I-64, the chances of running into a camera were low. If Iâ€™d pulled off onto a main county road, things might have been different.\n\nIn March, Amherst would conduct a search and be unable to find my vehicle. Same with Augusta County.\n\nAt 4:59 p.m., I exited the highway onto Richmond Avenue in Staunton. This time a Flock camera spotted my vehicle and got a clear picture. I went home and ordered pizza.\n\nWhich brings me back to the cops in the coffee shop, a few weeks later.\n\n* * *\n\nAs I mentioned, the two police officers were not interested in doughnuts, or even coffee. They asked to speak to the manager. The counter person explained that the manager was at the other store across town. They asked if they could speak to that person on the phone.\n\nIt was then I noticed that a person who had come in with them was part of this conversation.\n\nFrom what I could gather, because I didnâ€™t pull out my press badge and start asking questions, the young woman with them had been in some kind of incident; and that the police had determined that maybe some of the video footage that Dunkin takes of its drive-through may have caught the other car as it passed on the road beyond; or maybe the offending vehicle had come through the drive-through.\n\nIn a few minutes, the officers and the woman were guided behind the counter to review footage.\n\nThis scene somehow made me feel optimistic about how weâ€™re already using such technology. It still operates under the notion that not all data belongs to the police. They have to ask, or convince a judge to give them a court order.\n\nYet just glancing at the footage I have included in this story, itâ€™s also a little creepy to see how as few as four to six pictures, properly time- and date-stamped, can establish patterns that could enable someone to know with some likelihood how they could intercept me on my way to work one morning.\n\nThere are two differences between police use of other visual data (like a storeâ€™s security video) and Flockâ€™s gathering of public footage (such as my car). In that first case, thereâ€™s a crime involved. And the privately captured video is granted to police voluntarily and for a good reason. Itâ€™s not theirs to take and examine at their leisure.\n\nPublic-facing LRP cameras like Flockâ€™s, on the other hand, capture vast amounts of data unrelated to any criminal activity. And thereâ€™s zero oversight outside of the law enforcement community.This goes back to the idea that footage taken of me in public, non-investigative in nature, can be considered investigative and not subject to a public information request, and concerns me.\n\nThe idea that a law enforcement agency will claim the images that we see in this story are â€œinvestigativeâ€ in nature â€” and need to be protected from me â€” tells me that they are worried about something else. What is it?\n\nItâ€™s a paradigm shift where we go from having an expectation of privacy even in public spaces to its inverse. Not only do we not have a right to privacy in public; we donâ€™t even have a right to see ourselves as the government and police might see us â€” a set of still moments in place and time from which they, not us, can decide what our story is.\n\nWe want to know what you think! Tell us what you think about surveillance or share your experiences here.\n\n\t\t\t\tEnjoying our free stories?\n\nDonate today to help Cardinal News remain free for everyone.\n\n\t\t\t\tOne-time\n\n\t\t\t\tMonthly\n\n\t\t\t\tAnnually\n\n\t\t\tOne-time\n\n\t\t\t\t\t\t\t\t\t\t\t\t\t$150\n\n\t\t\t\t\t\t\t\t\t\t\t\t\t$200\n\n\t\t\t\t\t\t\t\t\t\t\t\t\t$500\n\n\t\t\t\t\t\t\t\t\t\t\t\tOther\n\n\t\t\t\t\t\t\t\t\t\t\t\tDonation amount\n\n\t\t\t\t\t\t\t\t\t\t\t\t\t$\n\n\t\t\tMonthly\n\n\t\t\t\t\t\t\t\t\t\t\t\t\t$15\n\n\t\t\t\t\t\t\t\t\t\t\t\t\t$20\n\n\t\t\t\t\t\t\t\t\t\t\t\t\t$50\n\n\t\t\t\t\t\t\t\t\t\t\t\tOther\n\n\t\t\t\t\t\t\t\t\t\t\t\tDonation amount\t\t\t\t\t\t\t\t\t\t\t\tper month\n\n\t\t\t\t\t\t\t\t\t\t\t\t\t$\n\n\t\t\tAnnually\n\n\t\t\t\t\t\t\t\t\t\t\t\t\t$150\n\n\t\t\t\t\t\t\t\t\t\t\t\t\t$200\n\n\t\t\t\t\t\t\t\t\t\t\t\t\t$500\n\n\t\t\t\t\t\t\t\t\t\t\t\tOther\n\n\t\t\t\t\t\t\t\t\t\t\t\tDonation amount\t\t\t\t\t\t\t\t\t\t\t\tper year\n\n\t\t\t\t\t\t\t\t\t\t\t\t\t$\n\n\t\t\tThanks for joining our flock!\n\n\t\t\tDonate Now\n\n\tRelated stories\n\n\t\tTagged: Redbird Stories,State of Surveillance",
    "summary": {
      "en": "Two police officers visited a Dunkin' doughnut shop not for coffee, but to request surveillance footage. This highlights the growing presence of public surveillance, particularly license plate reading (LPR) cameras, in communities. The author undertook a drive across the region, requesting footage of their vehicle from law enforcement agencies to explore the extent of surveillance data available.\n\nDuring the journey, the author noted different locations where Flock cameras are installed, observing that while some areas were covered, their vehicle was not always captured by the cameras. The investigation revealed that police can easily track individuals' movements through this data, raising concerns about privacy and the potential misuse of surveillance information.\n\nThe author also reflected on the ethical implications of surveillance, considering how accessible this data could be misused and the lack of oversight in its collection. The narrative concludes with the notion that citizens may not have the right to see how they are viewed by law enforcement, signaling a shift in expectations of privacy in public spaces.",
      "ko": "ë‘ ëª…ì˜ ê²½ì°°ê´€ì´ ë˜í‚¨ ë„ë„› ê°€ê²Œë¥¼ ë°©ë¬¸í•œ ì´ìœ ëŠ” ì»¤í”¼ë¥¼ ë§ˆì‹œê¸° ìœ„í•´ì„œê°€ ì•„ë‹ˆë¼, ê°ì‹œ ì¹´ë©”ë¼ ì˜ìƒì„ ìš”ì²­í•˜ê¸° ìœ„í•´ì„œì˜€ë‹¤. ì´ëŠ” ì§€ì—­ ì‚¬íšŒì—ì„œ ê³µê³µ ê°ì‹œ, íŠ¹íˆ ì°¨ëŸ‰ ë²ˆí˜¸íŒ ì¸ì‹ ì¹´ë©”ë¼ì˜ ì¡´ì¬ê°€ ì ì  ë” ì»¤ì§€ê³  ìˆìŒì„ ë³´ì—¬ì¤€ë‹¤. ì €ìëŠ” ì´ ì§€ì—­ì„ ì°¨ë¡œ ëŒì•„ë‹¤ë‹ˆë©°, ìì‹ ì˜ ì°¨ëŸ‰ì— ëŒ€í•œ ì˜ìƒì„ ë²• ì§‘í–‰ ê¸°ê´€ì— ìš”ì²­í•´ ê°ì‹œ ë°ì´í„°ì˜ ë²”ìœ„ë¥¼ ì¡°ì‚¬í–ˆë‹¤.\n\nì—¬í–‰ ì¤‘ ì €ìëŠ” í”Œë¡ ì¹´ë©”ë¼ê°€ ì„¤ì¹˜ëœ ë‹¤ì–‘í•œ ì¥ì†Œë¥¼ í™•ì¸í–ˆìœ¼ë©°, ì¼ë¶€ ì§€ì—­ì—ì„œëŠ” ê°ì‹œê°€ ì´ë£¨ì–´ì¡Œì§€ë§Œ ìì‹ ì˜ ì°¨ëŸ‰ì´ í•­ìƒ ì¹´ë©”ë¼ì— í¬ì°©ë˜ì§€ëŠ” ì•Šì•˜ë‹¤ëŠ” ì ì„ ê´€ì°°í–ˆë‹¤. ì¡°ì‚¬ ê²°ê³¼, ê²½ì°°ì´ ì´ ë°ì´í„°ë¥¼ í†µí•´ ê°œì¸ì˜ ì´ë™ì„ ì‰½ê²Œ ì¶”ì í•  ìˆ˜ ìˆë‹¤ëŠ” ì‚¬ì‹¤ì´ ë“œëŸ¬ë‚¬ê³ , ì´ëŠ” ì‚¬ìƒí™œ ì¹¨í•´ì™€ ê°ì‹œ ì •ë³´ì˜ ì˜¤ìš© ê°€ëŠ¥ì„±ì— ëŒ€í•œ ìš°ë ¤ë¥¼ ë¶ˆëŸ¬ì¼ìœ¼ì¼°ë‹¤.\n\nì €ìëŠ” ë˜í•œ ê°ì‹œì— ëŒ€í•œ ìœ¤ë¦¬ì  í•¨ì˜ì— ëŒ€í•´ ìƒê°í•´ë³´ì•˜ë‹¤. ì´ ë°ì´í„°ê°€ ì–¼ë§ˆë‚˜ ì‰½ê²Œ ì˜¤ìš©ë  ìˆ˜ ìˆëŠ”ì§€ì™€ ìˆ˜ì§‘ ê³¼ì •ì—ì„œì˜ ê°ë… ë¶€ì¡±ì— ëŒ€í•´ ê³ ë¯¼í–ˆë‹¤. ì´ì•¼ê¸°ëŠ” ì‹œë¯¼ë“¤ì´ ë²• ì§‘í–‰ ê¸°ê´€ì— ì˜í•´ ì–´ë–»ê²Œ ì¸ì‹ë˜ëŠ”ì§€ë¥¼ ì•Œ ê¶Œë¦¬ê°€ ì—†ì„ ìˆ˜ë„ ìˆë‹¤ëŠ” ì ì„ ì–¸ê¸‰í•˜ë©°, ê³µê³µ ì¥ì†Œì—ì„œì˜ ì‚¬ìƒí™œ ê¸°ëŒ€ì¹˜ê°€ ë³€í™”í•˜ê³  ìˆìŒì„ ì‹œì‚¬í•˜ë©° ë§ˆë¬´ë¦¬ëœë‹¤.",
      "ja": "äºŒäººã®è­¦å¯Ÿå®˜ãŒãƒ€ãƒ³ã‚­ãƒ³ãƒ‰ãƒ¼ãƒŠãƒ„åº—ã‚’è¨ªã‚ŒãŸã®ã¯ã‚³ãƒ¼ãƒ’ãƒ¼ã‚’æ±‚ã‚ã‚‹ãŸã‚ã§ã¯ãªãã€ç›£è¦–ã‚«ãƒ¡ãƒ©ã®æ˜ åƒã‚’ãƒªã‚¯ã‚¨ã‚¹ãƒˆã™ã‚‹ãŸã‚ã§ã—ãŸã€‚ã“ã‚Œã¯ã€ç‰¹ã«ãƒŠãƒ³ãƒãƒ¼ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’èª­ã¿å–ã‚‹ã‚«ãƒ¡ãƒ©ã®ã‚ˆã†ãªå…¬å…±ã®ç›£è¦–ãŒåœ°åŸŸç¤¾ä¼šã§å¢—ãˆã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚è‘—è€…ã¯åœ°åŸŸã‚’ãƒ‰ãƒ©ã‚¤ãƒ–ã—ã€æ³•åŸ·è¡Œæ©Ÿé–¢ã«è‡ªåˆ†ã®è»Šã®æ˜ åƒã‚’æ±‚ã‚ã¦ã€ã©ã‚Œã ã‘ã®ç›£è¦–ãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨å¯èƒ½ã‹ã‚’æ¢ã‚Šã¾ã—ãŸã€‚\n\næ—…ã®é€”ä¸­ã§ã€è‘—è€…ã¯ãƒ•ãƒ­ãƒƒã‚¯ã‚«ãƒ¡ãƒ©ãŒè¨­ç½®ã•ã‚Œã¦ã„ã‚‹ã•ã¾ã–ã¾ãªå ´æ‰€ã‚’ç¢ºèªã—ã¾ã—ãŸã€‚ä¸€éƒ¨ã®ã‚¨ãƒªã‚¢ã§ã¯ç›£è¦–ãŒè¡Œã‚ã‚Œã¦ã„ã¾ã—ãŸãŒã€è‘—è€…ã®è»ŠãŒå¸¸ã«ã‚«ãƒ¡ãƒ©ã«æ‰ãˆã‚‰ã‚Œã¦ã„ã‚‹ã‚ã‘ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ã“ã®èª¿æŸ»ã‹ã‚‰ã€è­¦å¯ŸãŒã“ã®ãƒ‡ãƒ¼ã‚¿ã‚’é€šã˜ã¦å€‹äººã®å‹•ãã‚’ç°¡å˜ã«è¿½è·¡ã§ãã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã‚Šã€ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ã‚„ç›£è¦–æƒ…å ±ã®æ‚ªç”¨ã«ã¤ã„ã¦ã®æ‡¸å¿µãŒé«˜ã¾ã‚Šã¾ã—ãŸã€‚\n\nè‘—è€…ã¯ã¾ãŸã€ç›£è¦–ã®å€«ç†çš„ãªå´é¢ã«ã¤ã„ã¦è€ƒãˆã¾ã—ãŸã€‚ã“ã®ãƒ‡ãƒ¼ã‚¿ãŒã©ã‚Œã»ã©ç°¡å˜ã«æ‚ªç”¨ã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã‹ã€ãã—ã¦ãã®åé›†ã«å¯¾ã™ã‚‹ç›£è¦–ãŒæ¬ å¦‚ã—ã¦ã„ã‚‹ã“ã¨ã«ã¤ã„ã¦ã‚‚è§¦ã‚Œã¾ã—ãŸã€‚ç‰©èªã¯ã€å¸‚æ°‘ãŒæ³•åŸ·è¡Œæ©Ÿé–¢ã«ã©ã®ã‚ˆã†ã«è¦‹ã‚‰ã‚Œã¦ã„ã‚‹ã‹ã‚’çŸ¥ã‚‹æ¨©åˆ©ãŒãªã„ã‹ã‚‚ã—ã‚Œãªã„ã¨ã„ã†è€ƒãˆã§ç· ã‚ããã‚‰ã‚Œã€å…¬å…±ã®å ´ã«ãŠã‘ã‚‹ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ã®æœŸå¾…ãŒå¤‰ã‚ã‚Šã¤ã¤ã‚ã‚‹ã“ã¨ã‚’ç¤ºå”†ã—ã¦ã„ã¾ã™ã€‚"
    }
  }
]